the federal government is one of the world's largest and most diverse entities , with about $3.5 trillion in outlays in fiscal year 2013 , funding an extensive array of programs and operations .

it faces a number of significant fiscal , management , and performance challenges in responding to the diverse and increasingly complex issues it seeks to address .

addressing these challenges will require actions on multiple fronts .

for example , program structures that are outmoded , fragmented , overlapping , or duplicative and not up to the challenges of the times must be reformed or restructured .

in addition , weaknesses in management capacity , both government - wide and in individual agencies , undermine efficient and effective government .

moving forward , federal decision makers will be confronted with making tough choices in setting priorities as well as reforming programs and management practices to better link resources to results .

in that regard , the performance planning and reporting framework originally put into place by the government performance and results act of 1993 ( gpra ) , and significantly enhanced by the gpra modernization act of 2010 ( gprama ) , provides important tools that can help inform congressional and executive branch decision making to address challenges the federal government faces .

the office of management and budget's ( omb ) 2012 guidance implementing gprama established a strategic review process in which agencies , beginning in 2014 , were to conduct leadership - driven , annual reviews of their progress towards achieving each strategic objective — the outcome or impact the agency is intending to achieve through its various programs and initiatives — established in their strategic plans .

effective implementation of strategic reviews could help identify opportunities to reduce , eliminate , or better manage instances of fragmentation , overlap , and duplication because agencies are to identify the various organizations , program activities , regulations , tax expenditures , policies , and other activities that contribute to each objective , both within and outside the agency .

where progress in achieving an objective is lagging , the reviews are intended to identify strategies for improvement , such as strengthening collaboration to better address crosscutting challenges , or using evidence to identify and implement more effective program designs .

if successfully implemented in a way that is open , inclusive , and transparent — to congress , delivery partners , and a full range of stakeholders — this approach could help decision makers assess the relative contributions of various programs to a given objective .

successful strategic reviews could also help decision makers identify and assess the interplay of public policy tools that are being used to ensure that those tools are effective and mutually reinforcing , and results are being efficiently achieved .

we are required to review implementation of gprama at several critical junctures.specific objective for this report was to identify and illustrate , through case agency examples , practices that facilitate effective strategic reviews by federal agencies .

to identify and illustrate the practices , we analyzed and synthesized information gathered from this report is part of our response to that mandate .

our related legal requirements in gprama and omb guidance for implementing those requirements ; a literature review we conducted , which covered public administration and public policy journals , business administration journals , our body of work on performance management and program evaluation , and other sources on policies and practices that can facilitate or challenge the effectiveness of strategic reviews as a decision - making tool ; a guide for conducting strategic reviews developed by the performance improvement council ( pic ) ; documentation from six selected agencies' strategic review processes and results , including guidance , meeting agendas , relevant evidence used to inform the review , and internal and published summaries of the results ; interviews we conducted with more than 30 performance management and evaluation experts representing different levels of government , sectors ( e.g .

public , non - profit , foundations ) , and nations , who had experience with implementing elements of strategic reviews or academic or consultative expertise in this area ; interviews we conducted with officials involved in conducting strategic reviews at six selected agencies and staff from omb and the pic .

we selected six agencies to illustrate the practices we developed — the departments of agriculture ( usda ) , education ( education ) , homeland security ( dhs ) , and housing and urban development ( hud ) , and the environmental protection agency ( epa ) , and the national aeronautics and space administration ( nasa ) .

we selected these agencies based on various criteria .

this included the extent to which agency strategic review processes had a greater chance of addressing areas of fragmentation , overlap , and duplication , and high - risk issues identified in our past work .

we also considered agency results on selected leadership involvement and performance information use items in our 2013 survey of federal managers on performance and management issues .

our selection was also informed by agency size , based on the number of full - time equivalent employees , and suggestions about agencies with robust review processes from omb staff with government - wide perspective on agency strategic reviews .

see appendix i for additional information about the objective , scope , and methodology for this report .

we conducted this performance audit from august 2013 to july 2015 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

gprama requires omb to annually determine whether agencies have met the performance goals and objectives outlined in their performance plans and submit a report on unmet goals .

in implementing this provision , omb's guidance directs agencies to continue reporting on unmet performance goals in their annual performance reports , as has been required since fiscal year 1999 .

in addition , omb's guidance directs agencies to conduct leadership - driven , annual reviews of progress towards each strategic objective — the outcome or impact the agency is intending to achieve — established in the agency's strategic plan .

figure 1 , an illustrative example from omb's guidance , shows how strategic objectives relate to other goals within an agency's performance management structure .

agencies began conducting these reviews in fiscal year 2014 .

the results from their first round of reviews were published in their annual performance reports in february 2015 , as well as on performance.gov , the central governmentwide performance reporting website implemented by omb to meet gprama requirements .

omb's guidance directs agencies to provide a progress update for each strategic objective , including a brief summary of what progress was made and an explanation of the achievements made or challenges that have impeded progress .

as part of their reporting , agencies were to identify a portion of their objectives as ( 1 ) having demonstrated noteworthy progress and ( 2 ) focus areas for improvement .

according to omb's guidance , the results of these reviews should ( 1 ) inform long - term strategy ; ( 2 ) inform annual planning and budget formulation ; ( 3 ) facilitate identification and adoption of opportunities for improvement , including risk management ; ( 4 ) identify areas where additional program evaluation , other studies , or analyses of performance data are needed to determine effectiveness or set priorities ; ( 5 ) identify where additional skills or other capacity are needed ; ( 6 ) improve decision - making response time ; ( 7 ) strengthen collaboration on crosscutting issues ; and ( 8 ) improve transparency .

the pic also provided support to agencies as they began planning for and implementing their strategic reviews .

according to omb and pic staff , through the pic's internal reviews working group , agency officials shared information about their planned strategic review processes as well as lessons learned from the initial round of reviews .

the pic also hosted several summits focused on strategic reviews and published a guide in august 2014 on leading effective strategic reviews , based on agencies' initial experience .

moving forward , omb staff told us that they expect agencies' strategic review processes will mature over time , and as such expect the results of those reviews to mature over time as well .

according to omb staff , they used the information conveyed in figure 2 to communicate to agencies that they likely would not be able to fulfill all requirements in omb's guidance in initial implementation , but instead should develop a maturity model to ensure they continue to strengthen the reviews over time .

sufficient planning and preparation is important to ensure that the agency's strategic review process is successful .

our february 2013 report on data - driven performance reviews found this was critical to a successful review .

planning enhances the quality , credibility , and usefulness of the review , and helps ensure that participants' time and resources are used effectively .

establishing common purposes for strategic review meetings can build trust and encourage active participation by participants .

in addition , developing common terminology , policies , and procedures , and clarifying roles and responsibilities helps facilitate collaboration for productive meetings .

participants need to be prepared to review progress towards their strategic objectives and determine any subsequent actions .

key features for planning the strategic review include: leadership commitment and involvement .

agency leadership should be directly and visibly engaged in the review process and invest the time necessary to understand and interpret the evidence being presented .

this involvement fosters ownership among those involved in the review and helps ensure that participants take the reviews seriously and can make decisions and commitments with the knowledge and backing of leadership .

communication of expectations and time frames .

guidance and agendas provided in advance of review meetings can establish a common understanding of the purpose of the review , the process to be used , and time frames for completing the review .

in addition , standardized templates used to collect and share key information are helpful to facilitate strategic review discussions and help to ensure consistency across reviews .

accountability for results .

the focus of accountability should be on the responsible objective leader's role in credibly assessing progress in achieving a strategic objective using evidence .

agency leaders should hold objective leaders and other responsible managers accountable for knowing the progress being made in achieving outcomes and , if progress is insufficient , understanding why and having a plan for improvement .

if evidence is insufficient for assessing progress , managers should be held accountable for improving the availability and quality of the evidence so that it can be used effectively for decision making .

managers should also be held accountable for identifying and replicating effective practices to improve performance .

in addition , omb's guidance strongly encourages agencies to leverage existing decision - making processes to conduct strategic reviews .

according to the guidance , in most cases , the strategic reviews should be integrated into existing agency management processes to raise key decisions , issues , and analysis to agency leadership .

omb's guidance also provides agencies flexibility in developing their processes , stating that agencies should use a tailored approach that is appropriate for the nature of the agency's programs , operations , and strategic objectives and evidence available .

in developing the agency's strategic review process in late 2013 , nasa's performance improvement officer ( pio ) at the time and her staff sought input on the process from nasa senior leaders .

this group included the leaders for each of nasa's strategic objectives who typically represent the most senior official with direct oversight of the programs and activities supporting each objective , such as division directors and deputy associate administrators , among other senior positions .

according to pio staff , all of nasa's guiding principles for the strategic review process were informed by senior leadership , such as using existing management processes and structures , promoting transparency , and making the process intuitive and easy to understand .

nasa pio staff told us that this helped create buy - in and understanding for the strategic review process .

each strategic objective leader , along with deputy objective leaders and relevant nasa staff , was involved in conducting individual assessments of each objective and provided a suggested rating .

for example , the director of the heliophysics division was the strategic objective leader for the strategic review of the objective “understand the sun and its interactions with the earth and the solar system , including space weather.” nasa's pio and her staff then led crosscutting reviews of these individual assessments to identify themes and provide an independent rating recommendation .

following the crosscutting review , nasa's chief operating officer ( coo ) determined final ratings during a briefing attended by the pio and each of the strategic objective leaders .

at that meeting , a member of nasa's pio staff summarized review findings and results to the coo .

the coo then asked each strategic objective leader clarifying questions and sought suggestions that would lead to performance improvements before settling on the final rating .

according to nasa pio staff , this approach of having all strategic objective leaders ( and relevant program staff ) attend the entire briefing encouraged transparency , and the personal involvement of the coo encouraged accountability for results and performance improvements .

dhs's office of the chief financial officer / office of program analysis and evaluation ( cfo / pa&e ) leads departmental implementation of performance management activities , including strategic reviews .

in addition , each component agency has a designated pio and performance staff who coordinate efforts in their component agency as part of department - wide performance management activities .

for example , for u.s .

citizenship and immigration services ( uscis ) , this role is performed by the office of the uscis cfo .

in early january 2014 , cfo / pa&e met with component pios to provide a basis for understanding and participating in the department's first strategic reviews .

recognizing the important role that they played in the initial reviews , cfo / pa&e revised its orientation process for the 2015 strategic reviews to include a separate briefing for assessment leads — the senior executives who lead teams reviewing progress towards each strategic goal .

the dhs briefing slides informed participants about the related gprama requirement and omb's guidance , as well as the purpose and expected benefits of the department's strategic reviews , such as informing the next dhs strategic plan , strengthening collaboration , and informing program and budget reviews .

the briefing provided an overview of the department's strategic review process , describing a structured methodology for conducting the reviews and samples of four standard deliverables ( templates ) to be used to collect information from each assessment team .

it also identified the roles and responsibilities for various participants in the process , including assessment leads and teams conducting the review of each goal , the component and dhs pios , and cfo / pa&e staff .

the briefing also provided a timeline for implementing the department's strategic reviews , with specific dates for key activities to be completed .

among other responsibilities , usda's office of budget policy and analysis ( obpa ) oversees implementation of the department's performance management activities .

according to the associate director of obpa , who also serves as usda's pio , his office and relevant component agencies provide regular performance updates to the secretary on key initiatives , such as the blueprint for stronger service , an effort launched in 2012 to enhance administrative services and management operations .

for these updates , which primarily occur monthly , depending on the initiative , usda uses a standard template , known as a “quad chart,” to collect and present information to the secretary for decision making .

because of the secretary's familiarity with the quad chart format , the department adapted the chart for use in its strategic review process , known as the strategic objective annual review ( soar ) ( see figure 3 ) .

as illustrated in figure 3 , the soar quad chart includes the following information: the relevant agency or office within usda responsible for the objective and the officials leading the efforts , known as objective owners and lieutenants ; the strategic objective and the strategic goal it supports ; a summary of progress towards the objective and related achievements ; key performance indicators along with actual performance results compared to targets ; a discussion of challenges that could affect program outcomes ; and a description of next steps , crosscutting analysis , or evaluations to improve objective performance .

objective owners and lieutenants are responsible for populating the information in the quad charts .

subsequently , obpa reviews the quad charts before they go to the secretary to ensure consistency in information reported and progress assessments , identify any needed changes , and determine if the information provided could impact other initiatives across the department .

according to obpa officials , the quad charts provide usda leadership with succinct and sufficient information to make decisions to improve performance , such as approving new or modifying existing strategies , or adjusting time frames .

a strategic review starts with framing the outcome or impact the agency seeks to achieve .

according to omb guidance , strategic objectives should be relatively simple statements that break down the broader , mission - oriented strategic goals to a level that reflects the impact or outcome the agency is trying to achieve through its programs .

objectives should be framed so they can serve as standards against which an assessment can reasonably be performed to determine the effectiveness of the agency's implementation of its programs , as well as progress toward the ultimate outcome .

in some cases , defining and measuring the outcome related to a strategic objective may be relatively straightforward .

for example , increasing employment rates for participants who completed a training program is an outcome defined in a way that can be measured .

however , where agencies are focused on more long - term or complex outcomes , determining if the agency is making progress each year can be more challenging .

in these instances , the agency may need to break the strategic objectives into pieces that can be more easily be measured or assessed .

as part of its performance framework , nasa has associated time frames with its goals , as illustrated in figure 4 .

for the agency's planning process for its 2014 strategic plan and annual strategic review , strategic objective leaders developed success statements that covered up to a 10-year time frame for each of their objectives .

according to pio staff , for the success statements , objective leaders and staff were asked to characterize or define the outcomes of success in implementing their objectives in the next 10 years by answering questions such as , “what will the agency have completed , obtained , contributed , advanced ? ” nasa officials told us that because it can be difficult to measure progress towards long - term , scientific discovery - oriented outcomes , they also rely on underlying multiyear performance goals , annual performance indicators , and milestones to better plan for and understand near - term progress towards those objectives .

table 1 illustrates how nasa clarified long - term and near - term progress for its objective to understand the sun .

to frame dhs strategic goal 3.1 , “strengthen and effectively administer the immigration system,” in more concrete terms , the lead agency , uscis , focused on three sub - goals .

table 2 identifies the sub - goals and describes them .

in addition to the sub - goals , uscis also developed performance measures ( known as strategic measures ) as part of its ongoing performance monitoring efforts for this goal .

for example , one measure is the average processing cycle time ( in months ) for naturalization applications .

taken together , the sub - goals and performance measures show how dhs has identified measureable pieces of its efforts related to the larger goal .

it is critical to identify , at a conceptual level , the various strategies and factors that can help or hinder achievement of the strategic objective .

the federal government uses numerous activities and policy implementation tools , such as loans , grants , contracts , social and economic regulations , insurance , and tax expenditures , among others ( hereafter strategies ) to help address public problems .

however , since 2011 , our annual series of reports examining federal programs has found that agencies often employed overlapping or fragmented program strategies that were poorly coordinated .

in addition , because the federal government rarely works in isolation , the efforts of other levels of governments ( local , state , and international ) and sectors ( private and nonprofit ) frequently contribute to the achievement of an outcome as well .

beyond these strategies and efforts , factors both within and beyond the control of any particular agency — generally referred to as internal and external factors — may influence an outcome .

internally , these factors could include an agency's culture , management practices , and business processes .

external factors may include the economy , demographic trends , technological advances , and the natural environment .

the strategic review for each objective should take into account the comprehensive set of federal strategies , nonfederal efforts , and factors within and outside an agency's control related to the outcome .

the more complex the outcome , the more likely it is to be influenced by multiple strategies , nonfederal efforts , and factors .

although these influences may have been previously identified through an agency's strategic planning process or similar vehicle , they should be revisited as part of the strategic review to determine if anything has changed .

omb's guidance directs agencies to identify in their strategic plans the various organizations and policy tools , both within and external to the agency , that contribute to their strategic objectives .

however , our work reviewing gprama implementation has found weaknesses in agencies' abilities to identify contributors to their goals .

for example , in our april 2013 report on agency priority goals ( apg ) , we found that agencies had not always identified external organizations and policy tools that contributed to their goals , although required by gprama and omb's guidance .

we recommended that omb ensure agencies adhere to its guidance by providing complete information about the contributors to their apgs .

omb staff agreed with this recommendation .

according to information provided by omb staff in april 2015 , agencies were asked to identify organizations , program activities , regulations , policies , tax expenditures , and other activities contributing to their 2014-2015 apgs , first as part of the september 2014 update to performance.gov , with opportunities for revisions in subsequent quarterly updates .

our analysis found that agencies have made progress in identifying external organizations and programs for their apgs , but they did not present this information consistently on performance.gov .

although each apg webpage has a location where agencies are to identify contributing programs , agencies did not always identify external organizations and programs there .

instead , they identified these external contributors elsewhere , such as apg overview or strategy sections , which could limit the ability of users to easily locate this information .

we will continue to monitor progress on implementation of this recommendation .

using existing knowledge , expertise , and evidence , those involved in the review should identify the strategies , nonfederal efforts , and factors that are likely to have the strongest influence on the outcome .

this information will help to establish priorities for the scope of the review .

there are a number of methods that can be used to map or model the causal relationships among the inputs , processes , and outputs produced by various strategies and the forces that influence achievement of outcomes , such as results mapping and logic modeling .

these methods can help to clarify the issues that must be addressed conceptually to create change or achieve the intended outcome .

by identifying and examining the various influences on the strategic objective or expected outcome during the strategic review , an agency can better understand how the existing set of program outputs and activities are contributing to the achievement of outcomes and whether gaps exist or changes are needed in light of all the other factors that are influencing outcomes .

recognizing that some of these influences may present risks or challenges to achieving expected outcomes , omb's 2014 update to its guidance ( covering agency's strategic reviews in 2015 ) states that while agencies cannot mitigate all risks related to achieving strategic objectives and performance goals , they should identify , measure , and assess to that challenges related to mission delivery , to the extent possible .

end , the guidance encourages agencies to institute an enterprise risk management ( erm ) approach , and leverage such efforts when conducting strategic reviews .

the guidance defines erm as an effective agency - wide approach for addressing the full spectrum of the organization's risks by understanding their combined impact as an interrelated portfolio , rather than addressing risks within silos .

the guidance further states that with an erm approach , agencies can be better positioned to quickly gauge which risks are directly aligned to strategic objectives , and which have the highest probability of impacting the agency's mission.opportunities and challenges are routinely identified , analyzed , and such an approach can help ensure that addressed , as appropriate , enhancing the agency's capacity to more efficiently and effectively determine priorities and allocate resources .

dhs's review of its strategic goal 2.2 “safeguard and expedite lawful trade and travel” involved four component agencies: customs and border protection ( cbp , the designated lead agency for the review ) , the transportation security administration ( tsa ) , immigration and customs enforcement ( ice ) , and the u.s. coast guard ( coast guard ) .

according to cbp officials , each of these component agencies plays a role in implementing strategies supporting this goal .

according to dhs's strategic plan for fiscal years 2014-2018 , the strategies for this goal are to ( 1 ) safeguard key nodes , conveyances , and pathways ; ( 2 ) manage the risk of people and goods in transit ; and ( 3 ) maximize compliance with u.s. trade laws and promote u.s. economic security and com - petitiveness .

the goal leader — cbp's executive director for planning , program analysis , and evaluation , within the office of field operations , who also led the assessment team — asked participating officials from the four contributing agencies to identify which of their programs and activities contributed to the achievement of the goal , and then subsequently to rank them by level of influence .

table 3 provides illustrative examples of programs and activities that support this goal from each of the four contributing component agencies .

according to cbp officials who coordinated the review , participating officials determined that a few of the programs and activities they initially identified as contributing to the goal had relatively minor influence towards the outcome .

in these instances , the programs and activities primarily supported another dhs goal .

dhs officials decided to include only those programs that primarily supported the goal under review .

for example , cbp officials determined that cbp's container security initiative , which works with foreign governments to examine potentially high - risk cargo prior to departure from the foreign port of origin , may have had influence on safeguarding trade and travel , but more directly supported another dhs goal , “secure u.s. air , land , and sea borders and approaches. .

usda's food and nutrition service ( fns ) seeks to increase food security and reduce hunger by providing children and low - income people access to food , a healthful diet , and nutrition education in a way that supports american agriculture and inspires public confidence .

fns uses a logic model ( figure 5 ) to understand how its programs and other factors influence outcomes related to usda's objective to “improve access to nutritious food.” fns first developed the logic model in the early 2000s as part of an effort to better integrate performance measurement into its operations .

fns officials told us that the concepts included in the logic model are often used when the agency is making decisions about performance measurement and evaluation because it shows the connections among program inputs , outputs , and overall outcomes .

by making those linkages explicit , decision makers can have more focused and meaningful discussions for how proposed strategies are tied to desired results and how to measure the success of strategy execution and impact , according to fns officials .

as part of the strategic review process , fns used its logic model to reaffirm the connections between program outputs and related outcomes .

as illustrated in figure 5 , the logic model shows how the output of fns's programs ( left column ) contribute to relevant near - term and long - term outcomes ( the three columns to the right ) .

the model covers five contributing fns programs: child and adult care food program ( cacfp ) , fresh fruit and vegetable program ( ffvp ) , national school lunch program ( nslp ) , supplemental nutrition assistance program ( snap ) , and special supplemental nutrition program for women , infants , and children ( wic ) .

at each level , the logic model identifies related performance measures as well as external factors that could influence progress , such as fns and state implementing agency resource levels , competing priorities and policies , and food price and availability .

because the achievement of outcomes may be complex and involve a variety of contributors from within an agency , or include other federal agencies , levels of government , and sectors , it is critical to consider which key stakeholders should be involved in a strategic review .

each of these stakeholders provides a unique perspective on their contribution or view of progress of the outcome under review .

omb's guidance and our past work reinforce the importance of including key stakeholders in the review .

omb's guidance states that the analysis of each objective should be conducted at the objective lead level , with support from relevant bureaus and programs , and that the coo and pio office should be involved in analysis and decision making across all objectives .

our prior report on effective practices for data - driven performance reviews also indicated that performance review participants should include high - level leaders and managers with an agency - wide perspective , as well as those with programmatic knowledge and responsibility for the specific performance issues likely to be raised .

each of the six agencies covered by our work for this report developed strategic review processes that involved relevant internal stakeholders , from contributing program officials to the agency head or coo .

agencies should also consider including the perspectives of relevant third - party policy experts , academics , professional associations , end users / clients or advocacy groups that represent them in the review process .

when outcomes are complex and involve multiple organizations , it is also important to establish how existing collaboration mechanisms can facilitate joint data collection , analysis , and reporting , or if new networks should be established .

in some cases , there may be an existing interagency group , such as a task force , that has been formed to achieve an outcome .

our prior work has shown that agencies that participated in various planning and decision - making forums together — such as interagency councils or planning bodies — reported that such interactions contributed to achieving their goals .

specifically , agencies reported that such participation opened lines of communication , fostered trust , and helped build relationships , which can in turn lead to more effective collaboration across agency lines .

in spite of the compelling rationale for all parties contributing to an outcome to collaborate , our past work on gprama implementation has found that agencies generally have not included external stakeholders when reviewing progress on an outcome .

in our report on implementation of data - driven reviews in february 2013 , we concluded that as the implementation of various gprama provisions continues , agencies may need to reevaluate the most effective way to engage outside stakeholders in the performance review processes for apgs and other performance goals that depend on other organizations to achieve desired outcomes .

we recommended that omb work with the pic and other relevant groups to identify and share promising practices to help agencies extend their quarterly performance reviews to include , as relevant , representatives from outside organizations that contribute to achieving their agency performance goals .

omb staff generally agreed with this recommendation .

as of april 2015 , omb staff told us that agencies continue to find that most apg reviews are appropriately focused on internal agency management , rather than involving external stakeholders .

therefore , omb and the pic have focused recent efforts on developing and sharing promising practices related to conducting reviews internal to the agencies or on improving evidence / measurement .

we will continue to monitor progress on implementation of this recommendation .

gao - 13-228 .

office of the secretary , who serves as the objective leader .

the review involved officials from the office of special needs assistance programs within the office of community planning and development , which administers the department's homelessness programs , such as the continuum of care program , which funds local networks of organizations to quickly rehouse individuals and minimize the trauma and dislocation caused to individuals , families , and communities by homelessness .

in addition , the review included participants from other hud offices , such as the office of public and indian housing and the office of multifamily housing , whose programs can assist in ending homelessness .

for example , the office of public and indian housing's housing choice voucher program provides rental subsidies for low - income families , which may include families experiencing homelessness .

this crosscutting and inclusive approach reinforced one of hud's strategies supporting this objective — to fully engage and leverage mainstream housing assistance to build capacity among public housing agencies and multifamily owners to admit homeless households into their units .

although no one outside of hud directly participated in the review , hud officials stated that they leveraged their existing relationship with officials at the u.s. interagency council on homelessness ( interagency council ) and the 18 other federal agencies that comprise it to better understand how other federal programs are contributing to progress in ending this included attending and homelessness for the target populations.participating in various meetings , including quarterly meetings with the interagency council principals , staff - level coordinating meetings , and targeted working groups , such as bimonthly meetings of the chronic and family homelessness working group .

in addition , as part of this objective , hud and the department of veterans affairs ( va ) share an apg to end veterans homelessness .

hud officials described regular coordination between the two agencies , in conjunction with interagency council officials , to monitor progress towards the goal .

in its strategic review of dhs strategic goal 3.1 , “strengthen and effectively administer the immigration system,” uscis involved two organizations that understand and promote the appropriate level of attention to the rights and views of uscis customers — dhs's office for civil rights and civil liberties ( crcl ) and the office of the citizenship and immigration services ombudsman ( cisomb ) .

while both offices are within dhs , organizationally they are located outside of uscis .

crcl supports the department's mission to secure the nation while preserving individual liberty , fairness , and equality under the law .

cisomb , which was created by congress in 2002 , assists industry and other employers with the services and benefits provided by uscis .

cisomb maintains neutrality and identifies issues where trends or policy could be corrected with uscis by making formal recommendations and providing an annual report to congress .

according to uscis officials , strategic review participants from cisomb and crcl were able to offer perspectives that reflected the views of those who receive services and benefits provided by uscis .

the presence of a crcl representative helped to ensure that concerns related to civil rights and civil liberties were given proper consideration when discussing the administration of citizenship and immigration benefits , according to those involved in the review .

for example , the crcl representative shared that while reaching certain output or outcome goals is important , it is also critical to clearly communicate the various means through which uscis customers can contest , appeal , or seek reconsideration of certain adverse determinations involving dhs employees or programs , or to correct outdated or otherwise incorrect information that could impact determinations .

according to uscis officials , the crcl representative's comment led them to evaluate , during the strategic review , whether the agency was clearly communicating the various avenues for customers to seek redress .

they subsequently determined that it was .

overall , the uscis officials involved in the strategic review told us that the presence of cisomb representatives helped ensure the review accurately portrayed the views and experiences of customers and employers that interacted with and received benefits from uscis .

a representative from cisomb told us that because of their institutional knowledge regarding the impact of uscis activities , cisomb officials involved in the strategic review were able to ask informed questions about the evidence presented during the strategic review .

in one instance , cisomb representatives encouraged uscis participants to broaden their assessment beyond quantitative output data to identify the impact of the agency's public engagement efforts .

uscis officials said this was valuable input from the cisomb representatives , and refocused the review to also look at the quality and end results of uscis's services to its customers .

officials in epa's office of solid waste and emergency response ( oswer ) told us that , concurrent with the strategic review of an objective related to the cleanup and reuse of contaminated sites , they launched a working group with the agency for toxic substances and disease registry ( atsdr ) located within the center for disease control and prevention at the department of health and human services .

this group was created to collaborate in better understanding methodology to assess human health at superfund sites .

oswer is responsible for providing policy , guidance , and direction for epa's emergency response and waste programs , including the superfund program .

the superfund program responds to abandoned and active hazardous waste sites and accidental chemical releases .

atsdr is responsible for performing specific functions concerning the effect on public health of hazardous substances in the environment , such as public health assessments of waste sites and health consultations concerning specific hazardous substances .

the objectives of the working group were to develop measures to estimate the number of people exposed to or potentially exposed to contaminants at superfund sites , as well as the number of people who are now protected as a result of actions taken by oswer and atsdr .

from this collaboration , the working group made recommendations to improve the methodology for determining measures to assess health impacts and oswer's clean - up efforts at its clean - up sites .

while the collaborative effort was not completed in time to be incorporated into the fiscal year 2014 strategic review findings , oswer officials told us the project had stronger internal support because the type of evidence the working group was seeking to develop could help with reviewing progress on the strategic objective .

going forward , oswer officials told us that the results of the epa / atsdr working group could help subsequent strategic reviews by producing better evidence of the superfund program's effectiveness in achieving the “promote sustainable and livable communities” objective .

given the long - term and complex nature of many outcomes , the strategic review should be informed by a variety of evidence regarding the implementation of strategies and their effectiveness in achieving the outcome .

omb's guidance states that the strategic review process should consider multiple perspectives and sources of evidence to understand the progress made on each strategic objective .

this should include progress made by the agency towards the performance goals and measures related to the strategic objective as well as program evaluations , research studies , data , and policy analysis relevant to the objective or its related programs.evidence , studies conducted by external entities , such as academics , think tanks , nonprofits , associations , and oversight entities ( such as ourselves or inspectors general ) , may prove useful to the review .

while performance measurement and program evaluations can serve as key evidence for assessing progress , our past work has identified issues with agencies' capacities to develop and use these types of evidence in decision making .

performance measurement is the ongoing monitoring and reporting of program accomplishments , particularly progress toward preestablished goals .

because of its ongoing nature , performance measurement can serve as an early warning system to management and as a vehicle for improving accountability to the public .

although our work on federal performance measurement during the past 2 decades has found an increase in the reported presence of different types of performance measures across the government , it has not resulted in similar increases in the reported use of performance information in decision making .

moreover , in june 2013 , we found that agencies continue to face common , long - standing difficulties in measuring the performance of various types of federal programs and activities — contracts , direct services , grants , regulations , research and development , and tax expenditures .

we recommended that the director of omb work with the pic to develop a detailed approach to examine these difficulties across agencies , including identifying and sharing any promising practices from agencies that have overcome difficulties in measuring the performance of these program types .

omb staff agreed with this recommendation .

as of april 2015 , omb and the pic have taken some initial steps to address this recommendation in a few areas , such as acquisition management ( contracts ) .

in addition , according to information provided by omb staff , the pic formed a working group on performance measurement that , in part , is focusing on how to develop appropriate performance measures .

however , omb has not yet developed a comprehensive and detailed approach to address these issues as envisioned in our report .

we will continue to monitor progress on implementation of this recommendation .

program evaluations are individual systematic studies conducted periodically or on an ad hoc basis to assess how well a program is working .

a program evaluation's typically more in - depth examination of program performance and context allows for an overall assessment of whether the program works and identification of adjustments that may improve its results .

however , as reported in june 2013 based on results from a governmentwide survey , we found that most federal managers lacked recent evaluations of their programs.reported that an evaluation had been completed within the past 5 years of any program , operation , or project in which they were involved .

another 40 percent of managers reported that they did not know if an evaluation had been completed .

however , 80 percent of managers who did have evaluations reported that those evaluations contributed to a moderate or greater extent to improving program management or performance , and to assessing program effectiveness or value .

our past work has found that the capacity to collect and analyze useful evidence is critical to successful reviews .

to be useful to various decision makers , evidence must be accessible , accurate , complete , credible , consistent , relevant , timely , and valid .

in addition , having the capacity to disaggregate data according to demographic , geographic , or other relevant characteristics can aid in highlighting significant variation , which can help meeting participants to pinpoint problems and identify solutions .

agencies also need to plan for the time and resources required to generate and communicate performance data and other evidence in a timely manner .

easy access to relevant databases and systems - generated analysis , such as providing analysts with the ability to develop performance reports without relying on information technology staff , can streamline the data collection and analysis processes .

hud's office of policy development and research ( pd&r ) is responsible for maintaining current information on housing needs , market conditions , and existing programs , as well as conducting research on priority housing and community development issues .

according to hud performance staff , pd&r supported the review of each strategic objective by providing a template containing the most relevant research and evaluations related to each objective .

this included both hud - funded and external evidence .

in addition , hud's performance staff asked objective leaders to supplement the evidence provided by pd&r with any additional evidence they thought would inform the review .

figure 6 provides examples of the research and evaluations that informed the department's review of its objective to end homelessness for veterans , people experiencing chronic homelessness , families , youth , and children .

hud performance staff told us that when a strategy has a clear outcome measure tied to departmental funding and support , identifying or developing relevant research was a lower priority because the existing measures provided an understanding of progress towards a goal or objective .

for example , they told us that hud has outcome information for its rental housing programs , in terms of individuals who are subsequently housed .

hud performance staff told us they were more concerned about developing new performance measures and identifying relevant research to inform policy changes where existing strategies lacked clear measures .

for instance , hud does not have broader outcome information on how all of its rental housing programs help individuals become more self - sufficient in terms of obtaining further education or employment .

prior to kicking off the review for dhs's goal to strengthen and administer the immigration system , uscis performance staff compiled relevant evidence — including agency performance data , program evaluations , and relevant reports by us and the dhs inspector general — into a database to allow strategic review team members to focus on analyzing the evidence and determining progress in achieving the goal .

in compiling the database , performance staff summarized key findings from the evidence and provided potential users with the source of the evidence so they could obtain additional context , if necessary .

further , they categorized the evidence to allow for easy sorting by users .

for example , the evidence could be sorted by the sub - goal to which it was related ; dhs's four assessment areas it supported ; whether it represented an accomplishment , planned activity , challenge / recommendation , a study , or other information ; and key contributing organization within uscis .

figure 7 provides an excerpt from this database , illustrating how agency performance data on processing applications was categorized .

for its objective to promote sustainable and livable communities , oswer officials developed what they called a “ladder of evidence” — a framework and inventory of relevant performance information , scientific studies , academic research , and program evaluations , which they then assessed and categorized by strength .

officials said the different levels ( types ) of evidence allowed them to better assess and communicate the results of oswer's programs .

the first level of evidence provides descriptive data , covering information about what oswer does , whom it serves and why , and performance trends over time .

for example , one performance measure at this level is the number of superfund sites with human exposure to contamination under control .

the second level of evidence identifies a relationship between oswer's activities and its outcomes .

it provides evidence about the effectiveness of program implementation which can help identify promising practices or problematic areas for further study .

the third level of evidence establishes a causal link between oswer's programs and the impact they are having on human health and environmental outcomes .

figure 8 provides additional information about each level of evidence along with illustrative examples .

using relevant evidence , strategic review participants should assess whether strategies are being implemented as planned and whether they are having the desired effect , as well as whether other factors are influencing results .

the review may highlight areas where action is needed to improve or enhance implementation and impact .

the following questions , based broadly on practices from omb's guidance and our past work on performance management , could help participants focus and facilitate this assessment and determine any needed actions .

if progress is lagging , why and what actions ( strategy changes , revised management practices , legislative or budgetary proposals , etc. ) .

could lead to better results ? .

are there any potential gaps in strategy ? .

conversely , is there any unnecessary overlap and duplication ? .

addressing such issues could lead to improvements in effectiveness and efficiency .

where progress is sufficient or exceeding expectations , are there strategies or practices that could be replicated and / or scaled to further enhance effectiveness ? .

have there been recent changes in the agency's operating environment that need to be addressed ? .

are there strengths / opportunities on which to capitalize ? .

are there weaknesses / threats that need to be overcome ? .

if the review identified evidence gaps , what steps will the agency take to develop sufficient evidence ? .

in addition , omb's guidance suggests additional actions that agencies should consider , which could lead to enhanced performance .

these include benchmarking information from others trying to accomplish the same or similar objectives or using the same or similar key process , and identifying lessons learned from past efforts to continuously improve service delivery and resolve management challenges .

education officials told us that , in addition to the department's policy development and spending plan review , they used the strategic review process to assess how recent changes to its school improvement grant ( sig ) program contributed to progress in one of the department's strategic objectives .

education's sig program is designed to fund significant reforms in low - performing schools in support of the department's objective to “accelerate achievement by supporting states and districts in turning around low - performing schools and closing achievement gaps , and developing models of next - generation high schools.” according to education's fiscal year 2014 annual performance report and fiscal year 2016 performance plan , turning around the lowest - performing schools takes several years to show progress and success .

education reported that since 2009 , more than 1,700 schools have received up to $2 million for 3 years through the sig program to implement intervention models intended to turn around the lowest - performing schools .

while nearly two - thirds of the schools have made progress , the remaining schools have either not shown progress or had decreased performance .

through their ongoing sig program monitoring , education officials told us they learned about two challenges grantees reported facing that could be hindering progress and developed new strategies intended to address them .

first , officials at state and local educational agencies expressed concerns to education officials about sustaining turnaround efforts , since they are long term in nature and sig program funds were only available for 3 years.approaches to better support sustainability .

using waiver authority , the department gave grantees flexibility to extend their use of existing funding into a fourth year .

in addition , beginning with its fiscal year 2014 appropriations , education obtained additional authority for state educational authorities to make school improvement grants for up to 5 education officials told us they took two different years .

education officials told us grantees also expressed concerns about a lack of principals with knowledge about or experience in turning around schools .

recognizing the importance of sustained leadership commitment , the department launched a new grant program in 2014 , the turnaround school leaders program .

this program provides funding for 3 years to local educational agencies to help ensure that leaders at schools eligible for or receiving sig program funds possess the specialized skills needed to drive successful efforts to turn those schools around .

although cbp , tsa , ice , and coast guard officials determined during their review that sufficient progress was being made on dhs's goal 2.2 to safeguard and expedite lawful trade and travel , they also identified gaps to address in performance monitoring .

officials told us that they realized that while they tracked a number of performance measures related to aspects of trade , they had none regarding the travel portion of the objective ( see table 3 below ) .

further , while most of the existing measures addressed enforcement and security , they noted that they had few measures that addressed the facilitation aspects of their mission — reducing barriers to the efficient flow of trade and travel .

according to one of the cbp officials who coordinated the review for this goal from the office of planning , program analysis , and evaluation ( ppae ) , cbp is responsible for most of the activities that would be covered by the gaps in performance information .

he told us that cbp has been working to address these weaknesses since they were identified last year .

for example , he shared that ppae has been working with the trusted traveler division within the office of field operations ( ofo ) to develop travel - specific performance measures .

these measures would address the land border and air travel modes , the principal avenues by which most international travelers enter the country .

one or more of the travel measures developed is to address the facilitation aspect of cbp's mission , as expressed in goal 2.2 .

in addition , he told us that ppae is working with the cargo and conveyance security directorate within ofo to develop a trade facilitation measure .

cbp expects to complete the formulation of these measures during calendar year 2015 , and plans to subsequently submit them to dhs as formal performance measures to begin reporting in the second quarter of fiscal year 2016 .

much like we found for data - driven reviews , thorough and sustained follow - up on issues identified during strategic reviews is critical to the success of the reviews as a performance improvement tool .

to ensure that actions identified as a result of the strategic review are carried out in the period between reviews , the agency should have a process to track these actions and communicate the progress made towards them .

such a process should identify , among other things for each action item , the responsible party , target completion dates , and significant milestones .

in addition , agency leadership should hold responsible officials accountable for taking the agreed upon actions and communicating what has been done routinely .

for example , agencies could use their existing quarterly performance review processes to monitor progress on strategic review action items , in line with the emphasis in omb's guidance for using existing agency management processes for strategic reviews .

omb's guidance further reinforces this practice by stating that agencies must incorporate actions to maintain or improve progress toward each objective , along with related implementation activities , into their next annual performance plan or other operating plans .

for the fiscal year 2016 annual performance plan , this is to include , at a minimum , the agency's summary of plans to improve or maintain performance , key milestones planned for the next year with completion dates , and efforts to close evidence gaps , as appropriate .

hud's performance reviews for its agency priority goals , known as hudstat meetings , occur frequently and regularly ( quarterly ) .

to conduct its strategic reviews , hud broadened the focus of its hudstat meetings in one quarter to review progress toward its strategic objectives .

for both sets of meetings , hud's performance staff have developed a process for identifying and tracking action items stemming from the reviews .

according to hud performance staff , action items can be identified in a number of ways , including by the secretary or pio during reviews of materials prior to the hudstat meeting , by meeting participants during the hudstat session , or in a postmeeting session among the secretary , pio , and objective leads .

hud's performance staff then compile and share a list of action items by objective or goal to all participants via e - mail within a day of the hudstat meeting to ensure agreement .

these are then added to a central tracking database for all action items .

for each action item , the tracking database identifies the responsible party , a target completion date , any interim dates ( milestones ) , and a status update .

for example , following the 2014 strategic review for hud's objective to “end homelessness for veterans , people experiencing chronic homelessness , families , youth , and children,” one action item identified during the review was to establish targets for homeless family admissions to public housing , tenant - based vouchers , and project - based vouchers .

it identifies the office of public and indian housing and the office of multifamily housing as the responsible parties .

according to hud officials , as of april 2015 , the office of public and indian housing is working to understand the capacity of local partners and will subsequently set targets .

the office of multifamily housing began collecting homeless admissions data in late 2014 and requiring it in february 2015 .

however , it is at least a year off from establishing and validating a baseline , and subsequently setting a target .

hud performance staff told us they will use the department's 2015 strategic reviews to reinforce accountability for setting these targets .

hud's performance staff told us they work with responsible parties to update the status of each action item and provide a report to the deputy secretary regularly .

according to hud performance staff , following the 2014 strategic review , these updates occurred either biweekly or monthly , and for the 2015 strategic review they will occur biweekly .

usda uses quarterly updates to the soar quad charts to keep the secretary and other senior leaders informed of ongoing progress towards the objectives , as well as any related challenges .

this includes providing updated information on the status of actions that were identified in prior quarters .

for example , the food safety and inspection service ( fsis ) , which is responsible for ensuring that the nation's commercial supply of meat , poultry , and egg products is safe , wholesome , and correctly labeled and packaged , is the lead agency for usda's strategic objective to “protect public health to ensure food is safe.” as part of the initial soar quad chart , from the second quarter of 2014 , one of the next steps fsis identified for this objective was to ensure continued progress in controlling salmonella by developing new performance standards targeting chicken parts and ground poultry , and improving the agency's verification sampling plans .

according to usda , salmonella is the leading known cause of bacterial foodborne illness and death in the country , causing an estimated 1.3 million illnesses , and between 400 and 500 deaths annually .

as part of its soar quad chart update for the fourth quarter of 2014 , fsis noted that it had developed a workplan for the federal register to announce and seek public comment on draft performance standards for salmonella in chicken parts and ground chicken as part of the progress update .

however , fsis also noted in the significant challenges section that the draft rule was deemed “significant” by omb,and fsis was also responding to internal comments prior to moving forward with publication .

we provided a draft of the report to the director of the office of management and budget , the secretary of the department of agriculture , the secretary of the department of education , the secretary of the department of homeland security , the secretary of the department of housing and urban development , the administrator of the national aeronautics and space administration , and the administrator of the environmental protection agency for comment .

omb staff and officials from the six agencies generally agreed with the findings presented in this report .

in addition , dhs , education , epa , hud , nasa , and omb provided technical comments , which we incorporated as appropriate .

we are sending copies of this report to interested congressional committees , the director of the office of management and budget , the secretary of the department of agriculture , the secretary of the department of education , the secretary of the department of homeland security , the secretary of the department of housing and urban development , the administrator of the national aeronautics and space administration , the administrator of the environmental protection agency , and other interested parties .

this report will also be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-6806 or mihmj@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of our report .

key contributors to this report are listed in appendix ii .

we are required to review implementation of the gpra modernization act of 2010 ( gprama ) at several critical junctures .

this report is part of our response to that mandate .

our specific objective for this report was to identify and illustrate , through case agency examples , practices that facilitate effective strategic reviews by federal agencies .

to identify practices , we analyzed and synthesized information gathered from a literature review we conducted , which covered public administration and public policy journals , business administration journals , our body of work on performance management and program evaluation , and other sources on policies and practices that can facilitate or challenge the effectiveness of strategic reviews as a decision - making tool .

we also conducted interviews with performance management and evaluation experts representing different levels of government ( local , state , federal ) , sectors ( e.g .

public , non - profit , foundations ) , and nations , who had experience with implementing elements of strategic reviews or academic and / or consultative expertise in this area.and interviews experts based on the results of our literature review ( i.e. , the authors of relevant articles or books included in our review ) .

based on suggestions from those individuals , we expanded our list of experts and conducted a second round of interviews .

using the information we obtained from our literature review and expert interviews , we developed a broad set of practices for conducting effective strategic reviews .

we refined the practices through our audit work at selected agencies ( see next paragraphs ) .

we also compared our practices with legal requirements in gprama , guidance from the office of management and budget ( omb ) , and a guide for conducting strategic reviews developed by the performance improvement council ( pic ) , and found them to be broadly consistent .

to help illustrate and refine our draft practices , we selected a non - generalizeable sample of agencies based on several criteria and analyses .

we limited the initial population for selection to the 24 agencies covered by the chief financial officers act of 1990 ( cfo act ) , as amended , because gprama directs us to periodically evaluate how implementation of the act is affecting performance management at those agencies .

we further refined the list to exclude two agencies , the departments of defense ( dod ) and veterans affairs ( va ) , from selection .

we excluded dod because the department had not published strategic objectives related to its 2014 strategic goals at the time of our selection process .

we excluded va because of ongoing corrective actions it was taking to address significant shortcomings in the accuracy and reliability of certain performance information .

because agencies conducted their initial strategic reviews in 2014 as we were selecting our sample , we could not use information about agencies' strategic review processes to inform selection .

as a proxy , we used relevant agency - level results on selected items from our 2013 survey of federal managers on performance and management issues to approximate if agencies had robust review processes and selected agencies with varying levels of robustness .

these survey items covered the extent to which agency leadership was committed and involved in performance management activities , as well as the use of performance information .

we also considered the extent to which agency strategic review processes had a greater chance of addressing areas of fragmentation , overlap , and duplication , and high - risk issues identified in our past work .

we have previously reported that effective implementation of strategic reviews could help identify opportunities to reduce , eliminate , or better manage instances of fragmentation , overlap , and duplication because , as part of the reviews , agencies are to identify the various organizations , programs , regulations , tax expenditures , policies , and other activities that contribute to each objective both within and outside the agency.addition , because agencies are to identify goals and strategies to resolve major management challenges they face , strategic reviews could also identify opportunities to better address issues on our high risk list .

we also took into consideration agency size , based on the number full - time equivalent employees , given the potential for variation in review practices due to organizational size and capacity .

based on the criteria and analyses outlined above , we selected the departments of agriculture , education , homeland security , and housing and urban development , and the environmental protection agency and national aeronautics and space administration .

these selections were also in line with suggestions we independently obtained from staff in omb's office of performance and personnel management who had reviewed each of the agencies' plans for conducting their strategic reviews as well as the results of those reviews .

to identify illustrative examples for each of our practices from the six selected agencies and to further refine our practices , we reviewed documentation about agencies' strategic review processes and results , including guidance , meeting agendas , relevant evidence used to inform the review , and internal and published summaries of the results .

we also conducted interviews with officials involved in conducting strategic reviews at the six selected agencies — which included agency performance improvement officers and their staff , strategic objective leaders , and strategic review participants — and staff from omb and the pic .

we conducted this performance audit from august 2013 to july 2015 in accordance with generally accepted government auditing standards.those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the above contact , elizabeth curda ( acting director ) and benjamin t. licht ( assistant director ) supervised this review and the development of the resulting report .

crystal bernard , virginia chanley , jehan chase , carole j. cimitile , emily gruenwald , and katherine wulff made significant contributions to this report .

robert robinson developed the graphics for this report .

sandra beattie , ellen grady , adam miles , jason vassilicos , and dan webb verified the information contained in this report .

