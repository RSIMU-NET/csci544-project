a growing body of research on both private - and public - sector organizations has found that increased levels of engagement — generally defined as the sense of purpose and commitment employees feel toward their employer and its mission — can lead to better organizational performance .

employee engagement is particularly important within federal agencies , where employees influence the well - being and safety of the public in myriad ways , such as by conducting advanced scientific research , verifying and administering benefits , or ensuring the safety of our workplaces , airports , and national borders .

however , government - wide levels of employee engagement have recently declined 4 percentage points , from an estimated 67 percent in 2011 , to an estimated 63 percent in 2014 , as measured by the office of personnel management's ( opm ) federal employee viewpoint survey ( fevs ) , and a score opm derived from the fevs beginning in 2010 — the employee engagement index ( eei ) .

in advance of the 2015 fevs cycle , which began this spring , the administration elevated the importance of strengthening employee engagement across government .

for example , strengthening employee engagement is one of three subgoals of the people and culture cross agency priority ( cap ) goal , established under the gpra modernization act of 2010 ( gprama ) .

moreover , agency leaders are to be held accountable for making employee engagement a priority , as well as an integral part of their agency's performance management system .

the administration also set a goal for these efforts: by the issuance of the 2016 fevs results , the federal government is expected to increase employee engagement — as measured by the eei — from 63 percent to 67 percent .

in addition , as part of their annual performance plans and appraisals , members of the senior executive service ( ses ) will be responsible for improving employee engagement within their organizations and for creating inclusive work environments .

given the decline in employee engagement government - wide , you asked us to examine the federal government's efforts to strengthen employee engagement .

this report ( 1 ) describes trends in employee engagement as measured by the fevs , ( 2 ) identifies key practices and lessons learned in developing and implementing strategies to improve employee engagement , and ( 3 ) evaluates opm's tools and resources to support agency efforts to improve engagement as it relates to organizational performance .

in april 2015 , we testified on our review's preliminary results .

to describe trends in employee engagement as measured by the eei , we analyzed responses to questions from the fevs ( from which the eei is derived ) for the years 2006 through 2014 .

we started with 2006 to include trends across two different presidential administrations .

because opm calculates the eei and its component scores at the group level , we used data from opm to recalculate the eei for each individual , which enabled us to conduct regression analysis and assess the statistical significance of changes in the eei .

the individual level calculation is scaled between 0 and 100 and is based on the proportion of each individual's positive responses to the 15 constituent eei questions .

for 2006 and 2008 , we calculated the eei using only 11 of the 15 eei questions because the 2006 and 2008 surveys did not include four eei questions that were added to the survey in 2010 .

we did not make comparisons from 2008 to 2010 because of the change in the index composition .

we analyzed this information government - wide , by agency , and for selected employee population groups .

for each analysis , we determined statistically significant changes in the eei .

to assess the reliability of the fevs data , we examined descriptive statistics and data distribution , and reviewed missing data .

we also reviewed fevs technical documentation as well as the statistical code opm uses to generate the index and variance estimates .

based on this analysis , we found the data sufficiently reliable for our purposes .

for additional details on our analysis of fevs data , see appendixes i and ii .

to identify key practices and lessons learned in developing and implementing strategies to improve employee engagement , we ( 1 ) reviewed relevant literature and interviewed knowledgeable researchers , government officials from the united kingdom , canada , and australia responsible for their comparable public - sector employee survey , and consultants on employee engagement ; ( 2 ) used linear multiple regression analysis to assess the relationship between specific fevs questions and the 2014 eei , after controlling for other factors ; and ( 3 ) reviewed documents and interviewed officials from three case study agencies .

we considered the agencies that had the highest average sustained eei scores , most improved overall eei scores ; and most improved leadership component scores in the eei from 2010 to 2014 .

we selected the national credit union administration ( ncua ) , the federal trade commission ( ftc ) , and the department of education ( education ) to ensure that we included agencies that had high scores in one or more of the three metrics we identified and that we included at least one chief financial officers act of 1990 ( cfo act ) agency .

to evaluate the support opm provides to agencies to improve employee engagement , we reviewed opm guidance , tools , and resources regarding use of fevs data and related engagement action planning ; we also interviewed opm and case study agency officials and members of the chief human capital officers ( chco ) council and national council on federal labor - management relations joint working group on employee engagement .

we conducted this performance audit from july 2014 to july 2015 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

engaged employees are more than simply satisfied with their jobs .

instead , according to employee engagement literature , engaged employees are passionate about and energized by what they do , are committed to the organization , the mission , and their job , and are more likely to put forth extra effort to get the job done .

take pride in their work , a number of studies of private - sector entities have found that increased levels of engagement result in better individual and organizational performance including increased employee performance , productivity , and profit margins ; higher customer service ratings ; fewer safety incidents ; and less absenteeism and turnover .

studies of the public sector , while more limited , have shown similar benefits .

for example , the merit systems protection board ( mspb ) found that higher levels of employee engagement in federal agencies led to improved agency performance , less absenteeism , and fewer equal employment opportunity complaints .

the fevs measures employees' perceptions of whether , and to what extent , conditions characterizing successful organizations are present in their agencies .

opm has conducted this survey every year since 2010 .

the eei is composed of 15 fevs questions covering the following areas: leaders lead , which surveys employees' perceptions of the integrity of leadership , as well as employees' perception of leadership behaviors such as communication and workforce motivation .

supervisors , which surveys employees' perceptions of the interpersonal relationship between worker and supervisor , including trust , respect , and support .

intrinsic work experience , which surveys employees' feelings of motivation and competency relating to their role in the workplace .

according to opm , the eei does not directly measure employee engagement .

instead , it covers the conditions that lead to employee engagement .

specifically , opm noted that organizational conditions lead to feelings of engagement , which in turn lead to engagement behaviors , such as discretionary effort , and then to optimum organizational performance .

sometimes the eei is discussed in the same context as another workforce metric , the partnership for public service's best places to work in the federal government rankings .

although these scores are also derived from the fevs , they were created as a way of rating employee satisfaction and commitment across federal agencies .

the rankings are calculated using a weighted formula of three different questions from opm's fevs: ( 1 ) i recommend my organization as a good place to work , ( 2 ) considering everything , how satisfied are you with your job , and ( 3 ) considering everything , how satisfied are you with your organization .

the recent government - wide average decline in the eei masks the fact that the majority of federal agencies sustained and a few increased eei levels during the same period .

from 2006 through 2014 , government - wide eei levels increased to an estimated high of 67 percent in 2011 and then declined to an estimated 63 percent in 2014 , as shown in figure 1 .

the decline in the eei that began after 2011 is the result of several large agencies bringing down the government - wide average .

for example , we found that 13 out of 47 agencies saw a statistically significant decline in their eei score from 2013 to 2014 .

while this is 28 percent of agencies , they employ nearly 69 percent of federal employees and include the department of defense , department of homeland security , and department of veterans affairs .

meanwhile , the majority of agencies sustained their eei levels and a few improved them , as shown in figure 2 .

between 2013 and 2014 , of 47 agencies included in our analysis of the eei , 3 increased their scores , 31 held steady , and 13 declined .

the recent government - wide downward trend in employee engagement levels coincided with external events — such as sequestration , furloughs , and a 3-year freeze on statutory annual pay adjustments from 2011 to 2013 — that opm and others contend negatively affected federal employee morale .

for example , in march 2014 , we reported that officials from agencies — including those that furloughed employees — raised concerns about how sequestration affected the morale of current employees .

even one agency with a downward trending engagement score is not to be taken lightly and there is opportunity for improvement at all federal agencies .

however , the large number of agencies that sustained or increased their levels of employee engagement during this time suggests that agencies can positively influence employee engagement levels even as they weather difficult external circumstances .

for example , the ftc maintained a consistent estimated 76 percent eei score — well above the government - wide average — throughout the period of general decline .

of the three components that comprise the eei , employees' perceptions of leaders consistently received the lowest score , and at times was about 20 percentage points lower than the other components .

moreover , from a high point in 2011 , leadership scores saw the greatest decrease and accounted for much of the government - wide average decline in the eei , as figure 3 shows .

the questions comprising the eei leadership component focus on integrity of leadership and on leadership behaviors such as communication and workforce motivation ( see table 1 ) .

three of the five questions are specific to senior leaders — department or agency heads and their immediate leadership team responsible for directing policies and priorities and typically members of the senior executive service or equivalent ( career or political ) .

two are specific to managers — those in management positions who typically supervise one or more supervisors .

in our 2003 work on transformations , we found that leaders are the key to organizational change — they must set the direction , pace , and tone , and provide a clear , consistent rationale that brings everyone together behind a single mission .

the relative strength of the supervisors component of the eei suggests that the employee - supervisor relationship is an important aspect of employee engagement .

these questions focus on the interpersonal relationship between worker and supervisor and concern supervisors' support for employee development , employees' respect , trust , and confidence in their supervisor , and employee perceptions of an immediate supervisor's performance .

this is consistent with mspb research , which suggests that first - line supervisors are key to employee engagement and organizational performance .

intrinsic work experience was the strongest eei component prior to 2011 , but fell during the period of government - wide decline in engagement levels .

these questions reflect employees' feelings of motivation and competency related to their role in the workplace , such as their sense of accomplishment and their perception of utilization of their skills .

understanding how employee engagement varies within differing populations of employees can enable agency leaders to consider how different cohorts experience their environment and thus can help leadership determine how to focus engagement efforts .

for example , knowing that employees with fewer supervisory responsibilities could be less engaged — and could be having a negative effect on organizational performance — could spur agency leaders to direct additional resources to understanding the needs of this subset of the workforce and improving their sense of engagement .

we found that government - wide , the greatest variation in eei levels was related to pay category and supervisory status .

for example , respondents in progressively lower general schedule ( gs ) pay categories had progressively lower levels of engagement government - wide .

in contrast , employees in the ses pay category reported consistently higher engagement levels — at least 10 percent more than any lower pay category .

while there was less difference between the eei levels of other pay categories , employees in the gs 13 through 15 categories consistently had higher eei levels than employees in all other lower gs pay categories .

employees in the prevailing rate system , commonly known as the wage grade system , consistently had the lowest eei levels .

for example , in 2014 , eei levels for respondents in the ses pay category were an estimated 84.2 percent compared to an estimated 54.7 percent for respondents in the wage grade pay category .

similarly , respondents with fewer supervisory responsibilities had progressively lower eei levels government - wide .

because employees in higher pay categories are likely to have more supervisory responsibilities , responses by pay category and supervisory status represent similar populations .

variations in eei levels by supervisory status are shown in figure 4 .

with respect to other populations of employees , agency tenure , federal tenure , age , and race consistently resulted in some variation but less than pay category and supervisory status .

for example , in 2014 , american indian or alaska native respondents reported the lowest engagement for any race category with an estimated eei of 57.6 .

asian respondents reported the highest levels of engagement with an estimated eei score of 68.4 .

gender , ethnicity ( hispanic / non - hispanic ) , and work location ( headquarters / field ) consistently had the least variation .

for example , in 2014 , males had an estimated eei of 63.2 percent and females an estimated eei of 63.3 percent .

for results of our analysis of employee population groups , see appendix ii .

overall we found that what matters most in improving engagement levels is valuing employees — that is , an authentic focus on their performance , career development , and inclusion and involvement in decisions affecting their work .

the key is identifying what practices to implement and how to implement them , which can and should come from multiple sources — fevs and other data sources , other agencies , and opm .

the lessons learned from our three case study agencies were that the goal should not be to just increase a number — that is , have a high eei — but should also include a focus on improving the organization .

of the various topics covered by the fevs that we analyzed , we identified six that had the strongest association with higher eei levels compared to others , as described in figure 5 .

we used regression analysis to test which selected fevs questions best predicted levels of employee engagement as measured by the gao - calculated eei , after controlling for other factors such as employee characteristics and agency .

constructive performance conversations .

we found that having constructive performance conversations was the strongest driver of the eei .

for the question “my supervisor provides me with constructive suggestions to improve my job performance,” we found that , controlling for other factors , someone who answered “strongly agree” on that fevs question would have , on average , an engagement score that was more than 20 percentage points higher than someone who answered “strongly disagree” on the 5-point response scale .

as we found in our march 2003 report on performance management , candid and constructive feedback helps individuals maximize their contribution and potential for understanding and realizing the goals and objectives of an organization .

at education , one of our case study agencies , the office of the chief information officer ( ocio ) implemented a process to help ensure that constructive performance conversations regularly occur .

in addition to department - wide requirements for supervisors to hold two performance conversations a year , ocio officials said that they require all supervisors to offer ocio employees optional quarterly conversations .

these quarterly performance conversations are guided by a set of specific topics that supervisors and employees developed together to ensure that employees receive consistent and regular constructive feedback and coaching .

career development and training .

our analysis found that career development and training was the second strongest driver .

for the question , “i am given a real opportunity to improve my skills in my organization,” we found that , controlling for other factors , someone who answered “strongly agree” to that question would have , on average , an engagement score that was 16 percentage points higher than someone who answered “strongly disagree.” as we found in 2004 , the essential aim of training and development programs is to assist an agency in achieving its mission and goals by improving individual and , ultimately , organizational performance .

at ncua , another of our case study agencies , officials said the agency focused on providing training for employees throughout their careers .

for example , ncua requires each employee to develop an individual development plan .

for employees new to credit union examining — a majority of employees — ncua has a standardized 18-month training program that combines classroom and practical work .

new examiners must complete a core set of courses and may also choose additional elective courses .

ncua officials said that they are constantly assessing formal and informal training for entry - level employees to identify areas to improve the curriculum and instruction .

for more experienced examiners , ncua provides continuing training and development , according to these officials .

remaining drivers .

for the remaining four drivers , we found that , controlling for other factors , someone who answered “strongly agree” or “very satisfied” to those questions would have , on average , an engagement score that was 12 percentage points higher than someone who answered “strongly disagree” or “very dissatisfied.” those four drivers are work - life balance ( “my supervisor supports my need to balance work and other life issues” ) , inclusive work environment ( “supervisors work well with employees of different backgrounds” ) , employee involvement ( “how satisfied are you with your involvement in decisions that affect your work” ) , and communication from management ( “how satisfied are you with the information you receive from management on what's going on in your organization” ) .

examples of how our three case study agencies implemented practices consistent with these drivers include the following: work - life balance .

ftc officials implemented an outreach strategy to inform staff about child and elder care resources after learning that employees were not aware of the services or did not know that they qualified for these services .

officials said employee knowledge of and agency commitment to these kinds of programs enhances supervisor support for work - life balance .

similarly , to support work - life balance , as part of its engaged initiative , education revised telework policies , provided training for managers and employees on the new polices and on working in a telework environment , and improved infrastructure to make telework as effective as time spent in the office , according to education officials .

inclusive work environment .

the ftc established an agency - wide diversity council to develop comprehensive strategies to promote understanding and opportunity throughout ftc .

ftc officials said that employees of all levels were interested in forming such a council .

this included employees who experienced firsthand the diversity issues as well as managers who could address those issues .

the goal of ftc's diversity council — composed of representatives from each bureau and office — is to engage employees and supervisors across the agency , make recommendations for improving diversity , and foster the professional development of all agency employees , according to these officials .

employee involvement .

education's office of general counsel ( ogc ) has a permanent employee - driven workforce improvement team ( wit ) that grew out of an office - wide meeting with employees at all levels to involve employees in the discussions about the fevs results .

as a result of this group's work , education's ogc management introduced additional training and professional development opportunities and improved employee on - boarding through a new handbook and mentoring program .

education's ogc officials said that the staff - driven wit has created feelings of stronger ownership , engagement , and influence in office decision making .

education's ogc officials said that ogc's management seeks feedback from staff , including from the wit , to evaluate the effectiveness of improvement efforts .

these officials said this strengthens two - way communication , which improves employee engagement and organizational performance .

communication from management .

ncua officials told us that the head of the agency and its senior leaders communicate with line employees ( who are mostly in the field ) through quarterly webinar meetings .

the meetings are scheduled to accommodate the field employees' frequent travel schedule and generally start with any “hot topics” and continue with discussion of agency efforts to meet mission goals .

the agency head takes questions in advance and during the webinar and , when needed , participants research and share responses with agency employees .

according to ncua officials , these regular , substantive conversations demonstrate top leadership's commitment and respect for all employees as valued business partners .

these key drivers can help agencies develop a culture of engagement as agencies embed them into the fabric of everyday management practices , rather than simply reacting to the results of the most recent fevs .

importantly , these six practices were generally the consistent drivers of higher eei levels when we analyzed them government - wide , by cfo act agency , and by selected employee populations ( such as agency tenure and supervisory status ) .

because these six practices are the strongest predictors of the eei , this suggests they could be the starting points for all agencies embarking on efforts to improve engagement .

our case study agencies also identified three key lessons for improving employee engagement .

any change must be implemented using effective management practices .

the eei alone is not enough ; agencies must look to other sources of data for a complete picture of employee engagement levels in their organization and its components .

improving engagement and organizational performance takes time and does not neatly follow the survey cycle ; change may involve several efforts and effects are seen at different points in time .

our three case study agencies attributed their high or increasing levels of engagement to overall effective management practices more so than to efforts specifically aimed at improving engagement levels .

officials at these agencies said they pay attention to employee engagement scores , but also focus on overall positive organizational health and culture and on how their agency implements change efforts .

some of the practices agencies cited parallel those we identified in 2003 as key to successful organizational transformation , including top leadership involvement , consistency , creating a line of sight linking individual results to organizational performance , and employee outreach .

top leadership involvement .

officials from all three of our case study agencies said that top agency leaders were directly involved in organizational improvement efforts .

we have previously reported top leadership that is clearly and personally leading the change presents stability and provides an identifiable source for employees to rally around and helps the process / efforts stay the course .

for example , education officials said education's chief information officer is directly involved in efforts to address fevs scores — he is directly involved in the data analysis , reviewing education's ocio action plans developed by each of his subordinate directors , overseeing implementation of strategies , and assessing their effectiveness .

consistency .

officials at education's ocio said it is important to ensure that policies are applied consistently , which is the goal of that office's speaking with one voice initiative .

the biweekly management meetings to discuss and clarify the implementation of department policies ( eg , telework , resources , and employee bonuses ) were instituted after conversations with employees revealed that policies were inconsistently applied .

as a result of the initiative , education's ocio officials said employees know that senior leaders are paying attention to how policies affect employees and are accountable for ensuring appropriate implementation .

line of sight .

ftc officials emphasized the importance of creating a line of sight between the agency's mission and the work of each employee .

as we have previously reported , successful organizations create a “line of sight” showing how team , unit , and individual performance can contribute to overall organizational results .

ftc officials said that the agency lists every employee that contributed to a case in the pleadings , from the attorneys and paralegals to the information technology specialists who provided computer support .

officials said that legal actions are the culmination of the efforts of many employees , both mission and mission - support staff , and including their names on pleadings helps create a line of sight from each employee's contribution to the organization's success .

further , ftc officials said they recognize how mission support functions , such as excellent human resources customer service contribute to the agency mission .

for example , ftc officials said that they emphasize to the human resources staff that their prompt handling of payroll and benefits issues contributes to the overall efficiency and mission accomplishment by minimizing the time other ftc employees expend on these concerns .

as a result , mission employees can focus on accomplishing their mission - related responsibilities .

employee outreach .

according to officials at all three of our case study agencies , they all reach out to employees and their labor union representatives , if applicable , to obtain insight into their fevs scores or to inform other improvement efforts .

our 2003 report found that employee involvement strengthens the improvement process by including frontline perspectives and experiences .

by participating in improvement task teams , employees have additional opportunities to share their experiences and shape policies and procedures as they are being developed and implemented .

for example , in 2012 , while ncua's eei score was above the government - wide level , fevs questions about awards , performance appraisals , and merit - based promotions were its lowest scoring categories .

ncua officials said they contracted with an external facilitator to conduct workshops and webinar - based feedback sessions with employees to gain insight into their fevs results and identify root causes influencing the survey scores .

these officials said that using external facilitators offered employees confidentiality and created an environment that encouraged open conversations .

based on these feedback sessions , ncua created an internal employee - driven committee to inform revisions to the awards , performance appraisals , and merit - based promotion process , and developed recommendations for ncua's management to implement these changes .

most of the committee's recommendations were implemented .

according to officials at our case study agencies , while the eei provides a useful barometer for engagement , other indicators can provide officials with a deeper insight into reasons for engagement levels and areas for improvement .

other data such as turnover rates and equal employment opportunity ( eeo ) complaints — which are likely already collected by federal agencies — can provide additional insight and strategies for improving employee engagement .

notably , mspb found that there is a statistically significant correlation between higher levels of employee engagement and fewer eeo complaints .

officials in the three case study agencies said that they pay attention to their fevs scores , but other sources of data can provide explanatory or agency - specific information valuable to developing improvement strategies .

as one example , ncua officials said they identified a slight increase in turnover in recent years from the human capital data and are reviewing their exit survey process in calendar year 2015 to determine the best way to gather this information as well as to identify trends in reasons for employees leaving .

ncua officials said providing applicants with a clear understanding of the work will help to ensure a good position fit initially , which leads employees to stay engaged with the organization .

credit union examiners often travel between credit unions and do not regularly report to an office .

therefore , ncua is revising its vacancy announcements to better communicate the nontraditional work environment of field staff , which officials said comprises nearly 80 percent of the agency's workforce .

for example , ncua officials said that applicants are asked to also indicate preferences on working independently .

case study agency officials told us that they take a multi - year , multi - prong approach to improving engagement and do not base engagement efforts solely on the survey cycle or focus their attention on year to year changes in the eei .

some case study agency officials said a single survey cycle does not provide enough time to implement changes and see results because real change usually takes more than 1 year .

the fevs cycle begins around may and agencies receive results in september or october .

it may be late - winter or early - spring before an agency will have designed an action plan .

by the time the next survey cycle begins , agencies may still be interpreting results and developing and implementing their action plans .

moreover , according to case study agency and other officials we interviewed , the annual survey cycle does not allow enough time for employees' perceptions to change before the next cycle begins .

for example , an education official said that it took a few years to see the effects of engagement - related actions .

members of the chief human capital officers council and national council on federal labor - management relations joint working group on employee engagement said that the effects of initiatives implemented to improve engagement will not be reflected in the eei scores for at least a couple of years , which makes evaluating their effectiveness challenging .

opm officials agreed that efforts to improve engagement should not be based on the survey cycle , but noted the benefits of an annual survey .

specifically , opm stated that agencies are increasingly using the fevs as a management tool to help them understand issues at all levels of an organization and to take specific action to improve employee engagement and performance .

an annual survey such as fevs can help ensure that newly appointed agency officials ( or a new administration ) can maintain momentum for change , as the surveys suggest employees are expecting their voices to be heard .

further , opm officials noted if agencies , managers , and supervisors know that their employees will have the opportunity to provide feedback each year , they are more likely to take responsibility for influencing positive change .

instead of focusing exclusively on fevs and eei scores , case study agencies took a longer term approach to their engagement efforts .

for example , according to officials , education established engaged , a long - term cultural change initiative , to build a more innovative , collaborative and results - oriented agency and create a more engaged workforce .

this initiative focused on three areas — increasing multi - way communications , performance accountability , and professional growth opportunities — which officials said were consistently identified as challenges through the fevs analysis and facilitated feedback discussions .

instead of focusing on one specific fevs question , education identified these broad themes to bring about a systemic change , according to officials .

engaged addressed these challenges through several actions intended to prompt thoughtful discussion among employees , accountability for results , and developmental opportunities .

among others , these actions included the following: quarterly all - staff meetings with the secretary to discuss various topics .

a “lunches with leaders” program allowed agency employees more access , input , and participation in key topics discussed by senior agency leaders .

a redesigned performance appraisal system to simplify and standardize performance rating levels to more clearly reflect performance expectations , and consistently recognize and reward successful performers within principal offices and across the agency .

periodic leadership summits to provide agency leaders with developmental activities identified by staff that are focused on teams , individual leadership , and problem resolution .

an education policy briefing series to provide agency employees with an opportunity to learn about cutting - edge education issues that relate to the goals and work of the agency and to provide a forum for staff to interact and share expertise .

according to education officials , this longer - term , broad - based approach helped education improve its scores even while government - wide scores were decreasing .

officials said they monitor each year's results , but their success demonstrates the value of taking a long - term perspective .

opm provides a number of tools and resources to support agencies' efforts to use eei data to identify areas that need improvement , as shown in table 2 .

however , these tools do not provide agencies with the drivers of the eei or enable agencies to determine if changes in eei levels are meaningful .

one of opm's key strategic goals is to help agencies create inclusive work environments where a diverse federal workforce is fully engaged and energized to put forth its best effort , achieve their agency's mission , and remain committed to public service .

opm's strategic plan for fiscal years 2014-2018 states that it will ensure agencies target , address , and measure key drivers of employee engagement .

however , opm does not analyze the drivers of the eei or provide agencies the tools to do so .

a driver analysis based on fevs questions can help agencies more effectively target limited resources and can provide a roadmap to design strategies to improve eei levels .

opm officials told us that they do not conduct a driver analysis to determine which fevs questions are associated with higher eei scores and report them via opm's online tools because they would have to use a more complicated and less transparent method of calculating the eei .

specifically , to conduct a driver analysis opm would have to calculate the eei for each individual respondent by determining the proportion of positive responses to the 15 eei questions for each respondent .

opm would also have to account for unanswered questions .

opm currently calculates the eei by averaging all the positive responses to the eei questions for the group of respondents .

while opm officials acknowledged the importance and value of the individual level calculation for determining drivers , they said that the benefit of the current method of calculating the eei is that it is simpler and officials can see how the scores are calculated — as an average .

however , opm officials noted that they could separately conduct a driver analysis outside of the online tools .

in 2006 , opm conducted a regression analysis to identify which questions best predicted overall job satisfaction , overall satisfaction with the organization , and intent to stay or leave .

this suggests that opm has the capability to conduct such an analysis .

research on employee engagement emphasizes the importance of identifying the drivers of an engagement or related metric as an initial step in improving employee engagement .

for example , the partnership for public service's best places to work in the federal government guidance lists a driver analysis as a key element in determining where agencies should focus their action planning efforts .

if managers understand the drivers of engagement , then they can better target their engagement efforts , particularly in times of limited resources .

the results of our driver analysis demonstrate consistency of results government - wide and by cfo act agency as well as selected employee populations .

similar or even more limited investment of opm resources could yield information that would benefit all agencies .

however , by not determining which fevs questions are associated with higher eei levels , opm is missing an opportunity to assist agencies in targeting their engagement resources .

as noted earlier , the administration has said agency leaders will be held accountable for making employee engagement a priority and making it an integral part of their agency's performance management system .

for example , the december 2014 memorandum on engagement and performance calls on agencies to incorporate engagement measures into ses and agency performance plans .

according to the memorandum , ses performance plans are to include a measurable component related to improving employee engagement by 2016 .

gprama annual performance plans are to include baselines and organizational targets for strengthening employee engagement with a focus on a percent change .

as agencies begin to use engagement measures to inform other performance measurement decisions , understanding whether eei changes are statistically significant will become especially important .

however , opm does not report whether changes in agency eei scores are statistically significant — that is , whether the change is meaningful and not due to random chance .

as a result , agency officials do not have the information they need to appropriately interpret changes in the eei .

opm does provide agencies with absolute changes in the eei — increases and decreases that may or may not be statistically significant due to sampling variability .

the method we used to determine statistical significance showed that only 34 percent ( 16 of 47 ) of the absolute changes in agency eei scores from 2013 to 2014 were actually statistically significant .

without understanding whether changes are statistically significant , managers may take action based on data that has limited meaning .

for example , a manager might assume an annual increase in the eei meant specific engagement efforts were successful when they were not or assume an annual decline in the eei meant specific engagement efforts were not successful and abandon an effort too soon .

statistical significance is a function of two things: ( 1 ) the size of the change — the increase or decrease in the eei , and ( 2 ) the size of the population sampled .

in general , the smaller the sample , the larger the change needs to be before it is statistically significant , and the larger the sample , the smaller a change needs to be to be significant .

in fevs , sample sizes tend to be substantially smaller at smaller agencies .

for example , from 2013 to 2014 the federal mediation and conciliation service , with a workforce of over 200 employees , had a 2 percentage point change in the eei , which was not statistically significant , based on the method we used to determine statistical significance .

during that same period , the department of defense — the largest federal agency with over 700,000 employees — had about a 0.7 percentage point decrease in the eei ; this was a statistically significant change .

without knowing whether changes in the eei are statistically significant , agency officials do not have the context to determine whether a change is meaningful .

as agencies move from analyzing data to developing strategies to improving engagement and linking it to organizational performance , the specific strategies and lessons learned from the experiences of other agencies can be beneficial to those who may be seeking information related to improving employee engagement and performance .

table 3 describes opm efforts to help agencies develop and implement strategies to improve employee engagement and link engagement to performance .

opm has several efforts under way to support agencies' efforts to develop and implement strategies to improve engagement and link it to performance .

most of these efforts focus on the identification and sharing of promising practices , where opm works in partnership with federal agencies .

during the course of our audit , opm officials described the following avenues for identifying these practices — the engagement outreach team , in - person events , the chco council – national council on federal labor - management relations employee engagement working group , and through the designation of agency - appointed senior accountable officials .

opm officials said their goal is to use the community of practice page on unlocktalent.gov as the platform for sharing the identified promising practices .

however , as of may 2015 , opm has only posted limited content on the community of practice page — video clips from three events .

engagement outreach team .

opm's engagement outreach team is a seven - person intra - agency team formed in august 2014 , representing four opm offices .

each outreach team member provides individualized support to three to four president's management council agencies and identifies potential promising practices .

opm officials said the outreach team speaks with each of their assigned agencies , and based on these conversations , the outreach team meets weekly to share successes and challenges , address action items on their respective agencies' efforts , and identify potential promising practices .

however , as of may 2015 , none of the promising practices identified by the outreach team had been added to the community of practice page on unlocktalent.gov and opm officials said they did not have a plan for how they will use the information gathered from president's management council agencies to inform the community of practice page .

in april 2015 , opm officials said the outreach team was evaluating all of the qualitative data received from agencies , including feedback on previous events and resources offered by the team to determine the next best steps forward , including developing content for the community of practice page of unlocktalent.gov .

however , officials did not provide a time frame for completing the evaluation or developing the content .

in - person events .

during the fall of 2014 , opm hosted three in - person , washington , d.c. - based events for agency officials aimed at identifying promising practices in improving employee engagement .

specifically , in november 2014 , opm partnered with omb and the presidential personnel office to hold the federal employee engagement forum event at the white house .

panels of public - and private - sector representatives discussed ( 1 ) approaches to improving employee engagement and performance through use of data , ( 2 ) best practices in collaborative engagement strategies , and ( 3 ) the best use of tools and strategies to improve employee engagement and performance .

opm officials said approximately 150 people attended including senior agency officials or their staff and representatives from national labor unions and private - sector organizations .

opm also held two sessions for agency officials in opm's innovation lab to identify strategies for improving employee engagement .

opm officials said about 20 people attended each session from 11 different agencies .

participants included chcos and other senior leaders as well as other agency officials involved with employee engagement efforts .

on may 18 , 2015 , following a briefing on the preliminary findings of our audit , opm posted video clips on the community of practice page of unlocktalent.gov from the federal employee engagement forum held at the white house and another in - person event , the ses leadership event .

regarding the innovation lab events , according to opm officials , summaries of the sessions were shared with participants and by request with other officials .

opm officials said they have no further plans for when and how to share the innovation lab summaries with a broader government - wide audience .

chco council – national council on federal labor - management relations employee engagement working group .

coordinated by the chco council executive director , the working group was launched in february 2014 with representatives from 15 agencies and 8 nongovernment organizations including federal employee unions and organizations representing managers and executives .

the group meets on approximately a quarterly basis and is organized into three subcommittees — ( 1 ) promising practices , ( 2 ) key enablers and barriers , and ( 3 ) measures and incentives .

two representatives , one each from an agency and a labor union , co - chair the full working group and each of the subcommittees .

the group's 2014 work culminated in presentations to the chco council and the national council on federal labor - management relations .

according to the chco council executive director , a key goal of the working group is to identify practices that will be shared on the community of practice page of unlocktalent.gov .

however , despite the preliminary work as reflected in the november 2014 presentations , no practices had been posted on the community of practice page , as of may 2015 .

further , according to the chco council executive director , agencies have been reluctant to hold their engagement practices up as a model .

agency - appointed senior accountable officials .

according to opm officials , from march through may 2015 , opm met once with each agency's senior accountable official to discuss their agency's engagement baseline , plans for engagement activities , assistance needed , and best practices .

in addition , opm officials said in may 2015 they hosted a workshop for the senior accountable officials to share leading practices and strategies to address common challenges .

opm officials said materials from this event were provided to participants , and included examples from participating agencies .

opm officials said after this workshop , they designed five workgroups for senior accountable officials or their designee to work with officials from the people and culture cap goal to address specific engagement challenges .

opm officials said the workgroup's outcomes and next steps will be shared in the fall of 2015 , when the 2015 survey results are available to agencies .

linking increased employee engagement to improved organizational performance is important because it recognizes that improved engagement is not an end in itself .

instead , the ultimate aim is to enhance the ability of agencies to cost - effectively carry out their missions .

the administration's december 2014 memorandum calls for agencies to establish the linkage between employee engagement and mission performance .

specifically , agencies are to collect return on investment information — that is , whether a change in engagement levels resulted in improvements to performance metrics related to agency mission , such as a reduction in error rates .

opm , as the lead agency on the cap employee engagement subgoal , has provided limited examples or guidance for how agencies could establish a linkage between engagement and performance .

according to omb officials , establishing such a link is the key step in agency efforts to improve employee engagement and performance .

opm officials said they began a study on how to link engagement to outcomes at three agencies whose outputs can be quantitatively measured .

these agencies are the u.s. mint's bureau of engraving and printing , the patent and trademark office , and opm's retirement services division .

specifically , opm planned to analyze the relationship between eei scores and production or performance measures at a team level .

however , this effort has been delayed with no estimated completion date , and officials said that linking the eei to team level performance or production outputs has been more difficult than anticipated .

following a briefing on the preliminary findings of our audit , opm posted a video clip from the federal employee engagement forum panel on linking metrics to business outcomes .

while this is an important step , the video segment featured only one example from a federal agency .

because experience with linking employee engagement in the public sector to organizational performance is limited ( as indicated by our interviews with opm and omb officials and the literature that we reviewed ) , agencies do not have a clear model on how to make this link and demonstrate that it resulted in improved mission accomplishment .

even at our three case study agencies — each of which have high or improving eei scores — officials said that they lacked sufficient in - house expertise to develop and conduct such an analysis .

pursuant to the people and culture employee engagement cap subgoal , the administration has established a target of improving employee engagement government - wide to 67 percent by the issuance of 2016 fevs results , a 4 percentage point increase from the 2014 government - wide score .

without the ability to link increased engagement to improved performance , the extent to which an increase of 4 percentage points will translate into improved performance is unclear .

further , given the time horizon necessary to see real improvements , it is unclear if efforts to improve engagement can be achieved by 2016 .

higher levels of employee engagement can translate into higher levels of organizational performance .

however , for agencies to attain the ultimate goal of improving organizational performance , agencies must take a holistic approach — analyzing data , developing and implementing strategies to improve engagement , and linking their efforts to improved performance .

the tools and resources opm has developed represent an important first step toward helping agencies improve employee engagement .

however , opm cannot ensure officials are correctly understanding and using eei data , because it does not report on whether eei changes are statistically significant — that is , whether the changes are due to something other than chance .

opm also does not determine the fevs questions that lead to increased eei levels , which would enable agencies to focus on areas that drive engagement .

at the same time , informed decisions require more than just eei data .

when faced with multiple options , agencies need to target their resources to the practices found to drive employee engagement — notably constructive performance conversations .

moreover , as indicated by our case study agencies , how changes are implemented — including the involvement of top leadership , consistency , employee outreach , and creating a line - of - sight between individual and organizational performance — ultimately affects whether those changes merely produce temporary compliance or result in sustainable cultural transformation .

further , other data can be used to provide more specific information on what needs attention .

however , efforts take time and should not be seen solely as an annual effort measured by the results of the next survey , but as a continuous process .

although opm has developed a process for identifying and collecting promising practices , opm's sharing of promising practices has been limited , and whether and when its efforts will come to fruition is unclear .

promising practices around analyzing eei data and implementing improvement strategies are important ; however , given the public sector's limited experience linking engagement to performance , promising practices on creating this linkage are critical .

in furtherance of its role to support agencies' efforts to improve employee engagement and performance , we recommend that the director of opm take the following three actions: 1 .

to enable agencies to better target resources for engagement efforts , opm should annually analyze and report on drivers of the eei government - wide and by selected subsets of the federal workforce , such as agencies or employee population groups .

2 .

to enable agencies to identify meaningful changes in eei levels , opm should provide agencies with information on whether annual changes to eei scores , both government - wide and by selected subsets of the federal workforce , are statistically significant .

3 .

to ensure agencies are leveraging promising practices and lessons learned from other agencies in developing effective strategies to improve engagement and performance , opm should , in partnership with federal agencies , expand its efforts to share promising practices to include information on linking engagement to mission accomplishment and monitoring how engagement investments improve performance through data - driven reviews , like hrstat ; and implement its strategy to share these practices in time to inform agency efforts stemming from their 2015 fevs results .

we provided a draft of this product to the director of opm for comment .

in written comments , which are reproduced in appendix v , opm concurred with our first recommendation and partially concurred with our second and third recommendations .

opm stated that it concurred with our recommendation to analyze and report on the drivers of employee engagement government - wide and by subsets of the federal workforce .

opm said that starting with the release of the 2015 fevs , it is committed to conducting , analyzing , and reporting on key drivers of the eei at the government - wide level and has formed a working group to make recommendations on the scope of the analysis and the reporting in subsets of the federal workforce .

opm stated that it partially concurred with our recommendation to provide information on whether changes are statistically significant , and noted that among other actions , the working group referenced above is to provide guidance on how best to disseminate this information to agencies .

at the same time , opm maintained that in addition to the eei , agencies should also rely on multiple indicators to assess organizational performance .

this was a key point that we made in our report .

specifically , we said that in addition to the eei , other indicators — such as turnover data — can provide officials with additional insights into reasons for engagement levels and areas for organizational improvement .

however , in order for agencies to meaningfully use eei data in their analyses , we continue to recommend that opm provide agencies with information on whether changes in the eei are statistically significant .

with respect to our third recommendation , opm noted that while it agreed with our recommendation to share promising practices in time to inform agency efforts based on the fevs 2015 survey results , opm disagreed with our assessment of opm's efforts .

in its written comments , opm outlined the steps taken to identify and share promising practices after being briefed on the findings of our audit .

for example , opm noted that in may 2015 , it held a workshop with the senior accountable officials responsible for agency engagement efforts in an effort to share promising practices and generate solutions to common challenges ; opm also noted it has formed workgroups among the senior accountable officials around specific topic areas , with a goal of sharing those practices with the larger federal community this fall .

we have modified our report to include more information on opm's efforts and plans to share promising practices with agencies in time to inform the analysis of the fevs 2015 survey results .

however , until such information is shared with the larger federal community and includes models for linking engagement to mission accomplishment , we continue to believe that opm should take additional actions to assist agencies in leveraging their lessons learned , as we recommended .

we also provided a draft of this product to the secretary of education , chairwoman of the ftc , and the chairman of ncua for technical review and comment .

we received technical comments from them that we incorporated , as appropriate .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the appropriate congressional committees , the director of the office of personnel management , and other interested parties .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report please contact me at ( 202 ) 512-2757 or goldenkoffr@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this product are listed in appendix vi .

to determine the trends in employee engagement as measured by the office of personnel management ( opm ) federal employee viewpoint survey ( fevs ) and identify key practices to improve employee engagement we analyzed ( 1 ) employee engagement index scores ( eei ) from 2006 to 2014 and ( 2 ) the extent to which selected 2014 fevs questions predicted eei scores .

this appendix describes our methodology for preparing the dataset and for calculating the eei to conduct these analyses .

for the methodology and results of our analysis of eei trends , see appendix ii ; for our methodology for identifying the drivers of the 2014 eei , see appendix iii ; and for the results of our driver analysis , see appendix iv .

the fevs provides a snapshot of employees' perceptions about how effectively agencies manage their workforce .

topic areas are employees' ( 1 ) work experience , ( 2 ) work unit , ( 3 ) agency , ( 4 ) supervisor , ( 5 ) leadership , ( 6 ) satisfaction , ( 7 ) work - life , and ( 8 ) demographics .

opm has administered the fevs annually since 2010 ; from 2002 to 2010 , opm administered the survey biennially .

the fevs includes a core set of questions , and agencies have the option of adding questions to the surveys sent to their employees .

the fevs is based on a sample of full - and part - time , permanent , non - seasonal employees of departments and large , small , and independent agencies , which in 2014 represented about 97 percent of the federal executive branch workforce .

according to opm , the sample is designed to ensure representative survey results would be reported by agency , subagency , and senior leader status as well as for the overall federal workforce .

once the necessary sample size is determined for an agency , if more than 75 percent of the workforce would be sampled , opm conducts a full census of all permanent , non - seasonal employees .

for 2014 , the total sample size was 872,495 .

according to opm , this size was more than sufficient to ensure a 95 percent chance that the true population value would be between plus or minus 1 percent of any estimated percentage for the total federal workforce .

government - wide , in 2014 , 392,752 employees completed surveys for a response rate of 46.8 percent .

among departments and large agencies , the department of veterans affairs had the lowest response rate — 32.6 percent — and the national science foundation had the highest — 77.3 percent .

we analyzed the 2006 through 2014 fevs data file containing the 84 core questions and demographic variables provided to us by opm .

the datasets contain the full demographic and work unit location information on the respondents .

opm forward coded older fevs datasets to match the coding for the 2014 survey so that question numbering and response categories were consistent across time .

if a question from the 2014 survey instrument was not present in a previous year , opm coded the questions as missing in the older data set .

to assess the reliability of the fevs data , we examined descriptive statistics , data distribution , and reviewed missing data .

we also reviewed fevs technical documentation as well as the statistical code opm uses to generate the index and variance estimates , and we interviewed officials responsible for collecting , processing , and analyzing the data .

on the basis of these procedures , we believe the data were sufficiently reliable for use in the analysis presented in this report .

opm first introduced the eei in 2010 , when it contained 8 questions .

opm revised it in 2011 to contain the 15 questions that currently comprise the eei .

according to opm , the eei is a measure of the conditions conducive to engagement .

the eei consists of three components — leaders lead , supervisors , and intrinsic work experience .

opm calculates the eei by averaging the component scores , which are an average of the percent of positive responses to each question in the respective component .

for a full list of eei questions , see table 1 earlier in this report .

to determine trends in employee engagement as measured by the fevs for the years 2006 to 2014 , we calculated the eei using the data provided by opm .

for 2010 to 2014 , we calculated the index using responses to the 15 questions contained in the current index .

for 2006 and 2008 , we calculated the eei using only 11 of the 15 eei questions because the 2006 and 2008 surveys did not include four questions that were added to the survey in 2010 .

because opm calculates the eei and its component scores at the group level , we used data from opm to recalculate the eei for each individual , which enabled us to conduct regression analysis and assess the statistical significance of changes in eei .

the individual level calculation is scaled between 0 and 100 and is based on the proportion of each individual's positive responses to the 15 constituent eei questions .

to test the comparability of the 2010 to 2014 estimates , which we calculated based on the 15 questions in the current eei , and the 2006 and 2008 estimates , which we calculated based on the 11 eei questions in the survey at that time , we recalculated the eei for 2010 to 2014 using just the 11 eei questions present in the 2006 and 2008 survey data .

the revised eei estimates for 2010 to 2014 based upon just the 11 questions averaged about 2.9 percentage points less than the eei estimates based on the full 15 questions .

while the trend line with a peak in 2011 was similar when the estimates were plotted by year , we did not make comparisons from 2008 to 2010 because of the change in the index composition .

to generate estimates for agencies and employee population groups , we aggregated the index across individuals using the appropriate sample weights .

we followed the replicate weight variance estimation methodology recommended by opm to generate sample variance estimates for the index scores .

this enabled us to analyze the drivers of engagement and assess the statistical significance of differences .

to ensure that our calculation of the eei would yield sufficiently similar results as opm's methodology for 2014 , we assessed the correlation between the two versions .

when aggregated to the agency level , our index is nearly perfectly correlated with the opm measure in 2014 ( ρ=0.99971 ) .

to confirm the cohesiveness of the individual index , we calculated cronbach's alpha , a measure of internal consistency that ranges from zero to 1 for 2014 .

the alpha value of .94 suggests that the scale of the items captures the majority of the variation in the underlying items , indicating high internal consistency .

using the employee engagement index ( eei ) calculated at the individual level , for 2006 through 2014 we analyzed the eei government - wide , including the eei components scores ; by agency for those with a minimum of 5 years of federal employee viewpoint survey ( fevs ) data for the years analyzed and at least 100 respondents , and by employee population measured by the fevs .

for each analysis , we determined statistically significant year - to - year changes in the eei from 2006 to 2014 , with the exception of 2008 to 2010 because the questions in the eei for those years were not comparable .

we identified statistical differences by assessing whether the 95 percent confidence intervals of two estimates overlapped or not rather than conducting multiple t - tests ; confidence intervals that do not overlap represent differences that are statistically significant .

if the change was statistically significant , there is less than a 5 percent probability that the difference occurred by chance .

this method of assessing difference is conservative , in that it may underestimate the amount of statistically significant differences in cases of minor overlap of confidence intervals , but does not require us to use a testing methodology modification such as a bonferroni adjustment to account for multiple comparisons .

table 4 below shows the downward trend in the government - wide eei and for two of the three components .

tables 5 and 6 show the eei trends for the 47 agencies with a minimum of 5 years of fevs data for the years analyzed and at least 100 respondents and whether year to year changes were statistically significant .

these tables are the basis for figure 2 .

table 7 shows the estimated eei by employee population category .

to determine the extent of variation in responses within an employee population , we measured the greatest possible amount of variation in each of the years 2006 through 2014 .

specifically , we measured the percentage point difference between the confidence interval upper bound of the category with the highest eei and the lower bound confidence interval of the category with lowest eei in each of the years .

pay category and supervisory status consistently had the widest variation in eei scores .

our analysis of the drivers of engagement measures the extent to which selected fevs questions predict the eei .

to conduct this analysis , we reviewed relevant literature and interviewed knowledgeable individuals to identify and refine a list of potential drivers of engagement , and then identified corresponding fevs questions not included in the eei .

using fevs 2014 data , we then used multiple linear regression analysis to assess the correlation between the driver questions and the eei , controlling for other factors such as agency and employee characteristics .

we used both statistical significance and the magnitude of regression coefficients to define drivers of the eei .

we conducted sensitivity tests to ensure that our results were robust to differences in model specification , functional form , and to the exclusion of cases with high levels of missing data .

in addition to our government - wide analysis , we analyzed the drivers among employees at each of the chief financial officers act agencies and selected employee populations .

results of these analyses were generally consistent with our government - wide analysis .

to determine the fevs questions to include in our statistical model we reviewed relevant literature and interviewed knowledgeable researchers , government officials from the united kingdom , canada , and australia responsible for their comparable public - sector employee survey , and consultants on employee engagement .

we then categorized all the potential drivers identified by sector — such as academia , consultants , and the federal government .

we selected the drivers identified by two or more sectors , as well as those for public policy reasons we considered important to include in our model .

we subsequently identified the corresponding fevs questions not included in the eei that reflected the concepts for each of the drivers .

we selected at least one fevs question as a proxy for each of the potential drivers that we identified , as shown in table 8 .

the questions that we selected were those we determined to be the most actionable by managers and representative of the potential driver .

we also selected three drivers and questions for other public policy considerations .

to assess the relationship between potential drivers and employee engagement as measured by our index , controlling for other factors , we used linear multiple regression analysis using fevs 2014 data .

our ordinary least squares regression analysis assesses the unique correlation between the potential drivers and engagement , controlling for respondent characteristics .

for most models , we controlled for supervisory status , agency tenure , location , veteran's status , and age .

in other models we also controlled for respondent's sex , education , reported likelihood of leaving their job in the near future , race , hispanic ethnicity , disability status , and sexual orientation .

with the exception of age group and agency , we used the modal category of the sample as a referent category .

we also included a variable to control for how many of the 15 index questions the respondent answered .

in general , our agency variable included dummies for 37 individual agencies and an intercept for the remaining agencies , which tended to be substantially smaller in size ; results were similar when we tested a model with intercepts for all individual agencies available in the sample .

we used statistical software to account for the sample design in our variance estimates .

the 37 agencies include the 24 cfo act agencies as well as other agencies that participated in early fevs data collection efforts .

is a sample specific measure of how well the variation in the model's independent variables ( such as agency or demographics ) predicts the variation in the dependent or outcome variable ( here , engagement ) .

it runs from 0 to 1 , with a score of 0 suggesting that the model has no explanatory power and a score of 1 suggesting that the independent variables predict 100 percent of the variation in the dependent variable .

some questions offering a “do not know” response category .

for respondents missing or answering “do not know” to specific driver questions , we imputed data using the agency - level average for that individual to avoid losing cases in estimation through listwise deletion .

our model treats drivers of engagement as linear predictors of the engagement index .

this is a strong assumption in light of the fact that the response categories to the driver questions are ordinal , rather than interval data .

in other words , while the responses are ordered , the difference between two adjacent categories ( such as very negative and somewhat negative ) is not necessarily equal to the difference between two other adjacent categories ( such as neutral and somewhat positive ) , and therefore the assumption of linearity may not be appropriate .

we conducted sensitivity tests to ensure that our results were similar when we treated the drivers as categorical variables including intercepts for item nonresponse and no basis to judge responses .

given that our results were similar under either specification , we decided to use the linear covariates in our models to ease the interpretation of results and to reduce the degrees of freedom required to estimate the model .

given the large number of cases in our government - wide analysis , nearly all of the coefficients on the drivers in the model were statistically significant .

accordingly , we incorporated a substantive threshold in our determination of whether an independent variable acted as a driver .

we considered variables to be drivers of engagement if they had a coefficient that rounded to 3 or above , indicating that on average , each increase in positivity of responses was associated with a 3 percentage point increase in the 0 to 100 measure of engagement .

in other words , a coefficient of 3 implies that , compared to a respondent who answered neutrally to a given driver question , a respondent who answered very positively ( which is two units above neutral ) would have a predicted engagement score 6 percentage points higher .

the results for our government - wide model appear in table 9 in appendix iv .

they demonstrate that while almost all of the questions we tested attained statistical significance , a subset of questions could be considered drivers in that they had statistically significant coefficients that rounded to 3 or above .

as shown in table 9 , we identified six driver questions that strongly and significantly predicted the employee engagement score after controlling for agency and employee characteristics — these were questions 1 , 42 , 46 , 55 , 63 and 64 .

the strongest driver from our model was an employee's response to question 46 , a question related to performance management , which asks whether “my supervisor provides me with constructive suggestions to improve my job performance.” compared to employees who gave a neutral response to this question , employees who strongly agreed had an average employee engagement score approximately 10.5 percentage points higher on a 0 to 100 scale after controlling for other factors such as agency , employee characteristics and other drivers .

similarly , compared to employees who responded strongly disagree , employees who answered strongly agree had an eei score , on average , more than 20 points higher .

the second strongest driver we identified was question 1 , “i am given a real opportunity to improve my skills in my organization.” compared to those who answered neutral to this measure of career development and training , those who answered strongly agree had predicted engagement scores approximately 8 percentage points higher .

compared to a strongly disagree response , the eei score was , on average , approximately16 points higher .

four other questions had slightly smaller coefficients that rounded to 3 or above , suggesting that a respondent who answered strongly agree ( or very satisfied ) would have a predicted engagement level approximately 5 to 7 points higher than one who answered neutral , controlling for other factors .

compared to a strongly disagree ( or very dissatisfied ) response , the eei score was , on average , approximately 12 points higher .

these four questions were question 42 ( “my supervisor supports my need to balance work and life issues” ) ; question 55 ( “supervisors work well with employees of different backgrounds” ) ; question 63 ( “how satisfied are you with your involvement in decisions that affect your work ? ” ) ; and question 64 ( “how satisfied are you with the information you receive from management on what is going on in your organization ? ” ) the coefficients in our analysis indicate the unique association between a given independent variable , such as a driver or employee population control , accounting for the potential effects of other variables .

the r in light of these results , as well as reasons cited above , we determined that the linear specification is sufficient for identifying which independent variables appear to best predict variation in the engagement index .

however , we also recognize that it may be appropriate to relax the assumption of linearity depending on the research question .

finally , we tested our model on subsets of the population with response patterns that could reflect data quality issues , such as missing more than a third of the index questions or more than half of the driver variables .

our results from these analyses were consistent with the overall government - wide estimates .

the potential drivers we considered in our models were selected based on an extensive review of academic , government , and policy - related literature and a logical assessment of the particular concepts with which they related .

however , researchers may disagree over which fevs questions provide the best and most actionable proxies for the drivers we identified .

had we selected different questions as proxies for drivers found in the literature , our results may have been different .

fevs was not initially designed with the express purpose of measuring engagement or of identifying factors related to engagement .

to the extent policymakers seek to use data to assess drivers of engagement , best practices suggest designing a survey or questions to align expressly with the concepts of interest .

although we believe that fevs as designed and currently implemented is sufficient for an analysis such as that presented above , our sensitivity tests suggest that alternative measures of engagement or drivers might provide different insights as to which factors most strongly predict engagement .

our analysis does not provide insight into the validity of the eei for measuring conditions conducive to engagement or employee engagement directly .

although we found that the 15 questions comprising the eei had strong internal cohesion , we did not conduct factor analysis or additional research to determine whether an alternative scale or questions better captured the concept of engagement .

our model is not a causal assessment of the relationship between the specific fevs questions included in our model and increased engagement .

while our results identify some areas that might relate to increased engagement , we cannot be certain that an investment in a specific driver will result in increases in employee engagement .

however , our results do confirm a general consistency of which drivers of the eei , as measured by questions currently available in fevs data , appear to be statistically and substantively significant across a wide range of agencies and subgroups .

in other words , across agencies and selected employee population groups , positive responses to the six fevs questions in our government - wide model were associated with increases in the eei .

to assess potential drivers for agencies , we replicated our government - wide regression model among employees at the 24 cfo act agencies .

we limited our analysis to the cfo act agencies because they were of sufficient size so as to produce reliable results .

as shown in tables 10 through 15 in appendix iv , the drivers for the cfo act agencies were generally consistent with the results of our government - wide analysis , with some exceptions .

for example , for several agencies , question 63 would not meet our definition of a driver in that the coefficient does not always round to 3 or above .

we analyzed the drivers by employee population groups .

we selected employee population groups ( 1 ) with different amounts of variation in eei levels within the employee population group ; ( 2 ) with distinct subsets of the employee population from the others selected ( for example , we did not select both pay category and supervisory status because the categories would represent similar populations ) ; and ( 3 ) for which , in our opinion , agencies could identify actionable steps for a subset of the employee population group .

the employee population groups we analyzed were supervisory status , age , veterans status , work location ( headquarters or field ) , and agency tenure .

we then estimated versions of our regression model that included a subset of employee characteristic control variables to assess which potential drivers most strongly correlated with eei , after controlling for agency and other factors .

as shown in tables 16 to 20 in appendix iv , the drivers for the selected employee population groups were generally consistent with the results of our government - wide analysis , with minor exceptions .

for example , when analyzing potential drivers by age group , question 63 does not reach our threshold for a driver among respondents younger than 40 .

appendix iv: results of gao's analysis of the drivers of the employee engagement index question / variable federal employee viewpoint survey question included in gao model question no .

1: i am given a real opportunity to improve my skills in my organization .

question no .

42: my supervisor supports my need to balance work and other life issues .

question no .

46: my supervisor provides me with constructive suggestions to improve my job performance .

question no .

55: supervisors work well with employees of different backgrounds .

question no .

63: how satisfied are you with your involvement in decisions that affect your work ? .

question no .

64: how satisfied are you with the information you receive from management on what's going on in your organization ? .

question no .

9: i have sufficient resources to get my job done .

question no .

10: my workload is reasonable .

question no .

14: physical conditions allow employees to perform their jobs well .

question no .

17: i can disclose a suspected violation of any law , rule or regulation without fear of reprisal .

question no .

20: the people i work with cooperate to get the job done .

question no .

24: in my work unit , differences in performance are recognized in a meaningful way .

question no .

29: the workforce has the job - relevant knowledge and skills necessary to accomplish organizational goals .

question no .

32: creativity and innovation are rewarded .

question no .

37: arbitrary action , personal favoritism and coercion for partisan political purposes are not tolerated .

question no .

38: prohibited personnel practices are not tolerated .

question no .

41: i believe the results of this survey will be used to make my agency a better place to work .

question no .

70: considering everything , how satisfied are you with your pay ? .

imputation flags by question question 1 0.62 ref .

 .

ref .

 .

education level less than high school high school diploma / ged or equivalent some college ( no degree ) associate's degree ( e.g .

aa , as ) bachelor's degree ( e.g .

ba , bs ) ref .

 .

master's degree ( e.g .

ma , ms , mba ) doctoral / professional degree ( e.g .

ph.d. , md , jd ) agency tenure less than 1 year ref .

 .

ref .

 .

military service status no prior military service ref .

 .

currently in national guard or reserves ref .

 .

missing age group 25 and under ref .

 .

yes , to take another job within the federal government ref .

 .

yes , to take another job outside the federal government 0.2 ref .

 .

race american indian or alaska native native hawaiian or other pacific islander ref .

 .

sexual orientation heterosexual or straight ref .

 .

gay , lesbian , bisexual , or transgender i prefer not to say flag for number of the 15 index questions for which respondent answered do not know or gave no response no index questions missing / do not know ref .

 .

1 to 5 index questions missing / do not know 6 to 10 index questions missing / do not know more than 10 index questions missing / do not know office of management and budget ref .

court services and offender supervision agency national aeronautics and space administration national archives and records administration legend: * p < 0.05 , ** p < 0.01 , *** p < 0.001 constant: - 46.42*** r - squared: 0.74 number of cases: 392,749 design degrees of freedom: 392,667 imputation flags for potential driver variables , subgroup models control for 37 distinct agencies , the number of index questions missing , as well as the following employee population group variables: supervisory status , location , age group and military status .

we incorporated a substantive threshold in our determination of whether an independent variable acted as a driver .

we considered variables to be drivers of engagement if they had a coefficient that rounded to 3 or above , indicating that on average , each increase in positivity of responses was associated with a 3 percentage point increase in the 0 to 100 scale .

imputation flags for potential driver variables , subgroup models control for 37 distinct agencies , the number of index questions missing , as well as the following employee population group variables: agency tenure , supervisory status , age group , and military status .

we incorporated a substantive threshold in our determination of whether an independent variable acted as a driver .

we considered variables to be drivers of engagement if they had a coefficient that rounded to 3 or above , indicating that on average , each increase in positivity of responses was associated with a 3 percentage point increase in the 0 to 100 scale .

for further information regarding this statement , please contact robert goldenkoff , director , strategic issues , at ( 202 ) 512-2757 or goldenkoffr@gao.gov .

individuals making key contributions to this statement include chelsa gurkin , assistant director ; tamara stenzel , analyst - in - charge ; carl barden , alyssia borsella , martin de alteriis , deirdre duffy , robert gebhart , donna miller , anna maria ortiz , ulyana panchishin , jerry sandau , and karissa schafer .

