the department of homeland security ( dhs ) is charged with leading national efforts to secure america by deterring terrorist attacks , ensuring the nation's borders are safe and secure , and welcoming lawful immigrants and visitors , among other tasks .

after it began operations in march 2003 , dhs began developing information technology ( it ) systems to perform both mission - critical and support functions .

these systems included the acquisition of an integrated financial management system , the it infrastructure to support the secure border initiative network ( sbinet ) “virtual fence” along the nation's southwest border , and the coast guard's ( uscg ) rescue 21 system that supports its search and rescue operations off our nation's shores .

dhs has faced challenges in developing these and other systems , which have resulted in schedule delays , cost increases , and not delivering the sought - after capabilities .

independent verification and validation ( iv&v ) is a process whereby organizations can reduce the risks inherent in system development and acquisition efforts by having a knowledgeable party who is independent of the developer determine whether the system or product meets the users' needs and fulfills its intended purpose .

we have previously recognized the use of iv&v as a leading practice for federal agencies in the acquisition of programs that are variously complex , large - scale , or high risk .

congress has also previously required its implementation as one of several conditions for the obligation of funds for several high risk dhs it acquisitions , including u.s. customs and border protection's ( cbp ) sbinet and automated commercial environment ( ace ) .

as agreed , our objectives were to determine ( 1 ) how dhs's iv&v policies and procedures for it acquisitions compare with leading practices and ( 2 ) the extent to which dhs has implemented iv&v on its large it system acquisitions .

to accomplish this , we researched the iv&v policies of recognized leading practices guides , industry standards , and other federal departments and agencies ; analyzed relevant dhs department and component - level policies and guidance ; and conducted interviews with relevant department and component - level officials .

we then identified eight large it system acquisitions from dhs components for further study using specific criteria .

for these eight , we analyzed relevant program documentation , including iv&v plans , statements of work and reports from iv&v service providers , and dhs's acquisition review board ( arb ) decision memoranda .

we conducted this performance audit from march 2010 to july 2011 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

see appendix i for a complete description of our objectives , scope , and methodology .

dhs's mission is to lead the unified national effort to secure america by preventing and deterring terrorist attacks and protecting against and responding to threats and hazards to the nation .

dhs is also responsible for ensuring that the nation's borders are safe and secure , welcoming lawful immigrants and visitors , and promoting the free flow of commerce .

created in 2003 , dhs assumed control of about 209,000 civilian and military positions from 22 agencies and offices that specialize in one or more aspects of homeland security .

the intent behind the merger that created dhs was to improve coordination , communication , and information sharing among these multiple federal agencies .

figure 1 shows dhs's organizational structure ; table 1 identifies dhs's principal organizations and describes their missions .

not since the creation of the department of defense in 1947 has the federal government undertaken a transformation of this magnitude .

as we reported before the department was created , such a transformation is critically important and poses significant management and leadership challenges .

for these reasons , we designated the implementation of the department and its transformation as high risk in 2003 , and we continue to do so today .

in this regard , we have stated that failure to effectively address dhs's management challenges and program risks could have serious consequences for our national security .

in support of its organizational transformation and in response to the nation's evolving security needs , dhs has been spending billions of dollars each year to develop and acquire it systems to perform both mission - critical and support functions , which frequently must be coordinated among components , as well as among external entities .

for fiscal year 2010 , dhs expected to spend approximately $6.3 billion on 348 it - related programs , which included 53 major it acquisition programs that were designated for oversight by the dhs under secretary for management .

we refer to these 53 programs as “large acquisitions” throughout this report .

table 2 describes the programs relevant to this review .

in order to manage these acquisitions , the department finalized an acquisition life cycle and review process in 2010 , and established the management directorate , headed by the under secretary for management , which houses both the chief information officer ( cio ) and chief procurement officer ( cpo ) .

the cio's responsibilities include setting departmental it policies , processes , and standards , and ensuring that it acquisitions comply with dhs it management processes , technical requirements , and approved enterprise architecture , among other things .

additionally , the cio chairs dhs's chief information officer council , which is responsible for ensuring the development of it resource management policies , processes , best practices , performance measures , and decision criteria for managing the delivery of it services and investments , while controlling costs and mitigating risks .

the cpo is the department's senior procurement executive , who has leadership and authority over dhs acquisition and contracting , including major investments .

the cpo office's responsibilities include issuing acquisition policies and implementation instructions , overseeing acquisition and contracting functions , and ensuring that a given acquisition's contracting strategy and plans align with the intent of the department's arb , the department's highest investment review board .

dhs's acquisition management directive defines four acquisition life cycle phases that are to ensure consistent and efficient management , support , review , and approval for programs across the department .

each phase culminates in an arb review on whether a program is ready to proceed to the next life cycle phase .

the arb's chairperson is responsible for determining the readiness of a program and for approving the key acquisition documents critical to establishing a program's business case , operational requirements , acquisition baseline , and testing and support plans .

also , the arb's chairperson is responsible for assessing breaches of the acquisition plan's cost and schedule baselines and directing corrective actions .

other dhs entities share responsibility for it management and procurement activities .

for example , control of it management functions is shared by the dhs cio and cios at the major organizational components ( eg , directorates , offices , and agencies ) .

similarly , dhs relies on a structure of dual accountability and collaboration between the cpo and the heads of dhs components to carry out the acquisition function .

dhs components have also designated component acquisition executives to serve as the senior acquisition officials within the components and to be responsible for implementation of management and oversight of all component acquisition processes .

since its creation , dhs has faced challenges in acquiring large it systems , leading to cost and schedule overruns on multiple programs .

our november 2008 report on dhs's oversight of major acquisition programs described several of these challenges .

specifically ,  dhs had not effectively implemented or adhered to its investment  dhs had not consistently enforced decisions that were reached by the investment review board because the department did not track whether components and offices had taken the actions required by the board ; and two of nine components did not have the required component - level review processes to adequately manage their major investments .

accordingly , we made a series of recommendations to dhs to address weaknesses in departmentwide acquisition policies and practices and with individual programs , such as reinstating the department's oversight board to review and approve acquisition requirements and assess potential duplication of effort , and directing that component heads establish a mechanism to ensure that major investments comply with established component and departmental investment review policy standards .

the department generally concurred with our findings and recommendations , citing actions that had been taken and efforts under way to improve the investment review process .

in september 2009 and again in june of 2010 , we reported on the status of dhs's acquisition improvement efforts and on selected major acquisition programs .

despite some progress , we found that many of dhs's major system acquisitions were still not receiving effective oversight and that dhs continued to face challenges in fully defining and implementing key system investment and acquisition management policies and procedures .

among other things , we noted that the arb had begun to meet more frequently than in the past and had reviewed dozens of major acquisition programs , but more than 40 programs had not been reviewed , and programs did not consistently implement review action items by established deadlines ;  nearly 80 percent of major programs lacked basic acquisition documents , and a database established to track key program information — such as cost and schedule performance and program risks — relied on self - reported program data rather than independently verified data ; and component acquisition review processes were not fully in place , and components' efforts to implement department oversight directives and sufficiently staff the associated processes were not yet complete .

we concluded that , while the department had made progress in establishing key institutional acquisition and it investment management - related controls and implementing them on large - scale programs , considerable effort remained before the department could be considered a mature it system acquirer and investor and that our prior recommendations continued to provide the department with a framework to guide its efforts .

iv&v is a process whereby organizations can reduce the risks inherent in system development and acquisition efforts by having a knowledgeable party who is independent of the developer determine that the system or product meets the users' needs and fulfills its intended purpose .

iv&v involves proactively determining early in a program's life cycle what its risks are likely to be , and then identifying those that could be mitigated or lessened by performing additional reviews and quality assessments .

iv&v activities can help ensure that quality is built into program deliverables from the beginning — starting with business and requirements analysis , continuing through software development and unit - testing activities , and ending with system and integration testing and acceptance .

we have previously identified iv&v as a leading practice for large and complex system development and acquisition programs .

in addition , a review published in 1999 by the institute of electrical and electronics engineers ( ieee ) found that iv&v had a measurable beneficial effect on a program's development .

for example , it  promoted the earlier detection of system faults , identified a greater number of faults ,  helped to reduce the average time it takes to fix faults , and  enhanced operational correctness .

the study concluded that any process that systematically applies well - designed iv&v activities to a structured software development process would result in similar benefits .

typically , iv&v is performed by an agent that is independent of the development organization to obtain unbiased reviews of a system's processes , products , and results , with the goal of verifying and validating that these meet stated requirements , standards , and user needs .

as such , we have reported that iv&v is work above and beyond the normal quality assurance and performance review activities performed during system development and acquisition .

this work must not substitute for the developer's responsibility , but should complement and reinforce the developer's system engineering processes , configuration management , and qualification test functions .

according to recognized industry standards , iv&v can provide management with an objective assessment of a program's processes , products , and risks throughout its life cycle and help ensure conformance to program performance , schedule , and budget targets .

furthermore , it can help facilitate the early detection and correction of system anomalies and support the system's conformance to performance , schedule , and budget goals , among other benefits .

we have previously identified the independence of the responsible agent as a key aspect of iv&v's value to the it acquisitions process .

independence is defined by the following three components:  technical independence – requires the effort to be performed by personnel who are not involved in the development of the system .

this ensures that the iv&v team brings a fresh viewpoint to the analysis of the system development process and its products .

 managerial independence – requires that the agent be managed separately from the development and program management organizations .

the effort must be allowed to freely select the system components or segments it will analyze and test , and the test and analysis techniques it will use .

the agent must also be allowed to freely report its findings to program management , without prior approval from the development group .

 financial independence – requires that the funding for iv&v be controlled by an organization separate from the development organization .

this ensures that the effort will not be curtailed by having its funding diverted to other program needs , and that financial pressures cannot be used to influence the effort .

an iv&v effort that exhibits all three of these characteristics is fully independent ( see fig .

2 ) .

rigorous independence from the development or acquisition effort ensures that iv&v's insights into a program's processes and associated work products are objective .

verification and validation ( v&v ) are related processes intended to provide evidence that developed or acquired products meet specified requirements and that they fulfill their intended use when placed in their intended environment , respectively .

v&v practitioners gather this information through the assessment , analysis , evaluation , review , inspection , and testing of system engineering products and processes .

in other words , verification ensures that “you built the product right,” while validation ensures that “you built the right product.” table 3 illustrates iv&v activities and work products for a typical development / acquisition life cycle .

iv&v activities may also focus on program management activities and work products across the development / acquisition life cycle .

for example , the agent may be involved in the program's risk management efforts by identifying new risks , or by providing recommendations to eliminate , reduce , or mitigate risks .

the agent may also provide an independent view of the program's progress in terms of its ability to meet cost , schedule , or performance commitments .

congress has recognized the value of iv&v , in that it has previously required its implementation as one of several conditions for the obligation of funds for certain acquisitions at dhs .

for example , congress directed the department to certify that an iv&v agent was under contract as a condition for obligating funds in fiscal year 2007 for ace , sbinet , and the u.s .

visitor and immigrant status indicator technology program .

in addition , the deputy administrator of e - government and information technology at the office of management and budget told us that he has seen the value of the practice during their reviews of major investments , although its use is not required at federal agencies .

our review of leading practices from industry and across the federal government identified several key elements of effective iv&v , which are described here along with examples we obtained from examining the policies of several federal departments and agencies contacted during this review .

 decision criteria .

when deciding to perform iv&v , risk - based criteria should be used to determine which programs , or aspects of programs , should be subject to review .

in other words , the determination to conduct iv&v and its extent should be made on the basis of the relative mission criticality of the program and its components , as well as on the potential impacts to the program from undetected system errors , immaturity of the technology to be used , and unreliability of program schedule and cost estimates , among other program risks .

for example , nasa policy states that the iv&v board of advisors provides recommendations to the chief , safety and mission assurance , for implementing iv&v on specific programs , based on specific criteria such as technical complexity , human safety , consequences of failure , program costs , and required time frames .

the chief then authorizes iv&v for the programs with the highest risk profiles .

 standards for independence .

organizations should also include standards that describe the degree of technical , managerial , and financial independence required of the personnel or agents performing iv&v .

having standards for independence helps to ensure that the results of activities are reported to program oversight officials , as well as to program management .

in this regard , nasa has established an agencywide program for managing all of the system software iv&v efforts .

the program includes an internal organization that functions as their iv&v agent and that has no technical , managerial , or financial ties to the development organization .

 defined scope of the effort .

the effort should document which program development or acquisition activities will be subject to iv&v .

examples of such activities may include: requirements evaluation , concept / design evaluation , risk evaluation , risk management procedures evaluation , configuration management procedures evaluation , test evaluation , operational readiness evaluation , and cost estimate evaluation .

further , compliance criteria should be established for each activity .

for example , nasa's iv&v technical framework has defined assessment procedures for various system development activities , along with related pass / fail criteria .

 required program resources .

plans should identify the required personnel , funding , facilities , tools , and methods that will be required to perform the activities necessary for the defined scope of the iv&v effort .

for example , the federal bureau of investigation requires identification of staff , tools , and training necessary to perform iv&v activities and to develop and maintain work products .

 management and oversight .

as with any investment , organizations should conduct proper management and oversight of their iv&v efforts .

for example , in order to effectively manage the effort , the roles and responsibilities of all parties involved should be specified and a process for responding to issues raised by the effort should be defined .

several agencies we spoke with had established policies that defined the roles and responsibilities of parties involved in their iv&v process .

for example , the federal bureau of investigation's policy defines the relationship between the program manager , the developer / integrator , and the contractor , including distribution channels for program artifacts , assessments , and deliverables .

further , organizations should also provide the means for senior management to obtain timely information regarding the progress of their iv&v investments in terms of cost , capability , timeliness , and quality .

concerning iv&v oversight , organizations should evaluate the effectiveness of their efforts .

a variety of guidance recommends that organizations should actively monitor service providers to ensure that they are effective in delivering services and meeting requirements .

moreover , organizations should ensure that sufficient information about their iv&v investments is maintained to support current and future investment decisions and to highlight lessons learned .

for example , nasa has found over the years that the application of rigorous iv&v has provided a positive return on investment , and has taken steps to assess the quality and consistency of their efforts through its technical quality and excellence group , which examines iv&v results across all projects and ensures that efforts were conducted in accordance with approved guidelines and standards .

adoption of iv&v can provide agencies with information to better manage their it investments .

to be effective , leading industry practices and government guidance recommend , among other things , that organizations adopt certain key elements of effective iv&v .

dhs's acquisition guidebook recognizes iv&v as a leading practice , recommends ( though generally does not require ) its use , and cites the ieee standard for v&v as the basis for iv&v .

however , dhs's policy contains key gaps or ambiguities relative to each of the key elements of effective iv&v .

 decision criteria .

dhs policy does not specify a risk - based approach , does not define related criteria for making decisions regarding iv&v , and does not require component agencies to do so .

specifically , the department does not establish risk - based decision making criteria in its acquisition guidebook for determining whether , or the extent to which , it programs should use it and does not require that programs conduct assessments against such criteria .

 standards for independence .

dhs acquisition policy does not address the independence of agents .

dhs's policy does not define the required degree of independence that agents must demonstrate and does not require that its component agencies define such standards for themselves .

consequently , the policy does not specify mechanisms to ensure that efforts on major it acquisitions are adequately objective .

moreover , the policy does not establish reporting mechanisms to ensure that the results of activities are reported to program oversight officials for use in dhs's investment management process .

 defined scope of the effort .

dhs does not require that the specific scope of efforts be defined .

while department policy suggests performing iv&v on life cycle activities such as requirements definition , requirements management , and operational readiness activities , department policy does not require that its component agencies or acquisition programs critically assess their it acquisition programs to determine and document the appropriate scope of iv&v efforts for each program .

in addition , the policy does not require that such efforts identify and document compliance criteria for the validation and verification activities .

 required program resources .

dhs acquisition policy does not require ( or require that its component agencies ensure ) that it acquisitions identify and document the resources needed to execute their efforts — including facilities and tools .

it is also silent on other essential aspects of planning the effort , including funding and human resources .

 management and oversight .

dhs policy does not address iv&v management or the need to effectively oversee the department's investment in this practice .

while dhs policy assigns certain responsibilities for agents and government officials , it does not require a process for responding to issues raised by the effort and does not require that its component agencies or their acquisition programs do so .

in addition , officials at both the office of the cio and office of the cpo stated that dhs does not track which programs across the department employ iv&v unless a program is under a congressional mandate to do so .

further , dhs officials stated that they do not measure the effectiveness of iv&v efforts across the department .

thus , department officials were unaware whether or the extent to which iv&v was being used by the largest it acquisition programs .

they were also unaware of the department's total expenditures for iv&v , or if those expenditures ( which total approximately $91 million across the eight programs we reviewed in detail ) are producing satisfactory results .

officials from the office of the chief information officer said that they attempted to address iv&v in their 2010 acquisition policy , but they agreed that the policy still contains gaps relative to how it is currently planned , executed , and overseen across the department .

they stated that this was due to limited resources and other priorities .

further , they acknowledged that these gaps should be addressed and that the current policy was being revised .

until dhs provides a clear departmentwide policy requiring programs to employ the key elements of effective iv&v , it is less likely to achieve the full potential of such efforts on its large acquisitions .

consequently , iv&v may not provide the intended benefits of ensuring that dhs's it systems and their components meet quality standards , satisfy user needs , and operate as intended .

furthermore , in the absence of a clearly articulated risk - based decision framework for undertaking iv&v , applying its results , and evaluating its effectiveness , dhs's investments in iv&v efforts are unlikely to provide optimal value for the department and , in some cases , may even fail to deliver any significant benefits .

many large it acquisitions from across dhs report using iv&v as part of their acquisition and / or development process .

however , despite reports of this widespread use , we found that the department did not consistently implement key elements of iv&v on eight major it acquisition programs .

for example , none of the eight used a structured , risk - based decision making process when deciding if , when , and how to use iv&v .

in part , these weaknesses can be attributed to the lack of clear departmentwide policy requiring the application of such elements .

as a result , dhs's inconsistent use of iv&v may not reliably and significantly contribute toward meeting the schedule and mission goals of the department's major it programs .

dhs's large it programs reported widespread use of iv&v as part of their acquisition and / or development processes .

specifically , 35 of 41 major it acquisition programs from dhs's oversight list reported that iv&v efforts were planned , under way , or completed .

the specific iv&v activities reported for each program are listed in appendix ii , along with other descriptive program information .

the 35 programs reported using iv&v across a range of program activities .

for example , 26 of the programs reported performing iv&v on at least half of the life cycle activities listed in our questionnaire .

requirements validation and verification and operational readiness were the most commonly reported activities ( reported by 27 of the 35 programs responding ) ; risk management was the least reported activity ( reported by 19 programs ) .

 ( see fig .

3 for total responses on the activities we specifically identified in our questionnaire. ) .

a few programs reported other iv&v activities , such as assessment of standards compliance ; readiness of integrated logistics support ; assessment of equipment usability ; contract auditing ; and compliance with the system engineering life cycle .

to accomplish iv&v activities , program officials reported obtaining expertise from several different sources: commercial firms , federally funded research and development centers , internal resources , and other federal agencies .

some programs reported obtaining iv&v services from multiple sources .

 ( for further information reported by dhs about the programs and their iv&v efforts , see app .

ii. ) .

despite dhs's reported widespread use of iv&v , the eight programs selected for our review did not consistently implement the elements of effective iv&v .

these programs — ace , tasc , itp , tecs - mod , ncps , itip , c4isr , and transformation — all reported that they planned and performed iv&v on system development and / or acquisition activities throughout their respective program life cycles , at a total estimated cost of about $91 million .

 ( see app .

iii for a description of the iv&v efforts and costs of these programs , as reported by dhs. ) .

however , our review of documents and artifacts for these programs determined that , in most cases , there were gaps in their implementation of iv&v .

notably , one program — ncps — demonstrated almost none of the elements of iv&v leading practices .

table 4 summarizes the extent to which each program implemented key elements of effective iv&v .

a high - level discussion of implementation across the programs , with selected examples , follows the table .

appendix iv provides the detailed results of our analysis .

 decision criteria .

none of the eight programs had fully established decision criteria to guide their iv&v efforts .

the five programs that partially met our criteria determined how or when to apply iv&v results to improve the program's management , but they did not establish and use a risk - based approach for deciding whether or to what extent to use iv&v .

for example , tasc officials told us that they meet weekly to review key findings and determine how they can improve the management of the program , but that they did not follow a structured , risk - based process in deciding to use iv&v .

the remaining three programs did not incorporate either of these aspects into their program decision processes .

 standards for independence .

each of the programs at least partially addressed the independence of their iv&v agents , but none of them ensured full technical , managerial , and financial independence .

for example , tecs - mod requires that the iv&v contractor provide written certification of its technical , managerial , and financial independence , but the effort is not managerially independent because , according to officials , the contractor is overseen by the tecs - mod program manager .

in another example , the statement of work for transformation's iv&v effort requires the agent to be technically independent , but it does not address financial or managerial independence .

 defined scope of the effort .

almost all of the programs defined the scope of their iv&v effort to at least some degree .

however , only one fully defined its scope .

itp's iv&v plan describes activities subject to iv&v in the concept , requirements , design , and testing phases of the program and includes v&v compliance criteria for all its iv&v activities .

six programs partially defined their scope .

although they defined and documented their iv&v activities , they did not define the related compliance criteria for all activities .

for example , the transformation program identified 15 tasks the iv&v agent is to perform , such as reviewing requirements management and test and evaluation activities , but it did not define all of the required compliance criteria for these tasks .

the eighth program — ncps — did not address either aspect of scope .

it documented a high - level description of desired iv&v services , but it did not define the specific activities to be performed or the related evaluation compliance criteria .

 required program resources .

just over half of the programs defined the resources required for their iv&v effort to at least some degree .

however , only one fully defined them .

transformation identified the personnel needs , facilities , and tools that were needed to support its iv&v activities , for example , by listing certification requirements for personnel .

on the other hand , the c4isr's iv&v statement of work defined the program's needs for security and test - related activities , but did not define its resource needs for other planned iv&v activities , such as cost estimation and performance verification .

three programs did not specify the resources required for their efforts .

 management and oversight .

seven of the eight programs established some degree of management and oversight for their efforts , although each contained gaps .

for example , ace's iv&v plan and the statement of work note that the agent is to report its results to the program , but do not identify a process for how ace will respond to such issues .

in addition , the responsibilities of ace's agent are defined ; however , the roles and responsibilities for government officials and evaluating the effectiveness of the iv&v effort were not specified .

these weaknesses in iv&v efforts can be partly attributed to the fact that dhs's acquisition policy does not require that programs apply recognized practices to their iv&v efforts .

performing iv&v without an established framework for planning and managing the effort could result in duplicative , unnecessary , or potentially ineffective iv&v efforts .

as a result , dhs risks not maximizing the value of its investment in iv&v , in turn making it less likely that iv&v will contribute significantly toward meeting the schedule and mission goals of its major it acquisition programs .

dhs spends billions of dollars on large it acquisitions in support of its national security mission , including millions on independent reviews of these programs .

investment in iv&v by a large number of these programs reflects a view across dhs that it is a worthwhile acquisition practice , a view also represented in dhs's acquisition policy .

however , because dhs has not provided guidance for planning , executing , and overseeing the elements of this practice across the department nor required its components to do so , it lacks consistent approaches and criteria for determining whether and how to proceed with iv&v on programs , specifying the needed independence of agents , defining the scope of efforts , planning and procuring the needed resources , and managing and utilizing results .

not surprisingly , none of the high - budget acquisition programs that we reviewed had fully implemented the key elements of effective iv&v .

executing such efforts without a disciplined framework for planning and management may make such efforts duplicative , unnecessary , or unusable .

moreover , without well - defined mechanisms for tracking iv&v efforts , results , and effectiveness , and incorporating this information into the department's investment management processes , dhs's investment decisions may not adequately take into account the concerns raised by these efforts .

to realize iv&v's promise as a tool for reducing the risks inherent in developing it systems , dhs needs to promote a common understanding of effective iv&v across the department , and through its oversight activities , ensure that component agencies and their large it programs conduct efforts that consistently contribute toward meeting it acquisition cost , schedule , and mission goals .

to help guide consistent and effective execution of iv&v at dhs , we recommend that the secretary of homeland security direct the department cio and cpo to take the following three actions:  revise dhs acquisition policy such that it establishes risk - based criteria for ( 1 ) determining which major and other high - risk it acquisition programs should conduct iv&v and ( 2 ) selecting appropriate activities for independent review of these programs ; requirements for technical , financial , and managerial independence of agents ; standards and guidance for defining and documenting plans and products ; controls for planning , managing , and overseeing efforts ;  mechanisms to ensure that plans and significant findings inform dhs acquisition program reviews and decisions , including those of the arb ; and  mechanisms to monitor and ensure implementation of this policy on applicable new it acquisition programs .

 reevaluate the approach to iv&v for ongoing programs ( including the eight programs featured in this report ) and ensure that appropriate actions are taken to bring each of them into alignment with the elements of leading practice .

 collect and analyze data on iv&v efforts for major it acquisition programs to facilitate the development of lessons learned and evaluation of the effectiveness of dhs's investments , and establish a process that uses the results to inform the department's it investment decisions .

in written comments on a draft of this report , signed by the director , departmental gao / office of inspector general liaison and reprinted in appendix v , dhs stated that it concurred with our recommendations and described actions planned or under way to address them .

regarding our first recommendation , the department stated that it is drafting an interim iv&v policy implementation plan that will outline best practices , templates , tools , and processes for iv&v .

the interim plan will also require programs to develop iv&v plans early in their life cycle , and to assess programs at their conclusion to ensure that all iv&v artifacts , processes , and systems had been developed properly .

further , the response stated that dhs components will be expected to use the department's implementation plan to tailor iv&v activities based on program size , complexity , risk , and other program management factors .

in addition , dhs stated that it is considering modifications to its existing guidance to reflect iv&v industry standards and best practices , and to demonstrate requirements for the independence of iv&v agents as called for in this report .

regarding our second recommendation , the department responded that it is creating an independent team of subject matter experts to provide oversight of iv&v efforts across dhs .

this team is to determine whether appropriate resources , tools , and facilities have been allocated , and will report results as necessary .

given the limited extent to which the programs we reviewed are currently employing the key elements of effective iv&v , expeditiously establishing this team and conducting the reviews would help identify the full extent of the need for improvements departmentwide .

concerning our third recommendation , the department's response stated that dhs will create a repository to store data about its iv&v efforts in order to generate lessons learned and gauge the effectiveness of these efforts , among other things .

the department also provided technical comments , which we have incorporated in the report , as appropriate .

we are sending copies of this report to the appropriate congressional committees ; the secretary of the department of homeland security ; and other interested parties .

in addition , this report is available at no charge on our web site at http: / / www.gao.gov .

if you or your staff members have any questions on the matters discussed in this report , please contact me at ( 202 ) 512-9286 or pownerd@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix vi .

our objectives were to determine ( 1 ) how the department of homeland security's ( dhs ) independent verification and validation ( iv&v ) policies and procedures for information technology ( it ) acquisitions compare with leading practices and ( 2 ) the extent to which dhs has implemented iv&v on its large it system acquisitions .

to determine how dhs's iv&v policies and procedures for it acquisitions compare with leading practices , we first identified key elements of leading practices for iv&v .

specifically , we reviewed ( 1 ) the software engineering institute's capability maturity model® integration , focusing on the validation and verification process areas , ( 2 ) the institute of electrical and electronics engineers ( ieee ) standard for software verification and validation , ( 3 ) the ieee / international organization for standardization / international electrotechnical commission standard for system life cycle processes , ( 4 ) the international organization for standardization standard for software life cycle processes , and ( 5 ) our prior work .

within these documents , we identified validation , verification , and independence concepts and practices that these sources have in common .

we then categorized the concepts and practices into the following key elements of leading practice for iv&v: ( 1 ) decision criteria , ( 2 ) effort independence , ( 3 ) project scope , ( 4 ) project resources , and ( 5 ) management and oversight .

we also examined how iv&v is used by other federal agencies to provide context for our review of dhs .

we selected the additional agencies by identifying those that had the highest average it spending per investment for fiscal years 2008 to 2010 .

they are: the department of commerce , the department of defense , the department of energy , the department of homeland security , the department of justice , the national aeronautics and space administration ( nasa ) , the social security administration , the department of state , the department of transportation , and the department of veterans affairs .

we reviewed their policies regarding iv&v and selected examples that were used to illustrate some of the leading iv&v practices that they follow and perform .

specifically , we identified relevant examples from the department of justice and nasa .

next , we held interviews with dhs officials , and gathered and reviewed the department's policy documents related to iv&v .

we then compared the policy and procedures with the five key elements of iv&v leading practice .

we used the following rules to characterize the extent to which dhs's policies addressed the elements:  met .

dhs provided evidence that fully satisfied all aspects of the element .

 partially met .

dhs provided evidence that satisfied some , but not all aspects of the element .

 not met .

dhs provided evidence that did not satisfy any aspects of the element or provided no evidence .

to determine the extent to which dhs had implemented iv&v on its large it system acquisitions , we first collected information on the status and program characteristics of the 53 level 1 and 2 it acquisitions listed in dhs's major acquisitions oversight list of may 26 , 2010 .

to do so , we requested from program officials their respective program's life cycle approach , estimated acquisition costs , and planned iv&v activities .

during our review , 12 programs were defunded , recategorized to level 3 or non - it , or taken off the oversight list by dhs and therefore were not analyzed for this report .

we used the self - reported program data to populate table 5 in appendix ii and to select a subset of programs for more detailed analysis of iv&v implementation .

we used three criteria to identify programs for further study .

first , the selected programs were to represent iv&v implementation across a variety of dhs components .

second , the selected programs would be among dhs's largest ( level 1 ) .

third , the selected programs would have the highest estimated acquisition cost within each of dhs's components .

thus , we selected the largest program ( based on estimated acquisition cost ) from each dhs component that reported having at least one level 1 it acquisition that reported using iv&v — with one exception .

since we have previously issued detailed reports on the coast guard's largest program , rescue 21 , we instead selected u.s. coast guard's command , control , communications , computers , intelligence , surveillance , and reconnaissance ( c4isr ) program .

using this approach , we selected the eight it acquisitions featured in appendixes iii and iv .

next , we collected and analyzed iv&v related documents and information from each of these programs and conducted follow - up interviews with cognizant officials to clarify documentation and elaborate their responses .

we then compared these data with key elements of effective iv&v and scored the programs using the previously described scoring methodology .

to assess the reliability of the data that was used to support the findings in the report , we reviewed relevant program and agency documentation to substantiate evidence obtained through interviews with knowledgeable agency officials .

we validated that the documents we used in this review were current and officially issued by conferring with dhs and component agency officials in meetings and in the formal exit conference .

on this basis , we determined that the data used in this report are sufficiently reliable .

we appropriately attributed the sources of data we used throughout this report .

this includes sections in which data is self - reported , such as figure 3 , table 4 , appendix ii , and appendix iii .

we conducted this performance audit at gao headquarters in washington , d.c. , from march 2010 to july 2011 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

to characterize the extent to which dhs has implemented iv&v on its large it acquisitions , dhs department , component , and program officials provided the data in table 5 for the level 1 and level 2 it acquisition programs listed in the major acquisition oversight list issued by the under secretary for management on may 26 , 2010 .

of the 41 programs , 35 reported planning , conducting , or completing some type of iv&v activity .

the decision makers for conducting iv&v on these programs — congressional mandate , departmental decision , or others — are summarized in the discussion that follows and in table 6 .

dhs officials also provided information about the origins of their iv&v decisions for these programs .

for the 18 level 1 acquisitions that reported iv&v activities , congress mandated that 2 of the acquisitions perform iv&v ; dhs required that 7 of the programs use iv&v ; and the component , program , or other entity decided to perform iv&v on 9 of the acquisitions .

for the 17 level 2 acquisitions that reported iv&v activities , none were congressionally mandated ; dhs required iv&v for 2 of the acquisitions ; and component , programs , or other entities decided to perform iv&v on 15 acquisitions .

table 6 summarizes the decision makers for conducting iv&v on level 1 and level 2 programs .

table 7 summarizes key characteristics of eight large dhs it acquisitions and their associated iv&v efforts and costs , as reported by dhs program officials for this review .

the systems engineering life cycle stages identified in the table are further discussed in the context of dhs's acquisition life cycle after the table .

dhs's acquisition instruction / guidebook establishes a four - phase acquisition life cycle .

these life cycle phases are: ( 1 ) identify a capability need ; ( 2 ) analyze and select the means to provide that capability ; ( 3 ) obtain the capability ; and ( 4 ) produce , deploy , and support the capability .

these phases generally align with one or more systems engineering life cycle phases .

the directive requires the acquisition review board ( arb ) to review each major acquisition program at least three times at key acquisition decision events during a program's acquisition life cycle .

selected documents considered during acquisition decision events , such as the mission need statement , the acquisition plan , and the integrated logistics support plan , are depicted in the following figure , along with the associated systems engineering life cycle phases .

this appendix presents brief program overviews and our assessment of dhs's implementation of iv&v on eight select large it acquisitions compared with key elements of effective iv&v .

ace is a commercial trade processing system intended to facilitate the movement of legitimate trade , strengthen border security , and replace existing systems with a single system for collecting and providing trade data to federal agencies .

it is a level 1 acquisition with a life cycle cost of approximately $4.5 billion .

of the total life cycle cost , approximately $2.8 million has been budgeted for iv&v .

ace has been divided into 11 segments , consisting of one in the planning stage , two in the development stage , and eight in the operations and maintenance stage .

ace officials reported that the following iv&v activities are under way or planned: independent cost estimation or cost estimate validation ;  program progress or performance verification or evaluation ; requirements validation or verification ; concept or design validation , verification , or alternatives analysis ; security vulnerability or security risk assessment ; component verification testing and evaluation ; system or integration verification testing and evaluation ; and  operational readiness testing and evaluation .

table 8 describes the extent to which ace has implemented the key elements of effective iv&v .

tasc was announced in 2007 and is intended to modernize , transform , and integrate the various financial acquisition and asset management systems in use at the department's components .

it is a level 1 acquisition and has a life cycle cost estimate of approximately $991 million , with $3.4 million budgeted for iv&v .

tasc reported that it was in the solutions engineering phase of its life cycle and that iv&v is planned or under way in the following activities:  program progress or performance verification or evaluation ; requirements validation or verification ; concept or design validation verification , or alternatives analysis ; security vulnerability or security risk assessments ; component verification testing and evaluation ; system or integration verification testing and evaluation ; and  operational readiness testing and evaluation .

table 9 describes the extent to which the program has implemented the key elements of effective iv&v .

itp is intended to contribute to dhs's consolidated infrastructure investment , supporting areas such as data center , network , and e - mail consolidation .

with a life cycle cost of approximately $1.2 billion , itp is a level 1 acquisition .

the program has four segments ; one segment is in the planning stage , and three are in the operations and maintenance phase .

officials from the office of the chief information officer report that the iv&v agent for itp is currently performing the following program activities: independent cost estimation or cost estimate validation ;  program progress or performance verification or evaluation ; requirements validation or verification ; concept or design validation verification , or alternatives analysis ; security vulnerability or security risk assessments ; component verification testing and evaluation ; system or integration verification testing and evaluation ; and  operational readiness testing and evaluation .

table 10 describes the extent to which the program has implemented the key elements of effective iv&v .

tecs - mod is intended to modernize the system ice uses to perform investigative activities .

specifically , tecs - mod involves modernizing the investigative case management system and related support modules of the legacy tecs system .

ice's total combined life cycle cost is estimated at approximately $1.1 billion and an estimated $1.75 million for iv&v efforts .

the program is a level 1 acquisition and is currently in the requirements definition phase .

according to ice officials , the iv&v agents for tecs - mod are to perform the following iv&v activities: independent cost estimation or cost estimate validation ;  program progress or performance verification or evaluation ; requirements validation or verification ; concept or design validation , verification , or alternatives analysis ; security vulnerability or security risk assessments ; component verification testing and evaluation ; system or integration verification testing and evaluation ;  operational readiness testing and evaluation ; and software design and development request for proposals .

table 11 describes the extent to which the program has implemented the key elements of effective iv&v .

the ncps program is intended to reduce the federal government's vulnerabilities to cyber threats by decreasing the frequency of cyberspace disruptions and minimizing the duration and damage of those disruptions .

it is classified as a level 1 acquisition with a total estimated life cycle cost of approximately $1.2 billion .

the program is structured in five segments , three of which are under development — one in the planning stage , one in design , and one in integration .

two segments have been completed and are in the operations and maintenance phase .

nppd officials reported that the following iv&v activities are either planned , under way , or have been completed: independent cost estimation or cost estimate validation ; requirements validation or verification ; concept or design validation , verification , or alternatives analysis ; risk evaluation ; security vulnerability or security risk assessments ; component verification testing and evaluation ; and system or integration verification testing and evaluation .

table 12 describes the extent to which the program has implemented the key elements of effective iv&v .

itip is intended to provide comprehensive technical infrastructure support for tsa in four main program areas: ( 1 ) office automation , ( 2 ) infrastructure , ( 3 ) program management , and ( 4 ) contract support .

it is a level 1 acquisition , with a life cycle cost of approximately $3.5 billion .

itip is currently in operations and maintenance .

itip officials reported that the following iv&v activities are under way: independent cost estimation or cost estimate validation ;  program progress or performance verification or evaluation ; requirements validation or verification ; security vulnerability or security risk assessments ; configuration management verification ; and  operational readiness testing and evaluation .

table 13 describes the extent to which the program has implemented the key elements of effective iv&v .

uscg's c4isr program is intended to be an interoperable network that combines information from uscg assets and sensors , allowing the uscg to see , comprehend , and communicate rapidly .

it is a level 1 acquisition with a life cycle cost of approximately $1.3 billion ( according to its 2011 budget submission ) and is currently in the development phase .

of this cost , about $20.6 million is budgeted for iv&v .

uscg officials report that the iv&v agent is performing the following iv&v activities: independent cost estimation or cost estimate validation ;  program progress or performance verification or evaluation ; security vulnerability or security risk assessments ; component verification testing and evaluation ; system or integration verification testing and evaluation ; and  operational readiness testing and evaluation .

table 14 describes the extent to which the program has implemented the key elements of effective iv&v .

transformation is a 5-year effort to modernize business processes and information technology throughout uscis .

the goal of the program is to move uscis from a paper - based filing system to a centralized and electronic filing system .

it is a level 1 acquisition , and its current life cycle cost estimate is $1.7 billion ; however , the lcce is under review .

the program has budgeted approximately $62 million for iv&v services .

there are five segments of the program ; four segments are in the planning phase , and one is in the requirements definition phase .

uscis reports that the iv&v agent is currently reviewing or plans to review the following activities: independent cost estimation or cost estimate validation ;  program progress or performance verification or evaluation ; requirements validation or verification ; concept or design validation , verification , or alternatives analysis ; security vulnerability or security risk assessments ; component verification testing and evaluation ; system or integration verification testing and evaluation ; and  operational readiness testing and evaluation .

table 15 describes the extent to which the program has implemented the key elements of effective iv&v .

in addition to the individual named above , the following staff also made key contributions to this report: paula moore ( assistant director ) , neil doherty , lynn espedido , rebecca eyler , nancy glover , daniel gordon , jim houtz , justin palk , and shawn ward .

