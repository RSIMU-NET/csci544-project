compensation for members of the career senior executive service ( ses ) , the government's cadre of senior leaders , is grounded in the notion of pay for performance , which has as its cornerstone creating incentives and rewarding excellence and achievement .

career ses employees receive a base salary and benefits , but pay increases — as well as performance awards — are to be performance driven , based on annual ratings of executives' performance following reviews within their agencies .

a central element of ses pay - for - performance systems encourages executive branch agencies to have an office of personnel management ( opm ) certified performance appraisal system to gain access to higher levels of pay for their senior executives .

opm , with the office of management and budget ( omb ) concurrence , certifies these systems , which include elements such as factoring organizational performance into appraisal decisions and making meaningful distinctions in performance and pay .

in addition , a november 2013 memo from opm and omb stated that it is critical that agencies' use of performance awards be managed in a way that is cost effective and leads to increased employee performance and organizational results .

in 2003 , congress refined the pay systems for members of the ses by requiring a clearer link between performance and pay .

this legislative provision came several years after opm had advised federal agencies that they needed to provide more rigorous and realistic ratings of their senior executives .

additionally , the president's management agenda emphasized pay for performance for senior executives and criticized agency performance management systems that failed to make meaningful distinctions between senior executives' job performance .

key features of the new pay system , which took effect on january 11 , 2004 , included the elimination of locality pay and across - the - board annual pay adjustments ; the replacement of six pay rates with one broad pay range ; an increase in the cap on base pay ; and the addition of a second higher cap for those covered under an ses appraisal system that had been certified by opm with the concurrence of omb .

performance awards are part of ses compensation and recognize excellence in ses performance during a one - year period .

executive branch career ses employees received approximately $42 million in performance awards for fiscal year 2013 , the latest year for which data were available , and according to opm regulations on certification of ses appraisal systems for executive branch agencies , agencies seeking certification are to recognize the highest performing executives with the highest ratings and the largest performance awards .

maintaining an ses compensation system that rewards and helps retain top performers is critical to achieving the goal of developing a world - class executive team in the federal government .

you requested that we examine ses performance awards .

this report ( 1 ) describes key characteristics of the awards , such as rating and award distributions , award amounts , and percentage of executives receiving awards , from fiscal years 2010 through 2013 , and ( 2 ) describes and assesses the extent to which selected departments' ses performance appraisal systems factored in organizational and individual performance and made meaningful distinctions in their fiscal year 2013 performance awards .

for an additional perspective , the second objective provides an in - depth view of five selected departments' ses ratings and performance awards' processes for the last fiscal year of rating and awards data .

to address our first objective , we reviewed agency data provided to opm on the number of ses performance awards within the 24 chief financial officers ( cfo ) act agencies and other variables from fiscal year 2010 — the year prior to the implementation of policies that limited awards — through fiscal year 2013 .

only career members of the ses who received a performance rating for a given fiscal year are eligible for performance awards , so we limited our analysis to those executives .

we reviewed opm's ses data for the presence of any obvious or potential errors in accuracy and completeness and interviewed opm officials about the accuracy of the data .

on the basis of these procedures , we believe the data are sufficiently reliable for use in the analyses presented in this report .

to address the second objective , we selected five departments based on criteria such as varied distributions of ses performance awards at different rating levels and those with the highest numbers of ses .

case studies included the departments of defense ( dod ) , energy , health and human services ( hhs ) , justice ( doj ) , and treasury .

we reviewed these departments' ses performance appraisal systems and their most recent certification documentation submitted to opm .

we also examined whether individual ses performance metrics were linked to agency performance and whether performance awards were tied to outcomes by looking at examples of individual ses performance appraisals from our case studies .

we did not verify the validity of the measures used or the performance of the senior executives .

we also interviewed agency officials from the selected departments with responsibility for their department's ses program as well as selected members or representatives of the performance review boards ( prb ) charged with ensuring consistency , stability , and objectivity in ses performance appraisals .

we conducted this performance audit from june 2014 to december 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

more detailed information on our scope and methodology appears in appendix i .

the ses is relatively small — about 7,900 members in 2013 — and represents less than one percent of the over two million federal civilian employees .

as a corps of executives selected for their leadership qualifications , members serve in the key positions just below the top presidential appointees .

ses members are the major link between these appointees and the rest of the federal work force .

they operate and oversee nearly every government activity in approximately 75 federal agencies .

opm manages the overall federal executive personnel program , and opm staff provides the day - to - day oversight of and assistance to executive branch agencies as they develop , select , and manage their federal executives .

opm has a key leadership and oversight role in the design and implementation of executive branch agencies' ses performance - based pay systems by certifying that the agencies' systems meet certain criteria .

specifically , agencies are allowed to raise ses basic pay and total compensation caps if opm certifies , with the concurrence of omb , that agencies' performance appraisal systems make — in design and application — meaningful distinctions based on relative performance .

agencies' performance appraisal systems are evaluated against certification criteria , including linking performance for senior executives to the organization's goals .

barring any compliance problems that might arise after certification has been awarded , full certification is for about 24 months .

provisional certification for about 12 months is awarded when an appraisal system meets design requirements , but there is insufficient documentation to determine whether implementation meets certification requirements .

certifying ses performance appraisal systems is also opm's opportunity to ensure that these systems meet statutory requirements .

from july 2011 through january 2012 , opm , ses members , and other agency representatives from various agencies and organizations developed a new ses performance appraisal system to try to meet the needs of executive branch agencies and their ses members .

under the new system , agencies were intended to have a more consistent and uniform framework to communicate expectations and evaluate the performance of ses members .

while promoting greater consistency , the new system was also designed to enhance clarity , transferability , and equity in the development of performance requirements , the delivery of feedback , the development of ratings , and the link to compensation .

opm stressed that a major improvement of the new system included dealing with the wide disparity in distribution of ratings by agency through the provision of clear , descriptive performance standards and rating score ranges that establish mid - level ratings as the norm and top - level ratings as truly exceptional .

while agencies are not required to adopt the new system , opm encourages agencies to do so .

table 1 shows the criteria and documentation needed for distinctions in performance and differentiation in pay and a description of the guidelines used for those criteria .

 ( appendix ii has a complete copy of opm's certification report form. ) .

in our 2008 report on ses performance management systems , we noted that while opm certified that the selected agencies were making meaningful distinctions based on relative performance as measured through the pay and performance differentiation certification criteria , performance ratings at the selected agencies raised questions about the extent to which meaningful distinctions based on relative performance were being made and how opm applied these criteria .

for example , we reported that fiscal year 2007 ses ratings were concentrated at the top two levels .

as part of making meaningful distinctions in performance , opm has emphasized to agencies through its certification guidance that its regulations prohibit forced distribution of performance ratings and that agencies must avoid policies or practices that would lead to forced distributions or even the appearance of it .

we recommended that opm strengthen communication with agencies and executives regarding the importance of using a range of rating levels when assessing performance while avoiding the use of forced distributions .

we also noted that communicating this information to agencies will help them begin to transform their cultures to ones where a “fully successful” rating is valued and rewarded .

opm implemented the recommendation , and the agency has been communicating the importance of using a range of rating levels through the new ses performance management system .

in 2003 , when congress refined the pay systems for members of the ses by requiring a clearer link between performance and pay , many senior executives were receiving the top rating .

under its regulations , opm requires agencies to write performance requirements for each senior executive at the “fully successful” level .

in addition , under opm's new ses performance appraisal system , a “fully successful” rating indicates a “high level of performance” and “effective , solid , and dependable” leadership .

a rating of 5 is the highest , ( labeled “outstanding” ) , followed by 4 ( “exceeds fully successful” ) , 3 ( “fully successful” ) , 2 ( “minimally satisfactory” ) , and the lowest rating of 1 ( “unsatisfactory” ) .

executives with a rating of 2 or 1 are ineligible for performance awards , and a rating of 1 also triggers immediate additional performance actions .

an executive receiving a rating of 1 must either be reassigned or transferred within , or removed from , the ses .

for fiscal years 2010 through 2013 , all of the cfo act agencies had four or five rating levels in place for assessing ses performance .

figure 1 shows ses performance rating distributions for the cfo act agencies for those years .

as the figure shows , more than 85 percent of career ses were given a rating of either 5 or 4 each year .

for the same four years , approximately 46 percent of career ses members received the highest possible rating .

at a few agencies , the proportion of senior executives who received a rating of 5 was larger than 70 percent .

table 2 shows the number of career ses rated and the percentage at each rating level for the 24 cfo act agencies for fiscal year 2013 .

 ( appendix iii shows career ses ratings and performance awards for the 24 cfo act agencies for fiscal year 2013. ) .

a small proportion of senior executives received a rating of 3 or lower .

for fiscal years 2010 through 2012 , about 13 percent of career executives were given a rating of 3 .

for fiscal year 2013 , 641 ( or 10.3 percent ) of executives received a rating of 3 , and at a third of the agencies , less than 5 percent were given a rating of 3 or lower .

twenty - one ( or 0.3 percent ) senior executives were rated less than fully successful .

across all of the cfo act agencies , 17 executives received a rating of 2 for fiscal year 2013 , and 4 executives received a rating of 1 .

budget constraints have affected ses performance awards in recent years , and the number of executives receiving performance awards and the size of awards has decreased since fiscal year 2010 .

while legal requirements have not changed — that ses performance awards be between 5 and 20 percent of an individual executive's rate of basic pay — opm and omb issued guidance in june 2011 that capped spending on ses performance awards at no more than 5 percent of aggregate ses salaries at a given agency , rather than the normal cap of 10 percent .

this cap was further reduced in february 2014 to 4.8 percent of aggregate salaries .

additionally , senior executives did not receive pay adjustments for three years ( from january 1 , 2011 through december 31 , 2013 ) due to federal pay - freeze legislation , which included a prohibition on ses pay increases .

figure 2 shows a timeline of selected events affecting ses performance awards from 2003 through 2014 .

table 3 shows the average ses performance awards for the four fiscal years in inflation - adjusted dollar amounts and as a percentage of base salary .

to deal with the effects of sequestration , dod chose to limit funding for ses performance awards to 1 percent of aggregate career ses salaries for fiscal year 2013 .

several other agencies also limited funding for performance awards to around 1 percent of aggregate career ses salaries .

this is one reason for the sharp decrease in the percentage of ses receiving performance awards and the decrease in average award amounts across the 24 cfo act agencies for fiscal year 2013 .

officials at several agencies said that in recent years , budget constraints have forced them to make difficult decisions about how to allocate limited award money and still make distinctions in performance pay .

figure 3 shows the average ses performance awards by rating level for the 24 cfo act agencies for fiscal years 2010 through 2013 .

since 2010 , agencies have made smaller distinctions in performance award amounts between senior executives rated at different levels of performance .

for example , for fiscal year 2010 , the average performance award for an executive with a rating of 5 was $4,991 more than the average award for an executive with a rating of 4 .

by fiscal year 2013 , the average performance award for a rating of 5 was $2,604 more than the average award for a rating of 4 .

in a report on federal performance management , we noted that it was frequently perceived that ratings were inflated by supervisors because , among other things , they were used for multiple decisions involving pay and awards , which can create a situation in which a significant number of employees are rated in the “outstanding” and “exceeds fully successful” levels .

to the extent that employees with such high ratings do not receive a monetary award , the perception that rewards are not directly linked to performance is reinforced .

on the other hand , as the number of individuals receiving monetary awards increases , the average dollar award will be reduced , resulting in the perception that the awards are less motivating .

since fiscal year 2010 , the percentage of eligible ses receiving a performance award at each rating level has decreased .

figure 4 shows the percentage of ses receiving a performance award by rating for fiscal years 2010 through 2013 .

to help assess how agencies are meeting the certification requirement to make distinctions in pay based on performance , opm uses pearson correlation coefficients as a metric to analyze the strength of the relationship between executives' pay adjustments and performance awards and their ratings .

correlation coefficients measure the linear association between ses performance pay and senior executives' ratings , and the value of the coefficient will be lower if the actual relationship between the two is not a straight line .

for this reason , differences between years or agencies in the value of the correlation coefficient may not be meaningful .

to meet the certification guidelines for pay differentiation , agencies are generally expected to have a correlation coefficient of 0.5 or greater ; if the correlation coefficient is lower than 0.5 , the guidelines state that an agency's ses appraisal system can still receive full certification if pay and awards data show the system makes distinctions in pay .

opm reported that fiscal year 2013 correlations of ses ratings and performance pay ranged from .19 to .99 for the 24 cfo act agencies: the national aeronautics and space administration had the lowest coefficient and the nuclear regulatory commission had the highest .

although correlation coefficients are useful for measuring the strength of the linear relationship between ratings and performance pay , they do not measure whether there are meaningful distinctions in pay based on performance .

for example , if an agency makes small distinctions in pay across different rating levels ( such as 5 percent of salary for executives rated 4 and 5.05 percent of salary for executives rated 5 ) , the value of the correlation coefficient may be high , even though the difference in pay between rating levels is not meaningful .

according to a 2012 opm document on the new ses performance appraisal system , with a different ses system in each agency , inconsistency among the executive branch agencies was a problem because of different definitions for rating levels across government , a mix of four - and five - level rating systems , and variable application of rating levels in evaluating ses — which led to a disparity in the ratings distribution across government .

opm officials said that when the new ses performance appraisal system was first available in fiscal year 2012 , seven agencies used the system because they were already closely aligned with it .

since then , opm officials said that about 90 percent of agencies have started to use the new system .

as more agencies adopt the new system , the system's intent of promoting greater consistency may also result in greater uniformity in the development of ratings with their link to compensation .

as mentioned previously , under the new system , opm stated that agencies will be able to rely upon a more consistent and uniform framework to communicate expectations and evaluate the performance of ses members .

while promoting greater consistency , the new system was also intended to enhance clarity , transferability , equity in the development of performance requirements , and the delivery of feedback .

in addition , opm noted that ses mobility is complicated by inconsistency — for executives moving between agencies or considering moving , there has been uncertainty regarding performance evaluations .

the new ses appraisal system was intended to help address all of these areas .

of the five systems we reviewed — dod , energy , hhs , doj , and treasury — dod , energy , and hhs used the new ses performance appraisal system .

doj and treasury were in the process of converting to the new system .

for example , a human capital official from treasury said the department is transitioning toward using government - wide performance requirements ; the official said treasury's fiscal year 2013 system had three critical elements rather than the five in opm's standard version .

four out of the five departments had automated ses appraisal systems or had plans to convert to one within the next fiscal year ; doj did not .

in addition , all of the five selected departments had performance appraisal systems that were certified by opm and omb .

dod , energy , and doj had full certification ; hhs and treasury had provisional certification .

as mentioned previously , for an agency's ses performance appraisal system to be certified , agencies' appraisal systems must meet criteria including that there is alignment between organizational and individual performance and that distinctions in pay are being made based on performance .

the selected departments were all on a fiscal year appraisal period with ratings decisions for the previous fiscal year made in the first few months of the next fiscal year .

department officials told us that the process of issuing ratings and making awards decisions happens in a fairly short timeframe .

we previously identified the alignment of individual performance expectations with organizational goals as a key practice for an effective performance management system .

it is important for individuals to see a connection between their daily operations and results to help them understand how individual performance can contribute to organizational success .

leading organizations have recognized that effective performance management systems create a “line of sight” showing how unit and individual performance can contribute to overall organizational goals and can help them drive internal change and achieve external results .

the five selected departments linked individual metrics or competencies to either component - or department - wide goals in the performance plans provided by the departments .

the plans included specific links between individual ses competencies or responsibilities and a specific organizational goal .

additionally , opm's certification criteria require that agencies align ses individual performance expectations with organizational goals , and opm has issued relevant guidance .

agencies must establish one or more ses performance review boards ( prb ) , which is a higher level of review within the ses performance management system .

the prbs review and evaluate the senior executive's initial summary rating and , if applicable , the executive's response and a higher level official's comments on the initial rating .

the boards also make written recommendations to the appointing official on annual summary ratings and performance awards .

prbs serve to ensure consistency , stability , and objectivity in performance appraisals .

boards also take into account organizational performance when making recommendations .

opm guidance states that , for agencies seeking access to higher levels of pay through certification , prbs are to ensure meaningful distinctions in executive performance and that pay increases and performance awards are made based on individual and organizational performance .

when appraising a career appointee's performance or recommending a career appointee for a performance award , more than one - half of the prb's members must be ses career appointees .

the selected departments varied somewhat in their prb structures as well as in who provided the final approval of the appraisal decisions ; some departments have additional steps or guidance as part of their processes .

for example , in addition to the prb that evaluates ratings , treasury has a front - end prb that meets to discuss ses employees' commitments early in the performance planning cycle .

a treasury official said this helps to ensure consistency in the performance plans as well as the rating and award .

once prbs have reviewed ratings and awards , they make recommendations to the appointing authority — such as the head of an agency — for final ratings and awards decisions .

prb representatives we interviewed said that awards decisions are based on ratings within individual pay pools .

although the selected departments linked ses performance plans with agency strategic objectives , the departments varied in their requirements that the prbs compare the performance ratings to the outcomes of department goals and objectives .

most of the selected departments' prb representatives said that the prb explicitly helps to ensure that there is alignment between individual performance and organizational performance by having prbs consider the organizational assessment — an assessment of the agency's overall performance — when reviewing proposed ratings and performance awards .

for example , energy provides the prb with the organizational assessment , as well as guidance on how to use the assessment when reviewing ratings .

an energy official said that both rating officials and prbs consider the organization's performance when determining senior executives' ratings .

however , a treasury official told us that the prb for some bureaus within treasury does not have access to an organizational assessment when reviewing ratings .

the official said that tracking and reviewing organizational performance is done by the final rating official .

all five departments rated the majority of ses in the top two categories , indicating little differentiation between executives in their ratings .

as figure 5 shows , the five selected departments gave outstanding ratings to executives ranging from 30.6 percent in dod to 73.6 percent in doj .

in 2008 , we reported that senior executives for fiscal year 2007 were concentrated in the top two rating levels .

as figure 6 shows , at the three departments ( dod , energy , and treasury ) that we looked at in both fiscal years 2007 and 2013 , the proportions of ratings were nearly the same , although energy had switched from a four - rating system to a five - rating system during that time .

agency officials offered varied explanations for the high concentration of performance ratings at the top two rating levels , ranging from stating that the ratings are justified to stating that the ratings may be too high , but they are reinforced by an agency culture where executives may not view a rating of 3 as acknowledgement of a fully successful performance .

for example , human capital officials at doj pointed out that the individuals chosen for the ses are already high performers and continue to perform well as ses , earning high ratings .

an hhs human capital official , however , noted that competencies are written so that a rating level of 3 represents a fully successful performance , but it is difficult to convince executives who have traditionally received higher ratings that this rating reflects successful performance .

similarly , an energy official noted that the department communicates the message to rating officials ( both verbally and in writing ) that a “fully successful” rating is not average or ordinary ; it demonstrates a significant level of accomplishment .

one of the purposes of the new ses appraisal system is to help ensure standardized ratings with the understanding that a rating level of “outstanding” should always be a difficult goal to reach .

the departments had several layers of review , including both component - level and department - level review to ensure consistency across the department .

for example , in addition to the prbs , doj has an additional review level ( the senior executive resources board ) that analyzes the performance awards and attempts to identify trends and anomalies .

however , for fiscal year 2013 , four out of five selected departments awarded the same or higher performance awards as a percentage of base salary to ses with lower ratings as was awarded to those ses with higher ratings .

while opm has certified that the selected departments' appraisal systems make meaningful distinctions based on relative performance , actual awards at some departments do not seem to support that meaningful distinctions are being made .

figure 7 shows the range of performance awards given to eligible ses at the five selected departments for fiscal year 2013 .

prb representatives from the selected departments indicated that the variation in performance awards by ratings was caused by a number of different factors .

for example , a former prb chair said that in fiscal year 2012 , they had 9 different pay pools within certain dod non - combat entities ; each was given the latitude to determine how to distribute performance awards within the pay pool .

although the distribution of performance awards across ratings looked inconsistent when aggregated , no one with a lower rating received a larger award than anyone with a higher rating in the same pay pool .

a treasury prb representative said the range of performance awards is based on ratings as well as several other variables , such as relative contributions to the organization .

the treasury prb has the flexibility to review those factors when determining performance award amounts , and this sometimes results in an ses with a lower rating getting an equal ( or larger ) performance award as a percentage of salary than an ses with a higher rating .

the prb representative from doj said components were forced to prioritize ; when a large percentage of executives are outstanding and only 55 percent can receive a performance award , there are some difficult decisions .

doj also noted that different executives may get performance awards from year to year , based on their contributions to overall mission achievement .

one of the primary purposes for establishing the new ses appraisal system included increasing equity in ratings across agencies and their link to compensation .

the new system provides for the uniform administration of ses executive branch performance management systems by promoting consistency , clarity , and transferability of performance standards and ratings across agencies .

additionally , effective performance management systems recognize that merit - based pay increases should make meaningful distinctions in relative performance ; this principle is central to the ses performance management system , where under the law , to be certified and thereby able to access the higher levels of pay , the appraisal system must make meaningful distinctions based on relative performance .

opm's guidelines state that the modal rating should be below “outstanding” and that multiple rating levels should be used .

however , opm's guidelines also state that if an agency's modal rating level is “outstanding,” the appraisal system can still be certified if accompanied with a full , acceptable justification .

nonetheless , the continued concentration of senior executives at the top two rating levels indicates that this principle is not being met across government .

while making meaningful distinctions in ses performance continues to be a challenge for many agencies , some others have made progress .

for example , our 2008 report noted that according to a dod official , dod was communicating the message that the ses performance - based pay system recalibrates performance appraisals as a way to help change the culture and to make meaningful distinctions in performance , with a “fully successful” or equivalent rating as a high standard as well as a valued and quality rating .

according to dod , levels above “fully successful” require extraordinary results .

of the five selected departments that we examined in fiscal year 2013 , dod had the lowest percentage of senior executives receiving the highest rating — almost 31 percent .

according to opm officials , in 2015 opm plans to convene a cross - agency working group that is to revisit the ses certification process .

as part of this effort , it will be important for opm and the working group to consider whether — given the continued high ses performance ratings — the new system is contributing to making meaningful distinctions in performance ratings and awards , and if not , what refinements are needed .

the goal of having a uniform system would appear compromised if an “outstanding” rating in one agency does not have the same meaning in another agency .

some options might include revisiting and perhaps eliminating the guideline that allows opm to certify agencies' performance management systems with an ses modal rating of “outstanding,” so long as the agency provides acceptable justification .

this guideline could serve to work against encouraging agencies to make meaningful distinctions in ses performance .

alternatively , enhancing the transparency of opm's approval of agencies' justification for a modal rating of “outstanding” could shed light on whether the individual agency's high ratings seem justified .

these justifications are not on opm's website and opm does not report them to congress , nor does the chief human capital officers council review them for any consistency .

understandably , it could take more time for opm's 2012 efforts to standardize ses performance management to fully materialize .

however , data for fiscal year 2013 ( both government - wide as well as at our case study departments ) showed that a large majority of ses employees are still receiving one of the top two ratings .

coupled with evidence of overlap in performance awards across rating levels , this indicates that the link between performance ratings and awards is not being consistently applied .

by convening a cross - agency working group to review the ses certification process , opm is in a position to evaluate whether the new ses appraisal system actually helps agencies use ses compensation and performance awards in ways that are cost effective and lead to increased employee performance and organizational results .

if the performance definitions cannot be consistently applied across the government , creating a uniform framework to communicate expectations and evaluate the performance of ses members will be difficult to attain .

as opm convenes the cross - agency working group , we recommend that the director of opm , as the head of the agency that certifies — with omb concurrence — ses performance appraisal systems , consider the need for refinements to the performance certification guidelines addressing distinctions in performance and pay differentiation .

options could include revisiting and perhaps eliminating the guideline that allows opm to certify agencies' performance management systems with an ses modal rating of “outstanding,” or strengthening the accountability and transparency of this guideline by reporting agencies' justifications for high ratings to opm on its website .

reporting agencies' justifications for high ratings to congress .

obtaining third party input on agencies' justifications for high ratings , such as by the chief human capital officers council .

we provided a draft of this report to the director of opm and to the acting secretary of defense , the secretary of energy , the secretary of health and human services , the assistant attorney general for administration at the department of justice , and the secretary of the treasury for review and comment .

opm's comments are reprinted in appendix iv .

opm also provided technical comments , which we incorporated as appropriate .

dod , energy , doj , and treasury responded saying they did not have comments on the report .

hhs did not respond to our request for comments .

in its written comments , opm generally agreed with the information in the report but did not agree with our recommendation .

in disagreeing with our recommendation to consider not certifying agencies with modal ratings of “outstanding,” opm expressed concerns that imposing such a criterion would lead to arbitrary manipulation of the final ratings rather than an appropriate comparison of performance to standards .

opm asserted that this situation would be ripe for forced distribution of the ratings , which is explicitly prohibited by regulation .

opm also stated that the more appropriate action is to continue emphasizing the importance of setting appropriate , rigorous performance requirements and standards that logically support meaningful distinctions in performance .

as recognized in our report , opm's regulations contemplate that it is possible to apply standards that make meaningful performance distinctions and to use a range of ratings while avoiding the use of forced distributions .

as we also note , since our 2008 report on ses performance management systems — continuing through the career ses performance ratings for fiscal year 2013 — questions persist about the extent to which meaningful distinctions based on relative ses performance are being made .

although opm has emphasized that an “outstanding” rating represents a level of rare , high - quality performance , it appears from examining fiscal year 2013 ses ratings data that some agencies are not appropriately applying these performance standards to their ses ratings .

this undercuts one of the primary purposes for establishing the new ses appraisal system , which includes increasing equity in ratings across agencies and their link to compensation .

certifying agencies that are not adhering to the agreed - upon performance standards provides little incentive to those agencies that are adhering to the standards and could lead to ratings that are more skewed toward “outstanding.” as recently as 2008 , opm agreed on the importance of communicating to agencies the value of using a range of rating levels and transforming their cultures to those in which a “fully successful” rating is valued and rewarded .

opm also did not support the second part of our recommendation regarding three suggestions for increasing transparency for those agencies that are certified with a modal rating of “outstanding.” although we suggested that opm report high rating justifications to congress through its annual performance report , we understand that this may not be the most appropriate vehicle to use ; another avenue of reporting to congress would certainly be acceptable , and we have adjusted the text accordingly .

in addition , by suggesting that the chief human capital officers council have input on agencies' justifications for high ratings , we were in no way suggesting that this council role impact opm's ultimate authority over the regulation and oversight of the ses performance appraisal system ( including certification of agencies' systems ) .

we maintain , however , that — as an alternative action to more direct enforcement of the performance standards — transparency regarding opm's approval of justification for a modal rating of “outstanding” could shed light on whether the individual agency's high ratings seem justified .

given the recent data on ses performance ratings and awards , we remain concerned that meaningful distinctions in relative ses performance are not being made in a uniform fashion .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the secretaries of defense , energy , health and human services , and the treasury , to the assistant attorney general of administration at the department of justice , and to the director of the u.s. office of personnel management , as well as to the appropriate congressional committees and other interested parties .

in addition , this report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff members have any questions about this report , please contact me at ( 202 ) 512-6806 or goldenkoffr@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff members making key contributions to this report are listed in appendix v .

this report examines the distribution of performance awards to career senior executive service ( ses ) employees in executive branch agencies .

the objectives of this report were to ( 1 ) describe key characteristics of the awards , such as rating and awards distributions , award amounts , and percentage of executives receiving awards , from fiscal years 2010 through 2013 , and ( 2 ) describe and assess the extent to which selected departments' ses performance appraisal systems factored in organizational and individual performance and made meaningful distinctions in their fiscal year 2013 performance awards .

for an additional perspective , the second objective provides an in - depth view of five selected departments' ses ratings and performance awards' processes for the last fiscal year of ratings and award data .

for this report , we reviewed applicable legislation and regulations , as well as the office of personnel management ( opm ) and the office of management and budget ( omb ) guidance and government - wide reports , such as opm's annual reports for fiscal years 2010-2013 , report on senior executive pay and performance .

we also interviewed officials at opm and reviewed applicable reports from non - governmental organizations , such as the senior executive association .

we reviewed data from opm on agency performance rating levels , as well as the number and amount of ses performance awards .

we defined our universe of analysis as career senior executives who received ratings .

we also excluded ses employees ( where identifiable ) from agency inspector general offices because their inclusion in the data was inconsistent .

we reviewed opm's ses data for reasonableness and the presence of any obvious or potential errors in accuracy and completeness , and opm officials confirmed the correctness of the data .

on the basis of these procedures , we believe the data are sufficiently reliable for use in the analyses presented in this report .

to address our first objective , we reviewed data from opm on the amount of ses performance awards given to career ses within the 24 chief financial officers ( cfo ) act agencies and other variables since fiscal year 2010 ( the year prior to the limitation of performance award policies ) through fiscal year 2013 .

we analyzed aggregate ses basic pay and performance ratings as provided by opm for fiscal years 2010 through 2013 .

in calculating the percentage of eligible senior executives who received performance awards , we excluded executives who did not receive a performance rating .

to address the second objective , we selected five case study departments from the cfo act agencies based on several criteria .

using 2012 enterprise human resources integration data , we identified departments that had the largest number of ses employees and varying performance award distributions , including departments with both a large and small percent of ses employees who received an award , and we identified departments that had both a small and large range of award amounts , as both dollars and percent of salary .

selected case studies included the departments of defense ( dod ) , energy , health and human services ( hhs ) , justice ( doj ) , and treasury .

we reviewed these departments' ses performance appraisal systems and their most recent certification documentation submitted to opm .

we also examined whether individual ses performance metrics were linked to agency performance and whether performance awards were tied to outcomes by looking at examples of individual ses performance appraisals .

we did not verify the validity of the measures used or the performance of the senior executives .

we also interviewed agency officials from the selected departments with responsibility for their department's ses program as well as selected members or representatives of the performance review boards charged with ensuring consistency , stability , and objectivity in ses performance appraisals .

additionally , we analyzed opm data for each case study department to identify the percentage of ratings distributed across each rating category in fiscal year 2013 .

we compared results of three of the case study departments that were also reviewed in 2007 , using data from a previous report .

we also analyzed the data to determine the amount of performance awards — as a percentage of salary — given to ses employees for each performance rating level .

we conducted this performance audit from june 2014 to december 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

opm report on the ( agency name ) senior executive service ( ses ) performance appraisal system certification date of report: mm / dd / yyyy opm ( enter decision here ) certification of the ( agency name ) ses performance appraisal system .

the table below indicates the certification criteria fully met , minimally met , or not met during opm's review of the system .

description of “meets” criteria the agency is using the basic ses appraisal system description and it has been approved by opm .

 ( this means the system includes all the required system language , and the performance plans include all the required language for consultation , employee perspective , customer perspective , and accountability. ) .

all performance plans include specific organizational goals in the strategic alignment cell for each performance requirement under the results driven element in part 5 of the appraisal form .

each performance requirement under the results driven element for each performance plan contains adequate measurable results .

if the agency also includes a list of activities in the plans , the plan clearly identifies the measurable result ( s ) and denotes that it is the results that are to be rated for the results driven element .

description of “meets” criteria the agency has provided a copy of its memo issuing guidelines to executives , rating officials and prb members that includes the results of the organizational assessment , and guidelines for how to use the results when determining ratings , pay , and awards ; or , for small agencies , a description for how the guidelines and results of the organizational assessment were given to rating officials and prb members and the content of the guidelines ( eg , if communicated by email , a copy of the email is included ) .

the agency has provided a description of training or communications given that should include a briefing on the agency's ses performance management system , or the agency provides evidence it has conducted the training , but cannot verify how many executives attended the training , or the system has not yet been implemented and the agency provides training plans ; and communication of the average rating , pay , and awards given the previous year .

the ses rating distribution indicates the agency is clearly making distinctions in performance ( i.e .

the modal rating is below “outstanding” ) and the distribution appears to reflect organizational performance as explained by the agency , or , the modal rating is “outstanding” but the agency gave a full , acceptable justification ; and the percent of ses members not rated is less than 5 percent .

differentiation in pay based on performance a ) the agency's correlation coefficient of the rating and performance compensation ( that is , pay adjustments and awards ) is 0.500 or more , or the pay and awards data show the agency makes distinctions in pay b ) and the average performance compensation is higher for executives rated outstanding than for those rated exceeds , and exceeds is higher than fully successful ; c ) and the data does not include any violations of pay and awards limits .

description of “meets” criteria pay policy the agency provides a written , official pay policy and the policy describes clear differentiations in performance compensation ( that is , pay adjustments and awards ) based on the annual summary rating .

office of personnel management ( opm ) , small business administration ( sba ) , and social security administration ( ssa ) .

robert goldenkoff , ( 202 ) 512-6806 or goldenkoffr@gao.gov .

in addition to the contact named above , thomas gilbert , assistant director , and judith kordahl , analyst - in - charge , supervised the development of this report .

charles culverwell and mary diop made significant contributions to all aspects of this report .

other important contributors included sara daleski , karin fangman , donna miller , and rebecca shea .

