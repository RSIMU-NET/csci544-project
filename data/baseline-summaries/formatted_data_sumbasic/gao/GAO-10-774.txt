for years , gao has reported on significant cost overruns on the department of defense's ( dod ) major weapon system acquisition programs .

even though dod has incorporated previous legislative provisions into its acquisition policies , such as requiring weapon programs to use mature technologies from the start of development , programs are still experiencing cost and schedule problems .

the senate armed services committee reported that since the beginning of 2006 , nearly half of dod's largest acquisition programs have exceeded nunn - mccurdy cost - growth standards established by congress .

dod is now faced with making tough decisions about the viability of some of its weapon system programs .

in 2009 , for example , the secretary of defense proposed canceling or significantly curtailing weapon programs with a projected cost of at least $126 billion .

cost and schedule overruns can be attributed to a number of factors that occur early in an acquisition , including poorly analyzed requirements , design instability , and inadequate systems engineering and testing .

in may 2009 , congress passed the weapon systems acquisition reform act of 2009 ( reform act ) , aimed at improving dod's organization and procedures for the acquisition of major weapon systems .

this legislation places more emphasis on activities that should occur early in weapon systems development , including those related to systems engineering and developmental testing , in order to help establish a solid program foundation from the start of development .

the senate armed services committee asked us to examine ( 1 ) dod's progress in implementing systems engineering and developmental testing requirements called for in the reform act , ( 2 ) views on the alignment of the offices of the director of systems engineering and the director of developmental test and evaluation within the office of the secretary of defense , and ( 3 ) challenges in strengthening systems engineering and developmental testing activities .

in conducting our work , we interviewed officials and collected documents from the offices of the director of systems engineering and the director of developmental test and evaluation in order to learn the status of their efforts to implement the reform act legislation and challenges they are addressing .

we also interviewed officials from various offices within the office of the under secretary of defense for acquisition , technology and logistics ( at&l ) ; the office of the director , operational test and evaluation ; each of the military services ; the defense science board ; as well as former dod systems engineering and developmental testing executives to obtain their opinions on the alignment of the two offices within the office of the secretary of defense and potential challenges .

we conducted this performance audit from december 2009 to july 2010 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

systems engineering and test and evaluation are critical parts of the weapon system acquisition process and how well these activities are conducted early in the acquisition cycle can greatly affect program outcomes .

systems engineering translates customer needs into specific product requirements for which requisite technological , software , engineering , and production capabilities can be identified through requirements analysis , design , and testing .

early systems engineering provides the knowledge that weapon system requirements are achievable with available resources such as technologies , time , people , and money .

it allows a product developer to identify and resolve performance and resource gaps before product development begins by reducing requirements , deferring them to the future , or increasing the estimated cost for the weapon system's development .

systems engineering plays a fundamental role in the establishment of the business case for a weapon acquisition program by providing information to dod officials to make tradeoffs between requirements and resources .

systems engineering is then applied throughout the acquisition process to manage the engineering and technical risk in designing , developing , and producing a weapon system .

the systems engineering processes should be applied prior to the start of a new weapon acquisition program and then continuously throughout the life - cycle .

test and evaluation provides information about the capabilities of a weapon system and can assist in managing program risk .

there are generally two broad categories of testing: developmental and operational .

developmental testing is used to verify the status of technical progress , substantiate achievement of contract technical performance , and certify readiness for initial operational testing .

early developmental testing reduces program risks by evaluating performance at progressively higher component and subsystem levels , thus allowing program officials to identify problems early in the acquisition process .

developmental testing officials in the office of the secretary of defense and the military services provide guidance and assistance to program managers on how to develop sound test plans .

the amount of developmental testing actually conducted however , is controlled by the program manager and the testing requirements explicitly specified in the development contract .

in contrast , operational testing determines if a weapon system provides operationally useful capability to the warfighter .

it involves field testing a weapon system , under realistic conditions , to determine the effectiveness and suitability of the weapon for use in combat by military users , and the evaluation of the results of such tests .

dod's director of operational test and evaluation conducts independent assessments of programs and reports the results to the secretary of defense and congress .

in 2008 , the defense science board reported that operational testing over the previous 10 years showed that there had been a dramatic increase in the number of weapon systems that did not meet their suitability requirements .

the board found that failure rates were caused by several factors , notably the lack of a disciplined systems engineering process early in development and a robust reliability growth program .

the board also found that weaknesses in developmental testing , acquisition workforce reductions and retirements , limited government oversight , increased complexity of emerging weapon systems , and increased reliance on commercial standards ( in lieu of military specifications and standards ) all contributed to these failure rates .

for example , over the last 15 years , all service acquisition and test organizations experienced significant personnel cuts , including the loss of a large number of the most experienced technical and management personnel , including subject matter experts , without an adequate replacement pipeline .

the services now rely heavily on contractors to help support these activities .

over the past two decades , the prominence of the developmental testing and systems engineering communities within the office of the secretary of defense has continuously evolved , as the following examples illustrate .

in 1992 , a systems engineering directorate did not exist and the developmental test function was part of the office of the director of test and evaluation , which reported directly to the under secretary of defense for acquisition .

at that time , the director had direct access to the under secretary on an array of issues related to test policy , test assets , and the workforce .

in 1994 , the development test , systems engineering and evaluation office was formed .

this organization effectively expanded the responsibilities of the former testing organization to formally include systems engineering .

the organization had two deputy directors: the deputy director , development test and evaluation , and the deputy director , systems engineering .

this organization was dissolved in 1999 .

from 1999 to 2006 , systems engineering and developmental testing responsibilities were aligned under a variety of offices .

the responsibility for managing test ranges and resources , for example , was transferred to the director of operational test and evaluation .

this function was later moved to the test resource management center , which reports directly to at&l , where it remains today .

in 2004 , a director of systems engineering was re - established and then in 2006 this became the system and software engineering directorate .

developmental testing activities were part of this directorate's responsibilities .

as a result , systems engineering and developmental testing issues were reported indirectly to at&l through the deputy under secretary for acquisition and technology .

congress passed the weapon systems acquisition reform act of 2009 ( reform act ) — the latest in a series of congressional actions taken to strengthen the defense acquisition system .

the reform act establishes a director of systems engineering and a director of developmental test and evaluation within the office of the secretary of defense and defines the responsibilities of both offices .

the reform act requires the services to develop , implement , and report on their plans for ensuring that systems engineering and developmental testing functions are adequately staffed to meet the reform act requirements .

in addition , it requires the directors to report to congress on march 31 of each year on military service and major defense acquisition program systems engineering and developmental testing activities from the previous year .

for example , the report is to include a discussion of the extent to which major defense acquisition programs are fulfilling the objectives of their systems engineering and developmental test and evaluation master plans , as well as provide an assessment of the department's organization and capabilities to perform these activities .

figure 1 shows some of the major reorganizations over the past two decades , including the most recent change where dod decided to place the two new directors' offices under the director of defense research and engineering .

dod has made progress in implementing the systems engineering and developmental test and evaluation provisions of the reform act , but has not yet developed performance criteria that would help assess the effectiveness of the changes .

some requirements , such as the establishment of the two new offices , have been fully implemented .

the implementation of other requirements , such as the review and approval of systems engineering and developmental test and evaluation plans , has begun but requires sustained efforts .

the department has not fully implemented other requirements .

for example , dod has begun development of joint guidance that will identify measurable performance criteria to be included in the systems engineering and developmental testing plans .

dod initially decided that one discretionary provision of the act — naming the director of developmental test and evaluation also as the director of the test resource management center — would not be implemented .

however , the director of defense research and engineering is currently examining the implications of this organizational change .

it will be several years before the full impact of the reform act provisions is known .

the offices of the director of systems engineering and developmental test and evaluation were officially established by the under secretary of defense for at&l in june 2009 to be his principal advisors on systems engineering and developmental testing matters .

the directors took office 3 months and 9 months later , respectively , and are working on obtaining the funding , workforce , and office space needed to accomplish their responsibilities .

the directors have also completed evaluations of the military services' organizations and capabilities for conducting systems engineering and developmental testing , and identified areas for improvement .

these evaluations were based on reports provided by the services that were also required by the reform act .

as shown in table 1 , many of the requirements that have been implemented will require ongoing efforts .

the directors have the responsibility for reviewing and approving systems engineering and developmental test and evaluation plans as well as the ongoing responsibility to monitor the systems engineering and developmental test and evaluation activities of major defense acquisition programs .

during fiscal year 2009 , the director of systems engineering reviewed 22 systems engineering plans and approved 16 , while the director of developmental test and evaluation reviewed and approved 25 developmental test and evaluation plans within the test and evaluation master plans .

both offices are monitoring and reviewing activities on a number of major acquisition programs , including the virginia class submarine , the stryker family of vehicles , and the c - 130 avionics modernization program .

once their offices are fully staffed , the directors plan to increase efforts in reviewing and approving applicable planning documents and monitoring the activities of about 200 major defense acquisition and information system programs .

evaluations of 42 weapon systems were included in the directors' first annual joint report to congress .

the individual systems engineering program assessments were consistent in that they typically included information on 10 areas , including requirements , critical technologies , technical risks , reliability , integration , and manufacturing .

in some cases , the assessments also included an overall evaluation of whether the program was low , medium , or high risk ; the reasons why ; and a general discussion of recommendations or efforts the director has made to help program officials reduce any identified risk .

examples include the following .

in an operational test readiness assessment of the ea - 18g aircraft , the director of systems engineering found multiple moderate - level risks related to software , communications , and mission planning and made recommendations to reduce the risks .

the program acted on the risks and recommendations identified in the assessment and delayed the start of initial operational testing by 6 weeks to implement the fixes .

it has completed initial operational testing and was found to be effective and suitable by navy testers .

the director of operational test and evaluation rated the system effective but not suitable , and stated that follow - on testing has been scheduled to verify correction of noted deficiencies .

the program received approval to enter full rate production and is rated as a low risk in the joint annual report .

the systems engineering assessment of the global hawk program was high risk pending the determination of actual system capability ; it also stated that there is a high probability that the system will fail operational testing .

the assessment cited numerous issues , including questions regarding the system's ability to meet mission reliability requirements , poor system availability , and the impact of simultaneous weapon system block builds ( concurrency ) .

despite the director's concerns and efforts to help the program office develop a reliability growth plan for global hawk , no program funding has been allocated to support reliability improvements .

the expeditionary fighting vehicle assessment did not include an overall evaluation of risk .

the assessment noted that the program was on track to meet the reliability key performance parameter of 43.5 hours mean time between operational mission failure .

problems related to meeting this and other reliability requirements were a primary reason why the program was restructured in 2007 .

however , the assessment did not address the high degree of concurrency between development and production , which will result in a commitment to fund 96 low - rate initial procurement vehicles prior to demonstrating that the vehicle can meet the reliability threshold value at initial operational test and evaluation , currently scheduled for completion by september 2016 .

developmental testing assessments covered fewer programs and were not as structured as those provided by the systems engineering office in that there were no standard categories of information that were included in each assessment .

part of the reason is that the director of the developmental test and evaluation office was just developing the necessary expertise to review and provide formal assessments of programs .

for the programs that were reviewed , the assessments included a status of developmental testing activities on programs and in some cases an assessment of whether the program was low , medium , or high risk .

for example , the director of developmental test and evaluation supported an assessment of operational test readiness for the c - 5 reliability enhancement and reengining program .

the assessment stated that due to incomplete testing and technical issues found in developmental testing , there is a high risk of failure in operational testing .

the assessment recommended that the program resolve these issues before beginning operational testing .

the reform act also requires that the director of systems engineering develop policies and guidance on , among other things , the use of systems engineering principles and best practices and the director of developmental test and evaluation develop policies and guidance on , among other things , the conduct of developmental testing within dod .

the directors have issued some additional policies to date , such as expanded guidance on addressing reliability and availability on weapon programs and on incorporating test requirements in acquisition contracts .

the directors plan to update current guidance and issue additional guidance in the future .

according to dod officials , there are over 25 existing documents that provide policy and guidance for systems engineering and developmental testing .

the directors also have an ongoing responsibility to advocate for and support their respective dod acquisition workforce career fields , and have begun examining the training and education needs of these workforces .

two provisions , one of which is discretionary , have not been completed .

the reform act requires that the directors , in coordination with the newly established office of the director for program assessments and root cause analysis , issue joint guidance on the development of detailed , measurable performance criteria that major acquisition programs should include in their systems engineering and testing plans .

the performance criteria would be used to track and measure the achievement of specific performance objectives for these programs , giving decision makers a clearer understanding each program's performance and progress .

the offices have begun efforts to develop these policies and guidance , but specific completion dates have not been identified .

at this time , it is unclear whether the guidance will include specific performance criteria that should be consistently tracked on programs and any risks associated with these programs , such as ones related to technology maturity , design stability , manufacturing readiness , concurrency of development and production activities , prototyping , and adequacy of program resources .

finally , the reform act gives dod the option of permitting the director of developmental test and evaluation to serve as the director of the test resource management center .

dod initially decided not to exercise this option .

however , the director of defense research and engineering recently stated that his organization is examining the possibility of consolidating the offices .

the director stated that it makes sense to combine the two offices because it would merge test oversight and test resource responsibilities under one organization , but the ultimate decision will be based on whether there are any legal obstacles to combining the two offices .

while most of the reform act's requirements focus on activities within the office of the secretary of defense , the military services are ultimately responsible for ensuring that their weapon systems start off with strong foundations .

to that end , in november 2009 , the services , in reports to the directors of systems engineering and developmental test and evaluation , identified plans for ensuring that appropriate resources are available for conducting systems engineering and developmental testing activities .

the individual reports also highlighted management initiatives undertaken to strengthen early weapon acquisition activities .

for example , the army is establishing a center at aberdeen proving ground that will focus on improving reliability growth guidance , standards , methods , and training for army acquisition programs .

the navy has developed criteria , including major milestone reviews and other gate reviews , to assess the “health” of testing and evaluation at various points in the acquisition process .

the air force has undertaken an initiative to strengthen requirements setting , systems engineering , and developmental testing activities prior to the start of a new acquisition program .

air force officials believe this particular initiative will meet the development planning requirements of the reform act .

experts provided different viewpoints on the proper placement of the new systems engineering and developmental test and evaluation offices , with some expressing concern that as currently placed , the offices will wield little more power or influence than they had prior to the passage of the reform act .

according to the director of defense research and engineering , the under secretary of defense for at&l placed the new offices under his organization because the department wanted to put additional emphasis on systems engineering and developmental testing prior to the start of a weapons acquisition program .

the director believes this is already occurring and that both offices will continue to have a strong relationship with acquisition programs even though they do not report directly to an organization with significant involvement with major defense acquisition programs .

however , many current and former dod systems engineering and developmental testing officials we spoke with believe the offices should be closely linked to weapon acquisition programs because most of their activities are related to those programs .

similarly , the defense science board recommended that a developmental testing office be established and report directly to an organization that has significant involvement with major defense acquisition programs .

in addition , officials we spoke with believe several other significant challenges , including those related to staffing and the culture of the defense research and engineering organization , are already negatively affecting the offices' effectiveness .

dod has not established any performance criteria that would help gauge the success of the new directors' offices , making it difficult to determine if the offices are properly aligned within the department or if the reform act is having an impact on program outcomes .

after the passage of the reform act , dod considered several options on where to place the new offices of the director of systems engineering and director of developmental test and evaluation .

according to an official who helped evaluate potential alternatives , dod could have aligned the offices under at&l in several different ways ( see fig .

2 ) .

for example , the offices could have reported directly to the under secretary of at&l or indirectly to the under secretary of at&l either through the assistant secretary of defense ( acquisition ) or the director of defense research and engineering .

dod decided to place the offices under the director of defense research and engineering , an organization that previously primarily focused on science and technology issues .

under secretary of defense for acquisition , technology & logistics ( usd at&l ) .

the director of defense research and engineering is aware of the challenges of placing the offices under an organization whose primary mission is to develop and transition technologies to acquisition programs , but believes that the current placement makes sense given congressional and dod desires to place more emphasis on activities prior to the start of a new acquisition program .

he stated that the addition of systems engineering and developmental testing not only stretches the role and mission of his organization , but also strengthens the organization's role in acquisitions because it helps give the organization's research staff another point of view in thinking about future technologies and systems .

he plans for the offices to perform both assessment and advisory activities , including: providing risk assessments of acquisition programs for the defense acquisition board , continuing to help programs succeed by providing technical insight and assisting the programs in the development of the systems engineering plan and the test and evaluation master plan , and educating and assisting researchers to think through new concepts or technologies using systems engineering to inform fielding and transition strategies .

according to the director of defense research and engineering , the offices are already performing some of these functions .

for example , the new directors have provided technical input to the defense acquisition board on various weapons programs .

the director stated the systems engineering organization is reviewing manufacturing processes and contractor manufacturing readiness for weapons programs such as the joint strike fighter .

in addition , a developmental testing official stated they are assisting the director of defense research and engineering research directorate in conducting technology readiness assessments and helping programs identify the trade spaces for testing requirements while reviewing the test and evaluation master plan .

the director believes the value of having the offices perform both assessment and advisory activities is that they can look across the acquisition organization and identify programs that are succeeding from a cost , schedule , and performance perspective and identify common threads or trends that enable a program to succeed .

conversely , they could identify common factors that make programs fail .

the director of defense research and engineering identified three challenges that he is trying to address in order for systems engineering and developmental testing to have a more positive influence on weapon system outcomes .

first , the director would like to improve the technical depth of the systems engineering and developmental testing offices .

both functions have atrophied over the years and need to be revitalized .

this will require the offices to find highly qualified people to fill the positions , which will not be easy .

second , the director wants to improve the way the defense research and engineering organization engages with other dod organizations that are involved in weapon system acquisition .

the director noted that there are a lot of players and processes involved in weapon acquisition and that the systems engineering office can play a large role in facilitating greater interaction .

third , the director would like the defense research and engineering organization to find better ways to shape , engage with , contract with , and get information from the defense industrial base .

in addition to the three challenges , it will also be difficult to determine whether the two new offices are having a positive impact on weapon system outcomes .

the directors of systems engineering and developmental test and evaluation are not reporting the number of recommendations implemented by program managers or the impact the recommendations have had on weapon programs , which would allow senior leaders to gauge the success of the two offices .

this type of information could help the under secretary of at&l determine if the offices need to be placed under a different organization , if the offices need to place more emphasis on advisory or assessment activities , and if the reform act is having an impact on program outcomes .

the vast majority of current and former dod systems engineering and test officials we spoke with were opposed to the placement of the offices under the director of defense research and engineering .

their chief concern is that the mission of the director of defense research and engineering organization is primarily focused on developing new technologies and transitioning those technologies to acquisition programs .

while they recognize that the systems engineering and developmental testing offices need to be involved in activities prior to the official start of a new weapons program , they believe the offices' expertise should be focused on helping dod acquisition programs establish doable requirements given the current state of technologies , not on the technologies themselves .

therefore , they believe the offices would be more appropriately placed under the newly established offices of the principal deputy under secretary of defense for at&l or the assistant secretary of defense for acquisition , whose missions are more closely aligned with acquisition programs .

some officials we spoke with believe that a cultural change involving the focus and emphasis of the office of the director of defense research and engineering will have to take place in order for that organization to fully support its role in overseeing acquisition programs and improving the prominence of the two new offices within the department .

however , these same officials believe that this cultural change is not likely to occur and that the director of defense research and engineering will continue to focus primarily on developing and transitioning new technologies to weapon programs .

therefore , the offices may not get sufficient support and resources or have the clout within dod to effect change .

one former systems engineering official pointed out that the historic association of systems engineering with the director of defense research and engineering does not bode well for the systems engineering office .

based upon his experience , the director of defense research and engineering's focus and priorities resulted in a fundamental change in philosophy for the systems engineering mission , the virtual elimination of a comprehensive focus on program oversight or independent identification of technical risk , and a reduction in systems engineering resources .

in short , he found that the director of defense research and engineering consistently focused on science and technology , in accordance with the organization's charter , with systems engineering being an afterthought .

likewise , current and former developmental testing officials are concerned about the director of defense research and engineering's support for developmental testing activities .

they identified several staffing issues that they believe are key indicators of a lack of support .

first , they pointed out that it took almost 9 months from the time the director of developmental test and evaluation office was established before a new director was in place compared to 3 months to place the director of systems engineering .

if developmental testing was a priority , officials believe that the director of defense research and engineering should have filled the position earlier .

second , test officials believe the director of developmental test and evaluation office needs to have about the same number of staff as the offices of the director of systems engineering and the director of operational test and evaluation .

according to officials , dod currently plans to have about 70 people involved with developmental testing activities , 180 people for systems engineering , and 250 for operational testing .

however , testing officials believe the offices should be roughly the same size given the fact that developmental testing will cover the same number of programs as systems engineering and operational testing and that roughly 80 percent of all testing activities are related to developmental tests , with the remaining 20 percent being for operational tests .

third , even though the director of developmental test and evaluation expects the office to grow to about 70 people by the end of fiscal year 2011 , currently there are 30 people on board .

the director believes there are a sufficient number of qualified people seeking positions and therefore the office could be ramped up more quickly .

finally , the director of developmental test and evaluation stated that his office has only one senior - level executive currently on staff who reports to him and that there are no plans to hire more for the 70-person organization .

the director believes it is crucial that the organization have more senior - level officials because of the clout they carry in the department .

the director believes that the lack of an adequate number of senior executives in the office weakens its ability to work effectively with or influence decisions made by other dod organizations .

further , officials from other testing organizations , as well as the systems engineering office , indicated they have two or more senior executive - level employees .

a may 2008 defense science board report , which was focused on how dod could rebuild its developmental testing activities , recommended that developmental testing be an independent office that reports directly to the deputy under secretary of defense ( acquisition and technology ) .

at that time , according to the report , there was no office within the office of the secretary of defense with comprehensive developmental testing oversight responsibility , authority , or staff to coordinate with operational testing .

in addition , the existing residual organizations lacked the clout to provide development test guidance and developmental testing was not considered to be a key element in at&l system acquisition oversight .

according to the study director , placing the developmental testing office under the director of defense research and engineering does not adequately position the new office to perform the oversight of acquisition programs .

the military services , the directors of systems engineering and developmental test and evaluation , and we have identified a number of workforce and resource challenges that the military services will need to address to strengthen their systems engineering and developmental testing activities .

for example , it is unclear whether the services have enough people to perform both systems engineering and developmental testing activities .

even though the services reported to the directors that they have enough people , they do not have accurate information on the number of people performing these activities .

the director of developmental test and evaluation disagreed with the services' assertions , but did not know how many additional people are needed .

service officials have also expressed concern about the department's ability to train individuals who do not meet requisite certification requirements on a timely basis and being able to obtain additional resources to improve test facilities .

the military services were required by the reform act to report on their plans to ensure that they have an adequate number of trained systems engineering and developmental testing personnel and to identify additional authorities or resources needed to attract , develop , train , and reward their staff .

in november 2009 , the military services submitted their reports to the respective directors within the office of the secretary of defense on their findings .

in general , the services concluded that even with some recruiting and retention challenges , they have an adequate number of personnel to conduct both systems engineering and developmental testing activities ( see table 2 below ) .

according to service officials , this determination was based on the fact that no program offices identified a need for additional staffing to complete these activities .

the reports also stated the services generally have sufficient authorities to attract and retain their workforce .

in dod's first annual joint report to congress , the director of developmental test and evaluation did not agree with the military services' assertion that they have enough staff to perform the full range of developmental testing activities .

the director does not know how many more personnel are needed , but indicated that the office plans to work with the services to identify additional workforce needs .

the director of systems engineering agreed with the services' reports that they have adequate staffing to support systems engineering activities required by current policy .

according to the director , this was based on the 35,000 current personnel identified in the system planning , research development , and engineering workforce — a generic workforce category that includes systems engineering activities — as well as the services' plans to hire over 2,500 additional personnel into this same workforce category over the next several years .

although not clearly articulated in the services' reports , military service officials acknowledged that the personnel data in their reports may not be entirely accurate .

for example , officials believe the systems engineering numbers identified in table 2 overstate the number of people actually performing systems engineering activities because that particular career field classification is a generic category that includes all types of engineers .

the developmental test workforce shown in the table does not completely reflect the number of people who actually perform developmental testing activities because the information provided by the military services only identifies the personnel identified in the test and evaluation career field .

service officials told us that there are many other people performing these activities who are identified in other career fields .

the director of developmental test and evaluation believes these other people may not be properly certified and that in the case of contractors , they do not possess certifications which are equivalent to the certification requirements of government personnel .

this director plans to request another report from the services in fiscal year 2010 .

this report will address the overall workforce data ; it will cover current staffing assigned to early test and evaluation activities , training , and certification concerns they have related to in - sourcing staff , rapid acquisition resource plans , and infrastructure needs for emerging technologies .

the director of systems engineering does not intend to request another report from the services .

nevertheless , each of the military services plans to increase its systems engineering workforce over the next several years .

the exact number of personnel is uncertain because the services' hiring projections relate to a general engineering personnel classification , not a specific systems engineering career field .

the directors also identified challenges they believe the services will face in strengthening systems engineering and developmental testing activities .

the director of systems engineering pointed out that the services need to put greater emphasis on development planning activities , as called for by the reform act .

the services are currently conducting these activities to some extent , but the director believes a more robust and consistent approach is needed .

the director of developmental test and evaluation highlighted two other challenges facing the military services .

first , the director would like to increase the number of government employees performing test and evaluation activities .

the services experienced significant personnel cuts in these areas in the mid - 1990s and has to rely on contractors to perform the work .

dod's joint report to congress noted that the air force in particular relies heavily on prime contractor evaluations and that this approach could lead to test results that are inaccurate , misleading , or not qualified , resulting in turn , in premature fielding decisions since prime contractors would not be giving impartial evaluations of results .

the director believes there are a number of inherently governmental test and evaluation functions that produce a more impartial evaluation of results and that a desired end state would be one where there is an appropriate amount of government and contractor testing .

second , the director is concerned that dod does not have the capacity to train and certify an estimated 800 individuals expected to be converted from contractor to government employees within the required time frame .

while most of the contractors are expected to have some level of training and experience performing test activities , they probably will not meet certifications required of government employees because they have not had the same access to dod training .

in addition to those challenges recognized by the directors , we have identified other challenges we believe the services may face in implementing more robust systems engineering and developmental testing , including the following .

according to the military services , they plan to meet hiring targets primarily through the conversion of contractors who are already performing those activities , but do not have plans in place to ensure that they have the right mixture of staff and expertise both now and in the future .

dod officials acknowledge that they do not know the demographics of the contractor workforce .

however , they believe many contractors are often retired military with prior systems engineering experience .

therefore , while they may be able to meet short - term needs , there could be a challenge in meeting long - term workforce needs .

army test officials indicated that they have experienced a significant increase in their developmental testing workload since the terrorist attacks of september 2001 , with no corresponding increase in staffing .

as a result , personnel at their test ranges are working longer hours and extra shifts , which testing officials are concerned may affect their retention rates .

army officials also indicated that test ranges are deteriorating more quickly than expected and they may not have the appropriate funding to upgrade and repair the facilities and instrumentation .

test personnel are often operating in obsolete and outdated facilities that cannot meet test requirements , resulting in safety issues , potential damage to equipment , and degraded quality of life .

dod's increased emphasis on fielding rapid acquisition systems may require the services to tailor their approach to systems engineering .

according to an air force official , efforts that normally take months to complete for a more traditional acquisition program , have to be completed in a matter of weeks for rapid acquisition programs .

dod efforts to implement reform act requirements are progressing , but it will take some time before the results of these efforts can be evaluated .

current and former systems engineering and developmental testing officials offer compelling insights concerning the placement of the new directors' offices under the office of the director of defense research and engineering , but it is still too soon to judge how effective the offices will be at influencing outcomes on acquisition programs .

the current placement of the offices may present several challenges that could hinder their ability to effectively oversee weapon system acquisition programs and ensure that risks are identified , discussed , and addressed prior to the start of a new program or the start of operational testing .

foremost among these potential challenges is the ability of the director of defense research and engineering to change the focus of the organization to effectively assimilate the roles and missions of the two new offices and then ensure that the offices are properly staffed and have the appropriate number of senior leaders .

the mission of the office of the director of defense research and engineering has been to develop technology for weapon programs ; its focus has not been to manage the technical aspects of weapon system acquisition programs .

ultimately , the real proof of whether an organization outside of the major defense acquisition program arena can influence acquisition program decisions and outcomes should be based on results .

the directors' offices have started to assess and report on the systems engineering and developmental testing activities on some of the major defense acquisition programs .

they have also made recommendations and worked with program officials to help reduce risks on programs such as the ea - 18g , global hawk , and the c - 5 reliability enhancement and reengining programs .

however , guidance on the development and tracking of performance criteria that would provide an indication of how much risk is associated with a particular weapon system — such as those related to technology maturity , design stability , manufacturing readiness , concurrency of development and production activities , prototyping , and adequacy of program resources — has yet to be developed .

further , the directors are not reporting to congress on the extent to which programs are implementing recommendations and the impact recommendations are having on weapon programs , which would provide some insight as to the impact the two offices are having on acquisition programs .

although not required by the reform act , this type of information could be useful for congress to gauge the effectiveness of the directors' offices .

the military services , which face increasing demands to develop and field more reliable weapon systems in shorter time frames , may need additional resources and training to ensure that adequate developmental testing and systems engineering activities are taking place .

however , dod's first joint annual report to congress , which was supposed to assess the department's organization and capabilities for performing systems engineering and developmental testing activities , did not clearly identify the workforce performing these activities , future workforce needs , or specific hiring plans .

in addition , dod's strategy to provide the necessary training within the required time period to the large number of staff it plans to hire is unclear .

therefore , workforce and training gaps are unknown .

in order to determine the effectiveness of the newly established offices , we recommend that the secretary of defense direct the directors of systems engineering and developmental test and evaluation to take the following five actions: ensure development and implementation of performance criteria for systems engineering plans and developmental test and evaluation master plans , such as those related to technology maturity , design stability , manufacturing readiness , concurrency of development and production activities , prototyping , and the adequacy of program resources .

track the extent to which program offices are adopting systems engineering and developmental testing recommendations .

work with the services to determine the appropriate number of government personnel needed to perform the scope of systems engineering and developmental testing activities .

develop plans for addressing the training needs of the new hires and contractors who are expected to be converted to government personnel .

report to congress on the status of these efforts in future joint annual reports required by the reform act .

dod provided us with written comments on a draft of this report .

dod concurred with each of the recommendations , as revised in response to agency comments .

dod's comments appear in appendix i .

based upon a discussion with dod officials during the agency comment period , we revised the first recommendation .

specifically , instead of recommending that the directors of systems engineering and developmental test and evaluation develop a comprehensive set of performance criteria that would help assess program risk , as stated in the draft report , we now recommend that the directors ensure the development and implementation of performance criteria for systems engineering plans and developmental test and evaluation master plans .

the wording change clarifies the nature and scope of performance criteria covered by our recommendation and is consistent with reform act language that requires the directors to develop guidance on the development of detailed , measurable performance criteria that major acquisition programs should include in their systems engineering and developmental testing plans .

according to dod officials , the military services are then responsible for developing the specific criteria that would be used on their respective programs .

dod also provided technical comments , which we incorporated as appropriate .

we are sending copies of this report to the secretary of defense , the director of the office of management and budget , and interested congressional committees .

we will also make copies available at no charge on the gao web site at http: / / www.gao.gov .

if you have any questions about this report or need additional information , please contact me at ( 202 ) 512-4841 or sullivanm@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report were bruce thomas , assistant director ; cheryl andrew ; rae ann sapp ; megan hill ; and kristine hassinger .

