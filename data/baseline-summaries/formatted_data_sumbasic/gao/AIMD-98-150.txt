this report presents the results of our review of the navy's program for addressing its year 2000 computer systems problem .

the problem results from the inability of computer systems at the year 2000 to interpret the century correctly from a recorded or calculated date having only two digits to indicate the year .

time is running out to correct navy systems that could malfunction or produce incorrect information when the year 2000 is encountered during automated data processing .

the impact of these failures could be widespread , costly , and potentially debilitating to important navy operations worldwide .

we performed this work as part of our review of the department of defense's ( dod ) year 2000 computer systems efforts for the chairman , senate committee on governmental affairs ; the chairman and ranking minority member of the subcommittee on government management , information and technology , house committee on government reform and oversight ; and the honorable thomas m. davis , iii , house of representatives .

during the review , we assessed ( 1 ) the status of the navy's efforts to oversee its year 2000 program and ( 2 ) the appropriateness of the navy's strategy and actions for ensuring that the problem will be successfully addressed .

this letter summarizes our concerns and provides recommendations for addressing them .

our objectives were to assess ( 1 ) the status of navy's effort to identify and correct its year 2000 problem and ( 2 ) the appropriateness of the navy's strategy and actions for remediating year 2000 problems .

in conducting our review , we used our year 2000 assessment guide to assess the navy's year 2000 efforts .

this guide addresses common issues affecting most federal agencies and presents a structured approach and provides a checklist to aid in planning , managing , and evaluating year 2000 programs .

the guidance , which is consistent with defense's year 2000 management plan and the navy's own year 2000 management approach , describes five phases — supported by program and project management activities — with each phase representing a major year 2000 program activity or segment .

the phases and a description of each follows .

awareness - define the year 2000 problem and gain executive - level support and sponsorship .

establish a year 2000 program team and develop an overall strategy .

ensure that everyone in the organization is fully aware of the issue .

assessment - assess the year 2000 impact on the enterprise .

identify core business areas and processes , inventory and analyze systems supporting the core business areas , and prioritize their conversion or replacement .

develop contingency plans to handle data exchange issues , lack of data , and bad data .

identify and secure the necessary resources .

renovation - convert , replace , or eliminate selected platforms , applications , databases , and utilities .

modify interfaces .

validation - test , verify , and validate converted or replaced platforms , applications , databases , and utilities .

test the performance , functionality , and integration of converted or replaced platforms , applications , databases , utilities , and interfaces in an environment that faithfully represents the operational environment .

implementation - implement converted or replaced platforms , applications , databases , utilities , and interfaces .

implement data exchange contingency plans , if necessary .

during our review , we concentrated on the navy's efforts to oversee its year 2000 program during the awareness and assessment phases — the first two phases of its overall five - phased approach .

we focused our review on year 2000 work being carried out by ( 1 ) dod's office of the assistant secretary of defense for command , control , communications and intelligence ( asd / c3i ) , which is responsible for promulgating dod guidance on year 2000 matters and providing assistance to defense components , ( 2 ) navy headquarters , including the offices of the chief information officer ( cio ) , who is responsible for overall coordination and management and for issuing navy year 2000 policy and guidance , and ( 3 ) the navy's two largest systems commands , the naval air systems command ( navair ) and the naval sea systems command ( navsea ) , which are the central activities responsible for developing , acquiring , and supporting aeronautical systems and ships and related weapons and combat systems .

specifically , we met with the acting assistant secretary of defense for command , control , and communications and intelligence , the principal director for information management , the director for information technology , and other senior staff responsible for year 2000 issues .

we reviewed defense's year 2000 guidance and other documentation on year 2000 funding , reporting , and date format requirements .

we met with the acting deputy chief information officer , the team leader and coordinator from the year 2000 coordination office , and the navsea coordinator and the navair deputy cio .

we obtained and analyzed documents issued by these offices that describe organizational structure and responsibilities for carrying out the navy year 2000 program .

we reviewed the navy's year 2000 action plan to assess the level of guidance , roles , and responsibilities , and target milestone dates for the year 2000 effort .

we also reviewed other pertinent year 2000 program documentation such as defense and navy guidance and management directives , working group minutes , status reports , and cost and schedule data .

further , we reviewed available inventory information on the navy's mission - critical systems contained in the defense integration support tools ( dist ) database , which the navy uses to help manage its year 2000 efforts .

in doing so , we determined ( 1 ) the number of systems reported to be owned and operated by navy organizations and ( 2 ) the reported status of navy systems in their year 2000 efforts .

we also assessed the reliability and completeness of the navy's year 2000 information .

we relied on work previously conducted at the naval supply systems command ( navsup ) , which is the navy's primary supply manager .

in our report on navsup's year 2000 efforts , we found that navsup had made considerable progress in meeting its year 2000 challenges as a result of implementing a centralized management and control approach .

we performed our work primarily at the navy's year 2000 coordination office and the office of the assistant secretary of defense for command , control , communications and intelligence in arlington , virginia .

we conducted our work from august 1997 through april 1998 in accordance with generally accepted government auditing standards .

we requested comments on a draft of this report from the secretary of the navy .

comments from the department are discussed in the “agency comments and our evaluation” section and are reprinted in appendix ii .

most of the navy's automated information systems and weapons systems are vulnerable to the year 2000 problem , which is rooted in the way dates are recorded and computed in automated information systems .

for the past several decades , systems have typically used two digits to represent the year , such as “97” representing 1997 , in order to conserve electronic data storage and reduce operating costs .

with this two - digit format , however , the year 2000 is indistinguishable from 1900 , or 2001 from 1901 , etc .

as a result of this ambiguity , computerized systems and / or application software that use dates to perform calculations , comparisons , or sorting may generate incorrect results when working with years after 1999 .

in addition , any electronic device that contains a microprocessor or is dependent on a timing sequence may be also vulnerable to year 2000 problems .

this includes computer hardware , telecommunications equipment , building and base security systems , street lights at military installations , elevators , and medical equipment .

should navy computer systems fail , navy operations at all levels could be impacted by the incorrect processing of data as well as corrupted databases or even massive system failures .

in turn , this could result in such problems as delays in supply shipments , faulty inventory forecasts , unreliable budget estimates , and erroneous personnel - related information .

moreover , the problem could adversely impact critical maritime operations such as combat , communications , command and control , intelligence , surveillance , reconnaissance , strategic sealift , and fleet mobilization and readiness .

like the other military services , the navy has adopted dod's year 2000 management strategy , which charges components ( that is , program managers and system owners ) with responsibility for making sure that all of their systems correctly process dates and gives them the flexibility to implement solutions as they deem appropriate .

in december 1995 , the navy designated the navy information systems management center with responsibility for ( 1 ) coordinating year 2000 efforts being carried out by its 9 operating forces , including the u.s. marine corps , and its 17 shore establishments which include 5 major systems commands , ( 2 ) facilitating the sharing of year 2000 information and best practices departmentwide , and ( 3 ) monitoring the navy's year 2000 progress .

in august 1997 , the navy transferred this responsibility to its newly established office of the department of the navy chief information officer .

appendix i illustrates the navy's organizational structure and describes the complexity involved in carrying out year 2000 efforts at the component level .

to comply with dod's current year 2000 funding mandate , the navy is not providing program managers and system owners additional funds to manage and fix the year 2000 problem .

rather , program managers and system owners have been directed to use previously budgeted funds ( that is , primarily operational and maintenance ( o&m ) funds ) or reprogram other programmatic funds to fix year 2000 problems .

as of february 1998 , the navy estimated that it will cost about $421 million to successfully complete its year 2000 program , but as discussed later , this estimate is not reliable .

to increase awareness of year 2000 and to foster coordination among its components , the navy has taken the following actions .

in november 1995 , it formally began the awareness phase of its year 2000 program .

in april 1996 , it established a navy year 2000 homepage that serves as a clearinghouse for year 2000 information .

since october 1996 , it has participated in a number of year 2000 interface assessment workshops sponsored by defense .

these workshops are designed to acquaint managers with the nature and extent of interface problems pertaining to 21 functional areas , such as finance , intelligence , logistics , communications , and weapons systems .

from march 1997 through may 1998 , it has conducted quarterly reviews to keep abreast of year 2000 problems .

these reviews are attended by representatives from the secretary of the navy , the cio office , and the major navy and marine corps commands and activities .

since may 1998 , the navy cio office has been holding weekly briefings with the commands .

in april 1997 , it adopted and implemented dod's compliance checklist to assist system managers in ensuring that their systems are compliant for the year 2000 .

the checklist focuses on ( 1 ) identification of systems and interfaces , ( 2 ) assessment of date usage by the systems , and ( 3 ) compliance testing , among other subjects .

in august 1997 , it identified year 2000 as its highest priority behind life - threatening or mission failure repairs and instructed components to put a higher priority on funding remediation efforts than on other information technology initiatives .

in december 1997 , it tasked the navy inspector general to assess year 2000 readiness at its commands .

the ig plans to report on its assessment of 12 commands in april .

at the time of our review , the ig had not issued any reports .

in february 1998 , the navy requested the naval audit service to review year 2000 readiness at the commands not visited by the ig .

in january 1998 , it formally issued its year 2000 action plan .

the march 1998 revision of this plan sets milestones for the completion of major year 2000 activities and provides exit criteria for each phase .

in february 1998 , the navy reported to the office of management and budget that it had 812 mission - critical and 1,575 nonmission - critical automated information and embedded systems .

according to the navy , 781 mission - critical systems need to be repaired ; about a quarter of these were reported to be in the renovation phase and over half in the validation phase .

in addition , the navy reported that 1,422 nonmission - critical systems need to be repaired ; about a third of these were reported to be in renovation and half in validation .

specific reported totals for february 1998 are shown in table 1 .

as discussed later in this report , we found the navy's status information to be unreliable .

in its february 1998 report , the navy provided the following information on personal computers and communications and facility equipment .

the navy is behind schedule in completing the early phases of its year 2000 program .

for example , although defense required that all systems be assessed by june 1997 , the navy reported that it did not finish assessing its mission - critical systems until december 1997 , and , as of february 1998 , reported it was still assessing about 2 percent of its nonmission - critical systems .

in addition , it did not issue an approved year 2000 program management plan until january 1998 .

our guide recommends that this be done early in the assessment phase .

further , it is still assessing whether corrective actions are needed for other equipment such as computer hardware , communications equipment , and security systems .

in april 1998 , the navy issued a draft assessment guide to evaluate these assets .

technology experts like the mitre corporation and the gartner group estimate that organizations should spend less than 30 percent of their effort in the first two phases and reserve 70 percent for the renovation , validation , and implementation phases of the year 2000 program .

because the navy has spent about 60 percent of the time available completing the first two phases , it will be difficult to complete the more complex and time - consuming tasks of renovating , testing , and implementing its systems in the time remaining .

navy officials acknowledge that the assessment phase is taking longer than expected .

they attribute this delay to difficulties associated with developing a complete systems inventory and the lack of skilled field people to perform year 2000 tasks .

before its year 2000 effort , the navy did not have a comprehensive servicewide system inventory nor did many of its components .

therefore , it could not readily determine the magnitude of the year 2000 problem servicewide or the cost to fix it .

even though navy cio officials acknowledged that the department is behind schedule , the navy has recently moved up its target completion dates for its mission - critical systems for the remaining three phases .

under the accelerated schedule , the navy plans to complete the renovation phase for mission - critical systems about 1 month sooner than it originally anticipated and the testing phase 2 months earlier than originally anticipated .

it also plans to complete the implementation phase 4 months earlier than anticipated and 3 months before omb's recommended completion date .

based on the latest reported component data , the navy estimates that only seven mission - critical systems will not meet its new dates .

as the following sections of this report discuss , the navy is at risk of not meeting its new schedule because it has not yet established key management and oversight controls needed to successfully complete the next phases .

specifically: at the time of our review , navy headquarters as well as some components did not have strong program offices to guide them through the more complex and difficult phases of remediation .

the navy still does not have complete and accurate information on systems , the status of remediation efforts , and costs .

the navy has not yet identified all system interfaces nor ensured that interface partners are effectively working together to correct interfaces .

the navy has not developed an overall strategy for testing its systems .

in addition , navy operations are at risk because the navy has not developed contingency plans to ensure that mission functions can be performed if mission - critical systems are not corrected in time .

in view of the magnitude of the year 2000 problem , our assessment guide recommends that agencies plan and manage their year 2000 programs as a single large information system development effort and promulgate and enforce good management practices at the program and project levels .

the guide also recommends that agencies appoint a year 2000 program manager and establish an agency - level year 2000 program office .

the navy took a decentralized approach to the year 2000 effort but it did not initially establish a strong year 2000 program office to manage it effectively .

for example , during our review , the navy had assigned only five full - time personnel in the office of the cio to oversee and monitor the year 2000 progress of more than 2,000 systems and 300,000 personal computers and servers owned by five major systems commands , 17 shore establishments , and 9 operating forces , including the u.s. marine corps .

by contrast , the air force assigned 27 staff to the year 2000 problem — 3 to oversee and implement program and policy changes across the service and 24 to execute the program .

according to navy cio officials , the office had not managed year 2000 remediation efforts effectively , and most of the staff's time had been spent reporting the status of component efforts to top managers in the navy , dod , and external entities , such as the cio council and omb .

for example , at the time of our review , the staff was not validating information being reported by navy components for completeness and accuracy ; assessing component efforts to prioritize systems ; or tracking component progress in completing important year 2000-related activities , such as contingency planning and testing .

some of the navy's components also did not support their own efforts with a strong program office .

for example , at the time of our review , navsea did not have any dedicated full - time year 2000 staff at the command level , even though it is responsible for managing more than 350 systems involving 138 major acquisition programs and 345 ships — all of which are susceptible to year 2000 problems .

navair , which is responsible for about 870 systems involving over 200 aeronautical - related programs and over 4,600 aircraft , assigned only three full - time staff to work on the command's year 2000 problem .

the navy has recently responded to this problem by assigning three additional staff to the cio office to help coordinate year 2000 activities and by establishing a new year 2000 project office for navy operations , comprised of 15 staff .

as shown in appendix i , the chief of naval operations is responsible for operating forces across all navy commands and shore activities as well as key functions , such as intelligence , logistics , and training .

the office , which will begin operating in june 1998 , will be responsible for coordinating the testing efforts of navair , navsea , the space and warfare systems command , and fleet commands .

however , there are no plans to have either the cio office or the new project office validate data reported by the components or assess component progress in prioritizing systems , identifying and correcting interfaces , and developing contingency plans .

according to our assessment guide , a key part of the assessment phase is to identify business areas that are critical to the enterprise and , for each area , critical business processes and supporting information systems .

in constructing the inventory of information systems , it is important to assess the potential impact on business processes if systems are not fixed on time , to estimate the cost of remediation , and to monitor the progress components are making toward correcting their systems .

this provides the necessary foundation for year 2000 program planning .

the navy , however , does not yet have a complete and accurate inventory or reliable status and cost information .

as a result , it does not have a clear picture of its year 2000 remediation efforts and it cannot reliably prioritize systems for correction , determine what resources it needs , or identify problems that require greater management attention .

until recently , the navy's primary source of year 2000 system inventory information was the defense - wide database of automated systems , known as the defense integration support tools ( dist ) database .

the navy was using this database to help oversee its year 2000 efforts and prepare its quarterly status reports to the department of defense , which , in turn , submits the information to the office of management and budget .

in february 1998 , due to concerns that extensive and detailed information on all of the department's mission - critical systems was available on the internet , asd / c3i removed dist from the internet and classified it as “secret” — meaning that it can only be accessed by personnel with a valid security clearance , job - related “need - to - know,” and access to secure computer and communications equipment .

as a result , the navy has no readily accessible central repository of system information to help oversee system fixes or respond to ad hoc requests for year 2000 information from omb or defense .

according to the cio office , the secret classification given dist has “gravely hindered” its ability to manage the year 2000 effort .

the navy plans to resolve this problem by creating a separate unclassified year 2000 database and making it available by june 1998 .

as the navy implements this new database , it will be important for it to correct the data problems we identified in our discussions with command and headquarters officials as well as in our review of selected information from dist on the navy's mission - critical systems provided to us by the defense information systems agency ( disa ) database administrator .

these problems include the following .

of 819 mission - critical systems in the database , 6 systems failed to identify which stage of remediation they were in , 23 did not provide the name of the system or describe its function , and 118 failed to show an expected compliance date .

in providing the data , disa did not include cost information because the office of the assistant secretary of defense for command , control , communications and intelligence concluded that the data were unreliable .

for example , asd / c3i noted that in some cost estimates , the decimal point was misplaced , overstating some estimates by millions of dollars .

our discussions with headquarters and command officials further revealed that the cost estimate was incomplete .

for example , navsea officials told us that the navy was missing cost information for about 95 percent of navsea's 138 major acquisition programs .

navair also indicated that many of its system managers were not reporting costs .

the reliability of cost information is also questionable because some navy components are still using a cost formula derived from the gartner group and the mitre corporation , which recommends multiplying the number of lines of code by $1.10 for automated information systems and by $8 for weapons systems .

defense recommended that components use this formula early in their year 2000 efforts , but it also recommended that a more detailed cost analysis based on more than 30 cost factors be conducted as components progressed through the assessment phase and learned more about their systems and the resources that would be required to fix them .

the difference between the gartner / mitre formula and a more reliable analysis of data collected during the assessment phase can be significant .

for example , based on the gartner / mitre formula , the navy estimated that it would cost $4.3 million to correct a mission - critical ordnance management system .

based on a detailed cost analysis of data collected during its assessment , the navy estimated that remediation costs would actually be about $1.75 million — a 59 percent decrease over the original estimate .

in addition , as the new database is implemented , it will be important for the navy to routinely validate the information submitted by its components .

while it was using dist , the navy did not validate the data .

consequently , it had no assurance that the information on its systems , remediation progress , and cost was correct and complete .

navy systems interface with each other as well as with systems belonging to contractors , other federal agencies , and international entities , such as the north atlantic treaty organization and foreign military sales customers .

therefore , it is essential that navy components ensure that all interfaces are year 2000 compliant and that noncompliant interfacing partners will not introduce year 2000-related errors into compliant navy systems .

our assessment guide and dod's year 2000 management plan recommend that agreements with interface partners be initiated during the assessment phase to determine how and when interface conflicts will be resolved .

the navy has not managed the identification and correction of its interfaces effectively .

first , although the navy set the goal of completing renovation of its interfaces by june 30 , 1998 , many components , including the nine navair and navsea weapon system program offices we contacted during our review , were still in the process of identifying interfaces and assessing whether they need to be corrected .

second , as of february 1998 , the navy reported to omb that it had fixed only 5 of the 1,051 interfaces already identified .

for the rest , it had not yet determined whether data bridges would be required , negotiated who was responsible for installing and funding the bridges , or developed agreements documenting the method and schedule for correcting the interfaces .

third , the navy was not using dist ( before it was classified ) or any other information tool to track component progress in completing these activities .

the navy recently asked its inspector general and the naval audit service to review the completeness of memorandums of agreement as they conduct their year 2000 assessments at the commands .

however , these reviews will be performed on a limited basis — they are not designed to ensure that all mission - critical program managers and system owners have identified their interfaces , taken appropriate measures to fix them , and documented these agreements with their interface partners .

the validation ( testing ) phase of the year 2000 effort is expected to be the most expensive and time - consuming .

experts estimate that it will account for 40 to 60 percent of the entire effort .

as dod's year 2000 management plan notes , organizations “must not only test year 2000 compliance of individual applications , but also the complex interactions between scores of converted or replaced computer platforms , operating systems , utilities , databases , and interfaces.” to mitigate the risks associated with testing , our assessment guide calls on agencies to develop validation strategies and test plans .

validation strategies are developed at an organizationwide level to ensure that common test requirements are followed by all locations .

specifically , they describe the test organization's and its components' roles and responsibilities , system / project priorities , a master schedule of high - level test activities for each system / project , and the test resources to be used in carrying out these activities ( people , tools , facilities , and contractors ) .

the plan should be sufficiently detailed to allow system / project - specific planning to occur as well as to permit program office tracking of high - level test activity progress .

for example , it should have milestones , including completion dates , for application / system acceptance tests , specify project progress metrics , and allocate common test facilities and other resources among system renovation projects competing for these facilities and resources .

since agencies may need over a year to adequately validate and test converted or replaced systems for year 2000 compliance , our assessment guide recommends that this planning begin in the assessment phase .

the navy lacks an overall validation strategy that specifies the common criteria and processes components should use in testing their systems .

as such , it has no assurance that all systems and interfaces will be thoroughly and consistently tested .

for example , in the absence of a validation strategy: there is no guidance on who , when , and how tests of the navy's estimated 10,000 local area networks ( lans ) should be conducted .

as a result , the navy computer and telecommunications command , which manages these networks , is relying solely on its vendors to ensure that navy lans are year 2000 compliant .

it does not plan to perform end - to - end tests on shore - based lans or ensure that vendor tests are adequate .

one navy command has found that relying on vendors to ensure that systems are compliant is not enough to mitigate year 2000 risks .

when navsup tested products that vendors claimed were compliant , it found that many were not .

the navy does not know how much testing capacity is needed by its components and how much is available even though it has acknowledged that these resources will be in demand .

as our assessment guide notes , agencies may have to acquire additional facilities in order to provide an adequate testing environment .

the longer the navy waits to begin assessing the need for these facilities , the less time it will have to acquire additional facilities or otherwise ensure that all mission - critical systems can be tested before the year 2000 deadline .

in addition to lacking a departmentwide validation strategy , we found that two major components — navair and navsea — had not developed strategies nor were they ensuring that the organizations reporting to them did so .

in fact , navair did not require its program managers and system owners to develop individual year 2000 test plans .

to mitigate the risk that year 2000-related problems will disrupt operations , our recently issued guide on business continuity and contingency planning recommends that agencies perform risk assessments and develop realistic contingency plans during the assessment phase to ensure the continuity of critical operations and business processes .

contingency plans are important because they identify the manual or other fallback procedures to be employed should systems miss their year 2000 deadline or fail unexpectedly in operation .

contingency plans also define the specific conditions that will cause their activation .

the navy is not developing contingency plans that focus on ensuring the continuity of all of its critical military operations and business processes .

instead , it is developing plans for only a small portion of its mission - critical systems — specifically those systems that ( 1 ) are scheduled for implementation beyond january 1 , 1999 , ( 2 ) do not complete renovation by june 30 , 1998 , or ( 3 ) fail integrated platform testing .

the navy reported that , under these criteria , only 7 of the 812 mission - critical systems currently require a contingency plan .

three of these plans have been completed .

the navy is taking this approach because it believes that it should spend its resources on identifying and fixing year 2000 problems early and then concentrate its energy on contingency plans for systems for which renovation is going to be delayed .

preparing contingency plans on this basis is not judicious .

first , even if the navy's mission - critical systems are replaced or renovated in time , there is no guarantee that they will operate correctly .

second , the risk of year 2000 failures is not limited to the navy's internal systems .

in fact , the navy depends on information and data provided by other defense and federal agencies , international organizations , and private contractors whose systems can introduce year 2000 problems into navy's systems .

it also relies on services provided by the public infrastructure , which are susceptible to year 2000 problems that could disrupt operations — including power , water , and voice and data telecommunications .

until its contingency planning focuses on this chain of critical dependencies , the navy will not be able to ensure that it can maintain the basic functionality of its critical operations and core business processes .

navy operations may be severely disrupted if the navy does not successfully remediate its mission - critical computer systems before the year 2000 deadline .

while the navy has taken a number of actions to address this issue , many critical tasks remain to be done in a relatively short period .

at this point , the navy does not know whether it has identified all systems and interfaces ; it lacks reliable data on the status and cost of remediation efforts ; and it does not know if it has the capacity to handle the demanding task of testing systems , networks , operating platforms , and databases .

despite the fact that these weaknesses have greatly increased the chances that it will not correct its mission - critical systems in time , the navy is not adequately prepared to respond to unforeseen problems and delays .

we recommend that you direct the department of the navy chief information officer to ensure that the navy year 2000 coordination office is provided with sufficient staff and authority to implement the following recommendations .

establish a complete and accurate inventory of its information systems .

ensure that the data problems identified in this report are corrected and routinely validate the information submitted by components to the database .

ensure that components have identified and corrected interfaces and developed written memorandums of agreement with interface partners .

develop a departmentwide testing strategy that describes program manager and system owner roles and responsibilities , system / project priorities , a master schedule of high - level test activities for each system / project , and the test resources to be used in carrying out these activities ( people , tools , facilities , and contractors ) .

ensure that navy components develop their own test strategies and require their program managers and system owners to develop individual test plans .

ensure that year 2000 contingency planning focuses on the continuity of all of the navy's critical military operations and business processes rather than on only a small portion of mission - critical systems .

in written comments on a draft of this report , the department of the navy chief information officer ( cio ) concurred with all of our recommendations to improve the navy's year 2000 program .

in response to our recommendations , the navy agreed to establish a complete and accurate inventory of its information systems , ensure that components have identified and corrected interfaces and developed memorandums of agreement with interface partners , develop a departmentwide test strategy , and ensure that contingency planning focuses on the continuity of critical military operations and business processes .

the navy also stated that it has increased staff in its year 2000 coordination office to 10 full - time employees to help carry out these activities .

in addition , the navy noted that its new year 2000 database , which is expected to be on - line in june 1998 , will include additional data elements not contained in dist , such as actual and programmed costs , planned and actual dates that memorandums of agreements are signed with interface partners , the dates that test plans are prepared , and the status of testing activities .

as part of the validation process , the cio office plans to conduct weekly reviews of the data for completeness and accuracy .

the navy also stated that , in addition to requiring that contingency plans be prepared on the continuity of business operations and to ensure mission capability at the user level , it is now requiring contingency plans to be prepared for all — rather than a select few — mission - critical systems no later than december 1998 .

this report contains recommendations to you .

the head of a federal agency is required by 31 u.s.c .

720 to submit a written statement on actions taken on these recommendations to the senate committee on governmental affairs and the house committee on government reform and oversight not later than 60 days after the date of this report .

a written statement also must be sent to the house and senate committees on appropriations with the agency's first request for appropriations made more than 60 days after the date of this report .

we are providing copies of this report to the chairmen and ranking minority members of the senate committee on governmental affairs , the subcommittee on oversight of government management , restructuring and the district of columbia , senate committee on governmental affairs , the subcommittee on defense , senate committee on appropriations , the senate committee on armed services , the subcommittee on government management , information and technology , house committee on government reform and oversight , the subcommittee on national security , house committee on appropriations , and the house committee on national security .

we are also sending copies to the honorable thomas m. davis , iii , house of representatives ; the deputy secretary of defense ; the acting assistant secretary of defense for command , control , communications and intelligence ; the navy chief information officer ; and the director of the office of management and budget .

if you have any questions on matters discussed in this report , please call me at ( 202 ) 512-6240 .

major contributors to this report are listed in appendix iii .

as figure i.1 indicates , the size and complexity of the department of the navy's organization structure poses a significant management challenge .

year 2000 management and oversight efforts will have to be coordinated among 17 major navy shore establishments including 5 major systems commands and 9 operating forces , such as the u.s. marine corps , the naval reserve forces , the military sealift command , and the atlantic and pacific fleets .

figure i.2 provides an example of just one command's field structure .

to understand the complexity involved in carrying out year 2000 efforts at the command level , consider the following .

the naval sea systems command's fiscal year 1998 budget accounts for about 19 percent ( or $15 billion ) of the navy's total budget .

the naval sea systems command , which is the largest of five navy systems commands , employs about 55,000 personnel .

the command currently manages 138 acquisition category programs assigned to six program executive offices , including carriers , littoral warfare , and auxiliary ships ; mine warfare ; surface combatants / aegis program ; submarines ; theater air defense ; and undersea warfare .

the command is responsible for 345 ships , including 92 submarines and 14 aircraft carriers , assigned to 24 home ports in the united states and overseas .

the command manages about 1,275 foreign military sales cases .

because the command's systems interface with the systems belonging to its foreign military sales customers , it will need to develop interface agreements with its customers .

the naval sea systems command alone has about 56 year 2000 points - of - contacts .

office of the chief of naval operations deputy chief of naval operations ( manpower & personnel ) director of naval intelligence deputy chief of naval operations ( plans , policy , & operations ) deputy chief of naval operations ( logistics ) director of space command & control information director of naval training deputy chief of naval operations ( resources , warfare requirements , and assessments ) .

christopher t. brannon , senior evaluator teresa f. tucker , senior evaluator the first copy of each gao report and testimony is free .

additional copies are $2 each .

orders should be sent to the following address , accompanied by a check or money order made out to the superintendent of documents , when necessary .

visa and mastercard credit cards are accepted , also .

orders for 100 or more copies to be mailed to a single address are discounted 25 percent .

u.s. general accounting office p.o .

box 37050 washington , dc 20013 room 1100 700 4th st. nw ( corner of 4th and g sts .

nw ) u.s. general accounting office washington , dc orders may also be placed by calling ( 202 ) 512-6000 or by using fax number ( 202 ) 512-6061 , or tdd ( 202 ) 512-2537 .

each day , gao issues a list of newly available reports and testimony .

to receive facsimile copies of the daily list or any list from the past 30 days , please call ( 202 ) 512-6000 using a touchtone phone .

a recorded menu will provide information on how to obtain these lists .

