a large number of children's product recalls in 2007 and 2008 led to heightened scrutiny of the consumer product safety commission's ( cpsc ) regulation of consumer products and public access to product safety information .

in response to these concerns , congress enacted the consumer product safety improvement act ( cpsia ) on august 14 , 2008 , to strengthen cpsc's authority to enforce safety standards and provide greater public access to product safety information .

cpsia required cpsc to establish a publicly available , searchable database of consumer and other products and substances the commission regulates that are reported to be unsafe .

on march 11 , 2011 , cpsc launched the mandated database at saferproducts.gov ( http: / / www.saferproducts.gov ) .

the website has two portals — one for consumers and one for businesses .

for the consumer portal , website users can perform two main functions on the site .

first , consumers and members of other statutorily defined groups can submit second , consumers reports of harm or the risk of harm from products.and others can search for information on products reported to be unsafe that they own or may wish to purchase .

saferproducts.gov also shows manufacturers' comments alongside incident reports if the manufacturer requests their comments be published .

the act also requires that gao analyze the utility of the website , including an assessment of its use by consumers and efforts by cpsc to inform the public about the database .

in this report , we examine ( 1 ) cpsc's efforts to inform the public about saferproducts.gov , ( 2 ) who has used saferproducts.gov and to what extent , and ( 3 ) the extent to which consumers have found saferproducts.gov to be useful .

to address the first objective , we reviewed cpsc marketing materials and budget , evaluation , and planning documents , and interviewed cpsc officials to determine the status of the agency's efforts for saferproducts.gov .

this included reviewing the targets of cpsc's outreach , how the agency evaluated the outcomes of these efforts , and any future plans .

we compared cpsc's efforts with key practices for consumer education planning identified in a prior report and interviewed other entities ( such as consumer groups ) to determine what additional steps , if any , cpsc could take to better inform the public about saferproducts.gov .

for context , we reviewed documentation and interviewed officials about cpsc's strategies to increase overall public awareness of the agency .

to address the second objective , we analyzed data for 2011 through 2012 on users who filed incident reports through various methods , including saferproducts.gov , phone , e - mail , postal mail , and fax , and analyzed other data cpsc maintains to measure the amount of website use .

to assess data reliability , we drew on our prior work assessing saferproducts.gov and reviewed relevant documentation , performed manual tests to look for errors , and interviewed cpsc officials responsible for the data .

we determined that , for the purposes of this report , the data were sufficiently reliable .

we also interviewed cpsc officials about efforts to collect any demographic data — such as age , gender , and income — about users , and reviewed existing studies , including those by consumer groups and a law firm , related to use of saferproducts.gov .

to address the third objective , we conducted website usability tests with 37 consumers in three locations — washington , d.c. , dallas , texas , and san francisco , california — to obtain their views on how easy it was to use saferproducts.gov and how helpful the information on the website was .

we chose these locations for geographic dispersion and ease of testing .

we followed the protocols and used the washington , d.c. , facilities of the general services administration ( gsa ) for our testing conducted through the first fridays usability testing program .

at this location , we conducted three one - on - one tests with consumers whom gsa recruited .

we asked consumers to complete usability tasks we developed and discuss their general experiences using the site .

in the other two locations , we worked with a contractor to recruit prospective website testers having a mix of characteristics in terms of age , gender , education , and ethnicity .

we conducted two separate focus groups ( of 8-9 consumers ) in each of the other locations , asking them to complete specified usability tasks and discuss their experiences using the website .

while the results of the tests are not generalizable to all u.s. consumers , they provided us with in - depth interactive feedback and detailed perspectives from a range of consumers about the usability challenges associated with saferproducts.gov .

we also analyzed other usability resources to determine key practices on how to make websites easy to use and helpful .

appendix i contains a more detailed description of our objectives , scope , and methodology .

appendix ii contains the script used in our website usability tests .

we conducted this performance audit from july 2012 to march 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

cpsc was created in 1972 under the consumer product safety act to regulate certain consumer products and address those that pose an unreasonable risk of injury ; assist consumers in evaluating the comparative safety of consumer products ; and promote research and investigation into the causes and prevention of product - related deaths , injuries , and illnesses .

cpsc's jurisdiction is broad , covering thousands of types of manufacturers and consumer products used in and around the home and in sports , recreation , and schools .

cpsc does not have jurisdiction over some categories of products , including automobiles and other on - road vehicles , tires , boats , alcohol , tobacco , firearms , food , drugs , cosmetics , medical devices , and pesticides .

other federal agencies — including the national highway traffic safety administration ; coast guard ; bureau of alcohol , firearms , tobacco , and explosives ; department of agriculture ; food and drug administration ; and environmental protection agency — have jurisdiction over these products .

consumers and others previously were able to report safety problems or concerns about consumer products through cpsc's toll - free hotline ; the u.s. mail , or a form on cpsc's website submitted through e - mail and they can continue to use these methods in lieu of submitting reports through saferproducts.gov .

cpsia and cpsc define “harm” as injury , illness , or death or risk of injury , illness or death .

15 u.s.c .

§ 2055a ( g ) ; 16 c.f.r .

§ 1102.6 ( b ) ( 4 ) .

be published .

as required by statute , cpsc disclaims any responsibility to guarantee the accuracy of a report .

the submitter of an incident report on saferproducts.gov must fit into one of five categories: ( 1 ) consumers ; ( 2 ) local , state , and federal government agencies ; ( 3 ) health care professionals ; ( 4 ) child service providers ; and ( 5 ) public safety entities .

cpsc regulations specify that “consumers” include , but not be limited to , users of consumer products , family members , relatives , parents , guardians , friends , attorneys , investigators , professional engineers , agents of a user of a consumer product , and observers of the consumer products being used .

cpsia requires the following information when submitting a report of harm: ( 1 ) description of the consumer product sufficient to distinguish the product as a product or component part regulated by cpsc ; ( 2 ) identity of the manufacturer or private labeler by name ; ( 3 ) description of the harm related to use of the consumer product ; ( 4 ) approximate or actual date of the incident ; ( 5 ) category of submitter ; ( 6 ) submitter's contact information ; ( 7 ) submitter's verification that the information contained therein is true and accurate ; and ( 8 ) consent to publication of the report of harm .

15 u.s.c .

§ 2055a ( b ) ( 2 ) ( b ) ; c.f.r .

§ 1102.10 ( d ) .

subject to §§ 1102.24 and 1102.26 , cpsc will publish reports of harm containing all the required information .

required to contact the submitters for further information.transmits a copy to manufacturers , importers , and private labelers identified in the reports , to provide them with the opportunity to comment .

qualifying reports and manufacturer comments submitted for publication are then available on saferproducts.gov ( see fig .

1 ) .

cpsc's efforts to promote saferproducts.gov formed part of a larger effort to increase the public's awareness of the agency .

cpsc has taken a variety of approaches to inform the public about saferproducts.gov , many of which are consistent with key practices for consumer education planning .

however , cpsc has not established metrics for its efforts .

as a result , the agency does not know which of its efforts have had the most impact on increasing awareness and use of saferproducts.gov .

cpsc's efforts to inform the public about saferproducts.gov have been part of a larger effort to increase the public's awareness of the agency .

according to cpsc officials , certain segments of the public may not be aware of the agency or its mission in product safety , much less be aware of saferproducts.gov .

likewise , roughly one - third of the 37 consumers who participated in our website usability tests were aware of cpsc or its mission .

to promote awareness of cpsc , officials have conducted public information campaigns related to various product safety hazards such as fire hazards and those involving children's products , issued press releases about product recalls , and used social media .

officials said that media stories promoting the use of saferproducts.gov have had the benefit of promoting cpsc as a resource not only for information about product recalls ( for which the agency is most commonly known ) , but also as a place where consumers can raise concerns about the safety of consumer products .

in addition to the outreach efforts noted above , cpsc has planned initiatives to assess the public's awareness of the agency as a whole .

in fiscal year 2011 , cpsc's office of communications received funds to award a contract to plan and conduct field surveys to assess consumer awareness of the agency .

cpsc and a contractor are developing the survey tool .

these surveys are to cover such areas as the public's knowledge and awareness of the safety issues for which cpsc is responsible , how the agency's work affects consumers , and how the public responds to product recalls and other safety hazards that cpsc communicates .

cpsc officials told us that they plan to administer the survey in 2013 , but have been awaiting approval of the survey from the office of management and budget .

cpsc also recently redesigned its main website , cpsc.gov , based on feedback from the public .

according to cpsc officials , this redesign allowed the agency to provide a more visible link to saferproducts.gov .

as it has for publicizing the agency , cpsc has used a variety of approaches to inform the public about saferproducts.gov , including the use of social and other media .

before launching saferproducts.gov , cpsc hosted a web conference on january 11 , 2011 , to inform interested stakeholders such as consumer groups and the public about the site's search function and the information required to submit an incident report.2011 , cpsc promoted the new website through print and other media .

according to cpsc officials , the agency's promotional strategy emphasized both the public's ability to search saferproducts.gov for reports and submit such reports .

in addition , near the 1-year anniversary of saferproducts.gov , cpsc launched three public service around the time it launched saferproducts.gov in march announcements ( psas ) about saferproducts.gov , sending these psas to local and national media and making them available on online media channels , such as youtube ( http: / / www.youtube.com ) .

according to cpsc officials , the agency has a contract with a video production company to produce and distribute the videos .

cpsc officials said that the psas have been among the 10 most - viewed videos on cpsc's youtube channel .

they added that it was difficult to attract extensive television coverage or the best airtime slots given cpsc's psa budget of about $50,000 for fiscal year 2012 .

further , the officials said that psas can cost from $700,000 to $1 million to produce , distribute , and air during prime viewing or listening times .

the agency also has distributed informational materials to target audiences at conferences and community events ; referenced the site in speeches and presentations by the chairman , commissioners , and staff ; and held press interviews to promote the site , according to cpsc officials .

for example , cpsc developed a series of brochures , including some tailored to specific professional sectors , such as health care , child care , public safety , and government .

cpsc officials noted that they have mentioned the site at conferences , particularly those aimed at minority populations and professional groups .

the agency also has made a data feed of the incident reports available to third - party software developers to create mobile applications and provided information for developers in a frequently asked questions page on saferproducts.gov .

in conducting its public information efforts , cpsc has employed a number of strategies consistent with key practices for consumer education planning that we identified in a prior report .

for example , cpsc has worked with stakeholders such as consumer groups ( a key practice ) to promote saferproducts.gov , and used a variety of media ( another key practice ) to promote the site .

cpsc also has identified “messengers” such as consumer groups and state attorneys general to assist with publicity , and identified the resources needed for publicity ( other key practices ) .

most of the consumer product safety experts we interviewed from nine groups representing consumers , researchers , and various industries stated that cpsc has been taking appropriate measures to promote the site .

however , some also suggested that cpsc could conduct more targeted outreach to other professional groups , such as those in health care , and other populations , such as parents .

while cpsc has employed many of the key practices for consumer education planning as described previously , it has not employed one of the key practices that could further improve the efficacy of its outreach for saferproducts.gov .

specifically , cpsc has not established metrics , such as process and outcome metrics , to measure the success of its outreach in its 2013 performance budget request , as part of an effort to efforts.increase awareness of the agency , cpsc has a goal for the number of visits to cpsc.gov .

however , cpsc does not have a similar goal for the number of visits to saferproducts.gov , although it collects such data ( as discussed in the next section of this report ) .

similarly , cpsc has not determined whether its efforts to publicize saferproducts.gov at conferences or through psas have led to increased use of saferproducts.gov after the events .

cpsc also has not incorporated tools or features on the site ( such as a drop - down menu on the homepage that would ask users to select an option such as “conferences,” “psas,” “printed materials,” or “media” ) to identify how the user learned about and arrived at the site .

the information generated by such tools also may provide cpsc with ideas for additional metrics to measure awareness and use of the site .

cpsc has not established metrics to evaluate its outreach efforts for saferproducts.gov because the agency has been focused on increasing awareness of cpsc and improving the functionality of cpsc.gov .

cpsc officials said that in comparison with saferproducts.gov , cpsc.gov received almost 10 times as many visits each month .

officials have said they may focus on evaluating outreach efforts for saferproducts.gov in the future .

however , without current metrics to assess the efficacy of its outreach for saferproducts.gov , cpsc will not know which of its efforts — for instance , promoting the site at conferences and using psas — have had the most impact on increasing awareness and use of saferproducts.gov , or be able to best target its limited resources to increase use of the site .

cpsc collects limited data about the use of saferproducts.gov .

to track use , cpsc collects data on the number of visitors , most frequently visited pages , and number of reports received , among other metrics .

cpsc also collects some data about the category of person who is submitting a report .

however , cpsc does not collect any data about who is using the site to search for information .

in particular , cpsc has not sought to collect demographic data , such as age , gender , or income .

in mandating this report , congress required us to assess whether a broad range of the public uses the site .

however , cpsc's limited data collection related to use of the site made it difficult to conduct such an assessment .

according to cpsc officials , the agency's primary measure of the extent of use of saferproducts.gov is the number of visitors each month .

cpsc collects these data through web analytics software .

according to cpsc's data , visits to saferproducts.gov exceeded 100,000 each month since june 2011 , a few months after the launch of the site ( see fig .

2 ) , peaking at about 238,000 in november 2012 .

cpsc officials have not been able to identify the reasons for the increase in visits .

cpsc also collects data on the most frequently visited pages each month ( see fig .

3 ) .

these data show that users frequently used the site to search for information — for example , to search for recalled products or incident reports submitted by other users of the site .

cpsc also collects data on the number of reports received each month through saferproducts.gov , as well as by phone , e - mail , postal mail , and fax .

these data show that users submitted more than 1,000 reports from all sources each month from march 2011 through december 2012 ( see fig .

4 ) .

cpsc collects some data about the categories of persons using saferproducts.gov to submit incident reports but does not collect additional data such as age , gender , or income level of the submitters or others who use the site to search for information .

when completing a report , cpsc requires submitters to state whether they are consumers , represent a government agency , or are health care or other professionals , among other categories of user .

as shown in table 1 , our analysis of more than 12,000 reports posted on saferproducts.gov as of january 2013 found that most report submitters — about 97 percent — identified themselves as consumers , results consistent with our prior reporting .

as stated previously , “consumers” include , but are not limited to , users of consumer products , family members , relatives , friends , attorneys , investigators , and others .

representatives of government agencies and public safety entities , as well as health care professionals , child service providers , and medical examiners and coroners also submitted reports .

cpsc also asks report submitters to state their relationship to the victim of the incident ( such as self , parent , or spouse ) .

as shown in table 2 , of those who identified themselves as consumers , most identified themselves as the victims of an incident .

however , many submitters did not specify a relationship .

of those who did specify a relationship to the victim , 4,463 , or 60 percent , reported that they were the victims , and 1,867 , or 25 percent , reported that their child was the victim ( see table 3 ) .

cpsc asks that submitters specify the location of the reported incident , including the country and state .

most submitters providing this information — about 90 percent — reported that the incident took place in the united states ( see table 4 ) .

submitters also reported that incidents took place in other countries or did not specify where the incident took place .

in addition , states with the highest population — such as california , texas , new york , florida , and illinois — had the most reported incidents ( see fig .

5 ) .

beyond these data , cpsc does not request or obtain additional details about the users of saferproducts.gov .

according to cpsc officials , the agency also cannot distinguish new users from returning users because cpsc's web analytics software has not been configured with “cookies” to capture these data .

officials have cited resource and privacy concerns as reasons for not collecting these data , although they said they have been considering using cookies in the future .

in addition , cpsc does not collect more specific demographic information such as age , gender , or income level from the submitters of reports or other site users , citing an interest in minimizing the reporting burden on users .

as an example , cpsc has not requested that site users voluntarily provide this information during the report submission process or after submitting a report .

congress required us to assess whether a broad range of the public uses saferproducts.gov , but cpsc's limited data collection made it difficult to conduct such an assessment .

in addition , standards for internal control in the federal government state that agencies should have timely , relevant information for management decision - making purposes.result of its limited data collection about users of the site , cpsc has been limited in its ability to target its marketing and outreach efforts on specific groups , populations , or areas to achieve the goal of increasing use of the site .

as discussed earlier in this report , our website usability tests focused on asking consumers in our testing sessions to judge if saferproducts.gov was easy to use .

we had the consumers perform various tasks ( such as searching for recalled products and submitting mock incident reports ) and asked for opinions about the site's usefulness .

a moderator facilitated the sessions and we elicited feedback from participants .

in addition , a gsa official with expertise in website usability assessed saferproducts.gov , and another gsa official reviewed the site for website accessibility .

many consumers in our testing sessions generally found saferproducts.gov easy to use , but they encountered difficulties with certain aspects of the two main functions: searching for information and of the 37 consumers who participated in our submitting incident reports.testing sessions , 20 found saferproducts.gov easy to use as indicated by their responses to a questionnaire we administered following each test session .

for example , almost all the consumers were easily able to determine what initial steps to take to search for or report a product that may be unsafe .

in addition , the expert evaluator reviewing the site at our request described the site as clean and easy to navigate .

in conducting the search tasks , consumers generally were able to find recalled products using basic key word searches .

but some search functions , including those that required more complicated searches such as use of an advanced search function to narrow results , posed challenges .

for example , in one testing session , no consumers were able to complete a task that required them to narrow their search by injury , time period , and location .

in another session , the calendar function , which filters the results by time period , posed particular challenges .

five of the eight consumers in that session experienced difficulties in having to enter and , when seeking to make one change , re - enter all the dates to focus their search on products recalled within a particular time period .

the expert evaluator from gsa experienced similar challenges in using the calendar function .

in addition , when asked to search for and compare safety information for two products — one for which there were search results and one for which there were none — almost all the testers had difficulty interpreting the lack of search results for the latter product .

for example , while some testers assumed that a search for a product that produced no results indicated that the product was safe , others did not make this presumption .

in our testing sessions , most consumers were not sure which product to purchase based on their searches and roughly a quarter indicated that they would leave saferproducts.gov to search other websites if they found no results on saferproducts.gov .

in contrast to saferproducts.gov , other websites inform users of a possibly incorrect search term , such as a typographical error , which helps users interpret the results of their searches and identify potential errors .

during the usability tests , consumers experienced fewer challenges using the reporting function than the search function .

to submit an incident report , consumers must enter information on a series of pages that include a combination of required and optional fields .

during our testing , consumers found the instructions for submitting a report to be generally clear .

for example , almost all the testers thought the instructions for submitting information about the incident , product , and victims were clear .

however , 15 of the 37 consumers in our test sessions expressed concern about apparently needing to register before submitting a report and generally did not notice that they could continue without registering ( see fig .

6 ) .

by registering on saferproducts.gov , site users can save their reports to complete at a later time and receive updates on the status of reports .

when reaching the registration page , over a third of the consumers in our focus group sessions said that they would not be inclined to register .

in one session , seven of nine consumers said they would not be inclined to register and thought that having to register was a deterrent to completing a report .

in another session , none of the participants noticed the option to skip registration .

some of those who noticed that they could skip registration emphasized that the option should be more prominent — for example , placed alongside the registration box rather than below it where it might not be immediately visible .

likewise , as an issue of website usability , the expert evaluator from gsa reviewing the site on our behalf noted that the “continue without registering” option was not prominent enough and stated that registration may deter users from continuing the report submission process .

in addition , some consumers in our testing sessions said that the reporting pages contained too many questions and described the submission process as cumbersome , particularly for busy individuals such as parents .

to address this , one consumer suggested grouping all of the required fields on one page .

the expert evaluator from gsa also suggested that all the questions in the reporting process should be reviewed to determine if each was necessary .

when cpsc first developed saferproducts.gov , the agency conducted three focus groups — one with consumers and one with professionals — to test the site and assess users' experience with it.testing only addressed the incident reporting function , not the search function , and focused on ( 1 ) awareness of how and where to submit a safety complaint and ( 2 ) general reactions to the site .

cpsc has not conducted additional usability testing since launching saferproducts.gov in march 2011 .

as mentioned previously , cpsc officials have said that issues such as assessing the level of awareness of cpsc and redesigning cpsc.gov were higher priorities than assessing and improving saferproducts.gov .

cpsc's focus group a number of resources across the federal government are available to help agencies in making their websites more usable .

for example , as cited previously , gsa's first fridays usability testing program is designed to teach agency officials how to find and fix usability problems at no cost to the agency .

the program's services are ( 1 ) formal tests , ( 2 ) quick tests , ( 3 ) mobile tests , ( 4 ) observation , and ( 5 ) expert evaluation.gsa also offers digitalgov university , which includes courses in web design and usability best practices .

in addition , the department of health and human services ( hhs ) operates two usability labs , both of which are free of charge to other federal agencies , to evaluate websites to ensure that they are easy - to - use and useful .

furthermore , gsa and hhs maintain howto.gov and usability.gov , respectively , to provide guidance and resources to help agencies create websites that are usable , useful , and accessible .

because of the usability issues in the areas we identified , consumers may not take advantage of all the features of saferproducts.gov , and consumers may be dissuaded from completing and submitting incident reports .

as a result , cpsc may not be obtaining all possible information from consumers that can help inform its safety assessments and other regulatory efforts .

none of the consumers in our test sessions previously had heard of saferproducts.gov , although a few were familiar with cpsc as an agency involved in recalling certain products .

in addition , 5 of the 37 consumers who participated in our tests said that the purpose of saferproducts.gov was not clear based on its name and the initial information on the home page .

in our testing sessions , roughly a third of the consumers commented that the name of the website — saferproducts.gov — and the home page did not accurately convey what consumers could and could not do on the site .

for example , when asked about their impressions of saferproducts.gov , over a quarter of the testers thought that they would find information about safe products , such as a list of products that meet certain standards or a rating of products .

these consumers did not appear to notice information on the home page indicating that they would only find information on unsafe products ( see fig .

7 ) .

in our testing sessions , several consumers commented that the website would be more aptly named unsafeproducts.gov .

in addition , during our one - on - one testing sessions in washington , d.c. , two of the testers had difficulty distinguishing between recall notices and incident reports , which serve likewise , although the expert evaluator from gsa different purposes.was able to obtain a general sense of the purpose of the site , he noted that a tagline ( brief text that gives users an immediate idea of what the site does ) would help reinforce the site's purpose .

in one testing session , a few consumers also said that it was not apparent from looking at the home page that cpsc did not regulate certain categories of products , such as automobiles and medications , although more than half of the consumers in our testing sessions said at the outset that they routinely searched online for safety information on particular products .

similarly , none of the consumers in our testing sessions noticed that they could be directed to the agency's main site , cpsc.gov , by clicking on certain links in saferproducts.gov .

only the expert evaluator noticed that by opening a recall notice , the website user would leave saferproducts.gov and go to cpsc.gov .

however , as consumers completed the various tasks in the testing sessions , they better understood the website's features and functions .

in responding to our closing questions about their overall experiences in using the site , most said that they would use saferproducts.gov again now that they were aware of it .

for example , some consumers found information about product recalls the most useful component of the site and said they would give more weight to this information .

in our testing sessions , about one - quarter of the consumers also found value in the incident reports , noting that they helped website users understand whether products that had not yet been recalled had safety issues .

two of the consumers commented that they found the content of the reports to be more credible than other websites that provide a forum for consumer complaints .

in addition , a few consumers pointed to the amount of detail in the reports , such as the incident description , location , and date as particularly helpful .

nevertheless , because of the usability issues in the areas we identified ( for example , not having a clear and “up - front” statement of what the site contains and how it can be used ) , consumers may not use all of the site's available features and be dissuaded from completing and submitting reports .

cpsc officials also acknowledged that awareness of the agency could be heightened if consumers were informed about cpsc while using or searching saferproducts.gov .

cpsc has used many approaches to inform the public about saferproducts.gov , employing many key practices of consumer education planning in the process .

incorporating the promotion of saferproducts.gov into its broader effort to increase awareness of the agency has represented a logical approach that has prevented duplication .

however , our work confirms cpsc's perception that public awareness of saferproducts.gov is likely low .

for example , none of the participants in our usability tests had heard of saferproducts.gov prior to the testing .

although cpsc has employed many of the key practices for consumer education planning , it has not established metrics to measure the success of its efforts .

by establishing such metrics , the agency would be better able to determine which of its outreach efforts had the most impact on increasing awareness and use of the site and thus could more effectively target its limited resources to increase use of the site .

in addition to establishing and using metrics , more data about the use of saferproducts.gov could help cpsc target its marketing and outreach .

currently , cpsc collects limited data about the use of saferproducts.gov .

for example , it collects data on the number of visitors , but not whether they are using the site to search for information — one of the main functions of the site .

it also does not collect demographic data about the users' age , gender , or income .

these types of data could help cpsc identify groups , populations , or areas on which to focus to further increase use of the site .

our usability testing with consumers identified other ways in which cpsc may increase the use of saferproducts.gov .

although our testing revealed that many consumers found the site generally easy to use , it also revealed that certain search functions , site registration , and lack of a clear statement of purpose posed challenges for some users .

by improving the site in these areas , cpsc could help ensure that consumers take advantage of all the features of the site and are able to search for and report information in an easy and convenient manner .

making these improvements also may provide cpsc with additional reports from consumers to inform its safety assessments and other regulatory efforts .

to improve the awareness , use , and usefulness of saferproducts.gov , cpsc should take the following three actions: establish and incorporate metrics to assess efforts to increase awareness and use of saferproducts.gov , look for cost - effective ways of gathering additional data about the users and their use of saferproducts.gov , and implement cost - effective usability improvements to saferproducts.gov , taking into account the results of any existing usability testing or any new testing cpsc may choose to conduct .

we provided a draft of this report to cpsc for review and comment .

in commenting on the draft report , the chairman and commissioners stated that they support the report's recommendations .

specifically , they stated that cpsc staff will look for cost - effective ways to improve awareness of saferproducts.gov , improve the usability of the site based on research on best practices in web design , and gather additional metrics about users .

the chairman and commissioners' comments are reprinted in appendix iii .

cpsc also provided technical comments that we incorporated in the report as appropriate .

we are sending copies of this report to interested congressional committees and to the chairman and commissioners of cpsc .

in addition , the report will be available at no charge on gao's website at http: / / www.gao.gov .

if you or your staff members have any questions about this report , please contact me at ( 202 ) 512-8678 or cackleya@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iv .

the objectives of our report were to examine ( 1 ) the consumer product safety commission's ( cpsc ) efforts to inform the public about saferproducts.gov , ( 2 ) who has been using the website and to what extent , and ( 3 ) the extent to which consumers have found the website to be useful .

for the first objective , we reviewed cpsc marketing , budget , evaluation , and planning documents to determine the status of the agency's public information efforts related to saferproducts.gov .

we sought to determine whom cpsc had been targeting ; how , if at all , the agency was evaluating the outcomes of its efforts ; and any future plans to promote awareness and use of the site .

we compared cpsc's efforts with criteria on key practices for consumer education planning .

we interviewed consumer product safety experts from nine groups representing consumers , researchers , and various industries to determine what additional steps , if any , cpsc could take to better inform the public about saferproducts.gov .

we identified these experts through our prior work or based on recommendations from those we interviewed .

for context , we interviewed an official in cpsc's office of communications and reviewed cpsc's strategies to increase awareness of the agency as a whole .

see gao - 12-30 .

reliability and determined that , for the purposes of this report , the data were sufficiently reliable .

we did not review specific incident descriptions that individuals filed and do not attest to the reliability of that information .

for the third objective , we conducted website usability tests with 37 consumers — who represented a mix of demographic characteristics in terms of age , gender , and educational level — to obtain their views on how easy it was to use saferproducts.gov and how useful they found the website .

we conducted the tests in washington , d.c. , dallas , texas , and san francisco , california .

we chose these locations for geographic dispersion and ease of testing .

we followed the protocols and used the washington , d.c. facilities of the general services administration ( gsa ) for our testing conducted through the first fridays usability testing program .

at this location , gsa recruited three volunteer testers on our behalf .

consistent with the gsa program protocols , a moderator facilitated the testers' execution of various website tasks , such as searching for recalled products and submitting mock incident reports .

we followed similar protocols in san francisco and dallas .

to identify the participants in san francisco and dallas , we worked with a contractor to recruit prospective testers who had a mix of demographic characteristics .

we held two focus groups in each location , for a total of four groups .

two groups had eight participants per group and the other two groups had nine participants per group .

in all four groups , a moderator facilitated the testers' execution of various tasks , as was done in washington , d.c .

although the results of our usability tests are not generalizable to all u.s. consumers , they provided us with in - depth , interactive feedback and detailed perspectives from a range of website users about the usability challenges associated with saferproducts.gov .

to supplement our approach , we requested and reviewed an expert evaluation conducted by the first fridays program manager .

the gsa official evaluated saferproducts.gov based on the following criteria: ( 1 ) accessibility — the ability of people with physical or mental disabilities to use the site ; ( 2 ) identity and purpose — whether the site clearly presents its purpose , including what the site offers and what a user can do on it ; ( 3 ) clarity — the ability to read and digest content ; ( 4 ) navigation — how easily users can find information ; and ( 5 ) design and content — focusing on the layout , headers , and design .

another gsa official provided a more in - depth accessibility review of saferproducts.gov to identify issues that users with disabilities might encounter when navigating the site .

according to gsa , although an expert evaluation can be a useful starting point for determining a website's usability strengths and weaknesses , the expert evaluation emphasizes the importance of the user experience .

in addition , we reviewed various other website usability resources and criteria , including usability.gov , to understand the key practices for making websites easy to use and helpful .

we conducted this performance audit from july 2012 to march 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the individual named above , debra johnson , assistant director ; meghana acharya ; mark bird ; william carrigg ; jeremy cluchey ; meredith graves ; ronald ito ; sarah kaczmarek ; may lee ; marc molino ; patricia moye ; barbara roesmann ; andrew stavisky ; and julie trinder made key contributions to this report .

