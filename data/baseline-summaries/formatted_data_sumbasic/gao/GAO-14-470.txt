the department of defense ( dod ) invests billions of dollars annually to develop and implement enterprise resource planning ( erp ) systems , which it considers critical to transforming the department's business operations and addressing some of its long - standing weaknesses , including those related to financial management and business systems modernization .

dod officials have stated that the implementation of the erps , such as the global combat support system - army ( gcss - army ) , is a key component to the department's goal of correcting financial management deficiencies and ensuring that its financial statements are validated as audit ready by september 30 , 2017 , as called for by the national defense authorization act for fiscal year 2010 .

dod's business systems modernization program has been on gao's high - risk list since 1995 because of the size , complexity , and significance of the related efforts .

in october 2010 , we reported that the army did not fully follow best practices in developing a reliable schedule or cost estimate for gcss - army .

specifically , the army had not developed a fully integrated master schedule that reflected all activities , including government and contractor activities .

having such a schedule is crucial to the army's ability to reliably estimate the program completion date .

also , the army did not perform a sensitivity analysis for the cost estimate , which would have helped decision makers in determining how changes to assumptions or key cost drivers could affect the credibility of the cost estimate .

to support congress's continuing oversight of dod's progress in implementing its erp systems , you asked us to review the schedule and cost estimates for selected dod erp systems .

the objective of this review was to determine the extent to which the schedule and cost estimates for gcss - army were prepared consistent with gao's schedule and cost guides .

we reviewed the most current gcss - army schedule and cost estimates available at the time of our review , which supported dod's december 2012 full deployment decision .

we assessed the gcss - army schedule that supported dod's december 2012 full deployment decision using the gao schedule guide to determine whether it was comprehensive , well - constructed , credible , and controlled .

to assess the schedule , we obtained and reviewed documentation , including the integrated master plan , work breakdown structure , and statement of work .

to assess the program's cost estimate , we used the gao cost guide to evaluate the gcss - army program management office's estimating methodologies , assumptions , and results to determine whether the cost estimate was comprehensive , well - documented , accurate , and credible .

we obtained and reviewed documentation , including the program office estimate , software cost model , independent cost estimate , and risk and uncertainty analysis .

we also met with key program officials , such as the program manager , lead schedulers , and cost estimators to present the preliminary results of our assessment of the program's schedule and cost estimates best practices and obtained explanations and clarifications .

we conducted this performance audit from october 2011 to september 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

gcss - army was initiated in december 2003 and is intended to provide all active army , national guard , and army reserve tactical units with the capability to track supplies , spare parts , and organizational equipment .

the system is also intended to track unit maintenance , total cost of ownership , and other financial transactions related to logistics for all army units — about 160,000 users .

gcss - army is intended to integrate approximately 40,000 local supply and logistics databases into a single , enterprise - wide system .

in december 2012 , the under secretary of defense for acquisition , technology and logistics granted full deployment decision approval for gcss - army to be deployed to all remaining locations beyond the limited fielding locations of the life - cycle acquisition process .

dod officials reported that the gcss - army full deployment will be completed by the fourth quarter of fiscal year 2017 .

gcss - army program functionality is intended to be implemented across the army in two waves — the first is to include two releases and is to provide supply ( warehouse ) and financial reporting capabilities , and the second is to include one release , which is to provide property book and maintenance capabilities .

dod has approved the funding for the army to proceed with the deployment of the gcss - army functionality to all intended locations .

this funding is approximately $3.7 billion .

the army reported that it had spent about $1.6 billion as of june 30 , 2014 .

in october 2010 , we reported that the army did not fully follow best practices in developing a reliable schedule and cost estimate for implementing gcss - army .

in particular , the army had not developed a fully integrated master schedule that reflected all government and contractor activities and had not performed a sensitivity analysis for the cost estimate .

we recommended that the army develop an integrated master schedule that fully incorporated best practices , such as capturing all activities , sequencing all activities , integrating activities horizontally and vertically , establishing the critical path for all activities , and conducting a schedule risk analysis .

in addition , we recommended that the army update the cost estimate by using actual costs and preparing a sensitivity analysis .

dod concurred with our recommendations , and this report provides the status of the department's efforts to address our prior recommendations .

in march 2009 , we published the cost guide to address a gap in federal guidance about processes , procedures , and practices needed to ensure reliable cost estimates .

the cost guide provides a consistent methodology based on best practices that can be used across the federal government to develop , manage , and evaluate capital program cost estimates .

the methodology is a compilation of characteristics and associated best practices that federal cost estimating organizations and industry use to develop and maintain reliable cost estimates throughout the life of an acquisition program .

in may 2012 , we issued an exposure draft of the schedule guide as a companion to the cost guide .

a consistent methodology for developing , managing , and evaluating capital program cost estimates includes the concept of scheduling the necessary work to a timeline , as discussed in the cost guide .

simply put , schedule variances are usually followed by cost variances .

because some program costs , such as labor , supervision , rented equipment , and facilities , cost more if the program takes longer , a reliable schedule can contribute to an understanding of the cost impact if the program does not finish on time .

in addition , management tends to respond to schedule delays by adding more resources or authorizing overtime .

further , a schedule risk analysis allows for program management to account for the cost effects of schedule slippage when developing the life - cycle cost estimate .

a cost estimate cannot be considered fully credible if it does not account for the cost effects of schedule slippage .

we found that the program schedule and cost estimates for the gcss - army did not fully meet best practices .

specifically , the gcss - army schedule supporting the december 2012 full deployment decision partially met the comprehensiveness and construction characteristics and substantially met the credibility and control characteristics for developing a high - quality and reliable schedule .

in addition , the cost estimate fully met the comprehensiveness characteristic , substantially met the documentation and accuracy characteristics , and partially met the credibility characteristic for developing a high - quality and reliable cost estimate .

it is important that the schedule and cost estimates are continually updated throughout the program's life cycle so that management has the best information available to make decisions .

by incorporating best practices for developing reliable schedule and cost estimates , dod would increase the probability of gcss - army successfully achieving full deployment by the fourth quarter of fiscal year 2017 to provide needed functionality for financial improvement and audit readiness .

our analysis found that the gcss - army program substantially met two and partially met the other two characteristics of a reliable schedule estimate and therefore did not provide the information needed to support the december 2012 full deployment decision ( see table 1 ) .

appendix i contains our detailed analysis of the gcss - army schedule estimate .

the success of any program depends on having a reliable schedule of the program's work activities that will occur , how long they will take , and how the activities are related to one another .

as such , the schedule not only provides a road map for systematic execution of a program , but also provides the means by which to gauge progress , identify and address potential problems , and promote accountability .

comprehensive .

a schedule should reflect all activities as defined in the program's work breakdown structure , including activities to be performed by the government and the contractor ; the resources ( eg , labor , materials , and overhead ) needed to complete each activity ; and how long each activity will take .

we found that the gcss - army schedule partially met the comprehensive characteristic .

the schedule used to support the full deployment decision reflected all activities to be performed by both the government and contractor for the program .

however , resources were not loaded into the schedule software and were not assigned to specific activities in the schedule .

gcss - army program management officials told us that the contractor used a separate system outside the schedule to manage the resources needed for the program .

information on resource needs and availability in each work period assists the program office in forecasting the likelihood that activities will be completed as scheduled .

if the current schedule does not allow insight into the current or projected allocation of resources , the risk of the program's schedule slipping is significantly increased .

our analysis also determined that activity durations were not manageable and reasonably estimated in the schedule .

we found that 30 percent of the remaining activities in the schedule exceeded the standard best practice for activity duration , which should be shorter than approximately 44 working days , or 2 working months .

for example , audit support activities had durations over 100 working days .

durations should be as short as possible to facilitate the objective measurement of accomplished effort .

if activities are too long , the schedule may not have enough detail for effective progress measurement and reporting .

well - constructed .

a schedule should be planned so that critical project dates can be met .

to meet this objective , all activities should be logically sequenced — that is , listed in the order in which they are to be carried out .

in particular , activities that must finish prior to the start of other activities ( i.e. , predecessor activities ) , as well as activities that cannot begin until other activities are completed ( i.e. , successor activities ) , should be identified and their relationships established .

the schedule should identify the project's critical path .

establishing a valid critical path is necessary for examining the effects of any activity slipping along this path .

the calculation of a critical path determines which activities drive the project's earliest completion date .

the schedule should also identify total float so that the schedule's flexibility can be accurately determined .

we found that the gcss - army schedule was partially well - constructed .

the majority of logic used to sequence the activities within the schedule was generally error free , clearly indicating to program management the order of activities that must be accomplished .

however , the schedule's critical path was not valid because it included level of effort activities and date constraints .

level of effort activities , such as program management , should not define the critical path because they are nondiscrete support activities that do not produce a definite end product ; therefore , level of effort activities cannot determine the length of the project .

in addition , date constraints prevent the critical path from being a continuous sequence of events from the current to finish dates of the project .

rather than relying on such constraints , the schedule should use logic and durations in order to reflect realistic start and completion dates for activities .

successfully identifying the critical path relies on several factors , such as capturing all activities ; properly sequencing activities ; and assigning resources , which , as noted earlier , had not been completely done .

without a valid critical path , management cannot focus on activities that will have detrimental effects on the key project milestones and deliverables if they slip .

further , our analysis found that 28 percent of remaining schedule activities had more than 100 working days of total float , meaning that those activities could slip almost 5 working months and not affect the estimated finish date of the program .

based on the remaining duration of the program , 100 working days of float would not appear to be reasonable .

the gcss - army program management office stated that total float was not reliable at the time of the full deployment decision because the schedule was being updated to reflect a modification to the system .

without accurate values of total float for a program activity , management cannot determine the flexibility of tasks and therefore cannot properly reallocate resources from tasks that can safely slip to tasks that cannot slip without adversely affecting the estimated program completion date .

credible .

a schedule should be horizontally and vertically integrated .

a horizontally integrated schedule links products and outcomes with other associated sequenced activities , which helps verify that activities are arranged in the right order to achieve aggregated products or outcomes .

a vertically integrated schedule ensures that the start and completion dates for activities are aligned with such dates on subsidiary schedules supporting tasks and subtasks .

a schedule risk analysis should also be performed using statistical techniques to predict the level of confidence in meeting a program's completion date .

we found that the gcss - army schedule was substantially credible .

the schedule was substantially horizontally integrated , which means that outcomes were aligned with sequenced activities .

the schedule was also substantially vertically integrated ; we were able to trace varying levels of activities and supporting subactivities .

such mapping or alignment among subsidiary schedules enables different groups — such as government teams and contractors — to work to the same master schedule , and provides assurance that the representation of the schedule to different audiences is consistent and accurate .

however , our analysis found that a schedule risk analysis had not been fully conducted .

gcss - army program management officials provided documentation for a schedule risk analysis , but we noted that risk analyses were not performed for all supporting activities because program management officials stated that the program fielding schedule was not finalized at the time of the full deployment decision .

if a schedule risk analysis is not conducted , program management cannot determine ( 1 ) the likelihood that the project completion date will occur , ( 2 ) how much schedule risk contingency is needed to provide an acceptable level of certainty for completion by a specific date , ( 3 ) risks most likely to delay the project , ( 4 ) how much contingency reserve each risk requires , and ( 5 ) the activities that are most likely to delay the project .

controlled .

a schedule should be continually updated using logic , durations , and actual progress to realistically forecast dates for program activities .

a schedule narrative should accompany the updated schedule to provide decision makers and auditors a log of changes and their effect , if any , on the schedule time frame .

the schedule should be analyzed continually for variances to determine when forecasted completion dates differ from planned dates .

this analysis is especially important for those variations that affect activities identified as being in a program's critical path and that can affect a scheduled completion date .

a baseline schedule should be used to manage the program scope , the time period for accomplishing it , and the required resources .

we found that the gcss - army schedule was substantially controlled .

gcss - army program management officials stated that they met weekly to discuss proposed schedule changes and update the schedule's progress , and management also prepared a schedule narrative document that contained a list of custom fields and assumptions .

in addition , we found no anomalies throughout the schedule ( eg , activities with planned start dates scheduled to occur in the past and activities with actual finish dates scheduled to occur in the future ) .

however , we found that there was not a documented baseline schedule to measure program performance against , which would allow management to monitor any schedule variances that affect the completion of work .

without a formally established baseline schedule to measure performance against , management cannot identify or mitigate the effect of unfavorable performance .

in our october 2010 report , we recommended that the army develop an integrated master schedule that fully incorporated best practices , such as capturing all activities , sequencing all activities , integrating activities horizontally and vertically , establishing the critical path for all activities , and conducting a schedule risk analysis .

the army's december 2012 gcss - army schedule used to support the full deployment decision addressed several of the best practices that were an issue in our prior report , including capturing all activities , sequencing all activities , and integrating activities horizontally and vertically .

however , as discussed , we continued to identify several best practices that were not yet fully addressed and also identified several new areas where the 2012 schedule did not incorporate best practices , such as activity durations and baseline schedule .

although gcss - army is in full deployment , without fully addressing best practices for scheduling , program managers will not have the best information available to make decisions related to issues such as the sequencing of activities and the flexibility of the schedule according to available resources .

we found that the gcss - army program fully met one , substantially met two , and partially met one of the characteristics of a reliable cost estimate and therefore did not provide the information needed to support the full deployment decision , as shown in table 2 .

appendix ii contains our detailed analysis of the gcss - army cost estimate .

a reliable cost estimate is critical to the success of any program and is updated continually throughout its life cycle .

such an estimate provides the basis for informed investment decision making , realistic budget formulation and program resourcing , meaningful progress measurement , proactive course correction when warranted , and accountability for results .

comprehensive .

a cost estimate should include costs of the program over its full life cycle , provide a level of detail appropriate to ensure that cost elements are neither omitted nor double - counted , and document all cost - influencing ground rules and assumptions .

the cost estimate should also completely define the program and be technically reasonable .

we found that the cost estimate for gcss - army was fully comprehensive .

the cost estimate included both government and contractor costs of the program over its life cycle — from the inception of the program through design , development , deployment , and operation and maintenance .

the cost estimate also included an appropriate level of detail , which provided assurance that cost elements were neither omitted nor double - counted , and included documentation of all cost - influencing ground rules and assumptions .

the cost estimate documentation included the purpose of the cost estimate , a technical description of the program , and technical risks ( eg , the resolution for any identified deficiencies ) .

well - documented .

a cost estimate should be supported by detailed documentation that describes how it was derived and how the expected funding will be spent in order to achieve a given objective .

the documentation should capture such things as the source data used , the calculations performed , the results of the calculations , the estimating methodology used to derive each work breakdown structure element's cost , and evidence that the estimate was approved by management .

the documentation should discuss the technical baseline description , and the data in the technical baseline should be consistent with the cost estimate .

we found that the cost estimate for gcss - army was substantially well - documented .

the cost estimate captured such things as the calculations performed to derive each element's cost and the results of the calculations .

the documentation also included a technical baseline description that provided data consistent with the cost estimate .

further , the gcss - army program management office presented evidence of receiving approval of the estimate through briefings to management .

although program management officials did not provide us with written documentation of the source data , the office of the deputy assistant secretary of the army for cost and economics ( dasa - ce ) did provide us with a full deployment decision briefing , which showed each major cost element and listed the methodology and sources of the data .

however , the briefing documents included a limited amount of the actual source data , and we could not determine their reliability .

without sufficient background information about the source data and reliability of the data , the gcss - army cost estimator cannot know with any confidence whether the data collected can be used directly or need to be modified before use in the cost estimate .

accurate .

a cost estimate should provide for results that are unbiased , are not overly conservative or optimistic , and contain no major mistakes .

a cost estimate should be based on an assessment of most likely costs ( adjusted properly for inflation ) , updated to reflect significant changes and grounded in a historical record of cost estimating and actual experiences on other comparable programs .

in addition , variances between planned and actual costs should be documented , explained , and reviewed , and estimating techniques for each cost element should be used appropriately .

we found that the cost estimate for gcss - army was substantially accurate .

the gcss - army cost model detailed the inflation indexes and properly applied the indexes to each relevant cost element and included time phasing of the costs .

the gcss - army cost model did not include any major mistakes , and all its cost elements summed up properly and were consistent with the cost estimate .

in addition , the estimating techniques ( i.e. , engineering build - up ) used to create the estimate were used appropriately .

the cost model documentation did not explain whether the cost estimate was updated to reflect changes in technical or program assumptions .

the program management officials provided documentation that reflected the technical changes for the major deployment decisions , but the documentation did not include details on how the costs were updated .

unless such documentation is available to verify that the cost estimate is properly updated on a regular basis , management will not have reasonable assurance that the cost estimate provides accurate information to make informed decisions about the program .

credible .

a cost estimate should discuss any limitations of the analysis because of uncertainty or biases surrounding data or assumptions .

the cost estimate should include a sensitivity analysis that identifies a range of possible costs based on varying major assumptions and data .

a risk and uncertainty analysis should be conducted to determine the level of risk associated with the cost estimate and identify the effects of changing key cost driver assumptions and factors .

in addition , the estimate's results should be cross - checked and reconciled to an independent cost estimate to determine whether other estimating methods produce similar results .

we found that the cost estimate was partially credible .

the army cost review board developed an independent cost estimate that was reconciled to the program management officials' cost estimate .

the program management officials' cost estimate mentioned results of a risk analysis ; however the risk and uncertainty analysis was not documented .

further , since the cost estimate that was provided discussed risk only at a summary level , it is unclear how management considered risk related to the program .

without a fully documented risk and uncertainty analysis , the estimate will lose credibility and management's decision - making ability will be impaired because it will not know the level of confidence associated with achieving the cost estimate .

in addition , program management officials provided a cost estimate that identified major cost drivers , including system deployment and training .

the cost estimate documentation contained a reference that a sensitivity analysis was completed on these cost drivers , but results of this analysis were not documented .

as a result , the gcss - army cost estimator will not have a clear understanding of how each major cost driver is affected by a change in a single assumption and thus which cost driver most affects the cost estimate .

further , gcss - army program officials provided us with one example of evidence that indicated that some cross - checking was performed using cost models ; however , the results of this cross - checking were not documented .

the purpose of cross - checking is to determine whether alternative methods would produce similar results , which would increase the credibility of the estimate .

in our october 2010 report , we recommended that the army update the gcss - army cost estimate by using actual costs and preparing a sensitivity analysis .

for the 2012 cost estimate , we found that the army had made progress , but we continued to identify deficiencies in documentation related to the sensitivity analysis , risk and uncertainty analysis , and cross - checking of major cost elements for reasonableness .

while the army made some improvements to the schedule and cost estimates that supported the full deployment decision , the army did not fully meet best practices in developing schedule and cost estimates for the gcss - army program .

the army made progress in incorporating schedule best practices , such as capturing and sequencing all activities and integrating activities horizontally and vertically , but we identified other deficiencies in schedule and cost best practices .

for example , gcss - army did not meet best practices related to schedule durations , a valid critical path , and a cost sensitivity analysis .

it is critical to correct the deficiencies identified with the schedule and cost estimates to help ensure that the projected spending for this program is being used in the most efficient and effective manner .

by incorporating best practices for developing reliable schedule and cost estimates , dod would increase the probability of gcss - army successfully achieving full deployment by the fourth quarter of fiscal year 2017 to provide needed functionality for financial improvement and audit readiness .

to help improve the implementation of gcss - army , we recommend that the secretary of the army take the following two actions: ensure that the under secretary of the army , in his capacity as the chief management officer , directs the gcss - army program management office to develop an updated schedule that fully incorporates best practices , including assigning resources to all activities , establishing durations of all activities , confirming that the critical path is valid , and ensuring reasonable total float .

ensure that the under secretary of the army , in his capacity as the chief management officer , directs the gcss - army program management office to update the cost estimate to fully incorporate best practices by documenting the results of a risk and uncertainty analysis , the cross - checking of major cost elements to see if results are similar , and a sensitivity analysis .

we provided a draft of this report to dod for review and comment .

in its written comments , reprinted in appendix iii , dod concurred with our recommendation to update the schedule to fully incorporate best practices and described planned and ongoing actions that the department is taking to address the recommendation .

in particular , dod indicated that the army has taken steps to help ensure that ( 1 ) all activities are assigned resources in the schedule software , ( 2 ) all schedule activities with long durations have been detailed , ( 3 ) level of effort activities and date constraints have been removed from the schedule so that they do not define the critical path , and ( 4 ) the majority of the schedule activities associated with high total float have been removed .

if effectively implemented , these actions should address the intent of our recommendation .

dod also concurred with our recommendation to update the cost estimate to fully incorporate best practices by documenting the results of a risk and uncertainty analysis , the cross - checking of major cost elements to see if results are similar , and a sensitivity analysis .

dod described completed actions that the department has taken to address the recommendation .

dod stated that gcss - army achieved milestone c in august 2011 and a full deployment decision in december 2012 , and that it prepared a cost estimate per dod acquisition rules and guidelines .

dod also stated that the army ( 1 ) followed all army directed best practices and approvals from the office of the deputy assistant secretary of the army for cost and economics and ( 2 ) prepared a sensitivity analysis , a risk analysis , and cross - checked major cost elements for similar results , but that those documented analyses and results were not included in the formal cost estimates as directed by the army .

dod commented that these documented analyses and results are part of the formal working papers and were provided to gao in february 2013 .

however , these actions do not fully address the intent of our recommendation .

as stated in our report , we focused on the extent to which gcss - army's schedule and cost estimates were prepared consistent with gao's schedule and cost guides .

we reviewed the cost estimate documentation provided by the army in february 2013 and additional information provided in february 2014 and determined that the documentation did not fully meet best practices for a risk and uncertainty analysis , a sensitivity analysis , and cross - checking of major cost elements for similar results .

as stated in our report , gcss - army program management officials provided a cost estimate that mentioned the results of a risk and uncertainty analysis , and contained a reference that a sensitivity analysis was completed .

also , gcss - army program management officials provided us with one example of evidence that indicated some cross - checking was performed using cost models .

however , the results of the risk and uncertainty and sensitivity analyses , as well as the cross - checking were not documented consistent with best practices .

as stated in our report , incorporating best practices for a reliable cost estimate would help ensure that dod has a reliable cost estimate that provides the basis for effective resource allocation , proactive course correction when warranted , and accountability for results .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the appropriate congressional committees ; the secretary of defense ; the secretary of the army ; the assistant secretary of defense ( acquisition ) ; the acting deputy chief management officer ; the under secretary of defense ( comptroller ) ; the under secretary of the army , in his capacity as the chief management officer of the army ; and the program manager for gcss - army .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staffs have any questions about this report , please contact asif a. khan at ( 202 ) 512-9869 or khana@gao.gov or nabajyoti barkakati at ( 202 ) 512-4499 or barkakatin@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff members who made key contributions to this report are listed in appendix iv .

this appendix provides the results of our analysis of the extent to which the global combat support system - army schedule supporting the december 2012 full deployment decision met the characteristics of a high - quality , reliable schedule .

table 3 provides the detailed results of our analysis .

gao's methodology includes five levels of compliance with its best practices .

“not met” means the program provided no evidence that satisfies any of the criterion .

“minimally met” means the program provided evidence that satisfies a small portion of the criterion .

“partially met” means the program provided evidence that satisfies about half of the criterion .

“substantially met” means the program provided evidence that satisfies a large portion of the criterion .

“fully met” means the program provided evidence that completely satisfies the criterion .

this appendix provides the results of our analysis of the extent to which the global combat support system - army cost estimate supporting the december 2012 full deployment decision met the characteristics of a high - quality cost estimate .

table 4 provides the detailed results of our analysis .

gao's methodology includes five levels of compliance with its best practices .

“not met” means the program provided no evidence that satisfies any of the criterion .

“minimally met” means the program provided evidence that satisfies a small portion of the criterion .

“partially met” means the program provided evidence that satisfies about half of the criterion .

“substantially met” means the program provided evidence that satisfies a large portion of the criterion .

“fully met” means the program provided evidence that completely satisfies the criterion .

in addition to the contacts named above , arkelga braxton ( assistant director ) , karen richey ( assistant director ) , beatrice alff , tisha derricotte , jennifer echard , emile ettedgui , patrick frey , and jason lee made key contributions to this report .

