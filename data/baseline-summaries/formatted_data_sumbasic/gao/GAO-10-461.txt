for decades , the department of defense ( dod ) has been challenged in modernizing its business systems .

in 1995 , we designated dod's business system modernization program as high risk , and continue to do so because these systems are fundamental to addressing long - standing weaknesses related to the management of contracts , finance , and the supply chain .

moreover , we continue to report on business system investments that fail to effectively deliver promised benefits and capabilities on time and within budget .

organizations that implement enterprise resource planning systems have faced substantial challenges because of the complexity of the endeavor , and the army is no exception .

in 1998 , the army initiated the logistics modernization program ( lmp ) in order to replace two aging army systems used to manage its inventory and its repair operations at the depots .

lmp was originally scheduled to be completed by 2005 , but the army delayed fielding lmp because of the significant problems faced by the first deployment sites — the communications - electronics command and tobyhanna army depot — in july 2003 , which we detailed in several reports .

the army has since determined that fielding of lmp would occur in two additional phases of deployment: the aviation and missile command in 2009 , which includes corpus christi army depot and letterkenny army depot , and the tank - automotive and armaments command , the joint munitions and lethality command , and the army sustainment command in october 2010 .

through 2009 , the army has obligated more than $1 billion to implement lmp , and estimates a total life cycle cost in excess of $2.6 billion to procure and operate the system .

the army expects that lmp will reduce redundant and stove piped information technology investments and assist in driving business transformation across the army , which will enable the army to supply and service the warfighter more quickly and cost effectively .

we previously assessed the army's preparation for the second deployment of lmp and reported that the army had begun to implement our prior recommendations related to past issues on data conversion , billing and collection , requirements management and testing , and independent verification and validation .

we also reported that the army had implemented critical project management processes and controls that enabled the army to identify and understand the risks associated with making a deployment decision .

we further noted that these critical management processes — which addressed data conversion from legacy systems to lmp , training lmp users , and the ability to rapidly evaluate and respond to potential issues — were absent during the first deployment of lmp at tobyhanna army depot .

however , the effectiveness of the army's management processes could not be evaluated until the second deployment had occurred on may 14 , 2009 .

you asked us to continue monitoring the army's efforts to deploy lmp and evaluate the army's progress in addressing the issues that are critical to successful implementation .

you also asked us to monitor the actions taken by the army after the system has been deployed to ensure that its stated processes are adequate and have been effectively implemented .

accordingly , the objective of this review was to evaluate the effectiveness of the army's management processes in enabling the second deployment sites to realize the full benefits of lmp .

to address this objective , we reviewed and analyzed the army plans and policies that governed lmp implementation .

we obtained briefings from the lmp program management office on the intended purpose of lmp , as well as information related to the execution of the second deployment .

we also monitored the second deployment of lmp as it occurred and had personnel observing operations at corpus christi army depot , texas ; letterkenny army depot , pennsylvania ; and the lmp program management office's command center in marlton , new jersey .

we met with officials at each location to discuss how they were using lmp to perform their missions and attended and observed daily meetings held by each location and among the locations where they discussed issues that had arisen and the actions they were taking to resolve the issues .

after the initial deployment , we conducted follow - up visits to corpus christi army depot and letterkenny army depot to monitor the progress of implementation .

we also met with officials at the army materiel command , the aviation and missile command , and the lmp program management office to discuss how the army was managing the implementation and using the system .

lastly , we met with lmp program management officials to discuss plans for the third deployment of lmp scheduled to occur in october 2010 .

we conducted this performance audit from may 2009 through march 2010 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in february 1998 , the army materiel command began an effort to replace its existing materiel management systems — the commodity command standard system and the standard depot system — with lmp .

the army has used these existing systems for over 30 years to manage inventory and depot maintenance operations .

lmp is intended to transform the army's logistics operations in six core processes: order fulfillment , demand and supply planning , procurement , asset management , materiel maintenance , and financial management .

if effectively implemented , lmp is expected to provide the army benefits associated with commercial best practices , such as inventory reduction , improved repair cycle time , and increased response time .

additionally , lmp is intended to improve supply and demand forecast planning and maintenance workload planning and to provide a single source of data for decision making .

lmp became operational at the army communications - electronics command and tobyhanna army depot in july 2003 , and was originally expected to be fully deployed by fiscal year 2005 .

however , because of problems experienced at tobyhanna army depot , the army delayed implementation until the operational problems were resolved .

in may 2009 , lmp became operational at the army aviation and missile command and corpus christi and letterkenny army depots , and the third and final deployment of lmp is expected to occur in october 2010 at the army sustainment command , the joint munitions and lethality command , the tank - automotive and armaments command , and anniston and red river army depots .

when lmp is fully implemented , it is expected to include approximately 21,000 users at 104 locations across the globe ( see table 1 ) , and it will be used to manage more than $40 billion worth of goods and services , such as inventory managed at the national level and repairs at depot facilities .

according to lmp program management officials , preparations for the third deployment of lmp began in december 2008 .

in september 2009 , leaders from the third deployment sites formally established the executive steering committee to ensure a successful implementation of lmp during the third deployment .

the committee's responsibilities include reviewing plans and schedules , exchanging lessons learned , performing ongoing assessments of readiness to implement lmp , and making decisions on important issues .

as of january 2010 , lmp program management officials told us that several education courses had been completed and that the third deployment sites were in the process of completing their initial data conversion activities .

the army's management processes that were established prior to the second deployment of lmp were not effective in enabling the second deployment sites to realize the full benefits of lmp .

based on our observations , we found that data quality issues prevented personnel at corpus christ and letterkenny army depots from using lmp as envisioned .

the army acknowledged that data quality was one of the most important and challenging success factors in deriving the optimal business benefits from lmp .

at both depots , lmp users were unable to use lmp to conduct depot operations and inventory management functions immediately following the second deployment .

although the depots were able to continue to repair items and support the warfighter , lmp users had to rely on manual work - around processes , which are not part of how lmp is intended to function and hinder the army's ability to realize the benefits expected from lmp .

the depots experienced data quality issues , despite improvements the army made to address data quality issues experienced during the first deployment of lmp at tobyhanna army depot , because the army's testing strategy did not provide reasonable assurance that the data being used by lmp were accurate and reliable .

specifically , the army's testing strategy focused on determining whether the software worked as designed , but did not assess whether lmp was capable of functioning in a depot environment using the actual data from the depots .

additionally , the army's training strategy did not effectively provide users the skills necessary to perform all of their tasks in lmp .

users at the depots stated that the training they received before lmp became operational was not conducted in a realistic environment that showed them how to perform their expected duties .

however , users at both depots also stated that the lmp program management office had provided additional training after lmp became operational to address their concerns .

additionally , when monitoring lmp implementation at the second deployment sites , the army lacked a comprehensive set of metrics with which to accurately assess whether lmp was delivering the intended functionality .

instead , the metrics used by the lmp program management office focused on whether the software was working but did not measure whether the deployment sites were performing their day - to - day operations using lmp as envisioned .

despite these challenges , the second deployment sites reported achieving some benefits through the use of lmp , such as increased visibility over assets .

the army was unable to realize the full benefits of lmp at the second deployment sites because of data quality issues .

the benefits that lmp was expected to provide the depots included reducing the amount of time to repair items , automatically calculating the material requirements for repair projects , and improving the management of maintenance capacity .

however , the ability of the second deployment sites to realize these benefits depended on data quality , which according to the army , is one of the most important and challenging success factors in deriving optimal business benefits from an enterprise resource planning system like lmp .

in preparation for the second deployment , the army focused on addressing systemic data quality problems associated with the first deployment of lmp at tobyhanna army depot .

as we reported in june 2005 , lmp did not always contain the correct unit price or unit of issue for certain materials , resulting in excess material being ordered and incorrect prices being charged to jobs .

to avoid similar problems during the second deployment of lmp , the army developed processes to ensure that the unit of issue and unit of measure values shown for a given item were appropriate for that item .

according to lmp program management office officials , out of a target population of more than 12 million data records , 99.9 percent were loaded into lmp ( 12.40 million out of 12.41 million data records ) before the system became operational at the second deployment sites .

although the army's processes addressed some of the data issues from the first deployment of lmp , according to lmp program management office officials , these processes did not assess whether the overall quality of the data that the system would use was sufficient to support the lmp processes .

both corpus christi and letterkenny army depots experienced data quality issues that prevented the army from realizing the full benefits of lmp .

for example , during our visit to corpus christi army depot shortly after lmp became operational in may 2009 , we observed that personnel at the depot could not use lmp to induct a helicopter for repair because of data quality issues .

as a result , lmp could not automatically identify the materials needed to support the repair and ensure that parts would be available in time to support the repairs .

furthermore , labor rates were also missing for some stages of repair , thereby precluding lmp from computing the expected labor costs for a repair project .

users at corpus christi army depot addressed the data quality problems as they arose .

however , because of these data quality problems , some of the enterprise processes that lmp can perform had to be conducted using manual work - around processes to ensure that the depot accomplished its repair mission and thereby continued to meet the needs of the warfighter .

furthermore , these manual work - around processes are labor intensive and prevent the army from achieving the benefits that lmp is expected to provide , such as increasing the efficiency in ordering parts , determining whether sufficient funds are available to perform the expected work , and determining whether the production schedule could be achieved with existing resources .

letterkenny army depot also experienced issues with data quality .

for example , when we visited letterkenny army depot shortly after lmp became operational , depot officials told us that they had identified data quality errors when they attempted to induct a ground vehicle for the patriot system for repair .

letterkenny army depot officials also stated that prior to lmp becoming operational , they spent about 18 months rebuilding the data that were needed to perform repair and supply functions in lmp .

however , after lmp became operational , they realized that the data were not of sufficient quality to enable the depot to use lmp as envisioned , so letterkenny army depot officials took steps to correct the data .

during our subsequent visit to letterkenny army depot in august 2009 , depot officials stated that they were continuing to refine the data , and that they had nearly completed doing so for their most common repair item — the high mobility multi - purpose wheeled vehicle .

this refinement would then serve as a template for the remaining repair items .

officials at letterkenny army depot noted , however , that they had pre - positioned materials prior to the transition to lmp to ensure that the depot could perform its repair mission if difficulties arose , which enabled the depot to perform its day - to - day operations despite the data shortcomings .

nonetheless , officials at letterkenny army depot acknowledged that they were not using the preferred automated lmp processes as intended , and needed to use manual work - around processes to complete their tasks .

the army's testing strategy , as illustrated by the problems experienced at the second deployment locations , was not comprehensive enough to provide reasonable assurance that the data being used by lmp were accurate and reliable .

as we have previously reported , testing is a critical process utilized by organizations with the intent of finding errors before a system is implemented .

according to the army's master test plan for lmp implementation , the objective of system testing was to ensure that lmp operated as intended .

however , the army's testing efforts focused on determining whether the software worked as designed .

army officials stated that army testing efforts for the second deployment of lmp had incorporated lessons learned from the first deployment of lmp .

with respect to testing data conversion , the army noted two improvements in its testing process: the use of data - specific scenario testing and engaging users in critical business process tests .

according to the army's test plan , data - specific scenario tests were designed to assess the quality , validity , and integrity of the data to be migrated into lmp , as well as to validate that data migration processes function as designed .

additionally , critical business process tests , which were performed by users , involved the execution of business process - oriented scenarios using the data loaded into lmp with the intent of assessing the functional readiness of the software .

in order to assess the functional readiness of the software , the army used simulated test data to test the system .

for example , when assessing the functional readiness of the software to perform an induction of an item for repair , army officials told us that they did not attempt to induct an item for repair using the data loaded into lmp .

instead , the army tested whether lmp could perform an induction , and performed these tests using simulated data so that developers would know whether lmp could provide the intended capability .

while this approach is useful and desirable to determine whether the software can operate as expected , it does not assess whether the data are of sufficient quality to work in lmp .

thus , the first attempt to perform a process in lmp using actual data during the second deployment occurred when the depots attempted to use the system .

consequently , the army's testing strategy did not detect problems with the quality of the data at the deployment sites .

during lessons learned sessions held in june 2009 , army officials at the lmp program management office and at the second deployment sites acknowledged these weaknesses in their testing strategy .

army officials we interviewed also stated that testing needed to address whether the deployment sites could perform their work using the system as intended .

for example , officials at corpus christi army depot agreed that a better strategy to test whether lmp could perform as intended would be to induct a representative number of items at each depot using actual data from each deployment site .

by attempting to induct several items into the depot repair processes that are representative of the majority of their workloads prior to transitioning to lmp , the army would have likely detected problems related to data quality , which could have provided reasonable assurance that lmp could operate as intended if the tests were successful .

furthermore , by incorporating the use of actual data into its testing strategy , the army could have obtained reasonable assurance that the data loaded into lmp were of sufficient quality to be used and increased user confidence in the system .

for example , officials at letterkenny army depot told us that testing the system in a simulated environment with actual data would not only assess whether the system would work but also would gauge the effectiveness of training .

had the army's testing strategy used the actual data at the deployment locations , the army could have identified issues related to data quality prior to the transition to lmp .

although the army's training strategy was designed to provide lmp users the skills and knowledge to successfully perform their new roles , lmp users we interviewed at corpus christi and letterkenny army depots stated that the training they received prior to lmp becoming operational did not fully meet their needs .

lmp users we interviewed at corpus christi and letterkenny army depots stated that the training focused on what lmp was supposed to do rather than on how they were to use the system to perform their day - to - day missions .

additionally , because the duties of some lmp users at the depots were changing , the training users received was not always commensurate with the responsibilities they were assigned .

consequently , some lmp users told us that they did not always understand the actions they needed to perform in order to accomplish their assigned tasks .

furthermore , since the timeline for implementing the various lmp processes differed at each location , the training sometimes occurred weeks before it could be actually used , which resulted in users needing additional training after the system became operational .

despite these issues , lmp users at both depots stated that the additional training they received after lmp became operational was effective and addressed their needs .

according to the army's lmp end - user training and development delivery plan dated january 30 , 2009 , most implementation failures are caused by poor end user training , which is the transfer of knowledge to the end users who will run the enterprise with the new solution .

to prevent poor end user training , the army's plan stated that end user training must provide users not only with the transactions and tasks performed in lmp , but also with the ability to recognize the underlying flow of information through lmp .

to meet this goal , the army used a blended learning solution designed to provide lmp users with the skills , process knowledge , and performance support to successfully perform their new roles after the transition to lmp .

the army's plan also stated that training should occur as close as possible to the date of implementation because the user's ability to retain information diminishes each day the user is not able to put into practice the training he or she has received .

the army experienced challenges with the quality and timing of its education and training efforts .

according to the army , education focused on lmp concepts , while training demonstrated how the system should be utilized by the user .

however , according to army lessons learned documents , users received education on lmp concepts too far in advance of training , which limited the ability of lmp users to understand how the changes in the business processes that were to occur as a result of lmp implementation affected their job responsibilities .

additionally , lmp users we met at the depots questioned the overall quality of the training they received .

for example , these users stated that the instruction focused too much on concepts , rather than providing them the skills necessary to perform their day - to - day operations .

users also noted that they had limited opportunities to enhance their knowledge of the system by actually using the system in a training environment .

the army was also unable to deliver the correct training to some users because of challenges in properly assigning roles .

the army's plan for implementing lmp required not only the adoption of a new technological solution , but also required changes to the duty descriptions for some lmp users .

for example , prior to lmp implementation , production controllers at letterkenny army depot were responsible for tracking the flow of a repair item ; however , after lmp implementation , production controllers became asset managers , who were responsible not only for tracking the flow of the item through the repair process but also for ordering parts .

additionally , supervisors were generally responsible for assigning roles to their personnel , and based on these roles , users would receive training .

however , as noted in army lessons learned documents , the process for determining roles sometimes occurred before supervisors received any notable lmp education .

as a result , some users did not receive the correct training .

the army also faced challenges in its ability to deliver training as close as possible to the date of implementation because of the decentralized execution strategy at each deployment site .

in order to prepare users , the army used a master training calendar and standard training curriculum .

although this training was standardized across the second deployment sites , execution of lmp implementation was decentralized .

for example , after lmp implementation occurred on may 14 , 2009 , letterkenny army depot consolidated all of its production controllers into one area and began performing lmp functions in a phased approach .

in contrast , corpus christi army depot executed lmp implementation by attempting to perform all tasks shortly after the transition .

although each approach has merit , the approach used by letterkenny army depot did not match the army's approach to training .

that is , lmp users at letterkenny army depot only performed some of the lmp processes immediately after lmp became operational .

accordingly , some of the users at letterkenny army depot had to receive refresher training before they could perform their assigned duties .

despite the concerns that lmp users expressed about training , lmp users also stated that the army was able to successfully provide refresher training and ad hoc coursework to address their issues .

for example , lmp users we met with at both corpus christi and letterkenny army depots stated that these courses were effective because the content was focused and specific .

officials at both depots also stated that the contractor support personnel that the lmp program management office provided to assist each depot were also effective in providing information .

the army was unable to determine whether the second deployment sites had achieved the envisioned functionality of lmp because the army lacked a comprehensive set of metrics to measure the success of lmp implementation .

our previous work has shown that successful performance measures should be aligned throughout the organization and cover the activities that an entity is expected to perform to support the intent of the program .

however , based on our review of the second deployment of lmp , we determined that the army did not develop a comprehensive set of metrics .

as a result , the scorecards that the lmp program management office used to measure the progress of lmp implementation did not measure whether the deployment sites were performing their day - to - day operations using lmp as envisioned .

the lmp program management office assessed the progress of lmp implementation using a scorecard that was agreed to by the deployment sites and the lmp program management office .

this scorecard focused on four elements: ( 1 ) validating user access , ( 2 ) critical business processes validated by sites , ( 3 ) production support and infrastructure readiness , and ( 4 ) training readiness .

table 2 provides an explanation of each area .

as noted above , in addition to the criteria for each element , the lmp program management office's measurements included a legend that provided detail on the color coding used to assess progress .

according to this scorecard , a “green” rating was assigned if the element was “on track,” a “yellow” rating if the element had “issues being worked,” a “red” rating if the element had “significant problems / issues,” and a “white” rating if the element had not been started .

of the elements on the scorecard , the only category that assessed whether lmp could be used as intended was critical business process validation .

however , as stated in the critical business process validation reports submitted by the aviation and missile command , corpus christi army depot , and letterkenny army depot , this validation allowed the use of manual work - around processes that were not part of the envisioned lmp processes .

accordingly , the army did not have an assessment in place to determine whether lmp was delivering the envisioned capability to the second deployment sites .

based on our observations at corpus christi and letterkenny army depots , we found that the elements on the lmp program management office's scorecard did not accurately reflect the activities that the depots were expected to perform .

one of the primary purposes of implementing lmp was to gain the capability and efficiencies through automated processes associated with the software .

accordingly , while the scorecard measured the functionality of the software after lmp became operational , the scorecard did not assess whether the depots were able to perform their work using lmp as envisioned .

in addition to its scorecard , the lmp program management office provided periodic briefings regarding lmp implementation that identified problems as “what's important now” items .

the briefings described each problem , the impact of the problem , steps being taken to mitigate the problem , and an estimated date for when the problem would be resolved .

however , despite the presence of these items , the lmp program management office's scorecard reflected the status of lmp implementation as “green.” for example , a may 28 , 2009 , briefing that was provided to senior army management contained 17 “what's important now” items that identified problems related to missing data , the ability of the depots to fill customer requisitions , the ability to correct data in lmp , and challenges related to issuing materials to the shop floor to support repairs .

additionally , in the same briefing , the lmp program management office reported that corpus christi army depot had inducted an aircraft for repair using lmp .

in actuality , as discussed earlier , the aircraft was inducted by depot personnel using manual work - around processes that were similar to legacy processes rather than the envisioned lmp processes .

although the depot was unable to induct a helicopter using lmp as intended , the lmp program management office's scorecard reflected a “green” rating for all of the elements .

we also found that the lmp program management office's scorecard did not accurately reflect the internal assessment of lmp implementation at the depots .

for example , letterkenny army depot developed and used a scorecard to measure progress of lmp implementation , which included more than 50 processes that end users had to perform in lmp covering areas such as supply , maintenance , and finance .

according to officials at letterkenny army depot , a process was identified as “green” once the user had successfully performed the task in lmp using the envisioned processes .

however , the progress as tracked by the depot did not match the progress as reported on the lmp program management office's scorecard .

for example , on may 26 , 2009 , letterkenny army depot had identified 48 of its processes as “red” because the depot either had not yet performed the function in lmp or was unable to perform it successfully in lmp using the envisioned processes .

however , on the same day , the lmp program management office reported that lmp was “green” in all elements measured by the lmp program management office's scorecard .

these differences reflect the lack of a comprehensive set of metrics for measuring the success of lmp implementation , because while the lmp program management office was measuring whether the software was working , letterkenny army depot had identified that it was unable to conduct its daily operations using lmp as envisioned .

although data quality and training issues prevented the second deployment sites from using the full capabilities of lmp as envisioned , the use of lmp at the second deployment sites has provided the army some benefits that were not available in legacy systems , such as increased visibility .

for example , officials at corpus christi army depot stated that lmp has provided them the ability to track and trace individual transactions to specific end users .

with this tool , officials at corpus christi army depot stated that they are able to research individual actions , as well as ensure that individuals are following the procedures at the depot .

corpus christi army depot officials also stated that lmp provided them increased visibility over contractor - managed inventories , which was not available in the legacy systems .

the army has also achieved benefits through the common picture provided by lmp .

for example , when explaining how the life cycle management commands were using lmp , an item manager from the aviation and missile command showed us how the common view provided by lmp improved communication with the depots .

when attempting to find the location of an item for repair , the item manager stated that both the depot and the item manager saw that the item to be repaired had already arrived at the depot , so the depot could then begin the repair process .

according to the item manager , this visibility was not available in the legacy systems , and the lack of a common picture sometimes delayed induction of items for repair .

the item manager stated that the delays occurred because the item manager's system showed that an item was located at a depot , but the depot's system did not show the item as received , so personnel at the depot had to locate the item before it could be inducted for repair .

furthermore , the item manager demonstrated how the common view provided by lmp helped locate a critical part for the patriot missile system of a deployed unit .

in this case , the item manager was able to identify where the part was stored in order to support the deployed unit .

the item manager stated that this capability was not available in legacy systems .

the army has taken steps to address some of the concerns we identified during the second deployment of lmp .

lmp program management officials told us that preparations for the third deployment of lmp had begun in december 2008 , but that the army had adjusted its plans — specifically in the areas of testing and training — based on lessons learned from the second deployment .

for example , lmp program management officials told us that the third deployment sites had already begun data preparation activities in early 2009 , and that these activities would continue through september 2010 .

additionally , lmp program management officials stated that they had developed changes to their testing strategy and that tests are scheduled to begin in may 2010 .

lmp program management officials also stated that they intended to conduct selective testing using actual depot - specific data and that this testing is scheduled to begin in august 2010 .

however , according to lmp program management officials , the exact processes to be tested and the materials associated with supporting the tests have yet to be developed .

with respect to training , lmp program management officials told us that the training for the third deployment will be conducted by a cadre of personnel from each of the major deployment sites , and that members of this cadre would both serve as instructors to users at the locations as well as assist sites with implementing lmp .

lmp program management officials stated that they were in the process of completing instruction for the cadre of trainers , and that lmp users had already begun receiving instruction on the lmp process .

during a meeting with dod and army officials , a representative from one of the sites preparing for the third deployment stated that while the instructors had changed from contractors to the cadre of trainers , lmp users were still being taught with the same training materials from the second deployment .

additionally , according to the army's schedule for the third deployment of lmp , the army plans to update training for users in june 2010 and begin delivery of training to users in july 2010 .

accordingly , because these events have yet to occur , we were unable to determine whether they adequately addressed the issues we identified during the second deployment related to data testing and training .

implementation of enterprise resource planning systems , like lmp , is a complex endeavor , and based on the second lmp deployment , the army has improved its ability to manage implementation .

because the army improved its management processes based on lessons learned during the first deployment of lmp at tobyhanna army depot , the army was successful in mitigating some of the previous issues .

furthermore , the second deployment of lmp also demonstrated the potential to provide benefits for the army , such as providing better visibility of inventory and asset management .

however , despite the improvements and the benefits that were achieved , the deployment sites still faced challenges related to data quality and training , which limited their ability to use lmp as intended .

additionally , the army's lack of a comprehensive set of performance metrics prevented it from measuring whether the intended lmp functionality had been achieved at the depots .

although the army was effective in addressing these challenges after they had arisen at the second deployment sites , applying these lessons learned to the army's plans as it prepares to support the third phase of deployment in october 2010 is critical .

unless the army addresses these challenges , the third deployment locations are likely to face the same , or even greater , problems , since the third deployment of lmp will occur at more locations and affect more users than the previous deployments .

to improve the third deployment of lmp , we are recommending that the secretary of the army direct the commanding general , army materiel command , to take the following three actions: improve testing activities to obtain reasonable assurance that the data used by lmp can support the lmp processes .

improve training for lmp users by providing training on actual job processes in a manner that allows the users to understand how the new processes support their job responsibilities and the types of work they are expected to perform and providing training at the individual deployment sites to match deployment timelines .

establish performance metrics that will enable the army to assess whether the deployment sites are able to use lmp as intended .

in written comments on a draft of this report , dod stated that the army concurred with our recommendations and highlighted the corrective actions it is taking to ( 1 ) improve testing activities to obtain reasonable assurance that the data used by lmp can support the lmp processes , ( 2 ) improve training for lmp users , and ( 3 ) establish performance metrics that will enable the army to assess whether the deployment sites are able to use lmp as intended .

regarding our first recommendation , the army commented that the third deployment of lmp involves two new test activities — the process and data integration test and the business operational test — that are designed to address lessons learned from the second deployment of lmp .

the army commented that the process and data integration test will evaluate business processes using migrated business data from critical weapon systems , and that the business operational test will require expert and select end users to perform transactions in lmp using local data .

according to the army , these tests will bring together data , business processes , standard operating procedures , and end user training materials to ensure success .

while we have not evaluated the effectiveness or sufficiency of these two new tests in correcting the data testing issues we discuss in this report , we believe that the steps the army is taking appropriately address the intent of our recommendation .

with respect to our second recommendation , the army commented that it began role mapping and development of the training calendar earlier in the deployment process , and that training will be delivered to end users in a just - in - time method to ensure that the training is timely and focused to meet the needs of the users .

the army also commented that it will continue to provide refresher training after deployment .

we have not reviewed these new training initiatives , but we believe that they are a step in the right direction toward addressing the intent of our recommendation and improving lmp user training .

finally , regarding our third recommendation , the army commented that it is working to improve standard performance measures , and that the metrics will reflect lessons learned from previous lmp deployments .

the army commented that the expected date of completion for development of these measures is july 1 , 2010 .

the army's written comments are reprinted in appendix ii .

we are sending copies of this report to interested congressional committees ; the secretary of defense ; the secretary of the army ; and the director , office of management and budget .

the report also is available at no charge on the gao web site at http: / / www.gao.gov .

please contact william m. solis at ( 202 ) 512-8365 or solisw@gao.gov , asif a. khan at ( 202 ) 512-9869 or khana@gao.gov , or nabajyoti barkakati at ( 202 ) 512-4499 or barkakatin@gao.gov if you or your staff have questions on matters discussed in this report .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report were j. chris martin , senior - level technologist ; david schmitt , assistant director ; evelyn logue ; darby smith ; and jim melton .

in order to evaluate the effectiveness of the army's management processes in enabling the second deployment sites to realize the full benefits of the logistics modernization program ( lmp ) , we reviewed and analyzed army plans and policies that governed lmp implementation .

specifically , we reviewed plans created by the lmp program management office related to data conversion and migration , system testing , the training curriculum , and how the army intended to monitor the implementation of lmp .

we also held several meetings with lmp program management office officials and received briefings related to lmp implementation .

during these briefings , we also received information on how lmp is intended to function , as well as the benefits that the army expects to receive by using the system .

we also monitored the second deployment of lmp as it occurred and had personnel observing operations at corpus christi army depot , texas ; letterkenny army depot , pennsylvania ; and the lmp program management office's command center at marlton , new jersey .

during our initial visits to corpus christi army depot and letterkenny army depot , we met with depot officials to discuss how they were using lmp and any problems or successes that had arisen from their usage .

we also observed how personnel at the depots were performing certain processes using lmp and received documents related to those actions .

additionally , we reviewed how each of the depots was assessing the progress of lmp implementation , and attended several of the daily internal meetings held at corpus christi army depot and letterkenny army depot .

to assess how the army was managing the overall progress of implementation , we also attended daily meetings held by the lmp program management office , the aviation and missile command , corpus christi army depot , and letterkenny army depot .

after the initial deployment , we attended a lessons learned discussion hosted by the lmp program management office .

we conducted follow - up visits to letterkenny army depot in june 2009 and august 2009 and to corpus christi army depot in september 2009 to monitor the progress of implementation .

we also met with officials at the army materiel command , the aviation and missile command , and the lmp program management office to discuss how the army was managing the implementation , and received documents that were used to inform senior leaders at the army materiel command on the status of lmp implementation .

we also met with the army deputy chief of staff for logistics in january 2010 to discuss our initial observations .

during meetings we held with officials in the army materiel command and the lmp program management office , we discussed the steps that the army was taking to support the third phase of deployment for lmp .

we received copies of army briefings assessing the progress of implementation , as well as revisions to army plans and drafts of new plans based on the lessons learned from the second deployment of lmp .

because of the timing of this review , we did not assess the army's plans for the third deployment locations , nor were we able to observe actions taken by the third deployment locations to prepare for lmp implementation .

we conducted this performance audit from may 2009 through march 2010 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

