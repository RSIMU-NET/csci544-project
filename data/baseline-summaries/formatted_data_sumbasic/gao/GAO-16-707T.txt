i am pleased to be here today to discuss our past work on the transportation security administration's ( tsa ) expedited screening process and its use of transportation security officer ( tso ) performance data to improve screening operations .

tsa , an agency within the department of homeland security ( dhs ) , is the primary federal agency responsible for the security of the nation's aviation system .

as part of this responsibility , tsa screened or oversaw the screening of more than 708 million passengers and more than 1.6 billion carry - on bags at about 450 u.s. airports in 2015 .

tsa - employed screening personnel ( i.e. , tsos ) carry out passenger and checked baggage screening operations to identify prohibited items that could pose a threat to the aircraft and passengers .

these screening operations may include pat downs , search of property , and operating metal detectors and explosives detection equipment , among other things .

while tsa's primary aviation responsibility is to ensure security , it also strives to balance the safety and security of the traveling public with the efficient flow of passengers through the screening process .

in an effort to strengthen and improve these screening operations , tsa began providing expedited screening to selected passengers through its tsa pre® program in october 2011 .

the tsa pre® program uses risk - based , intelligence - driven screening concepts and technology to determine passenger risk prior to travel .

the use of expedited screening procedures is intended to allow tsa to devote more time and resources at the airport to screening the passengers tsa determines to be of higher risk or unknown risk while providing expedited screening to those passengers determined to pose a lower risk .

to further expedite passenger travel for selected passengers not approved through tsa pre® , tsa implemented the managed inclusion process in 2012 .

managed inclusion assesses passenger risk in real time at the airport using randomization procedures , behavior detection officers ( bdos ) , and passenger screening canine teams .

each year , tsa also conducts certification testing of its tsos , and in an effort to measure the performance of aviation security screening , both tsa and the department of homeland security office of inspector general ( dhs - oig ) conduct regular covert testing of tsa screening operations .

in response to the failure rates stemming from recent covert testing conducted by the dhs - oig , the secretary of the department of homeland security ( dhs ) directed tsa in june 2015 to take a number of actions to address the vulnerabilities identified in the testing .

specifically , the secretary directed tsa to revise its standard operating procedures ( sop ) for screening , brief all federal security directors ( fsd ) across the country on the inspector general's findings , and to conduct further training for all screening personnel and supervisors , among other things .

in october 2015 , the tsa administrator testified before congress on the steps tsa was taking to respond to the secretary's directive , including delivering further training to every tso and supervisor across the country .

my testimony today addresses the extent to which tsa ( 1 ) has taken steps to improve the security effectiveness of expedited screening and ( 2 ) uses tso performance testing data to enhance tso performance in screening for prohibited items .

this statement is based on reports we issued in may 2016 and december 2014 , and selected updates .

specifically , for our past work we analyzed tsa documentation including expedited screening and managed inclusion procedures , memorandums of agreement , and decision memorandums , tsa's risk assessment methodologies , and tsa's security assessment of the managed inclusion process , among other documents , to gain an understanding of how expedited screening and managed inclusion operate .

moreover , we reviewed data ( ranging from 2009 to 2015 ) on tsa's performance evaluation testing programs , compared the results by airport security category , and also assessed the reliability of the data .

we found that some testing programs had incomplete or unreliable data for the years we analyzed and therefore were not sufficiently reliable for describing national trends .

we also reviewed tsa's processes and actions for using screener performance testing results to inform its operations and future tso training , and assessed these processes against standards in standards for internal control in the federal government .

further , we interviewed program officials at tsa headquarters and at select airports about how they analyze performance test data and how , if at all , they use the results to adjust training or take other actions .

further details on the scope and methodology for the previously issued reports are available within each of the published products .

we conducted this work in accordance with generally accepted government auditing standards .

these standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions , based on our audit objectives .

in 2011 , tsa began developing new expedited security procedures intended to strengthen security and improve the passenger experience by shortening lines and wait times , and in october 2011 , implemented its expedited screening program — known as tsa pre® .

according to tsa , expedited screening involves a relatively more efficient and convenient screening process for individuals from whom tsa has obtained sufficient information to determine them to be lower risk , compared with the standard screening process for a traveler for whom tsa does not have such information .

for example , passengers eligible for expedited screening may no longer have to remove their shoes ; may leave their permitted liquids , gels , and laptops in carry - on baggage ; and are not required to divest light outerwear , jackets , or belts when passing through screening checkpoints unless the screening technology alarms , in which case these items must be removed .

tsa uses the following methods to assess whether a passenger is low risk and therefore eligible for expedited screening .

approved tsa pre ® lists of known travelers — these lists are comprised of individuals whom tsa has determined to be low risk by virtue of their membership in a specific group , such as active duty military members , or based on group vetting requirements , or if approved through the tsa pre® application program .

automated tsa pre ® risk assessments of all passengers — using these assessments , tsa assigns passengers scores based upon information available to tsa to identify low risk passengers eligible for expedited screening for a specific flight prior to the passengers' arrival at the airport .

real - time threat assessments through managed inclusion — these assessments use several layers of security , including procedures that randomly select passengers for expedited screening , behavior detection officers who observe passengers to identify high - risk behaviors , and passenger screening canine teams to help ensure that passengers selected for expedited screening have not handled explosive material .

tsa developed managed inclusion as a tool to improve the efficiency of dedicated tsa pre ® screening lanes .

when tsa began offering expedited screening at airports in the summer of 2011 , tsos initially provided such screenings in standard lanes to passengers aged 12 and younger , and subsequently extended expedited screening to certain flight crew members and then to passengers aged 75 and older .

however , in october 2011 , tsa began to expand the concept of expedited airport screening to more of the flying public by piloting the tsa pre ® program .

this pilot program allowed certain frequent fliers of two air carriers to experience expedited screening at four airports .

these frequent fliers became eligible for screening in dedicated expedited screening lanes , called tsa pre ® lanes , because they had opted into the tsa pre ® program through the air carrier with which they had attained frequent flier status .

since october 2011 , tsa has further expanded the known traveler populations eligible for expedited screening .

tsa established separate tsa pre ® lists for additional low - risk passenger populations , including members of the u.s. armed forces , congressional medal of honor society members , members of the homeland security advisory council , and members of congress , among others .

in march 2015 , tsa officials stated that the army , navy , marine corps , air force , and coast guard branches of the u.s. armed forces , as well as reserve and national guard personnel , were eligible to participate .

tsa also created its own tsa pre ® list composed of individuals who apply to be preapproved as low - risk travelers through the tsa pre ® application program , an initiative launched in december 2013 .

to apply , individuals must visit an enrollment center where they provide biographic information ( i.e. , name , date of birth , and address ) , valid identity and citizenship documentation , and fingerprints to undergo a tsa security threat assessment .

applicants must be u.s. citizens , u.s. nationals , or lawful permanent residents , and cannot have been convicted of certain crimes .

as of december 2015 , about 8.8 million individuals were eligible , through tsa pre ® lists , for expedited screening .

figure 1 shows the populations for each tsa pre ® list .

to carry out passenger and checked baggage screening operations , tsa employs tsos at the vast majority of the nation's commercial airports .

tsos must complete the new hire training program ( nhtp ) , which includes at least 40 hours of classroom training focused on their duties as a screener , a minimum of 60 hours of on - the - job training , and certification tests for the functions they will be performing .

in addition , tsos are required to take recurrent training throughout the year to maintain proficiency with skills learned during the nhtp , and to remain up - to - date with changes in screening standard operating procedures ( sop ) , as well as emerging threats .

also , tsos who are absent from their screening duties for a period of time must undergo some level of “return - to - duty” training based on the amount of time they were absent .

lastly , if tsos fail an operational test , they are required to take remedial training customized to fit the specific screener's performance improvement needs .

furthermore , each year , tsa conducts certification testing for its airport security screeners , and in an effort to measure the performance of aviation security screening , both tsa and the dhs - oig conduct regular covert testing of tsa screening operations .

recent covert tests conducted by the dhs - oig highlighted the following areas of concern: ( 1 ) the effectiveness of the passenger screening process , ( 2 ) tsa's advanced imaging technology ( ait ) screening equipment , ( 3 ) related automated target recognition software used by the ait systems , and ( 4 ) checkpoint screener performance in identifying and resolving potential security threats at airport checkpoints .

in response to the results of the covert testing , tsa updated its screening sops , retrained tsos to address the inspector general's findings , and provided additional classroom training nationwide to all tsos .

in addition , tsa developed new measures of effectiveness that it expects will better emphasize the agency's goals for improving security effectiveness by focusing the measures on both the screening system and workforce in the areas of readiness and performance .

to measure tso performance , tsa uses the following performance measurement tests: annual proficiency reviews ( apr ) evaluate tsos' ability to identify prohibited items on an x - ray machine , ability to resolve explosives detection system machine alarms using the appropriate tools , and whether tsos can perform various practical skills such as pat downs , bag searches , and use of explosive trace detection technology .

if a screener does not pass one of the components of the apr after two ; or , in some cases , three attempts , they are subject to removal from their position .

threat image projection ( tip ) monitors tsos' ability to identify prohibited items in x - ray images of carry - on baggage at the passenger checkpoint by projecting fictional threat items onto the bags .

tip also aides in keeping tsos focused and attentive , and in keeping their skills sharp in identifying items they do not routinely see .

according to tsa policy , fsds must monitor tip results monthly and , if one of their tsos identifies less than a target percentage of tip images accurately in a month , then the tso is required to attend remedial training .

aviation screening assessment program ( asap ) is a form of covert testing to measure , at a national level , tso screening performance against screening sops .

tsa's office of security operations utilizes local role players to take prohibited items such as knives , guns , or simulated improvised explosive devices , through the screening checkpoints to test tsos performance in accurately identifying those items .

asap tests are conducted by tsa at both screening checkpoints and checked baggage screening areas .

the tests are designed to assess the operational effectiveness of screeners .

tsa implemented a series of improvements to asap in 2010 and 2012 that introduced ( 1 ) specific testing scenarios to improve the level of standardization , ( 2 ) a formalized debriefing process , ( 3 ) training scenarios by which airports can tailor lessons learned to their operations , and ( 4 ) a strategy for allowing the reporting of comparable testing results , over time , from the airports .

after these improvements , tsa renamed the program asap advantage .

tsa implements asap advantage according to a 6- month testing schedule , and at the completion of each 6-month cycle , generates a report identifying trends in screening performance .

tsa has taken steps to improve the security effectiveness of expedited screening since we issued our december 2014 report .

specifically , tsa has begun planning for the testing of the security effectiveness of the managed inclusion process as an overall system – ensuring that the testing adheres to established design practices .

in addition , tsa has adjusted the tsa pre ® risk assessment program algorithm used to assign passengers scores and identify low risk passengers because the dhs - oig found that the algorithm allowed a high - risk individual access to expedited screening .

also , according to tsa documentation , tsa reduced the number of passengers screened by the managed inclusion process by limiting its use to airports that have canine teams to detect explosives .

our december 2014 report found that tsa has tested the effectiveness of the individual managed inclusion security layers , but that tsa had not yet tested the managed inclusion process as an overall system .

we stated that our previous work identified challenges in several of the layers used in the managed inclusion process , raising concerns regarding their overall effectiveness .

for example , in november 2013 , we found that tsa had not demonstrated that behavioral indicators can be used to reliably and effectively identify passengers who may pose a threat to aviation security .

while tsa is taking steps to revise and test the behavior detection program , such as working to provide scientifically validated evidence that demonstrates that behavioral indicators can be used to identify passengers who may pose a risk to aviation security , the issue remains open .

as of may 2016 , tsa told us that it is taking actions to optimize the effectiveness of its behavior detection program and plans to begin an operational test of these efforts in september 2016 .

in our december 2014 report , we noted that tsa has previously faced challenges designing studies to test the security effectiveness of programs in accordance with established methodological practices such as ensuring an adequate sample size or randomly selecting items in a study to ensure the results can be generalizable — key features of established evaluation design practices .

as a result , we recommended that tsa take steps to ensure and document that its planned testing of the managed inclusion process as a system adheres to established evaluation design practices .

dhs concurred with our recommendation , and according to tsa officials , tsa has developed a data collection and analysis plan to be used for the testing of the managed inclusion system .

as of may 2016 , tsa is reviewing and finalizing the plan and intends to test it at ten airports in late summer or early fall 2016 according to tsa officials .

we will continue to monitor tsa's progress in addressing this recommendation .

in addition , according to a tsa memorandum dated november 2015 , tsa made changes to the tsa pre ® risk assessment program and managed inclusion process to enhance aviation security as a result of the findings and recommendations included in three prior dhs - oig audit reports .

specifically , tsa made changes to the tsa pre ® risk assessment program algorithm used to assign passenger scores because the dhs - oig found that the program created a potential aviation security vulnerability in at least one instance by identifying a convicted felon as low risk and eligible for expedited screening .

as a result , tsa recognized the increased level of uncertainty surrounding a potential threat posed by individuals who obtain expediting screening eligibility through the risk assessment program as compared to individuals who have been vetted and are included on one of the tsa pre ® lists .

following the public release of the dhs - oig's covert testing results , tsa officials stated that tsa began a thorough review of checkpoint operations , and as a part of that review , evaluated all methods in which individuals without background checks became eligible for expedited screening .

as a result of this evaluation and based on a recommendation from another dhs - oig audit , tsa documentation shows that tsa discontinued the use of explosives trace detection ( etd ) devices as a method used to conduct real time threat assessments and is now limiting the use of managed inclusion to airports that employed canine team to detect explosives .

according to the tsa administrator , these changes have resulted in a 20 percent decrease in the number of individuals who receive expedited screening .

to address this decrease in expedited screening and its likely effect on passenger wait times , tsa plans to undertake efforts to increase the number of individuals included on the tsa pre ® lists of known travelers from the nearly 8.8 million individuals currently enrolled to 25 million individuals .

in order to achieve this increase , tsa plans to change the enrollment process , increase marketing and communication efforts , and expand the number of contractors that provide enrollment services .

tsa estimates that the tsa pre ® lists of known travelers will total 25 million individuals in 3 to 4 years .

tsa utilizes data on tso performance obtained from its various testing programs to help to ensure that individual tsos are ( 1 ) qualified to conduct passenger and checked baggage screening based on annual proficiency reviews and resulting recertifications , and ( 2 ) demonstrate proficiency , during live screening operations , in their adherence to screening standard operating procedures and other tsa guidance for detecting prohibited items .

however , incomplete and unreliable data and limited analysis constrains tsa's ability to determine the true level of tso performance in screening passengers and baggage for prohibited items .

without this knowledge , tsa cannot fully identify and make necessary improvements to screening operations .

tsa has several programs in place to yield data for oversight and analysis of tso screening performance .

as noted previously , tsa relies on annual proficiency reviews ( apr ) to recertify tsos .

tsa's office of training and workforce engagement examined the results of specific apr component tests administered in 2013 to inform their development of related courses for the annual training curriculum for tsos , known as the national training plan ( ntp ) .

specifically , tsa officials stated they reviewed the results of these component tests — screening of individuals with disabilities , bag searches , and standard pat downs — and added training to the fiscal year 2015 ntp to specifically address the deficiencies they identified .

in addition , during live screening operations , tsa also monitors individual tso performance through ( 1 ) threat image projection ( tip ) testing by local tsa officials which assesses the tsos' proficiency at identifying prohibited items in x - ray images of passengers' carry - on baggage , and ( 2 ) aviation screening assessment program ( asap ) covert tests which assess the tsos' ability to properly adhere to screening standard operating procedures and prevent the passage of prohibited items through passenger and baggage checkpoints .

tsa monitors the results of these testing programs to determine whether individual tsos need remedial training based on the results .

tsa policy requires airport personnel to manually download tip testing results from their individual x - ray machines and upload the monthly data into tsa's national database repository for tsa results .

according to tsa headquarters personnel responsible for overseeing the tip program , they use these uploaded results to determine if any adjustments are needed to the quality or usefulness of the library of images maintained in the tip system nationwide .

however , as we found in may 2016 , some airports had failed to submit tip data as required .

as shown in figure 2 , some airports in all five airport risk categories did not report any tip results nationally over the course of a year from fiscal year 2010 through fiscal year 2013 .

during the fiscal year 2009 through 2014 time frame , fiscal year 2013 had the highest percentage of airports failing to report any tip data at nearly 14 percent .

for category x and i airports , these results had generally improved by fiscal year 2014 with all of these airports reporting tip data that year .

however , the percentage of category iii and iv airports that did not report tip data generally increased during fiscal years 2013 and 2014 compared to prior years .

tsa officials attributed the missing tip data to a transition to new x - ray screening equipment at certain airports from fiscal year 2009 through fiscal year 2012 .

officials stated that , due to software compatibility issues with the new machines , tip image capability was turned off for an extended period of time , meaning that tip testing was not occurring on these machines and , therefore , tip data were neither collected nor reported for these airports .

tsa officials also told us that their older x - ray machines do not have the capability to automatically upload tip data results to headquarters .

as a result , some airports relying on these older x - ray machines were not able to submit tip data automatically by electronic means and did not submit it manually .

tsa officials reported that they do not have a process for determining whether tip data have been submitted by all airports , on a regular basis , as required .

tsa officials told us they are making efforts to install automatic uploading capabilities to all new machines that they expect will help ensure that tip data reporting is complete and timely .

however , tsa has placed these efforts on hold pending security concerns that must first be addressed stemming from the recent cybersecurity breaches at the office of personnel management that have led to tsa reviewing its own cybersecurity efforts before moving forward with installation of automatic uploading capabilities on its x - ray machines .

tsa officials also acknowledged that , in addition to the airports discussed above that did not report any tip data for a year or more at a time , other airports may have reported only partial tip results data during this same time frame .

tsa officials stated that , in the nationwide results data provided to gao , it would be difficult to ascertain how much data might be missing from individual airports ( during the time period covered by our data ) since the number and type of machines in use at those airports at any particular point in time could vary .

based on our observation of the incomplete tip data , we recommended in may 2016 that dhs ensure that tsa officials at individual airports submit complete tip results to the national database as required by tsa policy .

in addition , we noted that standards for internal control in the federal government states that the information requirements needed to achieve the agency's objectives should be identified and communicated to management in a timely manner in order that they may carry out their internal control and other responsibilities .

further , we stated that , unless tsa takes steps to ensure that all airports submit complete , nationwide tip data , tsa lacks assurance that ( 1 ) the decisions it makes on the content of the tip image library are fully informed , and ( 2 ) tsos are receiving remedial training from the tip program which has been developed to aid their ability to identify prohibited items .

in addition , we noted that , by not ensuring the collection of available tip data as required , the effectiveness of any potential further use of tip testing results to inform tso training or testing ( as described below ) programs would be limited .

dhs concurred with our recommendation on ensuring the completeness of tip data and is taking steps to address it .

specifically , dhs reported in april 2016 that tsa is working to establish a tracking system that will automatically identify and highlight specific airports that may be missing from the database , which will allow tsa managers to follow up with the fsds responsible for those airports .

tsa expects to pilot an information technology tool that is key to this system by may 2017 .

in the interim , tsa will reinforce the policy for reporting tip results in weekly conference calls with field staff .

once complete tip data are available , tsa could use those data to more accurately monitor the effectiveness of its tso training .

tsa headquarters officials stated that they had previously not systematically analyzed tip results data to determine any national trends for the purposes of informing future training programs or changes to screening processes or procedures .

tsa officials reported that they had not used tip data in this manner due to the agency's expectation that tip is a tool primarily for the benefit of local fsds to use in monitoring the training needs , and determining areas of focus , for their individual tsos locally .

specifically , we found that , without this complete picture that would be afforded by analysis of nationwide tip results , tsa could not use the results to fully inform tso training for screening passenger carry - on baggage for prohibited items that would help ensure continuous improvement in screening operations .

as a result of our examination of tsa's use of tip data , we recommended in may 2016 that , after complete tip data were available , dhs ensure that tsa conduct analysis of national tip data for trends that could inform training needs and improve future training and tso performance assessments .

we noted that using this trend analysis to inform tso training and enhance tso performance would satisfy provisions of the standards for internal control in the federal government which state that an agency's management should perform ongoing monitoring of its internal control system and associated operations , evaluate the results of those monitoring activities , and take corrective actions when warranted to achieve objectives and address risks .

further , we noted that by not including analyses of tip results data in nationwide efforts to inform either tso training or other image - based testing outside of tip , tsa is missing an opportunity to utilize this extensive , nationwide tso performance data for enhancing screening operations in addition to lacking assurance that remedial training is occurring , as required , at all airports .

dhs concurred with this recommendation and is taking steps to address it .

specifically , dhs reported in april 2016 that tsa is ( 1 ) examining airports with the best tip scores to develop best practices that can be shared with other airports , ( 2 ) examining airports with low tip scores to better understand challenges and options for improving tip performance , ( 3 ) planning to analyze data nationwide to determine what training best improves tip scores , and ( 4 ) developing a process to examine which categories of images most often present challenges to the screening workforce which will inform training efforts .

tsa also plans to assess tip training and assessments over a one - year period ending in may 2017 to determine if performance improvements have been realized and what contributed to the improvement .

tsa's plan for analysis is commendable , but until the tip data is largely complete , any nationwide review will be limited .

as we also reported in may 2016 , tsa determined that asap pass rate results data were unreliable , which caused them to question the extent to which asap tests accurately measure tso performance .

according to tsa officials , they hired a contractor to perform independent asap testing at 40 airports in fiscal year 2015 to verify the reliability of the results of testing previously performed by tsa personnel at those airports .

tsa found differences in the test results for most of the 40 airports when compared to the contractor's results .

specifically , tsa officials found that tsos at these 40 airports performed more poorly in the asap tests conducted by the contractor personnel as compared to the prior asap testing done by the local tsa personnel — indicating that these prior - year pass rates were likely showing a higher level of tso performance in screening passengers and baggage for prohibited items than was actually the case .

while tsa officials are still in the process of determining root causes for the variances of the testing results between the contractor and tsa personnel at the airports , they acknowledged that initial results from the contractor appeared to confirm their prior concerns that problems existed with maintaining the covert nature of the tests .

these prior concerns had been based on higher detection rates at some airports when compared to other airports on the same tests performed .

in order to address the concerns stemming from the contractor's test results , tsa initiated the following actions after reviewing results of the contractor's initial round of testing in fiscal year 2015: conducted briefings with fsds on the contractor's findings and ongoing asap testing which included expectations that the fsds use the information as input in overseeing their local asap testing programs .

according to tsa officials , they are engaging in more frequent and improved communication with fsds and staff responsible for the asap testing and are including discussions of potential corrective actions when warranted .

extended the work of the contractor by 6 months in order to determine if the previously - identified variances in results are continuing .

engaged in efforts to better identify root causes of asap testing failures , including the development of a data collection tool to facilitate these efforts .

added an asap headquarters testing program that will supplement the asap testing conducted by tsa field personnel .

these headquarters testing teams will perform , on a permanent basis , the quality assurance and validation activities for asap that are currently being performed by the contract test teams .

however , field personnel will continue to conduct the majority of asap testing .

tsa officials stated that , through these measures , they believe they are enhancing the accountability of the local fsds and their staff for ensuring the quality and reliability of the local asap testing programs moving forward .

the officials added that partial results during the 6-month extension period of contract testing indicated that the previously - identified variances in contractor and local asap testing had been reduced .

as we reported in may 2016 , tsa does not track whether recommendations from their summary reports on asap results have been implemented or reasons for not implementing them .

these recommendations may include , among other things , additional training for certain points in the screening process and further testing in certain areas .

tsa officials stated that the various recommendations in the reports are strictly for the consideration of fsds in the field and implementation is not mandatory .

such tracking would be consistent with standards for internal control in the federal government which requires that internal controls be designed to ensure that ongoing monitoring occurs during the course of normal operations .

this tracking would also help ensure that airports nationwide are taking corrective actions to improve tsa performance , which the agency has identified as an area of concern .

moreover , we reported that tracking the implementation of its recommendations , including the extent to which identified corrective actions are improving subsequent tso performance and test results , will help tsa better determine the extent to which its implemented recommendations are leading to improvements in screening operations and appropriately addressing identified root causes for previous test failures .

further , without the assurance that recommendations for corrective actions based on the root causes identified in asap testing will be fully implemented — where appropriate — nationwide , we stated that tsa would be limited in its ability to take full advantage of any findings from the program .

based on tsa's lack of a tracking mechanism for the implementation of its asap - related recommendations to the field , we recommended in may 2016 that dhs direct tsa to track implementation by airports of these recommendations to ensure that corrective actions identified through asap testing are being applied .

dhs concurred with this recommendation and is taking steps to address it .

specifically , dhs reported that tsa is taking actions to formalize asap reporting including the development of a standard format for corrective action plans that will help tsa track corrective actions and their effectiveness in addressing findings from asap tests .

tsa expected to complete these actions by may 31 , 2016 .

chairman johnson , ranking member carper and members of the committee , this completes my prepared statement .

i would be pleased to respond to any questions that you may have at this time .

for questions about this statement , please contact jennifer grover at ( 202 ) 512-7141 or groverj@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this statement .

individuals making key contributions to this statement include chris ferencik ( assistant director ) , mike harmond , michelle vaughn , ellen wolfe , amanda miller , thomas lombardi , and dominick dale .

key contributors for the previous work that this testimony is based on are listed in each product .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

the published product may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

