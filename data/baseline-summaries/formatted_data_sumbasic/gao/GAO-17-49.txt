commercial trucks and buses are vital transportation links connecting goods and people with american markets and communities .

however , the federal motor carrier safety administration ( fmcsa ) reported that crashes involving large commercial trucks and buses increased from about 131,000 in 2011 to nearly 157,000 in 2015 .

these crashes harm the well - being of the people involved and the companies that own commercial trucks and buses ( motor carriers ) .

fatalities resulting from these crashes have also increased , rising from about 4,200 in 2011 to almost 4,500 in 2015 .

further , fmcsa estimated that crashes involving large trucks and buses cost over $110 billion in 2014 .

fmcsa's compliance , safety , accountability ( csa ) program is intended to reduce the number of motor carrier crashes by using a data - driven approach to identify and intervene with the highest - risk motor carriers .

when motor carrier safety problems are identified , fmcsa applies a range of intervention types — such as sending warning letters , conducting investigations , or issuing civil penalties — that attempt to remedy those problems early and before crashes occur .

a provision in a senate appropriations committee report required us to periodically assess fmcsa's implementation of the csa program .

this report examines: ( 1 ) the extent to which fmcsa has implemented csa interventions and how it has applied them ; ( 2 ) the extent to which fmcsa has evaluated the effectiveness and efficiency of csa interventions ; and ( 3 ) any steps that fmcsa has taken to improve and monitor progress toward achieving its intended outcomes for csa interventions .

to determine the extent to which fmcsa has implemented csa interventions and how it has applied them , we analyzed fmcsa intervention data from fiscal year 2010 through fiscal year 2015 .

we intended to analyze whether there were any notable increases , decreases , or other trends in fmcsa's application of interventions — across states , regions , and motor carrier types .

however , data limitations prevented an adequate and comprehensive assessment of the reliability of fmcsa's intervention data .

for example , officials told us fmcsa changed the way it counted interventions over time , and as a result , we could not validate the results of our analysis against agency totals — a step to testing data reliability .

as a result , we concluded that fmcsa's intervention data were of undetermined reliability , a factor that precluded our analysis of trends in fmcsa's application of interventions across states , regions , and motor carrier types .

as a substitute , we requested that fmcsa provide estimates for how frequently it applied each intervention type from fiscal year 2010 through fiscal year 2015 to identify general trends .

after reviewing fmcsa documentation related to the estimates and interviewing responsible fmcsa officials , we concluded that fmcsa's estimates were sufficiently reliable for this purpose .

we also reviewed relevant regulations and fmcsa guidance and policy documents to identify how fmcsa should implement and apply interventions .

we interviewed headquarters officials from fmcsa's office of enforcement , office of field operations , and its office of research and information technology .

fmcsa has 52 divisions that correspond with each state , the district of columbia , and puerto rico .

one of the four service centers oversees each division .

we interviewed fmcsa division officials in eight states that we selected based upon their participation in fmcsa's operational model test of the csa program , geographic location , and program size , among other factors , and interviewed fmcsa officials from each of the four service centers .

although the information obtained from our interviews with officials from the selected states is not generalizable to all states or fmcsa divisions , it provided illustrative examples of how fmcsa is applying interventions as well as the perspectives of officials knowledgeable about the program .

to determine the extent to which fmcsa has evaluated the effectiveness and efficiency of csa interventions , we reviewed the four evaluations the agency has conducted .

these included fmcsa's january 2015 evaluation on intervention effectiveness ; the university of michigan transportation research institute's ( umtri ) august 2011 evaluation of the operational model test , sponsored by fmcsa ; and two effectiveness evaluations on individual intervention types that fmcsa conducted in march 2016 .

to assess these evaluations , we consulted accepted practices for evaluation design and drew upon internal methodological expertise .

we also interviewed fmcsa headquarters officials responsible for developing policy and conducting data analysis , as well as volpe national transportation systems center officials responsible for designing and conducting some fmcsa evaluations .

to determine any steps that fmcsa has taken to improve and monitor progress toward achieving its intended outcomes for interventions , we reviewed relevant fmcsa strategic planning and policy documents , such as fmcsa's strategic plan: fiscal years 2015 – 2018 .

we interviewed responsible fmcsa division , service center , and headquarters officials to identify any monitoring or improvement steps that fmcsa has taken as well as to determine their perspectives on the effect of these steps .

we compared the results of our documentary review and interviews against leading practices for performance management identified in our prior body of work .

we conducted this performance audit from july 2015 to october 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on the audit objectives .

fmcsa was established within the department of transportation ( dot ) in january 2000 , and is tasked with promoting safe commercial motor vehicle operations and reducing large truck and bus crashes , injuries , and fatalities .

it seeks to achieve this reduction through regulation , enforcement , and partnerships with stakeholders , among other activities , and with full accountability to the public through transparency , results - oriented performance measuring , and managing for results .

since fiscal year 2010 , fmcsa's total budget authority to conduct these activities has remained relatively stable , increasing about 6.5 percent from fiscal year 2010 through fiscal year 2016 ( see table 1 ) .

funding for implementing and applying interventions is included in both the motor carrier safety operations and programs and safety grants budget authorities .

the vast majority of fmcsa's staff are located in field offices , including divisions and service centers .

field staff are primarily responsible for implementing fmcsa's compliance and enforcement activities , including investigations .

federal safety investigators represent the majority of fmcsa's compliance and enforcement program staff ( see table 2 ) .

in addition , fmcsa partners with state agencies to perform some intervention activities , such as conducting carrier investigations ; however , fmcsa is responsible for ensuring that commercial motor carriers under its authority comply with federal safety regulations .

fmcsa's office of enforcement is the primary office responsible for developing policy for fmcsa's compliance and enforcement program , and overseeing the implementation of intervention activities .

the csa program is intended to improve the effectiveness of fmcsa's compliance and enforcement programs , while more efficiently using its resources to reach carriers that pose the highest safety risk .

the csa program has three key components: ( 1 ) the safety measurement system ( sms ) , meant to identify high - risk carriers by using data from roadside inspections and crashes ; ( 2 ) interventions , which are intended to help carriers address safety problems ; and ( 3 ) the safety fitness determination rule .

in contrast to the one investigation intervention , the compliance review , available under fmcsa's previous approach , fmcsa expects the csa program to more effectively change unsafe behaviors by reaching and intervening with more potentially unsafe carriers earlier using a range of intervention types to enforce compliance with safety regulations .

in 2014 , we reported on the effectiveness of the sms component of the csa program .

fmcsa conducted an operational model test of the program from february 2008 through june 2010 in nine pilot states .

in december 2010 , fmcsa began implementing the csa program in three phases: ( 1 ) implementation of sms and some intervention types nationwide , ( 2 ) introduction of new investigative techniques and the safety management cycle , and ( 3 ) nationwide rollout of all intervention types and fmcsa's new investigative software , the safety enforcement tracking and investigation system ( sentri ) .

after a series of four commercial motor vehicle crashes — two involving buses and two involving trucks — that together resulted in 25 deaths and injuries to 83 people , the national transportation safety board investigated and , in november 2013 , made recommendations to improve the quality of fmcsa's compliance review processes .

the secretary of transportation tasked the federal aviation administration , as a peer of fmcsa within dot , to conduct a review and develop appropriate recommendations for dot's response to the national transportation safety board .

the federal aviation administration formed an independent review team , which in july 2014 , issued a report that included a range of recommendations intended to support both incremental and transformative improvements to fmcsa's compliance and enforcement programs .

we discuss some steps fmcsa is taking to address these recommendations later in this report .

under the csa program , fmcsa can select from a range of eight intervention types , intended to give fmcsa the flexibility to address motor carriers' specific safety problems .

four of the intervention types were newly introduced under the csa program ; fmcsa had been applying the other four intervention types prior to the program ( see table 3 ) .

each type falls into one of the following intervention categories: early contact , investigation , and follow - on interventions .

before the csa program , fmcsa used one investigation intervention type — the onsite compliance review — and three follow - on intervention types .

compliance reviews required investigators to examine every part of a carrier's operations and were thus extremely resource intensive to conduct .

as a result , fmcsa and its state partners investigated only about 3 percent of active carriers .

according to fmcsa motor carrier safety progress reports , federal or state investigators conducted between approximately 15,000 and 17,000 compliance reviews each year from fiscal year 2006 through fiscal year 2009 .

under the csa program , fmcsa has established a process for measuring the relative safety risk of carriers in seven behavioral analysis and safety improvement categories ( basics ) , prioritizing carriers based on risk , assigning an appropriate intervention type , and investigating or enforcing compliance with regulations ( see fig .

1 ) .

the csa intervention process has no set progression , and based on existing guidance , fmcsa applies one or more interventions depending on the circumstances of each case .

for example , fmcsa may directly assign an onsite comprehensive investigation to a carrier without first assigning another type of intervention .

fmcsa may also apply multiple interventions to a carrier over time , and as a result , common patterns in fmcsa's application of csa interventions can be identified .

for example , if a carrier receives a warning letter as a first intervention and its safety performance does not improve , fmcsa may assign the carrier a second intervention , such as an onsite focused investigation .

if fmcsa identifies violations during an investigation , such as the onsite focused investigation , that warrant enforcement , fmcsa may assign a third intervention , such as a notice of claim .

in such a case , the resulting intervention pattern would be: ( warning letter ) → ( onsite focused investigation ) → ( notice of claim ) .

every month , fmcsa uses sms to generate percentiles in any of seven basics for carriers with sufficient data .

however , as we reported in 2014 , the sms methodology contains limitations that reduce fmcsa's ability to reliably assess carriers' safety risks because fmcsa lacks sufficient safety performance information on the majority of carriers .

we identified the lack of sufficient information as a particular limitation for carriers with few inspections and vehicles because their underlying violation rates can have artificially low or high values , or greater variability , which affects the precision of the basic percentiles used by fmcsa in comparing carriers to one another .

nonetheless , fmcsa uses these basic percentiles to identify potentially risky carriers , to prioritize them for intervention , and to automatically generate warning letters .

fmcsa automatically prioritizes carriers into risk - based categories of escalating urgency based on the extent to which a carrier's basic percentiles exceed certain combinations of designated thresholds , in addition to the carrier's intervention history and unresolved violations .

for example , under the new high - risk definition fmcsa adopted in march 2016 , for a carrier to be considered high - risk , its basic percentile has to be above 90 in at least two of four basics — unsafe driving , crash indicator , hours - of - service compliance , or vehicle maintenance — and the carrier cannot have had an onsite comprehensive investigation in the last 18 months .

in addition to changing the high - risk definition , fmcsa implemented a new prioritization approach with five risk - based categories , from most to least urgent: high - risk , moderate - risk , risk , warning letter , and monitor .

according to fmcsa , high - risk carriers are the agency's highest investigative priority .

after fmcsa prioritizes carriers for intervention , fmcsa division managers decide which intervention type carriers should receive based on priority level , guidance , and carrier history among other things .

the principal guidance document for assigning intervention types is the electronic field operations training manual ( efotm ) .

although efotm includes some requirements , division managers have some discretion to select investigation and follow - on intervention types based on additional information , such as complaints received , significant crashes , and professional judgment .

for example , fmcsa must investigate non - frivolous written complaints that allege substantial violations regardless of whether the carrier is prioritized for intervention , but have discretion to determine the most appropriate investigation type based on the safety problems associated with the complaint , the carrier's basic percentiles , and the carrier's history .

however , for carriers identified as high - risk , fmcsa must conduct an onsite focused or onsite comprehensive investigation .

federal safety investigators and their state partners follow efotm guidance when conducting investigation and follow - on interventions .

in april 2013 , fmcsa introduced enhanced investigative techniques ( eit ) that are intended to help investigators identify the root cause of a motor carrier's safety problems .

while financial and legal penalties are typically applied following an investigation , fmcsa may levy financial penalties against a carrier without an investigation if it believes there is sufficient evidence , such as evidence that the carrier operated after being placed out of service .

investigators may also request a change to the intervention type for some carriers when they find new and pertinent information that was not available at the time of the assignment .

fmcsa's information systems are critical to its data - driven enforcement and compliance programs and are intended to provide real - time access to data for the enforcement community , the transportation industry , stakeholders , and the general public .

field staff input intervention data through a variety of field information systems .

these systems are operated on laptop computers in the field .

for example , field staff use the compliance analysis and performance review information ( capri ) system to enter investigation intervention data , such as investigatory files and safety violations identified .

similarly , they use caserite to enter legal enforcement information .

as previously discussed , fmcsa plans to introduce a new field information system called sentri , which will consolidate the legacy information systems that field staff use to upload information related to interventions .

once uploaded by field staff , intervention data are stored and analyzed on multiple central information systems .

fmcsa staff may access csa intervention data on these systems through a centralized portal and use the data to monitor carriers' safety performance , among other things .

for example , the motor carrier management information system ( mcmis ) includes motor carrier performance data including inspection and investigation results , enforcement data , and state - reported crashes .

fmcsa also uses the enforcement management information system ( emis ) to monitor , track , and store data related to fmcsa enforcement actions , including follow - on interventions .

fmcsa's analysis and information online system provides public access to descriptive statistics and analyses regarding commercial vehicle , driver , and carrier safety information .

although fmcsa implemented all four new csa intervention types in pilot test states , the agency chose to delay implementing two of the new intervention types in the remaining states until it develops information technology ( it ) software .

implementation in pilot test states: fmcsa implemented the entire range of csa interventions — including all four new csa intervention types — in nine pilot test states as part of the operational model test that fmcsa conducted from february 2008 through june 2010 .

the test was intended to help the agency assess the four new intervention types and identify any features that needed to be adjusted prior to implementing them nationwide , among other things .

according to fmcsa headquarters officials , personnel experienced challenges using multiple legacy information systems that were not designed to support fmcsa's application of the expanded range of interventions under the csa program .

for example , fmcsa's data analysts found it difficult to extract data from information systems needed to monitor and oversee the agency's application of interventions .

implementation in non - pilot test states: according to headquarters officials , in july 2010 fmcsa chose to delay implementing two of the four new csa intervention types — offsite investigations and cooperative safety plans — in the remaining non - pilot test states until it completes its development of sentri software .

however , fmcsa decided to implement the remaining two new intervention types — warning letters and onsite focused investigations — nationwide because they believed those two interventions were demonstrated as effective during the operational model test and that delays would hinder safety benefits for the public ( see fig .

2 ) .

the operational model test evaluation found that offsite investigations demonstrated a similar pattern of effectiveness as onsite focused and onsite comprehensive investigations .

fmcsa headquarters officials told us that developing and implementing sentri is important to help field staff and their state partners conduct their work .

field staff currently may use a variety of legacy information systems to apply and manage interventions .

principally , field staff use the capri system to prepare for investigation interventions and to report their results .

however , capri was designed to support traditional compliance review investigations , not the expanded range of investigation types under the csa program .

according to fmcsa officials , this has resulted in field staff taking time - consuming additional steps to report their application of interventions .

for example , some division administrators spent additional time reviewing how investigators entered information into capri to determine the correct investigation type performed .

according to officials , sentri is expected to help address these inefficiencies by consolidating investigative , follow - on , reporting , and other functions into a single interface .

fmcsa officials also expect sentri to improve data consistency and enable better policy and program decisions through improved data quality .

however , fmcsa has faced longstanding delays in developing sentri software as part of its broader it modernization effort .

in september 2005 , fmcsa initiated a comprehensive overhaul of the way it collects , manages , and conveys safety information .

the agency - wide modernization effort was intended to help fmcsa achieve its effectiveness and efficiency outcomes for the csa program by centralizing fmcsa data and simplifying information access , among other things .

according to fmcsa headquarters officials , fmcsa began obligating funds to develop sentri software in fiscal year 2009 , when it established the business case for the system ( see app .

ii ) .

since that time , we and the dot's office of inspector general have reported continuing project delays .

fmcsa hired consultants to identify the causes of , among other things , its it project delays and actions to remediate them .

the resulting march 2013 report found a variety of underlying program challenges .

for example , it found that ineffective it governance practices provided limited visibility into the health of individual projects , contributing to project delays .

it also found that the lack of an appropriately scoped and measurable strategy made it unclear whether current resources were effectively prioritized — a challenge that was compounded when priorities shifted on multiple occasions over time .

officials stated that fmcsa executed a contract in january 2016 to complete the agency's it modernization effort .

as part of this effort , fmcsa plans to complete its development of sentri by april 2017 .

fmcsa's application of interventions declined from fiscal year 2012 through fiscal year 2015 , according to estimates provided by the agency .

fmcsa implemented warning letters nationwide in fiscal year 2011 , which resulted in a temporary spike in interventions .

however , after this temporary increase , the number of interventions fmcsa applied was less in fiscal year 2015 than in fiscal year 2012 for each intervention type , with notable decreases in offsite investigations ( 73 percent ) and notices of violation ( 71 percent ) .

in addition , according to fmcsa's estimates , about 26 percent fewer total investigation interventions were conducted in fiscal year 2015 compared to fiscal year 2012 .

see table 4 for detailed estimates of fmcsa's application of interventions .

reasons for these notable decreases are discussed below .

offsite investigations: division officials from each of the four pilot test states we interviewed told us they selected offsite investigations less frequently in more recent years , because the number of carriers that met efotm criteria for receiving them decreased over time .

for example , officials from one division told us their use of offsite investigations decreased because motor carriers' basic percentiles were typically too high or involved too many basics to qualify to receive an offsite investigation according to current efotm criteria .

fmcsa headquarters officials told us they are focused on increasing the use of offsite investigations , because they believe offsite investigations were demonstrated as both efficient and effective .

for example , in march 2016 fmcsa established a working group to explore modifying policy to give division managers more discretion in assigning offsite investigations .

notices of violation: division officials from four of the eight divisions we interviewed told us they selected notices of violation infrequently because the intervention type was time - intensive to process compared to other intervention types or was not appropriate to address severe safety violations .

fmcsa headquarters officials told us that investigators prefer to issue notices of claim instead , because they result in penalties to motor carriers .

however , officials stated that investigators may not be aware of other associated fmcsa activities that increase the overall resources used to issue notices of claim .

for example , notices of claim require additional legal oversight , which generally requires more resources .

headquarters officials said investigators may choose to issue notices of violation rather than notices of claim , when appropriate , if they better understood this context .

total investigation interventions: fmcsa headquarters officials told us that total investigation interventions declined because investigators spent more time conducting in - depth reviews of motor carriers' safety management practices to identify the root causes of underlying safety problems as part of fmcsa's eit initiative .

fmcsa implemented eit in fiscal year 2013 as part of continuous improvement efforts and in response to independent review team recommendations .

according to officials , using the more time - intensive eit approach decreased the number of investigations that fmcsa could conduct , particularly since 2012 .

fmcsa officials stated investigation counts have increased somewhat as investigators adjusted to the new eit procedures .

however , the officials did not expect investigation counts to return to previous levels without additional personnel .

as fmcsa introduced an expanded range of intervention types under the csa program , fmcsa did not redesign capri or other legacy information systems to reflect these changes .

for example , fmcsa did not redesign capri to include a dedicated data element that would uniquely record the occurrence of each intervention type .

instead fmcsa developed algorithms — rules that can be applied by computer programs — that attempted to reconstruct the occurrence of each intervention type by identifying specific combinations of multiple data elements .

using legacy information systems for purposes for which they were not designed produced two main limitations that affected the accuracy of fmcsa intervention counts: data recording limitations: fmcsa headquarters officials stated that the accuracy of csa intervention counts depended in part upon how users recorded intervention data into fmcsa's it systems .

for example , although all but 10 states did not implement offsite investigations , the capri system nonetheless allowed investigators in these states to select “offsite” for the “review location” data element .

according to fmcsa officials , this inflated counts when fmcsa used “review location” as one of multiple data elements to identify offsite investigations .

similarly , investigators may conduct onsite focused investigations on carriers that receive complaints , but capri requires investigators to select either “complaint” or “focused cr” for the “review reason” data element .

because fmcsa's algorithm used “review reason” as one of multiple data elements to count onsite focused investigations , this deflated onsite focused investigation counts when investigators selected “complaint” to conduct them .

evaluation limitations: fmcsa officials told us they occasionally modified algorithms used to identify the occurrence of intervention types , but generally did not evaluate how the modifications affected the accuracy of intervention counts .

according to officials , they modified algorithms for a variety of reasons , such as when the agency changed how it recorded intervention data .

once modified , fmcsa applied the most recent algorithm to all previous data — including historical data .

for example , in january 2016 , fmcsa removed a redundant data element from the algorithm used to count investigation interventions , a step that changed historical intervention counts .

fmcsa officials told us they did not know the extent to which applying the modified algorithm to previous data affected the accuracy of historical counts , because they generally did not evaluate the modification's effect on count accuracy before applying it .

although the extent of the effect is unknown , even small differences could limit the ability of fmcsa managers to accurately and effectively monitor trends in fmcsa's application of csa interventions over time .

fmcsa headquarters officials told us that sentri is intended to address the underlying it challenges that limit the accuracy of csa intervention counts by creating a dedicated data element that uniquely records the occurrence of each intervention type .

developing sentri in a timely manner is particularly critical , because data - driven targeted enforcement is fmcsa's primary strategy for meeting its safety goals and further delays represent missed opportunities for fmcsa to accurately monitor and improve the csa program .

moreover , unresolved data limitations would continue to preclude outside entities , such as auditing entities , from assessing the integrity of agency information , including the completeness and accuracy of computer - generated counts .

in may 2016 , we initiated a review to determine the extent to which fmcsa has evaluated the effectiveness of selected it systems , and to assess the extent to which fmcsa has implemented an it governance structure and plan to complete this work by june 2017 .

in addition , as we discussed above , fmcsa currently estimates that it will complete sentri development in april 2017 .

in light of our and fmcsa's ongoing work in this area , we are not making a recommendation on this matter in this report .

in its strategic plan: fiscal years 2015 – 2018 , fmcsa identified the improved effectiveness and efficiency of csa interventions as strategic outcomes .

fmcsa has evaluated both of these strategic outcomes , but its evaluations had limitations .

specifically , fmcsa's effectiveness evaluations did not produce sufficiently complete , appropriate , and accurate information on individual intervention types because of design and methodological limitations .

additionally , fmcsa's efficiency evaluation is no longer current , because fmcsa has not taken steps to update the evaluation's cost estimates , despite changes in the time and resources required to conduct csa interventions .

fmcsa's strategic plan: fiscal years 2015 – 2018 identifies improved effectiveness as a strategic outcome for csa interventions .

according to fmcsa , the agency conducts regular evaluations to determine how effectively its programs are achieving their effectiveness and other intended outcomes .

to evaluate the effectiveness of csa interventions specifically , fmcsa developed a statistical model intended to annually evaluate the combined effects of all of its interventions .

according to fmcsa , the model is a revised version of a prior model that fmcsa used to evaluate the effectiveness of compliance reviews , before the implementation of the csa program added new intervention types .

fmcsa has also evaluated intervention effectiveness in other studies , but according to officials , the new annual model is the agency's primary method of assessing intervention effectiveness .

in a january 2015 report , the annual effectiveness model estimated the combined effect of four csa intervention types on the crash rates of carriers in four size groups from fiscal year 2009 through fiscal year 2011 .

to assess effectiveness , the model estimated the change in group crash rates before and after carriers received one or more interventions , compared to the change in a comparison group of carriers that did not receive an intervention .

this design accounted for the effects of some external factors that also could have influenced group crash rates , such as broad changes in weather or economic conditions .

when used appropriately , a comparison group design is a key strength of a model , such as the one used by fmcsa , as is the use of statistical inference to evaluate the certainty of the model's results .

federal standards for internal control state that agencies should use quality information to determine the extent to which they are achieving their intended program outcomes .

characteristics of quality information include complete , appropriate , and accurate information that helps management make informed decisions and evaluate the entity's performance in achieving strategic outcomes .

because , according to headquarters officials , the annual effectiveness model is the primary method fmcsa uses to evaluate csa intervention effectiveness and fmcsa intends to use the model on a recurring basis , we conducted a detailed assessment of the model .

as discussed below , we identified several design and methodological limitations in fmcsa's annual effectiveness model , including the design of its comparison groups , a design limitation that can impact the quality of information that the model produces ( see app .

iii for our complete assessment ) .

fmcsa's report concluded that applying at least one intervention reduced crash rates for three out of four carrier size groups in fiscal year 2009 and fiscal year 2011 and provided positive safety benefits .

the report also concluded that warning letters independently reduced group crash rates and increased safety benefits .

however , fmcsa's annual evaluation did not provide sufficiently complete information on intervention effectiveness because the evaluation did not assess all intervention types or intervention patterns that fmcsa commonly applies .

specifically , the evaluation did not explicitly measure follow - on interventions , including cooperative safety plans , notices of claim , and notices of violation .

according to the january 2015 report , the evaluation did not include cooperative safety plans because mcmis data for that intervention were not consistently complete or accurate .

fmcsa officials told us that the model does not specifically exclude notices of claim and notices of violation , but rather simply does not distinguish between investigations that result in follow - on interventions and those that do not .

according to fmcsa , the model does not make this distinction because fmcsa typically applies follow - on interventions , such as notices of claim , within 90 days of conducting an investigation , based on the investigation's findings .

we determined that fmcsa's model cannot analyze such intervention patterns , because the agency designed it to identify only a carriers' first intervention in a fiscal year .

as a result , fmcsa does not have information on the unique effectiveness of its specific follow - on interventions , which are critical for enforcing regulatory compliance .

fmcsa could potentially increase the breadth of analysis for its model by using a design similar to the evaluation of fmcsa's operational model test , conducted by umtri in august 2011 .

that evaluation identified common patterns of interventions with sufficient data for analysis and then estimated each pattern's effectiveness .

the combined estimates supplemented those for individual intervention types .

the annual evaluation does not provide information that appropriately reflects how fmcsa designed and implemented csa interventions .

the agency designed csa interventions to replace the resource - intensive “one - size - fits - all” compliance review with a range of intervention types intended to better address safety problems specific to individual carriers .

according to fmcsa's strategic plan: fiscal years 2015 – 2018 , the agency's strategy to reduce the number of unsafe and high - risk carrier behaviors is to create and apply appropriate interventions .

as we previously discussed , fmcsa's application of individual intervention types depends upon a combination of efotm rules and managers' day - to - day discretion .

for example , according to efotm , managers generally assign offsite investigations when a carrier has percentiles above intervention thresholds in three or fewer basics .

however , managers have the discretion to apply an onsite focused investigation instead , based on the carrier's circumstances .

additionally , fmcsa may apply multiple intervention types for the same carrier over time , resulting in commonly observed intervention patterns .

for example , one official told us that most carriers that fmcsa investigates have , at one time , been issued a warning letter .

in contrast to the design and implementation of csa interventions , fmcsa's model does not include an assessment of either individual intervention types or common intervention patterns .

instead , the model estimates the impact of all interventions combined that were performed during a 12-month period being measured .

recommended practices for program evaluation recommend that program managers attempt to separately evaluate multiple types of program activities that seek to achieve a common outcome – in this case , multiple intervention types that seek to improve carrier safety performance .

consistent with these practices , fmcsa's strategic plan: fiscal years 2015 – 2018 calls for the agency to use data to make smarter day - to - day decisions and to determine the impact that various rules have on decreasing crashes , injuries , and fatalities by conducting regular program evaluations and effectiveness reviews .

therefore , to provide information appropriate to the design and implementation of csa interventions , an evaluation should assess how effectively each intervention type or common intervention patterns addressed the safety problems of the carriers that received them .

this specific information could help fmcsa identify the circumstances under which different types of interventions are effective and help managers optimize their choice of interventions on a day - to - day basis as the agency implements the program .

although officials told us that fmcsa designed the model to measure the cumulative effect of fmcsa contact with carriers through csa interventions and not to analyze individual intervention types , fmcsa used the model to draw conclusions about the safety benefits of warning letters , one of the most common intervention types used according to fmcsa estimates .

specifically , fmcsa concluded that “this suggests that the warning letter in and of itself can be an effective tool for improving motor carrier safety.” however , as accepted practices for designing evaluations explain , quality evaluations should draw conclusions commensurate with the power of the design .

because fmcsa did not evaluate the separate effect of warning letters , it lacks specific analytical evidence to support its conclusion .

as a result , fmcsa lacks quality information needed to estimate how each intervention type , including warning letters , or common intervention patterns affect motor carrier safety performance and address carriers' specific safety problems .

fmcsa headquarters officials stated that they were unsure if it was possible to measure the effects of individual intervention types or common intervention patterns because the quantity of available data may not be sufficient to produce reliable results .

however , as previously discussed , fmcsa's august 2011 evaluation of the csa operational model test , conducted by umtri , assessed the effectiveness of each intervention type and common intervention patterns for carriers that received multiple interventions .

an evaluation of these effects was possible for the operational model test , despite the fact that umtri had less data available than fmcsa would generate after nationwide implementation of the csa program .

according to the study , umtri assessed such patterns to provide a more detailed look at the effectiveness of the interventions , in light of how fmcsa actually applied them in the field .

furthermore , in march 2016 , fmcsa conducted separate evaluations of how two specific intervention types — onsite focused and offsite investigations — influenced carriers' basic percentiles in calendar years 2011 and 2012 .

by combining multiple years of intervention data , as fmcsa did in these evaluations , rather than using a fiscal year construction , which officials told us fmcsa used in the annual evaluation for administrative reasons , fmcsa could potentially overcome data sufficiency limitations ( see app .

iii ) .

fmcsa and independent evaluators have identified a need for this level of detailed information in the management and implementation of interventions .

for example , an internal fmcsa working group determined that the agency needed a more detailed understanding of the effectiveness of onsite focused investigations to empower investigators to select the most appropriate intervention to change carrier behavior .

additionally , in its 2014 assessment , the independent review team that dot tasked with reviewing fmcsa's compliance review processes identified a need for fmcsa to perform consistent , detailed , evaluations of effectiveness by enforcement tool , such as intervention types .

without detailed evaluations , the team said that fmcsa would be unable to focus resources on using its most effective tools or to reconfigure tools that are not meeting the agency's goals .

nonetheless , as discussed earlier in this report , fmcsa's ability to accurately identify specific intervention types is limited .

accepted practices for designing evaluations state that quality evaluations should rely on credible data that are sufficiently free of errors that could lead to inaccurate conclusions .

taking steps to reliably and accurately identify each intervention type in the data used to support its evaluations would help fmcsa conduct evaluations that produce information appropriate to the design and implementation of csa interventions .

uses and characteristics of comparison groups a comparison group , in the context of typical designs for evaluating program effectiveness , represents what would have happened in the absence of a program and is used to rule out alternative explanations for changes in outcomes .

in a truly randomized experiment , this w ould be the control group .

in a quasi - experimental evaluation , like fmcsa's annual effectiveness evaluation , w here participants ( i.e. , carriers ) are not sorted randomly into groups , the comparison group should be constructed to be as similar as possible to the group being influenced by the program ( i.e. , carriers receiving interventions ) , in order to draw strong conclusions about the effects of the program .

the groups should be similar enough that any difference in outcome can be plausibly attributed to the intervention type being evaluated .

fmcsa's annual and separate effectiveness evaluations had methodological limitations that limited their ability to accurately attribute changes in carrier safety behavior solely to interventions .

because of these limitations , fmcsa may not have accurately accounted for factors other than fmcsa's interventions that could be responsible for the outcomes observed .

most notably , fmcsa did not consistently use a comparison group design , which compares outcomes among carriers that did and did not receive interventions , for its effectiveness evaluations .

when fmcsa did use this design , it constructed comparison groups that did not sufficiently account for external factors that could affect group crash rates .

according to recommended practices for designing program evaluations , comparison group designs are typical for assessing program effectiveness , because they can isolate a program's unique effects when the comparison groups are sufficiently similar to the groups affected by a program .

see appendix iii for a complete assessment of the limitations we identified in fmcsa's annual effectiveness evaluation , along with accepted practices that could help fmcsa to address them .

fmcsa's separate evaluations of onsite focused and offsite investigation effectiveness did not use a comparison group and so , as previously discussed , did not account for external factors that could have influenced changes in motor carriers' basic percentiles .

officials stated that they determined that a comparison group method was not appropriate for fmcsa's evaluation of onsite focused investigations because the officials were concerned that a comparison group would overstate the effectiveness of onsite focused investigations due to the differing safety profiles of carriers that receive each intervention type .

fmcsa headquarters officials stated that they chose to use the same methodology as the onsite focused investigation effectiveness evaluation for the separate evaluation of offsite investigation interventions .

although fmcsa did use a comparison group approach in its annual effectiveness evaluation , we identified limitations with fmcsa's approach that affect the model's ability to accurately attribute changes in crash rates to interventions .

for example , fmcsa's comparison group was observed over a different measurement period from the carriers that received interventions , so that the two groups were not perfectly matched on broad changes , such as weather and economic changes .

by not matching the measurement period , fmcsa's use of a comparison group was limited in its ability to account for external factors , as intended .

additionally , in the 2015 evaluation , fmcsa's comparison groups held constant the effects of carrier size , but did not hold constant key factors that could influence intervention outcomes , such as pre - intervention safety behaviors as measured by regulatory violations or basic percentiles .

fmcsa headquarters officials said that comparison groups in the model accounted only for carrier size because of data limitations and their concern that accounting for too many additional variables would reduce the power of the model .

specifically , officials said that fmcsa does not currently have sufficient data to assess the effectiveness of agency interventions for motor carriers with different characteristics , such as the total number of miles a carrier's vehicles travel per year .

however , fmcsa has previously used the data it has available to hold constant important factors external to the program and attribute changes in outcomes to its interventions with greater accuracy ( see app .

iii ) .

for example , fmcsa's august 2011 evaluation of the operational model test , conducted by umtri , matched groups of carriers that did and did not receive various types of interventions on several key characteristics , such as the distributions of pre - intervention crash rates and basic percentiles .

without using a robust comparison group or a similar method , fmcsa cannot accurately determine whether changes in motor carrier safety performance are a result of interventions or whether other factors are responsible .

without more complete , appropriate , and accurate information on the effectiveness of individual csa intervention types , fmcsa lacks information it needs to make informed decisions and evaluate its performance in achieving its effectiveness outcome for csa interventions .

additionally , fmcsa's ability to accurately identify specific intervention types by analyzing mcmis and emis data is limited due to the data limitations which we described earlier in this report .

without taking steps to address these limitations , fmcsa cannot accurately evaluate how effectively csa interventions improve motor carriers' safety performance .

as with its effectiveness outcome , fmcsa identified improved efficiency in its strategic plan: fiscal years 2015 – 2018 as one of its strategic outcomes for csa interventions .

we have previously reported that agencies should measure program efficiency by considering the relationship between two elements: ( 1 ) inputs , such as costs or hours worked , and ( 2 ) desired results , such as a program's effect on conditions or behaviors .

in the past , fmcsa evaluated the efficiency of csa interventions using both of these elements .

specifically , umtri's august 2011 evaluation estimated the average cost of conducting individual intervention types and measured the effects on carrier safety performance of those csa intervention types , as well as common intervention patterns , in four pilot test states during an 8-month period from october 2008 through may 2009 .

since the umtri evaluation , fmcsa has continued to evaluate the effectiveness of csa interventions .

however , as we describe below , fmcsa has not taken similar steps to update its cost information — information fmcsa would need to understand the relationship between both efficiency elements .

the umtri evaluation developed average cost estimates for each intervention type by considering four cost variables: labor hours , government miles traveled , vouchers , and other expenses .

the evaluation studied 920 interventions applied to 586 carriers , with the number of carriers receiving each intervention type ranging from 6 carriers for notices of violation to 249 carriers for onsite focused investigations .

the evaluation concluded that cooperative safety plans and notices of violation had the lowest average estimated costs — ranging from $95 to $118 respectively .

onsite comprehensive investigations and onsite focused investigations had the highest estimated costs , averaging $1,038 and $677 respectively .

since umtri conducted its august 2011 efficiency evaluation , fmcsa has continued to use the results to report and estimate the efficiency of interventions .

for example , in its budget estimates: fiscal year 2017 report , fmcsa requested $2.5 million and 50 additional program analysts to complete the last phase of the csa program , including nationwide implementation of offsite investigations .

to support this request , fmcsa stated that offsite investigations were “extremely efficient” and specifically cited the evaluation's cost estimate .

similarly , fmcsa headquarters officials told us they currently use the umtri evaluation to estimate efficiency and to understand the relative costs of individual intervention types .

however , cost estimates from umtri's august 2011 evaluation are no longer current , because the time and resources needed to conduct interventions has changed and the evaluation's estimates are not representative of all states .

the evaluation's estimates are no longer current because the time and resources needed to conduct interventions has changed .

for example , in april 2013 , fmcsa implemented a substantial change to the way investigators conduct investigations , called eit , which is intended to help identify the root cause of motor carriers' safety problems .

fmcsa headquarters officials told us that , although using eit takes additional time , it results in improved motor carrier safety performance .

the evaluation's estimates do not represent costs in all states .

specifically , the evaluation stated that its estimates pertain only to the four states studied .

thus the evaluation's estimates may not appropriately represent the average costs associated with applying interventions in the remaining 46 states , the district of columbia , and puerto rico .

federal standards for internal control state that agencies should use quality information to achieve the agency's intended program outcomes .

quality information includes information that is current .

fmcsa headquarters officials told us that they have not taken steps to update the cost estimates from the umtri evaluation to determine current resources used in all states to conduct each intervention type because they believed that fmcsa policy and guidance were sufficiently well designed to enable division managers to select the least resource - intensive intervention type necessary to correct a carrier's safety problem .

in march 2015 , fmcsa's then - acting administrator testified that given fmcsa's limited resources relative to the size of the regulated motor carrier population , it is imperative for fmcsa to apply its resources efficiently .

however , without cost estimates for csa interventions that are current and representative of all states , fmcsa lacks information it needs to understand the most efficient methods of conducting csa interventions in all states .

because fmcsa lacks current cost information , it also cannot evaluate or understand the relationship between these costs and the effectiveness of csa interventions .

fmcsa has taken steps intended to improve the effectiveness and efficiency of csa interventions — strategic outcomes — principally by establishing a working group to address these issues and implementing some of the group's recommendations .

however , fmcsa has not established performance measures to monitor progress toward achieving its intended efficiency outcome for interventions .

without establishing measures for both outcomes , fmcsa is and will be limited in its ability to monitor program performance and to balance these two priorities , as needed .

in april 2014 , fmcsa formed a continuous improvement working group ( ciwg ) tasked with improving the effectiveness and efficiency of the csa program , including csa interventions .

comprised of fmcsa staff from divisions , service centers , and headquarters , as well as state partners , the ciwg's objective was to assess the agency's intervention and prioritization processes and to recommend improvements that increase program effectiveness and efficiency .

to develop its recommendations , the working group reviewed available intervention data — such as investigation reports — and assessed current intervention practices by surveying and interviewing field staff , among other things .

in february 2015 , the ciwg made 20 recommendations intended to achieve its effectiveness and efficiency objectives .

according to fmcsa officials , the agency had implemented 12 of these recommendations as of april 2016 and was working to implement the remaining 8 recommendations .

implemented recommendations include: changing fmcsa's high - risk definition and prioritization criteria: in march 2016 , fmcsa adopted a change to its definition of high - risk carriers and the criteria it used to prioritize carriers for intervention .

for example , as discussed above , for a carrier to be defined as high - risk under fmcsa's new criteria , it has to exceed higher percentile thresholds than previously used in any of at least two of four specified basics .

according to fmcsa , this decreases the total number of high - risk carriers but better identifies carriers at a high - risk for crashes and will allow investigators to investigate higher - risk carriers sooner , using current resources .

however , fmcsa's continued reliance on basic percentiles supported by insufficient safety data , which we identified in our 2014 report and discussed above , will limit its ability to effectively identify and prioritize the highest - risk carriers for intervention .

changing criteria to receive warning letters: in january 2016 , fmcsa expanded the criteria it used to determine which motor carriers receive warning letters in an effort to reach more carriers and , according to fmcsa , to prevent further non - compliance before a more intensive intervention type becomes necessary .

specifically , the ciwg recommended that fmcsa send warning letters to carriers with basic percentiles above the intervention threshold in more basics than previously allowed , while shortening the time period carriers have after receiving a warning letter to improve their safety performance before being prioritized for an investigation intervention .

the ciwg projected that implementing the change would increase the number of warning letters that fmcsa issued by 30 percent ; however , the ciwg noted that issuing a warning letter that is not effective may merely postpone the eventual necessity of a carrier receiving an investigation intervention and that issuing more frequent warning letters could dilute their effectiveness .

establishing intervention quality review procedures: in march 2016 , fmcsa issued two memorandums requiring field staff to use tools that fmcsa developed to evaluate and improve the quality of some intervention types .

specifically , fmcsa developed one tool to measure the extent to which investigators appropriately and accurately conducted onsite focused and comprehensive investigations and completed required documentation .

division managers are expected to use the tool to evaluate a selected sample of investigation reports quarterly , identify areas of needed improvement , and provide training to improve report consistency and quality .

similarly , fmcsa developed another tool that measures the extent to which investigators' enforcement cases for notices of claim and notices of violation include sufficient documentation to meet evidentiary requirements .

the memorandum requires division managers to ensure that each notice is reviewed to identify areas for improvement and ensure that enforcement cases are properly completed .

according to fmcsa officials , fmcsa intends to use the results of these evaluations to identify training or policy clarifications needed to continuously improve the application and effectiveness of each intervention performed .

as previously discussed , fmcsa's strategic plan: fiscal years 2015 – 2018 identified improved effectiveness and efficiency as strategic outcomes of csa interventions .

fmcsa headquarters officials told us that effectiveness and efficiency are complementary outcomes that fmcsa strives to balance .

for example , according to officials , while using eit requires more time and decreases the number of investigations that fmcsa can conduct ( i.e. , efficiency ) , it also increases investigation quality ( i.e. , effectiveness ) .

thus , senior fmcsa officials stressed the importance of considering both effectiveness and efficiency in any set of measures used to monitor interventions , and stated that without treating these two outcomes as parts of a whole , fmcsa cannot achieve its goals for csa interventions .

fmcsa has established some measures for its effectiveness outcome , and monitors these measures on an annual and ongoing basis .

while we identified several limitations with the design and methodology fmcsa used in its effectiveness evaluation above , fmcsa has established a measure for intervention effectiveness — crash rates — and annually monitors the agency's performance against that measure .

officials told us that fmcsa also monitors effectiveness using investigation outcome measures , such as violation rates and safety ratings , on an ongoing basis .

however , fmcsa has not established measures to monitor progress toward achieving its efficiency outcome .

according to headquarters officials , fmcsa considers the efficiency outcome to include two dimensions: ( 1 ) the number of carriers fmcsa reaches through interventions and ( 2 ) the resources required for fmcsa to conduct interventions , including the time and travel required to complete investigations .

while officials stated that fmcsa monitors some information related to efficiency , such as the number of investigations completed and investigative outcomes , officials acknowledged that fmcsa has not formally established measures for its efficiency outcome .

leading practices for performance management state that agencies should express outcomes in a measurable form and establish a set of performance measures that help monitor progress toward achieving each outcome .

additionally , our work has shown that agencies should create a set of performance measures that addresses important dimensions of program performance and balances competing priorities to increase the usefulness of performance plans in guiding decisions .

while our past work has identified challenges some federal agencies face developing and using outcome - based efficiency measures , it has also highlighted the importance of developing such measures .

because fmcsa does not have a complete set of measures that reflects both its effectiveness and efficiency outcomes for csa interventions , fmcsa managers lack benchmarks needed to regularly monitor progress toward achieving the outcomes .

fmcsa also lacks information needed to balance these priorities and guide management decisions about fmcsa's application of interventions .

fmcsa's limited resources and the increase in crashes involving motor carriers in recent years highlight the importance of ensuring that fmcsa regularly measures and monitors progress toward achieving both of these strategic outcomes .

fatalities involving motor carriers have increased — rising from about 4,200 in 2011 to almost 4,500 in 2015 — and interventions can play a critical role in reversing this troubling trend .

fmcsa aims to reduce such fatalities by using a data - driven approach that identifies and intervenes with the highest - risk motor carriers early .

to monitor its performance , fmcsa has identified improved effectiveness and efficiency as strategic outcomes for csa interventions and has taken some steps to improve agency performance in these areas .

for example , since march 2016 , fmcsa has required field staff to use tools that fmcsa developed to evaluate and improve the quality of onsite investigations and two follow - on interventions .

however , we identified important limitations in the information that fmcsa used to evaluate the effectiveness and efficiency of interventions .

for example , fmcsa's effectiveness evaluations did not produce sufficiently complete , appropriate , and accurate information on individual intervention types or common intervention patterns , because of design and methodology limitations .

although fmcsa officials expressed concern about potential sample size limitations when evaluating the effectiveness of individual intervention types or common intervention patterns , the august 2011 umtri evaluation that fmcsa sponsored as part of its operational model test demonstrated that such evaluations are feasible .

similarly , fmcsa uses cost estimates from umtri's evaluation to understand the efficiency benefits of interventions .

however , the evaluation's cost estimates are no longer current because the time and resources needed to conduct interventions have changed and are not representative of costs nationwide .

without current cost estimates that are representative of nationwide costs , fmcsa lacks information it needs to understand the most efficient methods of conducting csa interventions and cannot assess the relationship between these costs and intervention effectiveness .

moreover , long - standing delays in developing sentri software have compromised the quality of intervention information , thereby limiting fmcsa's ability to accurately and effectively monitor trends in its application of interventions over time and to evaluate intervention effectiveness .

as fmcsa continues its efforts to address data limitations that affect the accuracy of intervention information , it is important that fmcsa not delay taking steps to improve how it currently evaluates the effectiveness and efficiency of csa interventions by ensuring , for example , that its annual effectiveness evaluation addresses other limitations we have identified .

fmcsa has dedicated significant resources to transition from a costly one - size - fits - all approach to a range of more effective and efficient interventions .

however , without improving the quality of information that fmcsa uses to evaluate its performance , the agency will continue to lack the information it needs to determine the extent to which it is achieving these fundamental programmatic improvements .

in addition , we found that although fmcsa has established some performance measures for its effectiveness outcomes , the agency has not established measures to monitor progress toward achieving its efficiency outcome .

fmcsa needs information on all dimensions of its effectiveness and efficiency outcomes to balance these priorities and guide management decisions about its application of interventions .

to determine whether csa interventions influence motor carrier safety performance , the secretary of transportation should direct the fmcsa administrator to: identify and implement , as appropriate , methods to evaluate the effectiveness of individual intervention types or common intervention patterns to obtain more complete , appropriate , and accurate information on the effectiveness of interventions in improving motor carrier safety performance .

in identifying and implementing appropriate methods , fmcsa should incorporate accepted practices for designing program effectiveness evaluations , including practices that would enable fmcsa to more confidently attribute changes in carriers' safety behavior to csa interventions .

to understand the efficiency of csa interventions the secretary of transportation should direct the fmcsa administrator to: update fmcsa's cost estimates to determine the resources currently used to conduct individual intervention types and ensure fmcsa has cost information that is representative of all states .

to enable fmcsa management to monitor the agency's progress in achieving its effectiveness and efficiency outcomes for csa interventions and balance priorities , the secretary of transportation should direct the fmcsa administrator to: establish and use performance measures to regularly monitor progress toward both fmcsa's effectiveness outcome and its efficiency outcome .

we provided a draft of this report to the dot for review and comment .

dot provided written comments , which are reprinted in appendix iv .

in its written comments , dot concurred with our recommendations .

dot also described actions that fmcsa has taken to improve the csa program and noted that csa interventions have been shown to effectively improve motor carriers' safety behavior .

as stated in this report , the evaluations that fmcsa uses to assess intervention effectiveness did not produce sufficiently complete , appropriate , and accurate information on individual intervention types because of design and methodological limitations that limited fmcsa's ability to accurately attribute changes in carriers' safety behavior solely to interventions .

we believe that identifying and implementing appropriate methods to address these limitations will help to provide fmcsa with information it needs to evaluate its performance in achieving its effectiveness outcome for csa interventions .

in addition , dot provided technical comments on the draft report , which we incorporated as appropriate .

we are sending copies of this report to relevant congressional committees , the secretary of transportation , and the administrator of fmcsa .

in addition , the report is available at no charge on gao's website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-2834 or flemings@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix v .

the objectives of our report were to examine: ( 1 ) the extent to which the federal motor carrier safety administration ( fmcsa ) has implemented compliance , safety , accountability ( csa ) interventions and how it has applied them ; ( 2 ) the extent to which fmcsa has evaluated the effectiveness and efficiency of csa interventions ; and ( 3 ) any steps that fmcsa has taken to improve and monitor progress toward achieving its intended outcomes for csa interventions .

to determine the extent to which fmcsa has implemented csa program interventions and how it applied them , we analyzed fmcsa intervention data from fiscal year 2010 through fiscal year 2015 , the most recent fiscal year for which intervention information was available .

specifically , we analyzed data from two fmcsa data systems: ( 1 ) the motor carrier management information system ( mcmis ) and ( 2 ) the enforcement management information system ( emis ) .

if we determined that mcmis and emis data were sufficiently reliable , we intended to then analyze whether there were any notable increases , decreases , or other trends in fmcsa's application of interventions — across states , regions , and motor carrier types ( eg , fleet size ) .

we also intended to determine common intervention patterns when carriers receive multiple interventions ( eg , warning letter , then off - site investigation , then notice of violation ) .

to determine the reliability of fmcsa data we requested a complete set of all mcmis and emis data from fiscal year 2010 through fiscal year 2015 .

to develop our request , we conducted interviews with cognizant fmcsa officials as well as officials from the volpe national transportation systems center , which provides technical support to fmcsa's data analysis .

we would typically review documentation to prepare a data analysis plan ; however , fmcsa could not provide up - to - date or complete data dictionaries or other reference documents for these data systems .

thus , we requested and fmcsa provided sample data tables and variables that we could use to identify the occurrence of each intervention type by analyzing mcmis and emis data .

using the information that fmcsa provided , we performed electronic data testing to count how frequently fmcsa conducted each intervention type in fiscal year 2010 through fiscal year 2015 .

we then compared the results of our analysis against fmcsa - published sources to determine if the results included obvious errors or outliers .

while we replicated fmcsa's counts for warning letters and unsatisfactory / unfit out - of - service orders in all fiscal years , our comparison revealed differences in at least one fiscal year for all remaining intervention types .

we subsequently met with fmcsa data analysis officials on several occasions to identify the cause of the differences that we identified .

fmcsa officials told us that when they modified the algorithms used to count interventions , the agency applied the most recent algorithm to all previous data — including historical data — thereby changing the way that fmcsa counted interventions over time .

as a result , fmcsa officials told us that we could not validate the results of our analysis against agency totals .

after evaluating the reliability of these data for our analytical and reporting purposes , we concluded that the data were of undetermined reliability , because data limitations prevented an adequate and comprehensive assessment .

this precluded our analysis of trends in fmcsa's application of interventions across states , regions , and motor carrier types .

as a substitute , we requested that fmcsa provide estimates for how frequently it applied each intervention type from fiscal year 2010 through fiscal year 2015 to identify general trends .

after reviewing fmcsa documentation related to the estimates and interviewing responsible fmcsa officials , we determined that fmcsa's estimates were sufficiently reliable for this purpose .

we reviewed relevant regulations and fmcsa guidance and policy documents to identify how fmcsa should implement and apply interventions .

for example , we reviewed the electronic field operations training manual ( efotm ) , which is the principal guidance document for assigning intervention types .

in addition , we interviewed fmcsa division officials in eight states that we selected based upon their participation in fmcsa's operational model test of the csa program , geographic location , and program size , among other factors .

selected states included: georgia illinois kansas maryland massachusetts montana oklahoma texas we selected these states to get a range of perspectives on fmcsa's application of interventions .

for example , four of the states participated in fmcsa's operational model test and thus had experience implementing all eight csa intervention types .

similarly , we selected two states from each service center .

although the information obtained from our interviews with officials from the selected states is not generalizable to all states or fmcsa divisions , it provided illustrative examples of how fmcsa is applying interventions as well as the perspectives of officials knowledgeable about the program .

in addition , we interviewed fmcsa officials from each service center — including fmcsa's eastern , midwestern , southern , and western service centers — as well as headquarters officials from fmcsa's office of enforcement , office of field operations , and office of research and information technology .

we also interviewed industry stakeholders , such as the commercial vehicle safety alliance , american trucking associations , trucking alliance , and the owner - operator independent drivers association to gain their perspectives on fmcsa's intervention and enforcement activities .

to determine the extent to which fmcsa has evaluated the effectiveness and efficiency of csa interventions , we intended to conduct our own effectiveness evaluation to determine how interventions affect motor carrier safety and illustrate the strengths and limitations of particular evaluation designs .

however , because mcmis and emis data were of undetermined reliability , we instead reviewed the four evaluations the agency has conducted .

specifically , we reviewed: the university of michigan transportation research institute , evaluation of the csa 2010 operational model test ( august 2011 ) ; fmcsa , fmcsa safety program effectiveness measurement: carrier intervention effectiveness model , version 1.0: summary report for fiscal years 2009 , 2010 , 2011 ( january 2015 ) ; fmcsa , analysis brief: effectiveness of onsite focused investigations ( march 2016 ) ; and fmcsa , effectiveness of offsite investigations: preliminary analysis ( march 2016 ) we conducted a more detailed assessment of the second report on fmcsa's annual effectiveness evaluation model because , according to fmcsa headquarters officials , it is the primary method fmcsa uses to evaluate intervention effectiveness and fmcsa intends to use it on a recurring basis .

in addition , we reviewed fmcsa policy documents — such as fmcsa's strategic plan: fiscal years 2015 – 2018 and efotm guidance — to determine how fmcsa used the information produced by each of its four evaluations .

we also interviewed fmcsa headquarters officials responsible for developing policy and conducting data analysis as well as officials from the volpe national transportation systems center responsible for designing and conducting some fmcsa evaluations .

to assess fmcsa's effectiveness evaluations , we consulted gao's guidance on designing program evaluations , which describes accepted practices for evaluating program effectiveness based on gao studies , policy documents , and program evaluation literature .

we also consulted federal standards for internal control for using quality information , and drew on internal methodological expertise to assess the extent to which the designs , implementation , and results of fmcsa's evaluations met quality information standards .

to determine any steps that fmcsa has taken to improve and monitor progress toward achieving its intended outcomes for interventions , we reviewed relevant fmcsa strategic planning and policy documents that established such outcomes , principally fmcsa's strategic plan: fiscal years 2015 – 2018 .

we reviewed reports from external entities that included recommendations intended to support improvements to fmcsa's compliance and enforcement programs , such as the independent review team's july 2014 report and a march 2014 report from the department of transportation's office of inspector general .

similarly , we reviewed fmcsa's continuous improvement working group's february 2015 report that included recommendations intended to achieve fmcsa's effectiveness and efficiency outcomes .

we also interviewed responsible division , service center , and headquarters officials to identify any steps fmcsa has taken to monitor or improve the effectiveness or efficiency of interventions as well as to determine their perspectives on the effects of these steps .

for example , we interviewed responsible officials at headquarters who develop policy and oversee adherence to federal regulations by interstate motor carriers across the country to understand how they monitor or improve interventions .

we also interviewed service center and division officials to understand the field's involvement in fmcsa's improvement activities .

we compared the results of our documentary review and interviews against leading practices for performance management as well as key attributes of successful performance measures identified in our prior body of work .

although gprama's requirements apply at the departmental level ( eg , the department of transportation ) , we have previously stated they can serve as leading practices at other organizational levels , such as component agencies , offices , programs , and projects .

we conducted this performance audit from july 2015 to october 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on the audit objectives .

headquarters officials told us that the federal motor carrier safety administration ( fmcsa ) obligated funds to develop safety enforcement tracking and investigation system ( sentri ) software each year from fiscal year 2009 through fiscal year 2013 ; however , they could not determine the exact amount of funds because fmcsa did not track information technology investments at the project level during those years .

in addition , the agency obligated about $12 million from fiscal year 2014 through fiscal year 2016 in contractor costs to develop the compliance , safety , accountability ( csa ) component of sentri ( see table 5 ) .

fmcsa officials told us that fmcsa made some progress in developing the csa component of sentri as a result of these investments .

for example , fmcsa coordinated with field staff to identify system requirements .

the federal motor carrier safety administration ( fmcsa ) , in conjunction with the john a. volpe national transportation systems center ( volpe ) has modified an existing effectiveness model to develop a statistical model , the carrier intervention effectiveness model ( ciem ) , which annually measures the effectiveness of interventions .

in january 2015 , fmcsa published its first report using the ciem , which evaluated the effectiveness of compliance reviews , and interventions fmcsa conducted in fiscal years 2009 , 2010 , and 2011 .

we analyzed the ciem and the january 2015 evaluation report , using accepted practices for designing program evaluations and internal staff expertise .

below , we identify methodological strengths and limitations of these efforts , in addition to potential methods fmcsa could use to improve the capabilities of its model to estimate program impacts .

specifically , we have identified strengths and limitations in four key aspects of fmcsa's effectiveness model: ( 1 ) general design , ( 2 ) comparison group , ( 3 ) observation periods , and ( 4 ) statistical analysis and inference .

according to fmcsa documentation , the ciem is a statistical impact evaluation model that uses historical data to compare the safety improvement of carriers receiving fmcsa interventions ( the treatment group ) to carriers that do not ( the comparison group ) .

the january 2015 evaluation report assessed two intervention types that existed prior to the compliance , safety , accountability ( csa ) program , including compliance review investigations and performance and registration information systems management letters , and four new csa intervention types , including warning letters , offsite investigations , onsite focused investigations , and onsite comprehensive investigations .

to estimate the impact of these interventions , the ciem measures the difference between crash rates among carriers in the treatment group before and after receiving interventions , and then subtracts the difference in crash rates among carriers in the comparison group .

the comparison group accounts for confounding factors ( other than fmcsa interventions ) that may affect safety performance during the post - intervention period , such as broad changes in weather or economic conditions .

the model is designed to estimate the impact of interventions carried out in a single fiscal year and measures crash rates over a 12-month period following the first intervention a carrier receives in the fiscal year .

the model estimates the combined impact of all interventions performed during 12-month periods , not the unique impact of each individual intervention type .

we identified the following limitations: lack of process evaluation: the ciem is designed to evaluate impact , but does not include a process study .

according to accepted practices for designing program evaluations , a program logic model or process evaluation that identifies the most important external influences on desired program outcomes is valuable in planning an impact evaluation that convincingly rules out most plausible alternative explanations for the observed results .

process evaluations clarify the program as implemented and specify which of its activities may be responsible for the observed outcomes .

the csa program's logic model might include elements of the csa program , such as fmcsa and state safety inspectors and information systems , roadside inspections , safety interventions , and crashes , injuries , deaths , and monetary losses prevented .

without an initial process evaluation , the impact evaluation cannot precisely identify what aspects of the program affect safety outcomes , or whether the estimated impacts reflect the program as designed .

without studying the program's implementation and comparing its theoretical logic model to actual practices , it is uncertain whether impact estimates represent the effectiveness of the program's activities as designed or the activities that program staff happened to have used in practice .

the ciem's ability to accurately evaluate the impact of the csa program could be improved by taking into account the program's strategy and goals , and studying how the program is implemented .

exclusion of intervention types: the january 2015 evaluation report did not include all intervention types .

according to the report , the evaluation did not assess cooperative safety plans or direct notices of violation and direct notices of claim , because data on these intervention types had inconsistent completeness and accuracy .

fmcsa officials told us that the evaluation included carriers that received follow - on notices of violation or claim , but it did not separately estimate their effects .

when notices of violation or claim follow an investigation , the model implicitly estimates their effects in the post - intervention crash rate .

however , the evaluation could have excluded some carriers that received a notice as their first intervention in the modeled year but not in the same fiscal year as the investigation .

aggregation of intervention types: the ciem implicitly estimates how combinations of interventions affect safety , not the effects of each individual intervention type .

the model identifies only the first intervention that a carrier receives in the modeled year , and estimates the intervention's effect on crash rates from that time of first contact .

according to fmcsa officials , the model is designed to evaluate the effect of general fmcsa contact with carriers through interventions .

officials said that they tested some alternatives to using the first intervention in the fiscal year , including using a carrier's most severe or last intervention in the fiscal year .

agency staff told us that they ultimately preferred to use the first intervention , because it represented the beginning of fmcsa's influence on a carrier within the target time period .

fmcsa did not seek to estimate the effectiveness of individual intervention types , because agency staff had concerns about the small amount of data available on specific intervention types and common intervention patterns when carriers receive multiple interventions over time .

fmcsa officials stated that volpe conducted preliminary analysis of the data used for the ciem to determine potential sample sizes , but did not provide documentation on the sample sizes for each intervention type or common patterns of interventions .

the challenges arising from small sample sizes could potentially be addressed by pooling together data from multiple years , rather than relying on intervention data from one fiscal year .

recommended practices of program and policy evaluation recommend that program managers attempt to separately evaluate multiple types of program activities that seek to achieve a common outcome .

such “comparative effectiveness ( or efficiency ) ” evaluations give managers information on how various activities perform compared to each other .

variation in outcomes across settings or populations can be the result of variation in program operations , such as varying types or levels of enforcement .

further , variation in outcomes associated with features under program control , such as different agency activities , may identify opportunities for managers to take action to improve performance .

to obtain this kind of information on comparative effectiveness , the treatment effects of interventions could be disaggregated into more nuanced categories than having at least one intervention .

this approach could directly evaluate how each of several intervention types , or common intervention patterns , affect safety outcomes .

detailed performance information would better align with the design of the csa program and give staff flexibility to choose from a range of intervention types that can address each carrier's unique safety problems .

with evidence of comparative effectiveness and efficiency , fmcsa would have better information on whether specific csa interventions or combinations of interventions are more effective than others in certain circumstances .

the challenges from small sample sizes on particular interventions could be addressed in several ways .

pooling together data from multiple years , rather than relying on intervention data from one fiscal year , might produce a sufficient sample for evaluating less commonly used interventions .

a multi - year design might become viable as the csa program continues to produce data over several years , though pooling data might increase the potential for unmeasured factors to influence safety outcomes .

a process evaluation , as discussed above , could clarify how fmcsa field staff and state partners have implemented the program and could identify intervention types , or specific combinations of interventions , with sufficient data for analysis .

regression to the mean: the ciem design does not fully account for the possibility that variation over time in the treatment group's safety outcomes reflects regression to the mean .

regression to the mean is a statistical phenomenon in which , following an extreme measurement assumed to be due to random sources of variation , such as sampling error , subsequent measurements are likely to be closer to the average , or mean .

under the csa program , fmcsa prioritizes carriers to receive interventions based on whether the carriers' percentiles exceed pre - determined thresholds in any of seven behavioral analysis and safety improvement categories ( basic ) .

fmcsa's decision to intervene with a carrier largely depends on basic percentiles , and officials use these percentiles , in addition to other criteria set out in guidance , to determine which type of intervention to apply .

this is especially true for carriers that exceed the thresholds intended to identify the highest risk carriers , because fmcsa policy requires that those carriers receive onsite investigations .

however , some carriers , especially those with few inspections or vehicles , may go above the intervention threshold in one measurement period due to anomalous events , but return below the threshold in the next measurement period due to factors unrelated to intervention .

for example , a carrier may generally violate vehicle maintenance regulations at the industry average rate over the long - term .

the carrier's estimated violation rate in fmcsa data — and its related basic percentile — may vary around the long - term average in any particular period .

the degree of variation could reflect the actual inconsistency of the carrier's maintenance practices over time or sampling error in the estimation of its violation rate , related to its frequency of inspection ( exposure to violating regulations ) .

a large deviation in one period from the long - term average could exceed basic percentile thresholds and trigger additional fmcsa oversight , but the deviation may not reflect a real change in the carrier's long - term maintenance behavior .

in a subsequent period , the carrier's basic percentile has a higher probability of returning to the long - term average than continuing at the extreme from the previous period , assuming the prior deviation was caused by random sources of variation , such as sampling error .

the same process may apply to crash rates .

according to recommended practices for evaluating the impact of a program , the evaluation must be carefully designed to rule out plausible alternative explanations for the results .

the ciem's quasi - experiment design implicitly controls for differences across carriers that do not vary substantially over short time periods , which could include carrier management practices , leadership , and operating routes and procedures .

the design controls for industry - wide changes over time that are constant across carriers , changes that could include weather and economic conditions .

lastly , the design explicitly controls for carrier size by stratifying the analysis by size groups .

although the size control may account for differences within carriers over time among the treatment carriers , the model includes few other controls that might specifically address this potential threat to valid causal inference .

by not fully accounting for regression to the mean , the ciem could be attributing changes in outcomes to csa interventions , when those changes would have occurred on their own without intervention .

accordingly , there is some evidence that some carriers' safety behavior improves without intervention .

for example , the independent review team found that , of the carriers fmcsa prioritized for intervention in 2013 , nearly 33 percent had a basic percentile above threshold when assigned for intervention that was no longer above threshold at the time of the review , suggesting that carriers' safety performance may improve naturally without intervention .

as we have previously reported , carriers with fewer vehicles experience wide variance in crash and violation rates , which can make them especially prone to regression to the mean .

an alternative design might compare carriers just above and just below the intervention - triggering threshold ( at a given point in time ) .

this “regression discontinuity” design would lend itself better to interventions triggered automatically when carriers exceed some threshold and would better reflect the nature of the csa program , as recommended in accepted practices for evaluation design .

another alternative approach that could address the regression to the mean issue would be to match carriers based on variation over time in the safety outcomes prior to exceeding a basic percentile threshold .

this design would fall into a general class of methods that include pre - treatment outcomes as an additional covariate .

this would enhance the comparison group's control for any deviations in the outcome over time prior to treatment and thereby ensure that treatment carriers would be matched to comparison carriers with similar outcome dynamics .

the ciem constructs comparison groups using carriers that did not receive any of the model's interventions during the modeled , prior , or subsequent year .

the model assigns carriers to one of several comparison groups , using the same measure of size — the number of vehicles — used to assign carriers to treatment groups .

these separate comparison groups are intended to eliminate differences associated with carrier size from the model's calculation of adjusted crash rates .

we identified the following limitation: limited control: accepted practices for program evaluation would classify the ciem as a “quasi - experimental” design for estimating impact .

quasi - experimental designs compare outcomes in a treatment group to outcomes in a comparison group formed using non - random assignment .

due to the lack of randomized assignment , the treatment and comparison groups may differ on other factors that affect the outcome .

to compensate for this potential bias , evaluators generally ensure that such confounding variables are held constant in the construction of the comparison group or use other methods of adjustment .

the ciem explicitly holds constant one factor in the construction of its comparison group: carrier size .

the model implicitly controls for all factors that vary between the treatment and control groups but remain constant over time , such as state or region of operation .

in addition , the model implicitly controls for all factors that vary over time and affect the treatment and comparison groups equivalently , such as industry - wide effects due to weather or economic conditions .

the ciem's “difference - in - difference” design provides these forms of implicit control , and thus is a key strength of the model .

however , fmcsa might try to construct a more robust comparison group that explicitly controls for more than just carrier size .

since the design controls for variables that are fixed across carriers and vary in the same ways within groups over time , fmcsa might construct a comparison group that controls for change across multiple variables .

if reliable data were available , then potential variables could include: multiple measures of size ; state of registration , inspections , or violations ; driver characteristics ; pre - treatment safety outcomes ; pre - treatment basic percentiles ; and pre - treatment inspections and regulatory violations .

controlling for pre - treatment outcomes and basic percentiles would be especially desirable and would address the potential limitation of regression to the mean because the fluctuations due to sampling error would be controlled by design .

data availability and reliability may limit fmcsa's ability to include additional control variables to construct comparison groups .

for example , the 2015 evaluation report notes that data on vehicle miles traveled — a measure of carrier exposure to crashes — were less reliable than vehicle count data because , according to officials , they were sometimes incomplete or inconsistent across carriers .

similarly , officials told us that fmcsa considered using carrier operation type to construct comparison groups , but ultimately did not because some carriers reported multiple operation types or changed their operation types over time .

given the central importance of the csa program to fmcsa's enforcement efforts , the agency would benefit from improving or expanding data collection to support a more robust model .

the ciem defines different observation periods for the treatment and control groups .

for the treatment group , the ciem uses the date of the first intervention in the modeled fiscal year as the demarcation between a 12-month pre - intervention period and a 12-month post - intervention period .

pre - and post - intervention crash rates are measured for these 12- month periods .

for the comparison group , in contrast , the ciem defines 18-month periods preceding and following the midpoint of the modeled fiscal year to measure pre - and post - intervention crash rates .

 ( this is because comparison carriers do not have an intervention date to define the pre - and post - intervention periods and measure crash rates. ) .

the evaluation report noted that these longer 18-month periods ensure that the comparison group's crash rates cover the entire treatment group time frame .

to adjust for the 50 percent longer observation period for carriers in the comparison group , the evaluation divided crash rates for those carriers by 1.5 to yield annual crash rates .

we identified the following limitation: inconsistent time periods: according to accepted practices for program impact evaluation , a design must confidently rule out non - program influences that could cause changes in outcomes to occur .

the ciem does not completely account for factors that might have affected crash rates for both treatment and comparison groups , because the lack of overlap between the measurement time periods does not hold constant factors unique to the season or period of measurement .

for example , as fmcsa officials noted to us , crash rates are known to depend on seasonal and periodic changes in weather , and the model's lack of overlap in measurement time periods meant that treatment and comparison groups were subject to different seasonal and periodic conditions .

other potential confounding variables include seasonal or periodic variation in economic demand and state enforcement resources .

the design might use measurement periods that vary as a function of each observed intervention's timing and characteristics .

for example , the design might construct a custom comparison group for each member of the treatment group , selecting multiple comparison carriers using size and other potential confounding variables .

a matching design in which each treatment carrier is compared to one or more control carriers would allow identical observation periods while still producing an impact estimate for interventions applied during a single fiscal year .

the ciem's use of statistical inference is appropriate to quantify the uncertainty of its impact estimates .

carrier behavior and safety outcomes are consistent with a partially random data generation process .

in this context , statistical inference estimates the sampling variability of the data over multiple hypothetical realizations of the same process .

applying inferential statistical methods appropriately reflects the potential for the observational regulatory , intervention , and safety data to vary partially at random .

a critical estimate in the ciem is the net crash rate change for the treatment group .

the model defines this quantity as the difference between the treatment group's pre - and post - intervention crash rates , after subtracting the crash rate change in the comparison group .

the model then tests whether the net change differs from zero at the 0.05 statistical significance level .

the model excludes insignificant findings from its subsequent estimates of total safety benefits calculated .

the model estimates safety benefits by transforming the estimated net change in crash rates due to interventions into an estimate of total crashes avoided , using the treatment group's pre - intervention crash rate per vehicle and post - intervention vehicle counts .

the model uses historical crash severity data to further estimate injuries prevented and lives saved associated with each prevented crash .

the model extrapolates these safety benefits — crashes avoided , injuries prevented , and lives saved — to carriers that received interventions , but were excluded from the treatment group due to missing or outlier crash or vehicle count data , and , according to officials , intrastate carriers that were excluded from the treatment group in the january 2015 version of the model .

the january 2015 evaluation notes that fmcsa assumed that these carriers will exhibit the same response to intervention as the carriers included in the model .

accordingly , the model adds the estimated safety benefits for carriers included in the model to those for carriers with outliers and missing data .

the sum determines the aggregate estimated safety benefits .

according to the 2015 evaluation report , fmcsa extrapolated safety benefits to the following number of carriers that received an intervention but were not included in the model: 9,567 carriers in fiscal year 2009 ; 9,929 carriers in fiscal year 2010 , and ; 14,816 carriers in fiscal year 2011 .

we identified the following limitations: multiple hypothesis tests: the model uses multiple statistical hypothesis tests to calculate total safety benefits .

the ciem estimates impact on crash rates within four strata of treatment and comparison groups defined by carrier size .

if the net change in crash rates within each stratum is statistically distinguishable from zero at the 0.05 confidence level , the model uses the results to estimate total safety benefits by summing the estimated benefits across groups .

statistically insignificant results in any stratum provide zero safety benefits by assumption .

in this sense , the model's estimate of total safety benefit reflects the results of 4 separate hypothesis tests , each at the 0.05 confidence level .

= 1 – ( 1 – α ) k. when k = 4 and α = 0.05 , α = 0.18 .

see hayes , 450. methods of hypothesis testing typically recommend adjusting the confidence level of each individual test , such as by applying bonferroni adjustments , so that the group - wise error probability matches the analyst's intended risk level for all planned tests .

these adjustments typically produce lower alpha values for each individual test .

multiple hypothesis testing methods would be appropriate for the ciem , given that it ultimately seeks to estimate total safety benefits as a function of multiple hypothesis tests .

without making these adjustments , the ciem's estimates of total safety benefits may have more risk of error than fmcsa intends to accept because the model does not conduct a joint test .

that is , the probability that at least one group's safety benefits equals zero may exceed the 0.05 confidence level that fmcsa accepts in each individual test .

an alternative approach might calculate the confidence interval of the summed safety benefit estimate and test whether it equals zero , consistent with the discussion below .

confidence intervals of estimated impacts: the ciem uses inferential statistical methods to test the hypothesis that the impact for each pair of treatment and control groups equals zero .

however , the ciem does not conduct statistical inference , such as estimating confidence intervals , when analyzing the net change in crash rates and associated total safety benefits .

this approach is inconsistent , given that the model's hypothesis test for a non - zero net change in crash rates implies that the quantity is a random variable with a sampling distribution and confidence interval .

the model's authors agree with this implication , suggesting that the test is equivalent to a “95 percent confidence interval that does not include zero.” total safety benefits must also have a confidence interval , given that it is a function of the change in net crash rates .

nevertheless , the ciem reports only point estimates of safety benefits , without conveying the statistical uncertainty that the model's assumptions imply .

accordingly , the ciem might estimate and report confidence intervals for its estimates of crash rate impact and safety benefits , in order to make the statistical inference consistent and quantify the uncertainty of its estimates .

the current hypothesis testing approach may produce a point estimate for safety benefits that appears more precise than the underlying confidence interval would support .

in addition to the individual named above , h. brandon haller ( assistant director ) , william colwell ( analyst in charge ) , katherine blair , melissa bodeau , russell burnett , david hooper , benjamin licht , grant mallie , ifunanya nwokedi , malika rice , sandra sokol , niti tandon , and jeff tessin made key contributions to this report .

