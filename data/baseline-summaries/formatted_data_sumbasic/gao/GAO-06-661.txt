the nation's economic prosperity and global competitiveness depend in the nation's economic prosperity and global competitiveness depend in large part on the effective education of the 48 million students who attend large part on the effective education of the 48 million students who attend public schools .

congress passed the no child left behind act of 2001 public schools .

congress passed the no child left behind act of 2001 ( nclba ) requiring states to steadily improve academic performance so ( nclba ) requiring states to steadily improve academic performance so that , at a minimum , all students are proficient , that is , able to read and do that , at a minimum , all students are proficient , that is , able to read and do math at grade level .

among the law's principal goals are that all students math at grade level .

among the law's principal goals are that all students are proficient by 2014 and achievement gaps close between high - and low - are proficient by 2014 and achievement gaps close between high - and low - performing students , especially those in designated groups such as performing students , especially those in designated groups such as economically disadvantaged students .

economically disadvantaged students .

with these two key goals in mind , states were required to set challenging with these two key goals in mind , states were required to set challenging standards for both academic content and achievement and to determine standards for both academic content and achievement and to determine whether schools made adequate yearly progress ( ayp ) toward meeting whether schools made adequate yearly progress ( ayp ) toward meeting those standards .

for a school to make ayp , it must meet or exceed the those standards .

for a school to make ayp , it must meet or exceed the state's annual proficiency targets and meet or demonstrate progress on a state's annual proficiency targets and meet or demonstrate progress on a target on another measure — graduation rates in high school or attendance target on another measure — graduation rates in high school or attendance or other measures in elementary and middle schools .

if schools do not or other measures in elementary and middle schools .

if schools do not meet these requirements , their students may be eligible to receive tutoring meet these requirements , their students may be eligible to receive tutoring or transfer to another school .

or transfer to another school .

states set proficiency targets using status models that calculate the percentage of students with test scores that meet or exceed these targets 1 year at a time .

with status models , states or districts determine whether schools make ayp based on annual performance while generally not taking into account how much better or worse the school did as compared to the previous year .

thus , a school that is showing large increases in student achievement but has too few students at the proficient level would not likely make ayp .

further , status models do not account for the fact that student characteristics in a school may change from one year to the next and these changes can affect whether a school makes ayp .

because of the limitations of status models , some states have expressed interest in determining ayp by using growth models that measure year - to - year progress in proficiency .

“growth models” is a term that refers to a variety of methods of tracking changes in proficiency levels or test scores over time .

one type of model , known as an improvement model , measures year - to - year school growth , but does not account for the fact that different students constitute a school from one year to the next .

because of this , some researchers do not consider it to be a growth model .

in this report , we included improvement models as a type of growth model in order to provide a broad assessment of options that may be available for states .

growth models vary in complexity , such as calculating annual progress in a school's average test scores from year to year , estimating test score progress while accounting for factors such as student background , or projecting future scores based on current and prior years' results .

in 2005 , the department of education ( education ) started a pilot project to allow up to 10 states to use growth models to determine whether schools make ayp for the 2005-2006 school year .

the pilot project requires that state growth models meet certain criteria , such as measuring progress toward universal proficiency by 2014 .

in response to congressional interest in how growth models may be used to meet the law's key goals and in anticipation of reauthorization of the elementary and secondary education act of 1965 , we assessed ( 1 ) the extent that states have used growth models to measure academic achievement , ( 2 ) the extent that growth models can measure school progress in achieving key nclba goals , and ( 3 ) challenges states may face in using growth models to meet ayp requirements and how education is assisting the states .

to address these objectives , we conducted a survey of all states , the district of columbia , and puerto rico to determine whether they were using growth models as of march 2006 .

we received responses from all except puerto rico , and in this report we will refer to the 51 respondents as states .

we visited or conducted telephone interviews with state and local educational agency officials in 8 states that collectively use a variety of growth models to understand their use .

we selected these states and schools based on expert recommendations and on variation in the types of models they used .

to examine the extent that these models measure progress toward key goals of universal proficiency by 2014 and closing achievement gaps , we analyzed student - level data from selected schools in massachusetts and tennessee , states selected because of data availability .

in both cases , gao conducted an assessment of the reliability of these data and found the data to be sufficiently reliable for illustrating how growth models measure progress toward key goals of nclba .

we conducted site visits to those states and selected school districts and schools to learn how their results were calculated .

we also conducted site visits in california and north carolina , two states with different types of growth models , to provide additional perspectives .

to identify challenges to using growth models and education's assistance to states , we interviewed education officials , state education officials , and other experts , including members of education's growth model working group .

we also reviewed relevant federal and state laws , policies , and guidance as well as research on growth models .

for more information on our methodological model , see appendix i .

we conducted our work between june 2005 and may 2006 in accordance with generally accepted government auditing standards .

the no child left behind act of 2001 increased the federal government's role in kindergarten - 12th grade education by setting two key goals: to reach universal proficiency so that all students score at the proficient level of achievement — as defined by the states — by 2014 , and to close achievement gaps between high - and low - performing students , especially those in designated groups: students who are economically disadvantaged , are members of major racial or ethnic groups , have learning disabilities , or have limited english proficiency .

with these two key goals in mind , nclba requires states to set challenging academic content and achievement standards in reading or language arts and mathematics to determine whether school districts and schools make ayp toward meeting these standards .

education has responsibility for general oversight of the nclba .

as part of this oversight , education is responsible for reviewing and approving state plans for meeting ayp requirements .

as we have reported , it approved all states' plans — fully or conditionally — by june 2003 .

it also reviews state systems of standards and assessments to ensure they are aligned with the law's requirements .

as of april 2006 , education had approved these systems for delaware , south carolina , and tennessee and was in the process of reviewing them in other states .

states measure ayp using a status model that determines whether or not schools and students in designated groups meet proficiency targets on state tests 1 year at a time .

to make ayp , schools must show that the percentage of students scoring at the proficient level or higher meets the state proficiency target for the school as a whole and for designated student groups , test 95 percent of all students and those in designated groups , and meet goals for an additional academic indicator ( which can be chosen by each individual state for elementary and middle schools but must be the state - defined graduation rate in high schools ) .

states generally used data from the 2001-2002 school year to set the initial percentage of students that needed to be proficient for a school to make ayp , known as a starting point , as prescribed in the nclba and education's guidance .

using these initial percentages , states then set annual proficiency targets that increase up to 100 percent by 2014 .

for example , for schools in a state with a starting point of 28 percent to achieve 100 percent by 2014 , the percentage of students who scored at or above proficient on the state test would have to increase by 6 percentage points each year , as shown in figure 1 .

setting targets for increasing proficiency through 2014 does not ensure that schools will raise student performance to these levels .

instead , the targets provide a goal , and schools that do not reach the goal will generally not make ayp .

school districts with schools receiving federal funds under title i part a that do not make ayp for 2 or more years in a row must take action to assist students , such as offering students the opportunity to transfer to other schools or providing additional educational services like tutoring .

school districts with schools that meet these criteria must set aside an amount equal to 20 percent of their title i funds to provide these services and spend up to that amount depending on how much demand exists for these services to be provided .

these schools , in consultation with their districts , are also required to implement a plan to improve their students' achievement .

the law indicates that states are expected to close achievement gaps , but does not specify annual targets to measure progress toward doing so .

states thus have flexibility in the rate at which they close these gaps .

to determine the extent that achievement gaps are closing , states measure the difference in the percentage of students in designated student groups and their peers that reach proficiency .

using a hypothetical example , figure 2 shows how closing achievement gaps between economically disadvantaged students and their peers would be reported .

in this example , 40 percent of the school's non - economically disadvantaged students were proficient compared with only 16 percent of disadvantaged students in 2002 , a gap of 24 percentage points .

to close the gap , the percentage of students in the economically disadvantaged group that reaches proficiency would have to increase at a faster rate than that of their peers .

by 2014 , the gap is eliminated , with both groups at 100 percent proficient .

if a school misses its status model target , the law also provides a way for it to make ayp if it significantly increases the proficiency rates of student groups that do not meet the proficiency target .

the law includes a provision , known as safe harbor , which allows a school to make ayp by reducing the percentage of students in designated student groups that were not proficient by 10 percent , so long as it also shows progress on another academic indicator .

safe harbor measures academic performance similar to certain growth models , according to one education researcher .

for example , in a state with a status model target of 40 percent proficient , a school could make ayp under safe harbor if 63 percent of a student group were not proficient compared to 70 percent in the previous year .

see figure 3 .

in contrast to status models that measure the percentage of students at or above proficiency in a school 1 year at a time , growth models measure change in achievement or proficiency over time .

some of these models show changes in achievement for schools and student groups using students' average scores .

other models provide more detailed information on how individual students progress over time .

growth models can enable school officials to monitor the year - to - year changes in performance of students across many levels of achievement , including those who may be well below or well above proficiency .

they may also be used to predict test scores in future years based on current and prior performance .

while definitions of growth models vary , for this report , gao defines a growth model as a model that measures changes in proficiency levels or test scores of a student , group , grade , school , or district for 2 or more years .

some definitions restrict the use of the term “growth models” to refer only to those models that measure changes for the same students over time .

gao included models in this report that track different groups of students in order to provide a broad assessment of options that may be available to states .

growth models can be designed to measure successive groups of students ( for example , students in the third grade class in 2006 with students in the third grade class in 2005 ) or track a cohort of students over time ( for example , students in the fourth grade in 2006 with the same students in the third grade in 2005 ) .

school - level growth models track changes in the percentage of students that reach proficiency or their achievement scores over time .

for example , the charts in figure 4 show how two hypothetical schools measure their proficiency with a status model and with a measure of progress over time .

in the case of washington middle school , a growth model shows a decline in performance , while a status model indicates that the school exceeded the state proficiency target of 40 percent .

this school was able to make ayp even though its proficiency rate decreased .

in contrast , the use of a growth model with adams elementary school shows that the school improved its performance , but its status model results indicate that the school did not meet the 40 percent proficiency target .

that school did not make ayp , even though its proficiency rate increased .

thus , the type of model used could lead to different perspectives on how schools are performing .

individual - level growth models track changes in proficiency or achievement for individual students over time .

for example , individual student growth can be measured by comparing the difference between a student's test scores in 2 consecutive years .

a student may score 300 on a test in one year and 325 on the test in the next year , resulting in an increase of 25 points .

these scores could then be averaged to measure school - level results as in the previous example .

individual student growth can also be measured over more than 2 years to identify longer - terms trends in performance .

additionally , growth can be projected into the future to predict when a student may reach proficiency , and that information may be used to target interventions to students who would otherwise continue to perform below standard .

nearly all states were using or considering growth models to track performance , as of march 2006 .

although nclba requires states to use status models to determine whether schools make ayp , the 26 states with growth models reported using them for state purposes such as identifying schools in need of extra assistance .

seventeen of these states had growth models in place prior to nclba .

twenty - six states reported using growth models in addition to using their status models to track the performance of schools , designated student groups , or individual students , in our survey as of march 2006 ( see figure 5 ) .

additionally , nearly all states are considering the use of growth models: 20 of 26 states that used one growth model were also considering or in the process of implementing another growth model , and 22 of 25 states that did not use growth models were considering or in the process of implementing them to provide more detailed information about school , group , or student performance .

seventeen of the 26 states using growth models reported that their models were in place before the passage of the nclba during the 2001-2002 school year , and the remaining 9 states implemented them after the law was passed , as shown in figure 8 .

once nclba was enacted , states were required to develop plans to show how they would meet federal requirements for accountability as measured by whether their schools made ayp .

education approved these plans , but generally did not permit states to include growth models .

according to education officials , since nclba requires that states make ayp determinations on the basis of the percentage of students who are proficient at one point in time — rather than the increase or decrease in that percentage over time — growth models were considered inconsistent with the goals of the act .

for example , california began using its model , called the academic performance index , in the 1999-2000 school year to set yearly growth targets for schools .

these targets were based on combined test scores for reading / language arts , mathematics , and other subjects .

however , according to officials at the california department of education , california's model , developed prior to nclba , was not designed to explicitly achieve the law's key goals of universal proficiency by 2014 or closing achievement gaps .

further , a california department of education official explained that because the model did not report scores from reading , math , and other subjects separately , california was not approved to make ayp determinations using its model .

in contrast , massachusetts' growth model was in place prior to nclba passage and then was adapted to align explicitly with the law's key goals .

education approved massachusetts' ayp plan , allowing the state to use both its status model and growth model to determine ayp .

instead of using growth models to make ayp determinations , states used them for other purposes , such as rewarding effective teachers and designing intervention plans for struggling schools .

for example , north carolina used its model as a basis to decide whether teachers receive bonus money .

tennessee used its value - added model to provide information about which teachers are most effective with which student groups .

in addition to predicting students' expected scores on state tests , tennessee's model was used to predict scores on college admissions tests , which is helpful for students who want to pursue higher education .

in addition , california used its model to identify schools eligible for a voluntary improvement program .

the type of growth model used has implications for how results may be applied .

california's model provides information about the performance of its schools , enabling the state to distinguish higher - performing from lower - performing schools .

however , the model does not provide information about individual teachers or students .

in contrast , tennessee's model does provide information about specific teachers and students , allowing the state to make inferences about how effective its teachers are .

while california may use its results for interventions in schools , tennessee may use its results to target interventions to individual students .

certain growth models measure the extent that schools and students are achieving key nclba goals .

while the use of growth models may allow states to recognize gains schools are making toward the law's goals , it may also put students in some lower - performing schools at risk for not receiving additional federal assistance .

while states developed growth models for purposes other than nclba , states such as massachusetts and tennessee have adjusted their state models to use them to meet nclba goals .

the massachusetts model has been used to make ayp determinations as part of the state's accountability plan in place since 2003 .

this model is approved by education in part because it complies with the key goal of universal proficiency by 2014 .

tennessee submitted a new model to education for the growth model pilot project that differs from the value - added model we describe earlier .

the value - added model , developed several years prior to nclba , gives schools credit for students who exceeded their growth expectations .

the new model gives schools credit for students projected to reach proficiency within 3 years in order to comply with the key nclba goal of showing that students are on track to reach proficiency by 2014 .

like status models , certain growth models can measure progress in achieving key nclba goals of reaching universal proficiency by 2014 and closing achievement gaps .

our analysis of how models in massachusetts and tennessee can track progress toward the law's two key goals is shown in table 2 .

our analysis of data from selected schools in those states demonstrates how these models measure progress toward the key goals .

one school in massachusetts had a baseline score of 27.4 points in math .

its growth target for the following 2-year cycle was 12.1 , requiring it to reach 39.5 points by 2004 .

in comparison , the state's target using its status model was 60.8 points in 2004 .

the growth target was set at 12.1 because , if the school's points increased this much in each of the state's six cycles , the school would have 100 points by 2014 .

in so doing , it would reach universal proficiency in that year , as is seen in figure 9 .

in fact , the school scored 42.6 in 2004 , thus exceeding its target of 39.5 .

the school also showed significant gains for several designated student groups that were measured against their own targets .

however , the school did not make ayp because gains for one student group were not sufficient .

this group — students with disabilities — showed gains of 9.3 points resulting in a final score of 23.6 points , short of its growth target of 28.6 .

figure 10 compares this school's baseline , target , and first cycle results for the school as a whole and for selected student groups .

massachusetts has designed a model that can measure progress toward the key goal of nclba by setting growth targets for each year until all students are proficient in 2014 .

schools like the one mentioned above can get credit for improving student proficiency even if , in the short term , the requisite number of students have yet to reach the current status model proficiency targets .

the model also measures whether achievement gaps are closing by setting targets for designated student groups , similar to how it sets targets for schools as a whole .

schools that increase proficiency too slowly — that is , do not meet status or growth targets — will not make ayp .

tennessee developed a different model that also measures progress toward the nclba goals of universal proficiency and closing achievement gaps .

tennessee created a new version of the model it had been using for state purposes to better align with nclba .

referred to as a projection model , this approach projects individual student's test scores into the future to determine when they may reach the state's status model proficiency targets in the future .

this model was accepted as part of education's pilot project , allowing the state to use it to make ayp determinations in the 2005-2006 school year .

in order to make ayp under this proposal , a school could reach the state's status model targets by counting as proficient those students who are predicted to be proficient in the future .

the state projects scores for elementary and middle school students 3 years into the future to determine if they are on track to reach proficiency , as follows: fourth grade students projected to reach proficiency by seventh grade , fifth grade students projected to reach proficiency by eighth grade , and sixth , seventh , and eighth grade students projected to reach proficiency on the state's high school proficiency test .

these projections are based on prior test data and are not based on student characteristics .

also , the projections are based on the assumption that the student will attend middle or high schools with average performance ( an assumption known as average schooling experience ) , and allow the student's current school to count them as proficient in the current year if they are projected to be proficient in the future .

tennessee estimated that of its 1,341 elementary and middle schools , 47 schools that did not make ayp using its status model would be able to make ayp under its proposed model that gives schools credit for students projected to be proficient in the future .

at our request , tennessee provided analyses for students in several schools that would make ayp under the proposed model .

to demonstrate how the model works , we selected students from a school and compared their actual results in fourth grade ( panel a ) with their projected results for seventh grade ( panel b ) ( see figure 11 ) .

some students who were not proficient based on their scores in 2004-2005 were projected to be proficient by the time they reach later grades .

for example , student a did not score at the proficient level in fourth grade but was projected to score at the proficient level in seventh grade .

the state has proposed to determine whether schools make ayp by using the percentage of students who are projected to be proficient ( like student a ) in the future , instead of the percentage of students presently proficient .

for example , if 79 percent of an elementary school's students are projected to be proficient on future math tests , the school will make ayp for the state's 79 percent target in the 2005-2006 school year , regardless of the percentage of students in that school that are currently proficient .

tennessee's proposed model can also measure achievement gaps .

under nclba , a school makes ayp if all student groups meet the state proficiency target .

for example , a school could have a 20 percentage point gap for one group if , for example , 59 percent of students with limited english proficiency were proficient compared to 79 percent of their peers .

while results based on projections may show that achievement gaps are closing , gaps would actually be closed only if the projections were realized .

using these models to measure progress , states could recognize improvement by allowing some schools to make ayp even though the schools may have relatively low achieving students .

these schools may have a long way to go before reaching 100 percent proficiency and will need to increase student proficiency at a faster rate than schools making ayp under a status model .

if a school that receives funds under title i is unable to sustain this rate of progress , it may have difficulty reaching universal proficiency by 2014 .

in addition , if a school that did not meet status model targets but made ayp by meeting growth model targets , its students may not qualify for additional assistance provided for by nclba .

schools that receive title i funds and that do not make ayp for 2 consecutive years are identified for improvement .

according to some school district officials , it may be helpful not to be identified for improvement because they can devise their own interventions instead of implementing school transfer programs or working with state - approved supplemental educational service providers .

while delaying these interventions may disadvantage students in some title i schools , reducing the number of schools identified for improvement could allow for greater concentration of dollars in the lowest - performing schools .

in massachusetts , of the 134 schools in the two districts we analyzed , 23 of the 59 schools that made ayp did so based on the state's growth model even though they did not reach the state's status model proficiency rate targets in 2003-2004 .

the state had its growth model approved by education as part of its accountability plan and therefore was able to determine that these 23 schools made ayp .

one of these schools served a high - minority , low - income population and missed the state proficiency target in english / language arts of 75.6 points for the school as a whole and for each of its student groups .

for example , one student group , students with disabilities , scored 44.3 points , missing the target by 31.3 .

however , this school made ayp , because the school as a whole and each of its student groups had shown enough improvement to meet their growth targets — including the group of students with disabilities that improved by 6.8 points .

in tennessee — of the 1,341 schools for which the state made ayp determinations in the 2004-2005 school year — 47 of the 353 schools ( 13.3 percent ) that had not made ayp would do so if the state's proposed projection model were applied .

however , some of these schools have many other indicators of needing assistance .

for example , one school that would be allowed to make ayp under the proposed model was located in a high - poverty , inner - city neighborhood .

that school receives title i funding , as two - thirds of its students are classified as economically disadvantaged .

the school was already receiving services required under nclba to help its students .

if it makes ayp 2 years in a row , these services may no longer be required .

additionally , estimates of future proficiency often rely on certain assumptions .

in the case of tennessee's proposed model , a key assumption is that students would receive an average schooling experience in the years between when the data were measured and when the final projection is made .

according to tennessee officials , an average schooling experience is defined as one in which a student receives instruction in a school whose performance is the average of all schools in the state .

to the extent that a student attends a school with performance that is significantly different from average , actual performance is likely to deviate from the estimates , rendering those estimates relatively less reliable .

moreover , by allowing a school to count students' future proficiency in the current year , the tennessee proposal may only be delaying a school's inability to meet status model targets and forestalling needed assistance .

states face challenges in implementing growth models that education's initiatives may help address .

challenges states face include the extent that states' data and assessment systems will support the models , whether the models can generate valid and reliable results , and states' expertise to use , manage and communicate results about growth .

these challenges are generally similar to those faced by states in implementing status models but are accentuated , because growth models measure progress over multiple years and thus require more data and systems designed to track data over time .

education's growth model pilot program and data system grants may make it possible for more states to meet ayp requirements using a growth model , but greater usage largely depends upon improving states' data and assessment systems .

one challenge states face in using growth models is the ability to collect comparable data over at least 2 years , a minimum requirement for any growth model .

states must ensure that test results are comparable from one year to the next and possibly from one grade to the next , both of which are especially challenging when test questions and formats change .

depending on the type of model , states may incorporate scores from 2 , 3 , or even more prior years .

officials from 13 states that were implementing or considering the use of growth models told us that they need to consider their state's ability to make comparisons from one year to the next before their model could be operational .

other states that are implementing new data systems or assessments may have to wait a few years before they have enough data to assess progress from one year to the next .

for example , one of those state officials said that his state will need at least 3 years of test data in order to set realistic multiyear growth targets for its proposed growth model .

some states currently using growth models , such as florida and ohio , have been collecting and comparing student data for several years .

a significant challenge to implementing growth models that use student - level data is the capacity to collect these data across time and schools .

this capacity often requires a statewide system to assign unique numbers to identify individual students .

at least 37 states have systems with unique numbers as of april 2006 , according to officials with the data quality campaign ( a nonprofit organization that helps states improve data quality ) .

developing and implementing these systems is a complicated process that includes assigning numbers , setting up the system in all schools and districts , and correctly matching individual student data over time , among other steps .

for example , school staff must have students' unique numbers when students change schools .

however , education officials have cited cases of school staff assigning a new number for a student instead of locating the student's original number .

additionally , peer reviewers for education's growth model pilot project cited concerns about the ability of 3 states to correctly match student data from year to year .

some states have contracted with outside organizations to assist them in establishing these systems .

in addition , one model provides a “teacher effect score” as an estimate of the impact that individual teachers have on individual students' academic achievement , thus requiring even more information .

ensuring data are free from errors is important for calculations using status models and growth models .

doing so is more important when using growth models , because errors in multiple years can accumulate , leading to unreliable results .

fourteen state officials cited concerns about the design and reliability of growth models in areas ensuring data accuracy and measuring progress .

states also need greater research and analysis expertise to use growth models as well as support for people who need to manage and communicate the model's results .

for example , tennessee officials told us that they have contracted with a software company for several years because of the complexity of the model and its underlying data system .

florida has a contract with a local university to assist it with assessing data accuracy , including unique student identifiers required for its model .

in addition , states will incur training costs as they inform teachers , administrators , media , legislators , and the general public about the additional complexities that occur when using growth models .

for example , administrators in one district in north carolina told us that personnel issues are their main concerns with using growth models .

their district lacks enough specialists who can explain the state's growth model to all principals and teachers in need of guidance and additional training .

in an effort to address their limited capacity , district officials told us they have been collaborating with neighboring districts to share training resources regarding the state's growth model .

in november 2005 , education announced a pilot project for states to submit proposals for using a growth model — one that meets criteria established by the department — along with their status model , to determine ayp .

education officials told us that the department is conducting its pilot project under authority provided in the law that , upon request from a state , allows the secretary to waive certain requirements in the nclba .

while the nclba does not specify the use of growth models for making ayp determinations , the department started the pilot in part to gain information on how these models might help schools achieve the law's key goals .

according to education officials , 7 states had already requested to use growth models for ayp determinations before the department invited states to submit growth model proposals .

for the growth model pilot project , each state had to demonstrate how its growth model proposal met education's criteria , referred to as “core principles” outlined in its november 2005 announcement .

while many of these criteria are consistent with the legal requirements of status models , tracking student progress over time and having an assessment system with tests that are comparable over time are new ( see table 3 ) .

twenty states submitted proposals to education by the february 17 , 2006 deadline .

education reviewed proposals from the 14 states that planned to make ayp determinations for the 2005-2006 school year and forwarded 8 of them for peer review .

in may 2006 , education approved north carolina and tennessee to use their proposed growth models to make ayp determinations for the 2005-2006 school year .

education noted that those states met all of the department's criteria , such as reaching the key nclba goals of universal proficiency and closing achievement gaps .

additionally , education and peer reviewers noted that those states had many years of experience with data systems that support calculating results using growth models .

the 6 states whose proposals had received peer review were invited to resubmit proposals in september 2006 .

other states that had submitted proposals for the 2006-2007 school year , and those that had not previously submitted proposals were invited to do so by november 1 , 2006 , for potential implementation in the 2006-2007 school year .

while tennessee received unconditional approval to implement its proposed growth model , peer reviewers noted they were concerned that tennessee's use of “average school experience” is likely to result in inaccurate projections , especially for disadvantaged students .

this is because many students attend schools in districts that are struggling , and the schools they are likely to attend 3 years out could provide them with a school experience that is markedly below average .

for this reason , education requested that the state , after it implements the model , provide data to compare actual results with its projections .

north carolina received approval as long as its system of standards and assessments was approved by july 1 , 2006 .

reviewers of the state's proposal noted that the state proposed to average student results for calculating growth , instead of examining growth results of all students , in direct violation of education's criteria .

according to education , the state changed its original approach so that growth would account for all students and would not use averages .

six states had proposals that were peer - reviewed but not approved .

the department cited a variety of reasons for not approving these proposals , including that they did not lead to universal proficiency by 2014 , applied growth calculations to nonproficient students only ( instead of all students ) , used a margin of error on individual test results that would likely lead to students' being counted as proficient when in fact they were not , and proposed annually resetting growth targets .

education is allowing these states to resubmit their proposals for review later in 2006 .

if approved then , they can use growth models to make ayp determinations in the 2006-2007 school year .

approved states must report to education the number of schools that made ayp on the basis of their status and growth models .

education expects to share the results with other states , congress , and the public after it assesses the effects of the pilot .

in addition to the growth model pilot project , education announced in april 2005 a competition for grants for the design and implementation of statewide longitudinal data systems .

while independent of the pilot project , states with a longitudinal data system — one that gathers data on the same student from year to year — will be better positioned to implement a growth model than they would have been without it .

many states applied to participate in the growth model pilot project or received a grant ( see table 4 ) .

longitudinal data systems link data , such as test scores and enrollment patterns , of individual students over time .

education intended the grants to help states generate and use accurate and timely data to meet reporting requirements , support decision making , and aid education research , among other purposes .

education received applications from 45 states for the 3-year grants , and in november 2005 , education awarded a total of $52.8 million in grants to 14 states .

states receiving grants must submit annual and final reports on the status of the development and the implementation of these systems .

education plans to disseminate lessons learned and solutions developed by states that received grants .

while status models provide a snapshot of academic performance , growth models can provide states with more detailed information on how schools' and students' performance has changed from year to year .

growth models can recognize schools whose students are making significant gains on state tests but are still not proficient and may provide incentives for schools with mostly proficient students to make greater improvements .

educators can use the growth models of individual students to tailor interventions to the needs of particular students or groups .

in this respect , models that measure individual students' growth provide the most in - depth and useful information , yet most of the models currently in use are not designed to do this .

through its approval of massachusetts' model and the growth model pilot program , education is proceeding prudently in its effort to allow states to use growth models to meet nclba requirements .

education is allowing only states with the most advanced models that can measure progress toward nclba goals to use the models to determine ayp .

if schools are allowed to make ayp by getting credit for growth , some lower - performing schools will make ayp and the opportunity for school improvements the federal law prescribes to help students may be missed .

however , if schools that show the most growth but do not meet status model targets are permitted to make ayp , states could target title i school improvement on their lowest - performing schools .

by proceeding with a pilot project with clear goals and criteria and by requiring states to compare results from their growth model with status model results , education is poised to gain valuable information on whether or not growth models are overstating progress or whether they appropriately give credit to fast - improving schools .

we obtained written comments on a draft of this report from the department of education .

education's comments are reproduced in appendix iii .

education also provided additional technical comments , which have been included in the report as appropriate .

education commented that it appreciates our concluding observation that the department “is poised to gain valuable information on whether or not growth models are overstating progress or whether they appropriately give credit to fast - improving schools.” education expressed concern that the definition of growth models used in the report may confuse readers because it is very broad and includes models that compare changes in scores or proficiency levels of schools or groups of students .

to inform its pilot project , education used research that defines the term “growth model” to refer to models that track the growth of individual students .

for the purposes of this report , we defined growth models to include models that track growth of schools , groups of students , and individual students over time .

while we acknowledge that some research exists to define growth models as tracking the same students over time , other research exists to show that there are different ways of classifying models that states use or could potentially use .

as such , the definition used in this report reflects the variety of approaches states are taking to measure academic progress .

as agreed with your staff , unless you publicly announce its contents earlier , we plan no further distribution of this report until 30 days after its issue date .

at that time , we will send copies of this report to the secretary of education and other interested parties .

we will also make copies available to others upon request .

in addition , the report will be made available at no charge on gao's web site at http: / / www.gao.gov .

please contact me at ( 202 ) 512-7215 if you or your staff have any questions about this report .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors are listed in appendix iv .

to address the objectives of this study , we used a variety of methodological models .

we interviewed experts in the field of measuring academic achievement as well as state , district , and school officials .

we also reviewed documentation from states' web sites , and examined published studies that detailed characteristics and policy issues of states' models .

we conducted a series of interviews in selected states with officials who had a variety of experiences and viewpoints on growth models .

in four of those states — california , massachusetts , north carolina , and tennessee — we interviewed officials at the state , district , and school levels so that we could obtain a variety of perspectives on growth models .

we selected those states for in - depth interviews based on diverse characteristics of their respective models , all of which were in place prior to the no child left behind act of 2001 ( nclba ) .

to address the first objective , we surveyed state education agencies in the 50 states , the district of columbia , and puerto rico and reviewed documentation from states' accountability workbooks .

states reported to us whether they were using or considering the use of a growth model to measure academic achievement .

the surveys were conducted using self - administered electronic questionnaires sent in an e - mail to all 52 states beginning january 13 , 2006 .

we closed the survey on march 16 , 2006 , after the 51st respondent had replied .

puerto rico did not complete the survey .

the survey asked respondents to indicate , first , whether the state was currently using a growth model .

gao classified school - level models , like improvement models , as growth models for the purposes of this report .

some restrict the use of the term “growth models” to refer only to those that measure changes for the same group of students or individual students over time ( see , for example , council of chief state school officers , policymakers' guide to growth models for school accountability: how do accountability models differ ? .

washington , d.c.: oct. 2005 ) .

gao included school - level models in this study to provide a broader assessment of options that may be available to states .

if the state was using a growth model , we asked about its characteristics , whether the state was considering use of an additional model , whether the state planned to apply to education's growth model pilot program , and how the results from its model were used .

if the state was not using a growth model , we asked whether it was considering doing so .

we also asked about characteristics of the model under consideration and about key issues that must be addressed in order for it to be implemented .

in some cases , we asked additional questions in e - mails and in phone interviews .

the other methods we used to learn about states' models included reviewing documentation from states' web sites and examining published studies that detailed characteristics and policy issues of states' models .

to address the second objective , we analyzed data from selected schools from two states , massachusetts and tennessee .

these states were chosen based on a variety of factors , including expert recommendation , their use of different growth models , geographic diversity , and data availability .

within these states , we selected schools that were in urban , suburban , and rural areas .

for massachusetts , for one urban district and one suburban district , we selected the median school ( as measured by the schools' index values ) among schools that had shown growth but had not made adequate yearly progress in the 2004-2005 school year .

for tennessee , for one urban district and one rural district , we selected schools that were used in the state's growth model pilot project proposal .

state officials from massachusetts provided individual student data to gao from the two selected school districts .

gao reviewed the state's adequate yearly progress and growth model calculations and replicated school - level index and calculations from student and statewide data .

state officials from tennessee provided analyses its contractor had performed , also using individual student data .

in both cases , gao conducted an assessment of the reliability of these data and found the data to be sufficiently reliable for illustrating how growth models measure progress toward key goals of nclba .

these assessments included electronic testing of data fields and interviews with state officials and in tennessee's case , the contractor as well .

these interviews consisted of questions regarding the history of the data system , system audits and security , and possible threats to the systems , among other topics .

gao's assessments also included reviews of documentation regarding the data systems .

to address the third objective , we used data from the survey and information provided to us by education and state officials .

we reviewed documentation related to education's growth model pilot project and proposals submitted by several states .

we interviewed education and state officials about the pilot project , including criteria for selection and processes for review and approval .

we conducted our work between june 2005 and may 2006 in accordance with generally accepted government auditing standards .

the tables below provide specific information on characteristics of states' growth models ( as of the 2005-2006 school year ) , as reported on the survey .

this information includes the grades in which growth models were reported , the level at which growth models were reported , the measures of achievement used to determine growth in test scores , and the characteristics of the assessments used to compare students' test scores .

states using growth models varied as to whether or not they used test scores from consecutive grades .

seventeen states reported using growth models in consecutive grades , while 9 states reported using them in nonconsecutive grades .

for example , tennessee uses test scores from grades 4 through 12 , while vermont uses grades 5 , 8 , and 10 .

whether states used test scores from consecutive grades may depend on the type of model they used .

the states that reported measuring individual student growth used test scores in consecutive grades ( for example , grades 3 through 12 or 4 through 10 ) .

in contrast , the 19 states that use school - level information in their growth model calculations varied in the combination of grades they used in their models: 11 of those 19 states used growth models in three or more 8 used a variety of grade combinations .

for each state with a growth model , table 5 lists the grades in which the state reports school growth and indicates whether the model measures individual student growth .

states with growth models reported results for schools but varied in terms of reporting results at other levels , such as the individual student or school district .

table 6 lists the different levels at which states with growth models reported results .

the measure of achievement in growth models indicates the methods states use to compare individual and group scores to determine the amount of growth .

table 7 outlines the measures that each state with a growth model used to determine how growth is reported .

growth models rely on data from state proficiency tests and measure growth with a variety of characteristics as shown in table 8 .

blake ainsworth ( assistant director ) , jason palmer ( analyst - in - charge ) , and dan alspaugh ( analyst - in - charge ) managed the assignment .

karen febey , shannon groff , and robert miller made significant contributions to this report , in all aspects of the work .

kathy larin , harriet ganson , lise levie , beth morrison , and rachael valliere provided analytic assistance .

luann moy provided support with the survey .

anna maria ortiz and beverly ross provided analytic assistance with measuring school results related to key nclba goals .

jim rebbe provided legal support and mimi nguyen developed the report's graphics .

no child left behind act: improved accessibility to education's information could help states further implement teacher qualification requirements .

gao - 06-25 .

washington , d.c.: nov. 21 , 2005 .

no child left behind act: education could do more to help states better define graduation rates and improve knowledge about intervention strategies .

gao - 05-879 .

washington , d.c.: sept. 20 , 2005 .

no child left behind act: most students with disabilities participated in statewide assessments , but inclusion options could be improved .

gao - 05-618 .

washington , d.c.: july 20 , 2005 .

charter schools: to enhance education's monitoring and research , more charter school - level data are needed .

gao - 05-5 .

washington , d.c.: jan. 12 , 2005 .

no child left behind act: education needs to provide additional technical assistance and conduct implementation studies for school choice provision .

gao - 05-7 .

washington , d.c.: dec. 10 , 2004 .

no child left behind act: improvements needed in education's process for tracking states' implementation of key provisions .

gao - 04-734 .

washington , d.c.: sept. 30 , 2004 .

no child left behind act: additional assistance and research on effective strategies would help small rural districts .

gao - 04-909 .

washington , d.c.: sept. 23 , 2004 .

special education: additional assistance and better coordination needed among education offices to help states meet the nclba teacher requirements .

gao - 04-659 .

washington , d.c.: july 15 , 2004 .

student mentoring programs: education's monitoring and information sharing could be improved .

gao - 04-581 .

washington , d.c.: june 25 , 2004 .

no child left behind act: more information would help states determine which teachers are highly qualified .

gao - 03-631 .

washington , d.c.: july 17 , 2003 .

title i: characteristics of tests will influence expenses ; information sharing may help states realize efficiencies .

gao - 03-389 .

washington , d.c.: may 8 , 2003 .

