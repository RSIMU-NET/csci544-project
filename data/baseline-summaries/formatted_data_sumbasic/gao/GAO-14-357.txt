the transportation security administration ( tsa ) , a component of the department of homeland security ( dhs ) , accelerated the deployment of advanced imaging technology ( ait ) systems , commonly referred to as full - body scanners , in response to the december 25 , 2009 , attempted terrorist attack on northwest airlines flight 253 .

according to tsa officials , ait systems provide enhanced security benefits compared with those of walk - through metal detectors by identifying nonmetallic threat objects and liquids .

in addition , tsa officials stated that ait systems provide additional deterrence to potential terrorists and enhance screening efficiencies when compared with physical pat - downs .

following the accelerated deployment of ait , the public and others raised privacy concerns because ait systems produced images of passengers' bodies that image operators ( io ) analyzed to identify objects or anomalies that could pose a threat to an aircraft or to the traveling public .

to mitigate those concerns , tsa began installing automated target recognition ( atr ) software on deployed ait systems in july 2011 .

ait systems equipped with atr ( ait - atr ) automatically interpret the image and display anomalies on a generic outline of a passenger instead of displaying images of actual passenger bodies like the ait systems that used ios ( ait - io ) .

screening officers ( so ) use the generic image of a passenger to identify and resolve anomalies on site in the presence of the passenger .

in response to the december 25 , 2009 , bombing attempt , tsa increased the number of units it originally planned to procure and deploy from 878 to 1,800 ait systems , but in 2012 , subsequently lowered the number of ait systems it sought to procure to 1,250 as a result of implementing new risk - based screening measures and tsa pretm lanes.2013 and 2014 , tsa did not request additional funding to procure ait systems .

in 2013 , tsa planned to further reduce the number of ait systems to 878 in response to changing screening processes .

as of march 2014 , tsa had deployed about 740 ait systems at almost 160 airports , and we estimate that tsa will spend over $3.5 billion in life cycle costs on deployed ait - atr systems and future ait systems .

pursuant to the federal aviation administration modernization and reform act of 2012 , enacted in january 2012 , tsa was mandated to ensure that ait systems used to screen passengers were equipped with atr software by june 1 , 2012 .

tsa subsequently extended this deadline to june 1 , 2013 .

according to tsa , by the june 1 , 2013 , deadline , all deployed ait systems have been equipped with atr software .

see pub .

l. no .

112-95 , § 826 , 126 stat .

11 , 132-33 ( 2012 ) ( codified at 49 u.s.c .

§ 44901 ( / ) ) .

further , in february 2012 , tsa issued a request for vendors to provide a second generation of ait systems , referred to as ait - 2 , which would be required to have atr software , among other things , as discussed later in this report .

approve this roadmap.procurements contingent on meeting those milestones and to acknowledge in the roadmap any uncertainty regarding the attainment of those milestones .

dhs agreed with these recommendations , and in february 2012 , tsa completed a roadmap that contained milestones for achieving enhanced capabilities , which we discuss later in this report .

we also recommended that tsa make future we also found that tsa had acquired ait systems that were not used on a regular basis , and thus were not providing a security benefit .

therefore , we recommended that tsa evaluate the use of deployed ait systems and redeploy systems that were not being extensively used .

dhs concurred with this recommendation .

although tsa has taken steps to address our recommendation by developing and implementing mechanisms to better track the use of deployed ait systems , we found during our most recent review that it has not fully addressed our recommendation because tsa has not ensured that the utilization data it collects are accurate , and , as a result , cannot use these data to inform future deployment decisions .

for more information on tsa's efforts to address this recommendation , see appendix i .

as an update to our prior work , you asked us to evaluate tsa's efforts to enhance effectiveness of ait systems .

specifically , this report addresses the following questions: 1 .

to what extent does tsa collect and analyze available information that could be used to enhance the effectiveness of the ait - atr system ? .

2 .

to what extent has tsa made progress toward enhancing ait capabilities to detect concealed explosives and other threat items , and what challenges , if any , remain ? .

to determine the extent to which tsa collects and analyzes available information that could be used to enhance the effectiveness of the entire ait - atr system , we analyzed improvised explosive device ( ied ) checkpoint drills conducted by tsa personnel at airports that submitted data to tsa from march 1 , 2011 , through february 28 , 2013 , under tsa's ied checkpoint drill operational directive .

tsa's ied checkpoint drill operational directive requires personnel at airports to conduct drills to assess tso compliance with tsa's screening standard operating procedures ( sop ) and to train tsos to better resolve anomalies identified by ait - atr systems .

among other things , we evaluated airport compliance with tsa's operational directive and standards for internal control in the federal government to determine the extent to which tsa is monitoring compliance with its directive .

further , we analyzed laboratory test results of the ait - atr system and the ait - io system from calendar years 2009 through 2012 conducted by the transportation security laboratory ( tsl ) to compare both systems' false alarm rates and conducted statistical analysis of those data .

we visited the tsl in atlantic city , new jersey , to interview laboratory scientists responsible for testing and evaluating ait - atr systems and reviewed tsl documentation related to laboratory test plans , records , and final reports .

further , we assessed the extent to which laboratory test results demonstrated that the ait - atr system met requirements outlined in key acquisition practices established by gao , because the ait system is considered a large - scale acquisition program .

we analyzed the adequacy of laboratory tests by comparing the testing design with generally accepted statistical methods used for data collection and analysis .

we assessed the reliability of the laboratory and ied checkpoint drill data we used by interviewing officials responsible for capturing and monitoring the data about , among other things , applicable quality control procedures to maintain the integrity of the data , performing statistical tests on the data , and reviewing testing reports and related documentation .

we determined these data were sufficiently reliable for the purposes of this report .

we also interviewed tsa officials involved in ait - atr system deployment , training , and covert testing .

we compared the extent to which tsa evaluated the performance of the entire system against key acquisition practices established by gao , guidelines contained in dhs's acquisition directive 102-01 , and tsl's test management plan .

we also visited a nonprobability sample of four u.s. airports to observe ait - atr systems and interviewed relevant tsa personnel who operate those systems to obtain their views on system performance .

the information we obtained from those visits cannot be generalized to other airports , but provided perspectives of various ait - atr system users .

to determine progress tsa has made and any challenges that remain toward enhancing ait capabilities to detect concealed explosives and other threat items , we analyzed tsa's original ait roadmap dated february 2012 , as well as the october 2012 revision .

to determine the extent to which tsa has met its projected time frames for ait - atr system upgrades and ait - 2 development , we reviewed actions taken by tsa testing officials and compared the actual dates for each milestone with the estimated dates documented in tsa's ait roadmap .

to determine the extent to which tsa's ait roadmap contains fundamental elements of technology roadmaps , we analyzed and compared technology roadmapping guidance developed by the department of energy's sandia national laboratories with tsa's ait roadmap .

we also reviewed technology roadmaps for large - scale acquisition programs developed by various agencies and organizations , such as the department of defense , for examples of technology roadmaps that adhered to established guidance and compared these roadmaps with tsa's ait roadmap .

to determine the extent to which the milestones contained in tsa's ait roadmap are attainable , we interviewed scientists from the sandia national laboratories and the pacific northwest national laboratory , a leading ait vendor , tsa acquisition officials , and a group of 12 experts identified by the national academy of sciences to discuss practices used to test technical performance of threat detection technologies , which include ait systems , at the developmental stage .

our interviews with these experts are illustrative and provide insights about testing best practices .

we also reviewed prior gao reports on ( 1 ) major acquisition programs to identify best practices for delivering capabilities within schedule and cost estimates and ( 2 ) key practices that can help sustain agency collaboration to leverage each others' resources and obtain additional benefits that would not be available if they were working separately.found in appendix ii .

more details on our scope and methodology can be this report is a public version of the prior classified report that we provided to you .

dhs and tsa deemed portions of information in the report as secret and sensitive security information , which must be protected from public disclosure .

therefore , this report omits a research question and recommendation about the ait - atr system's effectiveness at detecting threats and the extent to which ait - atr system performance compares with ait - io system performance .

this report also omits details related to tsa's tiered requirements for ait systems ; the results of our interviews with airport staff ; information about so performance at resolving anomalies identified by the ait - atr system ; specific testing results depicting the ait - atr systems' false alarm rate ; specific airport checkpoint drill requirements , including the number of airports that were required to conduct those drills ; specific details pertaining to the number of years it would take to provide enhanced capabilities ; and deficiencies identified during ait testing .

although the information provided in this report is more limited in scope , the overall methodology used for both reports is the same .

we conducted this performance audit from september 2012 to march 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

dhs and tsa share responsibility for the research , development , and deployment of passenger checkpoint screening technologies .

the aviation and transportation security act established tsa as the federal agency with primary responsibility for securing the nation's civil aviation system , which includes the screening of all passengers and property transported to , from , and within the united states by commercial passenger aircraft .

additionally , the homeland security act of 2002 established dhs and , within it , the science and technology directorate for , among other things , conducting research , development , demonstration , and testing and evaluation activities relevant to dhs.dhs's science and technology directorate is responsible for testing and evaluating aviation security technologies , including ait systems , at the tsl on behalf of tsa .

dhs and tsa conducted five types of tests to evaluate the performance of ait - atr systems .

qualification testing .

tsl conducted qualification tests in a laboratory setting to evaluate the technology's capabilities against tsa's procurement specification and detection standard that specified the required detection rate ait systems must meet in order to qualify for procurement .

qualification tests evaluate the technology's detection of threat items that are not artfully concealed as they are in covert tests , but do not test the entire system , including the so's interpretation and resolution of alarms .

qualification testing also includes testing of the system's false alarm rate .

for the purposes of this report , we refer to qualification testing as laboratory testing .

operational testing .

tsa conducted operational tests that assessed the technology's detection performance , called threat - inject tests , at airports to evaluate the ait - atr systems' ability to function in an operational environment .

operational testing also assesses how well ait systems are suited for use in a real - world , aviation checkpoint environment after systems have successfully completed qualification testing in a laboratory setting .

for example , operational testing includes determining whether the system interfered with other equipment fielded at the checkpoint and whether the system met tsa's requirements .

further , dhs's acquisition policy requires that operational tests be conducted prior to an agency procuring a technology .

according to tsa testing documentation , threat - inject tests are not intended to evaluate effectiveness of the entire ait - atr system , which includes the technology , the personnel who use the technology , and the processes that govern screening , in an operational setting .

covert testing .

tsa's office of inspection and the dhs office of inspector general conducted covert tests of ait - atr systems at the passenger checkpoint to identify vulnerabilities in tsa's screening process .

according to tsa officials , those tests were intended to identify weaknesses in the technology , the operators who used it , and tso compliance with sops by artfully concealing threat objects intended to simulate a likely terrorist attack .

performance assessments .

tsa conducted covert performance assessments of tso compliance with sops , under the aviation screening assessment program ( asap ) , which tsa uses as a standard performance measurement for the office of management and budget .

according to tsa officials , asap assessments determine so adherence to tsa's sops and are not intended to test ait - atr system capabilities .

checkpoint drills .

in accordance with tsa's ied checkpoint drill operational directive , tsa requires personnel at airports to conduct drills to assess tso compliance with tsa's screening sops and to train tsos to better resolve anomalies identified by ait - atr systems .

tsa conducts those drills at airports using test kits that contain inert bombs , bomb parts , and other threat items .

according to tsa officials , ied checkpoint drills assess so adherence to tsa's sops and are not intended to test ait - atr system capabilities .

tsa uses a multilayered security strategy aimed to enhance aviation security .

within those layers of security , tsa's airport passenger checkpoint screening system includes , among other things , ( 1 ) screening personnel ; ( 2 ) sops that guide screening processes conducted by tsos ; and ( 3 ) technology , such as ait - atr systems , used to conduct screening according to tsa , those elements collectively determine of passengers.the effectiveness and efficiency of passenger checkpoint screening .

in strengthening one or more elements of its checkpoint screening system , tsa aims to balance its security goals with the need to efficiently process passengers .

passenger screening is a process by which tsos inspect individuals and their property to deter and prevent an act of violence , such as carrying an explosive , weapon , or other prohibited item onboard an aircraft or into the airport sterile area — in general , an area of an airport for which access is controlled through screening of persons and property .

individuals for prohibited items at designated screening locations , referred to as checkpoints , where tsos use technology and follow sops to screen passengers .

according to tsa's sop for ait - atr systems , three tsos are required to operate lanes equipped with ait systems: one divestiture officer ( of either gender ) , one male so , and one female so .

see 49 c.f.r .

§ 1540.5 .

as we reported in january 2012 , tsa's requirements for the ait system have evolved over time .

tsa continued to use those revised requirements to determine whether the ait - atr system met the agency's needs .

additionally , tsa used those requirements to evaluate the next generation of ait systems , referred to as ait - 2 .

further , tsa's requirements for ait systems are based on tiers that correspond to the relative size of items that the ait system must identify and requirements that the ait system must meet , with tier i being the level currently deployed ait systems already meet and tier iv being tsa's anticipated goal for ait systems to meet .

tsa's procurement of ait - 2 systems requires vendors to ensure ait - 2 systems meet tier ii requirements and provide faster throughput , among other things .

tsa plans to seek proposals from ait - 2 vendors to provide tier iii and tier iv capabilities by time frames specified in its ait roadmap .

tsa did not initially plan for ait - io systems to meet levels beyond tier iii , but included tier iv in response to our recommendation .

tsa does not collect or analyze three types of available information that could be used to enhance the effectiveness of the entire ait - atr system .

first , tsa does not collect or analyze available airport - level ied checkpoint drill data on so performance at resolving alarms detected by the ait - atr system to identify weaknesses and enhance so performance at resolving alarms at the checkpoint .

second , tsa is not analyzing ait - atr systems' false alarm rate in the field using data that could help it monitor the number of false alarms that occur on ait - atr systems to help monitor the potential impacts that ait - atr systems may have on operational costs .

third , tsa assesses the overall ait - atr system performance using laboratory test results that do not reflect the combined performance of the technology , the personnel that operate it , and the process that governs ait - related security operations .

tsa does not collect or analyze ied checkpoint drill data , because it does not ensure compliance with its operational directive that requires each airport to conduct ied checkpoint drills each week .

specifically , the operational directive , originally issued in february 2010 and updated in november 2012 , requires tsa personnel at airports to conduct a certain number of ied drills per checkpoint lane every week at each airport .

the total number of drills per pay period must be split evenly between carry - on baggage and passenger screening .

additionally , for those airports equipped with ait systems , a certain percentage of on - person drills must be conducted on ait systems and a certain percentage must be conducted on walk - through metal detectors .

tsa is not enforcing compliance with its directive , and as a result , data on so performance are not being consistently collected or reported by approximately half of airports with ait - atr systems .

for example , according to tsa data , we found that tsa personnel at almost half of the airports with ait - io or ait - atr systems did not report any ied checkpoint drill results on those systems from march 2011 through february 2013 .

of the airports at which tsa personnel conducted ied checkpoint drills , the number of drills conducted by tsa personnel at airports varied from 1 to 8,645 .

further , roughly four - fifths of the on - person ied drills were conducted by screening passengers with metal detectors , with the rest of the ied drills conducted by screening passengers with ait systems , which did not comply the directive's specified requirements on the number of drills that must be conducted on each type of technology .

according to tsa officials , tsa's office of security operations is responsible for overseeing compliance with the operational directive at airports , but it does not analyze the ied checkpoint drill data at the headquarters level .

further , tsa officials told us that tsa formerly tracked the number of ied checkpoint drills in a monthly management report for federal security directors , but in fiscal year 2012 , that report was replaced by an executive scorecard that tracks each airport's ied checkpoint drill pass rate but does not include the number of drills conducted .

tsa officials stated that federal security directors could conduct very few drills that are easy for sos to identify in order to achieve a high pass rate , since the details of the drills are not provided to headquarters or analyzed beyond the pass rate .

according to tsa officials , the agency does not ensure compliance with the directive at every airport because it is unclear which office within the office of security operations should oversee enforcing the operational directive .

according to officials from tsa's office of training and workforce engagement , that office had the ability to monitor the program until tsa began using federal security director scorecards in 2012 , which are reviewed by the office of security operations .

as a result , it is still unclear which office is ultimately responsible for overseeing whether tsa is in compliance with the operational directive at airports .

data on ied checkpoint drills could provide insight into how well sos resolve anomalies detected by the ait systems , information that could be used to help strengthen the existing screening process .

by not clarifying which office is responsible for overseeing tsa's ied checkpoint drills operational directive , directing that office to ensure enforcement of the directive in conducting these drills , and analyzing the data , tsa is missing an opportunity to identify any potential weaknesses in the screening process , since performance depends in part on the ability of sos to accurately resolve anomalies .

tsa is not analyzing available data on the number of secondary screening pat - downs that sos conduct as a result of an ait - atr system alarm , which indicates that it has detected an anomaly .

analyzing this information could provide insight into the number of false alarms that occur in the field , which may affect operational costs .

specifically , when the ait - atr system identifies the presence of an anomaly , indicated by an alarm , the so must resolve the anomaly by conducting a pat - down to determine whether the anomaly is a threat item .

if the so does not resolve the anomaly during the pat - down ( i.e .

by locating an item in the location identified by the ait - atr system alarm ) , this may be attributed to either a false alarm ( the ait - atr system identified an anomaly when none actually existed ) or so error ( the so did not identify an anomaly that was present ) .

by not analyzing such operational data , tsa is limited in its understanding of the operational effectiveness of deployed ait - atr systems .

tsa collected information on false alarm rates through laboratory testing conducted at tsl .

these laboratory test results demonstrated that ait - atr systems have a higher false alarm rate than ait - io systems .

our analysis showed that the ait - atr system's false alarm rate can be expected to range significantly based on the estimate's 95 percent confidence interval , which could have implications for so performance at resolving alarms and operational costs .

although tsa's detection standard required ait - atr systems to meet a specific false alarm rate , tsl laboratory test results on the ait - atr system indicate that certain factors , such as body mass index ( bmi ) and headgear , such as turbans and wigs , may contribute to greater fluctuations in the false alarm rate , either above or below that threshold .

for example , the false alarm rate for passengers with a normal bmi was less than the false alarm rates for overweight and obese passengers .

additionally , the ait - atr system had a higher false alarm rate when passengers wore turbans and wigs .

while tsa did not include the false alarm rate as a key performance requirement that could be used as a basis to accept or reject ait - atr systems , higher false alarm rates could result in higher operational costs .

according to tsa , the ait - atr systems' current false alarm rate could produce an increase in annual staffing costs in the field , but it has not conducted studies on this issue .

according to dhs's science and technology directorate , effective checkpoint screening technologies have lower false alarm rates , as well as higher throughput and lower costs of operations , which enhance the effectiveness and efficiency of how tsa screens passengers .

tsa's functional requirements document stated that ait - atr systems must have a data collection and reporting system that collects , stores , analyzes , and displays a summary report on the outcomes of scans .

the ait - atr systems are required to provide , at a minimum , the total number of passengers scanned , total number of passengers on which the system detected anomalies , and the body location of where an anomaly was detected .

tsa reported in its system evaluation report that the ait - atr system was equipped with that data collection and reporting system and the summary report .

according to tsa , it verified that currently deployed ait - atr systems capture those data in operational testing and evaluation .

however , tsa does not collect or analyze those data at headquarters .

rather , tsa gives tsa management at airports the discretion to determine how to use those data and whether to enter those data into tsa's centralized information management system .

tsa officials agreed that collecting and analyzing operational data would provide useful information related to the impact of false alarm rates on operational costs , and collecting those data could be done on a selective basis so that it would not be too labor - intensive .

according to tsa officials , tsa is in the process of networking all ait - atr systems so that information can be collected at the headquarters level , and when this process is complete , tsa would be able to centrally collect operational data that could provide information on secondary screening outcomes , which provide insight into the operational false alarm rate .

tsa officials were not able to provide an estimate of when this will be completed .

given the potential staffing implications associated with a higher false alarm rate , it is important to fully understand the system's false alarm rate in the field .

without a complete understanding of how the systems perform in the field , tsa may be at risk of incurring significantly higher operational costs than anticipated .

although tsa officials stated that collecting such data could be labor - intensive if not collected selectively , the agency agreed that evaluating operational screening data in the field could provide useful information , and that data could be collected in such a way that it does not negatively affect operations .

standards for internal control in the federal government calls for agencies to identify , capture , and distribute operational data to determine whether an agency is by not establishing meeting its goals and effectively using resources.protocols that facilitate capturing operational data on passengers at the checkpoint once the ait - atr systems are networked together , tsa is unable to determine the extent to which ait - atr system false alarm rates affect operational costs and has less information for its decision - making process related to checkpoint screening .

according to tsa officials , checkpoint security is a function of technology , people , and the processes that govern them , but tsa does not include measures for each of those factors in determining overall ait - atr system performance .

tsa evaluated the technology's performance at meeting certain requirements in the laboratory to determine system effectiveness .

laboratory test results provide important insights but do not accurately reflect how well the technology will perform in the field with actual human operators .

figure 1 illustrates the multiple outcomes of the ait - atr screening process .

although tsa conducted operational tests on the ait - atr system prior to procurement , tsa does not assess how anomalies are resolved by considering how the technology , people , and processes function collectively as an entire system when determining ait - atr system performance .

tsa officials agreed that it is important to analyze performance by including an evaluation of the technology , operators , and processes , and stated that tsa is planning to assess the performance of all layers of security .

according to tsa , the agency conducted operational tests on the ait - atr system , as well as follow - on operational tests as requested by dhs's director of operational test and evaluation , but those tests were not ultimately used to assess effectiveness of the operators' ability to resolve alarms , as stated in dhs's director of operational test and evaluation's letter of assessment on the technology .

tsl officials also agreed that qualification testing conducted in a laboratory setting is not always predictive of actual performance at detecting threat items .

further , laboratory testing does not evaluate the performance of sos in resolving anomalies identified by the ait - atr system or tsa's current processes or deployment strategies .

according to best practices related to federal acquisitions , technologies should be demonstrated to work in their intended environment .

according to dhs's acquisition directive 102-01 and its associated guidebook , operational testing results should be used to evaluate the degree to which the system meets its requirements and can operate in the real world with real users like sos .

tsl's test management plan for ait systems stated that effectiveness must reflect performance under realistic or near - realistic operating conditions .

additionally , a group of experts on testing best practices assembled by the national academy of sciences concluded that agencies should include the human element when evaluating system performance .

that group of experts also determined that agencies should determine system effectiveness by conducting performance testing in an operational setting in addition to laboratory testing , which could include sos during testing .

tsa conducted operational tests , but it did not use those tests to determine ait - atr effectiveness .

instead , tsa used laboratory tests that did not factor in performance of the entire system that includes technology , people , and processes .

however , ait - atr system effectiveness relies on both the technology's capability to identify threat items and its operators to resolve those threat items .

given that tsa is seeking to procure ait - 2 systems , dhs and tsa will be hampered in their ability to ensure that future procurements meet mission needs and perform as intended at airports without measuring system effectiveness based on the performance of the ait - 2 technology and sos who operate the technology , while taking into account current processes and deployment strategies .

tsa has enhanced passenger privacy by completing the installation of atr software upgrades for all deployed ait systems but could do more to provide enhanced ait capabilities to meet the agency's mission needs .

moreover , the agency faces technological challenges in meeting its goals and milestones pertaining to enhancing ait capabilities .

tsa has met milestones as documented in its roadmap pertaining to the installation of atr software upgrades that were intended to address privacy concerns and improve operational efficiency for all deployed ait systems in accordance with the statutory deadline included as part of the federal aviation administration modernization and reform act of 2012.however , it did not meet proposed milestones documented in its ait roadmap to provide enhanced capabilities to meet the agency's mission needs .

for example , the february 2012 ait roadmap estimated that tsa would complete installation of tier ii atr software upgrades for currently deployed ait systems by december 2012 .

tsa's updated october 2012 ait roadmap revised this date to march 2013 .

according to tsa testing documentation , during operational testing conducted from may through june 2012 at an airport test site , the ait - atr tier ii system demonstrated limitations due to noncompliance with certain requirements .

accordingly , tsa decided not to pursue fielding of the tier ii system based on particular deficiencies identified during operational testing .

the vendor of this system submitted a new version of the ait - atr system for laboratory testing to tsl .

in september 2013 , the new version had passed laboratory testing and was undergoing operational test and evaluation .

as shown in figure 2 , tsa began operational test and evaluation for tier ii upgrades 17 months after the expected start date articulated in its october 2012 roadmap .

according to tsa , it completed operational test and evaluation in january 2014 .

according to the timeframes in tsa's revised roadmap , it would take an additional 7 months from january 2014 to complete tier ii upgrades .

however , tsa had estimated that it would provide tier iii capabilities by the end of fiscal year 2014 .

although tsa experienced challenges and schedule slippages related to meeting tier ii requirements for the currently deployed ait systems , in september 2012 , tsa made contract awards to purchase and test the next generation of ait systems ( referred to as ait - 2 ) from three vendors .

these systems are required to be equipped with atr software and must be capable of meeting enhanced requirements ( qualified at least at the tier ii level ) , among other things .

the updated october 2012 roadmap contained milestones for testing and acquiring ait - 2 systems , which tsa has not met .

specifically , tsa is about 9 months behind schedule for ait - 2 testing and procurement , as depicted in figure 3 .

for example , the roadmap indicated that tsa would begin qualification testing and evaluation for ait - 2 during the first quarter of fiscal year 2013 , would complete that testing by january 2013 , and would complete deployment by march 2014 .

however , tsa did not initiate qualification testing until july 2013 ( about 9 months behind schedule ) because all three vendors had difficulty providing qualification data packages verifying that the vendors had met contractual requirements and the systems were ready to begin testing .

accordingly , as of march 2014 , tsa is not on track to meet the march 2014 deployment milestone and these efforts have not resulted in enhancing ait capabilities because currently deployed ait - atr systems are qualified at the same tier i level as the systems originally deployed in 2009 .

we have reported in the past few years that although ait systems and the associated software have been in development for over two decades , tsa has faced challenges in developing and meeting program requirements in some of its aviation security programs , including ait .

best practices for acquisition programs state that when key technologies are immature at the start of development , programs are at higher risk of being unable to deliver on schedule .

as we concluded in january 2012 , at the start of ait development , tsa did not fully adhere to dhs acquisition guidance , and procured ait systems without meeting all key requirements .

according to best practices on major acquisitions , realistic program baselines with stable requirements for cost , schedule , and performance are important to delivering capabilities within schedule and cost estimates .

in its ait roadmap , tsa describes the time frames as notional and explains that establishing definitive timelines for reaching defined , additional tiers is difficult to achieve because of intricate dependencies that are outside of the program's control and may vary by manufacturer .

however , tsa officials stated that they did not use available scientific research or evidence to help assess how long it would take to develop enhanced capabilities .

in setting these time frames , tsa officials told us that tsa did not seek input from national laboratories that have conducted technology assessments and explosives research on behalf of dhs's science and technology directorate nor did it evaluate vendor data to determine the capabilities of the technology .

according to experts we interviewed from sandia national laboratories , to accurately determine realistic time frames in which vendors would be able to provide enhanced capabilities , it would require an evaluation of proprietary vendor data to understand how well the technology can meet requirements at a specific tier level .

rather , according to tsa officials , since tsa did not have access to proprietary data , it relied on notional time frames proposed by the ait vendors , which comprised estimates for when the vendors expected to be able to develop and deliver ait systems that would meet tsa's requirements .

tsa's october 2012 ait roadmap contains one key element of a technology roadmap — estimated time frames for achieving each milestone — and does not describe steps or activities needed to achieve each milestone .

moreover , in april 2012 , the vendor for currently deployed ait systems provided tsa with a detailed plan for delivering a system that could meet tier iii requirements that contained proposed milestones and time frames for achieving each milestone .

although tsa relied on discussions with this vendor to estimate roadmap time frames , the agency did not incorporate details from the vendor's plan into its roadmap .

according to a representative from this vendor , tsa did not consult with the vendor regarding the risks and limitations of its proposed time frames , including how long it might take to develop various hardware or software modifications , nor did it provide feedback to the vendor after the proposal was submitted .

the vendor's april 2012 plan states that after the tier ii system has met tsa's requirements , it would take the vendor several years to develop and deliver a tier iii system for tsa to test , followed by an operational test and evaluation system validation phase that would take several months .

in addition , according to experts we interviewed from the national laboratories that contributed to the development of imaging technology , the milestones contained in tsa's october 2012 roadmap are not achievable because it did not reflect the time needed to make sufficient improvements to the technology to ensure that it would be able to meet additional tier levels .

tsa did not incorporate available information from the national laboratories and vendors into its updated roadmap .

as a result , the roadmap underestimated the length of time it would take to develop and deploy ait - atr tier iii systems.discussed later in this report , moving forward , it will be important for tsa to incorporate scientific evidence and information from dhs's science and technology directorate , and the national laboratories , as well as nonproprietary information and data provided by vendors into the next revision of its ait roadmap to ensure that the time frames for achieving future goals and milestones are realistic and achievable .

consistent with the homeland security act of 2002 , as amended , the dhs science and technology directorate has responsibility for coordinating and integrating the research , development , demonstration , testing , and evaluation activities of the department , as well as for working with private sector stakeholders to develop innovative approaches to produce and deploy the best available technologies for homeland security missions .

moreover , we have previously identified key practices that can help sustain agency collaboration and concluded that collaborating agencies can look for opportunities to address resource needs by leveraging each others' resources , thus obtaining additional benefits that would not be available if they were working separately .

according to tsa officials , the agency recognizes the need to develop achievable milestones based on scientific evidence and is in the process of developing a roadmap for the entire passenger screening program .

they explained that they plan to collaborate with dhs science and technology directorate to determine milestones for the new roadmap that will be based on a scientific analysis of technology capabilities as well as ongoing research and development efforts .

tsa officials stated that they plan to update the ait roadmap using this new approach and expect the ait roadmap to be completed by september 30 , 2014 .

a group of experts moderated by gao in june 2013 stated that dhs must have personnel with technical expertise in atr software for ait systems and development who are engaged throughout the developmental process to ensure that vendors are providing improved capabilities over time .

according to these expert comments , it is important to leverage the technical expertise of academia and the national laboratories to improve capabilities over time and provide insight into reasonable time frames for meeting future tiers .

in september 2011 , we reported that given continuing budget pressures combined with the focus on performance envisioned in the government performance and results act ( gpra ) modernization act of 2010 , federal agencies must undertake fundamental reexaminations of their operations and programs to identify ways to operate more efficiently .

while there are various approaches that vendors could take to make needed improvements to the technology , including hardware modifications , software developments , or incorporating new imaging techniques to provide enhanced capabilities , these approaches could take years to develop , and would require significant investment of resources .

moreover , according to scientists that we interviewed from the national laboratories , there are several ways to improve atr software algorithms to enhance system capabilities ; however , there is little market incentive for existing vendors to invest in making these improvements or for new vendors to enter the relatively small airport checkpoint market , since one vendor has already met tsa's current requirements .

further , 2 of the 12 experts identified by the national academy of sciences with whom we spoke stated that establishing clear requirements would incentivize vendors to improve performance over time .

thus , according to these experts , it is unlikely that vendors will invest in making the needed improvements to meet tsa's mission needs .

according to a representative from the vendor of currently deployed ait systems , moving from tier ii to tier iii presents new technological challenges because meeting additional tiers will require the development of more targeted algorithms .

accordingly , to develop these new algorithms , vendors would have to build new data sets , conduct research , and invest additional resources before accurately determining realistic time frames for meeting tier iii and tier iv requirements .

therefore , given the current state of the technology as well as the amount of research that has to be conducted on developing algorithms that can meet tier iii and tier iv requirements , neither tsa nor the ait vendors can reliably predict how long it will take to meet tier iv requirements .

because tsa revised its requirements over time , scientists from the national laboratories noted that vendors have little incentive to meet additional tier levels since they are meeting tsa's current requirements .

in addition , tsa has not obtained the necessary information to accurately understand the future state of the technology .

thus , the agency has little assurance that vendors will provide ait - atr systems that meet tier iv requirements within tsa's estimated time frames .

as a result , the future capabilities of the technology and the time frames in which those capabilities will be delivered remain unknown .

given these challenges , tsa will be unable to ensure that its roadmap reflects the true capabilities of the next generation of ait - 2 systems without the use of scientific evidence and information from dhs's science and technology directorate , and the national laboratories , as well as nonproprietary information and data provided by vendors to develop a realistic schedule with achievable milestones that outlines the technological advancements , estimated time , and resources needed to achieve tsa's tier iv end state .

tsa has deployed nearly 740 ait systems and will spend an estimated $3.5 billion in life cycle costs on deployed ait - atr systems and future ait - 2 systems .

however , tsa faces challenges in managing its ait program because it is not using all available data that it collects to inform its decisions .

for example , tsa does not enforce compliance with its operational directive that requires each airport to conduct ied checkpoint drills each week , nor does it collect or use ied checkpoint drill data on so performance .

additionally , tsa is not analyzing available data on the number of secondary screening pat - downs that sos conduct when the system indicates that it has detected an anomaly , which could provide insight into the number of false alarms that occur in the field and the extent to which these alarms affect operational costs .

tsa could improve the overall performance of the ait system and better inform its decision - making process related to checkpoint screening by clarifying which office is responsible for overseeing tsa's operational directive , directing that office to enforce compliance with the directive , and analyzing the ied checkpoint data to identify any potential weaknesses in the airport screening process , and also establishing protocols that facilitate capturing operational data on passengers at the checkpoint to determine the extent to which ait - atr system false alarm rates affect operational costs .

although ait systems and the associated software have been in development for over two decades , tsa has not used available information from the scientific community and vendors to understand the technological advancements that need to be made and determine the time frames in which ait systems will meet tier iv requirements .

therefore , the milestones that tsa uses to guide its procurement of this technology do not incorporate scientific evidence from the national laboratories or vendors that could be used to produce an accurate , realistic roadmap .

tsa would have more assurance that its $3.5 billion investment in ait provides effective security benefits by ( 1 ) measuring system effectiveness based on the performance of the ait - 2 technology and sos who operate the technology , while taking into account current processes and deployment strategies and ( 2 ) using scientific evidence and information from dhs's science and technology directorate , and the national laboratories , as well as information and data provided by vendors , to develop a realistic schedule with achievable milestones that outlines the technological advancements , estimated time , and resources needed to achieve tsa's tier iv end state .

to help ensure that tsa improves so performance on ait - atr systems and uses resources effectively , the administrator of the transportation security administration should take the following two actions: clarify which office is responsible for overseeing tsa's ied screening checkpoint drills operational directive , direct the office to ensure enforcement of the directive in conducting these drills , and analyze the data to identify any potential weaknesses in the screening process , and establish protocols that facilitate the capturing of operational data on secondary screening of passengers at the checkpoint to determine the extent to which ait - atr system false alarm rates affect operational costs once ait - atr systems are networked together .

to help ensure that tsa invests in screening technology that meets mission needs , the administrator of the transportation security administration should ensure that the following two actions are taken before procuring ait - 2 systems: measure system effectiveness based on the performance of the ait - 2 technology and screening officers who operate the technology , while taking into account current processes and deployment strategies , and use scientific evidence and information from dhs's science and technology directorate , and the national laboratories , as well as information and data provided by vendors to develop a realistic schedule with achievable milestones that outlines the technological advancements , estimated time , and resources needed to achieve tsa's tier iv end state .

we provided a draft of this report to dhs for comment .

on march 21 , 2014 , dhs provided written comments , which are reprinted in appendix iii and provided technical comments , which we incorporated as appropriate .

dhs generally concurred with our four recommendations and described actions taken , underway , or planned , to implement each recommendation .

specifically , in response to the recommendation that tsa clarify which office is responsible for overseeing tsa's improvised explosive device screening checkpoint drills operational directive , instruct the responsible office to enforce the directive , and analyze the drill data to identify any potential weaknesses in the screening process , dhs stated that tsa's office of security operations will initiate a review of programs that contribute to assessing screening performance with consideration of the findings identified in our report .

tsa anticipates that it will complete this review by the end of fiscal year 2014 , and by tsa also stated that by september 30 , 2014 , the operations directive will be amended to assign responsibility to one office .

we believe that these are beneficial steps that would address our recommendation , provided that tsa directs the office to ensure enforcement of the directive in conducting the drills , and uses the data to identify any potential weaknesses in the screening process , as we recommended .

in response to our recommendation that tsa establish protocols to help determine the extent to which ait - atr system false alarm rates affect operational costs once ait - atr systems are networked together , dhs stated that tsa will monitor , update , and report the results of its efforts to capture operational data on the secondary screening of passengers resulting from ait - atr false alarms and evaluate the associated impacts to operational costs based on existing staffing levels .

once implemented , the new reporting mechanism will address our recommendation , provided that it captures sufficient information to determine the extent to which ait - atr system false alarm rates affect operational costs .

in response to the recommendation that tsa measure system effectiveness based on the performance of the ait - 2 technology and screening officers who operate the technology , while taking into account current processes and deployment strategies before procuring ait - 2 systems , dhs stated that tsa considers several factors when measuring system effectiveness , including documented deployment strategies , airport needs and conditions such as height and checkpoint space , tsa security operations processes and procedures , feedback from transportation security officers who operate the ait - atr systems , as well as concept of operations and formal operational and functional requirements documents .

further , dhs stated that tsa's testing process enables tsa to determine if technologies meet required standards and are feasible for use in the airport environment , and that the system evaluation report for ait - 2 — which will document system effectiveness using information from the laboratory and operational test reports — will state whether or not the next - generation ait system has an acceptable operationally effective and suitable rating for use within an airport environment .

while these are beneficial practices , we believe that it would be preferable for tsa to measure the ait - 2 system's overall probability of detection by including an evaluation of screening officer performance at resolving alarms detected by the technology in its assessment , as we recommended , since ait system effectiveness relies on both the technology's capability to detect items and screening officers ability to correctly resolve alarms .

in addition , dhs stated that tsa is currently implementing the transportation security capability analysis process , which will be used to better understand tsa's requirements and better articulate those requirements and needs for acquisition and requirements documentation .

this is an important first step toward addressing our recommendation , provided that tsa uses this process to determine the overall effectiveness of its system based on the performance of the ait - 2 technology as well as the screening officers who operate the technology and not solely on the capabilities of current ait technology as has been done in the past .

in response to the recommendation that tsa use scientific evidence and information from dhs's science and technology directorate , and the national laboratories , as well as information and data provided by vendors to develop a realistic schedule with achievable milestones that outline the technological advancements , estimated time , and resources needed to achieve tsa's tier iv end state , dhs stated that tsa has initiated an effort to complete a more comprehensive technology roadmap that forecasts technology progression through detection tiers , estimates cost to mature the technology , and includes a timeline with supporting narrative .

tsa expects this roadmap to be completed by september 30 , 2014 .

we believe that these are beneficial actions that could help tsa address the weaknesses identified in this report and we will continue to work with tsa to monitor progress on the proposed steps as the agency progresses .

as agreed with your offices , unless you publicly announce its contents earlier , we plan no further distribution of this report until 30 days after its issue date .

at that time , we will send copies of this report to the secretary of homeland security , the tsa administrator , the house homeland security committee , the house subcommittee on oversight and management efficiency , the house subcommittee on transportation security , and other interested parties .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-4379 or lords@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iv .

in january 2012 , we concluded that tsa had acquired advanced imaging technology ( ait ) systems that were not being used on a regular basis and thus were not providing a security benefit .

for example , we found that 32 of 486 ait systems had been used less than 5 percent of the days since their deployment , and that 112 of 486 ait systems had been used on less than 30 percent of the days since their deployment .

further , we observed that at 5 of the 12 airports we visited , ait systems were deployed but were not regularly used .

for example , at 1 airport we observed that tsa had deployed 3 ait systems in an area that typically handles approximately 230 passengers .

tsa officials informed us at the time that 2 of the ait systems were seldom used because of the lack of passengers and mentioned that they believed the ait systems were deployed based on the availability of space .

in addition , we observed instances in which ait systems were not being used because of maintenance problems that affected how often the deployed ait system screened passengers .

we concluded , on the basis of our observations on ait utilization , that there were concerns about how effectively deployed ait systems were being used .

accordingly , we recommended that tsa evaluate the utilization of currently deployed ait systems and potentially redeploy ait systems based on utilization data , so that those systems not being extensively used could provide enhanced security benefits at airports .

the department of homeland security ( dhs ) agreed , and tsa has taken steps to address our recommendation but has not fully addressed the intent of our recommendation .

specifically , tsa took the following actions .

develop and track ait utilization metrics .

tsa officials we spoke with in october 2012 stated that they revised tsa's metric for measuring utilization based on our january 2012 report to more accurately reflect the amount of time ait systems were being used .

according to tsa's field guide issued in march 2012 , tsa measures ait utilization as the percentage of passengers that are screened by ait systems .

to track ait utilization based on this metric , tsa developed specific targets to meet that are based on passenger throughput and hours that ait systems are in operation at an airport .

however , the target tsa establishes for an airport is reduced to account for ait systems that are not operational because of maintenance problems or that are not being used because of lane closures , staffing restrictions , or low passenger volume .

accordingly , the methodology employed by tsa to measure ait utilization does not accurately measure the extent to which ait systems are being used since the metric tracks ait system utilization only when they are being used .

furthermore , to calculate airport targets and track ait utilization , tsa relies on data submitted by airports into its centralized information management system .

however , in september 2013 , the dhs office of inspector general ( dhs oig ) reported that tsa did not have adequate internal controls to ensure accurate data on ait utilization .

specifically , the oig found that tsa's utilization data were unreliable because ( 1 ) ait throughput data recorded in its centralized information management system were different from data in the source document , ( 2 ) ait throughput data on the source document were not recorded in its centralized information management system , ( 3 ) the starting ait count was different from the previous day's ending ait count , and ( 4 ) ait throughput source documentation was missing .

further , since airports record and enter ait throughput in its centralized information management system manually , this may lead to inaccurate recording of information and does not provide an audit trail to validate data accuracy .

accordingly , without reliable throughput data , tsa decision makers cannot accurately measure ait utilization at airports .

backscatter x - ray technology uses a low - level x - ray to produce an x - ray image , while millimeter - wave technology beams the millimeter - wave radio - frequency energy over the body's surface to produce a three - dimensional image .

since the backscatter vendor was unable to develop automated target recognition ( atr ) software by the june 2013 statutory deadline , as extended by tsa , to upgrade all deployed ait systems with the software , tsa terminated its contract with this vendor and removed all of these systems from airports in order to meet the requirement .

number of ait systems that should be deployed to which airports .

accordingly , tsa is not using the data it collects on utilization to inform its deployment decisions .

while the actions tsa has taken represent important steps toward addressing our recommendation , ensuring that the utilization data it collects are accurate , and using these data to inform future deployment decisions , would help ensure the effective utilization and redistribution of ait systems and efficient use of taxpayer resources .

this report answers the following questions: 1 .

to what extent does tsa collect and analyze available information that could be used to enhance the performance of ait systems equipped with atr ( ait - atr ) ? .

2 .

to what extent has tsa made progress toward enhancing ait capabilities to detect concealed explosives and other threat items , and what challenges , if any , remain ? .

to determine the extent to which tsa collects and analyzes available information to improve the performance of screening officers ( so ) responsible for resolving anomalies identified by atr software , we analyzed improvised explosive device ( ied ) checkpoint drills conducted by tsa personnel at airports that submitted data to tsa from march 1 , 2011 , through february 28 , 2013 , under tsa's ied checkpoint drill operational directive .

tsa's ied checkpoint drill operational directive requires personnel at airports to conduct drills to assess transportation security officer ( tso ) compliance with tsa's screening standard operating procedures ( sop ) and to train tsos to better resolve anomalies identified by ait - atr systems .

we analyzed those data to determine whether airports were in compliance with tsa's operational directive by analyzing the number and percentage of tests that were conducted on ait systems and on other passenger screening methods at the checkpoint to evaluate whether , overall , airports with ait systems had conducted the required proportion of drills between ait drills and other passenger - screening drills .

additionally , we evaluated airport compliance with tsa's operational directive and standards for internal control in the federal government to determine the extent to which tsa is monitoring we also reviewed tsa's ait deployment compliance with its directive.schedules to determine which type of ait - atr system airports had , the dates those systems were first deployed , and the dates systems were upgraded with atr capability to assess how airport performance varied at resolving anomalies identified by the ait - atr system .

further , we analyzed laboratory test results of the ait - atr system and the ait systems that used ios ( ait - io ) from calendar years 2009 through 2012 conducted by the transportation security laboratory ( tsl ) .

we analyzed these data using statistical methods that estimated how the false alarm rates varied according to various characteristics of the mock passenger .

we assessed whether the laboratory tests complied with statistical principles by comparing the testing design to generally accepted statistical principles used for data collection .

we calculated the false alarm rates using two specific statistical calculations , called bias - corrected cluster bootstrap resampling and random effects methods , to estimate the sampling error of the ait - atr systems' estimated false alarm rates .

we used each of these methods to estimate the 95 percent confidence intervals of the false alarm rates , and achieved similar results using either method .

gao , homeland security: dhs requires more disciplined investment management to help meet mission needs , gao - 12-833 ( washington , d.c.: sept. 18 , 2012 ) .

we identified key acquisition management practices by reviewing 17 prior gao reports examining dhs , the department of defense , the national aeronautics and space administration , and private sector organizations .

and reviewing testing reports and related documentation .

we determined these data were sufficiently reliable for the purposes of this report .

furthermore , we compared the extent to which tsa evaluated the performance of the entire system to key acquisition practices established by gao , dhs's acquisition directive 102-01 , and tsl's test management plan .

we also visited a nonprobability sample of four u.s. airports to observe ait - atr systems and interview relevant tsa personnel .

we interviewed a total of 46 tsa personnel who operate ait - atr systems selected by airport officials to obtain their views on system performance , and six transportation security specialists for explosives to discuss airport ied checkpoint drills .

we selected these airports based on airport category and ait - atr system deployment .

the information we obtained from these visits cannot be generalized to other airports , but provided us with information on the perspectives of various participants in the deployment of ait units at airports across the country .

we also interviewed tsa officials involved in ait - atr deployment , training , and covert testing .

we visited tsl in atlantic city , new jersey , to interview laboratory scientists responsible for testing and evaluating ait - atr systems and reviewed tsl documentation related to laboratory test plans , records , and final reports .

we interviewed knowledgeable agency officials from tsa , tsl , and dhs's science and technology directorate to better understand how ait - atr and ait - io system performance was assessed .

to determine progress tsa has made and any challenges that remain toward enhancing ait capabilities , we analyzed tsa's original ait roadmap dated february 2012 , as well as the october 2012 revision .

to determine the extent to which tsa has met its projected time frames for ait - atr system upgrades and development of the next generation of ait systems , referred to as ait - 2 , we reviewed actions taken by tsa testing officials and compared the actual dates for each milestone with the estimated dates documented in tsa's ait roadmap .

we also reviewed a leading ait vendor's technology plan for meeting additional tiers to determine the extent to which tsa's ait roadmap contained achievable time frames for meeting future tier levels .

we further reviewed several technology roadmaps for large - scale acquisition programs developed by other agencies and organizations , such as the department of defense , as well as technology roadmapping guidance developed by sandia national laboratories to enhance our understanding of the fundamental elements of technology roadmaps .

we then compared this guidance with tsa's ait roadmap to determine the extent to which tsa's roadmap contained these elements .

we also reviewed prior gao reports on ( 1 ) major acquisition programs to identify best practices for delivering capabilities within schedule and cost estimates and ( 2 ) key practices that can help sustain agency collaboration to leverage each others' resources and obtain additional benefits that would not be available if they were working separately .

to determine challenges tsa faces toward enhancing ait capabilities , we interviewed scientists from the department of energy's sandia national laboratories and pacific northwest national laboratory to obtain their views on current and future capabilities of the technology and the scientific advancements that would need to occur to enable the development of future tier levels .

we also interviewed a leading ait vendor to obtain its views on the extent to which tsa obtained input from the vendor related to its ability to meet future tiers within expected time frames as well as the risks and limitations associated with pursuing alternative approaches for developing successive tiers .

we further interviewed tsa acquisition officials to obtain the agency's views on the vendors' ability to meet future tiers within estimated time frames .

last , we interviewed 12 experts identified by the national academy of sciences to obtain their views on best practices for testing detection technologies , such as ait - atr systems .

our interviews with these experts are illustrative and provide insights about testing best practices .

we conducted this performance audit from september 2012 to march 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

stephen m. lord at ( 202 ) 512-4379 or at lords@gao.gov .

in addition to the contact named above , david bruno , assistant director ; david alexander ; carl barden ; carissa bryant ; susan czachor ; emily gunn ; tom lombardi ; lara miklozek ; tim persons ; doug sloane ; and jeff tessin made key contributions to this report .

