for the past 2 years , the department of defense ( dod ) has been implementing provisions of the weapon systems acquisition reform act of 2009 ( reform act ) related to systems engineering and developmental testing .

greater attention to these activities provides the office of the secretary of defense an opportunity to affect weapon acquisition plans early and assess technical risks throughout weapon system development .

in addition , it could help control total acquisition costs , which we recently reported had increased by $135 billion over the past 2 years for dod's current portfolio of 98 major defense acquisition programs .

last year , we reported on the status of dod's initial efforts to implement reform act requirements related to systems engineering and developmental testing .

we found that dod had taken steps to implement the reform act requirements , including establishing new offices for the director of systems engineering and the director of developmental test and evaluation within the office of the secretary of defense .

the offices have since been renamed as the offices of the deputy assistant secretary of defense for systems engineering and the deputy assistant secretary of defense for developmental test and evaluation .

we found that there were concerns about the amount of influence the deputy assistant secretary for developmental test and evaluation could have on weapon acquisition programs based upon where the office is placed organizationally within the department .

however , we could not determine whether the office had the appropriate amount of influence because it was not tracking the extent to which its recommendations were being adopted or impacting weapon programs .

we also identified issues the military services face as they enhance systems engineering and developmental testing activities on their weapon acquisition programs , including determining whether they have enough people to perform these activities , training the influx of new hires they expect , and addressing test range resource needs .

based on our initial work , the senate armed services committee asked us to continue to monitor dod's efforts to implement the reform act provisions , as well as look at the military services' systems engineering and developmental test and evaluation capabilities .

our specific objectives were to determine ( 1 ) dod's progress in implementing the reform act's systems engineering and developmental testing requirements within the office of the secretary of defense and ( 2 ) whether there are challenges at the military service level that could affect their systems engineering and developmental testing activities .

in conducting our work , we analyzed information obtained from the offices of the deputy assistant secretaries of defense for systems engineering and developmental test and evaluation to determine the status of their efforts to implement the reform act legislation .

we also solicited the views of current and former dod developmental testing officials about the effectiveness of the developmental test and evaluation office .

in addition , we interviewed officials and analyzed pertinent documents related to workforce and test range issues from 12 dod test ranges , the test resource management center , and cognizant military service systems engineering , developmental testing , and personnel offices .

for purposes of this report , we use the term systems engineering career field to refer to two systems planning , research development , and engineering career fields — systems engineering and program systems engineering .

the test and evaluation career field is a combination of developmental and operational testing personnel .

both of these career fields represent a portion of the total systems engineering and developmental testing workforce .

see appendix i for a more detailed explanation of our scope and methodology .

we conducted this performance audit from september 2010 to september 2011 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

dod significantly downsized its acquisition workforce in the 1990s and 2000s as part of an overall reduction of military and civilian defense personnel after the end of the cold war .

according to dod's april 2010 strategic human capital plan update , the department decreased its core acquisition workforce from about 146,000 people in fiscal year 1998 to about 126,000 in fiscal year 2008 .

meanwhile , the number of major defense acquisition programs increased from 76 to 93 and total estimated costs to acquire them increased from nearly $805 billion to more than $1.6 trillion .

the systems engineering and test and evaluation career fields were affected by the workforce cuts .

for example , in 2008 the defense science board reported that the army's test and evaluation workforce was reduced by more than 55 percent from 1991 through 2007 .

in response to cuts in these career fields , dod reduced its emphasis in these areas and / or relied on prime contractors to analyze and interpret developmental testing data .

the defense science board also found that many weapon programs were failing initial operational testing due to a lack of a disciplined systems engineering approach .

additionally , in 2008 the national academy of sciences reported that there were no longer enough systems engineers to fill programs' needs .

the academy observed that dod cannot outsource its technical and program management experience and intellect and still expect to acquire new systems that are both effective and affordable .

over the past several years , the congress has called for dod to improve its acquisition workforce and increase emphasis on systems engineering and developmental testing during weapon systems development .

for example , the national defense authorization act for fiscal year 2008 required the secretary of defense to establish the dod acquisition workforce fund for the recruitment , training , and retention of dod acquisition personnel , which includes the systems engineering and test and evaluation career fields .

in addition , the reform act contains a number of systems engineering and developmental testing requirements aimed at helping weapon programs establish a solid foundation prior to the start of development .

for example , the deputy assistant secretaries are expected to review and approve acquisition planning documents for major defense acquisition programs , as well as monitor program activities .

in response to the reform act legislation , dod established new offices within the office of the secretary of defense for systems engineering and developmental testing to provide assistance to program offices as they are developing their acquisition strategies prior to the start of development and then oversee program office efforts to implement the strategies .

the systems engineering office has about 120 programs in its portfolio and the developmental test and evaluation office has about 250 programs .

in addition , they provide advocacy , oversight and guidance for their respective workforces throughout dod .

the secretary of defense also announced plans to increase the number of people performing acquisition activities by almost 20,000 employees through new hiring actions and by converting contractor positions to government positions ( insourcing ) between fiscal years 2009 and 2015 .

the strategic human capital plan update indicates that 22 percent of the almost 20,000 position growth will be for systems engineering and 1 percent for test and evaluation , which would increase the size of the career fields by 16 percent and 5 percent , respectively .

the majority of these new positions will be in the military services at headquarters , program offices , and test range locations .

the services maintain test ranges for development testing activities .

currently , 24 ranges are designated as part of the major range and test facility base ( mrtfb ) because they have unique test capabilities that are used by multiple services .

the test resource management center is responsible for ensuring that the mrtfb is adequately funded and maintained while the services oversee the remaining non - mrtfb ranges and facilities , which perform more service - specific testing .

the new offices of the deputy assistant secretary of defense for systems engineering and developmental test and evaluation have continued to make progress implementing the reform act requirements .

both offices , which provide assistance to program managers and perform oversight for decision makers , have issued additional policies and guidance , and are overseeing and providing information on more weapon acquisition programs than they did last year .

the systems engineering office will be staffed at 163 people in fiscal year 2012 and the developmental test and evaluation office will be staffed at 63 people , which is less than the developmental test and evaluation office originally projected .

yet , the offices are more reliant on contractor support than the deputy assistant secretaries would like .

in addition , many current and former testing officials continue to believe the developmental test and evaluation office does not have the resources or influence to effectively oversee and affect program decisions .

however , it is unclear how many people are needed .

dod established the two offices for systems engineering and developmental test and evaluation within the office of the secretary of defense in june 2009 .

since then , both offices have increased staffing , which is enabling them to meet statutory requirements for assisting and overseeing their portfolios of defense acquisition programs .

the table below shows the actual and planned workforces for both offices .

most of the staffing increases have been through hiring contractor employees .

while both offices have also increased their government staff , hiring freezes have curbed their ability to hire additional government employees and for the developmental test and evaluation office to meet its authorized staffing goal .

the systems engineering office was authorized 28 government employees for fiscal year 2011 , but has not yet been given permission to advertise for all of the positions because of the hiring freeze .

according to the deputy assistant secretary for developmental test and evaluation , the office was initially authorized to have 70 employees , but will be capped at 63 in fiscal year 2011 , 4 of which are detailees from the test resource management center .

in their fiscal year 2010 joint annual report to the congress , the deputy assistant secretaries reported on their ongoing efforts to implement reform act requirements .

the table below includes information that was included in the report or provided to us on their fiscal years 2009 and 2010 activities .

as shown , the offices have continued or increased their activities .

in addition to the progress highlighted in the table above , the offices are also taking actions in areas that they had not acted upon last year — issuing required guidance on the development and tracking of performance criteria and exercising a reform act option of designating the deputy assistant secretary of defense for developmental test and evaluation for concurrent service as the director of the test resource management center .

 developing performance criteria: the reform act requires the deputy assistant secretaries , in coordination with an official designated by the secretary of defense , who was the director of the performance assessments and root cause analysis , to jointly issue guidance on the development and tracking of detailed measurable performance criteria for major defense acquisition programs .

in response to this requirement , the deputy assistant secretaries , in cooperation with the director of performance assessments and root cause analysis , have agreed that each office shall develop guidance within their respective functional areas in coordination with each other and openly share the data and findings of those performance criteria in conducting their oversight .

the deputy assistant secretary for systems engineering developed a set of time - based metrics to assess each program's ability to execute its system engineering plans and address risks the office had identified in prior reviews .

the metrics measure program cost , schedule , staffing , reliability , availability and maintainability , software , integration , performance and manufacturing , and are to be incorporated into each program's systems engineering plan and evaluated at various points in the development process .

criteria developed by the deputy assistant secretary for developmental test and evaluation focus on early acquisition lifecycle activities to ensure that sound developmental testing planning is performed from the beginning of development .

other criteria measure program results and are meant to provide an objective foundation to assess a program's subsequent developmental testing performance as it approaches the production decision and the assessment of operational test readiness .

the office plans to pilot test the metrics on six programs , with a goal of rolling them out to other programs by the end of 2011 .

 changing leadership of test resource management center: effective april 1 , 2011 , the principal deputy under secretary of defense for acquisition , technology and logistics designated the deputy assistant secretary of defense for developmental test and evaluation for concurrent service as the director of the test resource management center .

dod had not acted upon this optional reform act provision last year .

both offices will continue to be managed separately and report to different authorities — developmental test and evaluation office activities will be reported to the assistant secretary of defense for research and engineering and test resource management center activities will be reported directly to the under secretary of defense for acquisition , technology and logistics .

according to the deputy assistant secretary of defense for developmental test and evaluation , the principal deputy under secretary for acquisition , technology and logistics asked him to complete a study in the near future to identify efficiencies that can be obtained by merging some of the offices' activities .

a study was started in july 2011 .

the deputy assistant secretary for developmental test and evaluation indicated that there could be some limitations on his ability to streamline management and reporting activities or shift resources between the organizations because the test resource management center is designated by statute to be a field activity and the organizations are funded separately .

dod has not studied the possible legal ramifications of combining the offices .

in their fiscal year 2010 joint annual report to the congress , the deputy assistant secretaries also identified several focus areas for improvement .

for example , the systems engineering office plans to reestablish the dod software working group to improve dod's capability to address systemic software program issues .

among other things , the developmental test and evaluation office wants to develop a responsible test organization model that the services would use to designate the lead government test organization responsible for overseeing and / or conducting the developmental test and evaluation for an acquisition program .

in addition , the office wants to issue a policy requiring programs to prioritize use of government capabilities and to provide a cost - benefit analysis when they decide to provide funding to use and / or develop test capabilities at prime contractor sites .

in a departure from the fiscal year 2009 joint annual report , the fiscal year 2010 report did not contain a discussion of the extent to which weapon acquisition programs are fulfilling their systems engineering or test and evaluation master plans .

further , the fiscal year 2010 report did not include a discussion of test and evaluation waivers or deviations that programs have received .

instead , the report identified the type of reviews or engagements both of the offices participated in for various programs .

the deputy assistant secretaries stated that they did not provide the information in the fiscal year 2010 report because they were directed to streamline the report .

in may 2011 , the senate armed services committee requested dod to supplement the fiscal year 2010 report with this information as required by the reform act .

dod has not yet provided the information .

the deputy assistant secretaries believe they have had a positive influence on weapon acquisition programs over the past 2 years during milestone reviews with senior department leaders and through recommendations to program offices .

although the assistant secretary of defense for research and engineering represents both systems engineering and developmental test positions at defense acquisition board meetings , the deputy assistant secretaries said that either they , or designees , also attend the meetings .

they said that they have been asked by the principal deputy for acquisition , technology and logistics to provide direct input about weapon acquisition programs at some of these meetings , including discussions on the gray eagle unmanned aircraft system , ohio replacement submarine , and the joint strike fighter aircraft programs .

the deputy assistant secretaries also said that program offices are making changes based on the recommendations made by their offices during regular program assessments and technical reviews .

while the deputy assistant secretaries have made progress implementing the reform act requirements , we identified several organizational challenges that could limit their effectiveness .

a summary of each of these challenges is presented below .

 reliance on contractor employees: the deputy assistant secretaries rely heavily on contractors to help perform office activities .

in fiscal year 2010 , for example , nearly 85 percent of the staff in the systems engineering office and 67 percent of the staff in the developmental test and evaluation office were contractors .

both deputy assistant secretaries would like to have a larger proportion of government employees because they believe it is important to maintain a core cadre of people with the required institutional knowledge and skills to support current and future program office needs .

however , they are not optimistic about their chances of getting additional government employees because of a civilian hiring freeze .

 developmental test and evaluation office influence: current and former dod test and evaluation officials continue to believe the developmental test and evaluation office could be more effective in its oversight role with the proper influence .

for example , they pointed out that the office's primary avenue for voicing concerns about weapon acquisition programs to senior leaders is at overarching integrated product team meetings that take place in preparation for defense acquisition board meetings .

the integrated product team leader ultimately decides which organizations will get to present issues at the defense acquisition board meetings .

current testing officials told us that in some cases developmental testing issues do not make the defense acquisition board meeting agendas , which is a concern to officials who believe the developmental test and evaluation office should provide independent assessments of weapon acquisition programs directly to senior leaders .

in addition , officials said that the deputy directors who attend the overarching meetings are not at the senior executive level like other meeting attendees , which officials said in some cases has reduced their relative influence during these meetings .

to ensure developmental testing information , such as the assessment of operational test readiness , receives appropriate consideration by senior leaders , the defense science board recommended in 2008 that the office report developmental testing issues directly to the deputy under secretary of defense for acquisition and technology .

currently , the office reports through an intermediary — the assistant secretary of defense for research and engineering .

even though the systems engineering office reports through the same reporting channel as the developmental test and evaluation office , the deputy assistant secretary for systems engineering believes his office has the appropriate amount of influence .

this is because the systems engineering office's primary emphasis is on assisting program managers in the development of their systems engineering plans .

in contrast , the deputy assistant secretary for developmental test and evaluation believes his office should put about equal effort into assisting and assessing program office activities .

 developmental test and evaluation office resources: information provided by the developmental test and evaluation office shows the office can not provide full coverage of its portfolio of about 250 acquisition programs given its current workforce .

for example , in fiscal year 2010 when the office had 30 people , 89 programs ( 36 percent ) did not receive any support , including the air and missile radar program and sub elements of the early infantry brigade combat team program , such as the small unmanned ground vehicles and unmanned aircraft system .

although staffing has doubled between fiscal years 2010 and 2011 , the office still has not been able to support all the programs the deputy assistant secretary for developmental test and evaluation believes it should .

the deputy assistant secretary for developmental test and evaluation said the office has had to be selective in using its resources and he has introduced a “triage” strategy for dealing with the overload of programs relative to the office's workforce .

this strategy includes dropping virtually all programs below acquisition category i from the developmental testing oversight list and eliminating oversight of some major automated information systems .

for the most part , the office focuses its efforts on major defense acquisition programs between milestone b ( development start ) and milestone c ( the production decision ) in order to retain sufficient depth with programs in development .

it is providing minimal coverage to programs prior to the start of development , which is the most opportune time to influence a program's acquisition strategy .

based on the “triage” strategy , the deputy assistant secretary for developmental test and evaluation believes only about half of the current portfolio of about 250 programs would receive the level of support he believes is needed with a staff of 63 people .

on the other hand , the deputy assistant secretary for systems engineering believes his office , which is supposed to have 163 people in fiscal year 2012 , will have enough staff to oversee its portfolio of 120 programs .

while current and former dod testing officials provided reasons for increasing the size of the developmental test and evaluation office , they could not specify the appropriate size for the office , as they indicated the issue has not been thoroughly analyzed .

officials familiar with the establishment of the office told us that three staffing scenarios were considered prior to the office being established — a high , medium , and low staffing scenario — but they indicated that no detailed analysis was done to support any of the scenarios .

under the high staffing scenario , the developmental test and evaluation office would have had 250 people , which would have matched the size of the office of the director of operational test and evaluation .

the medium level of staffing , 120-150 people , was based on the size of a legacy developmental testing organization and the low level , which called for 90 people , was based on an assumption about the number of programs each person would be responsible for overseeing .

as shown earlier in table 1 , the staffing goal is 70 people , which is fewer than the lowest staffing scenario considered .

former testing officials believe an opportunity exists to both increase the developmental testing office's influence and address resource concerns by merging test resource management center and developmental testing office activities .

they believe this would give the deputy assistant secretary for developmental test and evaluation the most flexibility in how to allocate resources .

they also pointed out that in the early 1990s , oversight of all developmental test and evaluation activities had been under one organization that reported directly to the under secretary of defense for acquisition .

the military services have been increasing the number of people in their systems engineering and test and evaluation career fields , but challenges exist that could impede future workforce growth plans as well as testing at the ranges , if not properly addressed .

the services planned to increase their systems engineering and test and evaluation career fields by about 5,000 people ( 14 percent ) and about 300 people ( 4 percent ) , respectively , between fiscal years 2009 and 2015 through hiring actions and by insourcing contractor positions .

these increases are part of dod's overall efforts to increase the number of people in acquisition career fields .

the services have increased the systems engineering career field by about half of their projections and exceeded their planned growth for the test and evaluation career field through the end of fiscal year 2010 .

however , budget cuts and a clarification in dod's insourcing approach may make hiring civilians more challenging in the future .

the services' developmental test ranges are also experiencing declining budgets , as the fiscal year 2012 budget includes cuts of nearly $1.2 billion over the next 5 years to support accounts that pay for overhead costs .

the services plan to cut range personnel in response to the budget reductions , which could offset some of the workforce gains they have already achieved .

they have not yet determined how the cuts will be allocated across the ranges or the impact they will have on meeting program office needs .

further budget cuts are possible based on the recent debt ceiling agreement , but details are unknown .

currently , the services lack common performance metrics that would assist in making funding decisions .

the services planned to increase their acquisition systems engineering and test and evaluation career fields by 14 percent and 4 percent , respectively , between fiscal years 2009 and 2015 through hiring and insourcing actions .

this would increase the overall systems engineering career field by about 5,000 people from about 35,000 to 40,000 people and the test and evaluation career field by almost 300 people from about 7,400 to 7,700 people .

these new positions would be located at service headquarters , program offices , and test range locations .

it should be noted that insourcing actions alone do not result in real growth to the collective number of civilians , military , and contractors performing an activity because it only involves the transfer of positions from contractors to the government .

hiring additional civilian employees , on the other hand , would result in growth , assuming the contractor and military workforces remain stable .

the following table shows the baseline , goal , and current number of civilian and military personnel performing systems engineering and test and evaluation activities for each of the services at the end of fiscal year 2010 , as well as the percentage of the growth goal target achieved .

through the end of fiscal year 2010 , the services have made significant progress towards increasing the two career fields .

for example , the services increased the systems engineering career field by about 2,600 people , about half of the projected growth .

collectively , they have achieved 94 percent of the growth goal target planned for that career field .

the services achieved 104 percent of the growth goal target planned for the test and evaluation career field by adding over 600 people .

information provided by the army and navy shows about 74 percent of their systems engineering career field growth was through new hires and the remaining 26 percent was through insourcing .

about 86 percent of their test and evaluation career field growth was through new hires and the remaining 14 percent was through insourcing .

recently proposed budget changes would result in modifications to the services' workforce growth plans for both acquisition career fields .

the services still plan to increase the systems engineering career field between fiscal years 2011 and 2015 , but with about 800 positions less than originally planned .

as a result , career field growth would be 10 percent instead of 14 percent .

on the other hand , the services plan to hire 400 more people than they originally planned for the test and evaluation career field , despite the fact that the overall number of dod civilians is frozen at fiscal year 2010 levels .

this would result in a 6 percent growth to the career field instead of 4 percent .

service officials stated that achieving additional career field growth , however , could be difficult because of a recent clarification in dod's insourcing policy .

according to a march 2011 memorandum issued jointly by the under secretary of defense for acquisition , technology and logistics and the under secretary of defense comptroller / chief financial officer , a case - by - case approach will be used for additional insourcing of acquisition functions based on critical need , whether a function is inherently governmental , and the benefit demonstrated by a cost - benefit analysis .

the memorandum also states that additional insourcing must be supported by current budget levels .

in cases where added insourcing would breach the existing civilian ceilings , the proposal and associated justification must be provided to the director of human capital initiatives and then the proposal will be reviewed by the two under secretaries of defense issuing the memorandum and approved by the deputy secretary of defense .

of the nearly 2,000 people the army and navy now plan to hire for the systems engineering career field between fiscal years 2011 and 2015 , 96 percent is to be achieved through insourcing .

and about 40 percent of the over 200 people they plan to hire for the test and evaluation career field are to be through insourcing .

although the services have increased their test and evaluation staff , each of the 12 test ranges we visited experienced a mixture of recruiting , hiring , training , or retention challenges .

for example , pacific missile range facility officials stated the range's location on the island of kauai , hawaii , has made it difficult to recruit personnel due to a lower pay grade structure and higher costs of living compared to other test ranges .

range officials stated that it can take months to hire new employees , forcing many qualified applicants to seek employment opportunities elsewhere .

test ranges have begun using acquisition workforce expedited hiring authority , which allows dod components to streamline the process for making offers to qualified acquisition personnel .

however , ranges have interpreted this authority differently .

service test and evaluation executives said they would clarify the policy to the ranges based upon our observations to ensure the policies are fully understood .

most of the test range officials we spoke with also had concerns about the timeliness and quality of the defense acquisition university's training classes .

the defense acquisition university is coordinating with the services to address the increased demand for acquisition training .

finally , some test ranges are having difficulty retaining engineers or some software specialties because the private sector can pay them a higher salary .

officials at aberdeen test center , maryland , are concerned that many of their employees will take higher paying jobs with organizations that are moving into their area as the result of a base realignment and closure decision .

the services' developmental test range budgets are being reduced , but the full impact of the cuts has yet to be determined .

the fiscal year 2012 president's budget includes cuts of nearly $1.2 billion ( 17 percent ) through fiscal year 2015 to the ranges' institutional funding accounts that fund operational and overhead expenses such as personnel , facilities , and equipment costs .

according to service officials , the budget cuts are a result of direction they received late in the fiscal year 2012 budget cycle to keep their civilian workforce at the same level as they had at the end of fiscal year 2010 .

research , development , test and evaluation accounts that fund range testing activities absorbed a large portion of the cuts .

as shown in figure 1 , the services had already planned to reduce their mrtfb research , development , test and evaluation funding between fiscal years 2012 and 2015 .

although range budgets reached a peak in fiscal year 2011 , budget estimates for that year projected funding decreases in subsequent years .

according to service officials these reductions were expected due to expected workload reductions , savings associated with implementing efficiency initiatives , and a civilian pay freeze .

the fiscal year 2012 budget contains additional , more significant decreases beyond those forecasted in the previous year's budget .

in total , this budget provides $5.7 billion for the ranges between fiscal years 2012 and 2015 — a 17 percent reduction from the $6.9 billion forecast in the fiscal year 2011 budget .

most notably , the army and air force range budgets were each cut over $100 million in fiscal year 2012 alone .

the chairman of the senate armed services committee recently expressed concern that these proposed reductions threaten to seriously undermine the implementation of the reform act's requirement to rebuild dod's systems engineering and developmental testing organizations and requested that the proposed cuts be reviewed .

the army and air force are in the process of reviewing these cuts and determining where they will be made .

to minimize the impact on these activities , they are examining potential reductions to their overhead or administrative staff at headquarters and field locations .

according to service headquarters officials , if dod's proposed budget cuts between fiscal years 2012 and 2015 remain intact , they may have to cut some of their developmental test capabilities as well as personnel who conduct tests .

this could offset some of the test and evaluation career field gains already achieved over the past 2 years .

test officials said that reductions in test personnel could limit the amount of testing performed on weapon acquisition programs , which could increase the risk associated with those programs and / or result in an extension of a program's test schedule .

final decisions on where to take the cuts have not yet been made .

therefore , we could not determine the impact funding cuts would have on the ranges' ability to meet program office testing needs .

range officials indicated that prior to these proposed cuts they had difficulty maintaining their test capabilities .

the national defense authorization act for fiscal year 2003 required the secretary of defense by fiscal year 2006 to establish the funding objective of ensuring that the overhead and institutional costs of the mrtfb ranges were fully funded through the major test and evaluation investment accounts and to ensure that dod customers were charged not more than the direct costs of testing .

the law also required dod to establish the test resource management center and required that the director of that organization certify whether the services' proposed budgets for test and evaluation activities are adequate .

to comply with this law , the services increased their range operating budgets by over 50 percent in fiscal year 2006 .

although mrtfb funding was fairly stable between fiscal years 2006 and 2011 , range officials said they have had difficulties maintaining their test capabilities because the infrastructure is aging and operating costs for expenses like utilities and fuel have grown at a higher rate than their overall funding .

as a result , officials said they have had to move money from their range modernization accounts to fund operating costs , only fix things that are broken or in emergency status , or fund capability upgrades over several years instead of a shorter period of time .

according to range officials , these challenges are less of a problem for non - mrtfb ranges like the redstone test center and other test / laboratory activities funded through working capital fund accounts , where customers pay direct and overhead costs .

service officials discussed several strategies or a combination of those strategies that the services could use to lessen the impact of budget cuts and funding concerns .

one strategy is that the ranges may have to curtail certain testing , mothball or close test facilities , or consolidate test capabilities .

another option could be to move certain test capabilities out of the mrtfb management structure , thereby allowing ranges to charge customers the full cost of testing .

additionally , on the basis of our range observations , service officials said more specific guidance for interpreting financial management regulations on what constitutes direct and overhead charges for mrtfb operations could be developed to clarify and standardize the types of costs that can be passed on to customers .

service test and evaluation executives and the deputy assistant secretary for developmental test and evaluation believe the ranges' current policy interpretation is too restrictive , inconsistent across the mrtfb , and constrains service options as they strive to sustain mrtfb capabilities .

the test resource management center recently established a team to study the issue .

the services have not implemented common range performance measures that would help them justify funding and assist them in making workforce decisions , how best to allocate funding , or make difficult decisions about mothballing , closing , or consolidating test capabilities , if necessary .

although ranges collect performance data relevant to their operations , these indicators may not be useful in making higher - level infrastructure decisions that cut across several ranges .

according to service officials , it is very difficult to develop a common set of performance measures because of the uniqueness of each range and its variable capacity .

we have found that performance measures can assist managers in making decisions about future strategies , planning and budgeting , identifying priorities , and allocating resources .

some efforts are under way to provide decision makers more information , but they are still in process and are not yet approved or implemented .

the test resource management center has sponsored an effort to develop a comprehensive set of range metrics .

according to the services , early efforts were not successful and were not well received .

while the air force plans to use metrics resulting from the test resource management center's effort , the army is evaluating the development of a readiness reporting system and a workload model for its ranges that could provide a better basis for investment or divestment decisions .

the navy is also in the process of developing metrics for its mrtfb test capabilities on the systems' condition , capacity , competency , and importance .

once developed , these metrics are expected to assist decision makers in directing future investment funding and to ensure test capabilities are adequate to support programs .

the reform act points to the need for dod to develop more robust systems engineering and developmental test and evaluation capabilities .

dod established new organizations and the services developed resource plans in order to increase emphasis on these activities .

from an organizational standpoint , the offices of the deputy assistant secretaries for systems engineering and developmental test and evaluation are providing assistance to program managers in developing acquisition plans and providing oversight of program efforts for the under secretary of defense for acquisition , technology and logistics and the congress .

however , the developmental testing office is not as robust or efficient as it could be in part due to resource and organizational constraints .

in addition , while the military services have made significant progress to date in increasing their systems engineering and developmental testing workforce capabilities , planned workforce reductions could offset these gains .

it is incumbent upon dod to provide the most effective systems engineering and developmental testing capability it can afford .

it should have a sound analytical basis for establishing and resourcing that capability .

however , it is not clear that dod is yet at this point , especially for developmental testing .

dod has not conducted analysis on the right size of the developmental test and evaluation office or captured data that would reinforce range funding and workforce actions , or suggest needed adjustments .

additionally , the deputy assistant secretary for developmental test and evaluation believes that there may also be a statutory provision that limits his ability to achieve efficiencies and address office challenges .

to the extent dod cannot provide adequate systems engineering and developmental testing support to its weapons portfolio , the risks of executing the portfolio within cost and schedule are increased .

we recommend that the secretary of defense take the following two actions:  assess the resources and influence needed by the developmental test and evaluation office to assist and oversee defense acquisition programs , including  the number of defense acquisition programs that can be supported by different developmental test and evaluation office staffing levels , including specifying the total number of personnel , the mix of government and contractor employees , and the number of senior executive service personnel needed for each of these staffing levels ;  whether the test resource management center and the office of the deputy assistant secretary for developmental test and evaluation should be combined or resources shifted between organizations to more effectively support the activities of both organizations and if so , identify for congress any statutory revisions that would be necessary ; and the proper reporting channel , taking into account the decision on whether or not to combine the organizations , the statutory oversight requirements , and the level of influence needed to oversee and assess program office developmental testing and service budgeting activities .

 develop a plan to implement the results of the assessment .

we also recommend that the secretary of defense , with input from the military services , take the following two actions:  develop metrics to assess the mrtfb test capabilities ( expanding to dod non - mrtfb , and non - dod government test facilities once an approved set of metrics are in place supporting the mrtfb ) , justify funding , and assist in making decisions on the right - sizing of personnel , how best to allocate funding , or make future decisions on whether to mothball , shut down , or consolidate test facilities .

these efforts should be coordinated with the test resource management center .

report the impact budget cuts reflected in the fiscal year 2012 budget , as well as the insourcing policy clarification , will have on their ( 1 ) total workforce ( civilians , military , and contractors ) that support both of these activities and ( 2 ) ability to meet program office systems engineering and developmental test and evaluation needs .

contingent upon the results of dod's assessment , the congress may want to consider revising any applicable statutory provisions necessary to allow for dod to combine or shift resources between the test resource management center and the office of the deputy assistant secretary for developmental test and evaluation .

dod provided us with written comments on a draft of this report .

dod concurred with two recommendations and partially concurred with two others .

dod offered suggested wording changes to the recommendations where it partially agreed to offer greater clarity .

we agreed with the suggested changes and reworded our recommendations accordingly .

dod's comments appear in appendix ii .

dod also provided technical comments , which we incorporated as appropriate in the report .

in its response , dod noted that the deputy assistant secretary for developmental test and evaluation has directed a study to assess the resources and influence needed by the developmental test and evaluation office to assist and oversee defense acquisition programs .

the deputy assistant secretary for development test and evaluation will develop a plan to implement actionable recommendations from the results of the assessment , with the approval of the under secretary of defense for acquisition , technology and logistics .

the deputy assistant secretary for developmental test and evaluation also plans to establish a working group , with participation from the military services , to develop metrics to assess mrtfb test capabilities , justify funding , and assist in making decisions on human capital and test facilities management .

finally , the deputy assistant secretaries for systems engineering and developmental test and evaluation plan to identify any impacts to the state of the workforce due to funding modifications or dod's workforce policy updates in their joint annual report to the congress .

we are sending copies of this report to the secretary of defense , the director of the office of management and budget , and interested congressional committees .

we will also make copies available at no charge on the gao web site at http: / / www.gao.gov .

if you have any questions about this report or need additional information , please contact me at ( 202 ) 512-4841 or sullivanm@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix iii .

this report examines the military services' systems engineering and developmental testing workforce capabilities and the department of defense's ( dod ) efforts to implement weapon systems acquisition reform act of 2009 ( reform act ) requirements .

specifically , we examined ( 1 ) the progress dod has made in implementing the reform act's systems engineering and developmental testing requirements and ( 2 ) whether there are challenges at the military service level that could affect their systems engineering and developmental testing activities .

to measure dod's progress in implementing reform act requirements related to systems engineering and developmental testing , we interviewed officials and collected pertinent documents from the offices of the deputy assistant secretary of defense for systems engineering and developmental test and evaluation .

specifically , we collected information on their efforts to develop additional policy and guidance ; review and approve acquisition planning documents of major acquisition programs ; monitor and review activities of major acquisition programs ; and develop guidance for the development of performance metrics to use on weapon acquisition programs .

we also reviewed their staffing plans and questioned the deputy assistant secretaries , as well as former dod developmental testing experts on whether each of the offices has the necessary amount of resources and influence to fulfill their missions .

in order to determine whether there are challenges at the military service level that could affect future systems engineering and developmental testing activities , we looked at planned and actual workforce growth and developmental test range activities , and specifically at the following .

 we collected and compared the military services' original workforce growth projections with their current workforce projections for the systems engineering and test and evaluation career fields .

for this report , when we use the term systems engineering career field , we are referring to the systems planning , research development , and engineering — systems engineering and program systems engineering career fields .

the air force and army's original plans were based on their fiscal year 2008 budget estimate submissions and the navy's was based on its fiscal year 2009 budget estimate submission .

current plans for each of the services were based on their fiscal year 2012 budget estimate submissions .

workforce data covered the fiscal years 2009-2015 timeframe for both the original and current plans .

we interviewed officials within the office of the secretary of defense and military services to determine the underlying causes for variances between the two plans and to determine how the secretary of defense's cost efficiency measures are affecting new hiring and insourcing plans .

navy officials stated that they used fiscal year 2009 as their baseline because before that time , information from various commands was not centralized and they could not verify the accuracy of the numbers .

navy officials stated that they have confidence in the validity of the numbers that support the fiscal year 2009 baseline because factors that affect workforce counts , such as recodes , decodes , reassignments , and attrition , are treated consistently .

 we compared the services' baseline workforce data with end of fiscal year 2010 workforce numbers to determine how much growth occurred in the two career fields over the past 2 fiscal years .

the air force's and army's workforce baseline was the end of fiscal year 2008 and the navy's was the end of fiscal year 2009 .

we assessed the reliability of these data by interviewing knowledgeable officials in the air force , army , and navy about the processes they use to ensure both the integrity and reliability of their manpower workforce databases used to track acquisition personnel .

we determined that the data were sufficiently reliable for the purposes of this report .

 we conducted site visits to 12 ranges and facilities — 11 of these are designated as part of the major range and test facility base ( mrtfb ) and one is a non - mrtfb range — to determine challenges affecting dod's ability to conduct developmental testing .

we focused our discussions on a broad range of topics , including funding , workforce , range facilities and instrumentation , encroachment , contractor duplication of dod test facilities , and test resource capacity and demand .

we selected four ranges per service based on geographical diversity , level of funding , type of testing , and recommendations from the office of the secretary of defense and the services .

the test ranges we visited were: aberdeen test center , maryland ; air force flight test center , california ; arnold engineering development center , tennessee ; atlantic undersea test and evaluation center , bahamas ; 46th test group , new mexico ; 46th test wing , florida ; high energy laser systems test facility , new mexico ; naval air warfare center – aircraft division , maryland ; naval air warfare center – weapons division , california ; pacific missile range facility , hawaii ; redstone test center , alabama ; and white sands missile range , new mexico .

 finally , we compared developmental test range funding included in the president's budget future year's defense plan for fiscal year 2011 and 2012 .

we discussed differences between the two plans and how decreases in the fiscal year 2012 plan would affect developmental testing activities with officials from the test resource management center , the military services , and the office of the deputy assistant secretary of defense for developmental test and evaluation .

we also discussed with these officials the progress dod and the services have made in developing metrics that could be used to make workforce and investment decisions .

we conducted this performance audit from september 2010 to september 2011 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact name above , bruce thomas , assistant director ; cheryl andrew ; rae ann sapp ; keith hudson ; laura greifner ; and marie ahearn made key contributions to this report .

