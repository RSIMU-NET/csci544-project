for decades , the department of defense ( dod ) has been challenged in modernizing its thousands of business systems .

in 1995 , we first designated dod's business systems modernization program as high risk , and we continue to designate it as such today .

as our research on public and private sector organizations shows , one key ingredient to a successful systems modernization program is having and using a well - defined enterprise architecture .

accordingly , we made recommendations to the secretary of defense in 2001 that included the means for effectively developing and implementing an enterprise architecture .

between 2001 and 2005 , we reported on challenges that the department faced in its efforts to develop a business enterprise architecture ( bea ) and made additional recommendations .

to require dod to address these and other modernization management challenges , congress included provisions in the ronald w. reagan national defense authorization act for fiscal year 2005 that were consistent with our recommendations .

in response , dod adopted an incremental , federated approach to developing its bea .

we subsequently reported that this approach was consistent with best practices and that the initial version of the architecture provided a foundation on which to build and align the department's bea with subsidiary architectures ( i.e. , military department and defense agency component - and individual program - level architectures ) .

in light of the critical role that military department architectures play in dod's federated bea construct , you asked us to assess the status of the departments of the army , navy , and air force enterprise architecture programs .

to accomplish this , we used a standard data and document collection instrument to obtain key information about each department's architecture governance , content , use , and measurement .

on the basis of the military departments' responses and supporting documentation , we analyzed the extent to which each satisfied the 31 core elements in our architecture maturity framework .

we also compared the current status of each military department's program against the status that we reported in 2006 .

we performed our work in the metropolitan area of washington , d.c. , from september 2007 through march 2008 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

details on our objectives , scope , and methodology are provided in appendix i .

dod is a massive and complex organization .

to illustrate , the department reported that its fiscal year 2007 operations involved approximately $1.5 trillion in assets and $2.1 trillion in liabilities , more than 2.9 million military and civilian personnel , and $544 billion in net cost of operations .

in support of its military operations , the department performs an assortment of interrelated and interdependent business functions — using thousands of business systems — related to major business areas such as weapon systems management , supply chain management , procurement , health care management , and financial management .

the ability of these systems to operate as intended affects the lives of our warfighters both on and off the battlefield .

as we have previously reported , the dod systems environment that supports these business functions is overly complex ; error - prone ; and characterized by little standardization across the department , multiple systems performing the same tasks , the same data stored in multiple systems , and the need for data to be entered manually into multiple systems .

moreover , dod recently reported that this systems environment is comprised of approximately 3,000 separate business systems .

for fiscal year 2007 , congress appropriated approximately $15.7 billion to dod ; for fiscal year 2008 , dod has requested about $15.9 billion in appropriated funds to operate , maintain , and modernize these business systems and the associated infrastructures , of which approximately $11 billion was requested for the military departments .

dod's pervasive business system and related financial management deficiencies adversely affect its ability to assess resource requirements ; control costs ; ensure basic accountability ; anticipate future costs and claims on the budget ; measure performance ; maintain funds control ; prevent and detect fraud , waste , and abuse ; and address pressing management issues .

in fact , dod currently bears responsibility , in whole or in part , for 15 of the 27 federal government's program areas that we have designated as high risk .

eight of these areas are specific to dod and the department shares responsibility for 7 other governmentwide high - risk areas .

dod's business systems modernization is one of the high - risk areas , and it is an essential component for addressing many of the department's other high - risk areas .

for example , modernized business systems are integral to the department's efforts to address its financial , supply chain , and information security management high - risk areas .

a well - defined and effectively implemented enterprise architecture is , in turn , integral to the successful modernization of dod's business systems .

an enterprise architecture ( ea ) is a blueprint that describes an organization's or a functional area's current and desired state in both logical and technical terms , as well as a plan for transitioning between the two states .

as such , it is a recognized tenet of organizational transformation and it management in public and private organizations .

without an ea , it is unlikely that an organization will be able to transform business processes and modernize supporting systems to minimize overlap and maximize interoperability .

for more than a decade , we have conducted work to improve agency architecture efforts .

to this end , we developed the enterprise architecture management maturity framework ( eammf ) that provides federal agencies with a common benchmarking tool for assessing the management of their ea efforts and developing improvement plans .

an enterprise can be viewed as either a single organization or a functional area that transcends more than one organization ( eg , financial management or homeland security ) .

an architecture can be viewed as the structure ( or structural description ) of any activity .

thus , eas are systematically derived and captured descriptions depicted in models , diagrams , and narratives .

more specifically , an architecture describes the enterprise in logical terms ( such as interrelated business processes and business rules , information needs and flows , and work locations and users ) as well as in technical terms ( such as hardware , software , data , communications , security attributes , and performance standards ) .

it provides these perspectives both for the enterprise's current , or “as - is,” environment , and for its target , or “to - be,” environment , and it provides a transition plan for moving from the “as - is” to the “to - be” environment .

the importance of eas is a basic tenet of both organizational transformation and it management , and their effective use is a recognized hallmark of successful public and private organizations .

for over a decade , we have promoted the use of architectures , recognizing them as a crucial means to a challenging end: optimized agency operations and performance .

the alternative , as our work has shown , is the perpetuation of the kinds of operational environments that saddle many agencies today , in which the lack of integration among business operations and the it resources that support them leads to systems that are duplicative , not well integrated , and unnecessarily costly to maintain and interface .

employed in concert with other important it management controls ( such as portfolio - based capital planning and investment control practices ) , architectures can greatly increase the chances that organizations' operational and it environments will be configured to optimize mission performance .

the concept of eas originated in the mid - 1980s ; various frameworks for defining the content of these architectures have been published by government agencies and the office of management and budget ( omb ) .

moreover , legislation and federal guidance requires agencies to develop and use architectures .

 ( see appendix iii for a brief description of architecture frameworks and related legislation and management guidance. ) .

in 2002 , we developed version 1.0 of the eammf to provide federal agencies with a common benchmarking tool for planning and measuring their efforts to improve enterprise architecture management , as well as to provide omb with a means for doing the same governmentwide .

we issued an update of the framework ( version 1.1 ) in 2003 .

this framework is an extension of a practical guide to federal enterprise architecture , version 1.0 , published by the chief information officers council .

version 1.1 of the framework arranges 31 core elements ( practices or conditions that are needed for effective enterprise architecture management ) into a matrix of five hierarchical maturity stages and four critical success attributes that apply to each stage .

within a given stage , each critical success attribute includes between one and four core elements .

based on the implicit dependencies among the core elements , the eammf associates each element with one of five maturity stages ( see fig .

1 ) .

the core elements can be further categorized by four groups: architecture governance , content , use , and measurement .

stage 1: creating enterprise architecture awareness .

at stage 1 , either an organization does not have plans to develop and use an architecture , or it has plans that do not demonstrate an awareness of the value of having and using an architecture .

while stage 1 agencies may have initiated some enterprise architecture activity , these agencies' efforts are ad hoc and unstructured , lack institutional leadership and direction , and do not provide the management foundation necessary for successful enterprise architecture development as defined in stage 2 .

stage 2: building the enterprise architecture management foundation .

an organization at stage 2 recognizes that the ea is a corporate asset by vesting accountability for it in an executive body that represents the entire enterprise .

at this stage , an organization assigns architecture management roles and responsibilities and establishes plans for developing architecture products and for measuring program progress and product quality ; it also commits the resources necessary for developing an architecture — people , processes , and tools .

specifically , a stage 2 organization has designated a chief architect and established and staffed a program office responsible for ea development and maintenance .

further , it has established a committee or group that has responsibility for governance ( i.e. , directing , overseeing , and approving architecture development and maintenance ) .

this committee or group membership has enterprisewide representation .

at stage 2 , the organization either has plans for developing or has started developing at least some architecture products , and it has developed an enterprisewide awareness of the value of enterprise architecture and its intended use in managing its it investments .

the organization has also selected a framework and a methodology that will be the basis for developing the architecture products and has selected a tool for automating these activities .

stage 3: developing the enterprise architecture .

an organization at stage 3 focuses on developing architecture products according to the selected framework , methodology , tool , and established management plans .

roles and responsibilities assigned in the previous stage are in place , and resources are being applied to develop actual products .

at this stage , the scope of the architecture has been defined to encompass the entire enterprise , whether organization - based or function - based .

although the products may not be complete , they are intended to describe the organization in terms of business , performance , information / data , service / application , and technology ( including security explicitly in each ) , as provided for in the framework , methodology , tool , and management plans .

further , the products are to describe the current ( “as - is” ) and future ( “to - be” ) states and the plan for transitioning from the current to the future state ( the sequencing plan ) .

as the products are developed and evolve , they are subject to configuration management .

further , through the established enterprise architecture management foundation , the organization is tracking and measuring its progress against plans , identifying and addressing variances , as appropriate , and then reporting on its progress .

stage 4: completing the enterprise architecture .

an organization at stage 4 has completed its architecture products , meaning that the products have been approved by the ea steering committee ( established in stage 2 ) or an investment review board and by the chief information officer ( cio ) .

the completed products collectively describe the enterprise in terms of business , performance , information / data , service / application , and technology for both its current and future operating states ; the products also include a plan for transitioning from the current to the future state .

further , an independent agent has assessed the quality ( i.e. , completeness and accuracy ) of the architecture products .

additionally , evolution of the approved products is governed by a written ea maintenance policy approved by the head of the organization .

stage 5: leveraging the enterprise architecture to manage change .

an organization at stage 5 has secured senior leadership approval of the architecture products and a written institutional policy stating that it investments must comply with the architecture , unless granted an explicit compliance waiver .

further , decision makers are using the architecture to identify and address ongoing and proposed it investments that are conflicting , overlapping , not strategically linked , or redundant .

as a result , stage 5 entities avoid unwarranted overlap across investments and ensure maximum systems interoperability .

maximum interoperability , in turn , ensures the selection and funding of it investments with manageable risks and returns .

also , at stage 5 , the organization tracks and measures ea benefits or return on investment , and adjustments are continuously made to both the architecture management process and the enterprise architecture products .

attribute 1: demonstrates commitment .

because the ea is a corporate asset for systematically managing institutional change , the support and sponsorship of the head of the enterprise are essential to the success of the architecture effort .

an approved enterprise policy statement provides such support and sponsorship by promoting institutional buy - in and encouraging resource commitment from participating components .

equally important in demonstrating commitment is vesting ownership of the architecture in an executive body that collectively owns the enterprise .

attribute 2: provides capability to meet commitment .

the success of the ea effort depends largely on the organization's capacity to develop , maintain , and implement the enterprise architecture .

consistent with any large it project , these capabilities include providing adequate resources ( i.e. , people , processes , and technology ) , defining clear roles and responsibilities , and defining and implementing organizational structures and process management controls that promote accountability and effective project execution .

attribute 3: demonstrates satisfaction of commitment .

satisfaction of the organization's commitment to develop , maintain , and implement an ea is demonstrated by the production of artifacts ( eg , the plans and products ) .

such artifacts demonstrate follow through — actual ea production .

satisfaction of commitment is further demonstrated by senior leadership approval of enterprise architecture documents and artifacts ; such approval communicates institutional endorsement and ownership of the architecture and the change that it is intended to drive .

attribute 4: verifies satisfaction of commitment .

this attribute focuses on measuring and disclosing the extent to which efforts to develop , maintain , and implement the ea have fulfilled stated goals or commitments of the enterprise architecture .

measuring such performance allows for tracking progress that has been made toward stated goals , allows appropriate actions to be taken when performance deviates significantly from goals , and creates incentives to influence both institutional and individual behaviors .

figure 1 illustrates the eammf's maturity stages , attributes , and core elements .

the framework's 31 core elements can also be placed in one of four groups of architecture - related activities , processes , products , events and structures .

the groups are architecture governance , content , use , and measurement .

each is defined below .

governance refers to core elements that provide the management structures and processes needed to guide and direct the architecture program .

content refers to core elements that provide for the scope , depth , integrity , understanding , and consistency of products and artifacts that make up the architecture .

use refers to core elements that provide for an architecture - centric approach to it investment management ( i.e. , treating architecture as the authoritative frame of reference in guiding and constraining it investments ) .

measurement refers to core elements that provide for determining and disclosing progress in developing , maintaining , and using the architecture , including measurement against plans , process standards , and product quality standards .

these groups are generally consistent with the capability area descriptions in the omb ea assessment tool .

for example , omb's completion capability area addresses ensuring that architecture products describe the agency in terms of processes , services , data , technology , and performance and that the agency has developed a transition strategy .

similarly , our content group includes developing and completing these same ea products .

in addition , omb's results capability area addresses performance measurement , as does our measurement group , and omb's use capability area addresses many of the same elements in our governance and use groups .

table 1 lists the core elements according to eammf group .

dod is pursing a federated strategy to develop and implement the many and varied architectures across the department's four mission areas — warfighting , business , dod intelligence , and enterprise information environment .

according to officials in the office of the assistant secretary of defense ( networks and information integration ) / chief information officer ( asd ( nii ) / cio ) , they have issued a strategy for evolving dod's global information grid ( gig ) architecture that is to provide a comprehensive architectural description of the entire dod enterprise , including all mission areas and the relationships between and among all levels of the enterprise ( eg , mission areas , components , and programs ) .

figure 2 provides a simplified , conceptual depiction of dod's ea federation strategy .

asd ( nii ) / cio officials stated that the goal of this strategy is to improve the ability of dod's mission areas , components , and programs to share architectural information .

in this regard , officials stated that the dod ea federation strategy will define federation and integration concepts , alignment ( i.e. , linking and mapping ) processes , and shared services .

the first business mission area ( bma ) federation strategy was released in september 2006 , according to asd ( nii ) / cio officials .

its purpose is to expand on the dod ea federation strategy and provide details on how various aspects of the federation will be applied within the department's bma .

in this regard , the bma strategy cites the following four goals: establish a capability to search for data in member architectures that may be relevant for analysis , reference , or reuse ; develop a consistent set of standards for architecture configuration management that will enable users to determine the development status and quality of data in various architectures ; establish a standard methodology for specifying linkages among existing component architectures that were developed using different tools and that are maintained in independent repositories ; and develop a standard methodology to reuse capabilities described by various architectures .

to assist in accomplishing these goals , the strategy described three concepts that are to be applied: 1 .

tiered accountability provides for architecture development at each of the department's organizational levels .

2 .

net - centricity provides for seamless and timely accessibility to information where and when needed via the department's interconnected network environment .

3 .

federating dod architectures provides for linking or aligning subordinate and parent architectures via the mapping of common architectural information .

this concept advocates subordinate architecture alignment to the parent architecture .

in 2005 , dod reassigned responsibility for directing , overseeing , and executing its business transformation and systems modernization efforts to the defense business systems management committee ( dbsmc ) and the business transformation agency .

the dbsmc is chaired by the deputy secretary of defense and serves as the highest - ranking governance body for business systems modernization activities .

according to its charter , the dbsmc provides strategic direction and plans for the bma in coordination with the warfighting and the enterprise information environment mission areas .

the dbsmc is also responsible for reviewing and approving the bea and the enterprise transition plan .

the business transformation agency operates under the authority , direction , and control of the dbsmc and reports to the under secretary of defense for acquisition , technology , and logistics in the incumbent's capacity as the vice chair of the dbsmc .

oversight for this agency is provided by the deputy under secretary of defense for business transformation , and day - to - day management is provided by the director .

the business transformation agency's primary responsibility is to lead and coordinate business transformation efforts across the department .

in particular , it is responsible for ( 1 ) maintaining and updating the department's architecture , ( 2 ) ensuring that functional priorities and requirements of various defense component organizations are reflected in the architecture , and ( 3 ) ensuring the adoption of dod - wide information and process standards as defined in the architecture .

under dod's tiered accountability approach to systems modernization , components are responsible for defining their respective component architectures and transition plans .

similarly , program managers are responsible for developing program - level architectures and transition plans and ensuring integration with the architectures and transition plans developed and executed at the enterprise and component levels .

between may 2001 and july 2005 , we reported on dod's efforts to develop an architecture and identified serious problems and concerns with the department's architecture program , including the lack of specific plans outlining how dod would extend and evolve the architecture to include the missing scope and detail .

to address these concerns , in september 2003 , we recommended that dod develop a well - defined , near - term plan for extending and evolving the architecture and ensure that this plan would address our recommendations: defining roles and responsibilities of all stakeholders involved in extending and evolving the architecture , explaining dependencies among planned activities , and defining measures of progress for the activities .

in response to our recommendations , in 2005 , dod adopted a 6-month incremental approach to developing its architecture and released version 3.0 of the bea and the associated transition plan in september 2005 , describing them as the initial baselines .

since then , dod has released three updated versions of both — version 3.1 , released on march 15 , 2006 ; version 4.0 , released on september 28 , 2006 ; and version 4.1 , released on march 15 , 2007 .

as we have previously reported , these incremental versions have provided additional content and clarity and resolved limitations that we identified in the prior versions .

for example , version 4.1 improved the financial visibility business enterprise priority area by including the standard financial information structure data elements and business rules to support cost accounting and reporting .

in addition , version 4.1 addressed , to varying degrees , missing elements , inconsistencies , and usability issues that we previously identified .

in august 2006 , we reported that the departments of the air force , navy , and army had fully satisfied about 45 , 32 , and 3 percent , and partially satisfied 26 , 39 , and 42 percent , respectively , of the 31 core elements in our architecture maturity framework ( see table 2 ) .

by comparison , other major federal departments and agencies that we reviewed had , as a whole , fully satisfied about 67 percent of the framework's core elements .

among the key elements that all three military departments had not fully satisfied were developing architecture products that describe their respective target architectural environments and developing transition plans for migrating to a target environment .

furthermore , while the military departments had partially satisfied between 26 and 42 percent of the core elements in our framework , we reported that partially satisfied elements were not necessarily easy to satisfy fully , such as those that address architecture content ; and thus , partials can have serious implications for the quality and usability of an architecture .

to assist the military departments in addressing their ea challenges and managing their programs , we recommended that they develop and implement plans for fully satisfying each of the conditions in our framework .

dod generally agreed with our findings and recommendations .

in april 2007 , we reported that dod's bma federation strategy provided a foundation on which to build and align dod's parent bea with its subordinate architectures ( i.e. , component - and program - level architectures ) .

in particular , we found that this strategy ( 1 ) stated the department's federated architecture goals ; ( 2 ) described federation concepts that are to be applied ; and ( 3 ) included high - level activities , capabilities , products , and services that are intended to facilitate implementation of the concepts .

however , we also reported that dod had yet to define the details needed to execute the strategy , such as how the architecture federation was to be governed ; how alignment with the dod federation strategy and other potential mission - area federation strategies was to be achieved ; how component architectures' alignment with incremental versions of the bea was to be achieved ; how shared services would be identified , exposed , and subscribed to ; and what milestones would be used to measure progress and results .

as a result , we concluded that much remained to be decided and accomplished before dod would have in place the means to create a federated architecture and thus be able to fully satisfy both our prior recommendations and legislative requirements aimed at adopting an architecture - centric approach to departmentwide business systems investment management .

in may 2007 , we concluded that while dod has made progress in developing the bea , much remained to be accomplished .

in particular , we reported that dod had yet to extend and evolve its corporate bea through the development of aligned , subordinate architectures for each of its component organizations , and while it had developed a strategy for federating the bea in this manner , this strategy lacked the detail needed for it to be fully effective .

we also reported that this situation was compounded by the known immaturity of the military departments' architecture efforts .

accordingly , we recommended that dod include in its annual report to congress on compliance with section 332 of the fiscal year 2005 national defense authorization act the results of assessments by its bea independent verification and validation contractor on the completeness , consistency , understandability , and usability of its federated family of business mission architectures , including the associated transition plans .

dod agreed with this recommendation .

each of the military departments' enterprise architecture programs is at the initial stage of our maturity framework , meaning that each has not fully satisfied all of the core elements associated with the framework's second stage ( establishing the management foundation for developing , maintaining , and using the architecture ) .

also , none have fully satisfied the core elements associated with stage 3 ( developing the architecture ) , 4 ( completing the architecture ) , and 5 ( leveraging the architecture for organizational change ) .

as a result , none have yet to advance to a state that can be considered fully mature and effective .

although all departments are at stage 1 , the status of the three vary considerably .

specifically , the air force far exceeds the navy , which generally exceeds the army , in terms of the total number of core elements that are fully satisfied .

further , even though all three are at stage 1 , the air force has at least partially satisfied all of the core elements associated with stage 3 and has partially satisfied all but three core elements across all stages .

the navy has at least partially satisfied all of the core elements associated with stage 2 and all but one of the stage 3 core elements .

moreover , the air force has made important progress in maturing its ea program over the last 2 years , while the navy has made mixed progress , and the army has not made progress .

as our research shows , the state of an organization's ea program owes largely to the extent to which the program has benefited from sustained executive leadership .

this is because virtually all of the barriers to effectively developing and using architectures , such as parochialism , cultural resistance , adequate resources , and top management understanding , can be addressed through such leadership .

in this regard , air force officials attributed their progress toward establishing a fully mature architecture program to sustained executive leadership .

without fully mature programs , the departments introduce increased risk of developing and implementing it solutions that are duplicative , do not interoperate , and thus do not optimize departmentwide performance .

to reach a given stage of maturity under our architecture framework and associated evaluation methodology , a military department had to fully satisfy all of the core elements at that stage .

using this criterion , each of the military departments is at stage 1 , meaning that none could demonstrate through verifiable documentation that it has established all of the core foundational commitments and capabilities needed to effectively manage the development , maintenance , and implementation of an architecture .

however , this does not mean that the departments are at identical states of maturity .

rather , the air force is considerably more advanced than the navy and army .

 ( see appendices iv through vi for details on the extent to which each military department satisfied each of the core elements of our maturity framework. ) .

assigning the military departments' architecture programs to a maturity stage based on whether all elements of a stage are fully satisfied provides only one perspective on these programs .

another is the extent to which each program has also fully satisfied core elements across higher stages of maturity .

when the percentage of core elements that have been fully satisfied across all stages is considered , a similar picture of the departments' relative variability is evident .

specifically , the percent of all core elements that are fully satisfied ranges from a high of 61 percent for the air force to a low of 3 percent for the army ( the navy fully satisfied 13 percent of the core elements ) .

table 3 summarizes the percentage of core elements that are fully satisfied in total , by maturity stage , for each military department .

notwithstanding this perspective , it is important to note that the staging of core elements in our framework provide a hierarchical or systematic progression to establishing a mature and effective architecture program .

that is , core elements associated with lower framework stages generally support the effective execution of higher maturity stage core elements .

for instance , if a program has developed its full suite of “as - is” and “to - be” architecture products , including a sequencing plan ( stage 4 core elements ) , but the products are not under configuration management ( stage 3 core element ) , then the integrity and consistency of the products cannot be adequately assured .

in this regard , even though the navy has partially developed its ea products , the quality of these products is questionable because the navy has not placed them under configuration management .

further , not satisfying even a single lower stage core element can have a significant impact on the effectiveness of an architecture program .

for example , not using a defined framework or methodology ( stage 2 core element ) or not performing configuration management ( stage 3 core element ) , can significantly limit the quality and utility of an architecture .

dod's experience between 2001 and 2005 in developing its bea is a case in point .

during this time , we made a series of recommendations grounded in , among other things , our architecture management framework to ensure that it was successful in doing so .

in 2005 , we reported that despite investing hundreds of millions of dollars and 4 years in developing multiple versions of wide - ranging architecture products , the department did not have a well - defined architecture , and what it did develop had limited utility .

among other things , we attributed the poor state of its architecture products to methodological , human capital , and configuration management weaknesses .

looking at related groupings of core elements that are fully satisfied also provides a useful perspective on the state of the military departments' architecture programs .

as noted earlier , these groupings of core elements are architecture governance , content , use , and measurement .

overall , the military departments varied in the extent to which each of the groups were met .

for example , while the air force fully satisfied 71 percent of the governance core elements , the navy and army only fully satisfied 14 and 7 percent , respectively .

the extent to which each department satisfied the core elements in each grouping are discussed below .

 ( see table 4 for a summary of the extent to which each department fully satisfied these groupings. ) .

governance refers to core elements that provide the management structures and processes needed to guide and direct an architecture program .

neither the navy nor the army has established effective architecture governance , having satisfied only 14 and 7 percent of these core elements , respectively .

for example , neither has a written or approved departmentwide policy for ea development and maintenance or for requiring that it investments comply with the ea .

this is important because approved policies demonstrate institutional commitment to having and using an architecture .

as our framework states , an approved enterprisewide policy provides the kind of top management support and sponsorship needed to overcome the barriers to architecture development and use .

in contrast , the air force has fully satisfied the majority of governance core elements .

however , the remaining unsatisfied core elements are significant .

for example , it has not fully established a committee or group with representation from across the enterprise to direct , oversee , and approve the architecture .

this is significant because the architecture is a corporate asset that needs to be enterprisewide in scope and accepted by senior leadership if it is to be leveraged effectively for organizational change .

content refers to core elements that provide for the scope , depth , integrity , understanding , and consistency of products and artifacts that make up the architecture .

only the air force has fully satisfied much in the way of architecture content , having fully met 60 percent of the core elements , with the navy and army meeting only 10 and 0 percent , respectively .

for example , while the air force has placed its ea products under configuration management and provided for ensuring that its ea products will describe the “as - is” environment , “to - be” environment , and sequencing plan , neither the navy nor the army has done the same .

moreover , none of the departments have fully addressed security as part of their respective “as - is” and “to - be” products developed to date .

this is important because security is relevant and essential to every aspect of an organization's operations , and therefore , the nature and substance of institutionalized security requirements , controls , and standards should be embedded throughout the architecture .

further , none of the departments is using an independent verification and validation agent to help ensure the quality of these products .

as we have previously reported , independent verification and validation is a proven means for obtaining unbiased insight into such essential architecture qualities as completeness , understandability , and consistency .

use refers to core elements that provide for an architecture - centric approach to it investment management ( i.e. , treating architecture as the authoritative frame of reference for guiding and constraining it investments ) .

again , the air force has fully satisfied 50 percent of this grouping's core elements , while the navy and the army have fully satisfied none of the core elements .

for example , the air force has made its ea an integral component of its it investment process by requiring that investments demonstrate their architectural compliance .

this is important because in order for the benefits of an ea to be realized , it investments must comply with it .

however , neither the air force nor the other two departments could demonstrate that their respective it investments are actually in compliance with their respective architectures .

this is relevant because the benefits from using an ea , such as improved information sharing , increased consolidation , enhanced productivity , and lower costs , cannot be fully realized unless individual investments are actually in compliance with , for example , architectural rules and standards .

measurement refers to core elements that provide for determining and disclosing progress in developing , maintaining , and using the ea , including measurement against plans , process standards , and product quality .

none of the departments satisfied many of these core elements .

specifically , the air force fully satisfied 40 percent and the navy fully satisfied 20 percent of these core elements , while the army did not satisfy any .

for example , while the air force has plans that call for the development of metrics to measure ea progress , quality , compliance , and return on investment , and the navy is measuring and reporting on progress against plans , none of the departments is measuring and reporting on it investment compliance with its architecture or return on investment from its architecture program .

without measuring architecture development , maintenance , and use , an organization is not positioned to take timely corrective action to address deviations from plans , expectations , and outcomes , which in turn limits the chances of ea program success .

in instances where the military departments have not fully satisfied certain core elements in our framework , two have at least partially satisfied many of these elements .

to illustrate , the air force would improve to stage 3 if the criterion for being at a given stage was relaxed to only partially satisfying a core element .

moreover , the navy would advance to stage 2 under this less demanding criterion .

in contrast , the army would remain at stage 1 .

partial satisfaction of a core element is an indicator of some progress and provides a basis on which to improve .

nevertheless , it also indicates that more work is needed , for example , to establish architectural commitments and capabilities and to demonstrate and verify that both exist and are functioning as intended .

moreover , even though a core element can be partially satisfied , what remains to fully satisfy it can be significant and can require considerable time and resources .

thus , it is important to note that even though the departments have partially satisfied some core elements , fully satisfying some of them may remain a challenge .

it is also important to note that fully , rather than partially , satisfying certain elements , such as those that fall within the architecture content group , are key to the success of an ea .

not fully satisfying these elements can have important implications for the quality of an architecture , and thus its usability and results .

the extent to which each of the departments partially satisfied the core elements at each stage of our framework is discussed below and summarized in table 5 .

metis architecttm is an architecture tool from troux technologies , inc. ea , these metrics do not address measuring progress against plans .

as our framework states , progress in developing ea products should be measured against ea plans so that deviations from expectations can be examined for cause and impact and appropriate actions can be taken to address them .

the navy has at least partially satisfied 93 percent of the elements associated with stages 2 and 3 and has in place many aspects of the core elements that support these stages , which it can use to continue establishing an effective architecture management foundation and associated plans and products .

however , important aspects of certain core elements are missing .

for example , similar to the air force , the navy is developing its ea using a framework ( the dod architecture framework ) and automated tools ( telelogic system architect® and metis architecttm ) .

also , similar to the air force , the navy does not have a documented methodology governing how its architecture is being developed and maintained .

in addition , the navy has yet to establish a committee or group representing the enterprise that is responsible for directing , overseeing , or approving the architecture .

establishing such a governance entity is important because it demonstrates the organization's commitment to building and using an architecture and helps to obtain necessary buy - in from across the organization .

further , while the navy has drafted an ea policy , the policy has not yet been approved .

approval is important because it demonstrates senior leadership commitment to the architecture and clearly assigns responsibility and accountability for development and maintenance of the architecture .

the army has at least partially satisfied 27 percent of the elements associated with stages 2 and 3 , but has not made progress toward establishing the commitments and capabilities that comprise the core elements integral to an effective architecture management foundation and associated plans and products .

in particular , while the army has an ea program office , the office does not have an approved charter .

a program charter is important because it defines key aspects about how the office will operate in order to achieve program goals and outcomes .

further , while the army is using an automated tool ( system architect ) to capture architecture products , it is not using a framework or methodology .

this is significant because the framework provides a defined structure and nomenclature for representing architecture information across the organization and the methodology describes a common set of procedures to be used for developing products in a coherent way .

together , they help to ensure that activities associated with capturing the architecture are understood by those involved and are completed in a consistent , accountable , and repeatable manner .

we reported in august 2006 that each of the military departments was at the initial stage of our architecture maturity framework .

more specifically , we reported that the air force , navy , and army had fully satisfied 45 , 32 , and 3 percent , and that they had partially satisfied 26 , 39 , and 42 percent , of the 31 core elements , respectively .

accordingly , we made recommendations for each department to fully implement the framework's core elements .

since then , the departments have addressed our recommendations to varying degrees .

specifically , the air force has made the most progress , increasing the percentage of fully satisfied core elements from 45 to 61 percent and increasing the percentage of partially satisfied core elements from 26 to 29 percent .

the navy has made mixed progress , decreasing the percentage of fully satisfied core elements from 32 to13 percent and increasing the percentage of partially satisfied core elements from 39 to 52 percent .

the army has not made progress , keeping the percentage of fully satisfied core elements at 3 percent while decreasing the percentage of partially satisfied core elements from 42 to 13 percent .

the specific progress made by each department is discussed below and summarized in table 6 .

the air force's 16 percent increase in the core elements that are fully satisfied relate to five core elements .

for example , we previously reported that the air force's architecture program plans did not call for developing metrics to measure ea progress , quality , compliance , and return on investment .

since then , the air force has expanded its plans to include such metrics .

the addition of these metrics is important because they provide the basis for knowing whether program expectations are being met , which could prompt timely corrective action to address any significant deviations .

also , while the air force did not previously have its architecture products under configuration management , it has since done so .

this progress is important because it helps to integrate and align the products and to track and manage changes to them in a way that ensures product integrity .

finally , the air force has also established the architecture as an integral component of its it investment management process by explicitly requiring that its it investments align with the ea .

this was not the case in 2006 and represents a significant improvement because without requiring alignment , investments are more likely to deviate from the architecture in ways that increase duplication of effort and decrease interoperability .

the air force's 3 percent increase in the core elements that are partially satisfied relate to three core elements .

for example , we reported in 2006 that the air force's ea products did not address security .

since then , the air force has developed an information assurance domain architecture to augment its ea products .

to the air force's credit , this document addresses important aspects of security relative to its technical reference models .

however , it does not similarly address security in relation to the ea's business , systems , and information models .

for example , the business models do not address the goals and strategies for addressing current security risks and future security threats .

in addition , while the air force now has a sequencing plan , this plan is not complete because it does not include , and is not grounded in , an analysis of the gap in capabilities between the department's “as - is” and “to - be” architectural environments .

such a gap analysis is necessary to determine what capabilities are currently lacking and which capabilities will need to be acquired or developed in a sequence that is based on a variety of factors .

according to air force officials , the positive progress that it has made in maturing its architecture program is due , in large part , to the focus , commitment , and leadership of senior department executives , including the secretary of the air force .

in this regard , they said that their experiences and lessons learned show that such leadership paved the way for establishing the department's institutional commitment to its ea .

such commitment , they said , is demonstrated by the air force's approved ea policies and funding , and its capabilities to meet commitments , such as the department's structures and processes for governing architecture development and implementation .

the navy's 19 percent decrease in the core elements that are fully satisfied relate to six core elements , and according to navy officials , are largely due to the navy's recent efforts to expand the scope of its architecture program beyond that which existed in 2006 .

more specifically , in 2006 , the navy's architecture program was focused on what it refers to as forcenet , which is the navy's it infrastructure architecture .

during the course of our review , the navy reported that it has adopted dod's federated architecture approach , thereby expanding its program to include all navy organizations and all architecture reference models ( eg , business , data , performance ) .

however , it has yet to reflect this expansion in program scope in key governance documents , such as its ea policies and plans , that relate to these six core elements .

without fully satisfying these governance core elements , the department will be challenged in its ability to develop and implement a navy - wide federated architecture .

the 13 percent increase in the core elements that are partially satisfied are largely associated with three content - related core elements .

for example , we reported in 2006 that the navy's forcenet products did not include descriptions of the “to - be” architecture in terms of , for example , business , information / data , applications / service , and performance .

under the navy's expanded scope , it has since developed “to - be” architecture products ( dod architecture framework views ) that address these areas .

however , these products are not yet sufficiently complete .

to illustrate , the functional areas ( eg , human resources ) in the business or operational views have not been decomposed into functional activities ( eg , recruiting ) and processes ( eg , interviewing ) , and the information exchanges between functional areas in the operational views are not defined .

moreover , there are no data models to identify and describe relationships among the data elements within each functional area .

according to navy officials , the shift to a broader , federated approach to developing and implementing a navy enterprise architecture was recently endorsed by secretariat - level leadership and senior department executives .

the army continues to fully satisfy one core element ( having a chief architect ) .

however , it has also experienced a 29 percent decrease in those core elements that it had partially satisfied in 2006 ( nine core elements ) , most of which relate to such governance topics as ea policies and plans .

specifically , the plans and policies that the army had in 2006 were not approved .

because they were not approved , they did not fully satisfy the various associated core elements .

since then , the army official principally responsible for the program told us that the department's senior executives , including the army vice - chief of staff , have endorsed a new architecture approach in which the army will use omb's reference models ( eg , business , performance , information / data ) .

to this end , the officials said that decisions are to be made in the near future about how to best structure the program to implement this approach , including what the program's scope will be and what resources will be needed to sustain it .

this official added that once these decisions are made , as part of the army's budget submission and approval process , the ea policies and plans will be updated to reflect these decisions .

if managed effectively , enterprise architectures can be a useful change management and organizational transformation tool .

the conditions for effectively managing enterprise architecture programs are contained in our five stage architecture maturity framework .

none of the military departments has fully satisfied all of the conditions needed to achieve stage 2 or above in the framework , which means that none have programs that we would currently consider effective and mature .

however , the navy has partially satisfied most , and the air force has partially satisfied all , of the core elements needed to be at stage 3 .

in addition , among the three military departments , the air force has satisfied the most core elements across all framework stages .

moreover , the air force has demonstrated the most progress in the last 2 years in satisfying the framework's core elements .

however , the military departments have not yet met the conditions for the effective governance , content , use and measurement of their respective architecture programs .

the air force has a solid foundation on which to continue building , but the navy and , even more so , the army has much to accomplish before either will have effective and mature architecture programs .

as a result , dod , as a whole , is not as well positioned as it should be to realize the significant benefits that a well - managed federation of architecture programs can provide .

as we have previously reported , the key to having a mature architecture program , and thereby realizing the benefits of an architecture - centric approach to it investment decision making , is sustained executive leadership .

this is because virtually all of the barriers to effectively developing and using architectures , such as parochialism , cultural resistance , adequate resources , and top management understanding , can be addressed through such leadership .

for the military departments to advance their respective architecture programs , sustained executive leadership will be needed .

in this regard , the navy and the army could benefit from the lessons learned and experiences to date of the air force's efforts to mature its architecture program .

because we have outstanding recommendations to the secretary of defense aimed at , among other things , having the departments of the air force , navy , and army fully satisfy each of the core elements in our architecture framework , we are not making additional recommendations relative to our framework at this time .

however , given the uneven status and progress of the respective military departments , we reiterate our outstanding recommendations and further recommend that the secretary of defense direct the secretaries of the navy and army to ensure that their respective departments reach out to the department of the air force to learn from and apply the lessons and experiences that have allowed the air force to make the progress it has in maturing its architecture program .

in written comments on a draft of this report , signed by the deputy under secretary of defense ( business transformation ) and reprinted in appendix ii , the department agreed with our recommendation , and described efforts underway and planned to implement it .

we are sending copies of this report to interested congressional committees ; the director , office of management and budget ; and the secretary of defense .

copies of this report will be made available to other interested parties on request .

this report will also be available at no charge on our web site at http: / / www.gao.gov .

if you or your staffs have any questions on matters discussed in this report , please contact me at ( 202 ) 512-3439 or hiter@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix vii .

our objective was to determine the current status of the military departments' enterprise architecture efforts .

to do so , we used a data collection instrument based on our enterprise architecture management maturity framework ( eammf ) , and related guidance , such as the office of management and budget circular a - 130 and guidance published by the federal chief information officers ( cio ) council , as well as our past reports and guidance on the management and content of enterprise architectures .

we also met with the chief architects of the military departments to discuss our scope and methodology , share the data collection instrument , and discuss the type and nature of supporting documentation needed to verify responses to instrument questions .

on the basis of documentation provided to support the departments' respective responses to our data collection instrument , we analyzed the extent to which each department satisfied the 31 core elements in our eammf .

to guide our analyses , we used our standard evaluation criteria for determining whether a given core element was fully satisfied , partially satisfied , or not satisfied ( see tables 7 , 8 , 9 , and 10 for the core elements of stages 2 , 3 , 4 , and 5 , respectively. ) .

to fully satisfy a core element , sufficient documentation had to be provided to permit us to verify that all aspects of the core element were met .

to partially satisfy a core element , sufficient documentation had to be provided to permit us to verify that at least some aspects of the core element were met .

core elements that did not meet criteria for fully or partially satisfied were judged to be not satisfied .

in applying our methodology , we first analyzed and determined the extent to which each department satisfied the core elements in our framework , and then met with their representatives to discuss core elements that were not satisfied and why .

as part of this interaction , we sought , and in some cases were provided , additional supporting documentation .

we then considered this documentation when determining the degree to which each department satisfied each core element .

in applying our evaluation criteria , we analyzed the results across different core elements to determine patterns and issues .

we conducted our work in the metropolitan area of washington , d.c. , from september 2007 through march 2008 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

during the mid - 1980s , john zachman , widely recognized as a leader in the field of enterprise architecture , identified the need to use a logical construction blueprint ( i.e. , an architecture ) for defining and controlling the integration of systems and their components .

accordingly , zachman developed a structure , or framework , for defining and capturing an architecture , which provides for six perspectives , or “windows,” from which to view the enterprise .

zachman also proposed six abstractions , or models , associated with each of these perspectives .

zachman's framework provides a way to identify and describe an entity's existing and planned component parts and the parts' relationships before the entity begins the costly and time - consuming efforts associated with developing or transforming itself .

since zachman introduced his framework , a number of frameworks have emerged within the federal government , beginning with the publication of the national institute of standards and technology framework in 1989 .

since that time , other federal entities have issued frameworks , including the department of defense and the department of the treasury .

in september 1999 , the federal chief information officers council published the federal enterprise architecture framework , which was intended to provide federal agencies with a common construct for their architectures , thereby facilitating the coordination of common business processes , technology insertion , information flows , and system investments among federal agencies .

the federal enterprise architecture framework described an approach , including models and definitions , for developing and documenting architecture descriptions for multiorganizational functional segments of the federal government .

more recently , office of management and budget ( omb ) established the federal enterprise architecture program management office to develop a federal enterprise architecture according to a collection of five “reference models” ( see table 11 ) .

these models are intended to facilitate governmentwide improvement through cross - agency analysis and the identification of duplicative investments , gaps , and opportunities for collaboration , interoperability , and integration within and across government agencies .

although these post - zachman frameworks differ in their nomenclatures and modeling approaches , each consistently provides for defining an enterprise's operations in both logical and technical terms , provides for defining these perspectives for the enterprise's current and target environments , and calls for a transition plan between the two .

legislation and federal guidance address enterprise architecture .

specifically , the clinger - cohen act of 1996 directs the cios of major departments and agencies to develop , maintain , and facilitate the implementation of information technology architectures as a means of integrating agency goals and business processes with information technology .

also , omb circular a - 130 , which implements the clinger - cohen act , requires that agencies document and submit their initial enterprise architectures and that agencies submit updates when significant changes to their enterprise architectures occur .

the circular also directs omb to use various reviews to evaluate the adequacy and efficiency of each agency's compliance with the circular .

since then , omb has developed and implemented an enterprise architecture assessment tool .

according to omb , the tool helps to illustrate the current state of an agency's architecture and assists agencies in integrating architectures into their decision - making processes .

the latest version of the assessment tool ( 2.0 ) was released in december 2005 and includes three capability areas: ( 1 ) completion , ( 2 ) use , and ( 3 ) results .

table 12 describes each of these areas .

the tool also includes criteria for scoring an agency's architecture program on a scale of 0 to 5 .

in early 2006 , the major departments and agencies were required by omb to provide a self - assessment of their architecture programs using the tool .

omb then used the self assessment to develop its own assessment .

these assessment results are to be used in determining the agency's e - government score within the president's management agenda .

stage 2: building the ea management foundation committee or group representing the enterprise is responsible for directing , overseeing , and approving ea .

program office responsible for ea development and maintenance exists .

ea being developed using a framework , methodology , and automated tool .

ea plans call for describing “as - is” environment , “to - be” environment , and sequencing plan .

ea plans call for describing enterprise in terms of business , performance , information / data , applications / service , and technology .

ea plans call for business , performance , information / data , applications / service , and technology to address security .

ea plans call for developing metrics to measure ea progress , quality , compliance , and return on investment .

stage 3: developing architecture products written and approved policy exists for ea development .

ea products are under configuration management .

ea products describe or will describe “as - is” environment , “to - be” environment , and sequencing plan .

both “as - is” and “to - be” environments are described or will be described in terms given in stage 2 .

these descriptions address or will address security .

progress against ea plans is measured and reported .

stage 4: completing architecture products written and approved policy exists for ea maintenance .

ea products and management processes undergo independent verification and validation .

ea products describe “as - is” environment , “to - be” environment , and sequencing plan .

both “as - is” and “to - be” environments are described in terms given in stage 2 .

committee or group representing the enterprise or the investment review board has approved current version of ea .

quality of ea products is measured and reported .

stage 5: leveraging the architecture to manage change written and approved organization policy exists for it investment compliance with ea .

process exists to formally manage ea change .

ea is integral component of it investment management process .

organization head has approved current version of ea .

return on ea investment is measured and reported .

compliance with ea is measured and reported .

stage 2: building the ea management foundation committee or group representing the enterprise is responsible for directing , overseeing , and approving ea .

partial program office responsible for ea development and maintenance exists .

ea being developed using a framework , methodology , and automated tool .

ea plans call for describing “as - is” environment , “to - be” environment , and sequencing plan .

ea plans call for describing enterprise in terms of business , performance , information / data , applications / service , and technology .

ea plans call for business , performance , information / data , applications / service , and technology to address security .

ea plans call for developing metrics to measure ea progress , quality , compliance , and return on investment .

stage 3: developing architecture products written and approved policy exists for ea development .

ea products are under configuration management .

ea products describe or will describe “as - is” environment , “to - be” environment , and sequencing plan .

both “as - is” and “to - be” environments are described or will be described in terms given in stage 2 .

these descriptions address or will address security .

progress against ea plans is measured and reported .

stage 4: completing architecture products written and approved policy exists for ea maintenance .

ea products and management processes undergo independent verification and validation .

ea products describe “as - is” environment , “to - be” environment , and sequencing plan .

both “as - is” and “to - be” environments are described in terms given in stage 2 .

organization cio has approved current version ea .

committee or group representing the enterprise or the investment review board has approved current version of ea .

quality of ea products is measured and reported .

stage 5: leveraging the architecture to manage change written and approved organization policy exists for it investment compliance with ea .

process exists to formally manage ea change .

ea is integral component of it investment management process .

organization head has approved current version of ea .

return on ea investment is measured and reported .

compliance with ea is measured and reported .

stage 2: building the ea management foundation committee or group representing the enterprise is responsible for directing , overseeing , and approving ea .

program office responsible for ea development and maintenance exists .

ea being developed using a framework , methodology , and automated tool .

ea plans call for describing “as - is” environment , “to - be” environment , and sequencing plan .

ea plans call for describing enterprise in terms of business , performance , information / data , applications / service , and technology .

ea plans call for business , performance , information / data , applications / service , and technology to address security .

ea plans call for developing metrics to measure ea progress , quality , compliance , and return on investment .

no stage 3: developing architecture products written and approved policy exists for ea development .

ea products are under configuration management .

ea products describe or will describe “as - is” environment , “to - be” environment , and sequencing plan .

both “as - is” and “to - be” environments are described or will be described in terms given in stage 2 .

these descriptions address or will address security .

progress against ea plans is measured and reported .

stage 4: completing architecture products written and approved policy exists for ea maintenance .

ea products and management processes undergo independent verification and validation .

ea products describe “as - is” environment , “to - be” environment , and sequencing plan .

both “as - is” and “to - be” environments are described in terms given in stage 2 .

organization cio has approved current version of ea .

committee or group representing the enterprise or the investment review board has approved current version of ea .

quality of ea products is measured and reported .

stage 5: leveraging the architecture to manage change written and approved organization policy exists for it investment compliance with ea .

process exists to formally manage ea change .

ea is integral component of it investment management process .

organization head has approved current version of ea .

return on ea investment is measured and reported .

compliance with ea is measured and reported .

in addition to the contact named above , tonia johnson ( assistant director ) , timothy eagle , elena epps , michael holland , neela lakhmani , rebecca lapaze , anh le , and freda paintsil made key contributions to this report .

