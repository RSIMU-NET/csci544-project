in 2011 , the army began a major undertaking to modernize its tactical network — at an estimated cost of about $3 billion per year indefinitely — to improve communication and other capabilities and to provide needed information to soldiers and commanders on the battlefield .

the army has identified this network as its number one modernization priority .

for nearly 20 years , the army has had limited success in developing its information network of sensors , software , and radios to give soldiers and commanders exact information when they need it , in any environment , and thus improve situational awareness and decision making in combat .

to achieve this goal , the army is implementing a new agile process , which would take advantage of emerging networking solutions to keep better pace with technology development and deploy selected systems to the field much faster than previously possible .

one key component of this process is the network integration evaluations ( nie ) , which are assessments of newly developed systems held twice a year .

the systems are included in brigade level military exercises , which help army senior leaders decide whether the army should field new systems .

capability gaps are identified unfulfilled capability needs .

new systems in an environment that models actual battle , resulting in recommendations by soldier and system evaluators on whether to field , continue to develop , or discontinue evaluation of these systems .

because of the network's importance , the ambitious nature of the current network modernization strategy , and the department's history with system acquisitions over the past decade , you asked us to examine elements of the new process the army is using to acquire network capabilities .

we will address issues related to the nie process , evaluation of new and current network capabilities , and current plans for major network acquisition programs in phases .

in our first report , we addressed issues related to the army's agile process .

in this report , we examine the army's nies , a key enabler of the agile process .

specifically , we evaluated ( 1 ) the results of the nies conducted to date and to what extent the army has procured and fielded proposed network solutions ; and ( 2 ) army actions and additional opportunities to enhance the nie process .

to conduct this work , we used dod policies and acquisition best practices as a guide as we evaluated the army's approach to the nies and their contributions to modernizing its tactical network .

we observed testing , visited laboratory facilities , interviewed acquisition and test officials , and analyzed key documentation .

a detailed description of our scope and methodology is included in appendix i .

we conducted this performance audit from september 2012 to august 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

as the army transitions away from major wartime operations , it faces fiscal constraints and a complex and growing array of security challenges .

the army will be smaller and senior leaders recognize that the core of a smaller yet still highly capable force is having a capable tactical information network .

over the last decade , the army focused most of its decisions to field network improvements on supporting operations in iraq and afghanistan , an effort that was both expensive and time consuming .

the army did not synchronize the development and fielding efforts for network technologies .

funding and time lines for network - related programs were rarely , if ever , aligned .

the army fielded capabilities in a piecemeal fashion and the user in the field was largely responsible for integrating them with existing technology .

in december 2011 , army leaders finalized the network - enabled mission command initial capabilities document , a central document that describes the essential network capabilities required by the army as well as scores of capability gaps .

these capabilities support an army mission command capability defined by a network of command posts , aerial and ground platforms , manned and unmanned sensors , and dismounted soldiers linked by an integrated suite of mission command systems .

a robust transport layer capable of delivering voice , data , imagery , and video to the tactical edge ( i.e. , the forward battle lines ) connects these systems .

to achieve the objectives of its network modernization strategy , the army is changing the way it develops , evaluates , tests , and delivers networked capability to its operating forces , using an approach called capability set management .

a capability set is a suite of network components , associated equipment , and software that provides an integrated network capability .

a requirement is an established need justifying the allocation of resources to achieve a capability to accomplish military objectives .

instead of developing an ultimate capability and buying enough to cover the entire force , the army plans to buy only what is currently available , feasible , and needed for units preparing to deploy .

every year , the army will integrate another capability set that reflects changes or advances in technology since the previous set .

to support this approach , the army is implementing a new agile process that identifies capability gaps and solicits solutions from industry and government to evaluate during the nies .

nies are a significant investment .

since 2011 , the army has conducted five of them , and has projected the cumulative cost of the events at $791 million .

the army conducts nies twice a year .

each nie typically involves around 3,800 soldiers and 1,000 vehicles , and up to 12,000 square kilometers of territory , and approximately 6 weeks in duration .

the two categories of the key participating systems during the nies are systems under test ( sut ) and systems under evaluation ( sue ) , and each is subject to differing levels of scrutiny .

suts are from an ongoing acquisition program ( sometimes referred to as a program of record ) that are formally determined to be ready for operational testing in order to inform an acquisition decision .

this operational testing is subject to review and is conducted with the production or production - like system in realistic operational environments , with users that are representative of those expected to operate , maintain , and support the system when fielded or deployed .

sues are provided by either industry or the government .

they are either ( 1 ) developing capabilities with sufficient technology , integration , and manufacturing maturity levels to warrant nie participation ; or ( 2 ) emerging capabilities that are seen as next generation war - fighting technologies that have the potential to fill a known gap or improve current capabilities .

sues are not subject to formal test readiness reviews , nor the same level of testing as the suts .

sues are operationally demonstrated and receive a qualitative user evaluation , but are not operationally tested and are not the subject of a formal test report ( as suts are ) .

aside from their role in the agile process , nies also provide the army with opportunities for integration , training , and evaluation that leads to doctrine , organization , training , materiel , leadership and education , personnel , and facilities recommendations ; and the refinement of tactics , techniques , and procedures related to the systems tested .

the army believes that traditional test and evaluation processes frequently result in fielding outdated technologies and expects to improve on those processes through the nies .

the army's test community members , including the brigade modernization command ( bmc ) and the army test and evaluation command ( atec ) , conduct the testing during the nies .

the bmc is a headquarters organization within the training and doctrine command .

it has an attached operational 3,800-soldier brigade combat team dedicated to testing during the nies .

bmc soldiers use systems during the nie in simulated combat scenarios for testing and evaluation purposes , resulting in qualitative evaluations based on their observations .

the bmc also recommends whether to field , continue developing , or stop developing each solution and to improve the integration of capabilities into deploying brigades .

atec has overall responsibility for the planning , conduct , and evaluation of all army developmental and operational testing .

atec also produces a qualitative assessment of the overall performance of the current capability set of network equipment .

two test offices within the office of the secretary of defense that help inform defense acquisition executive decisions also provide oversight on testing related to major defense acquisition programs .

the director , operational test and evaluation ( dot&e ) provides oversight of operational testing and evaluation for suts .

the deputy assistant secretary of defense for developmental test and evaluation ( dt&e ) provides oversight of developmental testing that precedes operational testing of suts .

dot&e and dt&e roles are limited to the suts selected for operational testing during the nies .

test and evaluation is a fundamental aspect of defense acquisition .

dod , under its defense acquisition system , requires the integration of test and evaluation throughout the defense acquisition process to provide essential information to decision makers ; assess attainment of technical performance parameters ; and determine whether systems are operationally effective , suitable , survivable , and safe for intended use .

testers generally characterize test and evaluation activities as either developmental or operational .

developmental testing is a generic term encompassing modeling and simulation and engineering type tests that are used to verify that design risks are minimized , that safety of the system is certified , that achievement of system technical performance is substantiated , and that readiness for operational test and evaluation is certified .

the intent of developmental testing is to demonstrate the maturity of a design and to discover and fix design and performance problems before a system enters production .

operational testing is a field test of a system or item under realistic operational conditions with users who represent those expected to operate and maintain the system when it is fielded or deployed .

specific operational tests include limited user tests , initial operational tests , and customer tests .

before operational tests occur for major acquisition programs , dt&e completes an independent assessment of operational test readiness .

each assessment of operational test readiness considers the risks associated with the system's ability to meet operational suitability and effectiveness goals .

this assessment is based on capabilities demonstrated in developmental testing .

the defense or component acquisition executive considers the results of the assessment of operational test readiness , among other inputs , in making decisions on a major acquisition program proceeding to operational testing .

the army has made steady improvements in the nie process since its inception and the evaluations continue to give the army useful information and helpful insights into current and emerging networking capabilities .

however , some resulting army decisions are at odds with knowledge produced during the nies .

most importantly , despite poor operational test results for a number of suts during the nies , the army has sought approval to buy additional quantities and field several major networking systems .

while many of the sues received favorable reviews , the army lacked a strategy that addresses a number of procurement barriers — such as funding availability and requirements — when it began the nie process , which precluded rapid procurement of successful sues .

additionally , as we reported previously , the army has not yet tapped into the potential to use the nie to gain insight into the effectiveness and performance of the overall tactical network .

to date , the army has conducted five nies , costing an average of $158 million to plan and execute .

through those five nies , the army has operationally tested 19 suts and evaluated over 120 sues .

nies have helped the army in a number of ways .

the nies allowed the army to formulate a network architecture baseline that will serve as the foundation upon which the army plans to add networking capabilities in the future ; evaluate industry - developed systems that may help address army - identified capability gaps in the future ; integrate the new capability sets into operational units and to create new tactics , techniques , and procedures for using the new systems in operations ; and provide soldiers with an opportunity to both provide input into the designs of networking systems and to integrate the systems before the army fields them to operational brigades .

according to army officials , testing during each nie generates a large volume of potentially useful information .

there are detailed operational test and evaluation reports for each of the suts , user evaluations for each of the sues , an integrated network assessment of the current capability set , and general observations on the nie event itself .

the dot&e has reported observations of the nies in its fiscal years 2011 and 2012 annual reports , including an overall assessment , operational scenarios and test design , threat information operations , and logistics .

according to dot&e , the intended nie objective to test and evaluate network components together in a combined event is sound , as is the opportunity to reduce overall test and evaluation costs by combining test events .

nies also offer the opportunity for a more comprehensive evaluation of a mission command network instead of piecemeal evaluation of individual network components .

in addition , the dot&e generally reported overall improvements in the execution of the nies , realistic and well - designed operational scenarios , and improvements in threat information operations .

atec , in addition to preparing operational test reports for specific systems , also prepares an integrated network assessment after each nie .

the reports attempt to characterize how well the current capability set performed with respect to several essential capabilities the army needs for improved mission command .

based on the performance characterizations presented in the available reports for all nies , it appears the army is making progress in improving its networking capabilities .

for instance , the integrated network assessments for nies 12.2 and 13.1 cited improvements in an essential capability called network operations .

these reports also showed improvements in the common operating picture , which is a capability that enables the receipt and dissemination of essential information to higher echelon command posts .

as the army has modified the reports to improve how they present both capability set performance and essential capabilities , the reports have become tools that are more useful for decision makers .

four suts that the army plans to buy and field as part of capability set 13 — warfighter information network - tactical ( win - t ) increment 2 , joint tactical radio system manpack radio , joint tactical radio system rifleman radio , and nett warrior — have demonstrated continued poor performance and / or reliability in both developmental tests before nies and operational tests during the nies .

according to the dot&e , system development best practices dictate that a system should not proceed to operational testing until it has completed developmental testing and corrected any identified problems .

to address these problems , the army has taken steps to implement design changes and schedule additional testing to verify performance after it has implemented those changes .

however , in doing so , the army faces the risk of making system design changes during the production phase or fielding systems with less than required performance or reliability .

two of these suts performed poorly during developmental testing .

developmental testers , through their assessment of operational test readiness reports , recommended that the manpack radio and the rifleman radio not proceed into operational testing .

despite these recommendations , the army proceeded with initial operational testing for these systems during nies while reclassifying the participation of other systems as either limited user tests or customer tests .

the outcomes were predictably poor , according to dot&e .

see table 1 for operational test results from atec and dot&e reports .

in its 2012 annual report , dot&e pointed out that proceeding to operational testing only confirmed the deficiencies identified in developmental testing .

for example , the win - t increment 2 system's reliability was troublesome enough in a limited user test to warrant a reduction in the reliability requirement .

however , win - t increment 2 was unable to meet the reduced requirement .

the rifleman radio also demonstrated poor reliability during developmental testing in 2011 and even worse reliability in operational testing due to the enhanced stress of an operational environment .

the dot&e stated in its 2012 annual report that , according to system development best practices , the army should not proceed to an initial operational test and evaluation with a system until it has completed developmental testing and the program has corrected any identified problems .

otherwise , the army may conduct costly operational tests that simply confirm developmental testing conclusions about poor system performance and reliability rather than taking action to fix system shortfalls .

further , dot&e's 2012 annual report was critical of the army's nie schedule - driven approach , which elevates meeting a schedule above adequately preparing a system to achieve success in operational testing .

an event - driven approach , conversely , would allow systems to participate in a test event after the systems have satisfied certain criteria .

under the army's schedule - driven approach , the nies are held twice a year and suts must align their operational testing to coincide with the next available nie .

an event driven - approach — versus a schedule - driven approach — is the preferred method of test scheduling .

using a schedule - driven approach can result in fielding systems that do not provide adequate utility for soldiers and require costly and time - consuming modification in theater .

in light of poor operational test results during previous nies , the army now must pay for and conduct additional , unanticipated , tests to improve system performance and reliability .

the extent to which the additional tests corrected all of the identified problems is unknown at this time as the army awaits the results of the operational testing conducted at the most recent nie .

ideally , the army would demonstrate greater levels of operational effectiveness and suitability prior to making production and fielding decisions .

both gao and dot&e have acknowledged the risks of proceeding through testing , and to procurement , with systems that perform poorly .

such systems often require design changes that frequently happen when systems are already in production , which can be more costly and technically challenging .

table 2 summarizes the additional activities required of selected systems .

in addition to the unplanned testing summarized in table 2 above , several systems have operational test and evaluation events scheduled .

see table 3 .

despite the poor test results and unplanned activities intended to improve sut performance , the army has begun fielding suts for capability set 13 , including win - t increment 2 , joint tactical radio system ( jtrs ) manpack radio , rifleman radio , and nett warrior .

without disputing the test findings and their implications , army leadership indicates that this equipment addresses critical capability shortfalls and operational needs by providing some level of capability that is otherwise unavailable .

for example , most deployed units previously had no or very limited capabilities other than voice communications .

consequently , the army believes it is urgent to modernize deploying units as quickly as possible , with the equipment in capability set 13 .

the army's approach carries risk .

dot&e has indicated that the principal way of operating a less reliable system is to invest more in recurring maintenance , which will enable the system to function , but will add to the program's life - cycle costs and increase its logistical support needs .

as a result , the army will likely have to work with a system that is less reliable than originally envisioned , and develop a new life - cycle cost estimate that reflects the added costs associated with the increased contractor support to keep this less reliable system operating .

in addition , atec officials state that the negative impact of an individual system falling short of its reliability target is magnified in the capability set .

this approach can result in fielded systems that do not provide adequate utility for soldiers and require costly and time - consuming modification in theater as well as additional testing .

our past work as well as reports from dot&e and dt&e have all found benefits from adequate developmental testing prior to fielding to prove system performance .

since the first nie in 2011 , the army has evaluated more than 120 sues from both industry and government , many of which have received positive reviews and recommendations for fielding from the soldiers .

however , the army has been unable to buy many of these systems because it did not have a strategy in place to rapidly buy promising technologies .

army officials explained that existing dod acquisition processes would not allow the army to quickly acquire sues that could immediately address networking capability gaps .

even so , army officials did not develop alternative acquisition approaches before they began the nie process .

it is unclear how long industry will continue to participate in the nies if the army is unable to begin buying systems .

as discussed later in this report , the army has now developed new approaches to address barriers to its ability to quickly buy and field sues that have successful demonstrations during the nies .

many sues have received positive reviews from soldiers at the nies — about five out of every six sues were recommended for fielding , field and continue development , or potential for follow - on assessment .

table 4 shows the range of soldiers' recommendations .

to date , the army has decided to buy only three sues — a company command post , which is a collection of capabilities that enhances a company commanders' ability to plan , execute , and monitor operations ; a touch screen - based mission command planning tool ; and an antenna mast .

the army will field only one of these systems in capability set 13 — the company command post .

while army officials tell us they would like to buy more systems , a number of factors — such as available funds , deployment schedules , system maturity , and requirements — determine which systems they can buy and when they can buy them .

because it did not have a strategy during the nies to address these factors , the army has been limited in its ability to buy successfully demonstrated sues .

the army expects industry participants to fund fully their own involvement and initial participation in the process and nies , which can be a costly endeavor .

army officials have said it can cost up to $250,000 for an interested contractor to provide a whitepaper for consideration .

these whitepapers , which interested contractors submit to the army in response to a sources sought notice , are the industry contractor's first opportunity to explain both their system and how it addresses a particular capability gap .

the army releases a sources sought notice to industry to solicit candidate commercial solutions for network / non - network capability gaps and the notice informs potential responders of evaluation criteria and subsequent nie participation criteria .

participation in later phases of the agile process , and ultimately the participation in a nie can cost the contractor an estimated million dollars , depending on the system the army is evaluating .

because of the limited number of successfully demonstrated sues that the army has purchased to date , and the cost associated with industry participation , there is concern that industry may lose interest .

this could be especially problematic for the army's agile process which , according to the army , is heavily dependent on industry participation for success .

army officials remain confident in the continued support of industry , but the depth and longevity of this support is unclear at this time .

while the nies are a good source of knowledge for the tactical network as a whole , the army has not yet tapped into that potential .

in january 2013 , we reported the army had not yet set up testing and associated metrics to determine how network performance has improved over time,which limited the evaluation of the cost - effectiveness of its network investments .

after completing each nie , atec has provided an integrated network assessment of how well the current capability set enables the execution of the mission command essential capabilities .

this qualitative assessment includes only the impact of the current capability set — and not the entire network — on the essential capabilities and does not attempt to evaluate the cost - effectiveness of the current capability set .

the army and dod consider the fielding of capability set 13 as the initial output from the army's network modernization portfolio , but the army has yet to define fully outcome - based performance measures to evaluate the actual contributions of the capability set .

establishing outcome - based performance measures will allow the army and dod to assess progress of network development and fielding and be in a position to determine the cost - effectiveness of their investments in capability set 13 .

we recommended that , among other things , the secretary of defense direct the secretary of the army to define an appropriate set of quantifiable outcome - based performance measures to evaluate the actual contributions of capability set 13 and future components under the network portfolio .

as discussed later in this report , dod has started to develop metrics in response to our earlier recommendation .

the army is taking action to correct inefficiencies and other issues based on lessons learned from previous nies .

the army is also planning to address potential barriers to rapid procurement of successful sues , and dod has started the process to implement our earlier recommendations on network metrics .

many of the initiatives are in the early stages of implementation so outcomes are not certain .

the army also has an opportunity to work more closely with the test community to further improve nie execution and results .

the army has identified inefficiencies or less - than - optimal results in its network modernization and the nie process and has begun implementing corrective actions to mitigate some of them .

table 5 shows some of the major issues identified by the army and the corrective actions , which are in early stages of implementation .

the army's lab - based risk reduction , currently under way , seeks to address concerns over too many immature sues sent to past nies .

through this initiative , the army performs technology evaluations , assessments , and integration of vendor systems .

officials test systems individually and as part of an integrated network so that problems can be identified before proceeding to an nie .

in some cases , army officials identify changes for these systems to increase the likelihood of their success during an nie , while it drops others when they do not perform well enough in lab testing .

since this effort began , the army has reduced the number of systems it evaluates during the nies , indicating the army may be making soldiers' nie workloads more manageable .

while army officials acknowledge that lab - based risk reduction does not eliminate all risks , this early evaluation of new systems seems to address some concerns .

it may reduce the number of immature systems in the nie , which could help the army train soldiers for the new systems .

sending only mature sues that have gone through integration testing to nies could also help avoid certain test costs .

additionally , to reduce costs , improve the results of nies , and better support rapid fielding of new network capabilities , the test community has reported on several issues requiring corrective action by the army .

additionally , the testers have also taken actions to help reduce redundancies in test data collection processes , among other things .

implementation of these corrective actions , which testers identified during earlier nies , could help prevent negative impacts to nie testing and modernization .

table 6 describes a number of major issues identified by the test community and corrective actions , which are in early stages of implementation .

most of the corrective actions to address test community concerns are in early stages of implementation .

below are additional details about the status of a few of the key initiatives .

army test officials anticipate avoiding $86 million in nie costs due to implementation of a dozen different efficiency initiatives , including making nies more efficient by eliminating duplicative surveys , consolidating data systems , refining sue test data delivery processes , reducing reliance on contractor data collectors by using military personnel more , and automating data collection .

additionally , bmc officials indicated they intend to incorporate additional testing and reduce the number of soldiers involved in future nies to help reduce testing costs .

over time , as the army conducts nies more efficiently , it plans to reduce the number of test personnel , realize commensurate salary savings , and reduce engineering expenses .

training and guidance for soldiers using new systems during the nie is another area receiving attention from the test community and the army .

army test officials reported that there were gaps in soldier training for the sues to be evaluated in nie 13.1 .

the training issues , in turn , affected the usefulness of the subsequent system evaluations .

dt&e officials also expressed concerns about soldier training , and said problems exist in the rehearsal phase of the nie process .

brigade combat team officials said they have also experienced a lack of training resources as they prepare to deploy overseas .

according to army officials , a lack of complete training information , tactics , techniques , and procedures is hampering soldier training on new network systems .

that experience was somewhat mitigated , however , by help from soldiers who had used these systems during earlier nie events .

it will be important for the army to resolve training issues before operational testers qualify systems as fully suitable for combat use following operational testing .

given that operations and support can often comprise about two - thirds of life - cycle costs , a good understanding of these requirements and costs will be necessary for the army to make well - informed investment decisions for new equipment .

assessing and using lessons learned from experience can help in planning and implementing future activities .

the army's efforts to reduce costs and implement corrective actions may take several years ; therefore , a continued focus on making nie processes more efficient and effective , as well as documenting the results of corrective actions would better support the army's business case for conducting future nies .

the army is developing a two - pronged approach to address barriers to its ability to quickly buy and field sues that have successful demonstrations during the nies .

according to army officials , these barriers included a lack of well - defined requirements for the network system ( instead of the more general capability gaps ) ; a lack of funding ; and lengthy time frames needed to complete the competitive procurement process .

the army found that the processes for translating capability gaps into requirements , identifying specific funding , and completing a competitive procurement can be very time consuming and challenging .

the army is now developing a strategy to address these barriers .

after the nie , if the army decides to buy and field a sue , the army plans to align that capability with a suitable existing requirement within an ongoing program of record .

the selected program manager would then identify buying options for the capability , including the feasibility of using an existing contract , and would determine whether ( 1 ) funding is available , ( 2 ) the army should identify the capability as an unfunded requirement , or ( 3 ) the army needs an above - threshold reprogramming action .

the program manager would also determine if the army can buy and field the capability in the capability set or identify what capability is achievable .

army officials plan to implement this new strategy in the coming months .

in cases where the army cannot align the successful sue with an existing program of record , it could develop a new requirement for the system .

army officials have indicated that in a small number of cases , the army could utilize a directed requirement .

the army generally develops and approves directed requirements to fill urgent needs that the army believes should be fielded as soon as possible .

this allows for essentially bypassing the regular requirements processes , which require additional time to complete .

in addition to this strategy , the army has developed a new nie acquisition plan that features an alternative means to buy successful sues rapidly .

under this new plan , the army is using a combined sources sought notice and a request for proposals approach to better shape requirements and allow for buying sues in less time than under normal acquisition processes .

with two nies per year , the army will continue to use a sources sought notice to solicit government and industry solutions to broadly defined capability gaps and will assess those solutions during a nie .

then , the army will use lessons learned and soldier feedback from the first nie to validate and refine the requirement and issue a request for proposal for participation in a future nie .

using a request for proposal differs from using sources sought notices because the request for proposals approach culminates in the award of indefinite - delivery , indefinite - quantity contracts for industry sues to participate in a future nie .

using an indefinite - delivery , indefinite - quantity contract allows the army to place production orders for industry sues following the nie .

the army released the first request for proposals supporting a nie on december 20 , 2012 , to solicit vehicle tactical routers for nie 14.1 .

vehicle tactical routers would allow users and systems located nearby to access networks securely .

for sues that already have a defined requirement , the army plans to issue a request for proposals for participation in one nie , without using a sources sought notice first .

however , army officials concede that a defined requirement is not usually available prior to the nie .

in those cases , the army plans to continue issuing sources sought notices for industry proposed solutions that the army will evaluate during a nie , as a precursor to issuance of a request for proposals in the future .

the army expects to comply with current dod acquisition policy when it decides to buy systems that proceed through the agile process .

however , the army may propose changes to existing policy and processes that inhibit realization of the full benefits of the agile process .

as the army implements this strategy over the coming months , it will be important to gather information on how well the strategy works and how rapidly the army can procure and field a sue after its successful demonstration during an nie .

at the same time , the army will be in a better position to determine how much of its constrained budget it can devote to the procurement of sues .

as recommended under internal control standards , it will be important for the army to establish specific measures and indicators to monitor its performance and validate the propriety and integrity of those performance measures and indicators.this type of information — on how many sues the army can buy and how rapidly — would be helpful for industry as it makes decisions on its future participation in the nie process .

in our initial report on the army's tactical network , we concluded that it will also be important for the army to assess the cost effectiveness of moreover , to individual initiatives before and during implementation.facilitate oversight , we concluded that it is important for the army and dod to develop metrics to assess the actual contributions of the initial capability set the army will field in fiscal year 2013 and use the results to inform future investments .

according to a key dod oversight official reporting on army networks to the under secretary of defense , acquisition , technology , and logistics , dod has started work to define quantifiable outcome - based performance measures for the army tactical network .

in addition , both dod and army officials indicated they are planning to develop a preferred end - to - end performance projection for the army tactical communications network and intend to quantify the performance needed in terms of voice , data , and so forth , and by network tier , sector , and subnet .

officials plan to define levels of performance for benign and conflict environments and the waveforms and radios soldiers will need for each tier as well as their specific performance characteristics .

although this effort is in its early stages , this dod oversight official stated that it is expected that the nie will generate data on performance of the network as a whole , which could then be compared to the expected performance demand .

separately , the army is also beginning to prepare qualitative assessments of the progress the army is making in filling capability gaps related to mission command essential capabilities .

for example , atec has prepared an integrated network assessment after each nie , which characterizes the level of capability achieved against the mission command essential capabilities .

in addition , the army has prepared a limited assessment of how capability set 13 will meet mission command essential capabilities .

once the performance measures are in place and the army evaluates the delivered capabilities against those measures , the army will have the tools to evaluate the progress it is making and make any necessary adjustments to its investment strategy .

the army's network strategy features a variety of different approaches to testing and evaluation to accommodate the rapid pace of technology change and to reduce the cost and time of acquisition .

the army has worked closely with the test community to plan , conduct , and evaluate the nies .

also , as mentioned earlier , the test community has taken a number of actions to reduce the costs of planning and executing the nies .

at the same time , the test community has been meeting its responsibility to objectively report on the tests and the results .

however , test results for several network systems at the nies that did not meet operational and other requirements will result in added time and expense to address identified issues .

an inherent value of testing is pointing out key performance , reliability , and other issues that need to be addressed as soon and as economically as possible , but not after fielding .

dot&e has stated that the schedule - driven nature of the nies contribute to systems moving to testing before they have met certain criteria .

tension between the acquisition and testing communities has been long - standing .

in that regard , the defense acquisition executive recently chartered an independent team to assess concerns that the test community' approach to testing drives undue requirements , excessive cost , and added schedule into programs and results in a state of tension between program offices and the testing community .

one area the defense acquisition executive assessment identified for improvement was the relationship and interaction among the testing , requirements , and program management communities .

in that regard , the memorandum reporting the results called attention to four specific issues those communities need to address the need for closer coordination and cooperation among the requirements , acquisition , and testing communities ; need for well - defined testable requirements ; alignment of acquisition strategies and test plans ; and need to manage the tension between the communities .

concurrently , a systematic review of recent programs by dot&e and dt&e examined the extent to which testing increases costs and delays programs .

the results of both efforts indicated that testing and test requirements by themselves do not generally cause major program delays or increase costs .

in addition , the defense acquisition executive found no significant evidence that the testing community typically drives unplanned requirements .

further , according to the dot&e fiscal year 2012 annual report , three specific areas exist where increased test community interactions could result in improved test outcomes , which can result in systems with needed and useful combat capability being delivered to our forces more quickly .

these include developing mission - oriented metrics to evaluate each system within the context within which it will operate ; leveraging test and evaluation knowledge in setting requirements ; and evaluating the multiple conditions in which the system is likely to be operated .

additional opportunities exist for leadership of the army and the test community to work together to further improve nie execution and results .

a good starting point would be for the army to consider addressing the test community observations and recommendations from previous nies .

those included the schedule driven nature of nies , the lack of well - defined network requirements , and the lack of realistic battlefield maintenance and logistical support operations for suts during the nies .

the army is not required to and has not directly responded to the test community about its nie observations and recommendations .

nevertheless , per internal control standards , managers are to , among other things , promptly evaluate findings from audits and other reviews , including those showing deficiencies and recommendations reported by auditors and others who evaluate agencies' operations .

in doing so , the army may not only improve nie execution and results but also reduce the tensions with the test community .

within a sizable investment of an estimated $3 billion per year to modernize its tactical network , the army is investing over $150 million per nie to help ensure that those planned development and procurement investments result in the expeditious delivery of increased capabilities to the warfighter .

the main product of the nies is knowledge .

the army has not consistently recognized , accepted , and acted upon the knowledge gained from the nies .

on the one hand , the army's fielding decisions to date seem driven by a pre - determined schedule rather than operational test results .

fielding individual systems that have done poorly during operational tests carries risk of less than optimal performance with the potential of costly fixes after fielding and increased operating and sustainment costs .

moreover , performance and reliability issues of individual systems could be magnified when these systems become part of an integrated network .

on the other hand , even with a new strategy for procurement of emerging capabilities to fill capability gaps , the army may still face an expectation gap with industry .

the current constrained budget environment and the level of funding already allocated to ongoing network acquisition programs , may leave little funding to procure new networking technologies .

until it has clearly demonstrated the means to rapidly buy and field emerging capabilities and provided this information to industry , the army may need to manage industry expectations of how many new networking systems it can buy and how rapidly .

the army has implemented some lessons learned from planning and executing the nies .

however , as part of a knowledge - based approach to its broader network modernization strategy , the army should also be open to consideration of observations from all sources to improve process efficiency and achieve improved outcomes .

we believe that the army can and should collaborate more extensively with the test community on a variety of issues that could improve nie outcomes .

for example , as part of its responsibility to objectively conduct tests and report on their results , the test community has provided reports , observations , and recommendations before and following nies .

to date , the army has not directly responded to the test community's observations and recommendations on the nies .

to improve outcomes for its entire network modernization strategy , we recommend that the secretary of defense direct the secretary of the army to take the following four actions: require that network systems from major defense acquisition programs obtain a positive assessment of operational test readiness ( now called a developmental test and evaluation assessment ) recommendation before being scheduled for operational testing during the nie ; correct network system performance and reliability issues identified during the nies before moving to buy and field these systems ; provide results to industry on the army's actual experience in buying and fielding successfully demonstrated systems under evaluation and the length of time it has taken to date ; and collaborate with all network stakeholder organizations to identify and correct issues that may result in improved network outcomes , including addressing the observations and recommendations of the test community related to the nies .

dod's written response to this draft is reprinted in appendix ii .

dod also provided technical comments that were incorporated as appropriate .

dod partially concurred with our recommendations that the army ( 1 ) require network systems obtain a positive assessment of operational test readiness ( now called a developmental test and evaluation assessment ) recommendation before being scheduled for operational testing during the nie and ( 2 ) correct network system performance and reliability issues identified during the nies before moving to buy and field these systems .

in both cases , dod states that processes are already in place to address these issues and that the recommendations as written take flexibility away from the department .

we disagree .

our findings indicate that dod is not using its current processes effectively to evaluate a system's readiness to begin operational testing .

while there may be instances where the army uses operational testing to obtain feedback on system performance , dod's system development best practices dictate that a system should not proceed to operational testing until it has completed developmental testing and corrected any identified problems .

the nies are a good forum for the army to generate knowledge on its tactical network .

however , nies are a large investment and dod and the army should strive to optimize their return on that investment .

approving network systems for operational testing at the nies after having poor developmental test results may not be the best use of nie resources because of the strong correlation between poor developmental test results and poor operational test results .

moreover , it is much more cost effective to address performance and reliability issues as early as possible in the system development cycle and well in advance of the production and fielding phases .

as we note in the report , dod and the army have been pursuing a schedule - based strategy for network modernization rather than the preferred event - based strategy where participation in a test event occurs after a system has satisfied certain criteria .

dod concurred with our recommendation that the army provide results to industry on how many successfully demonstrated systems under evaluation have been procured to date and how long it has taken for the procurements .

however , dod did not offer specific steps it would take to provide this information or a proposed timeframe .

because of the importance of continued industry participation in the development of the army network , we think that it is important for industry to have a clear picture of the army's success in rapidly buying and fielded emerging technologies .

finally , dod concurred with our recommendation that the army collaborate with all network stakeholder organizations to identify and correct issues that may result in improved network outcomes , including addressing the observations and recommendations of the test community related to the nies .

dod states that a collaborative environment with all stakeholders will assist in identifying and correcting issues and that the forum for doing so is the semiannual network synchronization working group .

we agree that a collaborative environment is important in responding to previous test community observations and recommendations and would expect the working group to address these issues .

we are sending copies of this report to the appropriate congressional committees , the secretary of defense , the secretary of the army , and other interested parties .

in addition , the report will be available at no charge on gao's website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact belva martin at ( 202 ) 512-4841 or martinb@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix iii .

our objectives were to evaluate ( 1 ) the results of the network integration evaluations ( nie ) conducted to date and identify the extent to which the army has procured and fielded proposed network solutions ; and ( 2 ) army actions and additional opportunities to enhance the nie process .

to address these objectives , we interviewed officials from the army's system of systems integration directorate ; the deputy chiefs of staff , g - 3 / 5 / 7 and g - 8 ; the army brigade modernization command , and the army test and evaluation command .

we met with representatives of army brigade combat teams preparing for deployment .

we also interviewed officials from the deputy assistant secretary of defense for developmental test and evaluation ; the director , operational test and evaluation ; and the office of the under secretary of defense for acquisition , technology , and logistics .

we visited the lab based risk reduction facility at aberdeen proving ground , maryland and the nie test site at white sands missile range , new mexico to meet with soldiers and civilian officials conducting testing .

to examine the results of nies conducted to date , we attended network integration evaluations and reviewed test reports from the brigade modernization command , u.s. army test and evaluation command , the director of operational test and evaluation , and the deputy assistant secretary of defense for developmental test and evaluation .

we reviewed briefing presentations for army leadership that discuss test results and recommendations , and we toured lab facilities to understand how the army is validating and selecting technologies for network evaluations .

we reviewed army programmatic and budget documentation to understand cost projections for testing and procuring network equipment under the new approach and we reviewed army plans for resourcing this approach .

to identify actions and opportunities to enhance the nie process , we interviewed army officials to identify other networking challenges the army is addressing concurrent with implementation of the agile process .

we reviewed test results from both the army and department of defense .

we reviewed army documentation identifying cost avoidance opportunities .

we reviewed briefing information regarding lessons learned from activities related to the nie , such as the screening and lab testing of candidate systems and soldier training .

we spoke with officials at both army and department of defense knowledgeable of lessons learned for the testing and fielding of new network capabilities .

we conducted this performance audit from september 2012 to august 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact named above , william r. graveline , assistant director ; william c. allbritton ; marcus c. ferguson ; kristine hassinger ; sean seales ; robert s. swierczek ; and paul williams made key contributions to this report .

