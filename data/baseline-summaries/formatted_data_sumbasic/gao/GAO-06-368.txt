dod's planned investment in research , development , and procurement of major weapon systems will total approximately $1.3 trillion between 2005 and 2009 , with over $800 billion of that investment yet to be made .

dod is facing a significant number of problems in managing its acquisitions .

military operations in afghanistan and iraq are consuming a large share of dod resources and causing the department to invest more money sooner than expected to replace or fix existing weapons .

meanwhile , dod is intent on transforming military operations while pursuing multiple megasystems that are expected to be the most expensive and complex ever .

these costly conditions coupled with increases in spending for other national priorities , such as health care and social security , make it essential that dod effectively leverage its investments , particularly in weapon system acquisitions .

if dod manages its current portfolio of weapons within traditional margins of error , the financial consequences could be dire .

dod's strategy for acquiring major weapon systems has traditionally been to plan programs that would achieve a big leap forward in capability within a single development program , a strategy that often results in major cost and schedule problems .

we have assessed weapon acquisitions as a high - risk area for 15 years , and although u.s. weapons are among the best in the world , the programs to acquire them have continued to produce poor cost and schedule outcomes .

however , the current defense acquisition environment continues to be characterized by cost and schedule growth , a lack of confidence by congressional and dod leaders , and no appreciable improvement in the defense acquisition system .

dod knows what to do to achieve better outcomes .

it has written into policy an approach that advocates that adequate knowledge be attained at critical junctures before dod managers agree to invest more money in the next phase of weapon system development .

the policy also emphasizes evolutionary principles for acquiring weapons rather than trying to achieve a big leap forward in capability within a single development program .

we have reported in the past that dod's revised policy does not incorporate adequate controls to ensure the effective implementation of a knowledge - based , evolutionary acquisition process .

however , dod believes that the policy includes the necessary controls to achieve effective outcomes .

you requested that we evaluate dod's compliance with and implementation of its revised acquisition policy intended to produce better cost , schedule , and performance outcomes for major acquisition programs .

in order to obtain an early assessment of the cost and schedule impact of the revised policy , and to assess dod's effectiveness in implementing a knowledge - based , evolutionary acquisition approach we assessed ( 1 ) the cost and schedule status of major weapons development programs initiated under the revised policy , ( 2 ) whether the policy's knowledge - based , evolutionary acquisition principles are being effectively implemented , and ( 3 ) whether effective controls and specific criteria are in place and being used to make sound investment decisions .

in conducting our evaluation , we reviewed pertinent acquisition statutes , policies , and guidance ; analyzed development cost and schedule data for 23 major acquisition programs approved to start system development under dod's revised acquisition policy between october 2000 and december 2004 ; conducted case study reviews of nine of those 23 programs ; and interviewed officials from the office of secretary of defense and each of the military services .

we conducted our review from may 2005 to february 2006 in accordance with generally accepted government auditing standards .

additional information about our methodology is contained in appendix i .

historically , dod's programs for acquiring major weapon systems have taken longer , cost more , and often delivered fewer quantities and other capabilities than planned .

gao has documented these problems for decades .

in 1970 , gao reported that considerable cost growth had been and was continuing to occur on many current development programs .

since that report was issued , numerous changes have been made to dod's acquisition process and environment to try to improve acquisition outcomes .

those changes include numerous executive branch initiatives and legislative actions as well as roughly 11 revisions to dod's acquisition policy between 1971 and 2005 .

despite these efforts , defense acquisition programs in the past 3 decades continued to routinely experience cost overruns , schedule slips , and performance shortfalls .

figure 1 illustrates the continued problem of development cost overruns .

the figure depicts the combined cost overruns for large development programs ( programs totaling more than $1 billion for research , development , testing and evaluation in fiscal year 2005 dollars ) in each of the past 3 decades .

the figure also identifies some of the major studies and improvement efforts initiated during this time frame .

as the figure illustrates , efforts to improve acquisition outcomes have not been successful in curbing acquisition cost problems .

programs initiated in the 1970s exceeded dod's initial investment estimate by 30 percent , or $13 billion ( in fiscal year 2005 dollars ) , and similar outcomes continued during the subsequent decades despite numerous reform efforts and policy revisions .

since the mid - 1990s , we have studied the best practices of leading commercial companies .

taking into account the differences between commercial product development and weapons acquisitions , we articulated a best practices product development model that relies on increasing knowledge when developing new products , separating technology development from product development , and following an evolutionary or incremental product development approach .

this knowledge - based approach requires developers to make investment decisions on the basis of specific , measurable levels of knowledge at critical junctures before investing more money and before advancing to the next phase of acquisition .

an evolutionary product development process defines the individual increments on the basis of mature technologies and a feasible design that are matched with firm requirements .

each increment should be managed as a separate and distinct acquisition effort with its own cost , schedule and performance baseline .

an increment that excludes one of these key elements puts an extra burden on decision makers and provides a weak foundation for making development cost and schedule estimates .

the knowledge - based , evolutionary approach in our model is intended to help reduce development risks and to achieve better program outcomes on a more consistent basis .

hoping to improve acquisition outcomes , dod leaders initiated significant revisions to the department's acquisition policy again in october 2000 , by adopting the knowledge - based , evolutionary system development approach .

we reported in november 2003 , that much of the revised policy agrees with gao's extensive body of work and that of successful commercial firms .

dod's revised policy emphasizes the importance of and provides a good framework for capturing knowledge about critical technologies , product design , and manufacturing processes .

if properly implemented and enforced this approach could help dod's decision makers gain the confidence they need to make significant and sound investment decisions for major weapon systems .

furthermore , the policy's emphasis on evolutionary system development sets up a more manageable environment for achieving knowledge .

we also noted that dod's policy strongly suggests the separation of technology development from system development , a best practice that helps reduce technological risk at the start of a program and makes cost and delivery estimates much more predictable .

figure 2 depicts in general how dod's revised policy adopts key aspects of the best practices model .

although dod took significant steps in the right direction , its policy does not include controls that require program officials to meet the key criteria that we believe are necessary for ensuring that acceptable levels of knowledge are actually captured before making additional significant investments .

we previously recommended that dod design and implement necessary controls to ensure that appropriate knowledge is captured and used to make decisions about moving a program forward and investing more money at critical junctures .

dod officials acknowledged the advantages of using knowledge - based controls , but stated that they believed the policy already included enough controls to achieve effective program results .

the officials agreed to monitor the acquisition process to assess the effectiveness of those controls and to determine whether additional ones are necessary .

the cost and schedule outcomes being achieved by development programs initiated since dod first issued its revised policy have not improved over those achieved by programs managed under prior versions of the policy .

of the 23 major programs we assessed , 10 have already reported estimated development cost growth greater than 30 percent or expected delays of at least 1 year in delivery of an initial operational capability to the warfighter .

these programs combined represent a cost increase of $23 billion ( in fiscal year 2005 dollars ) and an average delay in delivery of initial capability of around 2 years .

most of the other programs were still in the early stages as of december 2005 with over half of system development remaining and had not yet reported an adequate amount of cost or schedule data to effectively analyze their progress .

table 1 contains the cost and schedule increases for the 23 programs we assessed , expressed as a percentage of each program's development estimate .

the army's future combat system is a case in point .

less than 3 years after program initiation and with $4.6 billion invested , the army has already increased its development cost estimate $8.9 billion or 48 percent and delayed delivery of initial capability by 4 years over the original business case .

similarly , just over 1 year after initiating development of the aerial common sensor aircraft , the army has reported that severe weight and design problems discovered during development have stopped work on the program .

as a result , program officials are anticipating at least a 45 percent cost increase and a delay of 2 years in delivering an initial capability to the warfighter .

these two army programs are not the only ones experiencing problems .

table 2 contains cost and schedule data for 6 of the 10 largest development programs initiated under the revised policy , including the future combat system and aerial common sensor .

as the table illustrates there are several programs experiencing large cost increases and schedule delays .

a good measure of acquisition performance is return on investment as expressed in acquisition program unit cost because unit cost represents the value dod is getting for its acquisition dollars invested in a certain program .

the programs listed in table 2 will not achieve the return on investment that dod anticipated when they began development .

in the case of joint strike fighter , for example , dod initially intended to purchase 2,866 aircraft at an acquisition program unit cost of about $66 million .

the navy has reduced the number of joint strike fighter aircraft it plans to buy ; technology and design problems encountered during development have led to the significant cost growth .

as a result , the acquisition program unit cost is now about $84 million , an increase of 27 percent .

we recently reported that the risk of even greater increases is likely because flight testing has not yet started and the acquisition strategy involves substantial overlap of development and production .

similar problems have led to increases in the future combat system program .

at program initiation , the army anticipated that each of 15 units would cost about $5.5 billion to develop and deliver .

since that time , instability in the program's technologies and requirements have led to significant cost increases , leading to a 54 percent increase in acquisition program unit cost , now estimated to be $8.5 billion .

regarding all 23 development programs , dod leaders originally planned to invest a total of about $83 billion ( fiscal year 2005 dollars ) for system development and anticipated delivering an initial operational capability to the warfighter in 77 months on average .

however , development costs have grown and delivery schedules have been delayed significantly .

dod now expects to invest over $106 billion in those same programs , an increase of over $23 billion or 28 percent .

the delivery of initial capability to the warfighter is expected to take an average of 88 months or nearly 1 year longer than originally planned .

figure 3 shows changes in these business case elements for these programs in the short time since their initiation .

dod is not effectively implementing the knowledge - based process and evolutionary approach emphasized in its acquisition policy .

while the policy outlines a specific knowledge - based process of concept refinement and technology development to help ensure a sound business case is developed before committing to a new development program , almost 80 percent of the programs we reviewed were permitted to bypass this process .

furthermore , the policy emphasizes the need to mature all critical technologies before starting system development and to demonstrate that the product's design is mature before beginning system demonstration .

however , nearly three - fourths of the programs reported having immature critical technologies when they received approval to start development , and at least half of the programs had not achieved design maturity before holding their design review and gaining approval to enter the system demonstration phase of development .

the policy also emphasizes the use of an evolutionary product development approach , yet program officials continue to structure major acquisition programs to achieve large advances in capability within a single step development program .

this strategy has historically resulted in poor cost and schedule outcomes .

dod decision makers continue to approve programs for system development that have not followed key elements of the policy's suggested knowledge - based process .

the policy requires program managers to provide senior decision makers with knowledge about key aspects of a system at critical investment points in the acquisition process .

our prior reviews have identified those critical points as the start of system development or program start ( referred to as milestone b in the dod acquisition policy ) , design readiness review separating system integration and system demonstration , and production commitment ( milestone c in the dod acquisition policy ) .

the most important point occurs at program start , when system development begins .

dod acquisition guidance emphasizes the importance of the acquisition phases preceding program start , noting that the decisions made during those phases — concept refinement and technology development — generally define the nature of an entire acquisition program .

acquisition officials continue to begin system development without following early processes for developing executable business cases .

a business case should provide demonstrated evidence that ( 1 ) the warfighter's needs are real and necessary and that they can best be met with the chosen concept and ( 2 ) the chosen concept can be developed and produced within existing resources — including technologies , design knowledge , funding , and the time to deliver the product when it is needed .

establishing a business case calls for a realistic assessment of risks and costs ; doing otherwise undermines the intent of the business case and invites failure .

this process requires the user and developer to negotiate whatever trade - offs are needed to achieve a match between the user's requirements and the developer's resources before system development begins .

the revised policy and associated guidance emphasize the importance of following a sound process of systems engineering and decision making prior to initiating a system development program .

the process established in the policy consists of two phases , concept refinement and technology development , and a major decision review called milestone a , which if rigorously followed , would provide acquisition officials with an opportunity to assess whether program officials had the knowledge needed to develop an executable business case .

however , almost 80 percent of the programs we reviewed began system development without holding any prior decision review .

senior officials with the office of the secretary of defense confirmed that this is a common practice among defense acquisition programs .

this practice eliminates a key opportunity for decision makers to assess early product knowledge needed to establish a business case that is based on realistic cost , schedule , and performance expectations .

although program officials conduct analysis before starting a development program , they do not consistently follow a process to capture the critical knowledge needed to produce executable business cases , as evidenced by the poor outcomes current programs are experiencing .

officials with the office of the secretary of defense recognized this lack of rigor and discipline in acquisition process , and in february 2004 , the under secretary of defense ( acquisition , technology and logistics ) issued a department - wide policy memorandum directing acquisition officials to place greater emphasis on systems engineering when planning and managing acquisition programs .

the policy requires programs to develop a systems engineering plan that describes the programs' overall technical approach , including processes , resources , metrics , and applicable performance incentives .

although dod's systems engineering initiative has the potential to improve program performance , officials have found that the preliminary results are mixed .

early analysis shows that implementation is inconsistent while program officials learn to develop and implement systems - engineering plans .

dod decision makers continue to permit programs to enter system development before critical technologies are mature .

our review of technology readiness assessments and acquisition decision memorandums for our nine case study programs found that seven of the nine programs were approved to begin development even though program officials reported levels of knowledge below the criteria suggested in the policy and associated guidance , specifically in the area of technology maturity .

those seven programs are not isolated cases .

as illustrated in figure 4 , 13 of the programs ( nearly three - fourths ) that received approval to enter system development under the revised policy did so with less than 100 percent of their critical technologies mature to the level specified by dod .

only 2 of those programs had more than 75 percent of their technologies mature when they began ( see appendix iii for technology maturity data for each program ) .

even though acquisition policy states that technologies shall be mature before beginning system development , the practice of accepting high levels of technology risk at program start continues to be the norm and not the exception .

an official with office of the secretary of defense responsible for reviewing and validating program assessments of technology maturity informed us that the office generally views immature critical technologies at the beginning of development as an acceptable risk as long as program officials can show that they have a plan to mature the technologies by the time the program reaches its design readiness review , which requires additional investments to move a program from system integration into system demonstration .

therefore , risk management plans are consistently viewed as acceptable substitutes for demonstrated knowledge .

in addition to emphasizing the importance of capturing technology knowledge before starting system development , dod's policy also highlights the importance of demonstrating design maturity before moving from the integration phase of system development into system demonstration and initial manufacturing .

the policy establishes a design readiness review between the two phases to determine whether a product's design is mature and stable and whether the product is ready to move ahead .

while dod's policy does not require programs to demonstrate any specific level of design maturity , our past work has found that a key indicator of design maturity is the completion of 90 percent of the system's engineering drawings .

we found that defense programs that moved forward with lower levels of design maturity , as indicated by drawing completion , encountered costly design changes and parts shortages that , in turn , caused labor inefficiencies , schedule delays , and quality problems .

consequently , those programs required significant increases in resources — time and money — over what was estimated at the point each program entered the system demonstration phase .

we analyzed engineering drawing completion data for 8 programs initiated under the revised policy that have held a design review , and found that more than half of those programs had not completed 90 percent of their design drawings before they received approval to enter the system demonstration phase of development .

we also analyzed drawing - release data for three programs that have not yet held their design review but have projected the number of drawings officials anticipate will be completed when their reviews are held .

based on projections provided by program officials , 2 of those 3 programs are expected to have less than 55 percent of their drawings complete before they seek approval to begin system demonstration and initial manufacturing .

despite the revised policy's guidance that capabilities should be developed and delivered in individually defined and separately managed increments , a majority of major weapon acquisition programs we assessed continue to be structured to achieve revolutionary increases in capability within one development program .

according to the policy , the objective of an evolutionary approach is to balance needs and available capability with resources and put capability into the hands of the user quickly .

the policy states that the success of the strategy depends on consistent and continuous definition of requirements and the maturation of technologies that lead to disciplined development and production of systems that provide increasing capability .

in this approach , requirements that cannot be satisfied within these limits as well as available financial resources must wait for future generations of the product and be managed as separate system development programs with separate milestones , costs , and schedules .

in our case studies of nine acquisition programs initiated under the revised policy , we found only one program — the small diameter bomb — that satisfied all of the criteria of an evolutionary approach .

in five case studies , we found that program officials had claimed that their programs were evolutionary , yet our evidence shows they were not evolutionary in practice ; and in three cases , program officials chose not to use evolutionary acquisition from the outset .

table 3 summarizes our assessment of the nine case studies .

the revised acquisition policy does not contain effective controls that require the demonstration of product knowledge measured against specific criteria to ensure that acquisition officials make disciplined , transparent , and knowledge - based investment decisions .

the lack of specific required criteria creates an environment in which unknowns about technology , design , and manufacturing processes are acceptable .

decision makers and program officials are left with no objective measures against which to gauge a program's level of knowledge , making accountability difficult .

in the absence of criteria , transparency in acquisition decisions is essential to ensuring accountability , but key decision documents do not provide sufficient information about major decisions .

dod believes that acquisition decision memorandums , used to document program decisions , provide adequate transparency .

however , the decision memorandums we reviewed did not contain an explanation of the decision maker's rationale and rarely identify remaining risks , especially as they relate to the key knowledge standards emphasized in the policy .

further , the timeliness , accessibility , and depth , of the data contained in the selected acquisition reports , dod's primary means of providing congress with a status report of program performance , inhibits the reports' usefulness as a management and oversight tool .

in november 2003 , we reported that the revised acquisition policy lacked many of the controls that leading commercial companies rely on to attain an acceptable level of knowledge before making additional significant investments .

controls are considered effective if they are backed by specific criteria and if decision makers are required to consider the resulting data before deciding to advance a program to the next level .

controls used by leading companies help decision makers gauge progress in meeting cost , schedule , and performance goals and hold program managers accountable for capturing relevant product knowledge to inform key investment decisions .

the controls we have articulated as best practices used by successful commercial product developers are listed below in table 5 .

some senior officials with the office of the secretary of defense believe that the effective use of controls in dod's policy and the establishment of more specific criteria for decision making would improve program outcomes .

they note that specific criteria need to be established and that programs need to be held accountable to those criteria before being permitted to proceed into the next phase .

they also note that the criteria for moving an acquisition effort from one phase of the process to the next , primarily documented in acquisition decision memorandums as exit criteria , are not typically specific and often do not relate to the key knowledge - based criteria suggested in the policy .

we found this to be true for our nine case study programs .

we reviewed acquisition decision memorandums in our case studies and determined that they were not useful in explaining the decision maker's rationale and in almost all of the cases they did not address the key knowledge criteria suggested in the acquisition policy .

in most instances , the decision maker simply noted that the program being assessed was ready to proceed into system development , but did not provide an explanation of the rationale for the decision .

senior officials with the office of the secretary of defense told us that they agree that a better explanation of the decision maker's rationale , specifically in instances where the knowledge criteria are not fully met , would provide transparency and ultimately allow for a more accountable decision - making process .

the following two examples illustrate how decision documentation is lacking: the future combat system program received approval to enter system development and demonstration in 2003 , with 19 percent of its critical technologies mature , well below the policy's standard .

the acquisition decision memorandum supporting this decision did not provide the rationale for approving the system with such a large number of immature critical technologies .

the memo did direct an updated review of the decision 18 months later and that the program “remain flexible and open to accommodate trades in the system architecture and in the individual systems' designs.” the joint strike fighter program was approved to enter system development in 2001 .

the acquisition decision memorandum did not address the fact that 75 percent of the program's critical technologies were not mature to the policy's standard .

the memorandum did acknowledge that the program's requirements could be changed or modified , noting that further refinements in the requirements should be explored as a potential way to reduce program costs .

however , the memorandum did not explain why the decision maker determined that the program should enter development without achieving the technology and requirements knowledge emphasized in the policy .

the acquisition decision memorandums for most of the other programs we reviewed did not specifically address critical gaps in knowledge , nor did they effectively explain the decision makers' rationale for deeming those programs ready to begin system development .

in memos where we found a reference to key knowledge principles , such as technology maturity , the decision makers acknowledged that more effort was needed to meet the policy's suggested criteria but considered the risk acceptable to begin development .

these memos did not explain why risks were considered acceptable .

for example , the navy's multi - mission maritime aircraft program had none of its critical technologies mature at program initiation .

the decision maker acknowledged the need to further mature the critical technologies but approved the program to enter development .

instead of holding the program to the policy's criteria for entering development , the decision maker simply directed the navy to work with the office of the secretary of defense to implement risk mitigation and technology maturation plans during the integration phase of system development .

in addition to the lack of transparency provided through acquisition decision memoranda , we also found that the data presented to congress in dod's selected acquisition reports ( sars ) provided only limited usefulness as an oversight tool .

since 1969 , sars have been the primary means by which dod reports the status of major weapon system acquisitions to congress .

sars are reports that are expected to contain information on the cost , schedule , and performance of major weapon systems in comparison with baseline values established at program start , full - scale development , and production decision points .

our analysis , as well as a previous gao review , of current and historical sar data found that the timeliness , accessibility , and depth of the data contained in the reports limits their usefulness as an oversight tool .

our prior review noted that a number of opportunities exist for dod to give congress more complete information on the performance of major defense acquisition programs .

dod agreed that sar data could be improved to make it more useful to congress .

failing to consistently implement the knowledge - based process and evolutionary principles emphasized in the revised acquisition policy — coupled with a lack of specific criteria for making key investment decisions — are keeping dod on its historical path of poor cost and schedule outcomes .

most programs are incurring the same scope of cost overruns and schedule delays as programs managed under prior dod policies .

more consistent use of the early acquisition processes would improve the quality and viability of program business cases by ensuring they are founded on knowledge obtained from rigorous and disciplined analysis .

the initiative by office of the secretary of defense to reinstitute the use of systems engineering is a step in the right direction .

however , in order for this initiative to be effective dod must establish and enforce specific criteria at key decision points .

our past work has identified and recommended criteria and controls that should be consistently applied at major decision points .

the enforcement of these criteria is critical to ensuring that programs have the knowledge necessary to successfully move forward through the acquisition process .

dod officials have acknowledged the advantages of using knowledge - based criteria and controls , but believe the policy already includes enough controls to achieve effective program results .

however , without enforceable criteria , defense officials are challenged to determine whether adequate knowledge has been obtained for investing taxpayer dollars .

the lack of enforceable criteria also makes it difficult to hold defense officials accountable for their decisions .

dod must ensure that appropriate knowledge is captured and used at critical junctures to make decisions about moving a program forward and investing more money .

we recommend that the secretary of defense require program officials to demonstrate that they have captured appropriate knowledge at three key points — program start , design review for transitioning from system integration to system demonstration , and production commitment — as a condition for investing resources .

at a minimum those controls should require program officials to demonstrate that they have achieved a level of knowledge that meets or exceeds the following criteria at each respective decision point: program start ( milestone b ) : start of product development demonstrate technologies to high readiness levels ensure that requirements for the product are informed by the systems - establish cost and schedule estimates for product on the basis of knowledge from preliminary design using system engineering tools conduct decision review for program start design readiness review: beginning of system demonstration complete 90 percent of design drawings complete subsystem and system design reviews demonstrate with prototype that design meets requirements obtain stakeholders' concurrence that drawings are complete and complete the failure modes and effects analysis identify key system characteristics identify critical manufacturing processes establish reliability targets and growth plan on the basis of demonstrated reliability rates of components and subsystems conduct decision review to enter system demonstration production commitment ( milestone c ) : initiation of low - rate production demonstrate manufacturing processes build production - representative prototypes test production - representative prototypes to achieve reliability goal test production - representative prototypes to demonstrate product in collect statistical process control data demonstrate that critical processes are capable and in statistical conduct decision review to begin production furthermore , to ensure that major decisions are transparent and that program officials and decision makers are held accountable , we recommend that the secretary of defense require decision makers to include written rationale for each major decision in acquisition decision documentation .

the rationale should address the key knowledge - based criteria appropriate for milestone decisions , explain why a program's level of knowledge in each area was deemed acceptable if criteria have not been met and provide a plan for achieving the knowledge necessary to meet criteria within a given time frame .

dod provided written comments on a draft of this report .

the comments appear in appendix ii .

dod partially concurred with our recommendation that the secretary of defense should establish specific controls to insure that program officials demonstrate that they have captured a level of knowledge that meets or exceeds specific criteria at three key points in the acquisition process: program start , design readiness review , and production commitment .

dod agreed that knowledge - based decision making is consistent with sound business practice and stated that it would continue to develop policy that reflects a knowledge - based approach and improves acquisition outcomes .

dod noted that it would consider our recommendations as it reassesses the dod acquisition business model and the knowledge required at each decision point .

we believe that dod's plan to reassess its business model provides a good opportunity to establish the controls and specific criteria recommended in this report .

therefore , we are retaining our recommendation that the secretary of defense should establish controls to insure that program officials demonstrate that they have captured a level of knowledge that meets or exceeds specific criteria at three key points in the acquisition process .

dod also partially concurred with our recommendation that the secretary of defense require decision makers to provide written rationale in acquisition decision documentation for each major decision .

dod agreed that acquisition decisions should be documented , decision makers should be held accountable , and that they should provide the rationale for their decisions .

dod believes that the implementation of section 801 of the national defense authorization act for fy 2006 reinforces these processes .

the act calls for the decision maker to certify that the program meets certain requirements , such as technology maturity , prior to starting a new development program at milestone b .

however , the act is focused on the decision to start a development program and does not identify specific criteria for programs to be measured against at design readiness review or production commitment .

we believe our recommendation adds transparency and accountability to the process because it requires the decision maker to provide the rationale for a decision to allow a program to move forward , not only at milestone b but at other key decision points as well .

therefore , we are retaining our recommendation that the secretary of defense require decision makers to provide written rationale for each major decision in acquisition decision documentation .

we are sending copies of this report to the secretary of defense ; the secretaries of the air force , army , and navy ; and the director of the office of management and budget .

we will provide copies to others on request .

this report will also be available at no charge on gao's web site at http: / / www.gao.gov .

if you have any questions about this report or need additional information , please call me at ( 202 ) 512-4841 ( sullivanm@gao.gov ) .

contact points for the offices of congressional relations and public affairs are located on the last page of this report .

key contributors to this report were michael hazard , assistant director ; lily chin ; ryan consaul ; christopher deperro ; travis masters ; and adam vodraska .

to assess the impact of dod's revised acquisition policy , we analyzed cost and schedule data for 23 major defense acquisition programs that were approved to begin system development under the revised policy .

we did not assess space , missile defense , or ship programs .

we collected our data from selected acquisition reports , presidential budget documents , ongoing gao work , and pertinent program officials .

we utilized previous gao reports related to defense acquisition policies and worked with knowledgeable gao staff to ensure the use of current , accurate data .

we also analyzed more than 150 annual selected acquisition reports covering a 36-year period from 1969 to 2005 , to determine historical trends related to outcomes of acquisition policy implementation .

we assessed whether the revised policy's knowledge - based , evolutionary acquisition principles were being effectively implemented by conducting 9 case study reviews and analyzing design maturity data for 11 programs that have made engineering - drawing data available to gao .

our case study programs were the aerial common sensor , multi - platform radar technology insertion program , global hawk unmanned aerial vehicle , small diameter bomb , future combat system , joint strike fighter , expeditionary fighting vehicle , multi - mission maritime aircraft , and the e - 2 advanced hawkeye .

we interacted directly with numerous program officials to seek input on current developments with their programs .

we studied program documents to assess how well programs understand and are implementing the revised acquisition policy .

we also analyzed drawing release data for those programs that have either passed their design review or have provided gao with estimated drawing release data for a future design review to assess design maturity .

in several cases , we asked that program offices verify information in these various documents .

we also reviewed department of defense ( dod ) directive 5000.1 , dod instruction 5000.2 , and the defense acquisition guidebook .

in addition we examined each of the military services' policy directives and guidance , dod memorandums to include policy intent and dod expectations regarding policy implementation as well as joint capabilities integration and development system documents .

we interviewed relevant officials in washington , d.c. , from the office of the director , defense research and engineering , the joint staff , the office of the secretary of defense , and army , navy , and air force acquisition policy staff in order to better understand the content of these documents and the intent of dod's policy .

we conducted our review from may 2005 to february 2006 in accordance with generally accepted government auditing standards .

appendix iii: program data for 23 programs initiated under dod's revised acquisition policy ( as of december 2005 ) .

formal milestone i or milestone a decision review ? .

program office projections .

dod acquisition outcomes: a case for change .

gao - 06-257t .

washington , d.c.: november 15 , 2005 .

defense acquisitions: stronger management practices are needed to improve dod's software - intensive weapon acquisitions .

gao - 04-393 .

washington , d.c.: march 1 , 2004 .

best practices: setting requirements differently could reduce weapon systems' total ownership costs .

gao - 03-57 .

washington , d.c.: february 11 , 2003 best practices: capturing design and manufacturing knowledge early improves acquisition outcomes .

gao - 02-701 .

washington , d.c.: july 15 , 2002 .

defense acquisitions: dod faces challenges in implementing best practices .

gao - 02-469t .

washington , d.c.: february 27 , 2002 .

best practices: better matching of needs and resources will lead to better weapon system outcomes .

gao - 01-288 .

washington , d.c.: march 8 , 2001 .

best practices: a more constructive test approach is key to better weapon system outcomes .

gao / nsiad - 00-199 .

washington , d.c.: july 31 , 2000 .

defense acquisition: employing best practices can shape better weapon system decisions .

gao / t - nsiad - 00-137 .

washington , d.c.: april 26 , 2000 .

best practices: dod training can do more to help weapon system programs implement best practices .

gao / nsiad - 99-206 .

washington , d.c.: august16 , 1999 .

best practices: better management of technology development can improve weapon system outcomes .

gao / nsiad - 99-162 .

washington , d.c.: july 30 , 1999 .

defense acquisitions: best commercial practices can improve program outcomes .

gao / t - nsiad - 99-116 .

washington , d.c.: march 17 , 1999 .

defense acquisition: improved program outcomes are possible .

gao / t - nsiad - 98-123 .

washington , d.c.: march 17 , 1998 .

best practices: dod can help suppliers contribute more to weapon system programs .

gao / nsiad - 98-87 .

washington , d.c.: march 17 , 1998 .

best practices: successful application to weapon acquisition requires changes in dod's environment .

gao / nsiad - 98-56 .

washington , d.c.: february 24 , 1998 .

best practices: commercial quality assurance practices offer improvements for dod .

gao / nsiad - 96-162 .

washington , d.c.: august 26 , 1996 .

