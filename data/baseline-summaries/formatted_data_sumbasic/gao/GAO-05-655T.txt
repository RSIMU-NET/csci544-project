thank you for inviting me to discuss our work related to the efforts of the department of veterans affairs ( va ) to assure the quality and consistency of disability decisions .

assuring the quality and consistency of va's disability decisions is vital for assuring program integrity and equitable decisions .

as you know , in january 2003 , we designated va's disability program , along with other federal disability programs , as high - risk .

in part , we designated va's program as high - risk because of concerns about consistency of decision - making .

despite va's efforts to provide training and enhance communication to improve the consistency of decisions , we found indications of inconsistency such as the wide variation among states in the average compensation payment per veteran .

you asked us to update our 2002 report in which we found that the board needed to improve its quality review program .

specifically , the board needed to revise its sampling methods , the way it weighted quality review results in its calculation of accuracy rates , and the types of errors reported in the accuracy rates .

in that report , we also found that va needed to take action to assure consistency of decision - making within va as a whole .

today i would like to highlight the steps the board has taken since our 2002 report and discuss va's recent efforts to address inconsistent decision - making .

to update our 2002 report , we interviewed officials of and / or obtained pertinent documentation from the board and the veterans benefits administration ( vba ) , which oversees the operations of va's 57 regional offices .

we obtained comments from board officials on the updated information contained in this testimony regarding the board's quality assurance system , and they agreed with this information .

we did our work in accordance with generally accepted government auditing standards in april 2005 .

in summary , we found that the board has taken action to strengthen its system for reviewing the quality of its own decisions , but va still lacks a systematic method for ensuring the consistency of decision - making within va as a whole .

with respect to the board , it has taken steps to improve the sampling and accuracy rate calculation methods of its quality review system and also to assure that serious errors are not obscured by mixing them with less significant deficiencies .

regarding consistency , va still lacks a plan for an ongoing , systematic assessment of decision - making consistency at all levels of adjudication within va. as we concluded in 2002 , such an assessment is needed to provide a foundation for determining acceptable levels of decision - making variation and to reduce variations found to be unacceptable .

although va has much left to do regarding consistency of decision - making , it has begun efforts to understand the reasons behind one indication of inconsistency: the wide variations from state to state in the average compensation payment per veteran .

these efforts include studies being done by va's office of inspector general and vba .

va's disability compensation program pays monthly cash benefits to eligible veterans who have service - connected disabilities resulting from injuries or diseases incurred or aggravated while on active military duty .

the benefit amount is based on the veteran's degree of disability , regardless of employment status or level of earnings .

a veteran starts the claims process by submitting a disability compensation claim to one of the 57 regional offices administered by vba ( see fig .

1 ) .

in the average disability compensation claim , the veteran claims about five disabilities .

for each claimed disability , the regional office adjudicator must develop evidence and determine whether each disability is connected to the veteran's military service .

the adjudicator then applies the medical criteria in va's rating schedule to evaluate the degree of disability caused by each service - connected disability , and then the adjudicator determines the veteran's overall degree of service - connected disability .

if a veteran disagrees with the adjudicator's decision on any of the claimed disabilities , the veteran may file a notice of disagreement .

if the regional office is unable to resolve the disagreement to the veteran's satisfaction , the veteran may appeal to the board .

a veteran can dispute a decision not only if the regional office denies benefits by deciding that an impairment claimed by the veteran is not service - connected .

even for a claimed impairment found to be service - connected , the veteran may dispute the severity rating that the regional office assigns to the impairment and ask for an increase in the rating .

during fiscal years 2003 and 2004 , respectively , the regional offices made about 715 , 000 and 598,500 decisions involving disability compensation claims .

according to vba , during fiscal years 2003 and 2004 , respectively , veterans submitted notices of disagreement in about 13.4 and 14.5 percent of all decisions involving disability ratings , and of the veterans who filed notices of disagreement , about 34.9 and 44.4 percent went on to submit appeals to the board .

assisted by 240 staff attorneys , the board's 52 veterans law judges decide veterans' appeals on behalf of the secretary .

the board has full de novo review authority and gives no deference to the regional office decision being appealed .

the board makes its decisions based on only the law , va's regulations , precedent decisions of the courts , and precedent opinions of va's general counsel .

during the appeals process , the veteran or the veteran's representative may submit new evidence to the board and request a hearing .

in fiscal year 2004 , for all va programs , the board decided about 38,400 appeals , of which about 94 percent ( 35,900 ) were appeals of disability compensation cases that contained an average of 2.2 contested issues per case .

in any given case , the board might grant the requested benefits for one issue but deny benefits for another .

in some instances , the board may find that a case is not ready for a final decision and return ( or remand ) the case to vba for rework , such as obtaining additional evidence and reconsidering the veteran's claim .

if vba still does not grant the requested benefits after obtaining the additional evidence , it returns the case to the board for a final decision .

of the appeals involving compensation cases decided during fiscal year 2004 , the board reported that it granted requested benefits for at least one issue in about 18 percent of the cases , denied all requested benefits in about 23 percent of the cases , and remanded about 58 percent of the cases to vba for rework .

effective february 22 , 2002 , va issued a new regulation to streamline and expedite the appeals process .

previously , the board had remanded all decisions needing rework directly to vba's regional offices .

the new regulation , however , allowed the board to obtain evidence , clarify evidence , cure a procedural defect , or perform almost any other action essential for a proper appellate decision without having to remand the appeal to the regional office .

it also allowed the board to consider additional evidence without having to refer the evidence to the regional office for initial consideration and without having to obtain the appellant's waiver .

according to the board , this change in the process reduced the time required to provide a final decision to the veteran on an appeal , allowed regional offices to use more resources for processing initial claims rather than remands , and virtually eliminated multiple remands on the same case to the regional offices .

however , in may 2003 , the u.s. court of appeals for the federal circuit held that the board could not , except in certain statutorily authorized exceptions , decide appeals in cases in which the board had developed evidence .

as a result , va established a centralized appeals management center within vba in washington , d.c. , to take over evidence development and adjudication work on remands .

if the board denies requested benefits or grants less than the maximum benefit available under the law , veterans may appeal to the u. s. court of appeals for veterans claims , an independent federal court .

unlike the board , the court may not receive new evidence .

it considers only the board's decision ; briefs submitted by the veteran and va ; oral arguments , if any ; and the case record that va considered and that the board had available .

in cases decided on merit ( cases not dismissed on procedural grounds ) , the court may ( 1 ) reverse the board's decision ( grant contested benefits ) , ( 2 ) affirm the board's decision ( deny contested benefits ) or ( 3 ) remand the case back to the board for rework .

of the 3,489 cases decided on merit during fiscal years 2003-2004 , the court reversed or remanded in part or in whole about 88 percent of the cases .

under certain circumstances , a veteran who disagrees with a decision of the court may appeal to the u.s. court of appeals for the federal circuit and then to the supreme court of the united states .

the board of veterans' appeals has taken action to strengthen its internal system for reviewing the quality of its own decisions .

specifically , the board has taken steps to improve its quality review system's sampling methodology and to avoid obscuring serious errors by mixing them with less significant deficiencies .

we found , however , that the board still needs to revise its formula for calculating accuracy rates in order to avoid potentially misleading accuracy rates .

during our 2002 evaluation , we reviewed the board's methods for selecting random samples of board decisions and calculating accuracy rates for its decisions .

we found that the number of decisions reviewed was sufficient to meet the board's goal for statistical precision in estimating its accuracy rate .

however , we pointed out some board practices that might result in misleading accuracy rates .

these practices included not ensuring that decisions made near the end of the fiscal year were sampled and not properly weighting quality review results in the formula used to calculate accuracy rates .

at the time of our 2002 report , the board had agreed in principle to correct these practices .

we found in our most recent work that the board took corrective action in fiscal year 2002 to assure that decisions made near the end of the fiscal year were sampled .

the quality review program now selects every 20th original decision made by the board's veterans law judges and every 10th decision they make on cases remanded by the court to the board for rework .

however , we found that the board had not revised its formula for calculating accuracy rates in order to properly weight the quality review results for original decisions versus the results for decisions on remanded cases .

we determined that , even if this methodological error had been corrected earlier , the accuracy rate reported by the board for fiscal year 2004 ( 93 percent ) would not have been materially different .

however , to avoid the potential for reporting a misleading accuracy rate in the future , corrective action needs to be taken , and the board agreed to correct this issue in the very near future .

in our 2002 evaluation , we also found that the board included nonsubstantive deficiencies ( errors that would not be expected to result in either a remand by the court or a reversal by the court ) in calculating its reported accuracy rates .

we concluded that the reported accuracy rates understated the level of accuracy that would result if the board , like vba , counted only substantive deficiencies in the accuracy rate calculation .

vba had ceased counting nonsubstantive deficiencies in its error rate after the va claims processing task force said in 2001 that mixing serious errors with less significant deficiencies could obscure what is of real concern .

similarly , we recommended that the board's accuracy rates take into account only those deficiencies that would be expected to result in a reversal or a remand by the court .

in fiscal year 2002 , the board implemented our recommendation .

also , during the course of our 2002 evaluation of the quality review program , we brought to the board's attention the governmental internal control standard calling for separation of key duties and the governmental performance audit standard calling for organizational independence for agency employees who review and evaluate program performance .

these issues arose because certain veterans law judges who were directly involved in deciding veterans' appeals were also involved in reviewing the accuracy of such decisions .

the board took corrective actions during our review in may 2002 to resolve these issues so all quality reviews from which accuracy rates are determined are done by persons not directly involved in deciding veterans' appeals .

in 2002 , we also found that the board collected and analyzed issue - specific data on the reasons that the court remanded decisions to the board in order to provide feedback and training to the board's veterans law judges ; however , the board did not collect issue - specific data on the errors that its own quality reviewers found in decisions of the board's veterans law judges .

we recommended that the board revise its quality review program to begin collecting such issue - specific error data in order to identify training that could help improve decision quality .

in april 2005 , the board said it did not implement this recommendation because it believes the benefits would be too limited to justify the substantial reprogramming of the data system that would be required to collect issue - specific data .

the board also pointed out that the issue - specific data captured for court remands have not proved to be as useful as it had expected in identifying ways to provide training that could reduce court remands .

adjudicator judgment is an inherent factor in deciding disability claims , and it introduces the potential for variation in the process .

part of assessing inconsistency , as we recommended in 2002 , would include determining acceptable levels of variation for specific types of disabilities .

in late 2004 , in response to adverse media reports , va initiated its first study of consistency .

such studies are the first step in determining the degree of variation that occurs and what levels of variation are acceptable .

adjudicators often must use judgment in making disability decisions .

judgment is particularly critical when the adjudicator must ( 1 ) assess the credibility of different sources of evidence ; ( 2 ) evaluate how much weight to assign different sources of evidence ; or ( 3 ) assess some disabilities , such as mental disorders , for which the disability standards are not entirely objective and require the use of professional judgment .

in such cases , two adjudicators reviewing the same evidence might make differing judgments on the meaning of the evidence and reach different decisions , neither of which would necessarily be found in error by any of va's quality reviewers .

for example , in an illustration provided by the board , consider a disability claim that has two conflicting medical opinions , one provided by a medical specialist who reviewed the claim file but did not examine the veteran , and a second opinion provided by a medical generalist who reviewed the file and examined the veteran .

one adjudicator could assign more weight to the specialist's opinion , while another could assign more weight to the opinion of the generalist who examined the veteran .

depending on which medical opinion is given more weight , one adjudicator could grant the claim and the other could deny it .

yet , a third adjudicator could apply va's “benefit - of - the - doubt” rule and decide in favor of the veteran .

under this rule , if an adjudicator concludes that there is an approximate balance between the evidence for and the evidence against a veteran's claim , the adjudicator must decide in favor of the veteran .

in the design of their quality review systems , vba and the board acknowledge the fact that , in some cases , different adjudicators reviewing the same evidence can make differing , but reasonable , judgments on the meaning of the evidence .

as a result , vba and the board instruct their quality reviewers that when they review a decision , they are not to record an error merely because they would have made a different decision than the one made by the adjudicator .

vba and the board instruct their quality reviewers to not substitute their own judgment in place of the original adjudicator's judgment if the adjudicator's decision is adequately supported and reasonable .

another example provided by the board demonstrates how adjudicators must make judgments about the degree of severity of a disability .

va's disability criteria provide a formula for rating the severity of a veteran's occupational and social impairment due to a variety of mental disorders .

this formula is a nonquantitative , behaviorally oriented framework for guiding adjudicators in choosing which of the degrees of severity shown in table 1 best describes the claimant's occupational and social impairment .

similarly , va does not have objective criteria for rating the degree to which certain spinal impairments limit a claimant's motion .

the adjudicator must assess the evidence and decide whether the limitation of motion is “slight , moderate , or severe.” to assess the severity of incomplete paralysis , the adjudicator must decide whether the veteran's paralysis is “mild , moderate , or severe.” the decision on which severity classification to assign to a claimant's condition could vary in the minds of different adjudicators , depending on how they weigh the evidence and how they interpret the meaning the of the different severity classifications .

consequently , it would be unreasonable to expect that no decision - making variations would occur .

but it is reasonable to expect the extent of variation to be confined within a range that knowledgeable professionals could agree is reasonable , recognizing that disability criteria are more objective for some disabilities than for others .

for example , if two adjudicators were to review the same claim file for a veteran who has suffered the anatomical loss of both hands , va's disability criteria state unequivocally that the veteran is to be given a 100 percent disability rating .

therefore , no variation would be expected .

however , if two adjudicators were to review the same claim file for a veteran with a mental disability , knowledgeable professionals might agree that it would not be out of the bounds of reasonableness if one adjudicator gave the claimant a 50 percent disability rating and the other adjudicator gave a 70 percent rating .

however , knowledgeable professionals might also agree that it would be clearly outside the bounds of reasonableness if one adjudicator gave the claimant a 30 percent rating and the other , a 100 percent rating .

although the issue of decision - making consistency is not new , va only recently began to study consistency issues .

in a may 2000 testimony before the house subcommittee on oversight and investigations , committee on veterans' affairs , we underscored the conclusion made by the national academy of public administration in 1997 that vba needed to study the consistency of decisions made by different regional offices , identify the degree of subjectivity expected for various medical issues , and then set consistency standards for those issues .

in august 2002 , we drew attention to the fact that there are wide disparities in state - to - state average compensation payments per disabled veteran , and we voiced the concern that such variation raises the question of whether similarly situated veterans who submit claims to different regional offices for similar conditions receive reasonably consistent decisions .

in january 2003 , we reported that concerns about consistency had contributed to gao's designation of the va disability program as high - risk in 2003 .

again , in november 2004 , we highlighted the need for va to develop plans for studying consistency issues .

most recently , in december 2004 , the media drew attention to the wide variations in the average disability compensation payment per veteran in the 50 states and published data showing that the average payments varied from a low of $6,710 in ohio to a high of $10,851 in new mexico .

reacting to these media reports , in december 2004 , the secretary instructed the inspector general to determine why average payments per veteran vary widely from state to state .

as of february 2005 the office of inspector general planned to use data obtained from vba for all regional offices to identify factors that may explain variations among the regional offices .

in march 2005 , vba began a study of three disabilities believed to have potential for inconsistency: hearing loss , post - traumatic stress disorder , and knee conditions .

vba assigned 10 subject matter experts to review 1,750 regional office decisions and plans to complete its analysis of study data in mid - may 2005 , develop a schedule for future studies of specific ratable conditions , and recommend a schedule for periodic follow - up studies of previously studied conditions .

in our 2002 report , we recommended that va establish a system to regularly assess and measure the degree of consistency across all levels of va adjudication , including regional offices and the board , for specific medical conditions that require adjudicators to make difficult judgments .

for example , we said va could create hypothetical claims for certain medical conditions , distribute the claims to multiple adjudicators at each decision - making level , and analyze variations in outcomes .

such a system would identify variation in decision making and provide a basis to identify ways , if considered necessary , to reduce variation through training or clarifying and strengthening regulations , procedures , and policies .

although va agreed in principle with our recommendation and agreed that consistency is an important goal , it commented that it would promote consistency through training and communication .

we support such efforts but still believe va needs to directly evaluate and measure consistency across all levels of adjudication .

otherwise , va cannot determine whether such training and other efforts are directed at the causes of inconsistency and whether such efforts actually improve consistency .

in our november 2004 report , we found that vba's administrative data was insufficient to analyze inconsistency because we could not reliably use the data to identify decisions made after fiscal year 2000 , identify the regional offices that made the original decisions , or determine service - connection denial rates for specific impairments .

however , in october 2004 , vba completed its implementation of a new nationwide data system , known as rating board automation ( rba ) 2000 .

va said this new system could reliably collect the types of data needed to perform the analyses we sought to do .

therefore , we recommended that the secretary of veterans affairs develop a plan , and include it in va's annual performance plan , containing a detailed description of how va intended to use data from the new rba 2000 information system .

we recommended that va conduct systematic studies of the impairments for which rba 2000 data reveal indications of decision - making inconsistencies among regional offices .

va concurred with our recommendation .

because the new rba 2000 data system had been recently implemented , we acknowledged that va could not implement such a plan until it accumulated a sufficiently large body of data under the new system .

in our judgment , at least one year of data would be needed to begin such a study .

while we believe the studies recently begun by the office of inspector general and vba are positive steps forward in addressing consistency issues , the rba 2000 data system , if found to be reliable , can provide va with the data needed to proactively and systematically target specific impairments that have the widest variations in decision - making outcomes among the regional offices and focus va's efforts to study reasons for variations on those impairments .

building in such analytical capability to augment its quality assurance program would help enhance program integrity and better assure that veterans' disability decisions are made fairly and equitably .

mr. chairman , this concludes my remarks .

i would be happy to answer any questions you or the members of the subcommittee may have .

for further information , please contact cynthia a. bascetta at ( 202 ) 512- 7101 .

also contributing to this statement were irene chu , ira spears , martin scire , and tovah rom .

veterans benefits: va needs plan for assessing consistency of decisions .

gao - 05-99 .

washington , d.c.: november 19 , 2004 .

high - risk series: an update .

gao - 03-119 .

washington , d.c.: january 2003 .

veterans' benefits: quality assurance for disability claims and appeals processing can be further improved .

gao - 02-806 .

washington , d.c.: august 16 , 2002 .

ssa and va disability programs: re - examination of disability criteria needed to help ensure program integrity .

gao - 02-597 .

washington , d.c.: august 9 , 2002 .

veterans benefits administration: problems and challenges facing disability claims processing .

gao / t - hehs / aimd - 00-146 .

washington , d.c.: may 18 , 2000 .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

it may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

