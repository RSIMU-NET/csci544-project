in fiscal year 2017 , the federal government awarded $675 billion in grants to state and local governments and $500 billion in contracts .

recipients of these grants and contracts are required to report federal spending and a range of other information to comply with applicable laws and regulations .

grant recipients and federal contractors face challenges related to duplicative and burdensome reporting when complying with these requirements .

using standardized data and processes can reduce federal reporting burden and increase the accuracy of data reported .

the digital accountability and transparency act of 2014 ( data act ) required the office of management and budget ( omb ) and the department of the treasury to establish standardized government - wide financial data standards .

in addition , the data act added section 5 to the federal funding accountability and transparency act of 2006 ( ffata ) , which provided an opportunity for simplifying reporting for federal contracts , awards , and subawards .

toward that end , the act required omb , or a federal agency designated by omb , to establish a pilot program to test potential approaches for reducing reporting burden for federal award recipients – - both grantees and contractors ( procurement ) .

omb was also charged with developing evidence - based recommendations and guidance to federal agencies for eliminating unnecessary duplication in financial reporting , and for reducing compliance costs for federal award recipients based on the pilot findings .

the data act includes a provision for us to review its implementation .

this report assesses the extent to which ( 1 ) the section 5 pilot met the statutory requirements of the act , ( 2 ) the grants portion of the section 5 pilot demonstrated changes in federal award recipients' reporting burden , and ( 3 ) the procurement portion of the section 5 pilot demonstrated changes in federal award recipients' reporting burden .

to address these objectives , we assessed pilot activities by reviewing the requirements for the pilot contained in the data act as well as pilot plans and data from agencies involved in administering and executing the pilot .

these agencies included the department of health and human services ( hhs ) , omb's offices of federal financial management ( offm ) and federal procurement policy ( ofpp ) , and the general services administration ( gsa ) .

we determined that the pilot data we reviewed were reliable for the purposes of our work by reviewing the data , tracing them back to underlying agency source documents , and interviewing relevant agency staff .

we also reviewed omb documents including a report to congress and two memorandums to federal agencies based on the findings of the pilot .

we interviewed omb staff as well as hhs and gsa officials responsible for implementing the section 5 pilot .

additional details regarding our objectives , scope , and methodology are provided in appendix i .

we conducted this performance audit from november 2017 to april 2019 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

signed into law on may 9 , 2014 , the data act required omb , or an agency it designated , to establish a pilot program to facilitate the development of recommendations for ( 1 ) standardized reporting elements across the federal government , ( 2 ) elimination of unnecessary duplication in financial reporting , and ( 3 ) reduction of compliance costs for recipients of federal awards .

to meet these requirements , omb established a pilot program with two components — one that focused on federal grants and another on federal contracts ( procurement ) .

omb designated hhs as the executing agency of the grants portion of the section 5 pilot with oversight from offm .

ofpp was responsible for designing and leading the procurement portion of the pilot focusing on reporting of federal acquisition regulation ( far ) procurement requirements .

ofpp collaborated with the chief acquisitions officers' council and gsa on specific aspects of implementation including the development of the central reporting portal , a reporting tool which is intended to centralize far reporting .

see figure 1 for a timeline of the activities undertaken by the grants and procurement portions of the pilot as well as deadlines required by the act .

as part of our ongoing oversight of the data act's implementation , we have monitored omb's efforts to meet its statutory requirements related to the section 5 pilot .

in april 2016 , we reported on the design plans for the section 5 pilot .

we found that hhs's design for the grants portion of the pilot was generally on track to meet statutory requirements and partially adhered to leading pilot design practices .

however , we also reported that the procurement portion was not on track to meet requirements , and that its plans did not follow leading pilot design practices .

in response to a recommendation in our report , omb revised its plan for the procurement portion to better reflect leading practices for pilot design identified in our april 2016 report .

these changes included more fully documenting its data collection plans and including a sampling plan to meet diversity requirements for pilot participants .

according to omb staff , the ongoing work and related grants guidance resulting from the section 5 pilot reflects a broader strategy for reducing federal recipient reporting burden that is outlined in the president's management agenda ( pma ) .

released in march of 2018 , and led by the executive office of the president and the president's management council , pma is a strategy to modernize how federal agencies deliver mission outcomes and provide services in three key areas: ( 1 ) modern information technology ; ( 2 ) data , accountability , and transparency ; and ( 3 ) the workforce for the 21st century .

several cross - agency priority ( cap ) goals include pma's milestones and activities .

these cap goals identify opportunities for multiple agencies to collaborate on government - wide efforts and report on goal progress quarterly .

two of these , cap goals 5 and 8 , include strategies for reducing federal award recipient reporting burden .

omb staff told us that some of the findings from the section 5 pilot and recommendations from their subsequent report to congress informed the focus of these cap goals .

for example , according to omb staff , the grants portion of the section 5 pilot focused on identifying how changes in grants data collection and grant management may reduce federal recipient reporting burden .

pma cap goal 8 is described as building on these efforts by shifting the focus toward the life cycle of grants management and standardizing grants management activities using agile technology .

we determined that the section 5 pilot fully met three of the data act's statutory requirements , substantively met one , and partially met two others .

the section 5 pilot fully met the following statutory requirements: ( 1 ) that pilot data collection cover a 12-month reporting cycle ; ( 2 ) timely issuance of omb's report to congress in august of 2017 to select congressional committees ; and ( 3 ) that the report to congress contain a discussion of any needed legislative actions as well as recommendations related to automating and streamlining aspects of federal financial reporting to reduce the reporting burden of federal award recipients .

we found that the pilot also substantively met the requirement that the pilot program include a combination of federal award recipients and an aggregate value of awards of not less than $1 billion but not more than $2 billion .

although the $122 billion in grants included in the pilot greatly exceeded the upper bound , this was principally a result of the decisions by offm and hhs to pilot different test models for reducing reporting burden , and to include a wide range of different types of grants .

the total value of grant awards exceeded the amount envisioned by the act .

omb's august 2017 report stated that the decision to go beyond the minimum requirement of testing one approach was made in the interest of achieving the data act's objective to identify ways to reduce reporting burden as well as the effect this decision would have on the aggregate value of grants sampled .

we believe that the pilot substantively met this requirement and did not identify any negative effects related to the larger aggregate value of grants , contracts , and subawards included in the grants portion of the pilot .

we found that the approach followed by omb and hhs furthered the broader objective identified by this section of the act .

in addition , we determined that the pilot partially met two of the act's requirements .

the first of these requirements concerns the act's requirement that omb's report to congress include a description of the data collected , the usefulness of the data provided , and the cost to collect pilot data from participants .

the report that omb issued to congress in august 2017 included information on the first two of these but only partly addressed the third .

specifically , it contained cost information for only the grants portion of the pilot , stating that the cost associated with executing this portion during fiscal years 2015 through 2017 was more than $5.5 million .

the report did not contain any cost information on the procurement portion of the pilot .

the data act also required that omb issue guidance to agencies for reducing reporting burden for federal award recipients — including both grantees and contractors — but the guidance subsequently issued only pertained to the grants community .

we determined that omb only partially met this requirement .

on september 5 , 2018 , omb issued m - 18- 24: strategies to reduce grant recipient reporting burden .

among other things , this memorandum contained guidance to federal agencies making the sf - 424b form optional based on findings from the grants portion of the pilot .

form sf - 424b is used by grantees to document assurances regarding their compliance with a wide range of rules and regulations .

figure 2 summarizes our assessment .

as the agency designated by omb to execute the grants portion of the section 5 pilot , hhs developed and analyzed six “test models” to determine if adopting the proposed changes would contribute to the pilot program's objectives of reducing reporting burden and duplication .

these test models examined a variety of grant reporting issues that hhs had identified as presenting challenges .

all but one of the test models , the common data element repository ( cder ) library 2 , based their findings on data collected from grantees .

the text box below provides high - level summaries of each of the six models .

additional details on the approach followed for each model , as well as reported results , can be found in appendix ii .

omb's august 2017 report to congress on the findings of the section 5 pilot contained three broad recommendations and stated that omb plans to take action on these recommendations .

these recommendations covered ( 1 ) standardizing core data elements , ( 2 ) eliminating duplication through auto - population of data , and ( 3 ) leveraging information technology open data standards to develop new tools across the federal government .

we found that evidence from the grant test models supported all three recommendations for streamlining federal reporting discussed in the report .

for example , omb recommended that its staff standardize core data elements used for managing federal financial assistance awards based on reductions in administrative burden experienced in the cder library 1 test model .

in another example , four test models supported omb's recommendation for increased use of data auto - population from existing federal data sources as a way to reduce duplication in reporting .

findings from the grants portion of the section 5 pilot also provided support for government - wide efforts to streamline reporting and reduce recipient reporting burden .

these include omb's memorandum m - 18-24: strategies to reduce grant recipient reporting burden , which discusses efforts to automate and centralize grant management processes .

among other things , m - 18-24 requires that federal agencies evaluate the systems and methods currently used to collect information from grant recipients to eliminate duplicative data requests .

omb staff confirmed that m - 18-24 incorporates findings from some of the test models of the grants portion of the pilot such as the single audit test model , which examined reducing duplicative reporting of grant recipients' data .

the efforts to reduce duplicative reporting in m - 18-24 also align with omb's recommendation in its august 2017 report to congress to eliminate unnecessary duplication in reporting by leveraging information technology that can auto - populate from existing data sources .

in addition , omb staff told us that findings from the grants portion of the pilot contributed to broader , government - wide initiatives related to federal reporting .

for example , according to omb staff , the three recommendations from the august 2017 report to congress are reflected in cap goal 8 of the president's management agenda , which focuses on results - oriented accountability for grants .

these omb staff also told us that findings from the grants portion of the pilot informed two cap goal 8 strategies .

for example , the cap goal 8 grants management strategy focuses on standardizing grants management business processes and data .

omb developed a comprehensive taxonomy for core grants management data standards that is currently available for public comment .

in addition , a second strategy focuses on incorporating a risk - based performance management approach to metrics in grant award operations to determine low - risk and high - value federal awards .

cap goal 8 also states plans to streamline the 2019 single audit compliance supplement to focus on requirements that inform grant award performance .

unlike the grants portion of the pilot , the procurement portion did not result in data collection that could be used for an evidence - based assessment of ways to reduce reporting burden .

omb's office of federal procurement policy ( ofpp ) sought to assess five test models that , according to the report to congress , were essential to centralized procurement reporting .

however , the pilot did not fully test any of the hypotheses associated with those test models .

the reasons for not testing the hypotheses included a lack of contractor participation and a lack of iterative and ongoing stakeholder participation and engagement throughout the course of the pilot .

see appendix iii for additional information regarding the various procurement test models , associated hypotheses , and additional details regarding our assessment .

the procurement portion of the pilot focused entirely on the development and testing of a central reporting portal to consolidate far reporting requirements .

according to ofpp staff , the pilot intended to eventually identify ways to centralize a wide range of reporting requirements that contractors currently meet through decentralized methods .

contractors must report many types of information depending on the contract .

toward that end , ofpp , with the assistance of gsa , created a procurement reporting website called the central reporting portal .

to test the efficacy of this portal for reducing burden , ofpp initially decided to examine how well it handled a specific far reporting requirement — the reporting of payroll data in accordance with the davis - bacon act .

according to pilot plans , davis - bacon reporting requirements were selected because they were identified by contractors as “pain points” during initial stakeholder outreach conducted in 2014 and 2015 .

ofpp planned to collect and analyze 1 year of weekly davis - bacon wage reporting data from at least 180 contractors through the central reporting portal to identify how centralized reporting might reduce contractor reporting burden .

however , during the 12-month procurement data collection period , no contractors agreed to submit their davis - bacon data as part of the pilot .

consequently , ofpp did not collect any wage data .

despite ofpp stating in its plans and reiterating to us as late as september 2017 that it expected to be able to secure at least 180 pilot participants , only one contractor expressed interest in reporting its davis - bacon information using the portal .

this contractor withdrew from the pilot before submitting any data through the central reporting portal .

ofpp staff told us they were aware of the potential for low pilot participation for davis - bacon reporting when pilot testing began in february 2017 because contractors already had established processes for fulfilling the highly complex davis - bacon reporting requirements , and pilot participation was optional .

according to gsa contracting staff , the one contractor who initially expressed interest ultimately decided not to participate because the format in which the contractor tracked and reported payroll data was incompatible with that used by the pilot portal , resulting in additional burden .

however , it was not until august 2017 — approximately 7 months into its year - long data collection period — that specific steps were taken to address the fact that the procurement portion of the pilot had not collected any data from davis bacon contractors .

during this period ofpp did not conduct pilot outreach activities with the contractors , who were key to successful implementation of the pilot .

ofpp staff told us that at the time of the pilot launch they learned that contractors were interested in having the central reporting portal be able to communicate with third - party payroll reporting systems to automate reporting .

ofpp staff said that although they are exploring this possibility , it was not a capability that was included as part of the pilot .

had this type of feedback on stakeholder needs been obtained sooner , omb could have explored the feasibility of adding this capability to the portal or engaged in communication with stakeholders to develop alternate approaches that might have persuaded more contractors to participate .

the usefulness of iterative and ongoing communication is recognized by the standards for internal control in the federal government .

those standards state that management should use quality information to achieve its objectives , and that management should collect quality information by engaging with stakeholders through iterative and ongoing processes and in a timely manner .

in this case , key stakeholders include relevant agencies , contracting officials , and contractors using the system .

ofpp's plan for the procurement portion of the pilot recognized the importance of stakeholder engagement stating that , to include a diverse group of recipients in the pilot , they should identify eligible participants for the pilot , conduct outreach to identify participants , and repeat this process as necessary until they achieved the sample necessary to test the central reporting portal .

however , as previously stated , no contractors agreed to submit their davis - bacon data as part of the pilot .

therefore , ofpp did not repeat this process until the pilot obtained the necessary sample size .

such interactions could have provided important information on contractors' needs and concerns that ofpp could have used to inform their decisions regarding the pilot's implementation .

in november 2017 , ofpp expanded the type of data accepted by the pilot to include hydrofluorocarbon ( hfc ) reporting , a new far reporting requirement .

however , this choice had limitations in its suitability for providing useful data for testing the hypotheses of the five procurement test models .

unlike davis - bacon reporting , where contractors submit weekly reports , hfc is an annual reporting requirement for contractors that emit hfc gases over a certain threshold .

the central reporting portal is the only location where contractors can submit hfc reporting .

for the purposes of the pilot , the central reporting portal accepted hfc submissions from november 2017 through february 2018 .

during the pilot , 11 hfc annual reports were submitted to the portal ( see figure 3 ) .

as a result of the small number of reports collected , omb collected much less data than it had initially expected to receive to test the capabilities of the central reporting portal .

if the procurement portion of the pilot had been executed as planned , it could have theoretically resulted in 9,360 davis - bacon submissions for analysis .

a larger data set of contractors' experiences using the central reporting portal could have informed omb's decision - making process through analysis of more , and potentially more varied data .

in addition to the small number of submitted hfc annual reports , the decision to switch to using hfc data had another limitation .

these data could not be used to examine changes in reporting burden as a result of using the central reporting portal .

this is because hfc reporting was a new reporting requirement , and as such , it did not have an established reporting process to use as a point of comparison to assess changes in reporting burden .

the objective of the procurement pilot was to assess how centralized reporting can reduce reporting burden .

this objective could not be achieved without data on the existing reporting burden .

evidence from the procurement portion of the pilot did not support omb's government - wide recommendations for reducing reporting burden in its august 2017 report to congress .

as previously stated , omb's report to congress included three recommendations that focused on ( 1 ) standardizing core data elements , ( 2 ) eliminating duplication by using data auto - population , and ( 3 ) leveraging information technology open standards to develop new tools .

as support for the first recommendation , the report stated that results from the procurement pilot test models demonstrated that standard data elements — coupled with uniform data adoption — and the ability to centrally collect and share information reduces administrative burden .

since the procurement portion of the pilot did not gather or analyze any pilot data from the davis - bacon participants , omb did not assess the extent to which the ability to centrally collect data actually reduces burden .

recommendation two stated that support from the procurement test model demonstrated that recipient burden is reduced when identical data can be entered once in one place and reused .

however , the hfc data collection process did not reuse data when capturing information and did not have the ability to auto - populate data .

hfc data collection was the only part of the procurement portion of the pilot that collected information that could have been used to inform this recommendation .

according to ofpp staff , the davis - bacon portion of the portal had the capability to auto - populate data .

however , no davis - bacon data were collected that would have allowed quantification of the effects of reusing data on reporting burden .

omb stated that support for the third recommendation included data and information collected from the pilot .

although there was some consultation with stakeholders during initial planning and design of the procurement portion of the pilot and the early development of the portal , the pilot did not actually collect any data from either davis - bacon contractors or through the hfc portion of the pilot in the data gathering and analysis portion of the pilot related to this recommendation .

in august 2018 , omb announced plans to expand the use of the central reporting portal for far reporting , stating that the portal allows contractors to report data to one central location .

ofpp staff told us that they are considering centralizing a third far requirement using the portal in the future but have not yet determined what that will be .

as discussed above , the procurement portion of the pilot did not collect sufficient data to test the effect of the portal on reporting burden .

in addition , the plan for the procurement portion states that ofpp intended to analyze feedback on pilot data collection and , depending on that feedback , decide whether to expand the pilot to other far reporting requirements .

however , the pilot did not collect any such feedback to inform its determination to expand the central reporting portal in the future .

as a result , ofpp has limited information regarding issues that could affect expanded use of the centralized reporting portal .

in the absence of such information , it is difficult for ofpp to determine whether continued or expanded use of the central reporting portal will reduce reporting burden , and which additional far requirements , if any , to include .

to reduce the burden and cost of reporting for recipients of federal funds , congress included specific provisions in the data act to encourage omb to take a deliberate and evidence - based approach toward developing guidance for federal agencies in this area .

the section 5 pilot offered omb a valuable opportunity — namely , to test a variety of methods and techniques at a small scale before applying them more widely .

such a process may enhance the quality , credibility , and usefulness of evaluations in addition to helping to ensure that time and resources are used more effectively .

similar to what we found when we analyzed the design of the section 5 pilot in 2016 , our review of its implementation and the results it produced found differences between the grant and procurement portions .

omb and hhs designed and executed a robust grants portion of the pilot that tested several different approaches for reducing the reporting burden experienced by federal grant recipients .

the resulting findings were used to develop omb's government - wide recommendations , and to inform two subsequent goals in the 2018 president's management agenda related to reducing recipient reporting burden .

in contrast , omb did not fully implement the procurement portion of the pilot consistent with its plans .

the procurement portion did not collect data to test the hypotheses associated with any of its five test models , and therefore could not provide empirical support for either omb's government - wide recommendations or guidance related to reducing reporting burden .

among the factors responsible for this were the lack of davis - bacon contractor participation and omb's inability to find a suitable alternative .

omb has announced its intention to expand centralized reporting for far requirements across government .

in the absence of timely information regarding the needs and concerns of stakeholders , omb faces the risk of experiencing implementation challenges similar to those it experienced during the pilot .

although the use of a centralized reporting portal could ultimately prove useful for reducing burden , the lack of information from stakeholders — including the contractors who would use it — raises concerns about the future success of plans for expanding the central reporting portal .

the director of omb should ensure that information is collected regarding how centralized reporting of procurement requirements might reduce recipient reporting burden — including input from stakeholders such as contractors through an iterative and ongoing process — to inform omb's planned expansion of the central reporting portal .

we provided a draft of this report to omb , hhs , and gsa for review and comment .

hhs and gsa informed us that they had no comments .

omb provided technical comments , which we incorporated as appropriate .

omb neither agreed nor disagreed with our recommendation .

we are sending copies of this report to the appropriate congressional committees , the secretary of health and human services , the acting director of omb , the administrator of gsa , and other interested parties .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at 202-512-6806 or sagerm@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of our report .

gao staff who made key contributions to this report are listed in appendix iv .

this report assesses the extent to which ( 1 ) the section 5 pilot met the statutory requirements of the act , ( 2 ) the grants portion of the section 5 pilot demonstrated changes in federal award recipients' reporting burden , and ( 3 ) the procurement portion of the section 5 pilot demonstrated changes in federal award recipients' reporting burden .

to assess the extent to which the pilot met statutory requirements we reviewed section 5 of the federal funding accountability and transparency act of 2006 , as amended by the digital accountability and transparency act of 2014 , to determine the legal requirements set forth in the act pertaining to establishing , designing , and executing the section 5 pilot .

we compared these requirements to documents from the office of management and budget ( omb ) and designated agencies .

these documents included pilot plans for the grants and procurement portions of the pilot , omb's august 2017 report to congress , m - 18-23: shifting from low - value to high - value work and m - 18-24: strategies to reduce grant recipient reporting burden .

we also interviewed staff from agencies involved in administering and executing the pilot on how they carried out their responsibilities .

these agencies included the department of health and human services ( hhs ) , omb's offices of federal financial management ( offm ) and federal procurement policy ( ofpp ) , and the general services administration ( gsa ) .

to assess the extent to which the grants portion of the section 5 pilot demonstrated changes in federal award recipients' reporting burden , we reviewed hhs' plans .

we analyzed the plans compared to information collected from the various test models throughout the pilot .

the data we assessed included survey data and analyses .

we also assessed whether statements on changes in grantees' reporting burden made in omb's august 2017 report to congress were supported by documentation .

we did this by verifying the statements against supporting information .

we determined that the pilot data we reviewed were reliable for the purposes of our work by reviewing the data , tracing them back to underlying agency source documents , and interviewing relevant agency staff .

we also interviewed offm staff and hhs officials on how the grants portion of the pilot was executed .

to assess the extent to which the procurement portion of the pilot demonstrated changes in reporting burden , we reviewed omb's plans and compared them to actions omb took to execute the pilot .

we compared omb's actions to execute the procurement portion of the pilot against criteria identified in standards for internal control in the federal government .

we viewed a demonstration of the central reporting portal tool for reporting davis - bacon and hydrofluorocarbon ( hfc ) submissions .

gsa developed the portal and ofpp provided oversight for the portal's development .

we also reviewed documentation including hfc reporting submissions made through the portal .

in addition , we interviewed ofpp staff , gsa officials responsible for administering the portal , and three contracting officials from gsa who were assigned to participate in the davis - bacon component of the procurement portion of the pilot regarding their actions related to implementing the procurement portion of the pilot .

we conducted this performance audit from november 2017 to april 2019 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

this appendix provides detailed information regarding the test models from the grants portion of the section 5 pilot .

the common data element repository ( cder ) library is an online repository for federal grants - related data standards , definitions , and context .

the library is intended to be an authorized source for data elements and definitions for use by the federal government and for recipients reporting grant information .

hypothesis: if grant recipients are provided with definitions of data elements through the cder library , then they will be able to accurately complete forms in a timely manner .

methodology: the department of health and human services ( hhs ) divided test model participants into two groups to read a scenario based on the grants lifecycle and complete a data collection tool .

the first group used the cder library to complete the data collection tool while the second group used all other available sources to complete the data collection tool .

after completion of the data collection tool , test model participants filled out a survey about their experiences using the cder library .

test model metrics: accuracy and completeness of captured data within a period of time and survey results .

example of test model results: on average , test model participants that completed a data collection tool using the cder library scored 11 percent higher in the accuracy of information requested and , on average , spent 6 fewer minutes when completing the tool .

number of test model participants: fifty - nine .

the cder library 2 test model focused on identifying duplication in grant forms and data elements across the federal government based on the data standards , definitions , and context within the cder library 1 .

hypothesis: if duplication across forms can be identified using the cder library , then agencies can update or reduce forms to reduce grant recipient burden .

methodology: hhs conducted an internal analysis of sf - 424 form families , using the cder library , to identify duplication in data elements to determine which forms could be consolidated .

test model metrics: number of duplicative fields within form families and across forms for selected federal entities example of test model results: the internal analysis conducted by hhs identified 371 instances of data element duplication across 10 agency grant funding applications when using standardized data elements from the cder library 1 .

number of test model participants: not applicable ; the cder 2 library test model did not collect information from test model participants because the test model was an internal document review .

the cder library 2 test model tested the utility of the data element definitions within the cder library 1 .

the consolidated federal financial report test model focused on examining the potential early validation of consolidated cffr data and potential future streamlining of the close - out process by allowing the submission of federal financial report ( ffr ) data in one system , rather than in multiple entry systems .

hypothesis: if grant recipients can enter complete ffr information systematically through one entry point instead of multiple different avenues and that information could be shared electronically from that point forward , then grant recipient burden will be reduced and data accuracy will be improved .

methodology: hhs surveyed administration for children and families grant recipients on their experience submitting a consolidated ffr via hhs's payment management system , and grantees on their perceptions of the process for using a consolidated ffr through facilitated discussions .

test model metrics: survey results .

example of test model results: sixty - four percent of the cffr test model participants reported that submitting their ffr through a single system would result in reduced reporting time .

in addition , 65 percent of the cffr test model participants believed using the payment management system for submitting ffr data would improve the accuracy of the information they submitted .

number of test model participants: one - hundred fifteen tested the pilot environment and 30 participated in the facilitated discussions .

the single audit test model consisted of ( 1 ) an audit and opinions on the fair presentation of the financial statements and the schedule of expenditures of federal awards ; ( 2 ) gaining an understanding of and testing internal control over financial reporting and the entity's compliance with laws , regulations , and contract or grant provisions that have a direct and material effect on certain federal programs ( i.e. , the program requirements ) ; and ( 3 ) an audit and an opinion on compliance with applicable program requirements for certain federal programs .

the single audit test model focused on reducing reporting of data on duplicative forms .

hypothesis: if grant recipients do not have to report the same information on duplicative forms — for example , the sefa compared to the single audit report package and data collection form — then grant recipients' burden will be reduced .

methodology: hhs collaborated with the office of management and budget's office of federal financial management and the department of commerce federal audit clearinghouse ( fac ) to create a pilot environment for test model participants to submit key portions of a modified standard form — single audit collection .

hhs conducted two focus groups with test model participants subject to the single audit .

the first focus group discussed and completed a survey on the new form .

the second group , a sample of test model participants who are subject to perform a single audit submitted the existing form in the fac pilot environment , completed a separate data collection form similar to the new form , and completed a survey on the effectiveness and burden of the new form .

test model metrics: focus group feedback and survey results .

example of test model results: all test model participants with access to the single audit's pilot environment believed the upload feature for reporting requirements could decrease duplication in required grant reporting .

number of test model participants: thirteen tested the pilot environment and 123 participated in facilitated discussions .

this model focused on the feasibility of developing a standardized notice of award ( noa ) to reduce reporting burden and facilitate access to standardized data needed to populate single audit information collection .

hypothesis: if grant recipients have a standardized noa for federal awards , then grant - reporting burden may be reduced for recipients by standardizing access to data needed to populate information collections .

methodology: hhs divided test model participants into two groups and completed a data collection tool .

the first group completed the data collection tool using three standardized noas , while the second group completed the data collection tool using three non - standardized noas .

after completion of the data collection tool , test model participants self - reported their respective times to complete the data collection tool .

they also filled out a survey about the standardized noa's impact on reporting burden and provided input on elements to include in a standardized noa .

test model metrics: self - reported form completion time , accuracy , and survey results .

example of test model results: test model participants with access to the standardized noa coversheets spent an average of 3 minutes less when completing the test model's data collection tool .

number of test model participants: one - hundred four .

the learn grants test model is a website on grants.gov that summarizes and provides links to new and important grants information such as policies , processes , funding , and other information needed throughout the grants life cycle .

the website intended to make it easier for stakeholders to find , learn about , and apply for federal grants and promote the standardization of grants terminology and data .

hypothesis: if grant recipients are supplied with grants life cycle information in one website , then they will have increased access to grants resources and knowledge of the grants life cycle process .

methodology: hhs developed a grants knowledge quiz from information on the learn grants website .

hhs administered the knowledge quiz to test model participants in two phases .

first , test model participants completed the knowledge quiz using existing knowledge and without the learn grants website .

next , test model participants completed the knowledge quiz with access to the learn grants website .

hhs compared the results from both knowledge quizzes .

after completion of the knowledge quiz , test model participants completed a survey on the usefulness of the learn grants website and its impact on increasing knowledge quiz scores .

test model metrics: knowledge quiz accuracy and survey results on the usefulness of learn grants website .

example of test model results: test model participants experienced an average 10 percent ( one quiz point ) increase in their grant knowledge quiz scores when using the learn grants website .

new grantees who participated in the test model also reported that the learn grants website provided useful grants information .

number of test model participants: fifty - seven .

appendix iii: assessment of test models in the procurement portion of the section 5 pilot hypothesis not tested .

hypothesis: verification of far standards for post award reporting will confirm the value of existing data standards and reduce variations that will , in turn , reduce contractor burden and cost .

original plan ( davis - bacon ) : ofpp planned to execute this test model through focus groups .

according to ofpp , no focus groups were conducted .

revised strategy ( hfc ) : this hypothesis could not be tested through hfc reporting because it was a reporting requirement without an existing reporting method through which to compare reporting burden .

hypothesis not tested .

original strategy ( davis - bacon ) : ofpp planned to test this hypothesis by gathering data on the time it takes to submit reporting data through the central reporting portal and outside of the portal , with self - reported data from contractors .

according to ofpp , data were not collected due to a lack of participation in the davis - bacon portion of pilot .

revised strategy ( hfc ) : this hypothesis could not be tested through hfc reporting because it was a reporting requirement without an existing reporting method through which to compare reporting burden .

access ( proof of concept ) hypothesis: if contractors can enter far - required reporting data systematically through one entry point instead of multiple different avenues , and that information can be shared electronically with appropriate individuals , then contractor burden will be reduced and data access improved .

assessment rationale original plan ( davis - bacon ) : ofpp planned to test this hypothesis by gathering data on the time it takes to submit reporting data through the central reporting portal and outside of the portal , with self - reported data from contractors .

omb also planned to conduct guided discussions .

according to ofpp , data were not collected due to a lack of participation in the davis - bacon portion of pilot .

revised strategy ( hfc ) : this hypothesis could not be tested through hfc reporting because it was a reporting requirement without an existing reporting method with which to compare reporting burden .

hypothesis not tested , but metric associated with test model was met .

hypothesis: if interfaces can be built to support access to other reporting systems , contractor burden will be reduced .

original plan ( davis - bacon ) : according to ofpp staff , the davis - bacon part of the central reporting portal was able to provide prepopulating of data by interfacing with other reporting systems or drop down menus for all reporting fields .

however , it could not demonstrate that such prepopulation resulted in a reduction of contractor burden .

revised strategy ( hfc ) : this is not applicable for hfc reporting which is reported through open fields .

although ofpp did not actually test the hypothesis associated with this test model , it did meet the metric that it had associated with the test model in its pilot plan .

that metric is to develop prepopulating capabilities in the central reporting portal by interfacing with other reporting systems .

in addition to the contact named above , peter del toro , assistant director ; silvia porres - hernandez , analyst - in - charge ; jazzmin cooper ; and jimmy nunnally made major contributions to this report .

also contributing to this report in their areas of expertise were michael bechetti , jenny chanley , mike laforge , carl ramirez , stewart small , andrew j. stephens , james sweetman jr. , and tatiana winger .

