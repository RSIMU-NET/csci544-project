in fiscal year 2005 , the department of education ( education ) provided more than $42 billion in grants to state and local education agencies , school districts , colleges and universities , and other organizations to conduct various program and research activities .

while congress directs the allocation of most of these funds , a small portion of this money — $4.7 billion in 2005 — is awarded by the secretary either through program competitions or through consideration of unsolicited proposals .

in the case of competitions , selection of awardees is governed by regulations and policies designed to ensure that federal funds are directed to those proposals of highest merit .

in the case of proposals that are unsolicited , awards are to be made to grantees that are recommended for funding by external reviewers based on proposals they deem to be of high quality and national significance .

allegations were made that education did not follow its policies in making the grant awards that benefited specific grantees .

you asked us to review two grant awards — a competitive grant awarded in 2002 from the voluntary public school choice program to the arkansas department of education to fund its partnership with k12 , inc. , and a 2001 award based on an unsolicited proposal to the national council on teacher quality ( nctq ) .

in the course of our review , program officials directed us to another competitive grant where they noted similar concerns as those raised in your letter .

this third grant was awarded from the credit enhancement for charter school facilities grant program to america's charter school finance corporation .

the grants in question were awarded in 2001 and 2002 and education has subsequently issued new guidance for making grant awards and has moved the grant programs in question to the newly created office of innovation and improvement ( oii ) .

we assessed education's policies and procedures for both competitive awards and unsolicited proposals in 2003 and 2004 and determined whether education followed them in awarding grants in those years and we reviewed education's grant award decisions for several 2001 and 2002 grants to determine whether the department followed its own policies .

to assess the policies and procedures in place for the 2003 and 2004 competitive awards processes , we reviewed departmental guidance issued in march 2003 that governed the grants awarded in those years .

we reviewed a stratified random sample of 91 of the 521 competitive grants made by oii in 2003 and 2004 , including all 10 grants with over $15 million in obligations .

all percentage estimates from this sample have margins of error of plus or minus 10 percent or less .

to assess education's process for reviewing unsolicited proposals in 2003 and 2004 , we reviewed departmental guidance and all 65 files for unsolicited grants awarded by oii in 2003 and 2004 .

we used the department's grant administration and payment system ( gaps ) to identify all grants awarded in 2003 and 2004 .

we assessed the reliability of the data in gaps and found it to be reliable for our purposes .

to review education's decisions to award the 2001 and 2002 grants , we obtained and reviewed departmental grant - making guidance in place at the time these grants were awarded .

to determine whether or not departmental guidance was followed , we reviewed the official grant files for each of these grants , the corresponding files for the competitions that contain information on all of the applicants' proposals , the competition plans , and external reviewers' rankings and comments .

in 2002 , 34 applicants competed for grants from the credit enhancement for charter school facilities grant program and education awarded five grants , including the grant in question .

that year , the department also considered 21 unsolicited proposals and made awards to 18 grantees , including the grantee in question .

in 2002 , 46 applicants participated in the voluntary public school choice grant competition and the department awarded 13 grants , including the grant in question .

for additional details about our scope and methodology , see appendix i .

our work was conducted from may 2005 through february 2006 according to generally accepted government auditing standards .

education administers discretionary grants both through competitions and through consideration of unsolicited proposals .

in 2003 , oii awarded 267 competitive grants totaling $335 million and 41 grants based on unsolicited proposals totaling $64 million .

in 2004 , the department approved 254 competitive grants for $826 million and 24 grants for unsolicited proposals totaling $17.5 million .

education distributed more than $42 billion in grants in fiscal year 2005 , but only a small portion — 12 percent — was discretionary .

the rest of the funds were allocated to grantees on the basis of statutory formulas or as a result of a congressional earmarks ; the department has no discretion over who receives grants from those funds .

 ( see fig .

1 ) .

although education's grant awards have increased by about a third since before the enactment of the no child left behind act , funding for discretionary grants decreased by 19 percent .

most of the increase in grant funding is allocated through formula grants , such as title i — improving the academic achievement of the disadvantaged .

total funding for formula grants grew by about 45 percent between 2001 and 2005 .

in the case of competitions , selection of awardees is governed by policies and procedures designed to ensure a fair and objective evaluation of all of the applications .

education begins the competition process by publishing a notice in the federal register .

this announcement serves as a notice that federal funds are available through a specific program and invites interested parties to prepare an application for funding .

the notice provides information on the estimated number of awards that will be made and the estimated size of each award .

importantly , the notice establishes the rules by which the competition will be conducted ; among other things , this notice provides information on the eligibility criteria , the issues education expects the applicants to address in their applications , and the evaluation criteria for the competition .

the notice serves as a blueprint for applicants to use in developing a successful application .

in addition , program officials must develop a plan for how they will administer the competition .

the competition plan , known as an application technical review plan ( atrp ) , is a key management control that helps promote fairness and transparency in the process .

the competition plan includes such information as the schedule for the competition , the process for identifying and using external peer reviewers , the composition of the peer reviewer panels , a description of how the applications will be assigned to these panels , the process for resolving peer reviewers' conflicts of interest , and the methodology for selecting applications for funding .

any deviation from the original plan for reviewing the applications , selecting applicants , and approving the list of prospective grantees must be justified in writing , which is designed to enhance transparency .

another key control for ensuring fairness in the award process for grants is the peer review process .

peer reviewers are typically external experts who bring an independent assessment of the merits of the applications .

the number of individuals selected to serve as peer reviewers depends on the number of applications received for a specific competition .

these peer reviewers are usually grouped together in panels of three or more members to review applications .

each peer reviewer independently reads and scores a group of applications randomly assigned to the panel , generally using a numerical scoring system , against program criteria based on legislative and regulatory requirements .

program officials prepare a single score for each application — usually by averaging the scores of all the peer reviewers on the panel that reviewed the application or , less frequently , using a statistical technique to equalize unusual scoring variances among reviewers .

program officials then prepare a rank - ordered list of applications based on the single scores and use this list to prepare their funding recommendations .

education's regulations stipulate that the rank - order list is one of many factors the secretary may use in selecting new grants .

the secretary may also use information from the application as well as information concerning the applicants' performance and use of funds under a previous award .

ultimately , the peer reviewers' comments are advisory , and the secretary can determine which new grants to fund based on the program criteria outlined in the statute and the federal register notice .

in addition to developing the atrp , education's policy requires program officials to screen the applicants for eligibility , typically before applications are peer reviewed .

before making an award , program officials must conduct checks to ensure the applicants' competence to manage federal funds .

a budget analysis is also required to be conducted to ensure that no grant funds are awarded for unallowable purposes .

education's policy is to award the vast majority of discretionary grant funds through the competitive process , however it may also fund grants based on unsolicited proposals .

although education can fund unsolicited proposals from any program , the primary source for funding such proposals is the fund for the improvement of education ( fie ) .

this program was created in 1988 as the secretary's fund for innovation in education .

at the time , it provided the secretary with the authority to fund proposals that showed promise of identifying and disseminating innovative educational approaches .

the program has been reauthorized over the years , most recently in 2002 with enactment of the no child left behind act and maintains flexibility by providing the secretary with the authority to fund “meritorious” programs to improve the quality of elementary and secondary education at the state and local levels and help all children meet challenging state academic content and student academic achievement standards .

the fie program is also used to fund congressional earmarks for elementary and secondary education activities .

the statute does not require education to compare the relative merits of all the proposals it receives in any given year ; however , it does require that the secretary use a peer review process for reviewing applications .

appropriations for the fie program remained relatively steady until 1998 .

since 1998 appropriations increased dramatically .

 ( see fig .

2 ) .

before funding unsolicited proposals , education must also make sure that the regulatory requirements for funding such proposals are met .

education must first determine whether the unsolicited proposal could be funded under a competitive grant program ; if it could be funded under a competition , the secretary refers the proposal to the appropriate competition .

if an appropriate competition does not exist , departmental regulations require the secretary to decide if ( 1 ) there is a substantial likelihood that the application is of exceptional quality and national significance , ( 2 ) the application satisfies the requirements of all applicable statutes and codified regulations that apply to the program , and ( 3 ) selection of the project would not have an adverse impact on the funds available for other awards planned for the program .

if these criteria are met , education assembles a panel of experts to evaluate the unsolicited proposal based on the selection criteria .

if the experts highly rate the application and determine that the application is of such exceptional quality and national significance that it should be funded as an unsolicited application , then the secretary may fund the application .

education made progress since 2003 in improving its policies for awarding discretionary grants ; however , prior to these improvements we found that education made exceptions to its policies that benefited the grantees in question .

for the two competitive grants , we found that education officials reduced funding to all of the grantees to accommodate awards to lower - rated grantees and did not conduct analyses to assess the impact of these reductions on the ability of the applicants to achieve the goals of their projects .

in doing so , education broke from established practice by altering its selection methodology after it had developed a list of grantees recommended for funding .

with regard to the third grant , which was an unsolicited proposal , we found that education made the award with approval from only one of three independent reviewers and lacked a process for reconciling differences among peer reviewers' ratings .

furthermore , education awarded four unsolicited grants in 2001 that had not been recommended for funding by any one of the three reviewers , contrary to departmental regulations .

in order to fund a grant to the arkansas department of education , education officials reduced the prospective grant awards to all other competitors in the 2002 voluntary public school choice program by nearly 50 percent .

specifically , education's program office recommended 10 grantees for funding , but subsequently expanded this list to 13 awardees , including 13th - ranked arkansas .

as part of its decision to fund 13 grants instead of 10 , education funded each of the top 12 grantees at just 53 percent of its request , while it funded arkansas at 77 percent of its request .

 ( see fig .

3 ) .

in reducing the grant awards to accommodate 13 grants , education set aside its policy to conduct a thorough budget analysis of the programmatic impact of the reductions .

the program official responsible for the competition received assurances from all of the grantees that they could still achieve the goals of their proposals with decreased funds , and according to this official , all of the grantees submitted revised budgets reflecting reduced award amounts .

however , this official told us that education did not analyze the revised budgets , and we found no evidence from our file review that a budget analysis was conducted to determine if there would be a programmatic impact resulting from the reductions .

additionally , neither the assurances nor the rescoped proposals , which given the magnitude of the reductions could be substantially different from original proposals , were vetted by any external reviewers .

for example , arkansas scaled back its proposal by eliminating foreign language instruction and summer school programs .

in addition , we found that education broke from established practice and altered its selection methodology outlined in the competition plan .

the department's original list of 13 grantees would have required cutting the requests of the applicants other than arkansas across - the - board by 51 percent in order to fund each applicant .

arkansas received a reduction of only 23 percent .

the department altered its selection methodology , which resulted in one grant request for $3.6 million being replaced by one for $749,000 .

using the new methodology , funding reductions for each of the 12 grantees went from 51 percent to 47 percent .

officials told us it was not normal procedure to make changes to the selection methodology so close to the time of the award decision .

we found that the process used by senior departmental officials in making an award to america's charter school finance corporation under the credit enhancement for charter school facilities program set aside departmental policy and varied from standard departmental practice .

specifically , after receiving a list of four grantees recommended for funding , the deputy secretary asked his staff — a senior political appointee — to re - review the fifth and sixth ranked competitors , as ranked by expert reviewers .

based on this re - review , the order of the fifth and sixth ranked grantees was reversed , according to the department official conducting this review , because “the application from america's charter was stronger and had been evaluated too harshly by its peer review panel.” program officials said that they had never before experienced a case whereby a senior political appointee selectively re - reviewed and rescored particular applicants after the peer review process had been completed .

furthermore , the appointee recommended that “this excellent , ambitious application be awarded the fifth of five allowable grants,” expanding the initial list recommended by the program staff .

to fund five grantees , program officials reduced the awards to each of the grantees by anywhere from 16 to 40 percent .

we found no evidence that a budget analysis was conducted , as required by policy , to determine whether the reductions impeded the grantee's ability to perform the proposed activities and achieve the intended outcomes on which the reviewers based their scores .

in the case of the grant to nctq in 2001 , education awarded $5 million to the council , despite the fact that its proposal was not recommended for funding by two of three reviewers .

the council's award was based on an unsolicited proposal to create a new national accreditation program for teachers — the american board for certification of teacher excellence ( abcte ) .

we also found that in 2001 education funded eight other unsolicited proposals that had been rejected by at least two of three reviewers .

four of these eight were funded despite not being recommended by any of the three reviewers , which was contrary to departmental regulations .

in 2003 , education strengthened some of its policies governing the competitive grant process and in both 2003 and 2004 generally adhered to its key policies , although certain procedures were not always carried out or documented .

in our review of all 25 competitions we did not find evidence that education made funding reductions without conducting budget analyses of the potential impact on the proposals or rescored applications after they had been assessed by expert reviewers .

nor did we encounter any changes to the competition plans for 2003 and 2004 after peer reviewers had assessed the applications .

however , we did find found that many of the original competition plans we examined had not been finalized — that is to say , formally approved .

for this reason , we cannot be certain that all competitions had proceeded without alteration to the plans .

in addition , we found many of the grant files lacked documentation documented evidence that education had conducted three standard procedures for screening potential grantees: ( 1 ) a review of the applicant's compliance with audit requirements ; ( 2 ) a review of the applicant's eligibility for the program ; and ( 3 ) a review of requested costs and expenses to determine whether they were allowable .

in 2003 , education added certain controls over the competitive grants process aimed at increasing its fairness and transparency .

among these is an explicit requirement to document any changes to a competition plan , which would include changes to how competitors are scored or how peer reviewers are selected .

the new guidance provides that if there is a need to deviate from a plan during a competition , it should be formally amended and a written justification should be approved by a senior departmental official and included in the official file for the competition .

also , the department clarified the conditions under which it may reduce funding from what was applied for .

in addition , the department added several checks for program staff to consider before making awards as part of their responsibility for determining that potential awardees are competent to manage federal funds .

one of these checks requires that program staff submit for screening a list of the likely awardees to determine whether any have a grant history and met auditing requirements .

if the audit record reveals any problem , program staff are required to withhold or delay an award until such problems are resolved .

table 1 compares certain requirements from education's 1997 guidance with 2003 guidance .

in our review of all 25 competitions run by oii in 2003 and 2004 , we found that education generally adhered to its policies for ensuring fairness in the competitive process , and we found no evidence that education made funding reductions without conducting budgetary analysis of the potential impact on the proposals .

nor did we find any instances in which education officials re - reviewed peer reviewers' initial assessments .

in addition , we found that grants were generally awarded to the highest - scoring eligible applicants , as policy requires , and that exceptions to the rank order were appropriately documented and justified , as policy requires .

for example , we found several instances where applicants were dropped from the slate because they were ineligible for the program .

in 2003 and 2004 we found no evidence that competition plans — the procedural and scoring blueprint for each grant competition and a key management control — were changed after the expert reviews were completed .

however , only 5 of the 14 plans covering the 25 competitions had been finalized as required .

specifically , the plans did not contain documentation of approval by a principal officer , nor did the plans show whether they had been amended .

without such documentation , we could not determine whether changes had , in fact , been made to the plans that would have required justification and approval under education's 2003 guidance .

officials acknowledged that competition plans should be signed and dated when they are developed , but officials said they at times overlooked this step .

additionally , they said that any amendments to the plans were rare and usually not substantive in nature .

further , our review of the 2003 and 2004 grants showed that the files frequently lacked documentation that education had conducted three management controls that are designed to ensure that applicants are qualified to receive federal funds .

specifically , many of the files did not contain evidence that education determined whether the applicant had any past audit findings , met the eligibility requirements for the program , or requested any unallowable expenses .

we estimate that in 98 percent of the files , there was no evidence that program officers checked a grantee's audit history — a key check on an applicant's ability to manage federal grant funds .

the guidance requires program staff to submit lists of potential applicants to the audit administrator to determine whether applicants submitted federally required audits and , if applicable , adhered to corrective actions required in the audits .

the director of the audit division informed us , however , that this check was not universally implemented due to resource constraints .

as a result , there is no pre - award assessment of an applicant's prior performance under any previous federal grant , or that an applicant with audit findings resolved any deficiencies before a new grant was awarded .

further , we estimate that 45 percent of the grant files did not contain documentation that education , prior to award , screened the applicants for eligibility , and 68 percent of the grant files did not contain documentation of a thorough analysis of the applicant's requested budget to determine whether all costs were allowable .

program officials assured us that they perform both of these checks and acknowledged that documentation of the checks should be in the file .

while education has taken steps to centralize and improve its process for reviewing unsolicited proposals , it based its screening decisions on proposals that varied greatly and frequently provided extensive technical assistance .

prior to a departmental reorganization , education officials told us there was no established process for considering unsolicited applications ; instead , various offices within education ushered select applications through a peer review process , and the secretary decided among those which to fund .

in december 2002 , the secretary notified the various offices within the department to send any unsolicited proposals relating to elementary and secondary education initiatives to oii for review .

in 2003 , oii developed a process for reviewing unsolicited proposals to determine which would be asked to submit an application for peer review .

to select among the proposals received , senior oii officials told us they chose those proposals that aligned with the secretary's priorities .

at the beginning of the year , these officials said they met with the secretary to discuss his priorities and then , over the course of the year , selected some that matched the secretary's priorities to submit full applications .

in 2004 , education's ig reviewed oii's process to ensure that it complied with departmental regulations and policy and found that it failed to document compliance with a number of regulatory requirements .

specifically , the ig reported that education was not documenting whether unsolicited proposals that had been selected for peer review had been screened to ensure , among other things , that there was a substantial likelihood that the application was of exceptional quality and national significance , as required by regulations .

in response to the ig's findings , oii began to document the required screenings by including a memo in the grant file for each proposal that it planned to forward to peer review certifying , among other things , that there was a substantial likelihood that peer reviewers would deem the proposal to be of exceptional quality and national significance .

while education developed a standard process for reviewing unsolicited proposals , these proposals varied greatly in content and detail .

oii officials said that the proposals could range from multipage documents from experienced grantees to less formal proposals — sometimes one - page letters or e - mails — from novice grantees .

oii does not require that proposals be in a standard format before it selects which ones to forward to peer reviewers .

oii officials told us it was often difficult to discern from the submitted material which proposals would ultimately gain the support of the peer reviewers .

nonetheless , oii made its determinations that proposals were likely to meet regulatory requirements of national significance and exceptional quality on the basis of these varying proposals .

oii officials said that because the regulatory criteria defining significance and quality are broad many of the proposals submitted during the year met the criteria .

oii officials said that they were concerned that if they had to promulgate rules governing the format or topics for unsolicited proposals , they might be overwhelmed with applicants .

however , another office within education — the institute of education sciences ( ies ) — invites unsolicited research proposals and requires a standard submission .

ies' invitation provides guidance on standardized presentation formats — proposals are limited to six pages — and imposes deadlines on submitting the proposals to ies .

we also found that oii provided extensive technical assistance to some applicants .

our file review of unsolicited proposals showed that in many cases oii staff were in regular communication with the applicants , provided them with suggestions for how to organize and structure the narrative portion of their applications , assisted them in preparing proposed budgets , and commented on drafts of their applications .

in 2003 , despite education's screening and technical assistance efforts , peer reviewers gave low scores to 14 of 42 applicants , and education funded 13 of these low - scoring proposals .

 ( see appendix ii for a list of grants awarded in 2003 based on unsolicited proposals ) .

in its 2004 study , the ig found that oii failed to comply with regulations that make funding for unsolicited proposals contingent on recommendations from peer reviewers .

in response to the ig's findings and to comply with the regulation , oii began , in 2004 , to ask the peer reviewers to provide recommendations for or against funding , rather than just having them provide a numerical score for each proposal .

however , in 2004 , if peer review failed to recommend approving a proposal that oii had selected , oii provided the applicants with the reviewers' comments and asked them to rewrite their proposals .

in 2004 , 10 of the 27 applicants failed to garner the reviewers' support .

of those 10 grantees , 2 declined to resubmit their applications — citing time constraints — and were not approved .

the remaining eight applicants revised their proposals and were subsequently recommended for approval by peer reviewers after the revisions were submitted .

all eight were approved and funded .

 ( see app .

iii for a list of grants awarded in 2004 based on unsolicited proposals ) .

the department of education has the responsibility to ensure that when it makes discretionary grant awards it follows a transparent and fair process that results in awards to deserving eligible applicants .

in the case of unsolicited applications , oii's process is designed to meet statutory and regulatory requirements .

however , education based its decisions about the likely national significance and quality of proposals on information that varied greatly in detail and , as a result , sent applications forward for peer review that sometimes required extensive revisions .

without requiring a more uniform format for unsolicited proposals , oii may not have adequate information on which to base its screening decisions .

regarding its competitive awards process , the department has put in place management controls that , if followed , provide a reasonable assurance that awards are made appropriately .

these controls protect the integrity and transparency of the departmental grant award process by requiring , among other things , that competition plans are finalized prior to the competition , that any changes to such plans are documented and approved , that grantees are screened for competency and eligibility , and that departmental officials determine that proposed activities are allowable under the law .

when the department does not consistently follow these procedures , as we found to be the case , the integrity of its competitive grant award process may be undermined .

furthermore , in the absence of such diligence , actions taken that benefit specific grantees , such as those we found in 2001 and 2002 , could happen again .

we are making four recommendations to the secretary of education to address certain shortcomings in the department's grant - making policies through a variety of executive actions designed to promote fairness , enhance transparency , and provide greater access to funding opportunities .

specifically , to improve the process for selecting and awarding grants based on unsolicited proposals , we are recommending that the secretary develop a more systematic format to select unsolicited proposals for further consideration by peer reviewers .

in addition , to ensure fairness and improve transparency in the competitive grants process , we recommend that the secretary take the following steps: ensure that all competition plans are finalized before competitions begin and if a plan needs to be amended during a competition , the secretary should provide assurances that any such amendment is justified in writing and has been approved by a senior department official .

implement departmental policy to screen all applicants for compliance with audit requirements before the award , and ensure that outstanding audit issues — if there are any — are addressed before making an award .

take appropriate steps to ensure that program officers better document required checks such as budget analyses and eligibility screening .

education provided us with comments on a draft of this report ; these comments appear in appendix iii .

education also provided technical comments that we incorporated as appropriate .

education agreed with 3 of our recommendations for improving the transparency of its competitive review process and said it has already taken steps to improve its guidance and training .

specifically , it agreed to ( 1 ) finalize competition plans before the competitions begin and obtain approvals from senior department officials for any amendments to the plans , ( 2 ) ensure that program officers better document their analyses of applicants' budgets and eligibility , and ( 3 ) implement departmental policy to screen all applicants for compliance with audit requirements before awarding any new grants .

education disagreed with our recommendation that it develop a more systematic approach — modeled after the approach used by ies — to select unsolicited proposals for further consideration by peer reviewers .

education said implementation of our recommendation would not help it to select high - quality applications because of the broad nature of the fie program .

we disagree and think that collecting some systematic information would enhance education's ability to more effectively screen the quality of its applicants and enhance the transparency and consistency of this process .

as we reported , education officials acknowledge that , due to the nature of the proposals , it is often difficult to make quality screening decisions .

we acknowledge that fie awards and ies' research grants are fundamentally different , but we point out that the fie program does not necessarily need to collect information that is as detailed or that would place unnecessary burdens on organizations seeking fie funds .

to make it clear that education should focus on developing a systematic approach to selecting unsolicited proposals rather than duplicating the approach used by ies , we have modified our recommendation and removed reference to ies .

as agreed with your staff , unless you publicly announce its contents earlier , we plan no further distribution of this report until 30 days after its issue date .

at that time , we will send copies of this report to the secretary of education , education's oii , relevant congressional committees , and other interested parties .

we will also make copies available to others upon request .

in addition , the report will be made available at no charge on gao's web site at http: / / www.gao.gov .

if you or your staff have any questions regarding this report , please contact me at ( 202 ) 512-7215 .

contact points for our offices of congressional relations and public affairs are listed on the last page of this report .

key contributors are listed in appendix iv .

this appendix discusses in detail our scope and methodology for ( 1 ) reviewing education's grant award decisions for the 2001 and 2002 grants in question to determine whether the department had followed its policies in place at the time , ( 2 ) assessing the department's policies and procedures in place in 2003 and 2004 for the competitive awards process and determining whether education followed them in making such awards in those years , and ( 3 ) assessing education's process for reviewing unsolicited proposals in 2003 and 2004 .

to review education's grant award decisions for the 2001 and 2002 grants , we limited our in - depth inquiry to the three grants in question .

these grants were awarded before education reorganized in 2003 .

in 2003 , education created oii and consolidated a number of grant programs with it .

the grants in question were funded from programs that are now housed in oii .

in addition , in 2003 education published revised agency guidance on awarding .

this guidance governs the policies and procedures program staff must follow in holding grant competitions and in awarding grants .

consequently , we chose 2003 and 2004 as the time period for our systematic review of both competitive grants and grants based on unsolicited proposals .

we used the department's gaps to identify all grants awarded in 2003 and 2004 .

we assessed the reliability of the data in gaps and found it to be reliable for our purposes .

we reviewed the competition files from all 25 discretionary grant competitions held in 2003 and 2004 .

during this 2-year period , a total of 521 grants were awarded .

ten of these grants were for $15 million or more ; we selected all of these grants for review .

of the remaining 511 competitive grants awarded for amounts under $15 million , we selected a random sample of 81 additional grants to review .

the sample size was calculated to achieve a precision of plus or minus 10 percent for an attribute estimate with an expected proportion of 50 percent and a 95 percent confidence level .

with this probability sample , each grant in the population had a known nonzero probability of being selected .

each sample grant was subsequently weighted in the analysis to account statistically for all the members of the population , including those that were not selected .

all percentage estimates from this sample have margins of error of plus or minus 10 percent or less .

in addition to 91 competitive awards , we examined all 65 grants based on unsolicited proposals made by oii during 2003 and 2004 .

in 2003 , $64 million was awarded to 41 unsolicited grantees ; in 2004 , $17.5 million was awarded to 24 unsolicited grantees .

the grantees we examined were collectively awarded $507 million , or 41 percent of the $1.24 billion total competitive and unsolicited grant funds awarded in 2003 and 2004 by oii .

to review the 2001 and 2002 grants in question to determine whether the department had followed its policies , we reviewed departmental grant - making guidance in place at the time these grants were awarded and the official grant files for each of these grants .

for the two competitive grants , we also examined the corresponding files for the competitions that contain information on all of the applicants' proposals , the competition plans , and external reviewers' rankings and comments .

in addition , for the competitions , we interviewed relevant managers and program officers responsible for monitoring the grants , program attorneys , and ethics officials .

for the unsolicited grant , we reviewed the official grant file , including the peer review comments .

for comparison , we also reviewed the expert reviewers' rankings and comments for all other unsolicited awards made in 2001 .

further , we interviewed program officials responsible for monitoring the grant .

to assess the department's policies and procedures in place in 2003 and 2004 for the competitive awards process and determine whether education followed them in making such awards in those years , we examined departmental guidance issued in march 2003 that governed the grants awarded in those years as well as applicable statutes authorizing competitions and regulations .

also , we reviewed competition files and individual grant files for grants awarded during this 2-year period .

in reviewing the competition files , we recorded information in the federal register notice inviting applications , the competition plan , the funding memo and slate from the deputy under secretary to the executive secretary and information on the funded grantees from the gaps .

we used a structured instrument to collect information about each grant .

in reviewing each individual grant file , we recorded information on the ( 1 ) grantee's funding levels , years in the program , and contact information ; ( 2 ) application processing by education , including funding checklists , application log screening forms , and budget analysis ; ( 3 ) peer reviewers' comments and rankings ; and ( 4 ) single audit database reports .

we also interviewed key program officials from three of oii's six program offices to ascertain their familiarity with departmental guidance and to help us better understand how they implemented the department's guidance .

similarly , to assess education's process for reviewing unsolicited proposals in 2003 and 2004 , we reviewed departmental guidance and all 65 files for unsolicited grants awarded by oii in 2003 and 2004 .

we collected information from this review on the processes used by the department to assess each successful application for its quality and its national significance , the level of technical assistance provided to each successful application , the peer reviewers' comments on each application , and any additional post - review support provided to the awardees .

again , we used a structured instrument to collect information about each grant .

in addition , we interviewed officials responsible for administering grants based on unsolicited proposals .

we conducted our work between may 2005 and february 2006 in accordance with generally accepted government auditing standards .

appendix ii: grants awarded based on unsolicited proposals ( 2003-2004 ) colorado children's campaign black alliance for educational options hispanic council for reform and educational opportunities national council of negro women , inc .

corporation for educational radio and television ( cert ) accountability works , inc. / education leaders council national alliance of state science and mathematics coalitions research for better schools , inc. university of dayton school of education center for education innovation — public education association national football foundation and college hall of fame , inc alpha kappa alpha sorority , inc. first & goal , inc .

bryon gordon , assistant director , and bill keller , analyst - in - charge , managed this assignment and made significant contributions to all aspects of this report .

ellen soltow also made significant contributions , and jim ashley , joel grossman , and jerry sandau aided in this assignment .

in addition , richard burkard and jim rebbe assisted in the legal analysis , and sue bernstein assisted in the message and report development .

u.s. department of education's use of fiscal year appropriations to award multiple year grants .

b - 289801 .

washington , d.c.: december 30 , 2002 .

financial management: review of education's grantback account .

gao / aimd - 00-228 .

washington , d.c.: august 8 , 2000 .

education discretionary grants: awards process could benefit from additional improvements .

gao / hehs - 00-55 .

washington , d.c.: march 30 , 2000 .

department of education grant award .

gao / hrd - 93-8r .

washington , d.c.: december 9 , 1992 .

grants management: additional actions needed to streamline and simplify processes .

gao - 05-335 .

washington , d.c.: april 18 , 2005 .

grants management: epa needs to strengthen efforts to provide the public with complete and accurate information on grant opportunities .

gao - 05-149r .

washington , d.c.: february 3 , 2005 .

federal assistance: grant system continues to be highly fragmented .

gao - 03-718t .

washington , d.c.: april 29 , 2003 .

welfare reform: competitive grant selection requirement for dot's job access program was not followed .

gao - 02-213 .

washington , d.c.: december 7 , 2001 .

grant financial system requirements: checklist for reviewing systems under the federal financial management improvement act .

gao - 01-911g .

washington , d.c.: september 3 , 2001 .

grant financial system requirements .

gao / jfmip - sr - 00-3 .

washington , d.c.: june 1 , 2000 .

