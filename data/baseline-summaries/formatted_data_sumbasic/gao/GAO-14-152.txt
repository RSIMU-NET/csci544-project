the department of defense ( dod ) invests billions of dollars to develop and implement enterprise resource planning ( erp ) systems , which it considers critical to transforming the department's business operations and addressing some of its long - standing weaknesses , including those related to financial management and business systems modernization .

dod has stated that the development and implementation of the air force's defense enterprise accounting and management system ( deams ) is critical to the department's goal of producing auditable financial statements by september 2017 , as called for by the national defense authorization act for fiscal year 2010 .

in october 2010 , we reported that although the air force met best practices in developing a cost estimate , it did not meet best practices in developing the schedule estimate for implementing deams .

having such a schedule is crucial to the air force's ability to reliably estimate the program completion date .

to support congress's continuing oversight of dod's progress in implementing its erp systems , you asked us to review the schedule and cost estimates for selected dod erp systems .

the objective of this review was to determine the extent to which the current schedule and cost estimates for deams were prepared in accordance with gao's schedule and cost guides .

we reviewed the most current schedule and cost estimates that supported dod's february 2012 milestone b decision , which determined that investment in deams was justified .

we assessed the deams schedule using the gao schedule guide to determine whether it was comprehensive , well - constructed , credible , and controlled .

to assess the schedule , we obtained and reviewed documentation , including the integrated master plan and work breakdown structure .

in assessing the program's cost estimate , we used the gao cost guide to evaluate the deams program management office's estimating methodologies , assumptions , and results to determine whether the cost estimate was comprehensive , well - documented , accurate , and credible .

we obtained and reviewed documentation , including the program office estimate , software cost model , independent cost estimate , and risk and uncertainty analysis .

we also interviewed key program officials , such as the program manager , lead schedulers , and cost estimators , to obtain information , such as explanations to resolve identified discrepancies .

after we briefed deams program officials on the results of our assessment , they provided an updated schedule dated october 2012 .

for this updated schedule , we determined the extent to which it met certain best practices for the comprehensive , well - constructed , and credible characteristics , because not implementing these best practices would affect the reliability of the entire schedule .

in may 2013 , program management officials provided another updated deams schedule , which they acknowledged contained issues that prevented the schedule from meeting best practices .

although we did not independently assess the may 2013 schedule , we did confirm that it included certain information needed for long - term planning .

we conducted this performance audit from may 2012 to february 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

deams was initiated in august 2003 and is intended to provide the air force with the entire spectrum of financial management capabilities , including collections , commitments and obligations , cost accounting , general ledger , funds control , receipt and acceptance , accounts payable and disbursement , billing , and financial reporting for the general fund .

in february 2012 , the dod deputy chief management officer granted milestone b approval for deams to enter the engineering development phase of the acquisition life cycle , which is considered the official start of the program .

deams program functionality is intended to be implemented across the air force in a series of releases in two increments — increment 1 will include six releases and increment 2 will include two releases .

dod has approved the funding for the air force to proceed with the acquisition of the functionality for the first increment of deams .

this funding is approximately $1.6 billion , with deployment scheduled to occur during the fourth quarter of fiscal year 2016 .

the air force reported that it had spent about $427.5 million as of september 30 , 2013 , on the program .

as stated earlier , in october 2010 , we reported that although the air force met best practices in developing a cost estimate , it did not meet best practices in developing the schedule estimate for implementing deams .

in particular , the air force had not developed a fully integrated master schedule that reflected all government and contractor activities .

we recommended that the air force develop an integrated master schedule that fully incorporated best practices , such as capturing all activities , sequencing all activities , integrating activities horizontally and vertically , establishing the critical path for all activities , identifying float between activities , conducting a schedule risk analysis , and updating the schedule using logic and durations to determine dates .

dod concurred with our recommendation , and we discuss later in this report the status of dod's efforts to address this recommendation .

in march 2009 , we published the cost guide to address a gap in federal guidance about processes , procedures , and practices needed for ensuring reliable cost estimates .

the cost guide provides a consistent methodology based on best practices that can be used across the federal government to develop , manage , and evaluate capital program cost estimates .

the methodology is a compilation of characteristics and associated best practices that federal cost estimating organizations and industry use to develop and maintain reliable cost estimates throughout the life of an acquisition program .

in may 2012 , we issued the schedule guide as a companion to the cost guide .

a consistent methodology for developing , managing , and evaluating capital program cost estimates includes the concept of scheduling the necessary work to a timeline , as discussed in the cost guide .

simply put , schedule variances are usually followed by cost variances .

because some program costs , such as labor , supervision , rented equipment , and facilities , cost more if the program takes longer , a reliable schedule can contribute to an understanding of the cost impact if the program does not finish on time .

in addition , management tends to respond to schedule delays by adding more resources or authorizing overtime .

further , a schedule risk analysis allows for program management to account for the cost effects of schedule slippage when developing the life - cycle cost estimate .

a cost estimate cannot be considered fully credible if it does not account for the cost effects of schedule slippage .

a well - planned schedule is a fundamental management tool that can help government programs use public funds effectively by specifying when work will be performed in the future and measuring program performance against an approved plan .

moreover , as a model of time , an integrated and reliable schedule can show when major events are expected to occur as well as the completion dates for all activities leading up to them , which can help determine if the program's parameters are realistic and achievable .

a program's success depends in part on the quality of its schedule .

we found that the schedule for the deams program did not meet best practices .

the cost estimate did meet best practices , but the issues associated with the schedule could negatively affect the cost estimate .

specifically , the deams schedule supporting the february 2012 milestone b decision partially or minimally met the four characteristics for developing a high - quality and reliable schedule — it was not comprehensive , well - constructed , credible , or controlled .

in addition , our assessment of the october 2012 updated schedule found that it was not comprehensive , well - constructed , and credible and thus was also not reliable .

in contrast , the deams cost estimate fully or substantially met the four characteristics of a high - quality and reliable cost estimate — it was comprehensive , well - documented , accurate , and credible .

however , because the cost estimate is based on the schedule , the unreliability of the schedule could affect the cost estimate .

for example , if there are schedule slippages , the costs for the program could be greater than currently estimated .

our analysis found that the deams program partially met three and minimally met one of the characteristics of a reliable schedule estimate and therefore did not provide the information needed to support the february 2012 milestone b decision ( see table 1 ) .

appendix i contains our detailed analysis of the deams schedule estimate .

the success of any program depends on having a reliable schedule of the program's work activities that will occur , how long they will take , and how the activities are related to one another .

as such , the schedule not only provides a roadmap for systematic execution of a program , but also provides the means by which to gauge progress , identify and address potential problems , and promote accountability .

comprehensive .

a schedule should reflect all activities as defined in the program's work breakdown structure , including activities to be performed by the government and the contractor ; the resources ( eg , labor , materials , and overhead ) needed to do the work ; and how long each activity will take .

we found that the schedule used to support the milestone b decision included the activities to be performed by both the government and contractor for releases 1 through 3 of increment 1 .

however , the schedule did not reflect activities to be performed for releases 4 through 6 of increment 1 and for releases 1 and 2 of increment 2 .

the deams program manager stated that a comprehensive schedule for increment 1 that included the activities for all six releases would not be completed until mid - 2014 .

the program manager also stated that increment 2 had not been included because program officials did not know the detailed activities to be performed that far in advance .

to address this issue , the deams program office developed a roadmap depicting releases 1 through 6 of increment 1 and releases 1 and 2 of increment 2 with a full deployment date of fiscal year 2017 .

however , the program office did not provide a schedule that supported the estimated dates in the roadmap .

a comprehensive schedule should reflect all of a program's activities and recognize that uncertainties and unknown factors in schedule estimates can stem from , among other things , data limitations .

as such , a schedule incorporates different levels of detail depending on the information available at any point in time .

that is , near - term effort will be planned in greater detail than long - term effort .

effort beyond the near term that is less well defined is represented within the schedule as long - term planning packages .

planning packages are a summarization of the work to be performed in the distant future with less specificity .

planning packages are planned at higher levels such that a single activity may represent several months of effort , generic work to be accomplished , or even a future contract or phase .

planning packages can be used as long as they are defined and estimated as well as possible .

by not including all work for all deliverables for both increments and all releases , the deams program could incur difficulties resulting from an incomplete understanding of the plan and what constitutes a successful conclusion for the program .

deams program officials provided a draft of the schedule management plan that documented their intent to use a planning package approach when updating the deams schedule in the future .

resources were identified in the schedule ; however , the resources were not assigned to specific activities in the schedule .

although our analysis determined that activity durations were manageable and reasonably estimated , resource availability affects estimates of work and its duration , as well as resources that will be available for subsequent activities .

deams program management officials told us that government resource allocations are determined by management as needed .

these officials told us that management does not necessarily take into consideration the resource information captured in the schedule when determining resource allocations .

however , deams officials did not provide any documentation that specific resources were being mapped to the schedule .

as mentioned above , the estimates of work required and duration for an activity are tied to the availability of resources ; therefore , the lack of such information could hinder management's ability to compute total labor and equipment hours , calculate total project and per - period cost , resolve resource conflicts , and establish the reasonableness of the plan .

well - constructed .

a schedule should be planned so that critical project dates can be met .

to meet this objective , all activities should be logically sequenced — that is , listed in the order in which they are to be carried out .

in particular , activities that must finish prior to the start of other activities ( i.e. , predecessor activities ) , as well as activities that cannot begin until other activities are completed ( i.e. , successor activities ) , should be identified and their relationships established .

the establishment of a critical path is necessary for examining the effects of any activity slipping along this path .

the calculation of a critical path determines which activities drive the project's earliest completion date .

the schedule should also identify total float so that the schedule's flexibility can be accurately determined .

we found that the majority of logic used to sequence the activities within the schedule was generally error - free with a minimal use of lags , clearly indicating to program management the order of activities that must be accomplished .

although we found few missing logic relationships for release 3 of increment 1 , approximately 25 percent of the remaining activities for releases 1 and 2 of increment 1 were missing logic relationships .

because interdependencies among activities were not identified , the deams program management officials' ability to properly calculate dates and predict changes in the future is impaired .

we found a significant number of constraints for activities throughout the schedule .

a schedule is intended to be a dynamic , proactive planning and risk mitigation tool that models the program and can be used to track progress toward important milestones .

schedules with constrained dates can portray an artificial or unrealistic view of the project .

constraints should be minimized because they can create false dates in a schedule .

further , the schedule did not have a valid critical path and identified critical activities more by their constraints than by logic .

rather than relying on constraints , the schedule should use logic and durations in order to reflect realistic start and completion dates for activities .

successfully identifying the critical path relies on several factors , such as capturing all activities , properly sequencing activities , and assigning resources , which , as noted earlier , had not been done .

without a valid critical path , management cannot focus on activities that will have detrimental effects on the key project milestones and deliveries if they slip .

we found that total float was not reasonable , and that in some instances unreasonable float was a direct result of improper sequencing or missing logic .

releases 1 and 2 of increment 1 showed that 25 percent of program activities had total float equal to or greater than 392 working days , meaning that those activities could slip almost 2 working years and not affect the end date of the program .

without knowledge of the reason float exists for a program activity , management cannot determine the flexibility of tasks and therefore cannot properly reallocate resources from tasks that can safely slip to tasks that cannot slip without adversely affecting the estimated program completion date .

credible .

a schedule should be horizontally and vertically integrated .

a horizontally integrated schedule links products and outcomes with other associated sequenced activities , which helps verify that activities are arranged in the right order to achieve aggregated products or outcomes .

a vertically integrated schedule ensures that the start and completion dates for activities are aligned with such dates on subsidiary schedules supporting tasks and subtasks .

such mapping or alignment among subsidiary schedules enables different groups — such as government teams and contractors — to work to the same master schedule , and provides assurance that the representation of the schedule to different audiences is consistent and accurate .

a schedule risk analysis should also be performed using statistical techniques to predict the level of confidence in meeting a program's completion date .

we found that release 3 of increment 1 exhibited horizontal integration , but releases 1 and 2 of increment 1 did not because date constraints prevented forecasted dates from being calculated realistically for future activities .

if the schedule lacks horizontal integration , activities whose durations are greatly extended will have no effect on key milestones reflected in the schedule .

we further found that releases 1 and 2 of increment 1 did not demonstrate vertical integration .

for example , we found instances where the start dates for the same activities differed by 1 day , 1 week , and 1 month between the government and contractor schedules .

unless the schedule is vertically integrated , lower - level schedules will not be consistent with upper - level schedule milestones , affecting the integrity of the entire schedule and the ability of different teams to work to the same schedule expectations .

deams program management officials stated that a schedule risk analysis had not been conducted because the schedule had not been approved to be used as a baseline schedule — the target schedule against which program performance can be measured , monitored , and reported .

these officials stated that although this analysis had not been conducted , they were collecting best - case and worst - case durations from the contractor with their periodic schedule delivery .

these data can be used by program management to calculate more reliable estimates of durations for future activities .

however , we found that the schedule did not contain best - or worst - case duration data for 600 of 605 detailed activities .

for the five instances where duration data were contained in the schedule , we determined that four were questionable because two activities were already completed and two had already exceeded the worst - case estimate .

if a schedule risk analysis is not conducted , program management cannot determine the likelihood of the project's completion date , how much schedule risk contingency is needed to provide an acceptable level of certainty for completion by a specific date , risks most likely to delay the project , how much contingency reserve each risk requires , and the paths or activities that are most likely to delay the project .

as discussed later , the lack of a schedule risk analysis can affect the credibility of the cost estimate .

controlled .

a schedule should be continuously updated using logic , durations , and actual progress to realistically forecast dates for program activities .

a schedule narrative should accompany the updated schedule to provide decision makers and auditors a log of changes and their effect , if any , on the schedule time frame .

the schedule should be analyzed continuously for variances to determine when forecasted completion dates differ from planned dates .

this analysis is especially important for those variations that affect activities identified as being in a program's critical path and that can affect a scheduled completion date .

a baseline schedule should be used to manage the program scope , the time period for accomplishing it , and the required resources .

we found that deams program management met weekly to discuss proposed schedule changes and updated the schedule's progress .

however , a schedule narrative was not prepared by deams program management .

in addition , we found a number of date anomalies throughout the schedule , including activities with planned start dates scheduled to occur in the past and activities with actual finish dates scheduled to occur in the future .

we also found a number of out - of - sequence activities in the schedule — activities that started before their predecessors finished , in contradiction to the planned sequence .

if the schedule is not continually monitored to determine when forecasted completion dates differ from planned dates , then it cannot be used to determine whether schedule variances will affect work needed to be accomplished at a future date .

we also found that there was no baseline schedule that could be used to measure program performance .

deams program management officials did maintain a schedule narrative document that contained a list of custom fields and assumptions ; however , the document did not explain ground rules and assumptions , justifications for logic , and other unique features of the schedule .

these officials stated that other process documents were being developed .

without a formally established baseline schedule to measure performance against , management cannot identify or mitigate the effect of unfavorable performance .

our assessment of the updated schedule dated october 2012 found that it was not comprehensive , well - constructed and credible .

although the deams program manager stated that the government and contractor activities for releases 1 through 3 of increment 1 had been integrated in the october 2012 schedule , this schedule was not comprehensive .

specifically , it excluded activities for both the government and contractor related to releases 4 through 6 of increment 1 and releases 1 and 2 of increment 2 .

if activities are missing from the schedule , then other best practices will not be met .

the schedule was also missing relationships for a significant number of the remaining milestones and activities .

in addition , the october 2012 schedule included a significant number of date constraints with little or no justification for their use in the schedule .

similar to the previous schedule , the updated schedule presented unreasonable float throughout and did not include a schedule risk analysis .

as a result of these shortcomings , the updated schedule was not reliable .

further , program officials could not rely on this schedule as a baseline to effectively manage and monitor program performance .

in may 2013 , program management officials provided another updated deams schedule that they stated included some improvements , but they acknowledged that it contained issues that prevented the schedule from meeting best practices .

for example , these officials stated that the may 2013 schedule included long - term planning packages for activities related to releases 4 through 6 of increment 1 and releases 1 and 2 of increment 2 , integrated government and contractor activities , and reduced the number of constraints and out - of - sequence activities in the schedule .

however , the officials acknowledged that several outstanding issues remained related to , for example , vertical and horizontal integration , missing logic relationships , and the lack of a schedule risk analysis .

although we did not independently assess the may 2013 schedule to determine whether it met the four schedule characteristics , we did confirm that it included long - term planning packages , which are needed to create a complete picture of the program from start to finish and to allow the monitoring of a program's critical path .

the results of our analyses of the schedule that supported the february 2012 milestone b decision and october 2012 deams schedule reflect similar weaknesses to those we reported in october 2010 .

therefore , given the findings of this review , our prior recommendation for improving the deams schedule remains valid .

we found that the deams program fully or substantially met the four characteristics of a reliable cost estimate to support the milestone b decision , as shown in table 2 .

however , because the cost estimate relies on dates derived from the schedule and we are questioning the reliability of the forecasted program dates , the credibility of the cost estimate can be affected .

appendix ii contains our detailed analysis of the deams cost estimate .

a reliable cost estimate is critical to the success of any program .

such an estimate provides the basis for informed investment decision making , realistic budget formulation and program resourcing , meaningful progress measurement , proactive course correction when warranted , and accountability for results .

comprehensive .

a cost estimate should include costs of the program over its full life cycle , provide a level of detail appropriate to ensure that cost elements are neither omitted nor double - counted , and document all cost - influencing ground rules and assumptions .

the cost estimate should also completely define the program and be technically reasonable .

we found that the cost estimate for deams was comprehensive .

the cost estimate included both government and contractor costs of the program over its life cycle — from the inception of the program through design , development , deployment , and operation and maintenance — as outlined in the roadmap prepared by program officials .

as stated earlier , the roadmap provided an overall summary of the program's key phases ( increments and releases ) and the expected milestones for completion .

the cost estimate also included an appropriate level of detail , which provided assurance that cost elements were neither omitted nor duplicated , and included documentation of all cost - influencing ground rules and assumptions .

the cost estimate documentation included the purpose of the cost estimate , a technical description of the program , and technical risks ( eg , the resolution for any identified deficiencies ) .

well - documented .

a cost estimate should be supported by detailed documentation that describes how it was derived and how the expected funding will be spent in order to achieve a given objective .

therefore , the documentation should capture such things as the source data used , the calculations performed , the results of the calculations , the estimating methodology used to derive each work breakdown structure element's cost , and evidence that the estimate was approved by management .

we found that the cost estimate for deams was well - documented .

the cost estimate captured such things as the source data used , the calculations performed and the results of the calculations , and the rationale for choosing a particular estimating methodology .

this information was captured in such a way that the data used to derive the estimate can be traced back to , and verified against , the sources so that the estimate can be easily replicated .

however , there was no discussion of efforts taken , if any , to ensure the reliability of the data used .

the deams program management office presented evidence of receiving approval of the estimate through briefings to management .

accurate .

a cost estimate should be based on an assessment of most likely costs ( adjusted properly for inflation ) , updated to reflect significant changes and grounded in a historical record of cost estimating and actual experiences on other comparable programs .

we found that the cost estimate for deams was accurate .

the cost estimate provided results that were substantially unbiased , and the cost model detailed the calculations and inflation indexes underlying the estimate .

calculations within the model could be traced back to supporting documentation .

the cost estimate was updated regularly to reflect significant changes in the program and updated annually to incorporate actual costs expended in prior fiscal years .

further , the cost estimate was based on historical data .

however , the cost estimate did not discuss variances between planned and actual costs , which would enable estimators to assess how well they are estimating program costs and to identify lessons learned .

credible .

a cost estimate should discuss any limitations of the analysis because of uncertainty or biases surrounding data or assumptions .

in addition , the estimate's results should be cross - checked and reconciled to an independent cost estimate to determine whether other estimating methods produce similar results .

we found that the cost estimate was credible .

the deams program management office conducted a risk and uncertainty analysis by identifying the cost elements with the greatest degree of uncertainty , determining the cost drivers for the program , and identifying the impact of changing major ground rules and cost driver assumptions .

an independent cost estimate developed by the air force cost analysis agency was reconciled to the program's estimate .

however , a sensitivity analysis was not completed for each of the major cost drivers .

as a result , the cost estimator will not have a clear understanding of how each major cost driver is affected by a change in a single assumption and thus which scenario most affects the cost estimate .

further , as discussed previously , because a schedule risk analysis was not performed as required by best practices , the cost estimate does not include a contingency amount to account for any schedule slippage that could occur .

to the extent that a schedule slippage does occur , there could ultimately be an impact on the cost estimate .

the air force did not meet best practices in developing a schedule for the deams program .

as a result , this raises questions about the credibility of the deadline for acquiring and implementing deams to provide needed functionality for financial improvement and audit readiness .

because of these questions , the cost estimate , while following best practices , may not fully capture all costs associated with the program , particularly if there is significant schedule slippage .

moreover , air force management did not have a reliable schedule estimate when making its decision to invest in the deams program .

it is critical to correct the deficiencies identified with the schedule estimate to help ensure that the projected spending for this program is being used in the most efficient and effective manner .

to help provide for the successful implementation of deams , we recommend that the secretary of the air force direct the under secretary of the air force , in his capacity as the chief management officer , to consider and make any necessary adjustments to the deams cost estimate after addressing our prior recommendation to adopt scheduling best practices .

we provided a draft of this report to dod for review and comment .

in its written comments , reprinted in appendix iii , dod concurred with our recommendation .

dod also provided a technical comment , which we incorporated .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the appropriate congressional committees , the secretary of defense ; the secretary of the air force ; the assistant secretary of defense ( acquisition ) ; the deputy chief management officer ; the under secretary of defense ( comptroller ) ; the under secretary of the air force , in his capacity as the chief management officer of the air force ; and the program manager for deams .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staffs have any questions about this report , please contact asif a. khan at ( 202 ) 512-9869 or khana@gao.gov or nabajyoti barkakati at ( 202 ) 512-4499 or barkakatin@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff members who made key contributions to this report are listed in appendix iv .

this appendix provides the results of our analysis of the extent to which the defense enterprise accounting and management system ( deams ) schedule estimate supporting the february 2012 milestone b decision met the characteristics of a high - quality , reliable schedule .

table 3 provides the detailed results of our analysis .

gao's methodology includes five levels of compliance with its best practices .

“not met” means the program provided no evidence that satisfies any of the criterion .

“minimally met” means the program provided evidence that satisfies a small portion of the criterion .

“partially met” means the program provided evidence that satisfies about half of the criterion .

“substantially met” means the program provided evidence that satisfies a large portion of the criterion .

“fully met” means the program provided evidence that completely satisfies the criterion .

this appendix provides the results of our analysis of the extent to which the defense enterprise accounting and management system ( deams ) cost estimate supporting the february 2012 milestone b decision met the characteristics of a high - quality cost estimate .

table 4 provides the detailed results of our analysis .

gao's methodology includes five levels of compliance with its best practices .

“not met” means the program provided no evidence that satisfies any of the criterion .

“minimally met” means the program provided evidence that satisfies a small portion of the criterion .

“partially met” means the program provided evidence that satisfies about half of the criterion .

“substantially met” means the program provided evidence that satisfies a large portion of the criterion .

“fully met” means the program provided evidence that completely satisfies the criterion .

in addition to the contacts named above , cynthia jackson ( director ) , karen richey ( assistant director ) , beatrice alff , jennifer echard , patrick frey , and jason lee made key contributions to this report .

