the recession that began in december 2007 caused states and localities significant immediate fiscal pressures in the form of reduced tax revenues and increased demand for certain programs , including criminal justice programs .

under the american recovery and reinvestment act of 2009 ( recovery act ) , the existing edward byrne memorial justice assistance grant ( jag ) program , which the department of justice's ( doj ) bureau of justice assistance ( bja ) administers , provided an additional $2 billion to state and local governments through 4-year , formula - based grants .

jag program funds support local efforts to prevent and control crime and improve the criminal justice system through activities such as drug reduction and domestic violence prevention .

the recovery act jag program also attempts to meet the overall purposes of the recovery act which include promoting economic recovery , making investments to provide long - term economic benefits , and stabilizing state and local government budgets to minimize and avoid reductions in essential services .

the recovery act emphasizes the need for accountability and transparency in the expenditure of recovery act funds and makes it a central principle of the act's implementation .

importantly , the transparency that is envisioned for tracking recovery act spending and results is an extensive undertaking for the federal government and tracking billions of dollars that are being disbursed to thousands of recipients is an enormous effort .

the administration expects that achieving this degree of visibility will be iterative , whereby both the reporting process and the information recipients provide improve over time and , if successful , could be a model for transparency and oversight beyond the recovery act .

thus , recovery act jag funding recipients are required to meet federal reporting requirements that are in addition to the requirements doj established for non - recovery act jag program recipients .

specifically , recovery act jag recipients are required to provide quarterly status reports on the amount and use of such funds and information concerning jobs created or retained by the use of these funds .

other than the additional reporting requirements , however , the recovery act jag program did not alter the structure , purpose , or funding allocation methods of the preexisting jag program .

consistent with the preexisting program , states and localities can use their recovery act jag grant funds over a period of 4 years to support a range of activities in seven broad statutorily established program areas: ( 1 ) law enforcement ; ( 2 ) prosecution and courts ; ( 3 ) crime prevention and education ; ( 4 ) corrections ; ( 5 ) drug treatment and enforcement ; ( 6 ) program planning , evaluation , and technology improvement ; and ( 7 ) crime victim and witness programs .

across the seven areas , recipients can use jag funds for state and local initiatives — which are generally designed to improve a program , service , or system , or support training , personnel , or equipment .

you requested that we examine the recovery act jag program .

this report addresses the following questions: how are recovery act jag funds awarded and how have recipients in selected states and localities used their awards ? .

what challenges , if any , have selected recovery act jag recipients reported in complying with recovery act reporting requirements ? .

to what extent do states share promising practices related to the use and management of recovery act jag funds , and how , if at all , does doj encourage information sharing ? .

to what extent are doj's recovery act jag performance measures consistent with promising practices ? .

this report expands upon our may 2010 recovery act report , which described selected states' uses of jag funding and accountability provisions related to recovery act jag , as well as our july 2009 recovery act report , which discussed observations of recovery act jag fund obligations and planned uses of the funds .

in july 2009 , we reported that the 16 states and the district of columbia in our review had not obligated their total recovery act jag awards , in part because they were determining how the funds would be used and passed through to local entities .

in our may 2010 report , we visited 7 of the states from our july 2009 sample and found that all 7 had obligated their recovery act jag awards and reported planned uses consistent with their states' priorities and bja's allowable uses of jag funds .

to conduct our work for this review , we evaluated recovery act jag awards in a nonprobability sample of 14 states .

the states we selected for our review of recovery act jag spending are a subset of a 16-state ( plus the district of columbia ) sample that we used for our earlier recovery act work , but we did not include florida , new jersey , or the district of columbia since the doj office of the inspector general was already engaged in audit work on the jag program in these states .

the awards to the 14 states in this review accounted for approximately 50 percent of all of the recovery act jag funds provided .

where statements are attributed to state and local officials , we did not analyze state and locality data sources but relied on state and local officials and other state sources for relevant state data and materials .

we also tabulated and analyzed some recipient - reported data submitted to recovery.gov for the quarterly reports that had been due as of june 30 , 2010 .

we used these data because they are the official source of recovery act spending data and determined that they were sufficiently reliable for the purposes of this report .

we reviewed the relevant guidance doj provides to recovery act jag recipients on financial and program reporting as well as recovery act guidance related to federal recipient reporting to understand federal reporting requirements and associated time frames and interviewed doj officials who administer the recovery act jag program .

we also conducted interviews with officials in the state agencies that administer recovery act jag funds — known as state administering agencies ( saa ) — in the 14 states we selected for review .

in addition , we selected a nonprobability sample of 62 local law enforcement agencies and other recipients receiving recovery act jag funds within these 14 states and conducted interviews with cognizant officials from those jurisdictions that received the awards .

these jurisdictions were selected based on award amount , degree of project completion , planned use of funds , and how they received their funds ( either as passed - through funding from their saa or localities who received awards directly from doj — and in some cases as part of disparate jurisdictions ) .

our interviews addressed the use and perceived impact of recovery act jag funds , program performance measurement and reporting challenges , and the sharing of promising practices .

findings from our nonprobability samples cannot be generalized to all states and localities that were recipients of recovery act jag funds ; however , our samples provided us with illustrative examples of uses of funds , oversight processes , and reporting issues .

finally , we discussed doj's performance measurement efforts with doj staff and conducted an assessment of the performance measures applicable to the recovery act jag activities commonly undertaken by the grant recipients in our sample to assess the extent to which they contained elements consistent with promising practices .

specifically , from doj's 86 recovery act jag performance measures , we selected a nonprobability sample of 19 that were ( 1 ) related to the largest share of reported recovery act jag expenditures across certain activity types and ( 2 ) most often reported by the recipients in our sample .

we then analyzed this sample against a set of key characteristics that we have previously reported as being associated with individual measures in successful performance measurement systems .

see appendix i for a more complete description of our methodology and appendix ii for a list and definition of the 19 performance measures we assessed .

we conducted this performance audit from january 2010 through october 2010 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

according to doj officials , the jag program provides states and localities with federal funds to support all components of the criminal justice system while providing a great deal of flexibility in how they do so .

recovery act jag - funded projects may provide services directly to communities or improve the effectiveness and efficiency of criminal justice systems , processes , or procedures .

like non - recovery act jag funds , recovery act jag awards are to be used within the context of seven statutorily established areas .

the seven statutorily established areas and examples of how jag funds may be used within these areas are outlined in table 1 below .

financial requirements and internal controls doj requires that all recovery act jag award recipients establish and maintain adequate accounting systems , financial records , and internal controls to accurately account for funds awarded to them and their subrecipients .

award recipients must also ensure that recovery act jag funds are accounted for separately and not commingled with funds from other sources or federal agencies .

if a recipient or subrecipient's accounting system cannot comply with the requirement to account for the funds separately , then the recipient / subrecipient is to establish a system to provide adequate fund accountability for each project that has been awarded .

recipient reporting and performance measurement requirements all state and local recovery act jag recipients are required to meet both recovery act and bja quarterly reporting requirements .

the recovery act requires that nonfederal recipients of recovery act funds ( including recipients of grants , contracts , and loans ) submit quarterly reports , which include a description of each project or activity for which recovery act funds were expended or obligated , and an estimate of the number of jobs created and the number of jobs retained by these projects and activities .

in particular , the recovery act requires recipients to report on quarterly activities within 10 days of the end of each quarter .

for recovery act jag grants , bja has added language in the grant awards that requires that grantees meet the federal reporting requirements and provides sanctions if they do not .

because the recovery act jag program includes a pass - through element , saas must gather the required data elements for all pass - through recipients during the same 10-day time frame in order to meet their own reporting requirements .

separately , bja requires that states and those localities receiving their funds directly through doj report on their progress in meeting established performance measures related to funded activities .

bja also requires all recovery act jag recipients to submit an annual programmatic report with narrative information on accomplishments , barriers , and planned activities , as well as a quarterly financial status report as required by the office of management and budget ( omb ) .

in early 2010 , after a year - long development and initial refinement period , bja officially launched a new , online performance measurement tool ( pmt ) to improve upon its previous grants management system and allow online performance measurement data submission .

bja plans to use the pmt to help evaluate performance outcomes in at least 13 grant programs , including recovery act jag .

according to the standards for internal control in the federal government , activities need to be established to monitor performance measures and indicators .

such controls should be aimed at validating the integrity of performance measures and indicators — in other words , ensuring they are reliably designed to collect consistent information from respondents .

bja is also planning on using the pmt to assess performance measurement data and direct improvement efforts in 5 additional programs by the end of 2010 .

however , given that grantees were not required to submit their pmt reports until the second quarter of fiscal year 2010 , some grantees did not begin submitting their first completed pmt reports until march 2010 .

bja requires recovery act jag recipients to use the pmt for quarterly reporting on their status in meeting the recovery act jag program's 86 individual performance measures , such as percent of staff who reported an increase in skills and percent of recovery act jag - funded programs that have implemented recommendations based on program evaluation .

recipients of recovery act jag funding receive their money in one of two ways — either as a direct payment from bja or as a pass - through from an saa — and they reported using their funds primarily for law enforcement and corrections .

according to state officials from our sample states , more than half of the funding that localities received as pass - through awards from their saas was obligated specifically for law enforcement and corrections support , while about a quarter of the funds that recipients of direct awards received was dedicated exclusively to law enforcement .

regardless of the source , officials in states and localities reported using recovery act jag funds to preserve jobs and activities that without recovery act jag funds would have been cut or eliminated ; however , expenditure rates across states in our sample showed considerable variation .

bja allocates recovery act jag funds the same way it allocated non - recovery act jag funds by combining a statutory formula determined by states' populations and violent crime statistics with a statutory minimum allocation to ensure that each state and eligible territory receives some funding .

under this statutory jag formula , the total award allocated to a state is derived from two sources , each given equal value: half of the allocation is based on a state's respective share of the u.s. population , and the other half is based on the state's respective share of violent crimes , as reported in the federal bureau of investigation's ( fbi ) uniform crime report ( ucr ) part i for the 3 most recent years for which data are available .

of such amounts awarded to states , 60 percent of a state's allocation is awarded directly to a saa in each of the states , and each saa must in turn allocate a formula - based share of these funds to local entities , which is known as the “pass - through portion.” bja awards the remaining 40 percent of the state's allocation directly to eligible units of local government within the state .

the eligible units of local governments that receive direct awards from doj either get them individually or as part of awards to “disparate” jurisdictions which jointly use correctional facilities or prosecutorial services .

in the cases of the disparate jurisdiction awards , to qualify for funds , the units of local government involved must submit a joint application to doj and sign a memorandum of understanding ( mou ) outlining how they will share funds .

they also are to determine amongst themselves which local government will serve as the fiscal agent , and thereby be responsible for reporting to doj on behalf of the others and ensuring that all members of the disparate jurisdiction follow applicable federal financial guidance and meet reporting requirements .

the following figure illustrates the participation of localities in a disparate jurisdiction award .

in the example , high point city is the fiscal agent and greensboro city and guilford county are both subrecipients .

the total awards that doj allocates directly to units of local government — the 40 percent share — are to be based solely on the local jurisdiction's proportion of the state's total violent crime 3-year average based on reports from the fbi's ucr part i .

units of local government that could receive $10,000 or more after the bureau of justice statistics ( bjs ) analyzes the ucr data are eligible for a direct award from doj .

funds that could have been distributed to localities through awards of less than $10,000 are grouped together and then provided to the saa .

under the jag program , saas and direct grant recipient agencies may draw down funds from the treasury immediately rather than requiring up - front expenditure and documentation for reimbursement .

such funds are required to be deposited into an interest - bearing trust fund and , in general , any interest income that states and localities earn from the funds drawn down is to be accounted for and used for program purposes .

table 2 shows the total allocation of recovery act jag funding across our sample states , including the grant amounts bja made directly to the saas ( the 60 percent share ) ; the number of pass - through grants the saas made in turn ; and the grant amounts and number of grants bja made directly to localities ( the 40 percent share ) .

the 14 states in our sample received $1,033,271,865 in jag recovery act funds , which was more than half of the funds awarded nationwide for the program .

of the total of 1,338 direct awards that doj made to localities in the 14 states in our sample , approximately one - third of these direct awards , or 436 , went to disparate jurisdictions and are split by agreement among the designated jurisdictions .

under these arrangements , one jurisdiction functions as the prime recipient and fiscal agent who is supposed to be responsible for submitting all programmatic or financial reports on behalf of the disparate group as well as monitoring other neighboring localities' use of funds on activities covered by the grants .

in our sample states , while one - third of the total number of direct grant awards were made to disparate jurisdictions , these arrangements accounted for 72 percent of the funds doj awarded directly to local recipients .

for example , in illinois , 100 percent of direct awards were provided to disparate jurisdictions , and in 8 of the other 13 states doj awarded more than 70 percent of funds in this manner .

officials we met with in localities that received funds under this type of arrangement reported that they provided varying amounts of oversight in there role as fiscal agent .

the doj inspector general has raised the oversight of subgrantee awards as an issue for doj's attention and has recommended that doj develop further training for recipients ; doj concurred with the recommendation .

table 3 summarizes the distribution of direct award funds to disparate jurisdictions in our sample states .

the 14 saas in our sample received more than $630 million collectively as their share of the recovery act jag funds .

jag statutory provisions require that each state pass - through no less than a specific designated minimum percentage of the funds that they receive as subgrants to localities , municipal governments , and nonprofit organizations .

among our sample states , this mandatory pass - through percentage varied from a high of 67.3 percent in california to a low of 35.5 percent in massachusetts .

saas are also allowed to retain up to 10 percent of the funds that they receive for administrative purposes .

the completion of these pass - through award processes occurred at different rates across the 14 states that we sampled and resulted in some states expending their recovery act jag funds faster than others .

as of june 30 , 2010 , the saas we reviewed had made nearly all of their pass - through awards , with the exception of mississippi and pennsylvania .

in addition , many local pass - through recipients reported that there was a time lag in being reimbursed by their saas for funds that they had spent .

additional information on amounts drawn down and expended is included in appendix iv .

according to recovery.gov , the saas and localities that received grant funds directly from doj in our sample of 14 states were awarded approximately $1.028 billion in recovery act jag funds .

this amount represents about 52 percent of the nearly $2 billion awarded to saas and directly funded localities across the nation .

as of june 30 , 2010 , the saas and the directly funded localities in our sample expended over $270.7 million or about 26.4 percent of the total amount awarded .

recovery act jag fund recipients may spend their respective awards over a 4-year period .

as depicted in figure 2 below , in the 14 states in our sample , the expenditure of recovery act jag funds generally lags behind the amount of funds awarded by the saas and drawn down .

for example , as of june 30 , 2010 , california — whose saa received the largest direct award in our sample — had expended only about $6.6 million of the $135 million , or nearly 5 percent , of jag grant funds the state received .

texas reported expending the most — more than $37 million — after combining expenditures the saa made independently with the expenditures made by the more than 400 pass - through recipients .

california saa officials stated they delayed in awarding jag funds because of the design of two new programs focused on probation and drug offender treatment services that accounted for $90 million of the $135 million in grant funds the saa received .

as of june 30 , 2010 , 100 percent of california's subrecipients were finalized through grant award agreements , but many projects have recently become fully operational resulting in the slow expenditure of funds which are handled on a reimbursement basis .

in pennsylvania , saa officials said the state faced two challenges in expending recovery act jag funds quickly: ( 1 ) a state budget impasse , which delayed the allocation of recovery act jag awards ; and ( 2 ) recovery act jag funding for state projects focused on technology costs , which require lengthy procurement times .

further , they noted that state pass - through funding to localities is recorded on a quarterly basis after expenses are incurred , so the pace of expenditure could be somewhat misleading .

other saa officials we contacted cited additional reasons for more slowly expending recovery act jag funds .

for example , all of the saas we contacted have procedures in place that require subrecipients to make their purchases up - front with local funds and request reimbursement from the saa after documentation is received .

two states we contacted have policies that restricted recovery act jag funding to shorter time limits with an option for renewal rather than providing localities authority to use grants during the 4-year grant period applicable to the initial recipient of the grant .

in addition , 1 of the 14 saas had a preference to retain recovery act jag funds and expend funds gradually in longer - term projects , such as technology improvements , as allowed during the 4-year grant period .

using funds received through direct and pass - through awards , all states reported using recovery act jag funds to prevent staff , programs , or essential services from being cut .

in addition , local officials reported that without recovery act jag funding law enforcement personnel , equipment purchases , and key local law enforcement programs would have been eliminated or cut .

saas reported that they passed through about 50 percent of their funds and collectively they planned to use the largest share — about 30 percent , or almost $168 million — for law enforcement purposes .

direct recipients reported that funds were most often to be used for multiple purposes .

officials from all states in our sample reported using recovery act jag funds to prevent staff , programs , or essential services from being cut .

also , 19 percent of localities in gao's sample , or officials in 12 of 62 localities , provided specific examples of ongoing local law enforcement programs or activities , such as juvenile recidivism reduction programs , prisoner re - entry initiatives , and local foot or bicycle patrols in high - crime neighborhoods that would not have continued without the addition of these funds .

table 4 provides some examples that state and local recipients reported regarding how they used recovery act jag funds to help them preserve jobs and essential services .

saas reported that they awarded the largest share — about 30 percent , or almost $168 million — for law enforcement purposes , such as hiring or retaining staff who might otherwise have been laid off , or purchasing equipment in direct support of law enforcement activities , as shown in figure 3 .

in addition , saas reported awarding approximately 24 percent , or more than $137 million , to support corrections programs or activities .

saas reported allocating the smallest share for crime victim and witness programs , 2.1 percent or approximately $11.8 million .

within the category of law enforcement , equipment expenditures spanned a wide range of law enforcement gear , but vehicles and weapons purchases were often reported .

frequent types of purchases included: police cruisers ; weapons , such as tasers , and ammunition ; communications devices , such as hand - held two - way radios , and mobile laptops in police cruisers ; and safety equipment , such as protective vests and shields .

see appendix v for examples of selected equipment purchased with jag funds .

overall , localities in 13 out of the 14 states we contacted reported using recovery act jag funds to maintain positions or pay officer overtime for activities related to law enforcement .

individual saas , however , reported obligating their recovery act jag funds in a variety of ways as shown in table 5 .

the percentages do not include the funds that the saas retained for administrative purposes or funds not yet awarded .

nearly all saas in our sample states , except for iowa , which reported using most of its funds to support drug enforcement activities , reported using recovery act jag funds to support law enforcement activities .

with the exception of iowa , at the state level the share of recovery act jag funds used to support direct equipment purchases and personnel expenses ranges from a high of 65.8 percent in texas to a low of 1.7 percent in new york .

localities in more than a third of the states in our sample ( 5 of 14 ) reported that uncertainties about the availability of future jag funding steered them toward one - time equipment purchases , such as the procurement of license plate readers and in - car laptop computers , rather than investments , such as hiring new personnel , that would require an ongoing commitment of funds and whose sustainability could be threatened when recovery act jag funds expire .

in addition , officials in about a quarter of the localities in our sample ( 15 ) discussed how they coordinate the use of their recovery act jag funds with resources that they received from other federal funding streams .

for example , the cities of austin , texas and greensboro , north carolina were each waiting to receive a separate federal grant specifically for the purpose of hiring police officers so that they could determine whether to spend recovery act jag funds to equip the officers once hired .

see figure 4 for an interactive map with additional information on recovery act jag funds purchases and activities in our sample states .

as shown in figure 5 , data reported by direct recipient localities in the 14 states that we sampled indicate that they obligated the largest share — more than 63 percent , or over $256 million — for multiple purposes and 21.5 percent , or about $86.8 million , to directly support law enforcement programs or activities .

program planning , evaluation , and technology improvement funds , which accounted for approximately 8 percent of spending , were primarily used to enhance communications equipment or purchase computer hardware and software for all types of criminal justice agencies and programs .

based on the information grantees reported to recovery.gov , the number of the projects reported has dropped slightly over the last three reporting periods since projects that are completed discontinue reporting .

this was the case most often when funds were used for discrete equipment purchases , such as law enforcement vehicles , laptop computers in police cars , or weapons .

a majority of the saa officials we interviewed said that workload demand and personnel shortages made meeting recovery act mandated deadlines within the prescribed reporting period difficult .

section 1512 ( c ) of the recovery act requires that each recovery act award recipient submit a report no later than 10 days after the end of each quarter to the federal awarding agency .

in the case of recovery act jag , the federal awarding agency is doj .

the section 1512 ( c ) report that recovery act recipients , such as recovery act jag recipients , are required to submit must contain the following data: ( 1 ) the total amount of recovery funds received from the federal awarding agency ; ( 2 ) the amount of recovery funds received that were expended or obligated to projects or activities ; and ( 3 ) a detailed list of all projects or activities for which recovery funds were expended or obligated .

all 14 saas we contacted said that they had the necessary systems in place to account for recovery act jag funds received and that subrecipients were generally in compliance with their financial reporting requirements .

officials in 10 out of 14 saas in our sample specifically cited the recovery act's window of reporting no later than 10 days after the end of each quarter as challenging .

officials in 8 out of 14 saas in our sample said that meeting federal recovery act reporting requirements increased staff workload and about one - third of the saas told us that personnel shortages have created challenges in their abilities to specifically meet recovery act reporting deadlines .

for example , officials for one county in colorado noted that increased reporting responsibilities associated with recovery act jag grants resulted in one full - time staff member spending nearly 2 full work weeks on federal oversight and reporting requirements over a 5 ½ - month time frame .

officials noted that the same individual spent 16 hours on reporting requirements for a non - recovery act jag award and a state pass - through award during the same time period .

furthermore , officials in texas , new york , and mississippi said they required additional personnel to manage recovery act awards and meet reporting requirements .

in addition , an official in one saa also told us that because of short data collection time frames they initially submitted incomplete quarterly data and likely underreported the impact of the recovery act jag program in the first two quarterly 1512 ( c ) reports .

while state and local officials we interviewed said that meeting the 1512 ( c ) report's 10-day time frame remains challenging , none of the states in our sample said that they were unable to meet the 1512 ( c ) reporting deadline .

in addition , the number of direct award recipients that completed the report has generally remained constant ( around 800 ) over the three reporting quarters from october 1 , 2009 , to june 30 , 2010 .

doj awarded over 70 percent , or more than $289 million of direct award funds , to 436 disparate jurisdictions .

doj guidance states that the recipient ( i.e. , fiscal agent ) in each disparate jurisdiction is responsible for monitoring “subawards” and for “oversight of subrecipient spending and monitoring of specific outcomes and benefits attributable to the use of recovery act funds by its subrecipients.” doj guidance provides detailed information on financial and accounting requirements for direct recipients and subrecipients of doj grant programs .

the guidance also states that fiscal agents must implement and communicate a policy for reviewing subrecipient data .

doj guidance , however , does not provide instruction on what a subrecipient monitoring or data policy should include ; nor does it state how outcomes and benefits tied to the recovery act should be monitored .

the doj office of the inspector general issued a report in august 2010 which included the results of grant audits it performed across 12 state and local recipients of both recovery act and non - recovery act jag program funds .

the inspector general found that 7 of the 12 grant recipients had deficiencies in the area of monitoring of subrecipients and contractors .

the inspector general recommended that doj's office of justice programs provide additional training and oversight of jag recipients to ensure that they establish policies and procedures for monitoring subrecipients' activities to provide reasonable assurance that subrecipients administer jag funds in accordance with program guidelines .

doj concurred with the recommendation that it provide additional training and oversight over the monitoring of subrecipient activities , and plans to review financial training course content to ensure that proper internal control guidance on subrecipient monitoring is included .

doj anticipates developing a training module specific to subrecipient monitoring by march 31 , 2011 .

all of the saas we contacted ( 14 of 14 ) reported that they generally shared recovery act jag information , promising practices , or lessons learned with other states and localities using a variety of techniques .

furthermore , doj had developed a number of programs that encourage the sharing of information and promising practices .

state saa officials told us that efforts to share information with one another or amongst the localities in their jurisdictions include in - person meetings , telephone calls , e - mail , web postings , and / or hosting conferences .

in addition , the saa officials told us they find value in sharing information by attending doj training sessions and conferences and participating in programs and events sponsored by associations , such as the national governors association ( nga ) , the national criminal justice association ( ncja ) , and the council of state governments ( csg ) .

for example: texas officials developed an electronic state government grant management and tracking system that they stated is helpful and efficient in managing recovery act jag funds .

texas officials told us they shared the design of this online system with several states .

in addition , during bja conferences and other national training conferences , texas officials noted that they took the opportunity to discuss with other states the promising practices and lessons learned related to grant management and the administration of jag funds using their system .

colorado officials said that saa staff made presentations at national and regional conferences regarding the following: ( 1 ) grant management and monitoring of state uses for effective grant administration , ( 2 ) various programs the state has funded , and ( 3 ) outcomes the state has achieved .

saa officials said that the state encourages subgrantees that have demonstrated successful programs to respond to requests for presenters at state and national conferences .

officials told us that staff from three colorado recovery act jag subgrantee projects made presentations at the ncja western regional conference in april 2010 .

for example , colorado officials told us that one presentation involved the retraining of probation and parole officers to reduce recidivism by working with other agencies in taking an overall supportive approach to working with ex - offenders that included assistance in such areas as housing , health , and finding work .

ohio officials told us they take the initiative to contact other saas to discuss and share experiences , lessons learned , and promising practices regarding problems encountered in administering recovery act jag grants .

they also said that ncja provides saas with a forum to share information and challenges associated with administering recovery funds , which ohio has leveraged .

for example , they stated that at the 2010 ncja mid - western regional conference that ohio officials attended , there were sessions where saas shared experiences about the administration of recovery act funds , as well as were workshops on model projects funded through the recovery act .

according to ohio officials , the information was helpful both in terms of planning their own initiatives and in reaffirming decisions they had made regarding recovery act and recovery act jag programs .

illinois officials told us that they hosted a 2-day criminal justice planning summit in september 2010 for all state actors in the criminal justice system including recovery act jag practitioners , policymakers , academics , and legislators .

according to saa officials , the focus of the summit was on how to fight crime more effectively in a time of diminishing resources by using the promising evidence - based practices .

state summit planners told us that both presentations by state and national experts and workshops focused on implementing promising practices , while the emphasis in follow - up work groups was on producing a long - range criminal justice plan for the state of illinois .

in addition , saa officials told us that they share promising practices and lessons learned by participating in regional training conferences , web - based seminars , and / or informational conferences provided by omb , doj , as well as illinois state agencies .

doj encourages information sharing through regional training conferences , web - sites , and web - based clearinghouses .

for example , training meetings and webinars provide a forum which states find valuable for sharing information and promising practices , according to a majority of ( 9 of the 14 ) states we interviewed .

in addition , bja has developed a web site that illustrates examples of successful and / or innovative recovery act jag programs .

the web site highlights jag subgrantees and / or statewide projects that bja believes show promise in meeting the objectives and goals of recovery act jag .

in particular , the site describes the planned illinois criminal justice information strategic planning initiative and summit discussed above .

further , doj's office of justice programs is in the process of developing an informational web - based clearinghouse of promising practice information for the criminal justice community through a public web site where researchers , grant applicants , and others may find a list of model programs proven to be effective .

according to doj officials , it will also be a site that saas can use to help find best practices and model programs , thereby funding discretionary programs that show promise based upon evidence .

while the focus of the doj information - sharing programs is broader than recovery act jag , they offer methods and mechanisms to share information related to program priorities , such as law enforcement , corrections , and technology improvement .

saa officials , in a majority of the states we interviewed , indicated that they were supportive of these efforts .

in addition , national associations such as nga , csg , and ncja encourage states to share information and promising practices .

the focus of these programs is generally broader than recovery act jag , but some exclusively focus on recovery act jag priorities such as law enforcement , corrections , and technology improvement .

for example , bja has funded ncja to provide on - site training and technical assistance , webinars , and regional conferences , and creates and disseminates publications to assist saas in developing their statewide criminal justice plans and ensure effective use of recovery act jag funds .

ncja also serves as an information clearinghouse on innovative programming from across the nation , and coordinates information sharing for the justice assistance community .

doj developed and implemented 86 new performance measures for the recovery act jag program in 2009 and continues to make efforts to improve them , but the current set of performance measures varies in the degree to which it includes key characteristics of successful performance measurement systems .

according to doj officials , these performance measures are currently being refined in consultation with stakeholders , such as saas and the external contractor hired to maintain the pmt .

we acknowledge that creating such measures is difficult , given that the performance measurement system is under development , but until these measures are refined , they could hinder the department's ability to assess and communicate whether the goals of the recovery act jag program are being achieved .

in addition , states conveyed mixed perspectives about the utility of doj's performance measurement tool which enables recipients to self - identify activities associated with their grant and then self - report on the relevant set of performance measures under each activity .

doj has not yet completed development of a mechanism to verify the accuracy of this recipient - reported information in the pmt .

from the more than 80 recovery act jag performance measures , we analyzed a nonprobability sample of 19 ( see app .

ii ) and found several areas where the measures could better reflect the characteristics that our prior work has shown to support successful assessment systems ( see app .

iii ) for example , the 19 recovery act jag performance measures we reviewed generally lacked , in varying degrees , several key attributes of successful performance measurement systems , such as clarity , reliability , linkages with strategic or programmatic goals , objectivity , and the measurability of targets .

doj officials acknowledge the limitations of the current system and are undertaking efforts to refine recovery act jag performance measures .

as we have previously reported , performance measures that evaluate program results can help decision makers make more informed policy decisions regarding program achievements and performance .

by including key attributes of successful performance measurement systems into its performance measure revisions , doj could facilitate accountability , be better positioned to monitor and assess results , and subsequently improve its grants management .

table 6 describes 5 of 9 key characteristics of successful assessment systems and the potentially adverse consequences agencies face when omitting these attributes from their measurement design .

these 5 characteristics — clarity , reliability , linkage to strategic goals , objectivity , and measurable targets — are attributes that may be most effectively used when reviewing performance measures individually .

there are 4 others — governmentwide priorities , core program activities , limited overlap , or balance — that are best used when reviewing a complete set of measures .

since we selected a nonprobability sample of 19 measures that were most closely associated with the majority of expenditures , we focused our analysis on the 5 that could be applied to individual measures and did not assess the sample for the other 4 attributes that are associated with an evaluation of a full set of measures .

nevertheless , these 4 attributes also can provide useful guidance when establishing or revising a set of performance measures as a whole .

in conducting our analysis , we applied the 5 characteristics most applicable to assessment of individual performance to the 19 measures in our nonprobability sample .

our analysis found that 5 of the 19 measures were clearly defined but the remaining 14 were not , which is inconsistent with doj's guidance to grant recipients for assessing program performance .

in particular , doj advises that states' grant programs should have performance measures with “clearly specified goals and objectives.” in addition , 14 of the 19 measures were not linked to doj's strategic or programmatic goals .

we also found that while 9 out of the 19 measures were objective , 13 out of 19 were not reliable , and 17 out of the 19 measures did not have measurable targets .

in addition to our analysis , we provided a standard set of questions to officials across our sample states seeking their perspectives on how effectively the recovery act jag performance measures evaluate program results .

these officials provided their comments about the pmt and raised concerns about how the performance measures lack clarity , reliability , and linkage to strategic goals .

from our analysis we determined that 14 out of the 19 measures we analyzed lacked sufficient descriptive detail to facilitate precise measurement .

for example , our analysis found that 1 of doj's measures associated with evaluating personnel activities is the “percent of departments that report desired efficiency.” however , for this measure , doj's guidance based on the definition provided in the performance measure lacks key data elements that would make the measure more clear — namely , which departments should be included in the measure or how states and localities should interpret “desired efficiency.” in addition , officials we interviewed from 9 of the 14 saas in our sample stated that doj's recovery act jag performance measures were unclear .

some examples of states' perspectives follow: in particular , an official from the texas saa told us that texas refined its state data collection tool to clarify performance measure guidance and eliminate instances where doj rejected data entries because the measure was not clear .

as another example , according to texas officials , one of the doj performance measures related to training is “other forms of training conducted during the reporting period.” however , texas state officials noted that bja did not clarify whether this measure would include non - recovery act training .

as a result , the texas state data collection tool revised the performance measure for better context and asked for the “the number of other forms of training conducted during the reporting period and paid with arra jag funds.” other state officials from michigan and georgia cited challenges in understanding what is being asked by the 13 measures listed under the activity type , “state and local initiatives.” in particular , one of these states noted confusion and lack of clarity related to the measure , “number of defined groups receiving services,” since in many instances their initiatives were associated with equipment purchases , and it would be difficult to determine who and how many benefited from a new computer system or the acquisition of new ammunition , for example .

ohio and pennsylvania state officials noted that doj uses terminology such as “efficiency” and “quality” that is not clearly defined .

officials we interviewed from another five states stated that they could not understand whether the term “personnel” should include the entire agency or department that was awarded the recovery act jag grant or if it should include only the portion of staff within a department that is directly affected by the funding .

when we discussed with doj officials our concerns that the performance measure definitions at times lacked clarity , they stated that each was defined , but that further work was being done to solicit feedback from grantees on the measures and their definitions .

however , as we discussed above , our analysis determined that 14 out of the 19 measures do not have clear definitions .

doj officials noted that the department hosts several training opportunities designed to provide grantees opportunities for clarification , including two webinars every quarter and ongoing field training .

doj officials also explained that they hired an external contractor to operate the pmt help desk to provide grantees guidance from 8:30-5:00 est .

however , officials from three states we contacted noted that while the pmt help desk provided useful technical assistance , the help desk provided limited guidance to clarify the definition of performance measures .

therefore , officials from these states reported being confused about what to report .

in july 2010 , we reported that a measure not clearly stated can confuse users and cause managers or other stakeholders to think that performance was better or worse than it actually was .

our analysis showed that 13 out of 19 measures could lead to unreliable findings because respondents could interpret and report on the measures inconsistently .

a performance measure is considered reliable when it is designed to collect data or calculate results such that each time the measure is applied — in the same situation — a similar result is likely to be reported .

respondents' inconsistent interpretation of the measures could preclude using many of the measures as indicators of performance .

for example , we found that one measure: “the percent of departments that report desired efficiency,” was measured and reported on differently by different recipients .

according to saa officials in one state , different police department units in a single large metropolitan area counted themselves as separate departments , while according to saa officials in another state , all police department units were counted collectively as one .

in another state , saa staff stated that bja's guidance document for the recovery act jag performance measures did not provide enough instruction to ensure that agencies reported the correct data .

for example , the staff said they could not determine whether the pmt measure for “the number of personnel retained with recovery act jag funds during the reporting period” was to include any personnel position paid for with recovery act jag funds during the reporting period , or to represent an unduplicated number of personnel positions retained with recovery act jag funds during the reporting period .

given the confusion , the officials sought and received guidance from the help desk on how to interpret and report the measure .

further , officials from 4 of the 14 saas in our sample expressed concern about possible inconsistent data entry among the subrecipients of their pass - through grants .

for example , officials from ohio noted that since subrecipients had their own interpretation of how to report on the measures , they believed that there would be a lack of consistency and reliability within the state as well as across all states once bja attempted to aggregate the responses .

in addition , a related issue is how doj validates the information states and localities submit in order to ensure that the results the department reports are accurate and reliable .

we have previously reported that weaknesses in monitoring processes for verifying performance data can raise concerns about the accuracy of the self - reported data received from grantees .

we also reported that if errors occur in the collection of data or the calculation of their results , it may affect conclusions about the extent to which performance goals have been achieved .

for example , self - reported performance information that is not reported accurately could provide data that are less reliable for decision making .

doj officials acknowledged that they have not verified the accuracy of states' and localities' self - reported performance data .

however , they told us they have been meeting with their contractor to review a draft verification and validation plan , but have not yet implemented a system to verify and validate grantees' performance data or implement data reliability checks on the performance measures in the pmt .

doj officials also attributed their challenges to ensuring data integrity to limited resources , stating that they lack adequate full - time staff to improve , develop , and implement performance measures at this time .

specifically , doj officials told us that they rely on a contractor because they have only one staff person overseeing states' and locals' completion of the measures , and improving and developing the tool .

until a data verification process is in place , doj could experience difficulty in ensuring performance results are reported reliably across state and local grantee recipients .

doj communicated specific recovery act goals , such as jobs created or retained , to recipients ; but did not provide information on how its recovery act jag performance measures aligned with programmatic or strategic goals .

our analysis showed that 5 of the 19 measures were linked to recovery act goals .

for example , doj recently included a performance measure for recovery act jobs reporting , which is the “number of personnel retained with recovery act jag funds.” the remaining 14 measures lacked a clear linkage to any of doj's goals .

for example , 1 of the measures related to the activity type “information systems” is the “percent of departments that completed improvements in information systems for criminal justice.” however , doj does not explain how the performance measure for “improvements to information systems for criminal justice” relates or links to agencywide goals .

when we asked doj officials to describe how the recovery act jag performance measures align with broader departmental goals , they explained that the jag authorizing legislation guides the states' use of the funds within the seven general purpose areas for jag and that they do not link these purpose areas to current year doj goals .

however , doj officials explained that recovery act jag performance measures are linked to the department's strategic goal 2 , “prevent crime , enforce federal laws , and represent the rights and interests of the american people,” and strategic goal 3 , “ensure the fair and efficient administration of justice.” doj officials did not provide written documentation or guidance to recovery act jag recipients that explained this linkage to facilitate understanding of how performance measures were being used consistently with doj's strategic and programmatic goals .

further , with the exception of recovery act goals , officials from all 14 of the saas noted that they did not see a direct linkage between the recovery act jag performance measures and doj's overall agencywide goals .

as we have previously reported , successful organizations try to link specific performance goals and measures to the organization's overall strategic goals and , to the extent possible , have performance goals that will show annual progress toward achieving their long - term strategic goals .

in addition , we have previously reported that , without performance measures linked to goals on the results that an organization expects the program to achieve , several consequences can occur: ( 1 ) managers may be held accountable for performance that is not mission critical or at odds with the mission , and ( 2 ) staff will not have a road map to understand how the measures support overall strategic and operating goals .

in our assessment , we determined that 9 out of the 19 measures were objective .

we previously reported that to be objective , performance measures should ( 1 ) be reasonably free of significant bias ; and ( 2 ) indicate specifically what is to be observed , in which population or conditions , an d in what time frame .

an example of a bja performance measure that w determined is objective is the measure “amount of recovery act jag funds used to purchase equipment and / or supplies during the re period.” this measure provides a specific time frame in which expenditures for equipment and / or supplies must have occurred and clearly explains that the amount of funds used for purchasing equi and / or supplies is what should be reported .

an example of a bja performance measure that we determined lacks objectivity is the measure the “percent of staff that directly benefit from equipment or supplies purchased by recovery act jag funds , who report a desired change in their job performance.” we determined that this measure lacks objectivity because it does not indicate specifically what is to be observed , in wh d population , and in what time frame , and is not free from opinion an judgment .

for example , it requires those reporting to subjectively determine which staff members directly benefit from an equipment or supplies purchase and which staff members do not .

it also requires a subjective determination of how the purchase of equipment or suppli affected a desired change in the performance of staff members who directly benefited from the purchase .

when we discussed the issue of es objectivity with doj they stated that bja instructs grantees to only rep on bja funded activities which occurred during the reporting period .

however , they conceded that the measures were open to interpretation and that was a weakness , but suggested that that was the best option give the need to have universal measures that apply to a broad range of uses .

we do not agree that all the measures we reviewed were defined sufficiently to prevent subjective interpretation .

in addition texas officials expressed concern that doj will not be able to obtain useful data from the pmt because of the subjective interpretation involved in responding to certain of the recovery act jag performance measures .

for example , texas officials identified responses to questions , such as the “percent of departments that report desired program quality” or “percent of staff who reported an increase in skills” as illustrative of the kinds of questions that are open to wide interpretation based on the siz e of the law enforcement organization and the classification of individuals within the organization .

in our assessment , we determined that 17 out of the 19 measures lacke measurable targets .

among the 17 , the absence of measurable targets meant that outside of their original application the award recipients did not have the opportunity to establish in advance what their target level o performance would be to allow for comparisons to actual performance achieved for the reporting period covered .

for example , in the measure “number of overtime hours paid with recovery act jag funds,” bja did not design the measure to allow award recipients to specify their target number of hours paid prior to receiving funding .

doj did recognize that the “project objectives,” i.e .

the funded activities , should be linked to meaningful and measurable outcomes associated the recovery act and the likelihood of achieving such outcomes be assessed .

for example , language in the recovery act jag application instructions requires that , where possible and appropriate , an estimate o the number of jobs created and retained be developed .

in addition , the recovery act jag application for funds also requires that the narrative include performance measures established by the organization to assess whether grant objectives are being met and a timeline or plan to iden tify when the goals and objectives are completed .

however , measurable targets against which to benchm the narrative .

ark results are not explicitly required in as noted , two measures did include measurable targets , and as such will facilitate future assessments of whether overall goals and objectives ar e achieved because comparisons can be easily made between projected performance and actual results .

for example in these two measures — ”the change in the number of individuals arrested in a targeted group by crime type” and “the change in reported crime rates in a community by crime type” — doj provides a list of expectations , such as “we expected number of individuals arrested to increase as a result of our efforts” or “we expected number of individuals arrested to decrease as a result of our efforts,” from which the department expects respondents to choose , to facilitate comparison between the actual and expected number of arrests and reported crimes during a particular quarter .

state officials had mixed perspectives on the pmt and recovery act performance measures , with some critiquing it even as they acknowledged its utility in principle .

for example , five saas noted that doj's measures were in development and acknowledged the difficulty for doj in developing a tool that could be used nationwide for assessing outputs and outcomes across multiple programs .

they also were hopeful that the tool would increase uniform program data collection and allow for meaningful comparisons of data and outcomes across states and different jurisdictions .

state officials also had positive comments about doj's help desk and the staff who provided technical support for the use of the tool .

in addition , while eight states were silent on the issue , state officials from our remaining seven states stressed that reporting on the jag recovery act performance measures is time - consuming and duplicative of other existing state performance measurement reporting systems .

for examp officials from colorado , pennsylvania , and illinois had concerns about limited staff availability to monitor the workload associated with meeting both recovery act and the pmt reporting requirements .

specifically , officials stated that they have to monitor subrecipient activities and provide monthly and quarterly information — as well as validate jobs le , reporting through payroll , expenses , and timesheets — to ensure job cou are calculated accurately and consistently .

in other examples , officials from colorado and iowa expressed concern that the pmt duplicates their existing state performance measurement systems with similar measures and results in duplication of effort .

in addition , the burden of complying with both bja and state requirement led some states , such as michigan , ohio , and texas , to eliminate some of their state performance systems even though officials told us that they believed that these systems measured performance outcomes better than the pmt performance measures .

for example , michigan state officials explained that their preexisting state quarterly performance reports provided specific data on grant outcomes that were of interest to state legislators and policymakers , and which are not included in the pmt performance measures .

in particular , michigan's state performance system included measures related to drug courts , such as the number of drug - free babies that are born to participants .

under the recovery act , the jag program made available nearly $2 billion in additional funds for states and local governments , which states and localities reported using primarily for law enforcement activities while also maintaining some programs that would have been eliminated or cut .

although reporting challenges remain with regard to the recovery act itself , states and localities took steps to share information about promising practices funded through jag , and doj has measures in place to facilitate such information sharing .

in addition , the new performance measures that doj has developed capture information on the use of recovery act jag funds .

however , while doj's performance measures include attributes of successful measures , further improvements are possible .

because the recovery act jag program supports a wide array of activities , as well as the personnel to implement them , having clear performance measures that allow grant recipients to demonstrate results would provide useful information to doj regarding how recovery act jag funds are being used .

our previous work has identified key attributes of successful performance measurement systems that would help assess progress and make performance information useful for key management decisions .

according to the sample we reviewed , doj's performance measures do not consistently exhibit key attributes of successful performance measurement systems , such as clarity , reliability , linkage , objectivity , and measurable targets .

measures that are not clearly stated can confuse users and cause managers or other stakeholders to think that performance was better or worse than it actually was .

the lack of data reliability can create challenges in ensuring accurate information is recorded for performance purposes .

further , the lack of measurable targets also limits the ability to assess program performance and provides limited information to congress about the success of the program .

moreover , successful organizations try to link performance goals and measures to the organization's strategic goals and should have performance goals that will show annual progress toward achieving long - term strategic goals .

in addition , by establishing a mechanism to verify accuracy of self - reported data , doj can better ensure reliability of information that is reported .

by addressing attributes consistent with promising performance measurement practices as it works to revise its performance measures , doj could be better positioned to determine whether recovery act jag recipients' programs are used to support all seven jag program purposes and are meeting doj and recovery act program goals .

recognizing that doj is already engaged in efforts to refine its recovery act jag performance measures in the pmt , we recommend that the acting director of the bureau of justice assistance take the following two actions to better monitor recovery act jag program performance and demonstrate results through use of this instrument: in revising the department's recovery act jag performance measures consider , as appropriate , key attributes of successful performance measurement systems , such as clarity , reliability , linkage , objectivity , and measurable targets ; and develop a mechanism to validate the integrity of recovery act jag recipients' self - reported performance data .

we provided a draft of this report to doj for review and comments .

doj provided written comments on the draft report , which are reproduced in full in appendix vii .

doj concurred with the recommendations in the report and stated that bja plans to take actions that will address both of our recommendations by october 1 , 2011 .

specifically , in response to our first recommendation that doj revise the recovery act jag performance measures to consider , as appropriate , key attributes of successful performance measurement systems , doj stated that bja is taking steps to revise the recovery act jag performance measures — in conjunction with state administering agencies — and that it specifically will consider clarity , reliability , linkage , objectivity , and measurable targets in redesigning its performance measures .

in response to our second recommendation relating to data quality , doj stated that bja will develop and implement a mechanism to validate the integrity of recovery act jag recipients' self - reported performance data .

doj also provided technical comments on a draft of this report , which we incorporated as appropriate .

we are sending copies of this report to the attorney general , selected congressional committees , and other interested parties .

in addition , the report will be available at no charge on the gao web site at http: / / www.gao.gov .

please contact david maurer at ( 202 ) 512-9627 if you or your staff has any questions concerning this report .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix viii .

this report addresses the following four questions: ( 1 ) how are recovery act justice assistance grant ( jag ) funds awarded and how have recipients in selected states and localities used their awards ? .

 ( 2 ) what challenges , if any , have recovery act jag recipients reported in complying with recovery act reporting requirements ? .

 ( 3 ) to what extent do states share promising practices related to the use and management of recovery act jag funds , and how , if at all , does the department of justice ( doj ) encourage information sharing ? .

 ( 4 ) to what extent are doj's recovery act jag performance measures consistent with promising practices ? .

as agreed with your office , we focused our review on recovery act jag grants in a nonprobability sample of 14 states .

the grants made to these states included both direct awards that doj made to state administering agencies ( saas ) and localities , as well as pass - through awards saas made to localities .

a portion of this work was done in conjunction with our other recovery act reviews that focused on those 16 states , as well as the district of columbia that represent the majority of recovery act spending .

the 16 states included arizona , california , colorado , florida , georgia , illinois , iowa , massachusetts , michigan , mississippi , new jersey , new york , north carolina , ohio , pennsylvania , and texas .

we selected these states and the district of columbia on the basis of federal outlay projections , percentage of the u.s. population represented , unemployment rates and changes , and a mix of states' poverty levels , geographic coverage , and representation of both urban and rural areas .

collectively , these states contain about 65 percent of the u.s. population and are estimated to receive about two - thirds of the intergovernmental assistance available through the recovery act .

however , for the purposes of this report , we limited our scope to a subset of 14 of these states so as not to duplicate ongoing work in the other 3 ( florida , new jersey , and the district of columbia ) that the doj office of inspector general was conducting .

the awards to these 14 states accounted for approximately 50 percent of all recovery act jag funds provided .

to identify how recipients of direct and pass - through funds received and used their recovery act jag awards in selected states and localities , we conducted in - person and telephone interviews with officials from saas in all 14 states as well as officials from a nonprobability sample of 62 localities in these states .

where statements are attributed to state and local officials , we did not analyze state and locality data sources but relied on state and local officials and other state sources for relevant state data and materials .

we selected these localities based on the amount of their grant awards , the activities that they were undertaking with grant funds , whether they reported that they had completed 50 percent or more of their grant activities according to their responses provided in recovery act reporting , and how they received their funds ( either as passed - through funding from their saa or received awards directly from doj — and in some cases as part of disparate jurisdictions. ) .

our interviews addressed the use and perceived impact of recovery act jag funds , program performance measurement and reporting challenges , and sharing of promising practices .

also , we reviewed doj direct award data and saa pass - through awards in 14 saas .

we also reviewed recovery act quarterly reports from recovery.gov ( 4th quarter 2009 , 1st quarter 2010 , and 2nd quarter 2010 ) to identify additional information on the use of jag funds .

based on this information , we assigned the grants to one of the seven jag general purpose areas .

for those where multiple purposes were indicated , they were so identified .

in cases where a purpose could not be identified we placed it in the category of “not enough information.” we collected and used these funding data because they are the official source of recovery act spending .

based on our limited examination of the data thus far we consider them to be sufficiently reliable for our purposes .

findings from our nonprobability samples cannot be generalized to all states and localities that were recipients of recovery act jag funds ; however , our samples provided us with illustrative examples of uses of funds , oversight processes , and reporting issues .

to determine the extent to which recovery act jag recipients faced challenges in complying with recovery act requirements , we interviewed representatives from the 14 saas and 62 localities and asked them about their experience with 1512 ( c ) reporting requirements and office of management and budget ( omb ) guidance .

in addition , we reviewed our previous reports that discuss recovery act recipient reporting issues .

to identify how states share promising practice information , and the extent to which doj encourages information sharing , we conducted in - person and telephone interviews with representatives from all 14 of the saas .

we also reviewed doj information , interviewed doj officials , and consulted reports from the national criminal justice association , the national governors' association , and others that describe their information - sharing activities .

to identify the extent to which doj's performance measurement approach is consistent with promising practices to assess progress , we interviewed representatives from the 14 saas and 62 localities and asked them about their experience with the performance measurement tool ( pmt ) .

we also discussed the pmt's design and recovery act jag performance measure improvement efforts with doj staff .

further , we conducted a review of the performance measures that were required for use under the recovery act jag activities commonly reported to have been undertaken by the grant recipients in our sample .

from the 86 recovery act jag performance measures under 10 activity types , we analyzed a nonprobability sample of the 19 performance measures required under 4 of the activity areas ( personnel , equipment and supplies , information systems for criminal justice , and the category outcomes for all activity types ) .

we selected these activity types and measures because they were the ones associated with the largest share of reported recovery act jag expenditures and therefore most often encountered by the grant recipients .

we then assessed these measures against a set of key characteristics that we have previously reported as being associated with promising practices and successful performance measures we have identified in our previous work .

some of the 9 key characteristics of successful performance measures are attributes that may be most effectively used when reviewing performance measures individually and some are best used when reviewing a complete set of measures .

since we selected a nonprobability sample of measures that was most closely associated with the majority of expenditures , we focused our analysis most heavily on those attributes that could be applied to individual measures — clarity , reliability , linkage to strategic goals , objectivity , and measurable targets .

we did not assess the subset of 19 performance measures for the attributes of governmentwide priorities , core program activities , limited overlap , or balance that are associated with an evaluation of a full set of measures .

to evaluate the sample , four analysts independently assessed each of the performance measures against attributes of successful performance measures previously identified by gao .

those analysts then met to discuss and resolve any differences in the results of their analysis .

in conducting this analysis , we analyzed program performance measure information contained in doj's performance measurement tool for american recovery and reinvestment act ( recovery act - arra ) and fiscal year 2009 justice assistance grant programs .

we did not do a detailed assessment of doj's methodology for developing the measures , but looked at the issues necessary to assess whether a particular measure met the overall characteristics of a successful performance measure .

we also reviewed our previous reports that discuss the importance of performance measurement system attributes and obtained information on the extent to which such systems may impact agencies' planning .

the activity types and number of measures selected are listed in table 7 .

we conducted this performance audit from january 2010 through october 2010 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the following table contains the 19 performance measurement tool ( pmt ) performance measures that were required for use under the recovery act jag activity types commonly undertaken by the grant recipients in our sample .

department of justice ( doj ) records indicate that all 14 of the states in our sample have drawn down the vast majority of their recovery act justice assistance grant ( jag ) awards as of may 2010 .

specifically , the amounts drawn down range from less than 53 percent to almost 98 percent .

table 10 shows the amount and percentage of these funds that have been drawn down and expended by state administering agencies ( saas ) , their subrecipients , and localities .

the following table illustrates the types of equipment purchases recipients within our 14 sample states have made using recovery act justice assistance grant ( jag ) funds .

this appendix provides the full printed text of the interactive content in figure 4 on page 22 in the body of the report .

specifically , the following figures describe planned uses of recovery act justice assistance grant ( jag ) funds by each state administering agency ( saa ) across our 14 sample states , which are listed in alphabetical order by state name .

according to state officials , without recovery act funds , the state faced budget cuts and would have had to severely cut or discontinue at least half of the projects previously funded with jag money .

in particular , about $20.8 million in recovery act jag funds supported drug task forces and these drug task forces helped account for seizures of 847,665 grams of cocaine ; 49,586 grams of heroin ; 206,713 grams of methamphetamine ; and 305,082 pounds of marijuana in 2008 .

prosecution and courts $11,074,062 program planning , evaluation and technology improvement crime victim and witness programs $1,265,348 according to state and local officials , recovery act jag supported local gang and drug reduction efforts , helped prevent human trafficking , facilitated a regional approach to reducing methamphetamine production and distribution , and helped develop communications infrastructure .

prosecution and courts $11,981,362 crime prevention and education $835,678 drug treatment and enforcement $44,254,215 program planning , evaluation , and technology improvement $131,213 crime victim and witness programs $1,858,242 state officials noted that recovery act jag helped maintain services in corrections , such as support for problem youth and adult offenders and prison treatment programs , that faced cuts given the state's revenue shortfalls and budget reductions .

in addition , local officials stated that recovery act jag helped support jobs and purchase equipment that otherwise would have been eliminated or gone unfunded .

prosecution and courts $1,972,990 crime prevention and education $1,557,764 drug treatment and enforcement $2,252,813 program planning , evaluation , and technology improvement $2,173,632 crime victim and witness programs $381,322 according to state and local officials , recovery act jag funds helped support jobs , including retaining public safety personnel , and continue delivery of services , such as drug court services , drug prevention , and victims' assistance .

in addition , savannah police department officials noted that recovery act jag funds were used to purchase a fully “patrol - certified” belgian malinois breed canine to assist with recovery of stolen items , searching for suspects and missing persons , and tracking narcotics .

prosecution and courts $8,570,732 crime prevention and education $185,797 drug treatment and enforcement $233,962 program planning , evaluation , and technology improvement $1,468,394 crime victim and witness programs $2,138,127 according to state and local officials , recovery act jag funds helped purchase law enforcement equipment , such as in - car video systems , that would have gone unfunded .

support for other programs and services include , for example , support for overtime wages of law enforcement agents , mentoring programs and drug treatment programs , domestic violence programs , and specialty courts for nonviolent , repeat offenders .

prosecution and courts $8,142,570 crime prevention and education $5,671,274 drug treatment and enforcement $452,965 program planning , evaluation , and technology improvement $4,122,386 crime victim and witness programs officials in boone city , iowa have used a portion of their recovery act jag award to institute cross - training of some employees in the city's police and fire department .

under the city's public safety umbrella philosophy , some employees in the city's police and fire departments receive training in firefighting , emergency response , and law enforcement .

those who receive this “cross - training” are known as public safety employees and can respond to any type of incident where a police officer or firefighter is needed .

officials said that this type of cross - training has allowed the city to be able to do more with limited resources .

crime prevention and education $464,214 drug treatment and enforcement $7,540,845 program planning , evaluation , and technology improvement $36,296 crime victim and witness programs according to local officials , recovery act jag funds helped supplement current state public safety programs , retain jobs , and support core services , including supporting local police departments through funding officer and crime analyst salaries in localities adversely affected by local budget conditions .

crime prevention and education $3,100,000 program planning , evaluation , and technology improvement $599,672 crime victim and witness programs the ottawa county police department used their recovery act jag funds to purchase equipment for law enforcement purposes .

the department purchased a 20-foot patrol boat , a fingerprint and jail mug - shot system , and global positioning satellite ( gps ) tracker devices .

the patrol boat replaces a nearly 20-year - old boat in need of major maintenance .

the fingerprint and jail mug - shot system improves efficiency by enabling the department to identify potential suspects with the state's criminal databases .

the gps tracker devices have helped the department in retrieving numerous stolen items and have provided evidence useful in the prosecution of defendants .

prosecution and courts $14,270,111 crime prevention and education $1,067,558 program planning , evaluation and technology improvement $1,511,762 crime victim and witness programs according to state and local officials , recovery act jag funds helped support jobs to manage the state jag program , and supported local police departments by filling positions , retaining other positions , and funding overtime to provide increased patrols and surveillance .

jag funds will support a variety of programs including multijurisdictional task forces , victim witness assistance , juvenile justice , drug courts , family violence , and increased law enforcement training .

recovery act jag funds were also used to purchase law enforcement equipment including crime lab equipment , computers , police cruisers , and integrated software for patrol car laptops .

prosecution and courts $825,000 crime prevention and education $200,000 drug treatment and enforcement $2,625,320 program planning , evaluation , and technology improvement $2,619,462 crime victim and witness programs according to state and local officials , recovery act jag funds supported the implementa - tion of recent drug law reform , including helping assistant district attorneys in reducing the number of prison commitments , and continue recidivism pilot programs .

new york city officials estimate that jag funds enabled new york city to retain 158 jobs that would otherwise have been eliminated due to budget cuts , and helped create 51 new jobs .

prosecution and courts $9,586,534 drug treatment and enforcement $16,740,000 program planning , evaluation , and technology improvement $2,100,000 crime victim and witness programs the rutherford county sheriff's department used its share of recovery act jag funds to purchase a tactical vehicle for their officers when responding to volatile situations .

the vehicle replaces an old 1986 ford van that subjected officers to unnecessary risk and can accommodate a team of up to 16 officers as well as store equipment , such as weapons and bullet - resistant vests .

the department also purchased portable surveillance equipment that can be thrown or rolled into a room and can provide a 360-degree view to enable officers to identify any potential threats before entering a risky environment .

prosecution and courts $577,951 crime prevention and education $4,035,331 program planning , evaluation , and technology improvement $22,242,265 crime victim and witness programs according to state and local officials , without recovery act jag funds , law enforcement agencies would have faced massive layoffs .

additional funds were also used to support the purchase of law enforcement equipment such as a license plate reader .

prosecution and courts $2,805,401 crime prevention and education $4,593,430 drug treatment and enforcement $934,406 program planning , evaluation , and technology improvement $3,590,904 crime victim and witness programs $2,676,585 state and local officials noted that recovery act jag funds supported regional antidrug task forces , juvenile programs , and initiatives such as records management improvement , prisoner re - entry programs , and at - risk youth employment programs .

prosecution and courts $3,626,239 crime prevention and education $5,522,163 program planning , evaluation and technology improvement $4,838,141 crime victim and witness programs $3,930,520 according to state and local officials , recovery act jag funds largely helped support equipment purchases and technology improvements , as well as support law enforcement personnel , especially police officer overtime .

in addition to the contact named above , joy gambino , assistant director , managed this assignment .

dorian dunbar , george erhart , richard winsor , and yee wong made significant contributions to the work .

geoffrey hamilton provided significant legal support and analysis .

elizabeth curda and cindy gilbert provided significant assistance with design and methodology .

adam vogt and linda miller provided assistance in report preparation , and tina cheng made contributions to the graphics presented in the report .

