over the past decade , the rate of infant mortality in the united states has steadily declined .

in 1987 , there were 10.1 deaths per 1,000 live births ; by 1996 , the rate had dropped to 7.2 deaths .

yet , u.s. infant mortality rates have consistently been higher than those of many other developed countries .

in addition , there are large racial differences in infant mortality rates in this country — in 1996 , for example , the mortality rate for black infants was more than twice that for whites .

medical interventions can potentially address some of the leading causes of infant death .

however , it is thought that poverty , inadequate community services , and educational factors prevent some women from gaining access to appropriate medical care .

in an effort to reduce the nation's infant mortality rate , in 1991 the health resources and services administration ( hrsa ) of the department of health and human services ( hhs ) initiated the healthy start program , which encourages community - based strategies for reducing infant mortality .

the program was planned to be a 5-year demonstration project , and initially 15 communities were awarded healthy start grants .

in 1996 , the demonstration phase was continued for a sixth year .

although , the demonstration phase is considered to have been concluded , healthy start has continued into its seventh year .

over the life of the program , 48 communities have been added to the original 15 .

under the healthy start initiative , hrsa planned for an evaluation of the program to determine whether it had reduced infant mortality .

in 1993 , hrsa contracted with mathematica policy research ( mpr ) , inc. , to conduct a national evaluation of the 5-year demonstration in the original 15 sites .

although the evaluation is not complete , recent press reports have presented conflicting stories on what mpr's preliminary evaluation results indicate about healthy start .

in light of these events , you asked us to ( 1 ) describe the plan for the national evaluation , ( 2 ) determine what mpr's preliminary evaluation results indicate , and ( 3 ) describe what is expected from the final evaluation .

to conduct our work , we reviewed the national evaluation's preliminary results , available evaluation reports , and plans for future evaluations .

we also interviewed program officials and mpr's principal investigators and visited philadelphia and baltimore — 2 of the original 15 healthy start communities recommended by hrsa as exemplifying alternative approaches to project organization .

other elements of the evaluation of healthy start , such as the local evaluations , are beyond the scope of our work .

we conducted our study from january to may 1998 in accordance with generally accepted government auditing standards .

in 1991 , hrsa announced that it would fund 10 healthy start sites and issued guidance on how communities could obtain a grant .

by july 1991 , hrsa had received 40 applications , and in september of that year , it began funding 15 communities for a 5-year demonstration project .

in 1996 , funding for these communities was extended for a sixth year .

in 1994 , hrsa began funding seven new communities — called special projects — and funding for these was also extended in 1996 for an additional year .

forty - one additional communities have been awarded grants since 1997 , and these now share funding with the 15 original sites and 5 of the special projects judged by hrsa to have been successful .

to be eligible for the original grants , a community had to have an average annual infant mortality rate of at least 1.5 times the national average between 1984 and 1988 — that is , 15.7 deaths per 1,000 live births — and at least 50 but no more than 200 infant deaths per year .

applicants had to be local or state health departments , other publicly supported provider organizations , tribal organizations , private nonprofit organizations , or consortia of these organizations .

hrsa required only a few specific activities of all sites to provide grantees flexibility to make their projects relevant to local circumstances .

healthy start's principal goal to reduce infant mortality has usually been stated as a 50-percent reduction in infant mortality , attributable to the program , over 5 years .

healthy start also aims to achieve improvements in other outcomes — such as reductions in low birthweight , improved maternal health , and increased community awareness of threats to infant health — that are expected to help reduce infant mortality .

in addition , healthy start was designed to demonstrate how a program based on innovation , community commitment and involvement , increased access to care , service integration , and personal responsibility could work in a variety of locations with high infant mortality .

from fiscal year 1991 ( a planning year that preceded the 5-year demonstration ) , through fiscal year 1998 , program funding for healthy start has totaled more than $600 million .

healthy start's fiscal year 1992 funding was less than half of what was initially proposed , and the number of grantees was greater .

instead of $171 million being spread over 10 sites , funding for the first year of the demonstration was $64 million spread over 15 sites .

in 1997 , hrsa concluded the demonstration phase of healthy start and began the “replication phase” in 40 ( now 41 ) new sites .

in addition to providing healthy start services in their own communities , the established healthy start communities — the original 15 sites and 5 of the special projects — are mentoring several of the new sites .

while the new sites receive , on average , somewhat less funding than the established sites , funding is shared among all sites .

in september 1993 , hrsa contracted with mpr to conduct the national evaluation of the healthy start program .

this is currently funded with about $4.8 million , paid from the 1-percent set - aside for evaluation of health programs .

the original contract called for mpr to evaluate the first 4 years of the 5-year demonstration program and contained an option for hrsa to request evaluation of the fifth year .

in 1995 , hrsa exercised that option , and the contract now requires that the evaluation cover all 5 years of the originally planned demonstration .

although the demonstration was extended for a year , hrsa currently has no plans to request that mpr evaluate the sixth and final year of the demonstration phase .

the national evaluation , focused only on the original 15 sites , is designed to determine whether healthy start changed the rate of infant mortality and related outcomes , what factors contributed to any effects the program may have had , and how successful approaches to lessening infant mortality can be replicated in other communities .

although each healthy start community is unique and the details of the delivery of any one service may differ across communities , many of the services are common to all sites: outreach and case management ; support services , such as transportation and nutrition education ; enhancements to clinical services ; and public information campaigns .

the national evaluation has two major components: an impact evaluation and a process evaluation .

the impact evaluation is used to determine whether the infant mortality rates in healthy start communities have declined and whether related outcomes have improved .

the process evaluation describes how the program actually operates .

in its final evaluation report , mpr intends to synthesize these two components , linking outcomes with processes to determine why healthy start has or has not succeeded in communities and which strategies are likely to be successful elsewhere .

in the fall of 1997 , mpr reported some preliminary evaluation results , including a draft interim report on its impact evaluation , which led to press accounts suggesting a variety of interpretations about the success of the healthy start program .

we believe these preliminary evaluation results were not conclusive .

although the impact evaluation suggested that healthy start has not reduced infant mortality , such conclusions about the program would be premature because the impact evaluation does not include data from all the program sites or data from all the years of the program .

moreover , the process evaluation indicates that program implementation in many communities was slow and , therefore , that the impact data analysis may not be representative of a mature healthy start program .

the national evaluation's analysis of healthy start's effect on infant mortality and related outcomes is preliminary — mpr characterized its october 1997 report as a draft .

because of problems obtaining data from some of the states' departments of health , only 9 of the 15 program sites to be evaluated were represented in the analysis .

in addition , the analysis is related to only the first 3 of the 6 years of program operation .

moreover , for illustrative purposes , mpr has limited its principal impact analysis to data from only the last of those 3 years , 1994 .

however , if , as hrsa believes , fiscal year 1995 was the first fully operational year , even 1994 data may not reflect the communities' mature programs .

to determine program impact , mpr is conducting two types of analysis: availability and participation .

the availability analysis compares a healthy start community and two similar communities without healthy start to determine if the presence of the program in a community has an effect on infant mortality and related outcomes .

the participation analysis compares , within a healthy start community , mothers who were clients of the program and mothers who were not .

both analyses can be used to study infant mortality ; however , the availability analysis directly addresses the issue of reducing infant mortality in entire communities , while the participation analysis is restricted to outcomes for program participants .

the national evaluation's availability analysis found that for 1994 , the overall infant mortality rate in healthy start communities was about the same as that in comparison communities .

applied to the individual sites , the analysis found that of the nine healthy start communities analyzed , only one experienced a significant reduction in infant mortality relative to its comparison sites .

mpr similarly found that the neonatal and postneonatal mortality rates — two components of infant mortality — were not significantly reduced in the healthy start communities relative to the comparison sites .

in its analysis of birth outcomes considered to be risk factors for infant mortality at eight of the healthy start communities , mpr found that in 1994 , the low birthweight rate was reduced in only one community , the preterm birth rate was reduced in two other communities , and the rate at which women received adequate or better prenatal care was improved in five communities .

none of the analyses of data pooled from all sites yielded significant differences between sites with and without healthy start .

the national evaluation's participation analysis of healthy start's effect on infant mortality has not been completed because of problems of data availability .

the participation analysis of related outcomes , like the availability analysis , yielded little evidence of program effect in the eight communities analyzed .

participation in healthy start was not associated with reductions in low or very low birthweight rates or preterm birth rates .

in postpartum interviews with participants and nonparticipants , conducted in 1996 , after all sites became fully operational , mpr found that participants were more likely to rate their prenatal care experience more highly and to be using birth control .

however , no significant differences between participants and nonparticipants were reported for the receipt of services or health behaviors during pregnancy .

the national evaluation's process evaluation is intended to provide a detailed picture of what happened over time when healthy start was implemented at the various sites and assess its success in meeting its process objectives , such as hiring and retaining staff and putting the planned program in place .

the evaluation , which , according to hrsa's project officer for the evaluation , is to result in a series of reports , indicates thus far that the healthy start program was implemented largely as originally envisioned but more gradually than expected .

mpr's implementation report , a major portion of the process evaluation , provides an overview of program implementation in 14 of the 15 original sites and draws conclusions about these projects .

the report includes detailed information on the development of the projects , the barriers to successful implementation , and the gaps between what was planned and what resulted .

in addition , the report presents perceptions of variations across projects with respect to a variety of criteria , such as staff stability and consumer participation in the process .

it also contains timelines indicating for each site when specific program components became operative .

these timelines demonstrate , for example , that only 4 of the 14 sites had all their planned services operational by october 1994 .

the implementation report concludes with lessons learned , which are organized into four categories: community context , organization and administration , community involvement , and service delivery .

mpr has also completed a report on the infant mortality review process at the various healthy start sites .

it indicates that , in general , the review programs are operational but with varying degrees of success in identifying the factors leading to infant mortality in their communities .

two detailed reports on specific interventions are available only in draft form .

one describes , in greater detail than the implementation report , program participants , including comparisons of participants and nonparticipants with respect to the use of health and social services , satisfaction with services , and health - related behaviors , such as birth control and breast feeding .

the other describes how outreach and case management were delivered , with consideration given to both similarities and differences across sites .

because the impact and process evaluations are not finished , their synthesis has not yet begun .

mpr expects to be able to draw conclusions about the program characteristics that are most effective in improving maternal and child health outcomes and the circumstances under which they are most likely to succeed when it integrates the impact and process evaluations .

the synthesis of the impact and process components of the evaluation to be presented in the final report will be based on impact data from years one through four of the demonstration .

this synthesis may have to be revised when more impact data are available .

the final report as currently planned will not be the final evaluation of healthy start .

the final report will contain an analysis of outcomes through 1995 and a synthesis of this with the findings of the process evaluation reports .

thus , it will assess the program's impact on infant mortality through the fourth year of the demonstration , not the fifth year as planned .

further , these data will reflect the impact of only 1 or 2 years during which the program was fully operational .

an addendum to the report , planned to follow a year later , will contain an updated analysis of outcomes through 1996 .

the addendum will assess impact on infant mortality through the fifth year of the demonstration and thus will reflect the impact of only 2 or 3 years during which the program was fully operational .

however , by evaluating the sixth year of the demonstration , it would be possible to obtain an analysis of 3 or 4 years of impact data from the mature program .

evaluating the sixth year of the demonstration would likely enhance the value of the investment in mpr's evaluation for several reasons .

first , including data from the sixth year of the demonstration would allow evaluation of the years in which all 15 sites have been fully operational .

second , additional data would represent the effects of a more mature and potentially more effective program , which would likely provide more definitive answers about healthy start's success .

third , having more years of data would increase the likelihood of detecting small but real effects of the program .

further , it is possible that data from the more mature years of the program will reflect program impact on the wider healthy start community , not just direct participants in program services and activities .

in addition to hoped - for effects on the pregnant clients of healthy start , there may be effects of program services and education on those same women at other times , such as before or early in their next pregnancy ; indirect effects on their social network , such as their male partners , friends , and sisters ; and indirect effects on the community in general .

hrsa's project officer for the national evaluation notes that the cost associated with analyzing results for an additional year would be about $100,000 ; this would be inexpensive relative to the total national evaluation cost of about $5 million .

since states collect vital records on births and deaths routinely , funds would be needed only to obtain , analyze , and report on the data and to revise the synthesis of these data with the process evaluation .

since the national evaluation of the healthy start program has yet to be completed , preliminary results should not be used to conclude that the program has or has not achieved its goals .

hrsa and mpr plan for the “final” report of the national evaluation to include an extensive description of the program , indicate whether it has reduced infant mortality rates at healthy start sites , and provide an analysis of how program characteristics have influenced outcomes .

however , the final report will analyze infant mortality data from only 4 years of the demonstration .

primarily because implementation of the projects was slower than anticipated , data from the first 4 years of the demonstration may be insufficient for judging the success of healthy start in lowering infant mortality .

thus , even the final report will be inconclusive .

analysis of the fifth year of the demonstration , as planned , will help strengthen the evaluation , but this analysis will not reflect as many years of mature program operation as possible .

thus , at a relatively modest cost , mpr's evaluation would be further strengthened by including data from the sixth and final year of the demonstration .

to increase the value of the investment in the national evaluation of healthy start , we recommend that hrsa contract with mpr to expand the evaluation to include impact data from the sixth year .

in commenting on a draft of this report , hrsa agreed with our findings and indicated that it intends to add funds to the mpr contract to include impact data from the sixth year of the demonstration .

hrsa and mpr provided a number of technical comments that we incorporated as appropriate .

as arranged with your office , unless you announce its contents earlier , we plan no further distribution of this report until 30 days after the date of this letter .

we will then send copies to the secretary of health and human services , to the administrator of hrsa , and to others who are interested .

we will also make copies available to others on request .

please contact me at ( 202 ) 512-7119 if you or your staff have any questions .

you may also contact michele orza , assistant director , at 512-9228 , or donald keller , senior evaluator , at 512-2932 .

the availability analysis of infant mortality and related birth outcomes is part of mathematica policy research's ( mpr ) attempt to determine if healthy start has , as intended , reduced infant mortality at program sites , looking at the vital statistics for entire program and comparison areas where , respectively , the program is or is not available .

it does this without concern about the participation in the program of specific persons .

it attempts to separate any change that may occur in outcomes at program sites that is attributable to healthy start from change in outcomes at those sites that would have occurred without the program — for example , changes stemming from the national trends not related to health and social interventions , such as the persisting decline in infant mortality experienced almost everywhere in the united states .

it does this for each outcome of interest , obtained from the state health department's vital records of linked births and deaths for the sites of interest , by ( 1 ) comparing each program site with two comparison sites without healthy start , selected ( matched ) for similarity to the program site with respect to race and ethnicity , infant mortality rate , and trend in infant mortality over the pre - healthy start period and ( 2 ) statistically adjusting the data for differences between program and comparison site mothers on variables , also obtained from vital records , believed to affect the outcome .

to the extent that , as a result of site selection and statistical adjustment , the program and comparison sites do not differ in expected infant mortality rate , then the comparison of the program and comparison site adjusted outcomes should be a valid indication of the effectiveness of the program .

mpr's approach involves accepted statistical methods with known limitations .

one limitation stems from the possibility that program and comparison site mothers will systematically differ in ways , such as poverty level , that affect outcomes but are not taken into account in the selection of comparison sites and are not available for use in statistically adjusting the data .

such a difference could bias the estimation of the difference between program and comparison sites in outcomes .

nevertheless , mpr appears to have taken reasonable precautions to minimize the likelihood of bias .

mpr did this , for example , by using two comparison sites , not just one , for each program site and by avoiding the selection of comparison areas known to have interventions similar to healthy start .

further , mpr shared information on its site selections with each of the 15 sites and sought their comments and agreement on the choices .

reductions when such differences , in fact , exist .

roughly speaking , power depends on the number of observations — in this case , live births — in the analysis , and it is therefore often a problem when that number is not controlled by the design of the study .

in the case of healthy start , this implies that the ability to detect a real difference between program and comparison communities depends upon whether the comparison involves , for example , communities relatively small in population , large communities , or all communities pooled .

with respect to infant mortality , mpr reports that , using all data from 1984 to 1994 , the minimal detectable difference in infant mortality is computed to be 31 percent , 7 percent , and 6 percent for small , large , and all communities , respectively .

this means that if there are real differences between healthy start and comparison communities , but these differences are smaller than we have the power to detect ( that is , smaller than the percentages listed above ) , then we will mistakenly conclude that the program has no effect on infant mortality .

since power depends on the number of observations , increasing the number of years of data included in the analysis will increase the ability to detect any difference that may exist .

a third potential limitation concerns the number of statistical tests performed in the complete impact analysis .

if 15 sites and seven different birth - related outcome variables are considered , then at least 105 statistical tests will be done .

with as large a number of tests as this being done , it is likely that a portion of them will yield statistically significant results by chance alone .

this means that even if healthy start has no effect on infant mortality , we will mistakenly conclude that it does have one in a certain percentage of the statistical tests conducted .

there are statistical methods of dealing with this problem .

if they are not employed in the final analysis , then differences that are statistically significant by chance alone will occur more often than is considered acceptable by statistical convention .

mpr's participation analysis of birth outcomes is part of mpr's attempt to determine the effect of participation in healthy start within program sites .

it compares 1995 birth outcomes between participants and nonparticipants in each project area .

participants in the program's prenatal activities are identified from program files , the minimum data set required of all healthy start sites , and their birth certificates are flagged .

their birth outcomes are then compared with those of nonparticipants or participants with limited prenatal program involvement .

this kind of analysis is limited by possible preexisting differences between participants and nonparticipants and by the very definition of participant .

since participation in healthy start is voluntary , it is possible that participants systematically differ from nonparticipants .

program providers may , for example , tend to attract persons who are especially knowledgeable about services or already well connected to the health care system .

under these circumstances , program participants would be expected to have better outcomes even without healthy start .

alternatively , participants might be especially needy and at high risk for poor outcomes , in which case they would be expected to have relatively poor outcomes .

mpr deals with this by statistically adjusting the data on the basis of information that may reflect these preexisting differences , background information from birth certificates , and any other available sources .

although it is difficult to be certain that outcomes have been adjusted for all possible systematic differences between the groups being compared , mpr has stated that participants tend to be at high risk for poor birth outcomes , thereby making any potential finding of better outcomes for them than for nonparticipants more convincing of the program's value .

the question of who is a participant must be answered in order to conduct the participation analysis .

it turns out not to be easily answered because ( 1 ) the minimum data sets of many sites have been slow in developing into accurate record systems , ( 2 ) it is not always clear whether a participant's involvement has been intense enough to classify that person as a participant , and ( 3 ) when supplementary information has been sought from new mothers about their involvement in the program it is not always clear what criteria they use for judging whether or not to claim to be participants .

moreover , these problems vary somewhat from site to site , making it difficult to be sure that all participation analyses are comparable .

meaningful to the extent that the preexisting differences between participants and nonparticipants can be taken into account .

mpr's process evaluation is an effort to use both qualitative and quantitative information to assess the degree to which healthy start has implemented its program as conceived of , how it serves its target population , and how these processes developed over time .

this description of healthy start can be considered the documentation of the program's second goal — to demonstrate what happens when this kind of effort is mounted .

its methods are varied , including making site visits with and telephone calls to project staff , examining the client records of the minimum data set , the postpartum survey of participants and nonparticipants , running focus groups with service providers and with members of the communities , as well as using documents and vital records .

many aspects of the process evaluation are not complete and will not therefore be described further , but one major document — the implementation report — is complete .

the implementation report is based mainly on site visits , expenditure reports from each project , and the client records of the minimum data set .

further , two independent teams of site visitors rated certain dimensions of administrative success using a modified delphi consensus reaching process .

although they may not be avoidable , the limitations of this report are those common to most process evaluations that are heavily qualitative .

the methods employed provide a wealth of information suitable to inform those who would develop similar programs about what to expect if different options of organization , administration , and mode of service delivery are attempted .

however , the essential subjectivity of interview methods makes it difficult to know how closely other evaluators would agree with the conclusions drawn .

the first copy of each gao report and testimony is free .

additional copies are $2 each .

orders should be sent to the following address , accompanied by a check or money order made out to the superintendent of documents , when necessary .

visa and mastercard credit cards are accepted , also .

orders for 100 or more copies to be mailed to a single address are discounted 25 percent .

u.s. general accounting office p.o .

box 37050 washington , dc 20013 room 1100 700 4th st. nw ( corner of 4th and g sts .

nw ) u.s. general accounting office washington , dc orders may also be placed by calling ( 202 ) 512-6000 or by using fax number ( 202 ) 512-6061 , or tdd ( 202 ) 512-2537 .

each day , gao issues a list of newly available reports and testimony .

to receive facsimile copies of the daily list or any list from the past 30 days , please call ( 202 ) 512-6000 using a touchtone phone .

a recorded menu will provide information on how to obtain these lists .

