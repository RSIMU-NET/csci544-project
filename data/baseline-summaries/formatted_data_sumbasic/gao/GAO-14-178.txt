federal agencies rely on the commercial marketplace for a range of goods and services to conduct business and meet their mission needs .

in 1996 , congress authorized the use of simplified acquisition procedures — previously allowed for small purchases — for commercial items not exceeding $5 million under the test program for certain commercial items ( test program ) .

based on the premise that market forces would ensure reasonable prices for commercial items , the test program aimed to simplify the contracting process by providing contracting officers with additional procedural discretion and flexibility for the acquisition of commercial items .

further , effective and efficient access to commercial products and services can help agencies achieve their missions and save time and administrative costs in an era of constrained budgets .

the test program authority was initially only 3 years but has been repeatedly extended .

the most recent extension expired on january 1 , 2012 , and the authority was not extended at that time .

in january 2013 , congress extended the authority for use of the test program , retroactively from january 1 , 2012 , to january 1 , 2015 .

the house armed services committee report that accompanied the national defense authorization act for fiscal year 2013 mandated gao to report on the use of the authority provided under the test program .

this report addresses ( 1 ) the extent to which federal agencies have used the test program , and ( 2 ) its benefits and risks , if any .

to determine the extent to which federal agencies have used the test program , we analyzed data on contract actions awarded using the authority from the federal procurement data system - next generation ( fpds - ng ) .because it was the most recent fiscal year with complete data available when we began our review due to the authority's expiration in 2012 .

based on reported obligations , we determined that the departments of defense ( dod ) , homeland security ( dhs ) , and the interior ( doi ) collectively accounted for about 74 percent of all test program obligations .

within these departments , we focused on the five components reporting the greatest use of the test program as follows: dod's army materiel command , naval supply systems command , and air force materiel command ; dhs' u.s. coast guard ; and doi's acquisition services directorate .

we used fiscal year 2011 data from fpds - ng we assessed the reliability of the fpds - ng data by randomly selecting a generalizable sample of 243 contracts with obligations in fiscal year 2011 that were coded as having used the test program .

we obtained evidence from the contract files to verify that the contracts had been awarded using the test program and determined the fpds - ng data were sufficiently reliable to identify the minimum extent to which the five components used the test program .

we did not sample contracts that were identified as not using the test program , and as such , did not assess the extent to which test program actions and obligations may be underreported .

we also analyzed the number of new awards for commercial items and services in fiscal year 2011 and identified the percentage that used the test program .

we did not assess the test program's higher threshold of $12 million when used in support of a contingency operation or to facilitate the defense against or recovery from nuclear , biological , chemical , or radiological attack since we determined that these contracts accounted for only 2 percent of fiscal year 2011 obligations made by the components in our review .

we interviewed contracting officials from each department and component to determine the factors that influenced whether or not the test program was used .

to determine the benefits and risks of using the test program , we reviewed relevant legislation , applicable federal acquisition regulation ( far ) provisions , and agency guidance .

we also selected a nonrandom , nongeneralizable sample of at least four of the largest test program contracts from each of the five components for a total of 26 contracts .

for the 26 contracts sampled , we reviewed the contract and other relevant documents , such as acquisition plans , market research documentation and solicitations , and interviewed contracting officials to determine how the test program was used and to obtain their views on the benefits and risks of its use .

for eight competitively awarded test program contracts , we also compared the actual number of days from solicitation issuance to award with the estimated number of days from solicitation issuance to award of a contract using competitive negotiated procedures , based on agency guidance .

appendix i provides additional details on our scope and methodology .

appendix ii provides information on the 26 contracts we reviewed .

we conducted this performance audit from march 2013 to february 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the acquisition reforms of the mid - 1990s resulted in a number of regulatory changes that promoted the acquisition of commercial items and services .

these reforms grew out of the belief that ( 1 ) ever - increasing procurement laws and regulations resulted in federal contracting processes that were overly burdensome and time consuming ; and ( 2 ) acquiring commercial items would improve quality and cost outcomes by leveraging the innovation of the commercial market and using market forces to lower prices .

commercial items and services are those generally available in the commercial marketplace in contrast with items developed to meet specific federal government requirements .

figure 1 identifies key laws related to the commercial item test program .

as part of the acquisition reform efforts , the federal acquisition streamlining act of 1994 ( fasa ) authorized agencies to use simplified procedures for the acquisition of supplies and services not exceeding $100,000 .

simplified procedures for purchasing commercial items allow agencies to select contractors using expedited evaluation and selection procedures and to keep documentation to a minimum , which can reduce the government's administrative costs .

for example , evaluation of a contractor's past performance may be based on one or more of the following: the contracting officer's knowledge and previous experience with the supply or service being acquired , customer surveys , and past performance questionnaire replies .

additionally , fasa established a statutory preference for the acquisition of commercial items and defined the term “commercial item.” for example , fasa required agencies to conduct market research to determine whether commercial items are available to meet agency needs ; to define requirements in terms of functions to be performed , performance required , or essential physical characteristics so that commercial items can be procured ; and to acquire commercial items to the maximum extent practicable to meet agency needs .

the definition of commercial item includes items customarily used by and sold ( or offered ) to the general public , including with minor modifications “of a type” not necessarily available in the commercial marketplace made to meet federal government requirements , or services “of a type” offered and sold competitively in substantial quantities in the commercial marketplace .

including “of a type” items allows vendors to make adjustments to commercial products so that they meet government requirements even if those products have not been sold in a commercial setting or subjected to competitive price pressures .

far § 2.101. nuclear , biological , chemical , or radiological attack .

these thresholds have been changed periodically to take inflation into account , resulting in the current thresholds of $6.5 million for commercial acquisitions and $12 million for commercial acquisitions in support of contingency - related operations .

the authority lapsed in 2012 , but was subsequently reauthorized by congress until january 1 , 2015 .

various provisions of the far govern the policies and contracting methods for commercial item acquisitions .

far part 12 — acquisition of commercial items prescribes the policies unique to the acquisition of commercial items .

for example , contracting officers can use streamlined posting and solicitation procedures , which can reduce the time needed to advertise actions and solicit offers , respectively .

contracting officers are also required to use firm - fixed - price contracts or fixed - price contracts with economic adjustments , though the far also allows for the use of time - and - materials contracts or labor - hour contracts under certain circumstances .

far part 12 also instructs contracting officers to use the policies in conjunction with the solicitation , evaluation , and award policies and procedures described in other parts of the far , specifically far part 13 — simplified acquisition procedures , far part 14 — sealed bidding , or far part 15 — contracting by negotiation , that the contracting officer believes are most appropriate .

as shown in table 1 , the combination of the procedures provided for under far parts 12 and 13 generally constitute the flexibilities provided under test program .

by contrast , contracting by negotiated procedures requires more steps during the evaluation process and more detailed contract file documentation , but can provide contracting officers with greater visibility into the costs and technical capabilities of the offerors , if needed .

the far states that contracting activities must use the simplified procedures authorized by the test program to the maximum extent practicable .

however , when buying goods and services , federal contracting officers are required to procure from or through required government supply sources , which are listed in order of priority .

for example , one of the required government supply sources for both supplies and services is the general services administration's federal supply schedule program .

the schedule program provides federal agencies with a simplified method for procuring various quantities of a wide range of commercially available goods and services .

further , agencies can use existing indefinite - delivery contracts which allow them to issue task orders for services or delivery orders for supplies .

similarly , agencies may have pre - existing blanket purchase agreements which also provide a simplified method of fulfilling repetitive needs for supplies and services .

in the absence of a required government supply source , contracting officers can generally use existing contracts or award new contracts for commercial items using either simplified or negotiated procedures within the test program thresholds .

when using the test program , the far also requires competition to the maximum extent practicable , which can generally be achieved by posting the proposed contract action to the governmentwide point of entry located at federal business opportunities ( fedbizopps ) , or by soliciting sources from the local trade area .

noncompetitive awards are permissible under certain circumstances such as when only one responsible source and no other supplies or services will satisfy agency requirements , or when competition is precluded by the terms of an international agreement .

noncompetitive awards are also permissible under section 8 ( a ) of the small business act which authorizes the small business administration ( sba ) to enter into contracts on a competitive or noncompetitive basis with other agencies and award subcontracts for performing those contracts to firms eligible for program participation .

sba's subcontractors are referred to as “8 ( a ) contractors. .

our prior reports on the initial use of the test program found that there was limited data to assess its use or benefits .

for example , in 2001 we reported that the agencies had not collected data to provide a basis for measuring whether the test program was maximizing efficiency and economy and minimizing administrative burden and cost .

similarly , in 2003 , we reported that the test program data reported in fpds were not reliable and recommended that agencies take action to ensure data reliability .

subsequently , dod requested a change in 2007 to fpds - ng to improve test program reporting .

as a result , fpds - ng was modified in 2009 to include a specific , single reporting field to identify test program contracts .

we also recommended that dod and the office of federal procurement policy ( ofpp ) , which provides overall direction for government - wide procurement policies , develop evaluation mechanisms for measuring test program benefits .

dod stated that it would develop a methodology to evaluate the benefits of the test program on the basis of such metrics as contracting lead time , and share the results with ofpp .

however , according to dod and ofpp officials , no action has been taken to do so .

our work and that of others has shown that government contracting officials face risks in using commercial acquisitions in certain circumstances .

for example , in 2006 we reported that improper classification of an item as commercial can leave the government vulnerable to accepting prices that may not be the best value if the item is not sold in numbers sufficient for the government to determine the reasonableness of the vendor's prices as the government is precluded from requesting certified cost or pricing information .

the dod inspector general also issued a report in 2006 that found that contracting officials did not adequately justify the commercial nature of the items or services being acquired and concluded that the commercial item definition was too broad and allowed contracting officials to award contracts for defense systems and subsystems that had no commercial market and no meaningful price history .

the inspector general recommended that dod propose a legislative change to tighten the commercial item definition to state that the commercial item exception to submission of certified cost or pricing data must only apply to the acquisition of commercial items that are sold in substantial quantities to the general public .

at the time , dod did not concur with the recommendation .

in january 2007 , the acquisition advisory panel issued a report that concluded that the broadness of the commercial item definition , specifically the “of a type” provision for commercial services disadvantages the government in pricing , particularly when there is limited or no competition .

to ensure that an item meets the commercial item definition , dod amended the defense federal acquisition regulation supplement ( dfars ) in 2008 to require dod contracting officers to include a written determination in the contract file that an acquisition meets the definition of “commercial item” specified in the far when using commercial item procedures for acquisitions exceeding $1 million .

dod amended this requirement in 2012 to require approval one level above the contracting officer when the commercial item determination is based on the “of a type” commercial procurements or items “offered for sale,” but not yet sold to the general public .

in 2006 , we also noted the risks associated with commercial item acquisitions in a noncompetitive environment such as when there is only one responsible source and there are no other supplies or services that will satisfy agency requirements .

we found that similar to misclassifying acquisitions as commercial , the lack of market - based competition for commercial items for which there is only one responsible source may result in prices that may not be the best value for the government .

in situations when the government is acquiring a commercial item noncompetitively , agencies may use various means to determine that that the proposed price is reasonable , such as by comparison with prices found reasonable on previous purchases , or comparison with a commercial price list .

in 2010 , we also found that for services supporting dod weapons programs , the government's lack of access to proprietary technical data — information used to define a design and to produce , support , maintain or operate an item — and a heavy reliance on specific contractors for expertise limit , or even preclude the possibility of , competition .

federal agencies' use of the commercial item test program represents a relatively small portion of all commercial buying activity .

in fiscal year 2011 , of the $90 billion agencies obligated on new awards for commercial items and services , federal agencies obligated $1.9 billion or about two percent using the test program based on data reported in fpds - ng .

for new awards within the test program thresholds of $150,000 to $6.5 million , test program contracts constituted about 9 percent of obligations and 12 percent of awards for the five components we reviewed .

table 2 summarizes the extent of use of the test program for the five components we reviewed .

we identified significant variation in test program use between and within the components we reviewed which agency and component officials attributed to a variety of factors including the types of goods and services being acquired , the complexity of the acquisition , and the existence of other contracting approaches .

for example , within dod , the army material command awarded about 7 percent of its new awards in fiscal year 2011 using the test program ; by contrast , the naval supply system command awarded about 26 percent of its new awards in that year using the test program .

similarly , within the coast guard , the aviation logistics center used the test program for 139 of 370 new commercial awards ; in contrast , the coast guard's headquarters contract operations used the test program for only 3 of 164 new awards .

coast guard officials explained that the nature of the products and services purchased by the aviation logistics center — including parts and services for aircraft maintenance , upgrades , and repair — lends itself to using the test program .

by contrast , officials explained that the relatively lower use at coast guard headquarters is due to the fact that they use pre - existing indefinite - delivery order contracts to procure commercial items and services within test program thresholds such as information technology services .

in that regard , we found that 126 of 164 new coast guard headquarters awards , or 77 percent , were delivery orders .

department and component officials generally believe that the test program is used as much as possible , but noted that it is one tool among many others in the contracting officer's tool kit .

these officials explained that the decision regarding the appropriate contracting method for a commercial item is left to the contracting officers' discretion and may be based on factors including the estimated value of the contract at award , the urgency of the requirement , the availability of existing contracts or vehicles , as well as the nature of the item or service being acquired .

further , several officials noted that they would not use the test program for complex commercial procurements , regardless of the estimated value , if they believed a negotiated procedure was necessary to evaluate the costs and technical capabilities of the offerors .

federal internal control standards call for managers to measure and assess performance over time to ensure effectiveness and efficiency of operations and compliance with applicable laws and regulations .

these officials acknowledge , however , that their departments or components do not collect or assess data to determine whether the test program is used to the maximum extent practicable as required by the far , which may result in missed opportunities to use the test program .

we also found evidence that test program contracts may be underreported .

for example , based on data reported in fpds - ng , the army materiel command's mission installation contracting command - fort knox reported that it used the test program for 2 of 538 , less than 1 percent , of new commercial awards in fiscal year 2011 that fell within test program thresholds .

a fort knox contracting official told us that he believed actual use of the test program was likely to be much greater and attributed the underreporting to how their contract writing system defaults to a “non - test program” setting .

we did not assess the extent to which test program contracts were underreported .

the test program contracts we reviewed were generally awarded more quickly and with less administrative burden than had the contracts been awarded using negotiated procedures and generally did not incur risks above those experienced on other federal acquisition efforts .

the agencies and components we reviewed reported they generally applied their existing internal controls when reviewing and approving test program contracts .

further , contracting officers generally documented their efforts to identify commercial sources , but nevertheless awarded 16 of the 26 test program contracts noncompetitively .

while these awards were justified and approved in accordance with federal regulations when required , our work and that of others has found that noncompetitive contracting poses risks of overspending because these awards lack a direct market mechanism to help establish pricing .

dod regulations require a written and approved commercial item determination in some cases to mitigate risks associated with misapplication of the commercial item definition ; neither dhs nor doi have a similar requirement .

ofpp staff and agency contracting and policy officials we interviewed believed the test program provided benefits in terms of reducing lead time and administrative workload , however , data are not specifically collected to assess test program benefits on the basis of such metrics as contracting lead time , according to officials .

officials noted that when the test program authority lapsed in 2012 , ofpp and dod requested from the civilian agencies and military departments examples of how the test program has been used and benefits of its use .

our review of some of the responses provided found that contracting activities consider the test program a useful tool to manage workload and save resources .

for example , a naval supply systems command office prepared a workforce analysis that identified the contracting full - time equivalents associated with additional processing time which would be required if the test program were not available .

in the absence of the test program or additional funding , the office concluded that the capacity to perform contract administration and oversight would likely be negatively impacted .

based on our review of the test program contracts , the use of the test program reduced contracting lead time and administrative burdens in comparison to the agencies' estimated lead times for awarding contracts using negotiated procedures .

as we reported in 2011 , most agencies we reviewed have established guidance for contracting lead times that serve as internal deadlines for contracting offices and provide program offices with information about contract processing times .

for the purposes of our lead time analysis , we reviewed agency lead time guidance from each of the components we reviewed that identified the estimated time needed to award a contract using negotiated procedures , focusing specifically on the number of days from when the agency issued a solicitation to contract award .

the lead times established in the guidance varied considerably and did not consistently account for a number of factors such as the degree or type of competition ( i.e. , competed or not competed ) , the commercial availability and type of item or service procured , and estimated contract value of the acquisition .

recognizing these limitations , we compared the expected lead times for negotiated competitive procurements based on agency guidance with the actual lead times we observed for eight test program contracts we reviewed .

for these contracts , we identified the number of days from solicitation issuance to contract award and compared these actual days with the estimated time to award a competitive negotiated contract based on each respective agency's guidance .

as shown in table 3 , seven of the eight test program contracts we reviewed that were competitively awarded were awarded in fewer days than identified in agency guidance .

in general , test program contracts that were not competed were awarded in fewer days than those that were competed .

according to contracting officers we interviewed , the test program provided them flexibility and discretion with respect to evaluating offers and making contract awards and allowed them to keep documentation to a minimum .

for example , an army contracting officer competitively awarded a $1.3 million firm - fixed - price contract for blast barriers and bunkers for installations in kuwait in 20 days after receiving quotes from 23 local contractors and evaluating them for technical acceptability and price.awarded a $2.3 million firm - fixed - price contract for aircraft services for firefighting missions in colorado in 55 days after evaluating six quotations submitted by regional businesses for price and aircraft capability , among other criteria .

according to contracting officers we interviewed , had the test program not been available , they would have used negotiated procedures under far part 15 .

in that regard , they would have been required to establish formal evaluation criteria , convene an evaluation team , and evaluate proposals against the criteria , as well as notify unsuccessful offerors and generally conduct negotiations with the offerors in the competitive range .

in another example , a doi contracting officer competitively in contrast , under simplified acquisition procedures , if using price and other factors , the contracting officer must ensure that quotations or offers can be evaluated in an efficient and minimally burdensome fashion .

formal evaluation plans , and establishing a competitive range , conducting discussions , and scoring quotations or offers are not required .

some contracting officers explained that they chose to use simplified procedures under the test program because it would have taken additional time to use negotiated procedures to acquire the same goods and services .

contracting officers used the combined posting and solicitation issuance procedures allowed for all commercial item acquisitions in combination with the other flexibilities of the test program to varying degrees .

for example , contracting officers did not consistently issue combined notice and solicitation , or establish a reduced solicitation response time that affords potential offerors a reasonable opportunity to respond to the commercial item acquisition .

contracting officers used the combined notice and solicitation issuance procedure in only 6 of the 26 contracts we reviewed .

in 8 contracts involving noncompetitively awarded small business 8 ( a ) contracts , there was no requirement to post notice of the proposed contract action .

in other cases , contracting officers provided several reasons why they chose not to use the combined notice and solicitation issuance procedure .

for example , a coast guard contracting official explained that she did not use the combined posting and solicitation issuance procedures for a test program contract for ship repairs valued at approximately $800,000 because it is the office's practice to issue a separate notice and solicitation for all ship repair contracts valued over $150,000 to encourage competition among the limited number of vendors that can provide these services .

we also found that in some cases contracting officers did not reduce the solicitation response time and allowed a solicitation response time of 30 days or more .

contracting officials at the agencies we reviewed reported that combined posting and solicitation issuance procedures are more likely to be used in test program awards where there is limited time to complete an acquisition due to urgency , the need to award contracts before the end of the fiscal year , or when the specifications of the requirement are not complex .

according to officials from the agencies and components we reviewed , test program contracts are reviewed using existing internal controls and standard contract review processes , which are often based on dollar thresholds .

consequently , these officials noted that there is no difference between the reviews they conduct prior to awarding a test program contract versus other , comparably - valued contracts .

further , the far requires that agency needs are described in sufficient detail to allow for the conduct of market research .

market research establishes the foundation for the agency description of need , the solicitation , and resulting contract .

further , it is intended to help the agency determine if there is a commercial market , which helps ensure that the prices offered are subject to market forces .

we found that the contracting officers responsible for the contracts we reviewed documented their market research in 24 of 26 cases .

in the remaining two cases , agency officials could not provide evidence that market research was conducted .

the far also requires test program contracts to be competed to the maximum extent practicable , unless contracting officers justify awarding them noncompetitively .

noncompetitive awards are permissible under certain circumstances such as when only one responsible source and no other supplies or services will satisfy agency requirements , or under the 8 ( a ) small business program .

most contracts , however , were not awarded competitively .

our review found that 10 of the 26 contracts were awarded competitively and the remaining 16 were awarded on a noncompetitive basis and included justifications and approvals when required by federal regulations ( see appendix ii ) .

in 8 cases , the contracts were awarded noncompetitively to small businesses .

in another 7 cases , contracting officers justified the decision to award the contract noncompetitively on the basis that only a single contractor could satisfy the government's requirements .

for example , the coast guard awarded a $4.3 million contract for aircraft spare parts on a noncompetitive basis because the contractor owned the technical data — information used to define a design and to produce , support , maintain or operate an item — for the needed item .

in another example , the army justified a $1.6 million noncompetitive award to upgrade a mobile radio system on the basis that the vendor was the only source since it owns proprietary rights in the hardware and software .

in the remaining noncompetitive award , the army awarded a $1.2 million contract for computer systems equipment and troubleshooting on behalf of the saudi arabian national guard on the basis that competition was precluded by the terms of an international agreement .

our work and that of others has found that noncompetitive contracting poses risks of overspending because these awards lack a direct market mechanism to help establish pricing .

for example , we have reported that competitive contracts can help save the taxpayer money , improve contractor performance , curb fraud , and promote accountability for results .

important role in helping agencies meet needs that arise , they also present a risk because they place agencies in the position of having to negotiate contracts without the benefit of a direct market mechanism to help establish pricing .

a “of the type” or “offered for sale” language contained in the commercial item definition .

the purpose of the determination and higher level approval is to mitigate against the potential risk associated with misapplication of the commercial item definition .

as we found in 2006 , improper classification of an item as commercial can leave the government vulnerable to accepting prices that may not be the best value if the item is not sold in numbers sufficient for the government to determine the reasonableness of the vendor's prices as the government is precluded from requesting certified cost or pricing information for commercial items .

we found that contracting officers documented the required commercial item determinations in 11 of 13 dod contracts we reviewed valued over $1 million .

for 2 contracts , however , the commercial item determination was not documented and agency officials could not provide an explanation .

overall , about 18 percent of the new commercial item awards in fiscal year 2011 for the 3 dod components we reviewed had an estimated value each of $1 million at award .

at the coast guard and the department of the interior's acquisition services directorate , 22 and 39 percent , respectively , of their new contract awards had an estimated value at award of $1 million or more .

while dod requires its components to prepare written determinations for certain commercial acquisitions , neither dhs nor doi require or prepare commercial item determinations .

without such determinations , dhs and doi may be vulnerable to misclassifying an item as commercial and thereby accepting prices that may not have been subject to market forces .

federal internal control standards call for managers to identify , analyze , and decide what actions should be taken to manage risk .

agencies face increased pressure to award contracts for the billions of dollars the federal government spends acquiring commercial goods and services each year more efficiently and effectively .

the commercial item test program was intended to achieve such efficiencies by streamlining the acquisition process for commercial items and services and relying on the commercial marketplace to help improve quality and reduce prices .

we found that contracts awarded using the test program represented a small fraction of the total amount spent on commercial goods and services in fiscal year 2011 , in part because of the existence of other means or approaches to acquire commercial items that may be better suited for the particular good or service being acquired .

when the test program is used , we found that it helps reduce contracting lead times when compared to the agencies' guidance on the time contracting officers should plan for if they intended to award a negotiated contract .

the agencies we reviewed do not monitor or assess whether the test program is used to the maximum extent practicable and without further action by senior agency leadership , the possibility exists that the agencies are missing opportunities to further reduce their contracting lead times and administrative burdens .

from an oversight perspective , the agencies we reviewed indicated they generally subjected contracts awarded using the test program to their existing contract review and approval processes associated with contracts of similar value .

the risks and challenges we identified are not unique to the test program , but generally affect commercial item acquisitions .

for example , we found that contracting officers generally documented their market research as required for the use of the test program , but fewer than half of the contracts were competitively awarded .

in that regard , while there are benefits to acquiring commercial items , doing so should not be construed as being synonymous with buying goods and services competitively .

the limited competition we observed is a potential risk because our work and that of others has found that noncompetitive contracting poses risks of overspending because these awards lack a direct market mechanism to help establish pricing .

another challenge agencies faced when acquiring commercial items is the potential to inappropriately determine the good or service to be acquired is a commercial item .

dod officials have recognized that the misapplication of a commercial item definition may expose the government to additional risk and took steps to mitigate some of this risk by requiring its contracting personnel document their determination that the good or service being acquired met the definition of a commercial item , a prerequisite for using the authority .

neither dhs nor doi require their contracting officers to do so and the absence of this safeguard may increase the risks to those agencies .

to increase the potential benefits from using the test program and mitigate potential risks , we are making the following two recommendations: we recommend that the secretaries of defense , homeland security , and the interior collect and assess data to determine whether their agencies are using the simplified procedures authorized by the test program to the maximum extent practicable , as required by the far .

to mitigate the potential risk of improperly designating a good or service as a commercial item , we recommend the secretaries of homeland security and the interior require contracting officers within their agencies to make a written commercial item determination at a level that they determine appropriate for their agencies .

we provided a draft of this report to dod , dhs , doi , and the office of management and budget for comment .

dod concurred with our recommendation directed to the secretary of defense , but dhs and doi did not concur with the recommendations directed to them .

in an email response on january 30 , 2014 , the associate administrator of the office of federal procurement policy , office of management and budget generally agreed with our findings and included additional comments .

the agencies' comments and our responses are summarized below .

written comments from dod , dhs , and doi are reproduced in appendices iii , iv , and v , respectively .

doi also provided technical comments , which we incorporated as appropriate .

regarding our recommendation to increase the potential benefits from using the test program by assessing test program use , dod agreed with our recommendation and indicated it will establish a process to collect and assess data to do so .

dhs and doi both disagreed , noting they questioned the value of such an assessment and that current procedures were adequate .

dhs stated that a retroactive review to assess data on when the program was not used would be costly and labor intensive and would likely not result in findings that could be broadly addressed through policy changes or internal controls .

doi also questioned the value of assessing test program use , and indicated that doing such an assessment would imply that the use of the test program is a higher priority than other tools available to contracting officers .

we did not intend for either dhs or doi to retroactively assess the reasons why contracting officers did not choose to use the test program and agree that doing so would not be cost - effective .

however , the wide variation in the components' use of the authority and the lack of management visibility into its use indicates to us that the components may be missing opportunities to further reduce their lead times and administrative burden .

given the improved reliability of test program data reported in fpds - ng , agencies have data they can readily use to assess their commercial acquisition portfolios to help ensure that they maximize available resources by taking advantage of opportunities to use the test program when appropriate to reduce administrative burden .

similarly , the office of management and budget noted that in the event that the authority was made permanent , it would expect agencies to periodically review their use of the test program as part of their management reviews .

consequently , we continue to believe that collecting and assessing data on the program's use would be beneficial .

dhs and doi suggested that the temporary nature of the test program hindered its use and recommend that the authority be made permanent .

we believe our work provides a basis for helping inform the debate as to the future of the authority ; however , as our review focused on three agencies , making such a recommendation was beyond the scope of our review .

dhs and doi also disagreed with our recommendation to mitigate potential test program risks by requiring contracting officers to make a written commercial item determination in certain cases .

dhs stated that market research and existing internal controls are sufficient to ensure the test program is not misused to purchase non - commercial items .

similarly , doi stated that information needed to confirm the commerciality of the item or service being purchased should be documented as part of market research and that an additional requirement would deviate from ongoing efforts to streamline the acquisition process .

the office of management and budget also noted that it was unclear whether there were weaknesses with the current safeguards that necessitated additional determinations , but stated that it would expect agencies to make sure the authority was used only to acquire commercial items as part of their management reviews .

while we found that for the contracts we reviewed the risks associated with using the test program are generally no greater than other commercial acquisitions when internal controls are in place , gao and others have noted risks associated with the potential misapplication of the commercial item definition .

dod has taken action to address this risk by requiring a commercial item determination in certain cases , such as when purchasing commercial items “of a type” or “offered for sale” as authorized under the commercial item definition .

we continue to believe that the requirement for a commercial item determination in certain cases provides an additional safeguard against a known risk and that such a requirement could be implemented within the existing framework of internal controls already in place .

we are sending copies of this report to secretaries of defense , homeland security , and the interior ; the director , office of management and budget ; and interested congressional committees .

this report will also be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions concerning this report , please contact me at ( 202 ) 512-4841 or by e - mail at dinapolit@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

staff who made key contributions to this report are listed in appendix vi .

this report focuses on the federal government's use of the test program for certain commercial items ( test program ) authority provided under federal acquisition regulation ( far ) subpart 13.5 .

this report addresses ( 1 ) the extent to which federal agencies have used the test program , and ( 2 ) its benefits and risks , if any .

to determine the extent to which federal agencies have used the test program , we analyzed data on contract actions awarded using the authority from the federal procurement data system - next generation ( fpds - ng ) .

we used fiscal year 2011 data from fpds - ng because it was the most recent fiscal year with complete data available when we began our review due to a lapse in the program's authority in 2012 .

based on obligations reported for fiscal year 2011 , we determined that the departments of defense ( dod ) , homeland security ( dhs ) , and the interior ( doi ) were the largest dollar users of the test program , collectively accounting for 74 percent of test program obligations .

within these departments , we focused on the five components reporting the greatest use of the test program as follows: dod: army materiel command , naval supply systems command , and air force materiel command ( 53 percent of dod use ) ; dhs: u.s. coast guard ( 54 percent of dhs use ) ; and doi: acquisition services directorate ( 65 percent of doi use ) .

to assess the reliability of the test program data reported in fpds - ng , we drew a stratified , random sample of 243 contracts from the population of all contracts with positive obligations in fiscal year 2011 for the five components we reviewed .

we grouped the three dod components into one stratum as they all operate under dod supplemental regulations .

the two civilian components were grouped into their own strata .

we sent a list of sampled contracts to each of the five components and asked them to verify whether they were correctly coded in fpds - ng and to provide documentation from the contract file that the test program was used .

based on this assessment , we determined that the test program data reported in fpds - ng were sufficiently reliable to determine the minimum extent to which the test program was used by the components we reviewed .

we did not sample contracts that were identified as not using the test program , and as such , did not assess the extent to which test program actions and obligations may be underreported .

to assess the extent to which agencies used the test program , we analyzed the number of new awards for commercial items and services in fiscal year 2011 that fell within the test program thresholds of $150,000 to $6.5 million ( based on the estimated value at award ) and identified the percentage that used the test program .

we interviewed contracting officials at the department and component - level to identify the factors they considered when determining whether or not to use the test program .

we did not assess the test program's higher threshold of $12 million when used in support of a contingency operation or to facilitate the defense against or recovery from nuclear , biological , chemical , or radiological attack since we determined that these contracts accounted for only 2 percent of fiscal year 2011 obligations made by the components in our review .

to determine the benefits and risks of using the commercial item test program , we reviewed relevant legislation , including the federal acquisition streamlining act of 1994 and the clinger - cohen act of 1996 , as well as applicable federal acquisition regulation ( far ) provisions .

we reviewed agency and component policy and guidance related to test program use and oversight , commercial item acquisitions , simplified acquisition procedures , and contingency contracting .

we also interviewed contracting officials from each of the five components as well as officials from dod's defense procurement and acquisition policy and the office of management and budget's office of federal procurement policy .

further , we selected and reviewed a nonrandom , nongeneralizable sample of 26 test program contracts including at least four of the largest test program contracts from each of the five components .

for the selected contracts , we reviewed the contract and other relevant documents , such as acquisition plans , market research documentation , solicitations , and justifications and approvals , and interviewed the contracting officers who awarded the contracts , or other cognizant officials .

to assess test program benefits , we analyzed contract file documents and interviewed contracting officers for the selected 26 contracts to determine how they applied the simplified procedures and how the procedures resulted in either a savings of time or reduction in administrative burden .

we reviewed relevant regulation and compared the requirements for using the test program under far part 13 versus negotiated procedures under far part 15 which most officials told us they would likely use in the absence of the test program or existing mechanisms such as indefinite - delivery contracts and blanket purchase agreements .

for eight competitively awarded test program contracts , we also compared the contracting lead time — the amount of time between issuance of a solicitation and the date of contract award — for contracts awarded using the far part 13 test program and the estimated lead time for contracts using far part 15 negotiated procedures based on agency guidance .

we also analyzed the extent to which time savings , if any , were derived from the flexibility afforded by the test program versus the streamlined procedures available for all far part 12 commercial item acquisitions that are independent of the test program .

in addition , we analyzed contract file documents and interviewed contracting officers to determine how they used the test program and what procedures they would have used if the test program were not available .

to identify and assess risk , we analyzed agency policies and interviewed contracting officials to determine the manner in which test program contracts are reviewed and approved .

for noncompetitive awards , we determined whether the awards were justified in writing and approved at the required level when required .

additionally , we analyzed contract file documents to determine the extent to which contacting officers conducted market research .

for dod components , we reviewed test program contract files to determine whether commercial item determinations were included when required by dod regulation and whether these determinations were approved at the required level .

we determined whether or not the required documentation was provided but did not assess its adequacy .

to identify instances , if any , of fraud , waste , or abuse of the test program authority , we contacted inspector general offices at dod , dhs , and doi , as well as the military services .

we obtained and reviewed relevant documentation , and discussed with agency officials , as needed .

we also obtained information from ofpp officials on the extent to which the test program has been cited in bid protests .

we conducted this performance audit from march 2013 to february 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact name above , the following staff members made key contributions to this report: penny berrier , assistant director ; jacob beier ; gary bianchi ; danielle greene ; robert graves ; ioan ifrim ; julia kennon ; angie nichols - friedman ; ada nwadugbo ; dae park ; kenneth patton ; sylvia schatz ; erin schoening ; and roxanna sun .

