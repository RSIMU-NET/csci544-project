the frequency of information security incidents at federal agencies , the wide availability of hacking tools , and steady advances in the sophistication and effectiveness of attack technology all contribute to the urgency of protecting the federal government's information and systems .

in addition to these threats , we have consistently identified significant weaknesses in the security controls on federal systems , including desktops and laptops ( i.e. , workstations ) that have impacted the confidentiality , integrity , and availability of government information .

due to the persistent nature of these vulnerabilities and associated risks , we have designated information security as a governmentwide high - risk issue since 1997 in our biennial reports to congress .

in an attempt to standardize and thereby strengthen information security , the office of management and budget ( omb ) launched the federal desktop core configuration ( fdcc ) initiative in march 2007 .

the initiative mandated that federal agencies implement standardized configuration settings on workstations with windows xp or vista operating systems .

in view of the importance of fdcc in improving the ability of the federal government to safeguard its systems and protect sensitive information , you asked us to ( 1 ) identify the goals , objectives , and requirements for the initiative ; ( 2 ) determine the status of actions federal agencies have taken , or plan to take , to implement the initiative ; and ( 3 ) identify the benefits , challenges , and lessons learned in implementing this initiative .

we conducted our review at each of the 24 major federal agencies covered by the chief financial officers act , where we obtained and analyzed policies , plans , status reports , and agency descriptions of challenges relative to the requirements of the initiative .

we also developed a data collection instrument to gather information on the status of fdcc implementation at the 24 agencies as of september 2009 .

we compared agency documentation and descriptions of challenges with omb program requirements and relevant national institute of standards and technology ( nist ) guidance , which we confirmed through interviews with omb and nist officials .

we also met with staff from all 24 offices of the inspector general regarding their audit work performed relative to the initiative to obtain information on their audit methodology , findings , and related documentation .

based on our review of the adequacy of work performed , we have sufficient assurance to rely on work completed by the inspectors general in the context of our audit objective related to whether the agency had documented deviations and had incorporated language related to use of fdcc settings into its contracts .

we conducted this performance audit from december 2008 to march 2010 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

further details of our objectives , scope , and methodology are included in appendix i .

cyber - based threats to federal systems and critical infrastructure are evolving and growing .

these threats can be intentional or unintentional , targeted or non - targeted , and can come from a variety of sources , including criminals , terrorists , and other adversarial groups , as well as hackers and disgruntled employees .

these potential attackers have a variety of techniques at their disposal , which can vastly enhance the reach and impact of their actions .

for example , cyber attackers do not need to be physically close to their targets , their attacks can cross state and national borders , and they can preserve their anonymity .

further , the growing interconnectivity among different types of information systems presents increasing opportunities for such attacks .

reports of security incidents from federal agencies are on the rise , increasing by more than 200 percent from fiscal year 2006 to fiscal year 2008 .

in february 2009 , the director of national intelligence testified that foreign nations and criminals had targeted government and private sector networks to potentially disrupt or destroy them , and that terrorist groups had expressed a desire to use cyber attacks as a means to target the united states .

as recently as july 2009 , media accounts reported that a widespread and coordinated attack over the course of several days targeted web sites operated by major government agencies , including the departments of homeland security and defense , the federal aviation administration , and the federal trade commission , causing disruptions to the public availability of government information .

such attacks highlight the importance of developing a concerted response to safeguard federal information systems .

compounding the growing number and kinds of threats , we — along with agencies and their inspectors general — have identified significant weaknesses in the security controls on federal information systems , which have resulted in pervasive vulnerabilities .

these include deficiencies in the security of financial systems and information and vulnerabilities in other critical federal information systems and networks .

these weaknesses exist in all major categories of information security controls at federal agencies ; for example , in fiscal year 2008 , weaknesses were reported in such controls at 23 of the 24 major agencies .

specifically , agencies did not consistently authenticate users to prevent unauthorized access to systems ; apply encryption to protect sensitive data ; and log , audit , and monitor security - relevant events , among other actions .

our recent work focusing on specific agencies has also revealed security weaknesses , as illustrated by the following examples: in 2009 , we reported that three national aeronautics and space administration centers had not , among other things , sufficiently restricted system access and privileges to only those users that needed access to perform their assigned duties , appropriately implemented encryption to safeguard sensitive information , and expeditiously applied a critical operating system patch or patches for a number of general third - party applications .

at the same time , the agency experienced numerous cyber attacks and malicious software infections , thereby exposing critical and sensitive data to unauthorized access , disclosure , and manipulation .

we recommended that the agency take steps to mitigate these weaknesses and fully implement a comprehensive information security program .

in the same year , we reported that the financial crimes enforcement network , a bureau within the department of the treasury , had not consistently implemented effective password controls or effectively controlled user identification and authentication .

as a result , there was increased risk that malicious individuals could gain inappropriate access to sensitive systems and data .

we recommended that the agency take steps to fully implement an agencywide security program .

in 2008 , we reported that although the department of energy's los alamos national laboratory — one of the nation's weapons laboratories — had implemented measures to enhance the information security of its unclassified network , there were still vulnerabilities in monitoring and auditing compliance with security policies and controlling and documenting changes to a computer system's hardware and software .

finally , we reported in 2007 that the department of homeland security had significant weaknesses in computer security controls intended to protect the information systems used to support its u.s .

visitor and immigration status indicator technology program for border security .

for example , the department had not implemented controls to effectively prevent , limit , and detect access to computer networks , systems , and information .

specifically , it had not provided adequate logging or user accountability for the mainframe , workstations , or servers and had not consistently maintained secure configurations on the application servers and workstations at a key data center and points of entry .

in each of these cases , we made recommendations for strengthening or fully implementing agencies' information security programs .

in addition to the responsibilities of individual agencies , omb and nist play key roles in ensuring the security of federal systems and information .

under the federal information security management act of 2002 ( fisma ) , omb is responsible for developing and overseeing the implementation of policies , principles , standards , and guidelines on information security , and reviewing agency information security programs at least annually .

in addition , the act requires that omb report to congress no later than march 1 of each year on the status of agency compliance with fisma .

the act , which sets forth a comprehensive framework for ensuring the effectiveness of information security controls over information resources that support federal operations and assets , also assigned nist responsibility for developing standards and guidelines ( for systems other than national security systems ) that include minimum information security requirements .

fisma also assigns specific responsibilities to agencies to document and implement agencywide security programs and report on their security policies , procedures , and practices .

for example , agencies are responsible for developing and complying with minimally acceptable system configuration requirements .

finally , fisma requires agency inspectors general to annually evaluate agency information security activities .

to help carry out its responsibilities for ensuring federal information security , omb launched the fdcc initiative in march 2007 .

this initiative required federal agencies to implement common security configurations on windows xp and vista operating systems by february 2008 .

subsequently , omb issued several other memorandums detailing additional requirements and guidance to agencies on completing implementation of the initiative .

omb also has responsibility for approving any changes to the settings or setting parameters .

at the request of omb , nist published the first beta version of the fdcc configuration settings in july 2007 for federal workstations that use windows xp or windows vista as their operating system .

fdcc was based on settings developed by the air force in partnership with the national security agency , defense information systems agency , nist , and representatives from the army , navy , and marines .

over the course of the next 11 months , nist made several updates to the content and posted the revised versions on its web site .

the first major version of the configuration settings , version 1.0 , was posted on nist's web site in june 2008 after a period of public comment .

based on implementation information reported by the agencies to nist in march 2008 , agency feedback on settings that were problematic to implement , and comments from the federal community , omb had nist remove 40 settings from the original beta version for version 1.0 .

in addition to publishing the fdcc settings , nist also has responsibility for: developing resources , in collaboration with microsoft , to aid agencies in deploying and testing the security configuration settings within their computing environments .

these include group policy objects , which allow agencies to deploy the settings to desktop and laptop computers agencywide , and virtual hard - disk files , which allow agencies to test the settings in a non - operational environment .

these files were first made available for agencies to download from nist's web site starting in july 2007 and were later updated with the release of major version 1.0 .

establishing the security content automation protocol ( scap ) , which can be used to support the automated checking , measuring , and monitoring of the fdcc settings for compliance .

product vendors can create a tool ( i.e. , application ) that uses scap for these activities .

validating scap tools to ensure that a tool uses the features and functionality available through scap .

in order for a tool to receive validation , a vendor must first have the tool tested by 1 of 10 independent testing laboratories accredited under nist's national voluntary laboratory accreditation program .

the testing results are then sent by the laboratory to nist for review .

if the tool passes , nist will validate the scap tool , which is valid for 1 calendar year .

making technical changes to the scap that support the fdcc settings , such as when new specifications are added , existing specifications are updated , or when a more efficient method is found to test a particular setting .

nist has released two additional major versions to make technical modifications to the scap: version 1.1 in october 2008 and version 1.2 in april 2009 .

nist also publishes patch content updates based on microsoft's patch releases .

posting frequently asked questions on its web site on behalf of omb to answer agencies' questions about testing , deployment , reporting deviations , and use of scap tools for evaluation of compliance .

the questions have also provided clarification of the settings requirements and their applicability to different types of computers , including contractor - owned or operated machines .

these questions are revised on a periodic basis as needed and as determined by nist .

in its march 2007 directives to agencies to implement fdcc , omb established two goals for the initiative: improve information security and reduce overall information technology ( it ) operating costs for agencies that use or plan to use windows xp or vista operating systems on their workstations .

by implementing the initiative , omb intended that agencies should be able to achieve the following objectives: provide a baseline level of security through the use of standardized configuration settings that limit access privileges granted to users and other access controls , thereby controlling what a user may or may not do on his or her workstation .

the settings create a baseline from which agencies may increase the level of security by making the settings more restrictive or by employing firewalls and intrusion detection systems along with other security devices and practices .

reduce risk from security threats and vulnerabilities by employing the use of standards that are more restrictive than the default settings of the manufacturer .

for example , the required settings do not allow the installation of unauthorized software , which lowers the risk of introducing a virus or other malicious device along with the software .

save time and resources by requiring all fdcc workstations within an agency to use the same settings .

this standardization also allows an agency's it department to be more efficient in repairing computer problems .

improve system performance by restricting the access privileges of administrators and users to only those necessary to perform their duties .

this helps to limit downloading of unapproved software and information that could tie up system and help desk resources .

decrease operating costs by using standard configuration settings that allow it personnel to solve a workstation problem once and then replicate that solution for every workstation in the agency , saving labor and time .

ensure public confidence in the confidentiality , integrity , and availability of government information by standardizing strong security settings across all federal agencies .

this will help to protect federal systems from cyber attacks and may help to ensure the public's confidence that their personal information will not be compromised .

in its initial memorandums and subsequent guidance , omb identified several requirements with which agencies were directed to comply in order to implement fdcc .

the following are the key fdcc requirements: submit a draft implementation plan to omb by may 1 , 2007 .

agencies were required to submit an implementation plan to omb describing how they intended to ( 1 ) test configuration settings in a non - production environment to identify any adverse effects on system functionality ; ( 2 ) implement the settings and automate monitoring and use ; ( 3 ) restrict administration of these settings to authorized professionals ; ( 4 ) ensure , by june 30 , 2007 , that new it acquisitions include the settings and require it providers to certify that their products operate effectively using the settings ; ( 5 ) apply microsoft patches available from the department of homeland security when addressing new windows xp or vista vulnerabilities ; ( 6 ) provide to nist documentation of any deviations from these settings and the rationale for the deviations ; and ( 7 ) ensure the settings are incorporated into agency capital planning and investment control processes .

adopt the windows xp and vista security configuration settings by february 1 , 2008 .

agencies were required to implement the fdcc configuration settings on all government - owned desktops and laptops that use windows xp or vista operating systems and the internet explorer 7 or windows firewall applications .

this requirement was later clarified to include desktops and laptops that are owned or operated by a contractor on behalf of or for the federal government or that are integrated into a federal system .

the requirement excludes servers , embedded computers , process control systems , specialized scientific or experimental systems , and similar systems using these operating systems .

fdcc major version 1.0 includes 674 configuration settings for windows xp and windows vista systems , when bundled with internet explorer 7 and windows firewall .

examples of these settings include the following: specifies the number of minutes a locked - out account remains locked out before it automatically unlocks .

specifies the minimum number of characters a password must have .

specifies whether or not the user is prompted for a password when the system resumes from sleep mode .

requires the use of federal information processing standards - compliant algorithms for encryption , hashing , and signing .

shuts the system down immediately if it is unable to log security audits .

creates a log when windows firewall with advanced security allows an inbound connection .

the log will detail why and when the connection was formed .

document deviations and have them approved by a designated accrediting authority .

agencies were required to document deviations initially as part of their draft implementation plan efforts .

omb later required agencies to report these deviations to nist in march 2008 .

omb also later noted that configuration setting deviations are to be approved by the department or agency accrediting authority .

acquire a scap tool and use it to monitor fdcc .

agencies are required to acquire a nist - validated scap tool and to use these tools when monitoring the settings .

ensure that new acquisitions include security configuration settings .

agencies are required to ensure that new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

submit fdcc compliance reports to nist by march 31 , 2008 .

agencies were required to submit a spreadsheet that summarized workstation counts , setting deviations , and descriptions of plans of action and milestones for the deviations , along with related reports generated by a scap tool for each operational environment present within the agency .

report on status of fdcc compliance in annual fisma reporting .

none of the agencies has fully implemented all fdcc configuration settings on all applicable workstations , although most have complied with other requirements .

specifically , 11 agencies reported they had completed implementation of an agency - approved subset of the fdcc settings and do not plan to implement all the configuration settings , while the remaining agencies reported they are still completing implementation of the settings .

however , most agencies have generally complied with other initiative requirements .

for instance , 19 agencies have fully documented their deviations and 16 have established a policy for having those deviations approved by a designated authority .

in addition , 15 agencies have acquired and deployed a nist - validated scap tool to monitor the compliance of their setting implementation .

eight agencies have also incorporated language into their contracts to ensure that new acquisitions comply with fdcc .

while agencies were required to submit a draft implementation plan to omb by may 1 , 2007 , fewer than half of the agencies developed plans that addressed the seven actions necessary to fully implement the initiative .

of the 24 agencies , 19 provided their plans to us , while 5 agencies either did not develop an implementation plan or were unable to locate a copy of the plan .

of the 19 plans , 11 described how the agency intended to implement each of the seven actions required by omb .

the remaining 8 plans either did not address the actions or described only some of them .

table 1 shows how many agencies addressed each of the required actions in their fdcc implementation plans .

officials from one of the agencies whose plan did not address the required activities told us that omb had provided feedback and requested changes to the plan , but the remaining agencies indicated that omb had not provided feedback on the submitted plans and had not requested any changes .

omb was unable to confirm whether the 24 agencies had submitted the implementation plans by the required deadline because , officials stated , this information had been archived with the previous administration .

as discussed later in the section on lessons learned , agencies experienced problems in implementing this requirement due to unrealistic deadlines .

though agencies were required to adopt and implement the fdcc settings by february 1 , 2008 , as of september 2009 , none of the 24 major agencies reported that they had adopted and fully implemented the complete set of prescribed settings on all applicable workstations .

instead , all agencies planned to implement a subset of the fdcc settings , which they referred to as their agency baseline ; these baselines included deviations from the approved parameters established by fdcc , in some cases for up to one - fifth of the settings .

as of september 2009 , 11 agencies reported they had completed implementation of their baselines on all applicable workstations , and 11 were still in the process of finishing implementation of their baseline .

the other 2 agencies were unable to provide sufficient data to determine the status of implementation because they either lacked a scap tool or had data reliability issues due to using multiple tools .

 ( see app .

ii for more details on the status of each agency in implementing the fdcc settings , as of september 2009. ) .

for those agencies that were still in the process of completing implementation of their baseline , agency officials reported various milestones for expected completion ; however , some of those deadlines had not been met , and other agency officials did not report a milestone for completion .

for example , a few agency officials indicated they would complete implementation by september 2009 ; however , this deadline was not met .

figure 1 summarizes the status of agency - reported implementation of their fdcc baselines for applicable workstations with windows xp and vista operating systems .

agency officials told us that several factors had influenced their decision to establish deviations , whether less or more stringent , from the settings .

these factors included cases where fdcc settings had an adverse impact on applications , production , or legacy systems ; conflicted with agency policy ; prohibited agency administrators from completing tasks ; and impaired the capability to provide customer support or remote assistance .

in establishing their baselines , agencies allowed a range of deviations , some with parameters that were less stringent ( eg , less secure ) than the approved parameters , while others were more stringent .

of the 24 agencies , 23 provided us a list of their deviations and 1 agency indicated it had not developed a list .

each of the 23 lists identified deviations that were less stringent than the fdcc settings .

specifically , 15 agencies had 10 or more less - stringent deviations , and 6 agencies had 40 or more less - stringent deviations , which is 6 percent of the 674 total number of fdcc settings .

table 2 shows the range of the number of less - stringent deviations and the corresponding number of agencies .

our analysis revealed ten most common less - stringent deviations across the federal government .

for example , 21 of the 23 agencies that provided deviation lists had a deviation for the use of encryption algorithms that are compliant with federal information processing standards , and 17 agencies had a deviation for the setting regarding digital signatures of client communications .

table 3 shows the 10 most common less - stringent deviations and the number of agencies that reported having them .

additionally , 7 agencies listed deviations that were more stringent ( eg , had parameters that were more secure ) than the fdcc settings .

of the 7 agencies with more - stringent deviations , 1 had 10 or more of these more - stringent deviations , while the remaining 6 agencies had fewer than 10 .

there is also a common set of these more - stringent deviations among the 7 agencies .

for example , 3 agencies have a deviation for duration accounts can be locked out , 2 agencies have a deviation for how many invalid logon attempts can occur before an account is locked out , and 2 agencies have a deviation for the type of user who can format and eject removable media .

until those agencies that have not completed implementation of their fdcc baseline ( see app .

ii ) establish firm milestones for completion and complete implementation , agencies risk not achieving the potential benefits of the initiative .

although omb guidance indicates that agencies are to document and have a designated accrediting authority approve deviations from fdcc , several agencies did not do so .

of the 24 agencies , 23 had deviations and 1 did not maintain a list .

of the 23 , 19 had fully documented their deviations but 4 had not .

in addition , 16 agencies established a policy to have deviations approved by a designated accrediting authority , while 8 agencies have not established such a policy .

table 4 shows which agencies have documented deviations and have a policy in place to approve deviations by a designated authority .

agency officials who had not documented deviations said they either did not maintain lists for field offices or had not yet completed the process for establishing the agency baseline and documenting the deviations .

officials from agencies that did not have a policy in place for approving deviations told us they were still working to develop an approval process .

until agencies document their fdcc deviations or have a policy in place to approve those deviations , they cannot fully assess the potential risk of not implementing the required settings and they cannot ensure that configuration baselines are effectively controlled and maintained .

agencies were required to obtain a nist - validated scap tool and use it to consistently monitor the implementation of the configuration ; however , while 15 agencies reported acquiring and deploying nist - validated tools , 6 had not .

of the 3 remaining agencies , some of their components have a nist - validated scap tool , while the other components either do not have a tool or do not use a nist - validated tool for monitoring workstation configurations .

regardless of whether the tool has been validated or not , most agencies used one to monitor fdcc implementation .

however , 2 agencies that had a validated tool had not yet established a policy for monitoring compliance .

table 5 shows which federal agencies have acquired a nist - validated tool and were using it to monitor their workstation configurations .

at agencies that did not have a nist - validated scap tool , officials told us they were in the process of acquiring a tool but had been delayed due to funding issues .

for those agencies where only some components had acquired a tool , officials told us their components were responsible for acquiring a tool and noted that funding had been an issue .

at agencies without a policy for monitoring implementation , officials told us that either a policy had not been finalized or a policy would be developed once a scap tool had been acquired .

however , officials from one of these agencies noted that although they lacked a policy , they were still performing some monitoring of workstations .

until agencies acquire and deploy a nist - validated scap tool and develop , document , and implement policies to monitor compliance , they will not be able to ensure that the fdcc settings have been successfully implemented to help protect the confidentiality , integrity , and availability of their information .

although omb requires agencies to include language in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them , most agencies have not done so .

eight agencies had incorporated the language into their contracts , while 13 agencies had not , and 3 agencies had partially implemented the requirement .

table 6 shows which agencies have incorporated language into their contracts .

officials from agencies that had not included language in the contracts had either included language in only a portion of the contracts reviewed , or the agency indicated it was still working on incorporating the language into its contracts .

in addition , two agencies had one or more components that had not included the language in contracts .

until these agencies ensure that language is included into contracts to ensure that new acquisitions include fdcc settings and products of information technology providers operate effectively using them , agencies will not be able to ensure that new acquisitions are in compliance with fdcc requirements .

although most agencies submitted a compliance status report to nist , the documentation was not always complete , including plans for mitigating deviations , or timely .

agencies were required to report to nist the status of their compliance with fdcc by march 31 , 2008 , and submit a list of deviations , their plans of action and milestones for mitigating the deviations , and copies of reports generated by their scap tools .

the majority of the agencies in our review submitted documentation to nist ; however , 2 agencies told us they had not submitted information to nist , and 1 agency was unable to locate all the documents submitted .

of the 21 agencies that provided documentation , 12 agencies submitted all of the required information and documents .

the remaining 9 agencies were either missing the required information or did not submit all of the required scap tool reports .

in addition , while many of the agencies listed deviations , they either noted they did not plan to mitigate the deviations , or made general statements about addressing them at some point in the future .

furthermore , only 13 of the agencies in our review generally met the march 31 , 2008 , deadline for submission , while the remaining agencies took an additional month or more to provide documentation to nist .

as discussed later in the section on lessons learned , agencies experienced problems in implementing this requirement due to unrealistic deadlines .

while implementation of fdcc can result in improvements to agencies' information security as well as other benefits , such as cost savings , attempting to meet the requirements yielded lessons learned that could improve the implementation of future versions of fdcc or other workstation configurations .

in addition , agencies continue to face significant challenges in meeting fdcc requirements , monitoring their implementation of the settings , and measuring benefits of the initiative , among other things .

fdcc has the potential both to increase agencies' information security and to standardize their management of workstations .

other potential benefits include cost savings arising from reduced power usage .

fdcc implementation enhances security by requiring stricter security settings on workstations than those that may have been previously in place at federal agencies .

specifically , some of the key configuration settings serve to secure agency workstations by restricting user and administrative rights to particular system functions .

these settings reduce the potential for malware and other known vulnerabilities to affect agency workstations because the stricter access rights would prevent their automatic download and installation .

as an example , officials at two agencies reported that fdcc was responsible for protecting their workstations from recent malicious code infections .

the settings also reinforce access controls by restricting users' rights to what is necessary for their work .

ten of the agencies in our review attributed either increased security or increased security awareness to implementation of the settings and were generally supportive of a stricter configuration for the agency .

fdcc implementation also enabled agencies to reap the benefits of having more standardized configurations within agency computing environments .

for example , a more secure enterprisewide windows configuration and consistent workstation profile ( i.e. , the set of configuration settings and other software applied to a workstation ) across the agency can not only improve security but can also make it easier to manage changes to the security features of workstation software , such as applying updates or patches .

updates or patches can be applied more expeditiously because there are fewer workstation profiles that they must be tested on , which also reduces the amount of necessary supporting documentation .

agency officials we spoke to confirmed that fdcc provided an improved understanding of their computing environment as well as a consistent desktop image across the department .

another official stated that adopting and implementing the configuration settings would raise awareness of the importance of workstation configuration management across the government .

beyond the benefits to enhancing security within agency computing environments , there are other potential , if unanticipated , benefits to implementing particular settings and standardizing them across the federal government .

for example , while settings related to activating and password - protecting screen savers can provide added security by locking the workstation while the user is not present , they could also reduce power consumption and lead to savings in utility costs .

one agency official said his agency was anticipating saving between $10 million and $15 million a year by implementing the power settings , and would be deploying a tool to track this data .

in addition , an agency official from the chief information officers council's fdcc change control board said the board was working on recommending what it considered “green settings” to omb , which would also potentially reduce consumption of power and the paper used to print documents .

officials at one agency also told us that because they had observed several benefits — including improved security , cost avoidance through acquisition of workstations with settings already implemented , and a simplification of the software development process — by implementing their agency fdcc baseline , they were in the process of developing or finalizing configuration settings for other operating systems and servers .

there are a number of lessons to be learned from the management and implementation of the fdcc initiative which , if considered , could improve the implementation of future versions of fdcc or other configuration efforts .

omb did not provide a realistic time frame for agencies to meet the requirements of the initiative and complete implementation of fdcc by february 2008 .

this is due in large part to omb not considering several constraints when establishing time frames for agencies to complete the requirements and implement the beta version of the settings within 7 months , including: agencies were required to submit draft plans to implement the settings by may 1 , 2007 , approximately 3 months before being informed of the settings they were required to implement .

only one scap tool was validated in time for agencies to use to report the status of implementation to nist , and one agency found that the tool did not produce the needed reports required for nist reporting .

the earliest any of the other tools were validated was 7 months after the deadline .

multiple changes occurred to the fdcc content — including the settings , scap , and resources — that agencies were supposed to use in order to complete implementation by the february 2008 deadline .

in addition , another version of the settings was released between the february deadline and the march 2008 compliance reporting deadline .

furthermore , once the beta version of the settings was revised and major version 1.0 was released in june 2008 , omb did not establish a deadline for agencies to complete implementation of this version .

omb officials confirmed they have not established a schedule for announcing changes to fdcc versions or implementation deadlines .

however , they stated they were working with the chief information officers council and its newly developed fdcc change control board to provide a framework for soliciting input and feedback on future versions of the settings on a yearly basis .

nevertheless , without realistic deadlines that are effectively communicated with sufficient notice , agencies will continue to face challenges in meeting implementation deadlines for future versions of fdcc .

omb and nist guidance with regard to deviations was not always comprehensive , and agencies interpreted it in divergent ways .

specifically , omb memorandums and guidance published on nist's web site were not clear as to under what conditions deviations were permitted ; whether deviations could be permanent , or should be mitigated in a timely how deviations should be documented , tracked , and approved by a how frequently and to whom deviations should be reported .

as a result , agencies interpreted this guidance in significantly different ways .

only one agency interpreted the requirements to mean that no deviations were permitted , while other agencies , by contrast , interpreted full implementation of fdcc to mean applying 85 to 95 percent of the settings , with deviations allowed under certain circumstances .

in addition , most agencies responded , either in their descriptions of plans of action and milestones or in interviews , that they had permanent deviations from fdcc , indicating they interpreted the guidance to mean that deviations could be permanent .

however , several agencies also reported they may reduce the number of deviations as they upgrade , modify , or replace existing systems and applications .

in addition , agency processes to document and approve deviations varied .

for example , some agencies documented and approved deviations at the agency level while other agencies allowed their components to determine the number of deviations and approve them .

some agency officials told us their list of deviations may not be complete because they provided deviations from only a few components , or did not track or maintain a list of deviations at the component level .

for those agencies , officials noted they did not have visibility into the deviations documented and approved at the component level because responsibility for this was delegated to the components .

furthermore , agencies' interpretation of the requirement to report deviations to nist varied , with some agencies stating they were only supposed to report deviations to nist in march 2008 , while other agencies said they reported deviations to nist whenever they updated their lists .

omb officials stated that full compliance with the configuration meant implementing all the settings without deviations on all applicable workstations , although they allowed agencies to document deviations and later required them to be approved .

nevertheless , without further clarification on the approval , permanence , and reporting of deviations , the federal government will continue to be hindered in consistently implementing fdcc , and omb will be hindered in assessing the status and effectiveness of implementation across federal agencies .

the variety of approaches agencies took to testing the settings prior to implementation affected how successful they were .

in one case , an agency implemented the settings without testing , discovered problems , and subsequently changed its approach to include testing prior to implementation .

another agency reported having success with collaborative testing among agency components , which included officials from the components sharing results and other information at regular meetings .

officials from another agency stated that automated testing was a better approach because it allows for easier confirmation that there is a standard workstation configuration in use on the agency's systems .

ensuring that testing is carried out prior to implementation , with opportunities for information sharing and consideration of the benefits of automation , can help agencies make implementation of future versions of fdcc or similar configurations more successful .

agencies that implemented the settings in a phased , or sequential , fashion were able to avoid disruption in their operations and identify problems that arose during implementation .

officials from four agencies cited the benefits of or need for using such a phased implementation approach , rather than implementing the settings in one pass .

one agency's officials observed that sequential implementation was key to avoiding system disruption and down time because settings were not applied to all components within the agency at the same time .

following such an approach for future versions of fdcc and other configurations could prove beneficial to agencies .

another success factor in implementing fdcc was frequent communication and collaboration among and within agencies .

officials from two agencies noted that collaboration among its agency components on testing was helpful in addressing problems that occurred .

agencies noted that keeping the lines of communication open , both among agency components and between omb and nist and other agencies , would help in making such an initiative more successful .

one agency official recommended that there should be a way for nist to communicate operational impacts prior to the release of new fdcc settings , and another suggested that future versions of fdcc should be vetted by the broader it community before being rolled out to agencies .

officials from another agency stressed the importance of having communication and outreach among agencies to discuss fdcc issues and changes .

lastly , officials from one agency suggested having fdcc compliance sessions where agencies could discuss issues and learn from one another's experiences .

further collaboration between omb , nist , and agencies could increase the effectiveness of implementation among agencies and the chances for the success of similar future initiatives .

independent testing performed by the general services administration and department of the interior's inspector general found compliance results that differed from agency - reported information .

in a policy utilization assessment conducted over 2 years in multiple phases , the general services administration tested fdcc implementation at three agencies between december 2008 and february 2009 .

the results generally differed from agency - reported information on the level of policy implementation , level of compliance , and number of deviations reported between october 2008 and november 2008 .

at all three agencies , the scan results showed a higher level of policy implementation than the agencies had reported .

in addition , two agencies learned they had a lower number of deviations on the workstation sample than they had reported , and two agencies were provided a more accurate indication of their level of compliance .

in september 2009 , the inspector general of the department of the interior reported widespread noncompliance with mandatory fdcc settings and noncompliance with agency directives at the agency .

based on testing performed during summer 2009 , interior averaged 68 percent compliance for the configuration settings , which varied from the compliance status reported to us .

in addition , the inspector general noted that agency components reported an additional 323 deviations at the components that were not documented and approved according to the agency's policy .

the inspector general made a recommendation to ensure interior's compliance with fdcc guidance .

these results suggest that agency self - reported compliance may not always be accurate and that continued independent testing can provide important insight into the extent of fdcc implementation .

additional independent testing performed by external parties could provide opportunities for agencies to acquire additional information to assist them in complying with fdcc requirements .

in launching an initiative such as fdcc , having sufficient notice to marshal the necessary resources can improve agencies' chances of success .

agencies reported that having advance notice of the requirement to implement the initiative , with sufficient time for preparation and training , was necessary to successfully implement the initiative .

officials from one agency stated that such mandates should be widely announced well in advance of anticipated completion dates to allow all agencies appropriate lead time to ensure that budgets and resources would be available and that requirements and resulting impacts could be completely assessed .

further , agencies commonly reported a lack of sufficient resources ( time , money , labor , technical expertise ) to implement the fdcc settings , understand how the settings would affect their environments , address issues found with testing , and purchase a scap tool .

some agencies cited having to reallocate approved funding to cover the costs of implementation and the purchase of the tools .

although most agencies could not provide estimates of the time and labor spent implementing fdcc , several agencies provided estimates of the costs of implementation and purchasing scap tools , which ranged from the tens of thousands to hundreds of thousands of dollars .

in addition , officials from a few agencies stated they did not always have staff dedicated specifically to fdcc , which contributed to delayed implementation .

ensuring sufficient lead time can help agencies better plan use of their resources to implement initiatives like fdcc .

agencies face several ongoing challenges to fully complying with fdcc requirements , including retrofitting their existing applications and systems to comply with the settings , assessing the risks associated with deviations , and monitoring workstations to ensure that the settings are applied and functioning properly .

applying the configuration settings has and will continue to cause problems for agencies due to the variety of applications , legacy systems , and agency environments that exist within the federal government .

in particular , agencies have legacy systems or applications that use old software that have to be reconfigured to work with the settings .

in addition , while some agency environments consist of a small number of offices with under 10 thousand workstations , other agency environments have multiple components with hundreds of thousands of workstations that are spread out geographically across the country , and in a few cases , the world .

although agencies were required to implement all the fdcc settings , the number and scope of the deviations that agencies had to implement highlight the magnitude of the challenge that agencies faced in implementing the settings .

agency officials confirmed during interviews that there were several challenges in retrofitting their systems and applications to comply with the settings , including the following examples: some of the settings had affected other settings on workstations and servers , and it had been a challenge to determine which fdcc settings were responsible .

some of the settings impaired the functioning of custom programs , caused problems in environments , or interfered with basic functions ( eg , network printing ) .

the settings prevented the agencies from accessing legitimate web sites , such as certain federal , state , and local government sites .

applying particular fdcc settings to legacy systems or applications would require agencies to update their applications or operating systems .

however , potential solutions to these challenges are either not simple or may not exist .

as new versions of the settings or other configurations are established , it will be important for omb to recognize that retrofitting systems and applications to comply with new settings in complex environments will remain an ongoing challenge for agencies , and that sufficient time for implementation and the use of deviations may be necessary .

however , omb has not provided guidance to agencies on submitting plans for mitigating deviations , including the resources necessary for doing so .

until omb provides guidance to agencies on submitting plans of actions and milestones for mitigating deviations , to include resources necessary for doing so , omb will lack sufficient information to make decisions about the use of deviations and whether potential changes to fdcc are warranted .

a related challenge for agencies is sufficiently assessing the risks associated with deviations from the official fdcc settings .

as mentioned earlier , all agencies in our review had deviations , regardless of whether these deviations had been sufficiently documented or approved .

there are risks associated with deviations from individual settings and groups of settings , not only at individual agencies but among agencies , depending on the agency's computing environment .

for instance , having deviations such as passwords with a minimal number of characters , combined with allowing multiple users to connect to the workstation over the network and enabling wireless communication on the workstation , increases the risk that unauthorized users could gain access to workstations and sensitive government information .

however , many of the agencies in our review did not describe a process for assessing the combined risk of the deviations they had in place because deviations were submitted for approval on an individual basis , were submitted as part of a configuration that included other settings beyond fdcc , or , particularly at agencies where deviation approval was left up to components , the agency did not track the deviations at the component level .

although omb required agencies to approve deviations , it did not specify any guidance for agencies to use to consider the risks of having these deviations prior to approval .

until omb specifies guidance for agencies to use to assess the risks of having deviations prior to approving them , including the combined risk of deviations in place across the agency , workstations may remain particularly vulnerable to cyber threats .

challenges also exist in effectively and consistently monitoring the implementation of fdcc in order to ensure the settings have been implemented properly and are continuing to function as intended .

specifically , the frequency and scope with which agencies scan workstations for compliance may not be sufficient to ensure the settings are working properly , and the results could potentially be incomplete or inconsistent .

while some agencies scanned workstations on a weekly or bi - weekly basis , other agencies performed scans only when new patches or system updates had been installed or performed scanning only on a quarterly or annual basis .

the infrequent monitoring on the part of some agencies could be due to the scap tool used: agency officials without an enterprisewide tool noted that frequent monitoring was impractical because regularly scanning each workstation required them to individually scan up to tens of thousands of workstations .

in addition , while some agencies scanned every workstation on their network , other agencies only performed scans on test workstations , which could be insufficient if agency workstation configurations do not match the tested workstations .

scans of workstations on agency networks may also be incomplete in cases where user populations work remotely or have contractor - owned workstations .

agencies that use a scap tool to scan all workstations connected to their network may miss workstations belonging to these populations , which might not be connected to the network depending on the time of the scan .

consequently , agencies may be relying on incomplete information on whether the settings are working as intended .

while omb guidance indicates that agencies should monitor compliance using scap , the guidance does not specify the frequency or scope in which monitoring should be performed .

until omb improves its guidance on monitoring compliance using scap to include information on the frequency and scope with which agencies should perform monitoring , agencies may not be scanning with sufficient rigor to ensure the settings have been successfully implemented and are working properly .

agencies did not always have sufficient tools to monitor implementation and compliance with fdcc .

in particular , issues with the current nist - validated scap tools include the following: some tools generate errors when scanning for particular settings .

certain settings have to be checked manually because the tools do not scan for all settings .

some tools record false positives , particularly if the agency's parameter for a particular setting is stricter than the fdcc parameter .

it takes time for vendors to update their scap tools after nist changes scap content to address problems , with the result that the tools perform scans based on incorrect content .

agency officials we interviewed confirmed there were issues with the scap tools , and many agencies and their components found it easier to use some combination of nist - validated scap tools , group policy objects , or other configuration management software to monitor their configurations .

in addition , several agencies indicated they had acquired or were in the process of acquiring a different scap tool that would provide better functionality and capabilities in order to meet their needs .

nist officials confirmed they were aware of the issues with scap tools and stated they are taking steps to address them .

for instance , nist intends to release new requirements that scap tools must meet as well as change validation requirements so that vendors will be required to have their tools tested and validated against the new requirements within 1 year of the requirements being released .

nist requested comments on a draft of this document through january 2010 , but hasn't released a final version .

once nist releases the new requirements for scap tools and these tools are validated against these requirements , agencies should have more sufficient tools for monitoring implementation of fdcc .

although agencies have anecdotally reported a variety of benefits from efforts to implement fdcc , omb and agencies face challenges in accurately assessing the impact and measuring the benefits of the initiative .

this is because neither omb nor the agencies have developed specific metrics to measure the effectiveness and program impact of the initiative .

specifically , they have not required or collected measures or metrics that address how effectively the initiative is mitigating security risks or reducing costs , two of its stated goals .

for example , an official at one agency noted several benefits of implementing fdcc — a more secure user environment because of reduced user permissions , a stable development platform that resulted in cost savings and a simplification of the software development process , and a reduction in the number of customer support help calls and service calls by technicians .

however , the official admitted that he did not have specific metrics for quantitatively measuring these benefits .

implementing metrics that assess the effectiveness and program impact could give a more complete picture of the benefits of fdcc and help determine whether future versions of the settings or configurations for other operating systems or servers should be instituted .

in our september 2009 report , we recommended that omb , among other things , direct federal agencies to use balanced sets of information security measures that include effectiveness and impact , as well as compliance , and to require agencies to report on such a balanced set of measures .

without performance measures and guidance to agencies for reporting the benefits of fdcc , omb and federal agencies will be limited in their ability to determine if the initiative is meeting its goals of improving federal information security and reducing operating costs and if the initiative should be continued or expanded .

while agencies have taken steps toward implementing fdcc , work remains to be done in order to meet all the requirements established by omb .

specifically , many agencies have applied an agency - defined subset of the configuration settings to their windows workstations ; however , none of the 24 major agencies has fully applied all the fdcc settings .

further , not all agencies have put a process in place for documenting or approving deviations from the fdcc baseline and have not yet acquired the required scap tool to monitor compliance with the settings .

unless agencies fulfill these requirements , omb will not be able to ensure the effectiveness of the initiative .

the fdcc initiative was an innovative approach by omb to standardize and thereby strengthen information security at federal agencies , but lessons learned indicate ways that implementation could have been more successful .

specifically , omb did not establish realistic time frames for completion or provide comprehensive guidance on fdcc deviations , which has impacted agencies' ability to successfully implement the initiative .

in addition , collaboration among omb , nist , and the agencies , as well as independent testing of fdcc implementation by external parties , may help agencies be more successful in their implementation efforts .

finally , there are several ongoing challenges facing agencies in fully complying with the requirements , including retrofitting systems and applications amid complex environments , assessing the risks associated with deviations across each agency , and monitoring workstations to ensure the settings are applied and functioning properly .

as omb establishes additional versions of fdcc settings — or configuration settings for other applications or operating systems — understanding the lessons learned from implementation as well as the ongoing challenges agencies face will be essential to the initiative's success in ensuring public confidence in the confidentiality , integrity , and availability of government information .

to improve implementation of fdcc at federal agencies , we recommend that the director of omb take the following six actions: when announcing new fdcc versions , such as windows 7 , and changes to existing versions , include clear , realistic , and effectively communicated deadlines for completing implementation .

clarify omb policy regarding fdcc deviations to include: whether deviations can be permanent or should be mitigated in a timely manner ; requirements for plans of actions and milestones for mitigating deviations , including resources necessary for doing so ; guidance to use for assessing the risk of deviations across the agency ; and how frequently and to whom deviations should be reported to assist in making decisions regarding future versions .

inform agencies of the various approaches for testing the settings and implementing the initiative in phases , which may aid successful implementation .

assess the efficacy of , and take steps to apply as appropriate , other lessons learned during the initial implementation of this initiative such as the need for ( 1 ) additional collaboration efforts , ( 2 ) independent testing , and ( 3 ) advance notice of requirements , to assist agencies in implementing this initiative .

provide guidance on using scap tools to include information on the frequency and scope with which agencies should perform monitoring .

develop performance measures and provide guidance to agencies for reporting the benefits of fdcc .

we are also making 56 recommendations to 22 of the 24 departments and agencies in our review to improve their implementation of fdcc requirements that were not being met .

appendix iii contains these recommendations .

in providing e - mail comments on a draft of this report , the lead it policy analyst from omb's office of e - government and information technology stated that omb concurred with the report's findings , conclusions , and 6 recommendations addressed to omb .

we also sent a draft of this report to the 24 agencies in our review and received written , e - mail , and / or oral responses from all 24 agencies .

of the 22 agencies to which we made recommendations , 14 ( agriculture , defense , environmental protection agency , general services administration , health and human services , justice , national aeronautics and space administration , national science foundation , nuclear regulatory commission , small business administration , social security administration , treasury , u.s. agency for international development , and veterans affairs ) generally agreed with our recommendations .

one agency ( commerce ) did not comment specifically on our recommendations and the remaining 7 agencies generally concurred with some of our recommendations but provided qualifying comments with others .

the agencies' comments and our responses are summarized below: in oral comments on a draft of the report , the department of energy's acting associate chief information officer for cyber security generally concurred with 4 of our 5 recommendations .

however , he requested that our recommendations to ensure that all components acquire and deploy a nist - validated scap tool , and develop , document , and implement a policy to monitor compliance using a nist - validated tool be clarified to pertain only to those components that were required to implement fdcc .

we agree that this modification clarifies the intent of our recommendations and have modified those recommendations as appropriate .

further , in commenting on our fifth recommendation to ensure that fdcc acquisition language was included in contracts , the acting associate chief information officer for cyber security stated that the department will continue to evaluate our recommendation and determine an appropriate implementation approach .

in written comments on a draft of the report , the department of homeland security's chief information officer concurred with 3 of our 4 recommendations .

he also concurred , with a caveat , with our fourth recommendation to ensure that fdcc acquisition language was included in contracts .

the chief information officer stated that the department already has regulations in place to ensure new acquisitions meet fdcc requirements .

we agree that the department has regulations in place .

however , as indicated in our report , the fdcc acquisition language had not been incorporated into all contracts .

the department of homeland security's comments are reprinted in appendix viii .

in written and oral comments on a draft of the report , the department of housing and urban development's chief information officer generally concurred with 3 of our 4 recommendations .

in written comments on our recommendation that the department ensure fdcc acquisition language is included in contracts , he stated that the department had a policy in place for including clauses in contracts .

after subsequent discussion with department representatives , they orally concurred with our recommendation .

in written comments on our recommendation that the department develop , document , and implement a policy to approve deviations to fdcc by a designated accrediting authority , the chief information officer stated that the department had provided us with a copy of its policy for approving deviations in december 2009 .

after reviewing additional documentation provided , we agree that the department had met the requirement , modified the report as appropriate , and removed the recommendation .

the department of housing and urban development's comments are reprinted in appendix ix .

in written comments on a draft of the report , the department of the interior's assistant secretary for policy , management , and budget concurred with our recommendations , subject to modifications that reduced redundancy in the recommendations and clarified that components should follow the department's policy related to documenting and approving deviations , and acquiring and deploying nist - validated tools to monitor compliance with fdcc .

we agree that the suggested modifications clarified the intent of our recommendations , and have modified the recommendations accordingly .

the department of the interior's comments are reprinted in appendix x .

in written and oral comments on a draft of the report , the department of labor's assistant secretary for administration and management generally concurred with 1 of our 2 recommendations , subject to modification that clarified that fdcc acquisition language had been included in some contracts but not in all .

after reviewing additional documentation provided , we modified the recommendation as appropriate .

in written comments on our recommendation that the department complete deployment of a nist - validated scap tool , the assistant secretary for administration and management stated that deployment of the tool had been completed prior to the end of our audit field work .

after reviewing additional documentation provided , we agree that the department had met the requirement , modified the report as appropriate , and removed the recommendation .

the department of labor's comments are reprinted in appendix xi .

in written and oral comments on a draft of the report , the office of personnel management's chief information officer generally concurred with 3 of our 4 recommendations .

in written comments on our recommendation on documenting deviations and having them approved by a designated authority , he said that the department has documented its deviations and approved them .

after subsequent discussion with department representatives , they orally concurred with our recommendation .

in addition , in written comments on our recommendation to develop , document , and implement a policy to approve deviations to fdcc by a designated authority , the chief information officer stated that the agency has a policy in place .

after reviewing documentation provided , we agree that the department had met the requirement , modified the report as appropriate , and removed the recommendation .

the office of personnel management's comments are reprinted in appendix xiii .

in e - mail and oral comments on a draft of the report , the department of transportation's chief information security officer generally concurred with our 2 recommendations , subject to modification that clarified that the department had acquired a validated tool and was in the process of fully deploying it .

after reviewing additional documentation provided , we modified table 5 in the report to include a table footnote indicating a tool had been acquired but not deployed and revised the recommendation as appropriate .

in addition , in e - mail comments on our recommendation to ensure that fdcc acquisition language is included in contracts , the chief information security officer stated that the department had provided a copy of the policy guidance on contract clauses to us .

after subsequent discussion with department representatives , they orally concurred with our recommendation .

in addition , several agencies also provided technical comments , including one of two agencies to which we did not make recommendations .

we have incorporated these comments as appropriate .

the remaining agency to which we did not make recommendations stated that it did not have any comments .

furthermore , for appropriate coverage of a federal - wide information technology contract issue , the department of defense suggested we add a recommendation that contract language be included in the federal acquisition regulation "to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them. .

however , it was not within the scope of our review to evaluate whether such standard contract language was necessary or what it would entail .

nonetheless , the department of defense may wish to pursue this suggestion with omb and other stakeholders for possible promulgation of a federal acquisition regulation rule that would serve as a governmentwide template in solicitations or contracts for ensuring that fdcc settings are effectively incorporated and applied .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to other interested congressional committees , secretaries of the departments of agriculture , commerce , defense , education , energy , health and human services , homeland security , housing and urban development , the interior , labor , state , transportation , the treasury , and veterans affairs ; the attorney general ; the administrators of the environmental protection agency , general services administration , national aeronautics and space administration , small business administration , and u.s. agency for international development ; the commissioner of the social security administration ; the chairman of the nuclear regulatory commission ; and the directors of the national science foundation , office of management and budget , and office of personnel management .

the report also is available at no charge on the gao web site at http: / / www.gao.gov .

if you or your staff have any questions regarding this report , please contact me at ( 202 ) 512-6244 or at wilshuseng@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix xviii .

relative to the 24 major federal agencies covered by the chief financial officers act , the objectives of our review were to ( 1 ) identify the goals , objectives , and requirements for the initiative ; ( 2 ) determine the status of actions federal agencies have taken , or plan to take , to implement the initiative ; and ( 3 ) identify the benefits , challenges , and lessons learned in implementing this initiative .

to address our first objective , we reviewed applicable policies and memorandums issued by the office of management and budget ( omb ) and plans , artifacts , and other documentation provided by the national institute of standards and technology ( nist ) .

we also reviewed guidance and federal desktop core configuration ( fdcc ) and security content automation protocol ( scap ) materials located on nist's web site .

in addition , we held discussions with omb and nist representatives to further assess the initiative's requirements and confirm that the material posted on their web sites that we considered was current and accurate .

to address our second and third objectives , we obtained and analyzed polices , plans , artifacts , status reports , and other documentation relative to the requirements of the initiative from each of the 24 federal agencies in our review .

we obtained information through interviews with officials from each of the 24 agencies , industry officials , security experts , officials from general services administration's policy utilization assessment program , and members of the chief information officers council and fdcc change control board .

we also met with staff from all 24 offices of the inspector general regarding their fdcc audit work performed as part of federal information security management act fiscal year 2008 and 2009 reporting to obtain information on their audit methodology , findings , and related documentation .

based on our review of the adequacy of work performed , we have sufficient assurance to rely on work completed by the inspectors general in the context of our audit objective related to whether the agency had documented deviations and had incorporated language related to the use of fdcc settings into its contracts .

we also analyzed the information we obtained from all sources to determine the benefits , challenges , and lessons learned from implementation of fdcc .

for our second objective , in order to determine the status of fdcc implementation at federal agencies , we developed a data collection instrument to obtain information on the number of workstations that had fdcc settings applied , either with no deviations or with deviations established at these agencies .

to develop our data collection instrument , we reviewed the requirements of the initiative as well as the results from a previous data collection instrument used by nist to collect status information on fdcc as of march 2008 .

we designed the draft collection instrument in close collaboration with subject matter experts and participated in refining subsequent drafts of the instrument .

we sent the data collection instrument to the officials at the office of chief information officer at the 24 federal agencies and asked the agencies to provide status information as of june 30 , 2009 , and as of september 30 , 2009 .

we e - mailed our first data collection instrument , to collect fdcc status data as of june 30 , 2009 , to all 24 agencies in early june 2009 .

when our collection ended in july 2009 , we had received 19 usable responses .

after examining the results from this data collection to identify inconsistencies and other indications of error , we concluded that the extent of response error and the overall low level of participation precluded the use of these data in our report .

to refine the data collection instrument to collect september 2009 data , we conducted pretests with officials from 3 agencies to clarify any ambiguous or potentially biased questions .

these pretests were conducted by telephone with the 3 agencies , which were chosen to represent the variety of characteristics across the 24 agencies we would survey .

these characteristics included the operating system used , type of workstation , composition and size of the agency , and method used to collect status information .

we sent this instrument to agency officials in mid - september 2009 .

we conducted follow - up contacts by e - mail and phone to encourage response and clarify individual answers .

we received usable responses from 22 agencies , and ended the data collection period in november 2009 .

while our evaluation of the instrument data indicates that it is usable for the purposes of this report , the information may not be complete due to the inability of some agencies to provide information in the categories we requested , including some of the data supporting our estimates of contractor - owned workstations with fdcc compliance , and possibly some other estimates .

we conducted this performance audit from december 2008 to march 2010 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the table below shows , for the 24 agencies from which we collected data using our data collection instrument , the percentage of applicable windows xp and vista workstations that have all fdcc settings implemented with no deviations , workstations with an agency baseline implemented and deviations documented , and workstations that do not have the settings implemented .

to improve the department's implementation of fdcc , we recommend that the secretary of agriculture take the following three actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion ; document deviations to fdcc and have them approved by a designated develop , document , and implement a policy to approve deviations by a designated accrediting authority .

to improve the department's implementation of fdcc , we recommend that the secretary of commerce take the following three actions: ensure all components have acquired and deployed a nist - validated scap tool to monitor compliance with fdcc ; ensure all components develop , document , and implement a policy to monitor fdcc compliance using a nist - validated scap tool ; and ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the department's implementation of fdcc , we recommend that the secretary of defense take the following two actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion , and ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the department's implementation of fdcc , we recommend that the secretary of energy take the following five actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion ; document deviations to fdcc and have them approved by a designated ensure all components that are required to implement fdcc have acquired and deployed a nist - validated scap tool to monitor compliance with fdcc ; ensure all components that are required to implement fdcc develop , document , and implement a policy to monitor fdcc compliance using a nist - validated scap tool ; and ensure that language is included in contracts of those components that are required to implement fdcc to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the agency's implementation of fdcc , we recommend that the administrator of the environmental protection agency take the following two actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion , and develop , document , and implement a policy to approve deviations to fdcc by a designated accrediting authority .

to improve the agency's implementation of fdcc , we recommend that the administrator of the general services administration take the following action: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion .

to improve the department's implementation of fdcc , we recommend that the secretary of health and human services take the following three actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion ; develop , document , and implement a policy to monitor fdcc compliance using a nist - validated scap tool ; and ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the department's implementation of fdcc , we recommend that the secretary of homeland security take the following four actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion ; develop , document , and implement a policy to approve deviations to fdcc by a designated accrediting authority ; develop , document , and implement a policy to monitor fdcc compliance using a nist - validated scap tool ; and ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the department's implementation of fdcc , we recommend that the secretary of housing and urban development take the following three actions: acquire and deploy a nist - validated scap tool to monitor compliance develop , document , and implement a policy to monitor fdcc compliance using a nist - validated scap tool ; and ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the department's implementation of fdcc , we recommend that the secretary of the interior take the following three actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion ; ensure all components implement the department's existing policy to document deviations to fdcc and have those deviations approved by a designated accrediting authority ; and ensure all components implement the department's existing policy to acquire and deploy a nist - validated scap tool and monitor compliance with fdcc .

to improve the department's implementation of fdcc , we recommend that the attorney general take the following four actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion ; develop , document , and implement a policy to approve deviations to fdcc by a designated accrediting authority ; complete deployment of a nist - validated scap tool to monitor fdcc ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the department's implementation of fdcc , we recommend that the secretary of labor take the following action: complete efforts to ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the agency's implementation of fdcc , we recommend that the administrator of the national aeronautics and space administration take the following action: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion .

to improve the agency's implementation of fdcc , we recommend that the director of the national science foundation take the following action: complete deployment of a nist - validated scap tool to monitor fdcc compliance .

to improve the agency's implementation of fdcc , we recommend that the chairman of the nuclear regulatory commission take the following two actions: develop , document , and implement a policy to approve deviations to fdcc by a designated accrediting authority , and ensure that all components include language in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the agency's implementation of fdcc , we recommend that the director of the office of personnel management take the following three actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion ; document deviations to fdcc and have them approved by a designated ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the agency's implementation of fdcc , we recommend that the administrator of the small business administration take the following two actions: develop , document , and implement a policy to approve deviations to fdcc by a designated accrediting authority , and ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the agency's implementation of fdcc , we recommend that the commissioner of the social security administration take the following four actions: develop , document , and implement a policy to approve deviations to fdcc by a designated accrediting authority ; complete deployment of a nist - validated scap tool to monitor develop , document , and implement a policy to monitor fdcc compliance using a nist - validated scap tool ; and ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the department's implementation of fdcc , we recommend that the secretary of transportation take the following two actions: complete deployment of a nist - validated scap tool to monitor compliance with fdcc , and ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the department's implementation of fdcc , we recommend that the secretary of the treasury take the following two actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion , and ensure that all components include language in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the agency's implementation of fdcc , we recommend that the administrator of the u.s. agency for international development take the following action: ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

to improve the department's implementation of fdcc , we recommend that the secretary of veterans affairs take the following four actions: complete implementation of the agency's fdcc baseline , including establishing firm milestones for completion ; acquire and deploy a nist - validated scap tool to monitor compliance develop , document , and implement a policy to monitor fdcc compliance using a nist - validated scap tool ; and ensure that language is included in contracts to ensure new acquisitions include fdcc settings and products of information technology providers operate effectively using them .

the following are gao's comments on the department of commerce's letter dated february 18 , 2010 .

1 .

in its march 2007 directives , omb stated that an objective of fdcc was to provide a baseline level of security to agencies .

we used omb's characterization of fdcc for this report .

the following are gao's comments on the department of housing and urban development's letter dated february 17 , 2010 .

1 .

after reviewing additional documentation provided by department representatives , we agreed that the department had met the requirement and modified the column “have policy to approve deviations by designated authority” in table 4 from “no” to “yes.” the recommendation to this finding was removed from the report .

2 .

after subsequent discussion with department representatives , they orally concurred with our recommendation .

the following are gao's comments on the department of labor's letter dated february 12 , 2010 .

1 .

after reviewing additional documentation provided , we agreed that the department had met the requirement and modified the column “nist - validated scap tool acquired and deployed” in table 5 from “no” to “yes.” 2 .

after reviewing additional documentation provided by department representatives , we agreed that the department had partially met the requirement and modified the column “language incorporated” in table 6 from “no” to “partially.” 3 .

the recommendation to this finding was removed ( see comment 1 ) .

4 .

the recommendation to this finding was modified as appropriate ( see comment 2 ) .

the following are gao's comments on the office of personnel management's letter dated march 2 , 2010 .

1 .

after subsequent discussion with agency representatives , they orally concurred with our recommendation .

2 .

after reviewing additional documentation provided by agency representatives , we agreed that the agency had met the requirement and modified the column “have policy to approve deviations by designated authority” in table 4 from “no” to “yes.” the recommendation to this finding was removed from the report .

in addition to the individual named above , jeffrey knott ( assistant director ) , john bainbridge , william cook , kami corbett , neil doherty , michele fejfar , nancy glover , valerie hopkins , lee mccracken , zsaroq powe , carl ramirez , and shawn ward made key contributions to this report .

