the department of homeland security's ( dhs ) transportation security administration ( tsa ) fiscal year 2014 budget request amounts to approximately $7.4 billion for programs and activities to secure the nation's transportation systems .

this amount includes nearly $5 billion for tsa's aviation security account , a portion of which is requested to support screening of passengers by observation techniques ( spot ) within the behavior detection and analysis ( bda ) program , which seeks to identify persons who may pose a risk to aviation security .

through the spot program , tsa's behavior detection officers ( bdo ) are to identify passenger behaviors indicative of stress , fear , or deception and refer passengers meeting certain criteria for additional screening of their persons and carry - on baggage .

during this spot referral screening , if passengers exhibit additional behaviors , or if other events occur , such as the discovery of a suspected fraudulent document , bdos are to refer these passengers to a law enforcement officer ( leo ) for further investigation , which could result in an arrest , among other outcomes .

in october 2003 , tsa began testing its primary behavior detection activity , the spot program , and during fiscal year 2007 , tsa deployed the program to 42 tsa - regulated airports .

by fiscal year 2012 , about 3,000 bdos were deployed to 176 of the more than 450 tsa - regulated airports in the united states .

from fiscal years 2011 through 2012 , an estimated 1.3 billion people passed through checkpoints at the 176 spot airports .

tsa has expended approximately $200 million annually for the spot program since fiscal year 2010 , and a total of approximately $900 million since 2007 .

bdos represent one of tsa's layers of security .

in addition to bdos , other layers of security include travel document checkers , who examine tickets , passports , and other forms of identification ; transportation security officers ( tso ) , who are responsible for screening passengers and their carry - on baggage at passenger checkpoints using x - ray equipment , magnetometers , advanced imaging technology , and other devices ; as well as for screening checked baggage ; and random employee screening , among others .

in may 2010 , we concluded on the basis of our work , among other things , that tsa deployed spot nationwide without first validating the scientific basis for identifying passengers who may pose a threat in an airport environment .

tsa piloted the spot program in 2003 and 2004 at several new england airports .

however , the pilot was not designed to determine the effectiveness of using behavior detection techniques to enhance aviation security ; rather , the pilot was focused on the operational feasibility of implementing the spot program at airports .

in recognition of the need to conduct additional research , dhs's science and technology directorate ( s&t ) hired a contractor in 2007 to design and execute a validation study to determine whether the primary screening instrument used in the program — the spot referral report and its associated indicators based on behavior or appearance factors — could be used to correctly identify high - risk passengers .

the validation study , published in april 2011 , found that the spot program identified substantially more “high - risk” passengers — defined by the study as those passengers who , for example , possessed fraudulent documents — as compared with passengers who had been selected by bdos according to a random selection protocol .

however , the validation study cited certain methodological limitations , such as the potential for selection bias as a result of bdos participating in the study not following the random selection protocols , among others .

s&t concluded that the limitations were minimal and that the results were reasonable and reliable .

in may 2010 , we recommended that s&t convene an independent panel of experts to comment on and evaluate the methodology of the ongoing validation study .

in response , s&t established a technical advisory committee ( tac ) of 12 researchers and issued a separate report in june 2011 summarizing tac members' recommendations and opinions on the study results .

the results of the validation study and tac's comments and concerns are discussed later in this report .

we also concluded in may 2010 that tsa was experiencing challenges in implementing the spot program at airports , such as not systematically collecting and analyzing potentially useful passenger information obtained by bdos , and that the program lacked outcome - based performance measures useful for assessing the program's effectiveness .

as a result , we recommended that tsa take several actions to help assess spot's contribution to improving aviation security .

overall , tsa has taken action on all of the 11 recommendations we made , and , as of october 2013 , has implemented 10 of the recommendations .

for example , among other things , tsa revised spot standard operating procedures to more clearly instruct bdos and other tsa personnel regarding how and when to enter spot referral data into the transportation information sharing system ( tiss ) .

this would help enable the referral data to be shared with federal , state , or local law enforcement entities .

further , in november 2012 , tsa issued a plan to develop outcome - based performance measures , such as the ability of bdos to consistently identify spot behavioral indicators , within 3 years to assess the effectiveness of the spot program .

this plan is discussed in more detail later in this report .

you requested an updated assessment of the spot program's effectiveness .

specifically , this report addresses the following questions: 1 .

to what extent does available evidence support the use of behavioral indicators to identify aviation security threats ? .

2 .

to what extent does tsa have data necessary to assess the effectiveness of the spot program in identifying threats to aviation security ? .

in addition , we also reviewed information related to recent allegations of profiling in the spot program .

this information can be found in appendix i .

to address the first question , we reviewed academic and government research on behavior - based deception detection , which we identified through a structured literature search and recommendations from experts in the field .

we assessed the reliability of this research against established practices for study design , and through interviews with nine experts we selected based on their published peer - reviewed research in this area .

while the results of these interviews cannot be used to generalize about all research on behavior detection , they represent a mix of views and subject matter expertise .

we determined that the research was sufficiently reliable for describing the evidence that existed regarding the use of behavioral indicators to identify security threats .

we also analyzed documentation related to the april 2011 spot validation study , including study protocols and the final reports , and assessed the study against established practices for evaluation design and generally accepted statistical principles .

we interviewed headquarters tsa and s&t officials responsible for the validation study and contractor officials .

we obtained the data that were used by these officials to reach the conclusions in the validation study .

to assess the soundness of the methodology and conclusions in the validation study , we replicated some of the analyses that were conducted by the contractor , based on the methodology described in the final report .

generally , we replicated the study's results , and as an extra step , we extended the analyses using the full sample of spot referrals to increase the power to detect significant associations , as described in appendix ii .

we also analyzed data on bdos' spot referrals , hours worked , and characteristics , such as race and gender , from the spot program database , tiss , tsa's office of human capital , and the national finance center for fiscal years 2011 and 2012 to determine the extent to which spot referrals varied across airports and across bdos with different characteristics .

to assess the reliability of these data , we reviewed relevant documentation , including dhs privacy impact assessments and a 2012 data audit of the spot database , and interviewed tsa officials about the controls in place to maintain the integrity of the data .

we determined that the data were sufficiently reliable for us to use to standardize the referral data across airports based on the number of hours each bdo spent performing operational spot activities .

in addition , we interviewed bda program managers at headquarters , and visited four airports where the spot program was implemented in fiscal years 2011 and 2012 , and where the validation study was carried out .

we selected the airports based on their size , risk ranking , and participation in behavior detection programs .

as part of our visits , we interviewed 25 randomly selected bdos , as well as bdo managers and officials from the responsible local law enforcement agency for each airport .

while the results of these visits and interviews are not generalizable to all spot airports or bdos , they provided additional bdo perspectives and helped corroborate the research and statistical information we gathered through other means .

to address the second question , we analyzed documentation related to the april 2011 validation study , including study protocols and the final reports , and evaluated these efforts against established practices for designing evaluations and generally accepted statistical principles .

we also reviewed financial data from fiscal years 2007 through 2012 to determine the expenditures associated with the spot program , and interviewed officials in dhs's office of the inspector general ( oig ) who were working on a related audit of the spot program .

we also reviewed documentation associated with program oversight , including a november 2012 performance metrics plan and evaluated tsa's efforts to collect and analyze data to provide oversight of bda activities against criteria outlined in office of management and budget guidance , federal government efficiency initiatives , and standards for internal control in the federal government .

finally , to demonstrate effectiveness of the bda program , including spot , we analyzed documentation such as a return - on - investment analysis and a risk - based allocation analysis , both from december 2012 .

we interviewed headquarters tsa and s&t officials responsible for the validation study and tsa field officials responsible for collecting study data at the four airports we visited , as well as contractor officials , and 8 of the 12 tac members .

we interviewed bda officials in the offices of security capabilities and security operations , and tsa officials in the office of human capital on the extent to which they collect and analyze data .

in addition , to identify additional information about recent allegations of passenger profiling in the spot program , we reviewed documentation and data , and interviewed a nongeneralizable sample of 25 randomly selected bdos and an additional 7 bdos who contacted us directly .

we also interviewed tsa headquarters and field officials , such as federal security directors and bdo managers .

appendix iii provides additional details on our objectives , scope , and methodology .

this report is a public version of the prior sensitive report that we provided to you .

dhs and tsa deemed some of the information in the report as sensitive security information , which must be protected from public disclosure .

therefore , this report omits sensitive information about specific spot behavioral indicators , the validation study findings , and the results of our analysis on the extent to which spot referrals varied across airports and across bdos with different characteristics .

although the information provided in this report is more limited in scope , it addresses the same questions as the sensitive report .

also , the overall methodology used for both reports is the same .

we conducted this performance audit from april 2012 to november 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the aviation and transportation security act established tsa as the federal agency with primary responsibility for securing the nation's civil aviation system , which includes the screening of all passengers and property transported by commercial passenger aircraft .

at the more than 450 tsa - regulated airports in the united states , all passengers , their accessible property , and their checked baggage are screened prior to boarding an aircraft or entering the sterile area of an airport pursuant to statutory and regulatory requirements and tsa - established standard operating procedures .

bda , and more specifically , the spot program , constitutes one of multiple layers of security implemented within tsa - regulated airports .

according to tsa's strategic plan and other program guidance for the bda program released in december 2012 , the goal of the agency's behavior detection activities , including the spot program , is to identify high - risk passengers based on behavioral indicators that indicate “mal - intent.” for example , the strategic plan notes that in concert with other security measures , behavior detection activities “must be dedicated to finding individuals with the intent to do harm , as well as individuals with connections to terrorist networks that may be involved in criminal activity supporting terrorism.” tsa developed its primary behavior detection activity , the spot program , in 2003 as an added layer of security to identify potentially high - risk passengers through behavior observation and analysis techniques .

the spot program's standard operating procedures state that bdos are to observe and visually assess passengers , primarily at passenger screening checkpoints , and identify those who display clusters of behaviors indicative of stress , fear , or deception .

the spot procedures list a point system bdos are to use to identify potentially high - risk passengers on the basis of behavioral and appearance indicators , as compared with baseline conditions where spot is being conducted .

a team of two bdos is to observe passengers as they proceed through the screening process .

this process is depicted in figure 1 .

according to tsa , it takes a bdo less than 30 seconds to meaningfully observe an average passenger .

if one or both bdos observe that a passenger reaches a predetermined point threshold , the bdos are to direct the passenger and any traveling companions to the second step of the spot process — spot referral screening .

during spot referral screening , bdos are to engage the passenger in casual conversation — a voluntary informal interview — in the checkpoint area or a predetermined operational area in an attempt to determine the reason for the passenger's behaviors and either confirm or dispel the observed behaviors .

spot referral screening also involves a physical search of the passenger and his or her belongings .

according to tsa , an average spot referral takes 13 minutes to complete .

if the bdos concur that a passenger's behavior escalates further during the referral screening or if other events occur , such as the discovery of fraudulent identification documents or suspected serious prohibited or illegal items , they are to call a leo to conduct additional screening — known as a leo referral — who then may allow the passenger to proceed on the flight , or may question , detain , or arrest the passenger .

the federal security director or designee , regardless of whether a leo responds , is responsible for reviewing the circumstances surrounding a leo referral and making the determination about whether the passenger can proceed into the sterile area of the airport .

the costs of the spot program are not broken out as a single line item in the budget .

rather , spot program costs are funded through three separate program , project , activity ( ppa ) - level accounts: ( 1 ) bdo payroll costs are funded through the screener personnel compensation and benefits ( pc&b ) ppa , ( 2 ) the operating expenses of the bdos and the program are funded through the screener training and other ppa , and ( 3 ) the program management payroll costs are funded through the airport management and support ppa .

from fiscal year 2007 — when the spot program began deployment nationwide — through fiscal year 2012 , about $900 million has been expended on the program , as shown in figure 2 .

the majority of the funding ( approximately 79 percent ) for the spot program covers workforce costs and is provided under the screener personnel compensation and benefits ppa .

this ppa — for which tsa requested about $3 billion for fiscal year 2014 — funds , among other tsa screening activities , bdos and tso screening of passengers and their property .

the workforce of about 3,000 bdos is broken into four separate pay bands .

the f band , or master bdo , and the g band , or expert bdo , constitute the primary bdo workforce that screens passengers using behavior detection .

the h and i bands are supervisory - level bdos , responsible for overseeing spot operations at the airport level .

according to tsa figures , in fiscal year 2012 , the average salaries and benefits of an f band bdo full - time equivalent ( fte ) was $66,310 ; a g band bdo was $78,162 , and the average fte cost of h and i band bdo supervisors was $97,392 .

in 2007 , s&t began research to assess the validity of the spot program .

the contracted study , issued in april 2011 , was to examine the extent to which using the spot referral report and its indicators , as established in spot procedures , led to correct screening decisions at security checkpoints .

two primary studies were designed within the broader validation study: 1. an indicator study: an analysis of the behavioral and appearance indicators recorded in spot referral reports over an approximate 5- year period and their relationships to outcomes indicating a possible threat or high - risk passenger , and 2. a comparison study: an analysis over an 11-month period at 43 airports that compared arrests and other outcomes for passengers selected using the spot referral report with passengers selected and screened at random , as shown in table 1 .

the validation study found , among other things , that some spot indicators appeared to be predictors of outcomes indicating a possible threat or high - risk passenger , and that spot procedures were more effective than a selection of passengers through a random protocol in identifying outcomes that represent high - risk passengers .

while the validation study was being finalized , dhs convened a tac composed of 12 researchers and law enforcement professionals who met for 1 day in february 2011 to evaluate the methodology of the spot validation study .

according to the tac report , tac members received briefings from the contractor that described the study plans and results , but because of tsa's security concerns , tac members did not receive detailed information about the contents of the spot referral report , the individual indicators used in the spot program , the validation study data , or the final report containing complete details of the spot validation study results .

the tac report noted that several tac members felt that these restrictions hampered their ability to perform their assigned tasks .

according to tsa , tac members were charged with evaluating the methodology of the study , not the contents of the spot referral report .

consequently , tsa officials determined that access to this information was not necessary for the tac to fulfill its responsibilities .

s&t also contracted with another contractor , a human resources research organization , to both participate as tac members and write a report summarizing the tac meeting and subsequent discussions among the tac members .

in june 2011 , s&t issued the tac report , which contained tac recommendations on future work as well as an appendix on tac dissenting opinions .

the findings of the tac report are discussed later in this report .

meta - analyses and other published research studies we reviewed do not support whether nonverbal behavioral indicators can be used to reliably identify deception .

while the april 2011 spot validation study was a useful initial step and , in part , addressed issues raised in our may 2010 report , it does not demonstrate the effectiveness of the spot indicators because of methodological weaknesses in the study .

further , tsa program officials and bdos we interviewed agree that some of the behavioral indicators used to identify passengers for additional screening are subjective .

tsa has plans to study whether behavioral indicators can be reliably interpreted , and variation in referral rates raises questions about the use of the indicators by bdos .

peer - reviewed , published research does not support whether the use of nonverbal behavioral indicators by human observers can accurately identify deception .

our review of meta - analyses and other studies related to detecting deception conducted over the past 60 years , and interviews with experts in the field , question the use of behavior observation techniques , that is , human observation unaided by technology , as a means for reliably detecting deception .

the meta - analyses , or reviews that synthesize the findings of other studies , we reviewed collectively included research from more than 400 separate studies on detecting deception , and found that the ability of human observers to accurately identify deceptive behavior based on behavioral cues or indicators is the same as or slightly better than chance ( 54 percent ) .

a 2011 meta - analysis showed weak correlations between most behavioral cues studied and deception .

for example , the meta - analysis showed weak correlations for behavioral cues that have been studied the most , such as fidgeting , postural shifts , and lack of eye contact .

a 2006 meta - analysis reviewed , in part , the ability of both individuals trained in fields such as law enforcement , as well as those untrained , and found no difference in their ability to detect deception .

additionally , a 2007 meta - analysis on nonverbal indicators of deception states that while there is a general belief that certain nonverbal behaviors are strongly associated with deception — such as an increase in hand , foot , and leg movements — these behaviors are diametrically opposed to observed indicators of deception in experimental studies , which indicate that movements actually decrease when people are lying .

as part of our analysis , we also reviewed scientific research focused on detecting passenger deception in an airport environment .

we identified a 2010 study – based on a small sample size of passengers – that reviewed a similar behavior observation program in another country .

the first phase of the study found that passengers who were selected based on behaviors were more likely to be referred to airport security officials for further questioning as compared to passengers who had been selected according to a random selection protocol .

however , because the physical attributes of the passengers were found to be significantly different between those passengers selected based on behaviors versus those randomly selected , the researchers undertook a second phase of the study to control for those differences .

the second phase revealed no differences in initial follow up rate between passengers selected based on behaviors and those matched for physical attributes .

that is , when the control group was matched by physical attribute to passengers selected on the basis of behaviors , the follow up rate was the same .

the researchers concluded that the higher number of passengers selected based on behaviors and referred for further questioning during the first phase of the study “was more the result of profiling” than the use of behavior observation techniques .

as mentioned earlier in this report , the goal of the bda program is to identify high - risk passengers based on behavioral indicators that may indicate mal - intent .

however , other studies we reviewed found that there is little available research regarding the use of behavioral indicators to determine mal - intent , or deception related to an individual's intentions .

for example , a 2013 rand report noted that controversy exists regarding the use of human observation techniques that use behavioral indicators to identify individuals with intent to deceive security officials .

in particular , the study noted that while behavioral science has identified nonverbal behaviors associated with emotional and psychological states , these indicators are subject to certain factors , such as individual variability , that limit their potential utility in detecting pre - incident indicators of attack .

the rand report also found that the techniques for measuring the potential of using behavioral indicators to detect attacks are poorly developed and worthy of further study .

moreover , a 2008 study performed for the department of defense by the jason program office reviewed behavior detection programs , including the methods used by the spot program , and found that no compelling evidence exists to support remote observation of physiological signals that may indicate fear or nervousness in an operational scenario by human observers , and no scientific evidence exists to support the use of these signals in detecting or inferring future behavior or intent .

in particular , the report stated that success in identifying deception and intent in other studies is post hoc and such studies incorrectly equate success in identifying terrorists with the identification of drug smugglers , warrant violators , or others .

for example , when describing the techniques used by bdos in the spot program , the report concluded that even if a correlation were found between abnormal behaviors and guilt as a result of some transgression , there is no clear indication that the guilt caused the abnormal behavior .

the report also noted that the determination that the abnormal behavior was caused by guilt was made after the fact , rather than being based on established criteria beforehand .

recent research on behavior detection has identified more promising results when behavioral indicators are used in combination with certain interview techniques and automated technologies , which are not used as part of the spot program .

for example , several studies we reviewed that were published in 2012 and 2013 note that specific interviewing techniques , such as asking unanticipated questions , may assist in identifying deceptive individuals .

researchers began to develop automated technologies to detect deception , in part , because humans are limited in their ability to perceive , detect , and analyze all of the potentially useful information about an individual , some of which otherwise would not be noticed by the naked eye .

for example , the 2013 rand report noted that the link between facial microexpressions — involuntary expressions of emotion appearing for milliseconds despite best efforts to dampen or hide them — and deception can be evidenced by coding emotional expressions from a frame - by - frame analysis of video .

however , the study concludes that the technique is not suitable for use by humans in real time at checkpoints or other screening areas because of the time lag and hours of labor required for such analysis .

automated technologies are being explored by federal agencies in conjunction with academic researchers to overcome these limitations , as well as human fatigue factors and potential bias in trying to detect deception .

although in the early stages of development , the study stated that automated technologies might be effective at fusing multiple indicators , such as body movement , vocal stress , and facial microexpression analysis .

the usefulness of dhs's april 2011 validation study is limited , in part because the data the study used to examine the extent to which the spot behavioral indicators led to correct screening decisions at security checkpoints were from the spot database that we had previously found in may 2010 to have several weaknesses , and thus were potentially unreliable .

the spot indicator study analyzed data collected from 2006 to 2010 to determine the extent to which the indicators could identify high - risk passengers defined as passengers who ( 1 ) possessed fraudulent documents , ( 2 ) possessed serious prohibited or illegal items , ( 3 ) were arrested by a leo , or ( 4 ) any combination of the first three measures .

the validation study reported that 14 of the 41 spot behavioral indicators were positively and significantly related to one or more of the study outcomes .

however , in may 2010 , we assessed the reliability of the spot database against standards for internal control in the federal government and concluded that the spot database lacked controls to help ensure the completeness and accuracy of the data , such as computerized edit checks to review the format , existence , and reasonableness of data .

we found , among other things , that bdos could not record all behaviors observed in the spot database because the database limited entry to eight behaviors , six signs of deception , and four types of serious prohibited items per passenger referred for additional screening .

bdos are trained to identify 94 signs of stress , fear , and deception , or other related indicators .

as a result , we determined that , as of may 2010 , the data were not reliable enough to conduct a statistical analysis of the association between the indicators and high - risk passenger outcomes .

in may 2010 , we recommended that tsa make changes to ensure the quality of spot referral data , and tsa subsequently made changes to the spot database .

however , the validation study used data that were collected from 2006 through 2010 , prior to tsa's improvements to the spot database .

consequently , the data were not sufficiently reliable for use in conducting a statistical analysis of the association between the indicators and high - risk passenger outcomes .

in their report that reviewed the validation study , tac members expressed some reservations about the methodology used in analyzing the spot indicators and suggested that the contractor responsible for completing the study consider not reporting on some of its results and moving the results to an appendix , rather than including them as a featured portion of the report .

further , the final validation study report findings were mixed , that is , they both supported and questioned the use of these indicators in the airport environment , and the report noted that the study was an “initial step” toward validating the program .

however , because the study used unreliable data , its conclusions regarding the use of the spot behavioral indicators for passenger screening are questionable and do not support the conclusion that they can or cannot be used to identify threats to aviation security .

other aspects of the validation study are discussed later in this report .

bda officials at headquarters and bdos we interviewed in four airports said that some of the behavioral indicators are subjective , and tsa has not demonstrated that bdos can consistently interpret behavioral indicators , though the agency has efforts under way to reduce subjectivity in the interpretation by bdos .

for example , bda officials at headquarters stated that the definition of some behaviors in spot standard operating procedures is subjective .

further , 21 of 25 bdos we interviewed said that certain behaviors can be interpreted differently by different bdos .

spot procedures state that the behaviors should deviate from the environmental baseline .

as a result , bdos' application of the definition of the behavioral indicators may change over time , or in response to external factors .

four of the 25 bdos we spoke with said that newer bdos might be more sensitive in applying the definition of certain behaviors .

our analysis of tsa's spot referral data , discussed further below , shows that there is a statistically significant correlation between the length of time that an individual has been a bdo , and the number of spot referrals the individual makes per 160 hours worked , or about four 40-hour work weeks .

this suggests that different levels of experience may be one reason why bdos apply the behavioral indicators differently .

bda officials agree that some of the spot indicators are subjective , and the agency is working to better define the behavioral indicators currently used by bdos .

in december 2012 , tsa initiated a new contract to review the indicators in an effort to reduce the number of behavioral and appearance indicators used and to reduce subjectivity in the interpretation by bdos .

in june 2013 , the contractor produced a document that summarizes information on the spot behavioral indicators from the validation study analysis , such as how frequently the indicator was observed , that it says will be used in the indicator review process .

according to tsa's november 2012 performance metrics plan , in 2014 , the agency also intends to complete an inter - rater reliability study .

this study could help tsa determine whether bdos can reliably interpret the behavioral indicators , which is a critical component of validating the spot program's results and ensuring that the program is implemented consistently .

our analysis of spot referral data from fiscal years 2011 and 2012 indicates that spot and leo referral rates vary significantly across bdos at some airports , which raises questions about the use of behavioral indicators by bdos .

specifically , we found that variation exists in the spot referral rates among 2,199 nonmanager bdos and across the 49 airports in our review , after standardizing the referral data to take account of the differences in the amount of time each bdo spent observing passengers , as shown in figure 3 .

the spot referral rates of bdos ranged from 0 to 26 referrals per 160 hours worked during the 2-year period we reviewed .

similarly , leo referral rates of bdos ranged from 0 to 8 per 160 hours worked .

further , at least 153 of the 2,199 nonmanager bdos were never identified as the primary bdo responsible for a referral .

of these , at least 76 were not associated with a referral during the 2-year period we reviewed .

to better understand the variation in referral rates , we analyzed whether certain variables affected spot referral rates and leo referral rates , including the airport at which the referral occurred , and bdo characteristics , such as their annual performance scores , years of experience , as well as demographic information , including age and gender .

the variables we identified as having a statistically significant relationship to the referral rates are shown in table 2 .

we found that overall , the greatest amount of the variation in spot referral rates by bdos was explained by the airport in which the referral occurred .

that is , a bdo's spot referral rate was associated with the airport at which he or she was conducting spot activities .

however , separate analyses we conducted indicate that these differences across airports were not fully accounted for by another variable that is directly related to individual airports .

that variable accounted for less than half of the variation in spot referral rates accounted for by airports .

combined , the remaining variables – including bdo performance score , age , years of bdo experience , years of tsa experience , race , and educational level – accounted for little of the variation in spot referral rates .

in commenting on this issue , tsa officials noted that variation in referral rates across airports could be the result of differences in passenger composition , the airport's market type , the responsiveness of leos to bdo referrals , and the number and type of airlines at the airports , among other things .

however , because tsa could not provide additional supporting data on these variables with comparable time frames , we were not able to include these variables in our analysis .

see appendix iv for a more detailed discussion of the findings from our multivariate analysis of referral rates .

according to tsa , having clearly defined and consistently implemented standard operating procedures for bdos in the field at the 176 spot airports is key to the success of the program .

in may 2010 , we found that tsa established standardization teams designed to help ensure consistent implementation of the spot standard operating procedures .

we followed up on tsa's use of standardization teams and found that from 2012 to 2013 , tsa made standardization team visits to 9 airports .

in may 2012 , officials changed their approach and data collection requirements and changed the name of the teams to program compliance assessment teams .

from december 2012 through march 2013 , tsa conducted pilot site visits to 3 airports to test and refine new compliance team protocols for data collection , which , among other things , involve more quantitative analysis of bdo performance .

the pilot process was designed to help ensure that the program compliance assessment teams conduct standardized , on - site evaluations of bdos' compliance with the spot standard operating procedures in a way that is based on current policy and procedures .

as of june 2013 , tsa had visited and collected data at 6 additional airports and was refining data input and reporting processes .

according to bda officials , tsa deployed the new compliance teams nationally in august 2013 and anticipates visiting an additional 13 airports by the end of fiscal year 2013 .

however , the compliance teams are not generally designed to help ensure bdos' ability to consistently interpret the spot indicators , and the agency has not developed other mechanisms to measure inter - rater reliability .

tsa does not have reasonable assurance that bdos are reliably interpreting passengers' behaviors within or among airports , in part because of the subjective interpretation of some spot behavioral indicators by bdos and the limited scope of the compliance teams .

this , coupled with the inconsistency in referral rates across different airports , raises questions about the use of behavioral indicators to identify potential threats to aviation .

tsa has limited information to evaluate spot program effectiveness because the findings from the april 2011 validation comparison study are inconclusive because of methodological weaknesses in the study's overall design and data collection .

however , tsa plans to collect additional performance data to help it evaluate the effectiveness of its behavior detection activities .

dhs's 2011 validation study compared the effectiveness of spot with a random selection of passengers and found that spot was between 4 and 52 times more likely to correctly identify a high - risk passenger than random selection , depending on which of the study's outcome measures was used to define persons knowingly and intentionally trying to defeat the security process .

however , bdos used various methods to randomly select passengers during data collection periods of differing length at the study airports .

initially , the contractor proposed that tsa use random selection methods at a sample of 143 spot airports , based on factors such as the number of airport passengers .

if properly implemented , the proposed sample would have helped ensure that the validation study findings could be generalized to all spot airports .

however , according to the study and interviews with the contractor , tsa selected a nonprobability sample of 43 airports based on input from local tsa airport officials who decided to participate in the study .

tsa allowed the managers of these airports to decide which checkpoints would use random procedures and when they would do so during airport operating hours .

according to the validation study and a contractor official , the airports included in the study were not randomly selected because of the increased time and effort it would take to collect study data at the 143 airports proposed by the contractor .

therefore , the study's results may provide insights about the implementation of the spot program at the 43 airports where the study was carried out , but they are not generalizable to all 176 spot airports .

additionally , tsa collected the validation study data unevenly and experienced challenges in collecting an adequate sample size for the randomly selected passengers , facts that might have further affected the representativeness of the findings .

according to established evaluation design practices , data collection should be sufficiently free of bias or other significant errors that could lead to inaccurate conclusions .

specifically , in december 2009 , tsa initially began collecting data from 24 airports whose participation in the study was determined by the local tsa officials .

more than 7 months later , tsa added another 18 airports to the study when it determined that enough data were not being collected on the randomly selected passengers at participating airports to reach the study's required sample size .

the addition of the airports coincided with a substantial increase in referrals for additional screening and an uneven collection of data , as shown in figure 4 .

as a result of this uneven data collection , study data on 61 percent of randomly selected passengers were collected during the 3-month period from july through september 2010 .

by comparison , 33 percent of the data on passengers selected by the spot program were collected during the same time .

because commercial aviation activity and the demographics of the traveling public are not constant throughout the year , this uneven data collection may have conflated the effect of random versus spot selection methods with differences in the rates of high - risk passengers when tsa used either method .

in addition , the april 2011 validation study noted that bdos were aware of whether the passengers they were screening were selected as a result of the random selection protocol or spot procedures , which had the potential to introduce bias in the assessment .

according to established practices for evaluation design , when feasible , many scientific studies use “blind” designs , in which study participants do not know which procedures are being evaluated .

this helps avoid potential bias due to the tendency of participants to behave or search for evidence in a manner that supports the effects they expect each procedure to have .

in contrast , in the spot comparison study , bdos knew whether each passenger they screened was selected through spot or random methods .

this may have biased bdos' screening for high - risk passengers , because bdos could have expected randomly selected passengers to be lower risk and thus made less effort to screen passengers .

in interviews , the contractor and four of the eight members of the tac we interviewed agreed that this may be a design weakness .

one tac member told us that the comparison study would have been more robust if the passengers had been randomly selected by people without any prior knowledge of spot indicators to decrease the possibility of bias .

to reduce the possibility of bias in the study , another tac member suggested that instead of using the same bdos to select and screen passengers , some bdos could have been responsible for selecting passengers and other bdos for screening the passengers , regardless of whether they were selected randomly or by spot procedures .

according to validation study training materials , bdos were used to select both groups of passengers in an effort to maintain normal security coverage during the study .

another tac member stated that controls were needed to ensure that bdos gave the same level of scrutiny to randomly selected passengers as those referred because of their behaviors .

the contractor officials reported that they were aware of the potential bias , and tried to mitigate its potential effects by training bdos who participated in the validation study to screen passengers identically , regardless of how they were selected .

however , the contractor stated that they could not fully control these selections because bdos were expected to conduct their regular spot duties concurrently during the study's data collection on random passenger screening .

the validation study discussed several limitations that had the potential to introduce bias , but concluded that they did not affect the results of the study .

our analysis of the validation study data regarding one of the primary high - risk outcome measures — leo arrests — suggests that the screening process was different for passengers depending on whether they were selected using spot procedures or the random selection protocol .

therefore , the study's finding that spot was much more likely to identify high - risk passengers who were ultimately arrested by a leo may be considerably inflated .

specifically , a necessary condition influencing the rate of the arrest outcome measure — exposure to a leo through a leo referral — was not equal in the two groups .

the difference between the groups occurred because randomly selected passengers were likely to begin the spot referral process with zero points or very few points , whereas passengers selected on the basis of spot began the process at the higher , established point threshold required for bdos to make a spot referral .

however , because the point threshold for a leo referral was the same for both groups , the likelihood that passengers selected using spot would escalate to the next point threshold , resulting in a leo referral and possible leo arrest , was greater than for passengers selected randomly .

our analysis showed that because of the discrepancy in the points accrued prior to the start of the referral process , passengers who were selected on the basis of spot behavioral indicators were more likely to be referred to a leo than randomly selected passengers .

our analysis indicates that the validation study design could have been improved by treating each group similarly , regardless of the passengers' accumulated points .

for example , as a possible approach , both groups could have been referred to leos only in the cases where bdos discovered a serious prohibited or illegal item .

established study design practices state that identifying key factors known to influence desired evaluation outcomes will aid in forming treatment and comparison groups that are as similar as possible , thus strengthening the analyses' conclusions .

additionally , once referred to a leo , passengers selected at random were arrested for different reasons than those selected on the basis of spot indicators , which suggests that the two groups of passengers were subjected to different types of screening .

all randomly selected passengers who were identified as high risk , referred to a leo , and ultimately arrested possessed fraudulent documents or serious prohibited or illegal items .

in contrast , most of the passengers arrested after having been referred on the basis of spot behavior indicators were arrested for reasons other than fraudulent documents or serious prohibited or illegal items .

these reasons for arrest included outstanding warrants by law enforcement agencies , public intoxication , suspected illegal entry into the united states , and disorderly conduct .

such differences in the reasons for arrest suggest that referral screening methods may have varied according to the method of selection for screening , consistent with the concerns of the tac members and the contractor .

thus , because randomly selected passengers were assigned points differently during screening and consequently referred to leos far less than those referred by spot , and because being referred to a leo is a necessary condition for an arrest , the results related to the leo arrest metric are questionable and cannot be relied upon to demonstrate spot program effectiveness .

to help ensure that all of the bdos carried out the comparison study as intended , protocols for randomly selecting passengers were established that would help ensure that the methods would be the same across airports .

the contractor emphasized that deviating from the prescribed protocol could increase the likelihood of introducing systematic differences across airports in the methods of random screening , which could bias the results .

to ensure that airports and bdos followed the study protocols , the contractor conducted monitoring visits at 17 of the 43 , or 40 percent , of participating airports .

the first monitoring visits occurred 6 months after data collection began , and 9 of the 17 airports were not visited until the last 2 months of the study , as shown in figure 5 .

consequently , for 9 of these airports , the contractor could not have addressed the deviations from the protocols that were identified during the data - monitoring visits until the last weeks of data collection .

in the april 2011 report of all 17 monitoring visits that were conducted , the most crucial issue the contractor identified was that bdos deviated from the random selection protocol in ways that did not meet the criteria for systematic random selection .

for example , the contractor found that across airports , local tsa officials had independently decided to exclude certain types of passengers from the study because the airport officials felt it was unreasonable to subject these types of passengers to referral screening .

at 1 airport visited less than 4 weeks before data collection ended , bdos misunderstood the protocols and incorrectly excluded a certain type of passenger .

as a result , certain groups of potentially lower - risk passengers were systematically excluded from the population eligible for random selection .

in addition , the contractor found that some bdos used their own methods to select passengers , rather than the random selection protocol that was specified .

the contractor reported that if left uncorrected , this deviation from the protocols could increase the likelihood of introducing systematic bias into the study .

for example , at one airport visited less than 6 weeks before data collection ended , bdos selected passengers by attempting to generate numbers they thought were random by calling out numbers spontaneously , such as “seven,” and using the numbers to select the seventh passenger , instead of following the random selection protocol .

at another airport visited less than 6 weeks before data collection ended , contrary to random selection protocols , bdos , rather than the data collection coordinator , selected passengers to undergo referral screening .

although deviations from the protocol may not have produced a biased sample , any deviation from the selection protocol suggests that bdos' judgment may have affected the random selection and screening processes in the comparison study .

in addition to the limitations cited above , the april 2011 validation study noted other limitations such as the limited data useful for measuring high - risk passenger outcomes , the lack of information on the specific location within the airport where each spot indicator was first observed , and difficulties in differentiating whether passengers were referred because of observed behaviors related to elevated indicators of stress , fear , and deception , or for other reasons .

the validation study concluded that further research to fully validate and evaluate the spot program was warranted .

similarly , the tac report cited tac members' concerns that the validation study results “could be easily misinterpreted given the limited scope of the study and the caveats to the data,” and that the “results should be presented as a first step in a broader evaluation process.” thus , limitations in the study's design and in monitoring how it was implemented at airports could have affected the accuracy of the study's conclusions , and limited their usefulness in determining the effectiveness of the spot program .

as a result , the incidence of high - risk passengers in the normal passenger population remains unknown , and the incidence of high - risk passengers identified by random selection cannot be compared with the incidence of those identified using spot methods .

tsa plans to collect and analyze additional performance data needed to assess the effectiveness of its behavior detection activities .

in response to recommendations we made in may 2010 to conduct a cost - benefit analysis and a risk assessment , tsa completed two analyses of the bda program in december 2012 , but needs to complete additional analysis to fully address our recommendations .

specifically , tsa completed a return - on - investment analysis and a risk - based allocation analysis , both of which were designed in part to inform the future direction of the agency's behavior detection activities , including the spot program .

the return - on - investment analysis assessed the additional value that bdos add to tsa's checkpoint screening system , and concluded that bdos provide an integral value to the checkpoint screening process .

however , the report did not fully support its assumptions related to the threat frequency or the direct and indirect consequence of a successful attack , as is recommended by best practices .

for example , tsa officials told us that the threat and consequence assumptions in the analysis were designed to be consistent with the 2013 transportation security system risk assessment ( tssra ) , but the analysis did not explain why a catastrophic event was the only relevant threat scenario considered when determining consequence .

additionally , the analysis relied on assumptions regarding the effectiveness of bdos and other countermeasures that were based on questionable information .

for example , the analysis relied on results reported in the april 2011 validation study — which , as discussed earlier , had several methodological limitations — as evidence of the effectiveness of bdos .

further , a may 2013 dhs oig report found that tsa could not accurately assess the effectiveness or evaluate the progress of the spot program because it had not developed a system of performance measures at the time of the oig review .

in response , tsa provided the oig with a draft version of its performance metrics plan .

this plan has since been finalized and is discussed further below .

tsa's risk - based allocation analysis found that an additional 584 bdo ftes should be allocated to smaller airports in an effort to cover existing gaps in physical screening coverage and performance , an action that , if implemented , would result in an annual budgetary increase of approximately $42 million .

one of the primary assumptions in the risk - based allocation analysis is related to the effectiveness of bdos .

for example , this analysis suggests that bdos may be effective in identifying threats to aviation security where gaps exist in physical screening coverage and performance , including the use of walk - through metal detectors and advanced imaging technology machines .

however , tsa has not evaluated the effectiveness of bdos in comparison with these other screening methods .

in response to an additional recommendation in our may 2010 report to develop a plan for outcome - based performance measures , tsa completed a performance metrics plan in november 2012 , which details the performance measures required for tsa to determine whether the agency's behavior detection activities are effective , and identifies the gaps that exist in its current data collection efforts .

the plan defined an ideal set of 40 metrics within three major categories that bda needs to collect to be able to understand and measure the performance of its behavior detection activities .

tsa then identified the gaps in its current data collection efforts , such as , under the human factors subcategory , data on bdo fatigue levels and what staffing changes would need to be made to reduce the negative impact on bdo performance resulting from fatigue , as shown in figure 6 .

as of june 2013 , tsa had collected some information for 18 of 40 metrics the plan identified .

once collected , the data identified by the plan may help support the completion of a more substantive return - on - investment analysis and risk - based allocation analysis , but according to tsa's november 2012 plan , tsa is currently collecting little to none of the data required to assess the performance and security effectiveness of bda or the spot program .

for example , tsa does not currently collect data on the percentage of time a bdo is present at a checkpoint or other areas in the airport while it is open .

without this information , the assumptions contained in tsa's risk - based allocation analysis cannot be validated .

this analysis identified the existing bdo coverage level at the airports where spot was deployed in 2011 , and based its recommendations for an additional 584 bdos on this coverage level .

in may 2013 , tsa began to implement a new data collection system , bdo efficiency and accountability metrics ( beam ) , designed to track and analyze bdo daily operational data , including bdo locations and time spent performing different activities .

according to bda officials , this data will allow the agency to gain insight on how bdos are utilized , and improve analysis of the spot program .

the performance metrics plan may also provide other useful information in support of some of the other assumptions in tsa's risk - based allocation analysis and return - on - investment analysis .

for example , both analyses assumed that a bdo can meaningfully assess 450 passengers per hour , and that fatigue would degrade this rate over the course of a day .

however , according to the performance metrics plan , tsa does not currently collect any of the information required to assess the number of passengers meaningfully assessed by bdos , bdos' level of fatigue , or the impact that fatigue has on their performance .

to address these and other deficiencies , the performance metrics plan identifies 22 initiatives that are under way or planned as of november 2012 , including efforts discussed earlier in this report , such as the indicator study and efforts to improve the spot compliance teams , among others .

for additional information about the metrics that will result from these initiatives , see appendix v. these data could help tsa assess the performance and security effectiveness of bda and the spot program , and find ways to become more efficient with fewer resources in order to meet the federal government's long - term fiscal challenges , as recommended by federal government efficiency initiatives .

in lieu of these data , tsa uses arrest and leo referral statistics to help track the program's activities .

of the approximately 61,000 referrals made over the 2-year period at the 49 airports we analyzed , approximately 8,700 ( 14 percent ) resulted in a referral to a leo .

of these leo referrals , 365 ( 4 percent ) resulted in an arrest .

the proportion of leo referrals that resulted in an arrest ( arrest ratio ) could be an indicator of the potential relationship between the spot behavioral indicators and an arrest .

as shown in figure 7 , 99.4 percent of the passengers that were selected for referral screening — that is further questioning and inspection by a bdo — were not arrested .

the percentage of passengers referred to leos that were arrested was about 4 percent ; the other 96 percent of passengers referred to leos were not arrested .

the spot database identifies 6 reasons for arrest , including ( 1 ) fraudulent documents , ( 2 ) illegal alien , ( 3 ) other , ( 4 ) outstanding warrants , ( 5 ) suspected drugs , and ( 6 ) undeclared currency .

in february 2013 , bda officials said between 50 and 60 spot referrals were forwarded by the federal air marshal service to other law enforcement agencies for further investigation to identify potential ties to terrorism .

for example , tsa provided documentation of three suspicious incident reports from 2011 of passengers who were referred by bdos to leos based on behavioral indicators , and who were later found to be in possession of large sums of u.s. currency .

according to a fams report on these incident reports , the identification of large amounts of currency leaving the united states could be the first step in the disruption of funding for terrorist organizations or other form of criminal enterprise that may or may not be related to terrorism .

tsa officials said it is difficult to identify the terrorism - related nexus in these referrals because they are rarely , if ever , informed on the outcomes of the investigations conducted by other law enforcement agencies , and thus have no way of knowing if these spot referrals were ultimately connected to terrorism - related activities or investigations .

standards for internal control in the federal government calls for agencies to report on the performance and effectiveness of their programs .

however , according to the performance metrics plan , tsa will require at least an additional 3 years and additional resources before it can begin to report on the performance and security effectiveness of bda or the spot program .

given the scope of the proposed activities and some of the challenges that tsa has faced in its earlier efforts to assess the spot program at the national level , to complete the activities in the time frames outlined in the plan would be difficult .

in particular , the plan notes it is unrealistic that tsa will be able to evaluate the bdo security effectiveness contribution at each airport within the 3-year timeframe .

according to best practices for program management of acquisitions , technologies should be demonstrated to work reliably in their intended environment prior to program deployment .

further , according to omb guidance accompanying the fiscal year 2014 budget , it is incumbent upon agencies to use resources on programs that have been rigorously evaluated and determined to be effective , and to fix or eliminate those programs that have not demonstrated results .

tsa has taken a positive step toward determining the effectiveness of bda's behavior detection activities by developing the performance metrics plan , as we recommended in may 2010 .

however , 10 years after the development of the spot program , tsa cannot demonstrate the effectiveness of its behavior detection activities .

until tsa can provide scientifically validated evidence demonstrating that behavioral indicators can be used to identify passengers who may pose a threat to aviation security , the agency risks funding activities that have not been determined to be effective .

tsa has taken several positive steps to validate the scientific basis and strengthen program management of bda and the spot program , which has been in place for over 6 years at a total cost of approximately $900 million since 2007 .

nevertheless , tsa has not demonstrated that bdos can consistently interpret the spot behavioral indicators , a fact that may contribute to varying passenger referral rates for additional screening .

the subjectivity of the spot behavioral indicators and variation in bdo referral rates raise questions about the continued use of behavior indicators for detecting passengers who might pose a risk to aviation security .

furthermore , decades of peer - reviewed , published research on the complexities associated with detecting deception through human observation also draw into question the scientific underpinnings of tsa's behavior detection activities .

while dhs commissioned a 2011 study to help demonstrate the validity of its approach , the study's findings cannot be used to demonstrate the effectiveness of spot because of methodological limitations in the study's design and data collection .

while tsa has several efforts under way to assess the behavioral indicators and expand its collection of data to develop performance metrics for its behavioral detection activities , these efforts are not expected to be completed for several years , and tsa has indicated that additional resources are needed to complete them .

consequently , after 10 years of implementing and testing the spot program , tsa cannot demonstrate that the agency's behavior detection activities can reliably and effectively identify high - risk passengers who may pose a threat to the u.s. aviation system .

to help ensure that security - related funding is directed to programs that have demonstrated their effectiveness , congress should consider the findings in this report regarding the absence of scientifically validated evidence for using behavioral indicators to identify aviation security threats when assessing the potential benefits of behavior detection activities relative to their cost when making future funding decisions related to aviation security .

to help ensure that security - related funding is directed to programs that have demonstrated their effectiveness , we recommend that the secretary of homeland security direct the tsa administrator to limit future funding support for the agency's behavior detection activities until tsa can provide scientifically validated evidence that demonstrates that behavioral indicators can be used to identify passengers who may pose a threat to aviation security .

we provided a draft of this report to dhs and the department of justice ( doj ) for review and comment .

we also provided excerpts of this report to subject matter experts for their review to ensure that the information in the report was current , correct , and factual .

doj did not have any comments , and we incorporated technical comments from subject matter experts as appropriate .

dhs provided written comments , which are printed in full in appendix vi , and technical comments , which we incorporated as appropriate .

dhs did not concur with the recommendation to the secretary of homeland security that directed the tsa administrator to limit future funding support for the agency's behavior detection activities until tsa can provide scientifically validated evidence that demonstrates that behavioral indicators can be used to identify passengers who may pose a threat to aviation security .

citing concerns with the findings and conclusions , dhs identified two main areas where it disagreed with information presented in the report: ( 1 ) the findings related to the spot validation study and ( 2 ) the findings related to the research literature .

further , dhs provided information on its investigation of profiling allegations .

we disagree with the statements dhs made in its letter , as discussed in more detail below .

with regard to the findings related to the spot validation study , dhs stated in its letter that we used different statistical techniques when we replicated the analysis of spot indicators as presented in the dhs april 2011 validation study , a course of action that introduced error into our analysis and resulted in “misleading” conclusions .

we disagree with this statement .

as described in the report , we obtained the validation study dataset from the dhs contractor and replicated the analyses using the same techniques that the contractor used to conduct its analyses of spot indicators .

as an extra step , in addition to replicating the approach ( split - samples ) used by the contractors , as described in appendixes ii and iii of this report , we extended those analyses using the full sample of referral data to increase our ability to detect significant associations .

in both the replication of the study analyses and the extended analyses we conducted , we found essentially the same result in one aspect as the validation study — that some spot behavioral indicators were positively and significantly related to one or more of the outcome measures .

specifically , the validation study reported that 14 of the 41 spot behavioral indicators were positively and significantly related , and we found that 18 of the 41 behavioral indicators were positively and significantly related .

however , the findings regarding negatively and significantly related spot indicators were not consistent between the analyses we conducted and the validation study .

specifically , we found that 20 of the 41 behavioral indicators were negatively and significantly related to one or more of the study outcomes ( see app .

ii ) .

that is , we identified 20 spot behavioral indicators that were more commonly associated with passengers who were not identified as high - risk passengers than with passengers who were identified as high - risk passengers .

in other words , some of the spot indicators that behavior detection officers are trained to detect are associated with passengers who were defined by dhs as low risk .

our results were not consistent with the validation study , because the study did not report any indicators that were negatively and significantly correlated with one or more of the outcome measures .

further , because of limitations with the spot referral data that we reported in may 2010 and again in this report , the data the validation study used to examine behavioral indicators were not sufficiently reliable for use in conducting a statistical analysis of the association between the indicators and high - risk passenger outcomes .

we did use these data in order to replicate the validation study findings .

further , dhs stated in its letter that the tac agreed with the study's conclusion that spot was substantially better at identifying high - risk passengers than a random screening protocol .

however , we disagree with this statement .

while the tac report stated that tac members had few methodological concerns with the way the contractor carried out its research , the members did not receive detailed information on the study , including the validation study data and the final report containing the spot validation study results .

specifically , as discussed in our report and cited in the tac report , multiple tac members had concerns about some of the conclusions in the validation study and suggested that the contractor responsible for completing the study consider not reporting on some of its results and moving the results to an appendix , rather than including them as a featured portion of the report .

moreover , since the tac did not receive detailed information about the contents of the spot referral report , the individual indicators used in the spot program , the validation study data , or the final report containing complete details of the spot validation study results , the tac did not have access to all of the information that we used in our analysis .

as discussed in our report , the tac report noted that several tac members felt that this lack of information hampered their ability to perform their assigned tasks .

thus , we continue to believe that our conclusion related to the validation study results is valid , and contrary to dhs's statement , we do not believe that the study provides useful data in understanding behavior detection .

with regard to the findings related to the research literature , dhs stated in its letter that we did not consider all the research that was available and that s&t had conducted research — while not published in academic circles for peer review because of various security concerns — that supported the use of behavior detection .

dhs also stated that research cited in the report “lacked ecological and external validity,” because it did not relate to the use of behavior detection in an airport security environment .

we disagree .

specifically , as described in the report , we reviewed several documents on behavior detection research that s&t and tsa officials provided to us , including an unclassified and a classified literature review that s&t had commissioned .

further , after meetings in june and july 2013 , s&t officials provided additional studies , which we reviewed and included in the report as applicable .

we also included research in the report on the use of behavioral indicators that correspond closely to indicators identified in spot procedures as indicative of stress , fear , or deception .

these studies , many of which were included in the meta - analyses we reviewed , were conducted in a variety of settings — including high - stakes situations where the consequences are great , such as a police interview with an accused murderer — and with different types of individuals — including law enforcement personnel .

the meta - analyses we reviewed — which collectively included research from over 400 separate studies related to detecting deception conducted over the past 60 years — found that the ability of human observers to accurately identify deceptive behavior based on behavioral cues or indicators is the same as or slightly better than chance ( 54 percent ) .

further , in its letter , dhs cited a 2013 rand report , which concluded that there is current value and unrealized potential for using behavioral indicators as part of a system to detect attacks .

we acknowledge that behavior detection holds promise for use in certain circumstances and in conjunction with certain other technologies .

however , the rand report dhs cited in its letter refers to behavioral indicators that are defined and used significantly more broadly than those in the spot program .

the indicators reviewed in the rand report are neither used in the spot program , nor could be used in real time in an airport environment .

further , the rand report findings cannot be used to support tsa's use of behavior detection activities because the study stated that it could not make a determination of spot's effectiveness because information on the program was not in the public domain .

dhs also stated in its letter that it has several efforts under way to improve its behavior detection program and the methodologies used to evaluate it , including the optimization of its behavior detection procedures and plans to begin testing by the third quarter of fiscal year 2014 using robust test and evaluation methods similar to the operational testing conducted in support of technology acquisitions as part of its 3-year performance metrics plan .

we are encouraged by tsa's plans in this area .

however , tsa did not provide supporting documentation accompanying these plans describing how it will incorporate robust data collection and authentication protocols , as discussed in dhs's letter .

such documentation is to be completed prior to beginning any operational testing .

these documents might include a test and evaluation master plan that would describe , among other things , the tests that needed to be conducted to determine system technical performance , operational effectiveness or suitability , and any limitations .

additionally , in its letter , dhs stated that the omission of research related to verbal indicators of deception was misleading because a large part of bdos' work is interacting with passengers and assessing whether passengers' statements match their behaviors , or if the passengers' trip stories are in agreement with their travel documents and accessible property .

while bdos' interactions with passengers may elicit useful information , spot procedures indicate that casual conversation — voluntary informal interviews conducted by bdos with passengers referred for additional screening — is conducted after the passengers have been selected for a spot referral , not as a basis for selecting the passengers for referral .

further , since these interviews are voluntary , passengers are under no obligation to respond to the bdos questions , and thus information on passengers may not be systematically collected .

as noted in our report , promising research on behavioral indicators cited in the rand report and other literature is focused on using indicators in combination with automated technologies and certain interview techniques , such as asking unanticipated questions .

however , when interviewing referred passengers for additional screening , bdos do not currently have access to the automated technologies discussed in the rand report .

further , dhs stated that the goal of the spot program is to identify individuals exhibiting behavior indicative of simple emotions such as fear or stress and reroute them to a higher level of screening , and does not attempt to specifically identify persons engaging in lying or terrorist acts .

however , dhs also stated in its response that “spot uses a broader array of indicators , including stress and fear detection as they relate to high - stakes situations where the consequences are great , for example , suicide attack missions.” as noted in the report , tsa's program and budget documents associated with behavior detection activities identify that the purpose of these activities is to identify high - risk passengers based on behavioral indicators that indicate mal - intent .

for example , the strategic plan notes that in concert with other security measures , behavior detection activities “must be dedicated to finding individuals with the intent to do harm , as well as individuals with connections to terrorist networks that may be involved in criminal activity supporting terrorism.” the conclusions , which were confirmed in discussions with subject matter experts and an independent review of studies , indicate that scientifically validated evidence does not support whether the use of behavioral indicators by unaided human observers can be used to identify passengers who may pose a threat to aviation security .

dhs also cited the national research council's 2008 report to support its use of spot .

the national research council report , which we reviewed as part of our 2010 review of the spot program , noted that behavior and appearance monitoring might be able to play a useful role in counterterrorism efforts but also stated that a scientific consensus does not exist regarding whether any behavioral surveillance or physiological monitoring techniques are ready for use in the counterterrorist context , given the present state of the science .

according to the national research council report , an information - based program , such as a behavior detection program , should first determine if a scientific foundation exists and use scientifically valid criteria to evaluate its effectiveness before going forward .

the report also stated that programs should have a sound experimental basis , and documentation on the program's effectiveness should be reviewed by an independent entity capable of evaluating the supporting scientific evidence .

with regard to information provided related to profiling , dhs stated that dhs's oig completed an investigation at the request of tsa into allegations that surfaced at boston logan airport and concluded that these allegations could not be substantiated .

however , while the oig's july 2013 report of investigation on behavior detection officers in boston concluded that “there was no indication that bdos racially profiled passengers in order to meet production quotas,” the oig's report also stated that there was evidence of “appearance profiling.” in stating its nonconcurrence with the recommendation to limit future funding in support of its behavior detection activities , dhs stated that tsa's overall security program is composed of interrelated parts , and to disrupt one piece of the multilayered approach may have an adverse impact on other pieces .

further , dhs stated that the behavior detection program should continue to be funded at current levels to allow bdos to screen passengers while the optimization process proceeds .

we disagree .

as noted in the report , tsa has not developed the performance measures that would allow it to assess the effectiveness of its behavior detection activities compared with other screening methods , such as physical screening .

as a result , the impact of behavior detection activities on tsa's overall security program is unknown .

further , not all screening methods are present at every airport , and tsa has modified the screening procedures and equipment used at airports over time .

these modifications have included the discontinuance of screening equipment that was determined to be unneeded or ineffective .

therefore , we continue to believe that providing scientifically validated evidence that demonstrates that behavioral indicators can be used to identify passengers who may pose a threat to aviation security is critical to the implementation of tsa's behavior detection activities .

further , omb guidance highlights the importance of using resources on programs that have been rigorously evaluated and determined to be effective , and best practices for program management of acquisitions state that technologies should be demonstrated to work reliably in their intended environment prior to program deployment .

consequently , we have added a matter for congressional consideration to this report to help ensure that tsa provides information , including scientifically validated evidence , which supports the continued use of its behavior detection activities in identifying threats to aviation security .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 5 days from the report date .

we are sending copies of this report to the secretary of homeland security ; the tsa administrator ; the united states' attorney general ; and interested congressional committees as appropriate .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-4379 or lords@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are acknowledged in appendix vii .

according to the screening of passengers by observation techniques ( spot ) program's standard operating procedures , behavior detection officers ( bdo ) must apply the spot behavioral indicators to passengers without regard to race , color , religion , national origin , ethnicity , sexual orientation , or disability .

since 2010 , the transportation security administration ( tsa ) and the department of homeland security's ( dhs ) office of inspector general ( oig ) have examined allegations of the use of profiling related to the race , ethnicity , or nationality of passengers by behavior detection officers ( bdo ) at three airports — newark liberty international airport ( newark ) , honolulu international airport ( honolulu ) , and boston logan international airport ( boston ) — and tsa has taken action to address these allegations .

specifically , in january 2010 , tsa concluded an internal investigation at newark of allegations that bdos used specific criteria related to the race , ethnicity , or nationality of passengers in order to select and search those passengers more extensively than would have occurred without the use of these criteria .

the investigation was conducted by a team of two bdo managers from boston to determine whether two bdo managers at newark had established quotas for spot referrals to evaluate the performance of their subordinate bdos .

the investigation also sought to determine whether these managers at newark encouraged profiling of passengers in order to meet quotas that they had established .

the investigating team concluded that no evidence existed to support the allegation of a quota system , but noted widespread bdo perception that higher referral rates led to promotion , and that the “overwhelming majority of bdos” expressed concern that the bdo managers' “focus was solely on increasing the number of referrals and leo calls.” the investigating team said the information collected regarding the allegation of profiling resulted in a reasonable conclusion that that such activity was both directed and affected on a limited basis at newark , based on one manager's inappropriate direction to bdos regarding profiling of passengers , racial comments , and the misuse of information intended for situational awareness purposes only .

according to tsa officials , disciplinary action taken against this manager resulted in the manager's firing .

additionally , in 2011 , tsa's office of inspection ( ooi ) conducted an investigation of racial profiling allegations against bdos at honolulu .

the investigation consisted of a review of equal employment opportunity ( eeo ) complaints , and ooi did not find evidence to support the profiling allegations in the spot program .

in july 2012 , ooi conducted a compliance inspection at boston , during which allegations of profiling by bdos surfaced .

specifically , during interviews with inspectors , allegations surfaced that bdos were profiling passengers for the purpose of raising the number of law enforcement referrals .

these accusations included written complaints from bdos who claimed other bdos were selecting passengers for referral screening based on their ethnic or racial appearance , rather than on the basis of the spot behavioral indicators and were reported in a september 2012 ooi memorandum .

these allegations were referred to the oig , and in august 2012 , the oig opened an investigation into these profiling allegations in boston .

according to oig officials , its investigation was completed and its final report was provided to tsa in august 2013 .

in august 2012 , the secretary of homeland security issued a memorandum directing tsa to take a number of actions in response to allegations of racial profiling by bdos .

these actions include ( 1 ) a revision of the spot standard operating procedures to , among other things , clarify that passengers who are unwilling or uncomfortable with participating in an interactive discussion and responding to questions will not be pressured by bdos to do so ; ( 2 ) refresher training for all bdos that reinforces antidiscrimination requirements ; and ( 3 ) tsa communication with bdo supervisors that performance appraisals should not depend on achieving either a high number of referrals or on the arrest rate coming from those referrals , but rather from demonstrated vigilance and skill in applying the spot procedures .

as of june 2013 , tsa , together with the dhs acting officer for civil rights and civil liberties and counsel to the secretary of homeland security , had completed several of these action items and others were under way .

for example , the secretary of homeland security sent a memo to all dhs component heads in april 2013 stating that it is dhs's policy to prohibit the consideration of race or ethnicity in dhs's investigation , screening , and enforcement activities in all but the most exceptional instances .

during our visits to four airports , we asked a random sample of 25 bdos at the airports to what extent they had seen bdos in their airport referring passengers based on race , national origin , or appearance rather than behaviors .

these responses are not generalizable to the entire bdo population at spot airports .

of the 25 randomly selected bdos we interviewed , 20 said they had not witnessed profiling , and 5 bdos ( including at least 1 from each of the four airports we visited ) said that profiling was occurring at their airports , according to their personal observations .

also , 7 additional bdos contacted us over the course of our review to express concern about the profiling of passengers that they had witnessed .

we did not substantiate these specific claims .

in an effort to further assess the race , sex , and national origin of passengers who were referred by bdos for additional screening , we analyzed the available information in the spot referral database and the federal air marshal service's ( fams ) transportation information sharing system ( tiss ) database .

however , we found that the spot referral database does not allow for the recording of information such as race or gender .

without recording these data for every referral , it is difficult to disprove or substantiate such accusations .

since program - wide data on race were not available in the spot database , we analyzed a subset of available arrest data that were entered into the tiss database , which allows for race to be recorded .

however , because there is not a unique identifier to link referrals from the spot database to information entered into tiss , we experienced obstacles when we attempted to match the two databases .

for the spot referrals we were able to match , we found that data on race were inconsistently recorded in tiss .

the limitations associated with matching the two databases and the incompleteness of the race data in tiss made analyzing trends or anomalies in the data impractical .

in march 2013 , bda officials stated that they had initiated a feasibility study to determine the efficacy of collecting data on the race and national origin of passengers referred by bdos .

a pilot is to be conducted at approximately five airports , which have not yet been selected , to collect data and examine whether this type of data collection is feasible and if the data can be used to identify any airport - specific or system - wide trends in referrals .

according to bda officials , the purpose of this study is to examine whether disparities exist in the referral trends , and if so , whether these differences suggest discrimination or bias in the referral process .

this pilot is to also include an analysis of the broader demographics of the flying public — not just those referred by bdos for additional screening — which is information that tsa had not previously collected .

having additional information on the characteristics of the flying public that may be used to compare to the characteristics of those passengers referred by the spot program — if tsa determines these data can feasibly be collected — could help enable tsa to reach reasonable conclusions about whether allegations of passenger profiling can be substantiated .

the validation study reported that 14 of the 41 spot behavioral indicators were positively and significantly related to one or more of the study outcomes , but did not report that any of the indicators were negatively and significantly related to the outcome measures .

that is , passengers exhibiting the spot behaviors that were positively and significantly related were more likely to be arrested , to possess fraudulent documents , or possess prohibited or illegal items .

conversely , passengers exhibiting the behaviors that were negatively and significantly related were less likely to be arrested , to possess fraudulent documents , or possess serious prohibited or illegal items than those who did not exhibit the behavior .

while recognizing that the spot referral data used in this analysis were potentially unreliable , we replicated the spot indicator analysis with the full set of spot referral cases from january 1 , 2006 , to october 31 , 2010 , and found , consistent with the validation study , that 18 of the 41 behavioral indicators were positively and significantly related to one or more of the outcome measures .

we also found , however , that 20 of the 41 behavioral indicators were negatively and significantly related to one or more of the study outcomes .

that is , we identified 20 spot behavioral indicators that were more commonly associated with passengers who were not identified as high - risk passengers , than with passengers who were identified as high - risk passengers .

of the 41 behavioral indicators in the analysis , almost half of the passengers referred by bdos for referral screening exhibited one indicator .

this report addresses the following questions: 1 .

to what extent does available evidence support the use of behavioral indicators to identify aviation security threats ? .

2 .

to what extent does tsa have data necessary to assess the effectiveness of the spot program in identifying threats to aviation security ? .

in addition , this report provides information on tsa's response to recent allegations of racial profiling in the spot program , which can be found in appendix i .

to obtain background information and identify changes in the spot program since our may 2010 report , we conducted a literature search to identify relevant reports , studies , and articles on passenger screening and deceptive behavior detection .

we reviewed program documents in place during the period october 2010 through june 2013 , including spot standard operating procedures , behavior detection officer performance standards and guidance , a strategic plan , and a performance metrics plan .

we met with headquarters tsa and behavior detection and analysis ( bda ) program officials to determine the extent to which tsa had implemented recommendations in our may 2010 report and obtain an update on the spot program .

in addition , we met with officials from u.s. customs and border protection and the federal bureau of investigation ( fbi ) behavioral science unit to determine the extent to which they use behavior detection techniques .

we also interviewed officials in dhs's oig , who were working on a related audit .

we analyzed data for fiscal years 2011 and 2012 from tsa's spot referral database , which is to record all incidents in which bdos refer passengers for additional screening , including the airport , time and date of the referral , the names of the bdos involved in the referral , bdos' observation of the passengers' behaviors , and any actions taken by law enforcement officers , if applicable .

we also analyzed data for fiscal years 2011 and 2012 from the fams transportation information sharing system ( tiss ) database , which is a law enforcement database designed to retrieve , assess , and disseminate intelligence information regarding transportation security to fams and other federal , state , and local law enforcement agencies .

we reviewed available documentation on these databases , such as user guides , data audit reports , and training materials , and interviewed individuals responsible for maintaining these systems .

in addition , we analyzed data on bdos working at airports during this 2-year period , such as date started at tsa , date started as bdo , race , gender , and performance rating scores from tsa's office of human capital , and data on the number of hours worked by these bdos provided by tsa's office of security operations officials and drawn from the u.s. department of agriculture's national finance center database , which handles payroll and personnel data for tsa and other federal agencies .

further , we analyzed financial data from fiscal years 2007 through 2012 provided by bda to determine the expenditures associated with the spot program .

additional information about steps we took to assess the reliability of these data is discussed below .

we interviewed bda officials in the office of security capabilities and the office of human capital on the extent to which they collect and analyze these data .

we conducted visits to four airports — orlando international in orlando , florida ; detroit metropolitan wayne county in detroit , michigan ; logan international in boston , massachusetts ; and john f. kennedy international in new york city , new york .

we selected this nonprobability sample based on the airports' size and participation in behavior detection programs .

as part of our visits , we interviewed a total of 25 bdos using a semi - structured questionnaire , and their responses are not generalizable to the entire bdo population at spot airports .

these bdos were randomly selected from a list of bdos on duty at the time of our visit .

we interviewed bdo managers and tsa airport managers , such as federal security directors , who oversee the spot program at the airports .

in addition , to obtain law enforcement officials' perspectives on the spot program and their experiences in responding to spot referrals , we interviewed officials from the local airport law enforcement agency with jurisdiction at the four airports we visited ( orlando police department , wayne county airport authority , massachusetts state police , and port authority of new york and new jersey ) and federal law enforcement officials assigned to the airports , including u.s. customs and border protection , the fbi , and u.s. immigration and customs enforcement .

in nonprobability sampling , a sample is selected from knowledge of the population's characteristics or from a subset of a population where some units in the population have no chance , or an unknown chance , of being selected .

a nonprobability sample may be appropriate to provide illustrative examples , or to provide some information on a specific group within a population , but it cannot be used to make inferences about a population or generalize about the population from which the sample is taken .

the results of our visits and interviews provided perspectives about the effectiveness of the spot program from local airport officials and opportunities to independently observe tsa's behavior detection activities at airports , among other things .

to assess the soundness of the methodology and conclusions in the dhs april 2011 validation study , we reviewed the validation study and technical advisory committee ( tac ) final reports and appendixes , and other documents , such as the contractor's proposed study designs , contracts to conduct the study , data collection training materials , and interim reports on data monitoring visits and study results .

we assessed these efforts with established practices in designing evaluations and generally accepted statistical principles .

we obtained the validation study datasets from the contractor and replicated several of the analyses , based on the methodology described in the final report .

generally , we replicated the study's split - sample analyses , and as an extra step , extended those analyses using the full sample of spot referral data , as discussed below and in appendix ii .

in addition , we interviewed headquarters tsa , bda , and science and technology directorate ( s&t ) officials responsible for the validation study , representatives from the contractor who conducted the study , and 8 of the 12 members of the tac who commented on and evaluated the adequacy of the validation study and issued a separate report in june 2011 .

to assess the reliability of the spot referral data , we reviewed relevant documentation , including privacy impact assessments and a 2012 data audit of the spot database , and interviewed tsa and bda headquarters and field officials about the controls in place to maintain the integrity of the data .

to determine the extent to which the spot database is accurate and complete , we reviewed the data in accordance with established procedures for assessing data reliability and conducted tests , such as electronic tests to determine if there were anomalies in the dataset ( such as out - of - range dates and missing data ) and reviewed a sample of certain coded data fields and compared them with narrative information in the open text fields .

we determined that the data for fiscal years 2011 and 2012 across the 49 airports in our scope were sufficiently reliable for us to use to reflect the total number of spot referrals and arrests made , and to standardize the referral and arrest data , based on the number of hours each bdo spent performing operational spot activities .

in october 2012 , tsa completed an audit of the data contained in the spot referral database in which it identified common errors , such as missing data fields and incorrect point totals .

according to the 2012 audit , for the time period of march 1 , 2010 , through august 31 , 2012 , covering more than 108,000 referrals , the spot referral database had an overall error rate of 7.96 percent , which represented more than 8,600 known errors and more than 14,000 potential errors .

according to tsa , the agency has begun taking steps to reduce this error rate , including visits to airports with significant data integrity issues and the development of a new spot referral database that is designed to prevent the most common errors from occurring .

bda officials told us that they have begun steps toward a nationwide rollout of their new system in may 2013 , which includes pilots and developing procedures to mandate airports' use of the system .

on the basis of our review of the types of errors identified by the data audit , we determined that the spot referral data were sufficiently reliable for us to analyze bdo referral rates .

however , the audit identifies problems with arrest data , which is one of the three categories of “potential errors.” the audit does not report on the magnitude of this error category , because identifying these errors requires a manual audit of the data at the airport level .

as a result , we determined that the arrest data were not reliable enough for us to report on details about the arrests .

to determine the extent to which available evidence exists to support the use of behavioral indicators to identify security threats , we analyzed research on behavioral indicators , reviewed the validation study findings on behavioral indicators , and analyzed spot referral data .

working from a literature review of articles from 2003 to 2013 that were identified using search terms such as “behavior detection deception,” and discussions with researchers who had published articles in this area , we contacted other researchers to interview and academic and government research to review .

while the results of our interviews cannot be used to generalize about all research on behavior deception detection , they represent a mix of researchers and views by virtue of their affiliation with various academic institutions and governments , authorship of meta - analyses on these issues , and subject matter expertise in particular research areas .

we also reviewed more than 40 articles and books on behavior - based deception detection dating from 1999 to 2013 .

these articles , books , and reports were identified by our literature search of databases , such as articlefirst , eco , worldcat , proquest , and academic one file and recommendations by tsa and the experts we interviewed .

through our discussions and research , we identified four meta - analyses , which used an approach for statistically cumulating the results of several studies to answer questions about program impacts .

these meta - analyses analyzed “effect sizes” across several studies — the measure of the difference in outcome between a treatment group and a comparison group .

for example , these meta - analyses measured the accuracy of an individual's deception judgments when assessing another individual's credibility in terms of the percentage that lies and truths were correctly classified and the impact of various factors on the accuracy of deception judgments , such as the liar's motivation or expertise of the individual making the judgment .

we reviewed the methodologies of 4 meta - analyses covering over 400 separate studies on detection deception over a 60-year period , including whether an appropriate evaluation approach was selected for each meta - analysis , and whether the data were collected and analyzed in ways that allowed valid conclusions to be drawn , in accordance with established practices in evaluation design .

in addition , we interviewed two authors of these meta - analyses to ensure that the analyses were sound and we determined that the analyses were sufficiently reliable for describing what evidence existed to support the use of behavioral indicators to identify security threats .

we determined that the research we identified was sufficiently reliable for describing the evidence that existed regarding the use of behavioral indicators to identify security threats .

further , we reviewed documents developed by tsa and other foreign countries as part of an international study group to assess tsa's efforts to identify best practices on the use of behavioral detection in an airport environment .

to assess the soundness of the methodology and conclusions in the april 2011 validation study finding that 14 of the 41 spot indicators were related to outcomes that indicate a possible threat , we reviewed evidence supporting our may 2010 conclusions that the spot referral database lacked controls to help ensure the completeness and accuracy of the data .

we interviewed tsa officials and obtained documentation , such as a data audit report and a functional requirements document , to determine the extent to which problems in the spot database were being addressed .

we also reviewed the june 2011 tac final report and interviewed contractor officials regarding analysis limitations because of data sparseness , or low frequency of occurrences of indicators in the spot database .

we also obtained the dataset used in the study — spot referral data from january 2006 through october 2010 — and replicated the spot indicator analyses described in the study .

although we found that the data were not sufficiently reliable for use in conducting a statistical analysis of the association between the indicators and high - risk passenger outcomes , we used the data to assess the study's methodology and conclusions .

the dataset included a total of 247,630 spot referrals from 175 airports .

as described in the validation study , we calculated whether the odds on each of the four study outcome measures — leo arrest , possession of fraudulent documents , possession of a serious prohibited or illegal item , or the combination of all three measures — were associated with the 41 spot indicators .

these odd ratios were derived from four sets of 41 separate cross - tabulations — 2 x 2 tables — in which each of the four outcomes is cross - classified by each of the 41 individual indicators .

odds ratios greater than 1.0 indicate positive associations , that is , passengers exhibiting the behavior were more likely to be arrested , to possess fraudulent documents , or to possess serious prohibited or illegal items .

on the other hand , odds ratios of less than 1.0 indicate negative associations , that is , passengers exhibiting the behavior were less likely to be arrested , to possess fraudulent documents , or to possess serious prohibited or illegal items than those who do not exhibit the behavior .

the number of positive and significant associations we detected was slightly larger than the number reported in the validation study mainly because we reported results from an analysis of the full sample of spot referrals — a total of 247,630 spot passenger referrals .

in contrast , the validation study stated that a split - sample approach was used , in which each years' dataset was split into two stratified random subsets across the years and analyses were conducted independently on each aggregated subset .

the validation study stated that this approach allowed an examination of the extent to which results may vary across each subset and to address possible random associations in the data .

the validation study further stated that this was important because changes in the spot program , such as fewer airports and bdos involved in the earlier years and small changes to the spot instrument in march 2009 , could have affected the analyses .

however , after replicating the split - sample approach , we determined that it was not the most appropriate one to use because it substantially diminished the power to detect significant associations in light of how infrequently referrals occurred .

we report the results of our analyses of the full sample of spot referrals that indicate behavioral indicators that are positively and significantly related , as well as negatively and significantly related , in the behavioral indicator section of the report and in appendix ii .

to determine the extent to which spot referrals varied by bdos across airports for fiscal years 2011 and 2012 , we initially selected the 50 airports identified by tsa's may 2012 current airports threat assessment report as having the highest probability of threat from terrorist attacks .

we chose to limit the scope of our review to the top 50 airports because the majority of the bdos are deployed to these airports ; and they account for 68 percent of the passenger throughput , and 75 percent of spot referrals .

to standardize the referral rates across airports , we calculated the number of spot referrals by individual bdos and matched these bdos by the number of hours that particular bdos spent performing spot activities .

san francisco international airport was in the initial selection of 50 airports ; however , we excluded san francisco international because the hourly data provided to us for san francisco bdos , who are managed by a screening contractor , were not comparable with the hourly data provided to us for tsa - managed bdos .

the scope of our analysis was then 49 spot airports .

to calculate bdo hours spent performing spot activities , we analyzed bdo time and attendance data provided by tsa for fiscal years 2011 and 2012 from the u.s. department of agriculture's national finance center .

we limited our analysis to the hours bdos spent performing spot activities because it is primarily during these times that bdos make spot referrals .

thus , bdo hours charged to activities such as leave , baggage screening , or cargo inspection activities were excluded .

for example , we found that bdos had charged time to cargo inspection activities that were unrelated to the spot program .

these inspections are carried out under tsa's compliance division in the office of security operations , and are designed to ensure compliance with transportation security regulations .

we also limited our analysis to nonmanager bdos , as managers are not regularly engaged in making referrals .

finally , about 55 bdos , or about 2 percent of the approximately 2,400 bdos ( including both managers and nonmanagers ) , were not included in our analysis because we could not reconcile their names with time and attendance data after several attempts with tsa officials .

we calculated average referral rates per 160 hours worked , or about 4 40-hour weeks , across 2,199 bdos working at 49 airports , and a referral rate for each airport .

to better understand the variation in referral rates , we conducted a multivariate analysis to determine whether certain variables affected spot referral rates and leo referral rates , including airports at which bdos worked during fiscal years 2011 and 2012 ; bdo annual performance scores for 2011 and 2012 ; years of experience with tsa and as a bdo ; and demographic information on bdos , such as age , gender , race , and highest educational level attained at the time of employment .

although multivariate methods do not allow us to establish that referral rates are causally related to the bdo characteristics we had information about , they allowed us to examine the associations between referral rates and the different specific bdos while controlling for other bdo characteristics , including the airports in which the bdos worked .

moreover , the methods we employed allowed us to determine whether the observed differences in the sample data were different more than by merely chance fluctuations .

our statistical models and estimates are sensitive to our choice of variables ; thus , researchers testing different variables may find different results .

see appendix iv for additional information on the results of our analyses .

to determine the extent to which tsa has data necessary to assess the effectiveness of the spot program in identifying threats to aviation security , we reviewed the validation study's findings comparing passengers selected by spot with randomly selected passengers , analyzed tsa plans and analyses designed to measure spot's effectiveness , and analyzed data on spot referrals and leo arrests .

to assess the soundness of the methodology and conclusions in the april 2011 validation study findings that spot was more likely to identify high - risk passengers than a random selection of passengers , we assessed the study design and implementation against established practices for designing evaluations and generally accepted statistical principles .

these practices include , for example , probability sample methods , data collection and monitoring procedures , and quasi - experimental design .

we obtained the validation study datasets and replicated the study findings , based on the methodology described in the final report .

further , we analyzed the validation study data from december 1 , 2009 , to october 31 , 2010 , on passengers who were referred to a leo and who were ultimately arrested .

to the extent possible , we reviewed spot data to determine the reasons for the arrest and if there were differences between arrested passengers who were referred by spot and arrested passengers who were randomly selected .

to determine the extent to which tsa has plans to collect and analyze performance data to assess spot's overall effectiveness , we reviewed tsa's efforts to inform the future direction of bda and the spot program , such as a return - on - investment and risk - based allocation analyses .

we evaluated tsa's efforts against dhs , gao , and other guidance regarding these analyses .

for example , we reviewed tsa's return - on - investment analysis against the analytical standards in the office of management and budget's circular a - 94 , which provides guidance on conducting benefit - cost and cost - effectiveness analyses .

we also reviewed documentation associated with program oversight , including a 2012 performance metrics plan , and evaluated tsa's efforts to collect and analyze data to provide oversight of bda and the spot program against criteria in office of management and budget guidance and standards for internal control in the federal government .

further , we reviewed performance work statements in tsa contracts to determine the extent to which the contractor's work is to fulfill the tasks in tsa's performance metrics plan .

also , we reviewed fams law enforcement reports , tiss incident reports , and the spot referral database to determine the extent to which information from bdo referrals was used for further investigation to identify potential ties to terrorist investigations .

we also analyzed spot referral data that tsa uses to track spot program activities , including the number of passengers who were referred to a leo and ultimately arrested for fiscal years 2011 and 2012 .

to provide information about how tsa and dhs's oig have examined allegations of racial and other types of profiling of passengers by bdos , we reviewed documentation from 2010 to 2013 , such as investigation reports , privacy impact assessments , bdo training materials , and tsa memos .

to explore the extent to which we could determine the race , gender , and national origin of passengers who were referred by bdos for additional screening , we analyzed information in the spot referral database and the tiss database for fiscal years 2011 and 2012 .

we reviewed a september 2012 tsa contract that will , among other things , study whether any evidence exists for racial or ethnic profiling in the spot program .

we also reviewed interim reports produced by the contractor as of june 2013 .

because racial profiling allegations in boston were made during the course of our review , we asked the random sample of 25 bdos at the four airports we visited to what extent they had seen bdos in their airport referring passengers based on race , national origin , or appearance rather than behaviors .

these responses are not generalizable to the entire bdo population at spot airports .

further , 7 additional bdos contacted us over the course of our review to express concern about the profiling of passengers that they had witnessed .

we did not substantiate these specific claims .

we also interviewed tsa headquarters and field officials , such as federal security directors and bdo managers , as well as dhs oig officials .

we conducted this performance audit from april 2012 to november 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

to better understand the variation in referral rates , we analyzed whether certain variables affected spot referral rates and leo referral rates , including bdo characteristics , such as average performance scores for fiscal years 2011 and 2012 , years of tsa and bdo experience , age , gender , educational level , years employed at tsa and as a bdo , and race , as well as the airport in which the bdos worked .

as described earlier , these analyses standardized spot referral data for 2,199 bdos across 49 airports for fiscal years 2011 and 2012 .

the characteristics of the 2,199 bdos in our analyses varied across different categories , as shown in table 3 .

about 51 percent of the bdos were under 40 years of age , and slightly more than 25 percent were 50 years or older .

nearly 64 percent of the bdos joined tsa before the end of 2005 , but the majority , or more than 85 percent , became bdos after the beginning of 2008 .

nearly 65 percent of the bdos were male .

fifty percent were white , about 26 percent were african - american , and about 18 percent were hispanic .

about 65 percent of the bdos had a high school education or less .

the bdos were distributed unevenly across airports , with the largest numbers in logan international ( boston ) , dallas - fort worth international , john f. kennedy international ( new york ) , los angeles international , and o'hare international ( chicago ) .

each bdo worked primarily in one airport during the 2-year period .

for example , 80 of the 2,199 bdos , or about 4 percent , worked in multiple airports and the remaining 2,119 bdos , or 96 percent , worked at one airport during the 2- year time period .

overall , bdos averaged about 1.57 spot referrals and 0.22 leo referrals per 160 hours worked .

these rates vary across the different bdo categories .

however , these differences should be considered cautiously , as differences that appear to exist across categories for one characteristic may be confounded with differences across others .

for example , the apparent difference in referral rates between younger and older bdos may be the result of younger bdos working disproportionately in airports with higher referral rates .

to better understand the effects of bdo characteristics , including the airports they worked in , on spot referral and leo referral rates , we conducted simple regression analyses .

overall , the greatest amount of the variation in bdo spot referral rates was explained by the airport at which the referral occurred .

that is , the bdo's referral rate was associated substantially with the airport at which he or she was conducting spot activities .

these analyses show the size and significance of regression coefficients , from ordinary least - squares regression models , which reflect the estimated differences in the average number of spot referrals and leo referrals across categories of bdo , and across airports .

bdos in a few airports averaging significantly higher rates of referrals than bdos in the referent category , and bdos in most of the other airports averaging significantly lower leo referral rates .

because they were less common , leo referrals may have been more difficult to predict that spot referrals .

differences in the other bdo characteristics — multivariate model 1 — collectively accounted for a small percentage of the variation in average leo referral rates , while differences across airports accounted for a larger percentage .

separate analyses we conducted revealed that the sizeable and highly significant differences in spot referral rates and leo referral rates across airports were not fully accounted for by differences in the number of passengers who pass through airport checkpoints .

table 4 shows tsa's proposed performance metrics as detailed in appendix g in its behavior detection and analysis performance metrics plan dated november 2012 .

table 5 shows the validity , reliability , and frequency score tsa determined for each metric and the overall score for each metric subcategory , as detailed in appendix c of its performance metrics plan , dated november 2012 .

tsa's performance metrics plan defines validity as the ability of the metric to measure bdo performance , reliability as the level of certainty that data are collected precisely with minimal possibility for subjectivity or gaming the system , and frequency as the level of difficulty in collecting the metric and whether the metric is collected at the ideal number of scheduled recurrences .

in addition to the contact named above , david m. bruno ( assistant director ) ; charles w. bausell , jr. ; andrew m. curry ; nancy k. kawahara ; elizabeth b. kowalewski ; susanna r. kuebler ; thomas f. lombardi ; grant m. mallie ; amanda k. miller ; linda s. miller ; lara r. miklozek ; douglas m. sloane ; and jeff m. tessin made key contributions to this report .

