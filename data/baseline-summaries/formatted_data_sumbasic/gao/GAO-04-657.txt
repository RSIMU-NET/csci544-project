as the nation faces rising budget deficits and greater competition for federal resources to address 21st century challenges , it is becoming increasingly important for federal programs to demonstrate that they are meeting their long - range goals .

policy makers at all levels are seeking to understand whether our current employment and training system is making a difference in helping people get and keep jobs .

programs whose services are provided through the workforce investment act's ( wia ) one - stop centers constitute the largest portion of federal employment and training funds that provide direct assistance , with the three programs funded under wia — adults , dislocated workers , and youth — totaling about $3.3 billion in fiscal year 2004 .

with the passage of wia in 1998 , lawmakers envisioned a consolidated new system for delivering most federally funded employment and training programs — one that was more efficient and effective than prior programs .

to assess whether it is accomplishing its goals , wia established a rigorous performance accountability structure for the programs directly funded by wia — one that emphasized outcomes in areas of job placement , retention , earnings , and skill attainment , as well as customer satisfaction .

from federal long - range goals to local program policies , it is critical to demonstrate results at all levels with accurate outcome data , timely program management information , and impact studies to assess effectiveness .

but we and others have raised questions about whether anyone has a clear picture of what wia - funded programs are achieving .

because you were concerned whether wia's performance reporting system allows for a useful and accurate assessment of program achievements and to better understand how the performance system allows for local assessment of program successes , we examined ( 1 ) how useful wia performance data are for gauging program performance , ( 2 ) what local areas are doing to manage their wia performance and assess one - stop success on a timely basis and how states are assisting these efforts , and ( 3 ) to what extent the department of labor is trying to improve wia's performance measurement system and assess one - stop success .

to learn more about what the data tell us about outcomes achieved under wia , we examined states' annual reports , interviewed labor officials , and reviewed federal performance and reporting requirements .

in addition , to determine how states and local areas track interim progress toward meeting their wia performance levels that were negotiated with labor and to understand what they use to assess overall one - stop success , we surveyed the 50 states , as well as all 568 local workforce investment areas .

we received responses from all 50 states and 463 local workforce investment areas ( 81.5 percent ) .

we also visited three states — florida , michigan , and utah — and at least two local areas or one - stops in each of these states .

we selected these states because they are geographically diverse , have implemented additional performance measures or strategies to assess one - stop success , and have developed integrated statewide data systems .

we supplemented our site visits with telephone interviews with state and local officials in pennsylvania and interviews with experts in the area of workforce development performance measurement .

our review focused primarily on the employment - based measures that are tracked or partially tracked with the unemployment insurance wage records — entered employment rate , earnings change / replacement rate , employment retention rate , employment and credential rate , and the younger youth placement and retention rate .

we conducted our work between april 2003 and april 2004 in accordance with generally accepted government auditing standards .

labor required states to implement major provisions of wia by july 1 , 2000 , although some states began implementing provisions of wia as early as july 1999 .

services provided under wia represent a marked change from those provided under the previous program , allowing for a greater array of services to the general public .

wia requires that many federal programs provide employment and training services through one - stop centers .

wia is designed to provide for greater accountability than under previous law: it established new performance measures , a requirement to use unemployment insurance ( ui ) wage data to track and report on outcomes , and a requirement to conduct at least one multi - site control group evaluation .

when wia was enacted in 1998 , it replaced the job training partnership act ( jtpa ) programs for economically disadvantaged adults and youth and for dislocated workers with three programs — wia adult , dislocated worker , and youth — that provide a broader range of services to the general public , no longer using income to determine eligibility for all program services .

wia programs provide for three tiers , or levels , of service for adults and dislocated workers: core , intensive , and training .

core services include basic services such as job searches and labor market information .

these activities may be self - service or require some staff assistance .

intensive services include such activities as comprehensive assessment and case management — activities that require greater staff involvement .

training services include such activities as occupational skills or on - the - job training .

labor's guidance provides for monitoring and tracking for the adult and dislocated worker programs to begin when job seekers receive core services that require significant staff assistance .

wia excludes job seekers who receive core services that are self - service and informational in nature from being included in the performance measures .

wia's youth program does not have three tiers of services , but instead requires that 10 youth services , referred to as program elements , be made available to all eligible youth .

all youth who are determined eligible and receive wia services are included in the performance measures .

wia is designed to provide for greater accountability than its predecessor program by establishing new performance measures , a new requirement to use ui wage data to track and report on outcomes , and a requirement for labor to conduct at least one multi - site control group evaluation .

according to labor , performance data collected from the states in support of the measures are intended to be comparable across states in order to maintain objectivity in determining incentives and sanctions .

the performance measures also provide information to support labor's performance goals under the government performance and results act ( gpra ) , the budget formulation process using the office of management and budget's ( omb ) program assessment rating tool ( part ) , and for program evaluation required under wia .

in contrast to jtpa , for which data on outcomes were obtained through follow - ups with job seekers , wia requires states to use ui wage records to track employment - related outcomes .

each state maintains ui wage records to support the process of providing unemployment compensation to unemployed workers .

the records are compiled from data submitted to the state each quarter by employers and primarily include information on the total amount of income earned during that quarter by each of their employees .

although ui wage records contain basic wage information for about 94 percent of workers , certain employment categories are excluded , such as self - employed persons , independent contractors , federal employees , and military personnel .

according to labor's guidance , if a program participant does not appear in the ui wage records , states may use supplemental data sources , such as follow - up with participants and employers , or other administrative databases , such as u.s. office of personnel management or u.s. department of defense records , to track most of the employment - related measures .

however , only ui wage records may be used to calculate earnings change and earnings replacement .

 ( see table 1 for a complete list of the wia performance measures and data sources used for tracking the measures. ) .

unlike jtpa , which established expected performance levels using a computer model , wia requires states to negotiate with labor to establish expected performance levels for each measure .

states , in turn , must negotiate performance levels with each local area .

the law requires that these negotiations take into account differences in economic conditions , participant characteristics , and services provided .

to derive equitable performance levels , labor and the states primarily rely on historical data to develop their estimates of expected performance levels .

these estimates provide the basis for negotiations .

wia holds states accountable for achieving their performance levels by tying those levels to financial sanctions and incentive funding .

states that meet their performance levels under wia are eligible to receive incentive grants that generally range from $750,000 to $3 million .

states that do not meet at least 80 percent of their wia performance levels are subject to sanctions .

if a state fails to meet its performance levels for 1 year , labor provides technical assistance , if requested .

if a state fails to meet its performance levels for 2 consecutive years , it may be subject to up to a 5- percent reduction in its annual wia formula grant .

at the end of program year 2001 , four states received financial sanctions .

labor determines incentive grants or sanctions based on the performance data that states must submit each december in their annual reports .

states also submit quarterly performance reports , which are due 45 days after the end of each quarter .

in addition to the performance reports , states submit their updates for the workforce investment act standardized record data ( wiasrd ) every january .

all three submissions primarily represent participants who have exited the wia programs within the previous program year ( july 1 – june 30 ) .

wia also requires labor to conduct at least one multi - site control group evaluation by the end of fiscal year 2005 .

wia requires that evaluations address the general effectiveness of programs and activities in relation to costs and the impact of these services on the community and participants involved .

wia requires that states use the one - stop center system to provide services for many employment and training programs .

seventeen programs funded through four federal agencies are now required to provide services through the one - stop center under wia .

table 2 shows the programs that wia requires to provide services through the one - stop centers ( termed mandatory programs ) and the related federal agencies .

table 2 .

wia's mandatory one - stop partner programs and related federal agencies employment service ( wagner - peyser ) veterans ‘employment and training programs senior community service employment program employment and training for migrant and seasonal farm workers employment and training for native americans vocational education ( perkins act ) department of health and human services department of housing and urban development ( hud ) under wia , employers are expected to play a key role in establishing regional workforce development policies , deciding how services should be provided in the one - stop , and overseeing one - stop operations .

employers , who are encouraged to use the one - stop system to fill their job vacancies , are also seen as key one - stop customers under wia .

wia performance data are useful for providing a long - term national picture of program outcomes ; however , these data are less useful for providing information about current performance , and represent only a small portion of job seekers that received wia services .

ui wage recordsthe primary data source for tracking wia performance — provide a fairly consistent national view of wia performance and allow for tracking outcomes over time .

at the same time , the ui wage records have some shortcomings — they cannot be used to track job seekers who get jobs in other states unless states share data ; they do not cover certain categories of workers , such as self - employed persons ; and they are not available on a timely basis .

states are making progress in overcoming some of these shortcomings by sharing wage data with other states and supplementing information on participants not covered by the wage data .

despite this progress , time lags and other factors affect the timing of states' reports on their annual performance to labor and , subsequently , labor's reports to congress .

most of the outcomes data reported in a given program year actually reflect participants who left the program during the prior year , limiting usefulness for gauging current program performance .

in addition , the states' annual reports reflect only a small portion of job seekers who receive wia services because , under the law and labor's guidance , not all job seekers who utilize one - stop services are required to be included in the performance reports .

wia annual performance reportswhich provide a summary of states' performance on the 17 core measuresare useful for providing a national perspective of outcomes achieved over time .

the information presented in the annual reports compares states' negotiated performance levels with their actual performance levels .

 ( see table 3 for an example of national performance levels for wia's job placement ratecalled the entered employment ratein program year 2002. ) .

these reports provide congress with an annual picture of how well the wia program is meeting its long - range goals to increase the employment , retention , and earnings of participants .

the wia performance data are also useful to help labor assess quantitative , outcomes - oriented goals for its strategic plans , annual performance plans , and annual performance reports required by the government performance and results act ( gpra ) .

in its annual performance report for program year 2002 , labor used the wia outcome measures to assess its progress in meeting its strategic goals to increase employment , earnings , and assistance to adults and increase the number of youth in education or making a successful transition to work .

most of the performance outcomes in the annual reports are measured using ui wage records13 of the 17 wia performance measures rely on ui wage records as the primary data source for tracking employment outcomes .

 ( see table 4. ) .

states maintain ui wage records to determine whether unemployed workers qualify for unemployment compensation .

the records are compiled from data submitted to the state each quarter by employers and primarily include information on the total amount of wages paid to employees in the quarter .

however , ui wage records for most states do not include information on the number of hours an employee worked during the quarter and when in the quarter the wages were earned .

for example , the ui wage records for most states would not show that one employee may have worked 40 hours a week for the entire quarter and another worker may have worked 35 hours a week for the last two weeks of the quarter .

the ui wage records would provide an overall snapshot of the total amount of wages paid to both employees for the quarter .

the ui wage records provide a common yardstick for long - term comparisons across states because they contain wage and employment information on about 94 percent of the working population in the united states , and all states collect and retain these data .

in addition , ui wage records can be used as a common data source to track employment outcomes across multiple programs , such as vocational education and the temporary assistance for needy families ( tanf ) programs .

further , researchers have found that wage record data are more objective and cost - effective than traditional survey information .

for example , one state estimated that the cost of doing participant surveys , as was done under jtpa , was approximately $13.25 per participant compared with the cost of automated record matching to ui wage records , which costs less than $.05 per participant .

ui wage records make it easier to track longer - term measures , such as those that assess earnings change , earnings replacement , and employment retention 6 months after participants leave the program .

without ui wage records , tracking these outcomes would require contacting or surveying former participants , perhaps multiple times , after they leave the program .

ui wage records also have some shortcomings .

state wage record databases only include wage information on job seekers within their state ; they do not track job seekers who find jobs in other states .

states cannot readily gain access to ui wage records from other states , making it difficult to track individuals who receive services in one state but get a job in another .

to help gain access to wage information in other states , labor established the wage record interchange system ( wris ) a clearinghouse that makes ui wage records available to states seeking employment and wage information on their wia participants , and states are increasingly making use of this option .

nationwide , 38 states reported that they currently participate in wris , an increase from the 15 states that told us they were planning to or participating in wris in 2001 .

states may also elect to establish their own agreements to share wage information with other statesoften those that share a common border .

seven of the 38 states reported that they maintain their own interstate agreements with other states and they also participate in wris .

one state official we interviewed said the state maintains its own agreements in addition to wris so that the state can get data more quickly than through wris .

according to a labor official , states often retrieve wage record data from other states within a matter of days using wris .

however , the process can take much longer up to a couple of weeksif participating states take longer to respond to requests .

in addition , even though ui wage records contain information on about 94 percent of workers , they do not contain information on certain employment categories of workers , such as self - employed persons , most independent contractors , military personnel , federal government workers , and postal workers .

to compensate for the 6 percent of workers who are not in the ui wage records , labor allows states to report employment outcomes using other data sourcesfor example , by contacting participants after they leave the programto track wia participants who are employed in these uncovered occupations .

we found that 39 states reported relying on this supplemental information to report on participants not covered by the wage data .

twenty - three states told us that without the supplemental data , they would not have been able to show that they met minimum performance levels on at least one measure , and 10 of these states said they would not have been able to show that they met minimum performance levels on 10 of the measures in program year 2001 .

 ( see fig .

1. ) .

labor also allows states to use other employment and administrative data sources to track employees excluded from the ui wage records , such as the u.s. office of personnel management , the u.s .

postal service , and the u.s. department of defense .

eight states reported that they currently fill gaps in coverage using other administrative and employment data sources .

labor has recently established an agreement with the u.s. office of personnel management and is working on agreements with the u.s. department of defense and the u.s .

postal service to obtain employment data through a clearinghouse similar to wris to help more states obtain this outcome data .

labor plans to begin testing this new clearinghouse in program year 2004 .

 ( see app .

ii for a detailed listing of states' use of ui wage records and other data sources for reporting on wia outcomes. ) .

ui wage records also suffer significant time delays between the time an individual gets a job and the time it appears in the ui wage records .

state procedures for collecting and compiling wage information from employers can be slow and time - consuming .

data are collected from employers only once every quarter , and employers in most states have 30 days after the quarter ends to report the data to the state .

for example , the wage report for the last calendar quarter of the year ( ending on december 31 ) is due to the state on january 31 .

after the state receives the wage report , the data must be processed .

many employers report the data electronically , but some employersespecially small businessesare allowed to submit data in paper format , which then must be converted to electronic media .

after data entry , information must be checked for errors and corrected .

all these steps take time , which can delay the availability of the wage record data for reporting on outcomes for several months .

according to our survey , 28 states estimated they get information on job placement within 4 months after participants exit the program , and 44 states have this information within 6 months .

 ( see fig .

2. ) .

the time lags in receiving wage data , together with the use of longer - term outcome measures , affect when outcomes are reported and limit the data's usefulness for gauging current performance .

all 13 of wia's employment - related outcomes are measured after participants leaveor exitthe program , and some measures , such as those that assess wage changes and employment retention , require a 6-month wait .

to compensate for time lags , labor devised a reporting structure that reaches back to the prior year to provide a complete year's worth of outcome data on wia participants for the annual reports .

for example , for the employment - based measures , participants who are reported on in the program year 2002 annual report , provided to labor in december 2003 , left wia in the four quarters between october 2001 and september 2002 and may have received services much earlier .

the amount of time between when participants receive services and when their outcomes are reported to labor varies , but it is about 1½ years at a minimum .

a hypothetical example will illustrate this point by showing two participants that would be included in the program year 2002 report .

sue registered in april 2001 , participated in the program for at least 6 months , and left between october and december 2001 , taking about 32 months from the time of registration until her outcomes were reported .

joe , on the other hand , did not register until july 2002 , participated and left the program within 3 months , taking about 17 months from the time of registration until his outcomes were reported .

 ( see fig .

3. ) .

wia performance data represent a small proportion of the job seeker population receiving services at one - stops , making it difficult to know what the overall wia program is achieving .

most one - stop customers who participate in self - directed services and only receive limited staff assistance , for example to conduct a job search , are not reflected in the wia performance reports .

this group is estimated to be the largest portion of customers served under wia .

for example , one of the local areas in our study that tracks each one - stop customer told us that only about 5.5 percent of the individuals who walked into their one - stops in fiscal year 2003 were registered for wia services .

the current law excludes job seekers who receive services that are self - service and informational in nature .

labor's guidance tells states to register adults and dislocated workers who receive core services that require significant staff assistance designed to help with job seeking or acquiring occupational skills , but states have flexibility in deciding what constitutes significant staff assistance .

as a result of this flexibility , some local areas register a smaller proportion of participants than others , and in an earlier report , we said the local areas differed on when they registered wia customers .

in our recent visits to 4 states , we found that states and localities still differ on whom they tracksome local officials said they register job seekers who received core services that required significant staff assistance , and others said they do not register participants until they receive intensive services .

in addition , 21 of the 50 states we surveyed reported that they have instituted their own policies to more specifically define when registration should occur , suggesting that there is variation in interpreting labor's guidance .

some experts told us that local workforce areas do not get adequate credit for serving everyone , making it difficult to show what is being achieved with available funding .

with assistance from states , local areas manage wia performance and assess one - stop centers by collecting timely performance data and making use of a variety of performance information .

to understand how well they are doing in meeting their performance levels , most local areas directly contact former participants or employers to collect interim wia performance data that are not readily available from ui wage records .

states provide assistance to local areas in a variety of ways , ranging from supporting their information technology ( it ) systems to training local area staff .

while states and local areas must meet performance goals for wia , no similar goals exist for the overall one - stop systemthe service delivery system required under wia for most federally funded employment and training services .

nonetheless , some states and many local areas have developed a range of measures to help them assess how well the one - stop is doing .

despite the progress states and local areas have made in developing and using interim outcome information , states and local areas told us they would like more help from labor in collecting and disseminating promising practices on interim ways to assess wia performance .

according to our survey , many states play an active role in helping local areas monitor how well they are doing in meeting their performance levels .

the assistance they provide ranges from ensuring that local areas have ready access to participants' ui wage records to developing it systems and training local area staff on implementing wia performance measures .

to ensure local areas have ready access to wage record information on their participants , 23 states reported that they give local areas some form of electronic access to ui wage data for their wia participants .

ten of these states give local areas direct online access to the ui wage reporting system , making information available to local officials as quickly as it is reported to the state ; the others give local areas access once information has been merged into the statewide wia reporting system .

according to officials in florida , having direct access to ui wage data allows them to not only monitor performance levels but also develop industry and wage profiles , tailor training programs to meet regional needs , and obtain contact information for former participants , facilitating follow - up with individuals that would not be found otherwise .

when states do not give local areas ready access to ui wage data , as might occur in states with restrictive privacy laws , state officials usually provide local areas with standard reports on their wia progress , either for individual wia participants or , most often , aggregated across all wia participants in the local area .

in addition to helping provide timely information , almost all states are supporting local areas' it efforts .

according to our survey , 47 states have established or are in the process of establishing statewide it systems to help local areas organize , track , and report wia performance data .

in about three - fourths of these states , the statewide it systems allow the local areas to produce special reports that are tailored to local tracking needs and can report information for the local areas to use at the one - stop center , service provider , or case manager level .

although most local areas reported that they use a statewide system to help meet federal reporting requirements , half also use a locally developed it system in combination with a statewide it system .

local officials we met with often commented that they use a separate it system because they do not find their state systems useful for managing the day - to - day operations of a wia program .

as a result of needing both a statewide and a local system , almost half of local areas reported that at least some , if not all , of their one - stop staff must enter the same wia information into at least two it systems .

most states provide a range of other support services to local areas to help them manage their wia performance requirements and to understand what implementation approaches work better than others in providing one - stop services , according to our survey .

states reported they most often provide local areas with more specific written guidance or notices that explain federal guidance on the wia performance measures and performance reports .

in addition , about 90 percent of local areas told us that their states conduct training , make presentations , and hold regular meetings with local staff about wia performance measures .

to help local areas better understand what implementation approaches work better than others , several states have conducted special studies of the one - stop system .

sixteen states told us they have recently conducted studies on program implementation and processes ; 11 states told us they have done return - on - investment studies ; and 4 states have done impact evaluations that use control groups .

nationwide , half of the local areas believe that having a strong relationship with their state greatly helps them achieve their wia levels .

because ui wage data suffer from time delays , about three - fourths of local areas collect outcome information from other sources to help them assess whether they are meeting their wia performance levels and to help them manage their programs .

over 75 percent of local areas reported that they directly follow up with participants after they leave the program , collecting job placement or earnings information to help fill gaps until the data are available from the ui wage records .

sometimes local officials will also follow up with employers to verify employment or collect other documentation , such as pay stubs or w - 2 forms , as verification of employment .

if outcomes do not appear in ui wage records over time , many local areas will report the findings from these other data sources in their wia performance reports to the state .

local officials in a rural area of pennsylvania told us that collecting this interim outcome data is important to help them assess their progress in meeting their performance levels , so much so that they provide small gift certificates to former participants who periodically report back to wia staff .

according to these officials , this strategy of obtaining follow - up data saves considerable staff time as well as increases their performance levels by more completely capturing information on participants .

nearly all of the local areas reported on our survey that they track other types of interim indicators to manage their wia programsmost often the number of registered wia participants , services provided to wia participants , number of participants that have completed training , and number of wia exiters .

over half of these local areas report these data to decision makers on at least a monthly basis .

about 80 percent of local areas track some kind of cost information , such as cost per participant or cost per outcome , and 24 percent report this information at least monthly .

 ( see fig .

4. ) .

although these indicators may not be directly tracked and reported under wia , they are useful for helping local officials know the number of participants that will be counted in their wia measures .

furthermore , in some cases , these interim indicators also help the local areas predict their wia performance outcomes .

for example , one local official told us that knowing the number of participants who complete training helps him predict the number of participants who will find a job .

overall , nearly half of local areas reported that this type of interim information greatly helped them meet or exceed their performance levels .

despite the progress states and local areas have made in developing and using interim outcome information , nearly all states and local areas reported they would like more help from labor in collecting and disseminating promising practices on interim indicators to assess wia performance .

because meeting wia performance levels may affect future funding , most local areas hold service providers accountable and actively monitor their wia performance levels .

through our survey , we found that over 80 percent of local areas hold their service providers accountable by incorporating negotiated performance levels in their contracts .

in addition , nearly 80 percent of local areas establish goals for the number of participants who are registered in or exited from wia .

a lesser number of local areas24 percentestablish pay for performance contracts , and 18 percent provide financial incentives to their service providers .

 ( see table 5. ) .

officials from one local area that we visited told us they provide monetary bonuses to providers that exceed their wia goals and withhold 20 percent of their payments for those providers that do not reach their wia goals .

in addition , over 80 percent of local areas nationwide reported that having staff devoted to monitoring and managing wia performance greatly helps them achieve or exceed their levels .

once final wia performance information is available , local areas use this information to assess program services over time and to guide future program development .

most often local areas reported they use wia performance information to modify their programs .

we found that about two - thirds of local areas use performance information to a great extent to help them identify areas for program improvement and adopt new program approaches .

over half of local areas use their wia performance information to analyze trends over time and prepare strategic plans .

 ( see fig .

5. ) .

while wia requires that officials monitor outcomes for all job seekers who receive staff - assisted core , intensive , and training services funded by wia , there is no requirement to track those who receive self - directed core services , which may be the majority served under wia .

in addition , labor does not require that states and local areas measure the overall performance of the one - stop system .

nonetheless , most states and local areas have developed ways to assess the performance of their one - stops , using four basic types of indicatorsjob seeker measures , employer measures , program partnership measures , and family and community indicators .

 ( see fig .

6. ) .

even without a federal requirement to do so , according to our survey , almost 90 percent of local areas gather information on one - stop job seekers , even if they are not registered and participating in any particular federal program .

most often local areas reported that they require the one - stop centers to track and report the number of job seekers who visit the one - stop in a single time period , usually through a paper and pencil or computer log .

we also found that 58 percent of the local areas are collecting information on job seekers that repeatedly visit one - stop centers , sometimes through electronic means .

about 20 percent of all local areas reported using electronic swipe cards to track job seekers in their one - stop centers .

these swipe cards , similar to membership or grocery store discount cards , are issued to each job seeker using the one - stop and contain unique identifying information that can be read each time the job seeker accesses services .

for example , according to local officials in philadelphia , they issue swipe cards to job seekers and scan these cards to record both the services receivedsuch as using computers in the resource room , attending orientation workshops , or talking with the case managersand the date and time the services were provided .

using data from this system , one - stop managers can assess traffic flow and schedule staff accordingly , and may eventually be able to link participants and services to outcomes achieved .

officials also told us they are using demographic information from an analysis of swipe card data to target marketing efforts and to develop services more strategically .

in addition to counting the number of job seekers who visit the one - stop center , we found that local areas are tracking information on how many program referrals they receive , how satisfied they are with services , and what types of outcomes they achieve .

over half of local areas reported that they survey job seekers who visit the one - stop to gauge their satisfaction with services .

for example , a one - stop center in utah that we visited not only uses a one - stop satisfaction survey , but officials also periodically contact one - stop customers to ask how they liked the services .

according to our survey , some of the local areas said that having job seeker satisfaction information was one of the best ways to assess the one - stop system .

many local areas collect more in - depth information on all one - stop job seekersover one - third collect demographic characteristics , and over one - fourth monitor outcomes , such as whether job seekers got a job and at what wages .

 ( see fig .

7. ) .

many local areas also track information on employers' use of one - stops .

about 70 percent of local areas nationwide reported that they require one - stop centers to track some type of employer measure , such as the number of employers that use one - stop services , how many hire one - stop customers , and the type of services that employers use .

to gauge employer involvement , local areas most often require the one - stops to count and report the number of employers that use one - stop services .

over 40 percent of local areas require one - stops to track the number of employers that repeatedly use one - stop services .

for example , a one - stop center in utah we visited tracks employers that repeatedly use one - stop services and those that have not used services in a while .

it uses this information to reach out to employers who have not returned for services , encouraging them to use one - stop services again .

to understand how employers view the one - stop services they received , 60 percent of local areas reported they collect information on employer satisfaction .

a smaller numberabout 20 percent of local areastrack information on market penetration , such as the number of employers in the labor market that could potentially use one - stop services .

for example , philadelphia officials told us they measure market penetration by comparing the number of employers that use the one - stop center with the number of employers in the community as a whole .

 ( see fig .

8. ) .

most of the programs that provide services through the one - stop system have their own performance measures , but as we have reported in the past , these measures cannot be readily summed to obtain an overall measure of one - stop performance .

however , one - third of the local areas told us that they combine in one report some of the key federal measures for the various one - stop programsincluding wages at employment or other earnings indicatorsand use this report to assess the one - stop system as a whole .

for example , florida officials produce a reportcalled the red and green reportthat assembles for each local area outcomes on 22 measures from different one - stop programs , such as wia , wagner - peyser , and tanf .

weaker program outcomes are identified in red and stronger outcomes are identified in green .

they use this report to assess performance , diagnose weak spots , and predict long - term outcomes across one - stop partners .

more often local areas have gone a step further and have identified outcomes they consider to be key , developing common definitions for these measures to be used across programs .

just over half of the local areas reported in our survey that they track cross - cutting employment measures , such as job placement , and a little less than half said they track wages at placement and employment retention across programs .

for example , utah developed a set of outcome , process , efficiency , and activity measures to gauge the performance of all of their one - stops and to ensure alignment with agency goals and objectives .

these measures include entered employment , earnings increase , and employment retention across wagner peyser , wia , tanf , trade adjustment assistance , and food stamp employment and training programs .

in addition to tracking outcomes for the various one - stop partners , some local areas assess their one - stop systems by measuring the level of coordination among one - stop partners , as well as the range and quality of services they provide .

nearly 40 percent of local areas we surveyed said that they use indicators , such as increased coordination among partners and number of referrals partners made , to assess how well the overall one - stop system is operating .

for example , one local area reported it is developing a one - stop report card that will track the flow of customers through the system and monitor each program's contribution to the services provided , including the results of program referrals .

they will use this report card to target areas that need attention .

to ensure the one - stop system is providing quality services , some local areas we visited also conduct mystery shopper reviews wherein individuals posing as employers or job seekers evaluate the quality of the services they receive .

michigan conducts such mystery shopper visits of all their one - stops over the course of a year to assess the quality of customer services , including how courteous , professional , and knowledgeable one - stop staff are .

the state receives a comprehensive report of each visit and uses this information to target technical assistance .

a few local areas look outside their one - stops to assess how well one - stop services are meeting the needs of the family and the community .

in their written comments to our survey , several local areas told us that they consider some type of community indicator , such as changes in the local unemployment rate or increases in the average household income in the local area , to be the best way to determine the overall effectiveness of their one - stop system .

some local areas focus on indicators of family well - being , such as family self - sufficiencyor the ability of families to financially support themselvesto assess whether their one - stop systems are meeting family needs .

one rural one - stop in michigan even uses some indicators that are not related to income .

these local officials told us that their indicators include a collection of family indicators , including whether families are getting the child care they need and how well the children are doing at home and at school , to understand how well the one - stop is meeting the needs of the family .

although labor has taken steps to improve wia's performance measurement system and assess one - stops , some of its efforts do not go far enough .

labor has commissioned a study of adjustment methods that would better take into account economic and demographic differences when negotiating performance levels .

however , even if an acceptable model is developed , labor has made no commitment to put a standard adjustment method in place nationally .

to improve the quality of wia's performance data , labor has initiated a data validation project .

labor is taking a significant step toward measuring one - stop outcomes , but a planned change may lead to restricting the use of supplemental data to fill gaps in ui wage records .

while labor has plans to conduct impact studies , the department will not meet wia's requirement to conduct an impact study by 2005 , and without such a study , little will be known about wia's effectiveness .

labor has commissioned a study of adjustment methods that could be used to set expected performance levels during the negotiations process , but this effort does not go far enough .

wia requires that annual negotiations to establish expected performance levels consider differences in economic conditions , participant characteristics , and services providedfactors that can have a significant effect on the performance levels states and local areas are expected to achieve .

however , many of the state and local officials we interviewed said they did not think these factors were adequately addressed in the negotiations process , and as a result they think some of their performance levels were set too high for the current economy .

for example , some local officials said that their negotiated performance levels on the earnings change and earnings replacement measures were based on a stronger economy and did not reflect recent increases in the unemployment rate .

nationwide , 22 states reported that they are at risk of not meeting at least 80 percent of their negotiated performance levels on one or more of the wia measures for program year 2002 .

 ( see fig .

9. ) .

further , 10 states reported that they are at risk of receiving financial sanctions on one or more measures for program year 2002 .

to address states' concerns , labor has commissioned a study of adjustment methods , such as the type of model used under jtpaone that adjusted for factors beyond the control of local programs , such as high unemployment or a high concentration of non - english - speaking program applicants .

the jtpa model assigned adjustment factors and weights for each performance measure using a multiple regression analysis , predicting how well a local area might do based on the relevant factors .

for example , the model would assign a lower expected performance level to a local program serving extremely disadvantaged participants in an economically depressed area and a higher expected performance level to a local program serving job seekers who are nearly ready to get a job in an area with good economic conditions .

all states and nearly all local areas we surveyed told us they would like labor to use a model that can adjust for varying economic and population factors .

although labor is studying adjustment methods , even if an acceptable model is developed , it has made no commitment to implement such an adjustment method nationally .

some states currently use their own adjustment model or other methods in the negotiation process to account for factors beyond the control of local programs , but labor has not yet taken steps to increase consistency across states as it did under jtpa .

according to our survey , we found that nine states used a regression model or other method to a great extent to establish their performance levels for negotiating their program year 2004 performance levels with labor .

under jtpa , labor allowed states flexibility to develop their own adjustment procedures , but it established standard parameters to govern the adjustment methods used by states .

these parameters addressed the procedures for adjusting performance levels , the quality of data , and factors that could be used for adjustments .

for example , the procedures for adjusting performance levels were required to be objective and equitable across all local areas .

in addition , labor developed optional adjustment models that could be used by states because it recognized that not all states and local areas have the expertise and resources necessary to develop adjustment procedures .

without standard parameters , the process will lack consistency , and some states may be at a disadvantage in the process of negotiating their performance levels .

issues have been raised about the quality of performance data that labor uses to assess program performance .

as we mentioned previously , labor allows flexibility in determining which participants to track for reporting purposes .

this flexibility leads to variations in reporting , which raises questions about both the accuracy and the comparability of states' performance data .

in addition , we recently reported that performance data submitted by states in quarterly and annual reports were not sufficiently reliable to determine outcomes for the wia programs .

furthermore , labor's office of inspector general has said that there is little assurance that the states' performance data for all wia programs are either accurate or complete because of inadequate oversight of data collection and management at the federal , state , and local levels .

labor has initiated a new data validation project to improve the quality of the performance information collected and reported under wia .

labor's data validation project includes developing procedures and accuracy standards to help states validate that wia performance and participant data are correctly reported .

for this project , labor developed data validation handbooks and software and required states to begin validating program year 2002 data , which were reported to labor on december 1 , 2003 .

states are required to conduct two types of data validation: ( 1 ) review samples of wia participant files and ( 2 ) assess whether reporting software accurately calculated the performance measures .

labor provided software to help states generate the aggregate information required for performance reports , such as performance outcomes .

if states elect to use labor's software , they are not required to validate the calculations .

at the time of our surveydecember 2003 through february 2004we found that 41 states had begun using labor's data validation software .

labor also plans to hold states accountable for meeting accuracy standards , beginning in the third year of validation .

once these accuracy standards are in place , states failing to meet the standards may lose eligibility for incentive awards or , in cases with significant deviations from the standards , states may be sanctioned .

labor is taking a significant step toward measuring outcomes across one - stop partners by developing definitions for a set of common performance measures .

the office of management and budget established a set of common measures to be applied to all federal employment and training programs administered by labor , education , health and human services , veterans affairs , interior , and housing and urban development .

 ( see table 6. ) .

labor has developed standard definitions for calculating these measures across all of its employment and training administration programs .

 ( see table 7. ) .

this will allow labor to sum outcomes across all its programs to provide a more uniform picture of outcomes achieved .

according to a department official , labor worked with other federal agencies to get agreement on common data sources and common language , where possible .

for example , labor is working on developing a process , using wris , that would allow other federal programs to use ui wage records to track outcomes .

as part of the common measures , labor plans to require one - stops to track all participants who walk through the door of a one - stop center and receive any one - stop service , regardless of which program provides the service .

according to labor , tracking all one - stop job seekers will enable officials to obtain information about who is served , what services are provided , which partner programs provided services , and what outcomes are achieved .

while these changes can provide more information on job seekers , there is no provision for any measure of employer involvement in the one - stops , and experts and state and local officials we interviewed said that at least one measure is needed to address employer usage .

while most of labor's policies for the common measures can advance measurement across one - stop partners , labor plans to rely almost entirely on the ui wage records and discontinue the use of supplemental data for filling gaps in ui wage records .

labor officials tell us that they are making this change to address concerns about the quality of supplemental data being collected .

under labor's current guidance , supplemental data must be documented .

however , the department has no systematic process in place to monitor the accuracy of these supplemental data .

if labor elects to replace the current definitions of the wia entered employment rate and earnings retention measure with the common measure definitions , this restriction on the use of supplemental data could have a significant impact on the ability of states and local areas to meet their negotiated performance levels .

in addition , labor's new data validation project could help ensure the accuracy of supplemental data that is collected at the local level .

while labor has plans to conduct impact studies , the department will not meet wia's requirement to conduct at least one multi - site control group evaluation by fiscal year 2005 .

this type of impact study is important because outcome measures alone cannot show whether an outcome is a direct result of program participation or whether it is a result of other influences , such as the state of the local economy .

labor officials said they did not initiate impact studies of wia within the first few years after wia passed to allow states and local areas time to implement the considerable changes that were required under wia .

according to officials , labor had planned to initiate an impact evaluation of the wia adult and dislocated worker programs in 2004 , but this plan is currently on hold because labor is anticipating changes to these programs as a result of reauthorization .

once wia is reauthorized , labor officials told us that they would likely allow 2 or 3 years for changes to be implemented before initiating an impact evaluation .

the evaluation itself will take 5 to 6 years , but labor plans to issue interim reports on the findings once the study is under way .

even though the house passed a reauthorization bill , the workforce reinvestment and adult education act of 2003 ( hr1261 ) , and the senate passed a bill , the workforce investment act of 2003 ( s1627 ) , passage of a final bill has stalled .

both bills propose changes to wia , but most of the basic one - stop service delivery and governance structure would stay the same in both bills .

given that these changes will not likely affect the fundamental service delivery and structure of wia , it is unclear why labor has not proceeded with its evaluations of wia as planned .

when wia was implemented nearly 4 years ago , it fundamentally changed the way federally funded employment and training services are provided to job seekers , the way the system engages employers , and the way it measures performance .

making this shift has taken time and some trial and error as state and local policy makers and one - stop service providers learned what type of service structure met local needs .

since implementation , states and local areas have made great progress in retooling their systems and in gathering all the data needed to report on their performance to labor .

but , only recently are we getting a nationwide glimpse of outcomes achieved under wia .

the requirement to use ui wage data is a step in the right direction by providing a reasonably consistent look at national program results over time .

historically , there have been data quality issues with outcome data collected directly from participants , as was done prior to wia .

the ui wage data provide a level of credibility that other data sources do not have .

states have made progress in accessing data from other states .

but in order to meet their performance levels , some states must continue to rely on other data sources to fill gaps .

out of concern for data comparability , labor is proposing to limit the use of data from other sources .

this decision , if applied to the wia programs , will hinder the ability of some states to demonstrate that they have met their expected performance levels and may cause one - stops to focus their efforts on only those occupations covered by the ui wage records .

this policy also seems overly restrictive , given that labor is implementing data validation procedures that could be used to ensure the accuracy and validity of supplemental data .

even with the capability to use supplemental data , some states and local areas have failed to demonstrate that they met their negotiated performance levels for 2 years in a row and have suffered financial sanctions — often citing local economic conditions as the cause .

the development of a method to systematically adjust for economic and demographic factors outside the control of the local area in setting expected performance levels could help mitigate these concerns .

while the use of ui wage records has improved the quality of the data that are used to track outcomes under wia , this information alone does little for real - time program management .

we found that state and local officials have made significant strides in collecting their own data to assess whether they are likely to meet their federally required performance levels , manage their programs on a real - time basis , and track a broader one - stop population than just registered wia participants .

in some ways , the wia performance measures based on the ui wage records and the interim data collected at the state and local level provide a useful system to cross check these data .

however , not all states and local areas have determined what interim information is necessary , nor have they had the benefit of learning from their peers .

without some additional information or the sharing of promising practices , these states and local areas will be at a disadvantage in monitoring their progress and , perhaps , in meeting their minimum performance levels .

further , labor has also failed to meet wia's requirement to conduct a systematic evaluation of wia .

plans to do an evaluation have been delayed until reauthorization is complete , even though the proposed bills would retain most of the wia service delivery and governance structure .

delays in committing to an evaluation now may be costly because policy makers will not be able to benefit from an understanding of wia's effectiveness .

without clear guidance from labor , states and local areas continue to struggle with determining who should be tracked in the wia performance measures .

at the same time , even if states and localities had a common understanding of whom to track and were consistently reporting on the same categories of customers , they would only be reporting on a small portion of overall one - stop customers .

while a requirement to track all job seekers who visit the one - stops may appear to be a major change , we found that over half the local areas already collect information on job seekers that repeatedly use one - stops , suggesting that some local areas are already equipped to uniquely identify and track each job seeker .

it may take time and resources for local areas to fully develop the capability to collect data on each job seeker , but this may be the best way to start gauging the value of one - stops overall .

as long as the law excludes individuals who participate in self - service and informational services , it will be difficult to understand the full reach of wia .

to compensate for the impact of changes in the economy and to give states and local areas an equal opportunity to meet their performance levels , we recommend that the secretary of labor continue to allow the use of supplemental data for reporting outcomes , but develop more stringent guidance and monitoring of these data ; provide assistance to states and localities in developing and sharing promising practices on interim indicators for assessing wia's performance ; and develop an adjustment model or other systematic method to account for different populations and local economic conditions when negotiating performance levels .

to comply with statutory requirements and to help federal , state , and local policy makers understand what services are most effective for improving employment - related outcomes , we recommend that the secretary of labor expedite efforts to design and implement an impact evaluation of wia services .

we suggest that congress may wish to consider requiring that information be collected and reported on all wia participants , including those who only receive self - service and informational services , so that congress may have a better understanding of the full reach of wia and the one - stop system .

we provided a draft of this report to labor for review and comment .

labor generally agreed with recommendations about continuing the use of supplemental data , sharing promising practices on interim performance indicators , and developing an adjustment model or other systematic method for use in negotiating performance levels .

in addition , labor agreed with our matter for congressional consideration that information be collected and reported on all wia participants .

however , labor disagreed with our recommendation to expedite efforts to design and implement an impact evaluation of wia services .

we have incorporated labor's comments in our report , as appropriate .

a copy of labor's response is in appendix iii .

on our recommendation regarding the use of supplemental data for reporting outcomes under wia , labor responded that it will continue to allow supplemental wage data except when calculating results on the common measures that are reported to the office of management and budget .

labor also told us that its ongoing data validation effort will collect additional information that will help assess the quality of supplemental wage data that states are reporting .

we continue to believe that when assessing state and local progress toward meeting wia's expected performance levels , supplemental data will be essential to gather a more complete picture of wia outcomes .

on our recommendation to develop and share promising practices on interim indicators for assessing wia's performance , labor noted some of the efforts currently under way to facilitate information exchange , including state and local peer - to - peer alliances , labor's promising practices web site , and a performance enhancement project for states to share ideas and promising practices .

however , despite labor's ongoing efforts to facilitate information exchange , nearly all states and local areas reported on our survey that they would like more help from labor in collecting and disseminating information on promising practices on interim indicators to assess wia performance .

regarding our recommendation to develop an adjustment or other systematic method for use in negotiating performance levels , labor agreed with the importance of taking economic conditions and characteristics of the population into account when setting performance expectations .

labor noted the study it has commissioned on adjustment models that we cited in our report and said the results of this study are not yet available .

labor expressed concern that any systematic method for taking economic and demographic factors into account must not diminish the role of the states and local areas in setting strategic goals .

our recommendation for a systematic approach would not replace any state and local efforts to establish their own goals , but it could help make the national process for setting goals more uniform and provide tools for states and local areas that do not have the resources to develop their own adjustment procedures .

in response to our recommendation to expedite the design and implementation of an impact evaluation of wia services , labor told us that it believes the program consolidation changes proposed in the reauthorization bill passed by the house are significant enough to delay the multi - site evaluation required by wia .

however , we disagree that proposed reauthorization changes would significantly affect the basic one - stop service delivery structure under wia .

it is now 4 years past the full implementation of wia and a well - designed evaluation would help inform policymakers in the future .

waiting for the implementation of any changes resulting from the current reauthorization cycle would likely delay the start of an evaluation at least 2 years , thus not having results available until after another reauthorization cycle has passed .

we are sending copies of this report to the secretary of labor , relevant congressional committees , and others who are interested .

copies will also be made available to others upon request .

the report is also available on gao's home page at http: / / www.gao.gov .

please contact me on ( 202 ) 512-7215 if you or your staff have any questions about this report .

other major contributors to this report are listed in appendix iii .

we examined ( 1 ) how useful wia performance data are in gauging program performance , ( 2 ) what local areas are doing to manage their wia performance and assess one - stop success on a timely basis and how states are assisting these efforts , and ( 3 ) to what extent labor is trying to improve wia's performance measurement system and assess one - stop success .

our review focused primarily on the employment - based measures that rely on ui wage records — entered employment rate , earnings change / replacement rate , employment retention rate , employment and credential rate , and the younger youth placement and retention rate .

to address these questions , we conducted two surveys — one of state wia officials and one of local area workforce officials ; reviewed different types of literature about wia and the wia performance measurement system ; interviewed experts and department of labor officials ; interviewed state and local wia officials ; and visited three states and two local areas or one - stops within each state .

we supplemented our site visits with telephone interviews with state and local officials in pennsylvania we provided a draft of this report to officials at the department of labor for their review and incorporated their comments where appropriate .

we conducted our work from april 2003 through april 2004 in accordance with generally accepted government auditing standards .

to obtain further information on the area of wia performance management , we reviewed and analyzed numerous studies , reports , and other literature , and we interviewed experts on wia and workforce development performance measurement .

we reviewed a department of labor study that discussed costs of data collection and found it sufficiently reliable for the purpose of comparing costs of surveys and automated record matching to ui wage records .

we also interviewed department of labor officials , as well as representatives of the national governors' association and the national association of workforce boards .

to determine how useful wia performance data are in gauging program performance and what states and local areas are doing to manage and assess wia programs and one - stop systems , we surveyed all 50 states and the district of columbia , as well as all existing local workforce investment areas , using similar but not identical questionnaires .

we conducted both surveys via the internet .

we asked both groups to provide information on issues related to the wia performance measures , such as state or local policies , the availability and use of ui data , wia performance levels ; management practices ; information technology systems , efforts to monitor and manage their wia programs and one - stop systems , factors that adversely affected their ability to assess their one - stops systems , and the types of technical assistance that would help with managing their one - stop systems' performance .

we pre - tested the questionnaires used for each of the surveys at least three times .

table 8 provides survey numbers and response rates for both surveys .

because these were not sample surveys , there are no sampling errors .

however , the practical difficulties of conducting any survey may introduce errors , commonly referred to as nonsampling errors .

for example , difficulties in how a particular question is interpreted , in the sources of information that are available to respondents , or how the data are entered into a database can introduce unwanted variability into the survey results .

we took steps in the development of the questionnaires , the data collection , and data analysis to minimize these nonsampling errors .

for example , as already noted , we pretested the questionnaires to ensure that questions were clear and understandable .

in that these were web - based surveys whereby respondents entered their responses directly into our database , there was little possibility of data entry error .

in addition , we verified that the computer programs used to analyze the data were written correctly .

we visited three states — florida , michigan , and utah — and traveled to at least two local areas or one - stop centers in each of these states .

we supplemented our site visits with telephone interviews with state and local officials in pennsylvania .

 ( see table 9 for a list of the states and local areas in our study. ) .

based on input from recognized experts and our literature review , we selected these states because they are geographically diverse , have experience in implementing additional performance measures to assess one - stop success , and have developed integrated statewide data systems .

in each state , we interviewed state officials responsible for monitoring local areas' wia programs and analyzing and reporting on the state's wia performance data , as well as other state wia and it officials and staff of the state's workforce investment board .

at the local areas , we interviewed wia officials and staff , including service providers , staff responsible for performance management issues , it staff , case managers and other frontline staff , as well as staff of the local area workforce investment board .

the state and local interviews were administered using a semi - structured interview guide that we developed through a review of relevant literature and discussions with recognized experts on wia performance management .

information that we gathered on our site visits represents only the conditions present in the states and local areas at the time of our site visits , from june through october 2003 .

we cannot comment on any changes that may have occurred after our fieldwork was completed .

furthermore , our fieldwork focused on in - depth analysis of only a few selected states and local areas or sites .

based on our site visit information , we cannot generalize our findings beyond the states and local areas or sites we visited .

carolyn s. blocker and cheri harrington made significant contributions to all phases of the effort .

stu kaufman made significant contributions in the design and administration of the surveys .

in addition , jessica botsford provided legal support ; avrum ashery and barbara hills provided graphic design assistance ; and elizabeth curda , patricia dalton , catherine hurley , and shana wallace also provided key technical assistance .

national emergency grants: labor is instituting changes to improve award process , but further actions are required to expedite grant awards and improve data .

gao - 04-496 .

washington d.c.: april 16 , 2004 .

workforce investment act: labor actions can help states improve quality of performance outcome data and delivery of youth services .

gao - 04-308 .

washington d.c.: february 23 , 2004 .

workforce training: almost half of states fund employment placement and training and employment through employer taxes and most coordinate with federally funded programs .

gao - 04-282 .

washington d.c.: february 13 , 2004 .

workforce investment act: one - stop centers implemented strategies to strengthen services and partnerships , but more research and information sharing is needed .

gao - 03-725 .

washington , d.c.: june 18 , 2003 .

workforce investment act: issues related to allocation formulas for youth , adults , and dislocated workers .

gao - 03-636 .

washington , d.c.: april 25 , 2003 .

workforce training: employed worker programs focus on business needs , but revised performance measures could improve access for some workers .

gao - 03-353 .

washington , d.c.: february 14 , 2003 .

older workers: employment assistance focuses on subsidized jobs and job search , but revised performance measures could improve access to other services .

gao - 03-350 .

washington , d.c.: january 24 , 2003 .

workforce investment act: states' spending is on track , but better guidance would improve financial reporting .

gao - 03-239 .

washington , d.c.: november 22 , 2002 .

workforce investment act: states and localities increasingly coordinate services for tanf clients , but better information needed on effective approaches .

gao - 02-696 .

washington , d.c.: july 3 , 2002 .

workforce investment act: youth provisions promote new service strategies , but additional guidance would enhance program development .

gao - 02-413 .

washington , d.c.: april 5 , 2002 .

workforce investment act: better guidance and revised funding formula would enhance dislocated worker program .

gao - 02-274 .

washington , d.c.: february 11 , 2002 .

workforce investment act: improvements needed in performance measures to provide a more accurate picture of wia's effectiveness .

gao - 02-275 .

washington , d.c.: february 1 , 2002 .

workforce investment act: better guidance needed to address concerns over new requirements .

gao - 02-72 .

washington , d.c.: oct. 4 , 2001 .

workforce investment act: implementation status and the integration of tanf services .

gao / t - hehs - 00-145 .

washington , d.c.: june 29 , 2000 .

