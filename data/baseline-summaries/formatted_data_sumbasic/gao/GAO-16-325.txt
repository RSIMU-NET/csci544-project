cloud computing is a process for acquiring and delivering computing services via internal or external information technology ( it ) networks .

according to the national institute of standards and technology ( nist ) , cloud computing is “a means for enabling on - demand access to shared and scalable pools of computing resources with the goal of minimizing management effort or service provider interaction.” more specifically , purchasing it services through a provider enables agencies to avoid paying for all the assets ( eg , hardware , software , networks ) that would typically be needed to provide such services .

this approach offers federal agencies a means to buy the services faster and possibly cheaper than through the traditional methods they have used , such as keeping it all in - house .

to take advantage of these potential benefits , agencies have reported that they plan to spend more than $2 billion on cloud computing services in fiscal year 2016 .

an important part of acquiring it cloud computing services is incorporating a service level agreement ( sla ) into the contract .

an sla defines levels of service and performance that the agency expects the contractor to meet and the agency uses the information to measure the effectiveness of its cloud services .

to encourage the use of slas , the office of management and budget ( omb ) directed subject matter experts to issue guidance that highlighted slas as a key factor to be addressed in developing cloud computing contracts .

you asked us to examine federal agencies' use of slas .

specifically , our objectives were to ( 1 ) identify key practices used in cloud computing service level agreements to ensure service is performed at specified levels and ( 2 ) determine the extent to which federal agencies have incorporated such practices into their cloud computing service level agreements .

to identify key practices , we analyzed sla research , studies , and guidance developed and used by federal agencies and private entities and performed a comparative analysis of the practices to identify the most effective ones .

specifically , we analyzed information from publications and related documentation issued by the following ten public and private organizations to determine key sla practices: federal chief information officers council chief acquisitions officers council national institute of standards and technology european commission directorate general for communications networks , content and technology omb gartner mitre corporation cloud standards customer council international organization for standardization international electrotechnical commission we then validated our analysis through interviews with experts from these organizations .

we also had officials from omb review and validate that the practices we identified are those the office expects federal agencies to follow .

to determine the extent to which federal agencies have incorporated key practices into their cloud computing contracts , we selected five agencies to review based , in part , on the size of their largest fiscal year 2015 it budgets and planned spending on cloud computing services .

the agencies selected were the departments of defense , health and human services , homeland security , treasury , and veterans affairs .

to select and review the cloud services used by the agencies , we obtained a list of each agency's cloud services .

we listed the cloud services for each agency and selected two for each of three major cloud service models ( infrastructure , platform , or software ) .

in certain cases , the agency did not have two cloud services for a service model , so the number chosen for that service model was less than two .

for each of the selected cloud services , we compared its contract ( if one existed ) , any supporting sla , and other documentation to our list of key practices to determine the extent to which the agency had adhered to the key practices or if there were variances .

we also interviewed agency officials to corroborate our analysis and identify the causes and impacts of any variances from the practices .

 ( further details of our scope and methodology are in app .

i. ) .

we conducted this performance audit from january 2015 to april 2016 in accordance to generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the federal government spends more than $80 billion dollars on it annually , with more than $2 billion of that amount spent on acquiring cloud - based services .

this amount is expected to rise in coming fiscal years , according to omb .

a goal of these investments is to improve federal it systems by replacing aging and duplicative infrastructure and systems that are costly and difficult to maintain .

cloud computing helps do this by giving agencies the ability to purchase a broad range of it services in a utility - based model that allows an agency to pay for only the it services it uses .

according to nist , an application should possess five essential characteristics to be considered cloud computing: on - demand self - service , broad network access , resource pooling , rapid elasticity , and measured service .

essentially , cloud computing applications are network - based and scalable on demand .

according to omb , cloud computing is economical , flexible , and fast: economical: cloud computing can be a pay - as - you - go approach , in which a low initial investment is required to begin and additional investment is needed only as system use increases .

flexible: it departments that anticipate fluctuations in user demand no longer need to scramble for hardware and software to meet increasing need .

with cloud computing , capacity can be added or subtracted quickly .

fast: cloud computing eliminates long procurement and certification processes , while providing a wide selection of services .

in addition , according to nist , cloud computing offers three service models: infrastructure as a service — the agency has the capability to provision processing , storage , networks , and other fundamental computing resources and run its own software , including operating systems and applications .

the agency does not manage or control the underlying infrastructure but controls and configures operating systems , storage , deployed applications , and possibly , selected networking components ( eg , host firewalls ) .

platform as a service — the agency deploys its own or acquired applications created using programming languages and tools supported by the provider .

the agency does not manage or control the underlying infrastructure , but controls and configures the deployed applications .

software as a service — the agency uses the service provider's applications , which are accessible from various client devices through an interface such as a web browser ( eg , web - based e - mail system ) .

the agency does not manage or control the underlying infrastructure or the individual application capabilities .

as can be seen in figure 1 , each service model offers unique functionality , with consumer control of the environment decreasing from infrastructure to platform to software .

nist has also defined four deployment models for providing cloud services: private , community , public , and hybrid .

in a private cloud , the service is set up specifically for one organization , although there may be multiple customers within that organization and the cloud may exist on or off the customer's premises .

in a community cloud , the service is shared by organizations with similar requirements .

the cloud may be managed by the organizations or a third party and may exist on or off an organization's premises .

a public cloud is available to the general public and is owned and operated by the service provider .

a hybrid cloud is a composite of two or more other deployment models ( private , community , or public ) that are bound together by standardized or proprietary technology .

according to federal guidance , these deployment models determine the number of consumers and the nature of other consumers' data that may be present in a cloud environment .

a public cloud should not allow a consumer to know or control other consumers of a cloud service provider's environment .

however , a private cloud can allow for ultimate control in selecting who has access to a cloud environment .

community clouds and hybrid clouds allow for a mixed degree of control and knowledge of other consumers .

according to omb , the federal government needs to shift from building custom computer systems to adopting cloud technologies and shared services , which will improve the government's operational efficiencies and result in substantial cost savings .

to help agencies achieve these benefits , omb required agencies in 2010 to immediately shift to a “cloud first” policy and increase their use of available cloud and shared services whenever a secure , reliable , and cost - effective cloud service exists .

in february 2011 , omb issued the federal cloud computing strategy , as called for in its 25-point plan .

the strategy provided definitions of cloud computing services ; benefits of cloud services , such as accelerating data center consolidations ; a decision framework for migrating services to a cloud environment ; case studies to support agencies' migration to cloud computing services ; and roles and responsibilities for federal agencies .

for example , the strategy stated that nist's role is to lead and collaborate with federal , state , and local government agency chief information officers , private sector experts , and international bodies to identify standards and guidance and prioritize the adoption of cloud computing services .

in addition , the strategy stated that agency cloud service contracts should include slas designed to meet agency requirements .

in a december 2011 memo , omb established the federal risk and authorization management program ( fedramp ) , a government - wide program intended to provide a standardized approach to security assessment , authorization , and continuous monitoring for cloud computing products and services .

all federal agencies must meet fedramp requirements when using cloud services and the cloud service providers must implement the fedramp security requirements in their cloud environment .

to become authorized , cloud service providers provide a security assessment package to be reviewed by the fedramp joint authorization board , which may grant a provisional authorization .

federal agencies can leverage cloud service provider authorization packages for review when granting an agency authority to operate , where this reuse is intended to save time and money .

further , at the direction of omb , the chief information officers council and the chief acquisition officers council issued , in february 2012 , guidance to help agencies acquire cloud services .

in particular , the guidance highlights that slas are a key factor for ensuring the success of cloud based services and that federal agencies should include an sla when creating a cloud computing contract or as a reference .

the guidance provides important areas of an sla to be addressed ; for example , it states that an sla should define performance with clear terms and definitions , demonstrate how performance is being measured , and identify what enforcement mechanisms are in place to ensure the conditions are being met .

in addition , nist , in its role designated by omb in the federal cloud computing strategy , collaborated with private sector organizations to release cloud computing guidance , which affirms the importance of using an sla when acquiring cloud computing services .

moreover , a number of other public and private sector organizations have issued research on the incorporation of an sla in a cloud computing contract .

according to these studies , an sla is important because it ensures that services are being performed at the levels specified in the cloud computing contract , can significantly contribute to avoiding conflict , and can facilitate the resolution of an issue before it escalates into a dispute .

the studies also highlight that a typical sla describes levels of service using various attributes such as availability , serviceability or performance , and specifies thresholds and financial penalties associated with a failure to comply with these thresholds .

we have previously reported on federal agencies' efforts to implement cloud computing services and on progress oversight that agencies have made to help federal agencies in those efforts .

these include in may 2010 , we reported on the efforts of multiple agencies to ensure the security of government - wide cloud computing services .

we noted that , while omb , the general services administration ( gsa ) , and nist had initiated efforts to ensure secure cloud computing services , omb had not yet finished a cloud computing strategy ; gsa had begun a procurement for expanding cloud computing services for its website that served as a central location for federal agencies to purchase cloud services , but had not yet developed specific plans for establishing a shared information security assessment and authorization process ; and nist had not yet issued cloud - specific security guidance .

we recommended that omb establish milestones to complete a strategy for federal cloud computing and ensure it addressed information security challenges .

these include having a process to assess vendor compliance with government information security requirements and division of information security responsibilities between the customer and vendor .

omb agreed with our recommendations and subsequently published a strategy in february 2011 that addressed the importance of information security when using cloud computing , but it did not fully address several key challenges confronting agencies , such as the appropriate use of attestation standards for control assessments of cloud computing service providers , and division of information security - related responsibilities between customer and provider .

we also recommended that gsa consider security in its procurement for cloud services , including consideration of a shared assessment and authorization process .

gsa generally agreed with our recommendations and has since developed the fedramp program .

finally , we recommended that nist issue guidance specific to cloud computing security .

nist agreed with our recommendations and has since issued multiple publications that address such guidance .

in april 2012 , we reported that more needed to be done to implement omb's 25-point plan and measure its results .

among other things , we reported that , of the 10 key action items that we reviewed , 3 had been completed and 7 had been partially completed by december 2011 .

in particular , omb and agencies' cloud - related efforts only partially addressed requirements .

specifically , agencies' plans were missing key practices , such as a discussion of needed resources , a migration schedule , and plans for retiring legacy systems .

as a result , we recommended , among other things , that the secretaries of homeland security and veterans affairs , and the attorney general direct their respective cios to complete practices missing from the agencies' plans for migrating services to a cloud computing environment .

officials from each of the agencies generally agreed with our recommendations and have taken steps to implement them .

in july 2012 , we reported on the efforts of seven agencies to implement three services by june 2012 , including the challenges associated with doing so .

specifically , we reported that selected federal agencies had made progress in implementing omb's “cloud first” policy .

seven agencies had implemented 21 cloud computing solutions and had spent a total of $307 million for cloud computing in fiscal year 2012 , about 1 percent of their total it budgets .

while each of the seven agencies had submitted plans to omb for implementing their cloud services , a majority of the plans were missing required elements .

agencies also identified opportunities for future cloud service implementations , such as moving storage and help desk services to a cloud environment .

agencies also shared seven common challenges that they experienced in moving services to cloud computing .

we made recommendations to the agencies to develop planning information , such as estimated costs and legacy it systems' retirement plans , for existing and planned services .

the agencies generally agreed with our recommendations and have taken actions to implement them .

in september 2014 , we reported on the aforementioned seven agencies' efforts to implement additional cloud computing services , any reported cost savings as a result of implementing those cloud services , and challenges associated with the implementation .

all of the seven federal agencies we reviewed had added more cloud computing services ; the number of cloud services implemented by them had increased from 21 to 101 between fiscal years 2012 and 2014 .

in addition , agencies had collectively doubled the percentage of their it budgets from 1 to 2 percent during the fiscal year 2012 – 14 period .

further , the agencies reported a collective cost savings of about $96 million through fiscal year 2013 .

we made recommendations to the agencies to assess their it investments that had yet to be evaluated for suitability for cloud computing services .

for the most part , the agencies generally agreed with our recommendations and have taken actions to implement them .

based on our analysis of practices recommended by the ten organizations with expertise in the area of slas and omb , we compiled the following list of ten practices that are key for federal agencies to incorporate into a contract to help ensure services are performed effectively , efficiently , and securely for cloud computing services .

the key practices are organized by the following management areas — roles and responsibilities , performance measures , security , and consequences .

roles and responsibilities: ( 1 ) define the roles and responsibilities of the major stakeholders involved in the performance of the sla and cloud contract .

these definitions would include , for example , the persons responsible for oversight of the contract , audit , performance management , maintenance , and security .

 ( 2 ) define key terms , including activation date , performance , and identify any ambiguities in the definitions of cloud computing terms in order to provide the agency with the level of service they can expect from their cloud provider .

without clearly defined roles , responsibilities , and terms , the agency may not be able to appropriately measure the cloud provider's performance .

performance measures: ( 1 ) define the performance measures of the cloud service , including who is responsible for measuring performance .

these measures would include , among other things , the availability of the cloud service ; the number of users that can access the cloud at any given time ; and the response time for processing a customer transaction .

providing performance parameters provides both the agency and service provider with a well - defined set of instructions to be followed .

 ( 2 ) specify how and when the agency would have access to its data , including how data and networks will be managed and maintained throughout the life cycle of the service .

provide any data limitations , such as who may or may not have access to the data and if there are any geographic limitations .

 ( 3 ) specify management requirements , for example , how the cloud service provider would monitor the performance of the cloud , report incidents , and how and when they would plan to resolve them .

in addition , identify how and when the agency would conduct an audit to monitor the performance of the service provider , including access to the provider's performance logs and reports .

 ( 4 ) provide for disaster recovery and continuity of operations planning and testing .

this includes , among other things , performing a risk management assessment ; how the cloud service would be managed by the provider in the case of a disaster ; how data would be recovered ; and what remedies would apply during a service failure .

 ( 5 ) describe applicable exception criteria for when the cloud provider's service performance measures do not apply , such as during scheduled cloud maintenance or when updates occur .

without any type of performance measures in place , agencies would not be able to determine whether the cloud services under contract are meeting expectations .

security: ( 1 ) specify the security performance requirements that the service provider is to meet .

this would include describing security performance metrics for protecting data , such as data reliability , data preservation , and data privacy .

cleary define the access rights of the cloud service provider and the agency as well as their respective responsibilities for securing the data , applications , and processes to meet all federal requirements .

 ( 2 ) describe what would constitute a breach of security and how and when the service provider is to notify the agency when the requirements are not being met .

without these safeguards , computer systems and networks as well as the critical operations and key infrastructures they support may be lost , and information — including sensitive personal information — may be compromised , and the agency's operations could be disrupted .

consequences: specify a range of enforceable consequences , including the terms under which a range of penalties and remedies would apply for non - compliance with the sla performance measures .

identify how such enforcement mechanisms would be imposed or exercised by the agency .

without penalties and remedies , the agency may lack leverage to enforce compliance with contract terms when situations arise .

guidance issued in february 2012 , at the direction of omb highlighted slas as being a key factor for ensuring the success of cloud - based services and advised that federal agencies should include an sla or a reference within the contract when creating a cloud computing contract .

the guidance provides areas of an sla to be addressed ; for example , it states that an sla should define performance with clear terms and definitions , demonstrate how performance is being measured , and identify what enforcement mechanisms are in place to ensure the conditions are being met .

however , the guidance addressed only seven of the ten key practices listed in table 1 that could help agencies better track performance and thus ensure the effectiveness of their cloud services .

specifically , the guidance did not specify how and when the agency would have access to its data , provide for disaster recovery and continuity of operations planning , and describe any exception criteria .

omb staff members said that , although the guidance drafted by the chief information officers council and the chief acquisition officers council was a good start , including all ten key practices should be considered .

without complete guidance from omb , there is limited assurance that agencies will apply all the key sla practices into their cloud computing contracts , and therefore may be unable to hold contractors accountable when performance falls short of their goals .

many of the 21 cloud service contracts we reviewed at the five selected agencies incorporated a majority of the key practices , but the number of practices differed among contracts .

specifically , seven of the cloud service contracts reviewed met all 10 of the key practices .

this included three from dhs , three from treasury , and one from va .

the following figure shows the total cloud service contracts reviewed and the number that met the 10 key practices at the five selected agencies .

of the remaining 14 cloud service contracts , 13 incorporated five or more of the key practices , and 1 did not meet any of the key practices .

figure 3 shows each of the cloud service contracts we reviewed and the extent to which the agency had included key practices in its sla contracts .

appendix ii includes our analysis of all the cloud services we reviewed , by agency .

a primary reason that the agencies did not include all of the practices was that they lacked guidance that addresses these sla practices .

of the five agencies , only dod had developed cloud service contracting guidance that addressed some of the practices .

more specifically , dod's guidance only addressed three of the key practices: disaster recovery and continuity of operations planning , metrics on security performance requirements , and notifying the agency when there is a security breach .

in addition , the guidance partially addressed the practice on access to agency data , specifically , with regard to transitioning data back to the agency in case of exit / termination of service .

agency officials responsible for the cloud services that did not meet or only partially met key practices provided the following additional reasons for not including all ten practices: officials from dod's office of the chief information officer told us that the reason key practices were not always fully addressed is that , when the contracts and associated slas were developed , they did not have the aforementioned dod guidance on cloud service acquisition and use — namely , the agency's memorandum on acquiring cloud services that was released in december 2014 , and the current defense federal acquisition regulation supplement , which was finalized in august 2015 .

however , as previously stated , this updated guidance addressed three of the ten key practices , and part of one other .

officials from dhs's office of the chief information officer stated that the infrastructure as a service cloud service addressed the partially met and not met key practices but did not provide supporting documentation to show that the practices were in place .

if key practices have not been incorporated , the system may have decreased performance and the cloud service may not meet its intended goals .

hhs officials from the national institutes of health attributed unmet or partially met practices for four cloud services — remedy force , medidata , the biomedical imaging and bioengineering website , and the drug abuse public website — to the fact that they evaluate the cloud vendor's ability to meet defined agency needs , rather than negotiate with vendors on sla requirements .

while this may explain their shortfalls in not addressing all sla key practices , the agency may be placing their systems at risk of not conducting adequate service level measurements , which may result in decreased service levels .

hhs officials from the administration of children and families stated that the reason key practices were partially addressed or not addressed for the grant solutions cloud service was that these practices were being managed by hhs personnel using other tools and plans , rather than via the sla established for this service .

for example , according to the officials , they are using a management information system to monitor performance of the cloud provider .

in addition , with respect to disaster management , the officials said that they have their own disaster recovery plan .

nonetheless , leading studies show that these practices should still be incorporated as part of the cloud service contract to ensure agencies have the proper control over their cloud services .

treasury officials said the reason , among other things , the slas for treasury web services and irs portal environment only partially met certain key practices was because the practices were being provided by support contractors hired by the cloud service provider , and were not directly subject to the slas established between treasury and the cloud service provider .

nonetheless , while having contractors perform practices is an acceptable approach , treasury officials were unable to provide supporting documentation to show that support contractors were assisting with the practices in question .

officials from va's office of information and technology said the reason the key practice associated with penalties and remedies was not included in the terremark sla was because penalties were addressed within other parts of the contract ; however , officials were not able to provide documentation identifying such penalties .

with regard to an sla for ekidney , officials told us they had not addressed any of the key practices due to the fact that an sla was not developed between the agency and cloud service provider .

without including an sla in cloud service contracts , the agency runs the risk of not having the mechanisms in place to effectively evaluate or control contractor performance .

until these agencies develop sla guidance and incorporate all key practices into their cloud computing contracts , they may be limited in their ability to measure the performance of the services , and , therefore , may not receive the services they require .

although omb has provided agencies guidance to better manage contracts for cloud computing services , this guidance does not include all the key practices that we identified as necessary for effective slas .

similarly , defense , homeland security , health and human services , treasury , and veterans affairs have incorporated many of the key practices in the cloud service contracts they have entered into .

overall , this is a good start towards ensuring that agencies have mechanisms in place to manage the contracts governing their cloud services .

however , given the importance of slas to the management of these million - dollar service contracts , agencies can better protect their interests by incorporating the pertinent key practices into their contracts in order to ensure the delivery and effective implementation of services they contract for .

in addition , agencies can improve management and control over their cloud service providers by implementing all recommended and applicable sla key practices .

to ensure that agencies are provided with more complete guidance for contracts for cloud computing services , we recommend that the director of omb include all ten key practices in future guidance to agencies .

to help ensure continued progress in the implementation of effective cloud computing slas , we recommend that the secretary of defense direct the appropriate officials to ensure key practices are fully incorporated for cloud services as the contracts and associated slas expire .

these efforts should include updating the dod memorandum on acquiring cloud services and current defense acquisition regulations system to more completely include the key practices .

to help ensure continued progress in the implementation of effective cloud computing slas , we recommend that the secretaries of health and human services , homeland security , treasury , and veterans affairs direct appropriate officials to develop sla guidance and ensure key practices are fully incorporated as the contract and associated slas expire .

in commenting on a draft of this report , four of the agencies — dod , dhs , hhs , and va — agreed with our recommendations ; and omb and one agency ( treasury ) had no comments .

the specific comments from each agency are as follows: in an e - mail received on march 25 , 2016 , omb staff from the office of e - government and information technology stated that the agency had no comments at this time .

in written comments , the department of defense concurred with our recommendation and described actions it plans to take to address the recommendation .

specifically , dod stated that it will update its cloud computing guidance and contracting guidance as appropriate .

the department of defense's comments are reprinted in appendix iii .

in written comments , the department of homeland security concurred with our recommendation and described actions it plans to take to address the recommendation .

specifically , the department will establish common cloud computing service level agreement guidance .

dhs also provided technical comments , which we have incorporated in the report as appropriate .

the department of homeland security's comments are provided in appendix iv .

in written comments , the department of health and human services concurred with our recommendation , but noted that it was not directed by a federal mandate .

we acknowledge that our recommendation is not directed by a mandate ; however , implementing leading practices for cloud computing can result in significant benefits .

the department also provided technical comments , which we have incorporated in the report as appropriate .

the department of health and human service's comments are provided in appendix v. in an e - mail received on march 18 , 2016 , an audit liaison from the department of the treasury's office of the cio stated that the department had no comment .

in written comments , the department of veterans affairs concurred with our recommendation and described planned actions to address it .

for example , the department will develop service level agreement guidance to include the 10 key practices .

the department of veterans affairs comments are provided in appendix vi .

we are sending copies of this report to interested congressional committees ; the secretaries of defense , health and human services , homeland security , the treasury , and veterans affairs ; and the director of the office of management and budget , and other interested parties .

this report will also be available at no charge on our website at http: / / www.gao.gov .

if you or your staffs have any questions on matters discussed in this report , please contact me at ( 202 ) 512-9286 or pownerd@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix vii .

our objectives were to ( 1 ) identify key practices used in cloud computing service level agreements ( sla ) to ensure service is performed at specified levels and ( 2 ) determine the extent to which federal agencies have incorporated such practices into their cloud computing service level agreements .

to identify key practices used in cloud computing service level agreements , we analyzed sla research , studies , and guidance developed and used by federal agencies and private entities .

we then performed a comparative analysis of the practices to identify the practices that were recommended by at least two sources .

specifically , we analyzed information from publications and related documentation issued by the following ten public and private organizations to determine key sla practices: federal chief information officer council chief acquisitions officers council national institute of standards and technology european commission directorate general for communications networks , content and technology office of management and budget gartner mitre corporation cloud standards customer council international organization for standardization international electrotechnical commission next , we organized these practices into management areas and validated our analysis through interviews with experts from these organizations .

we also had officials from the office of management and budget ( omb ) review and validate that these practices are the ones the office expects federal agencies to follow .

in cases where experts disagreed , we analyzed their responses , including the reasons they disagreed , and made changes as appropriate .

these actions resulted in our list of key practices for cloud service slas .

to determine the extent to which federal agencies have incorporated key practices into their cloud computing contracts , we selected five agencies to review based , in part , on those with the largest fiscal year 2015 it budgets and planned spending on cloud computing services .

the agencies selected were the departments of defense ( dod ) , homeland security ( dhs ) , health and human services ( hhs ) , treasury , and veterans affairs ( va ) .

we selected these agencies based on the following two factors .

first , they have the largest planned it budgets for fiscal year 2015 .

their budgets , which collectively totaled $57 billion , represent about 72 percent of the total federal it budget ( $78 billion ) .

second , these agencies plan to spend relatively large amounts on cloud computing .

specifically , based on our analysis of omb's fiscal year 2015 budget data , each of the five departments were in the top 10 for the largest amount budgeted for cloud computing and collectively planned to spend $1.2 billion on cloud computing , which represents about 57 percent of the total amount that federal agencies plan to invest in cloud computing ( $2.1 billion ) .

to select and review the cloud services used by the agencies , we obtained an inventory of cloud services for each of the five agencies , and then , for each agency , we listed their cloud services in a random fashion and selected the first two cloud services in the list for each of the three major cloud service models ( infrastructure , platform , and software ) .

in certain cases , the agency did not have two cloud services for a service model , so the number chosen for that service model was less than two .

this resulted in a non - generalizable sample of 23 cloud services .

however , near the end of our engagement , agencies identified 2 of the services as being in a pilot stage ( one from dhs , and one from hhs ) , and thus not operational .

we excluded these services from our analysis , as our methodology to only assess operational cloud services .

due to the stage of the engagement , we were unable to select additional services for review .

further , because no computer - generated data was used we determined that there were no data reliability issues .

for each of the selected services , we compared its cloud service contract ( if one existed ) and any associated sla documentation to our list of key practices to determine if there were variances and , if so , their cause and impact .

to do so , two team analysts independently reviewed the cloud service contracts against the key practices using the following criteria: met: all aspects of the key practices were fully addressed .

partially met: some key practices were addressed .

did not meet: no key practices were addressed .

in cases where analysts differed on the assessments , we discussed what the rating should be until we reached a consensus .

we also interviewed agency officials to corroborate our analysis and identify the causes and impacts of any variances .

we conducted this performance audit from january 2015 to april 2016 in accordance to generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the following tables show each of the five agencies' — dod , dhs , hhs , treasury , and va — cloud services we assessed and our analysis of each contract for cloud services against the key practices .

in cases where the sla partially met a practice , the analysis also includes discussion of the rationale for why that assessment was provided .

with regard to those services that partially met key practices: the integrated risk information system partially addressed one key practice on how and when the agency was to have access to its data and networks .

it included how the data would be transitioned , but did not specify how access to data and networks was to be managed or maintained .

the case tracking cloud service partially included the practice on specifying metrics for security performance requirements .

it specified how security needs were to be met but did not give specific metrics for doing so .

email as a service partially addressed two key practices .

for the practice on specifying service management requirements , it specified how the cloud service provider was to monitor performance , but did not address how the provider was to report performance or how the agency was to confirm the performance .

for the other practice on specifying metrics for security performance requirements , it included how security needs were to be met but did not specify the security metrics .

the web portal partially incorporated two key practices .

for the practice on how and when the agency was to have access to its data and networks , it specified how the data was to be transitioned , but not how access to data and networks was to be managed or maintained .

for the other practice on specifying metrics for security performance requirements , it included monitoring of the contractor regarding security , but did not specify security metrics .

infrastructure as a service partially incorporated two key practices .

for the practice on how and when the agency was to have access to its data and networks , it specified how and when the agency was to have access to its data and networks , but did not provide how data and networks was to be transitioned back to the agency in case of an exit .

for the other practice on service management requirements , it described how the cloud service is to monitor performance , but did not specify how and when the agency was to confirm audits of the service provider's performance .

with regard to those services that partially met key practices , national institute of health's remedy force partially addressed one key practice on defining measurable performance objectives .

it included various performance objectives , such as levels of service and availability of the cloud service , capacity and capability , and measures for response time , but it did not include which party was to be responsible for measuring performance .

the national institute of health's medidata rave partially incorporated two key practices .

it defined measurable performance objectives , specifically it specified levels of service , capacity and capability of the service , and response time , but did not specify the period of time that it was to be measured .

for the other practice on specifying a range of enforceable consequences , it specified remedies , but did not identify any penalties related to non - compliance with performance measures .

the national institute on drug abuse public website partially addressed two key practices .

for the practice on specifying how and when the agency is to have access to its data and networks , it specified how and when the agency was to have access to its data and networks , but did not identify how data and networks were to be managed throughout duration of the sla .

for the other practice on specifying a range of enforceable consequences , it included a number of remedies , but did not specify a range of enforceable penalties .

hhs's grant solutions partially incorporated one key practice on specifying service management requirements .

it provided for when and how the agency was to confirm cloud provider performance , but did not specify how the cloud service provider was to monitor performance and report results .

with regard to those services that partially met key practices , treasury's internal revenue service's portal environment partially included one key practice on specifying how and when the agency was to have access to its data and networks .

it specified how and when the agency was to have access to its data and networks , but it did not provide on how data and networks were to be transitioned back to the agency in case of an exit .

the treasury's web solutions partially addressed two key practices .

for the practice on specifying how and when the agency was to have access to its data and networks , it specified how and when the agency was to have access to its data and networks , but it did not provide how data and networks would be transitioned back to the agency in case of an exit .

for the other practice on specifying a range of enforceable consequences , it did not provide detailed information on a range of enforceable penalties and remedies for non - compliance with sla performance measures .

in addition to the contact name above , individuals making contributions to this report included gary mountjoy ( assistant director ) , gerard aflague , scott borre , nancy glover , lori martinez , tarunkant mithani , karl seifert , and andrew stavisky .

