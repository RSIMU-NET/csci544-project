clinical lab tests are one of the most frequently billed medicare procedures and , according to the american clinical laboratory association , affect an estimated 70 percent of medical decisions .

to improve oversight of clinical labs , congress passed legislation in 1967 ; renewed concerns about quality , including errors in pap smear tests used to diagnose cervical cancer , resulted in enactment of the clinical laboratory improvement amendments of 1988 ( clia ) .

in recent years , despite clia , lab quality problems in several states have raised questions about the adequacy of lab oversight .

lab oversight is critical because inaccurate or unreliable lab tests may lead to improper treatment , unnecessary mental and physical anguish for patients , and higher health care costs .

the centers for medicare & medicaid services ( cms ) is responsible for overseeing compliance with clia requirements .

as of december 2005 , there were approximately 193,000 labs nationwide , ranging from very small physician office labs that conduct fewer than 2,000 tests annually to hospital labs that conduct millions of tests each year .

most clinical labs regulated under clia must obtain a certificate from cms but only about 19 percent — those that conduct moderate - to high - complexity tests — undergo biennial inspections , which are also referred to as surveys .

the surveys assess lab compliance with mandated personnel and testing standards .

in addition , surveyed labs must participate in proficiency testing , a program that requires them to test samples with unknown characteristics that are then graded by an external party .

labs with serious deficiencies may be sanctioned , eg , required to cease testing .

labs have a choice of being surveyed by ( 1 ) their state survey agency , under contract with cms ; ( 2 ) their state clia - exempt program for labs in new york and washington ; or ( 3 ) one of six private accrediting organizations .

state survey agency inspections use clia requirements that are intended to help ensure valid and reliable lab tests ; the two state clia - exempt programs and six accrediting organizations survey labs using their own requirements that cms has determined to be at least equivalent to clia's .

each survey organization is also responsible for investigating complaints about lab quality .

because of the critical importance of accurate lab test results and oversight , you asked us to conduct a nationwide assessment of ( 1 ) the quality of lab testing ; ( 2 ) the effectiveness of surveys , complaint investigations , and enforcement actions in detecting problems and ensuring compliance ; and ( 3 ) the adequacy of cms oversight of the clia program .

to determine what is known about the quality of lab testing , we analyzed data on serious deficiencies identified during surveys by state survey agencies using cms's on - line survey , certification , and reporting system ( oscar ) .

the clia program inspection requirements are classified as either “standard - ” or “condition - ” level .

similarly , deficiencies are also characterized as standard - or condition - level , based on the requirement in which the deficiency occurs .

because condition - level requirements generally consist of one or more standard - level requirements , a deficiency at the condition - level denotes a serious or systematic problem .

we requested comparable data on serious deficiencies from state clia - exempt programs and the three largest accrediting organizations — the college of american pathologists ( cap ) , cola , and the joint commission on accreditation of healthcare organizations ( jcaho ) — which together survey about 97 percent of accredited labs .

cap , cola , jcaho , and exempt - state programs each maintain their own separate databases .

we also analyzed proficiency testing data — another indicator of a lab's ability to produce accurate test results .

cms officials generally recognize oscar and proficiency testing data to be reliable .

we discussed the oscar database with cms officials and tailored our analysis to ensure the accuracy of our findings .

because exempt states and accrediting organizations survey labs using their own requirements , we worked with them to develop data comparable to oscar deficiency data .

we discussed our analyses with cms and each of the survey organizations to ensure that we had interpreted the data correctly .

based on discussions with officials from the three accrediting organizations , we determined that they take appropriate steps to ensure the reliability of their data .

because it was not practical to independently test the reliability of accrediting organization data , we present these data as reported by those organizations .

to assess the effectiveness of lab surveys , complaint investigations , and enforcement mechanisms in detecting problems and securing compliance , we reviewed the processes used to ensure the quality of clinical lab testing and analyzed available data related to these issues .

we also conducted structured interviews with officials from ( 1 ) cms , ( 2 ) three cms regional offices , ( 3 ) 10 state survey agencies , ( 4 ) the new york and washington clia - exempt programs , and ( 5 ) the three accrediting organizations .

we judgmentally selected the 10 state survey agencies to include a mixture of states whose lab inspections identified a range of serious deficiencies from few to many .

we also discussed the quality problems discovered at a maryland hospital lab with a maryland state survey agency official and interviewed 9 of the 36 cap surveyors who participated in surveys of this lab from 1999 through 2003 to obtain a firsthand perspective on the cap survey process .

based on our review and discussions with cms and survey organization officials , we focused on several key issues , including the rationale for announced surveys , the ability of lab surveys to identify serious deficiencies , the balance struck between the regulatory and educational goals of lab surveys , the implications of cap's use of volunteer surveyors from neighboring labs to conduct inspections , how survey organizations facilitate the filing of complaints , and the use of sanctions to encourage compliance .

we analyzed data on the number of complaints received by each survey organization from 2002 through 2004 and discussed cap's initiatives to encourage the filing of complaints .

in addition , we determined the extent to which labs had the same serious problems on consecutive surveys and discussed with cms the steps the agency had taken to deter an inconsistent pattern of compliance .

to assess the effectiveness of cms oversight of the clia program , we analyzed the laws and regulations that define cms's role and authority .

we also reviewed cms's process for determining that the survey requirements and procedures of state clia - exempt programs and accrediting organizations are at least equivalent to those of clia .

we analyzed the results of validation reviews that federal surveyors from cms regional offices conducted for state survey agency lab inspections and that state survey agency staff conducted for accrediting organization inspections from 1999 through 2003 .

we also examined other mechanisms that cms uses to hold survey organizations accountable for their performance: ( 1 ) the collection and analysis of data on surveys , complaints , and enforcement actions , including steps taken to address communication and coordination issues that became evident during a complaint investigation at a maryland hospital lab ; and ( 2 ) recently developed annual reviews that measure state survey agency compliance with clia program requirements , such as the timeliness of surveys .

we conducted our work from january 2005 through may 2006 in accordance with generally accepted government auditing standards .

a clinical lab is generally defined as a facility that examines specimens derived from humans for the purpose of disease diagnosis , prevention , and treatment , or health assessment of individuals .

while hospital and interstate labs were previously subject to regulation , clia strengthened federal requirements and extended them to most other clinical labs , including physician office labs .

for example , clia strengthened personnel requirements for lab workers , strengthened proficiency testing that evaluates the accuracy of lab testing between surveys , and created a range of sanctions to enforce compliance .

most clinical labs regulated under clia must obtain a certificate from cms and pay fees every 2 years to cover the costs of administering the clia program , including surveys and other oversight activities .

the fees vary based on the complexity and volume of testing performed .

lab tests are categorized as waived , moderate , or high complexity .

approximately 81 percent of all labs ( about 157,000 ) are not subject to routine biennial surveys because they perform ( 1 ) “waived” tests , which are examinations and procedures that have an insignificant risk of erroneous results , including those approved for home use or determined to employ methodologies so simple or accurate that the likelihood of erroneous results is negligible ; or ( 2 ) tests performed during the course of a patient visit with a microscope on specimens that are not easily transportable .

clia establishes more stringent requirements for the 19 percent ( about 36,000 ) of labs performing moderate - or high - complexity testing , including the requirement for a survey and participation in routine proficiency testing .

since the early 1990s , the number and proportion of labs subject to surveys have declined , while the number and proportion conducting waived tests have increased .

surveys examine lab compliance with clia program requirements in several areas including: personnel qualifications , proficiency testing , quality control , quality assurance , and recordkeeping .

personnel: clia sets minimum qualifications for all persons performing or supervising moderate - or high - complexity lab tests and specifies responsibilities for each position .

proficiency testing: surveyed labs must participate in an approved external proficiency testing program , which evaluates the accuracy of laboratory testing .

under this requirement , labs purchase samples with unknown characteristics several times each year from an approved proficiency testing provider .

the lab is required to test the samples with its routine patient testing , and the results are returned to the testing provider to be graded .

a proficiency testing failure is defined as unsatisfactory performance on two consecutive or two out of three testing events .

the results of proficiency testing for all inspected labs are transmitted to cms and maintained in a database .

quality control: labs must have a process for routinely monitoring personnel , testing equipment , and the testing environment to ensure proper operation and accurate results .

quality assurance: labs must follow their plan to monitor the overall operation of the laboratory on an ongoing basis and must resolve identified problems that affect the quality of their testing .

recordkeeping: labs must maintain an audit trail of testing that documents specimen integrity and test performance for all phases of the test process from the test order to the test report .

in general , labs have a choice of who conducts their surveys — state survey agencies using clia inspection requirements or other survey organizations that use requirements cms has determined to be at least equivalent to clia's .

cms contracts with state survey agencies in most states to inspect labs against clia requirements .

clia established an approval process to allow states and private accrediting organizations to use their own requirements to survey labs .

as noted earlier , new york and washington operate clia - exempt programs and cms has approved six private , nonprofit accrediting organizations to survey labs — the american association of blood banks ( aabb ) , the american osteopathic association ( aoa ) , the american society of histocompatibility and immunogenetics ( ashi ) , cap , cola , and jcaho .

the requirements of both state clia - exempt programs and accrediting organizations must be reviewed by cms at least every 6 years to ensure clia equivalency , but may be more stringent than those of clia .

for example , when inspecting labs engaged in moderate - and high - complexity testing , new york and some accrediting organizations also look at the labs' procedures for conducting “waived” tests , which is not required under clia .

figure 1 lists the three types of survey organizations and indicates whether they survey labs under clia requirements , or use their own clia - equivalent requirements .

it also shows the percentage of labs performing moderate - to high - complexity testing surveyed by each type of organization .

in general , state survey agencies , cola , and washington's clia - exempt program survey physician office labs , while new york's clia - exempt program , cap , and jcaho survey hospital labs .

survey organizations ( 1 ) conduct surveys and complaint investigations , and ( 2 ) monitor proficiency test results submitted by surveyed labs three times a year .

surveys are typically conducted by former or current lab workers , who assess lab compliance with clia or clia - equivalent requirements .

most lab inspections are announced , that is , the lab has advance notice of when the survey will occur .

generally , surveyors verify that lab personnel are appropriately qualified to conduct testing , evaluate proficiency test records , check equipment and calibration to ensure that appropriate quality control measures are in place , and determine whether the lab has a quality assurance plan and uses it to , among other things , appropriately identify and resolve problems affecting testing quality .

surveys also include an educational component to assist labs in understanding how to comply with clia requirements .

the duration of a survey generally depends on the size — in terms of the number of tests conducted — and complexity of a lab as well as the number of surveyors .

thus , a survey conducted at a small lab may only take a few hours to complete , while a survey at a large hospital lab may take a survey team a full week or more .

in addition to inspections , survey organizations are responsible for determining the seriousness of and investigating all complaints .

for those complaints that are determined to pose immediate jeopardy — an imminent and serious threat to patient health and a significant hazard to public health — cms requires that the investigation be initiated within 2 working days .

complaints may be investigated on - site or through communications between the survey organization and the lab .

complaint investigations for all survey organizations are unannounced .

lab survey requirements are classified as either “standard - ” or “condition - ” level .

generally , condition - level requirements are made up of one or more related standard - level requirements .

for example , the condition - level requirement on enrollment and testing of samples through a proficiency testing program has two related standard - level requirements: ( 1 ) enrollment , which includes requirements for the lab to provide the name of the program it has enrolled in to the department of health and human services and authorize the release of testing data to the department ; and ( 2 ) testing , which specifies that the samples must be tested in the same manner as any specimen and prohibits referring the test samples to another lab for analysis .

deficiencies are also characterized as standard - or condition - level based on the requirement in which the deficiency occurs .

deficiencies in standard - level requirements , that is , standard - level deficiencies , denote problems that generally are not serious , while condition - level deficiencies are cited when the problems are serious or systemic in nature .

a serious problem is defined as an inadequacy in a lab's quality of services that adversely affects , or has the potential to adversely affect , the accuracy and reliability of patient test results .

when deficiencies are found during surveys or complaint investigations , labs are required to submit a plan of correction , detailing how and when they will address the deficiencies .

additionally , cms can impose principal or alternative sanctions , or both .

principal sanctions include revocation of a clia certificate , cancellation of the right to receive medicare payments , or limits on testing .

revocation of a clia certificate is equivalent to termination from the clia program .

alternative sanctions are less severe and include civil money penalties or on - site monitoring .

for condition - level deficiencies that do not involve immediate jeopardy , labs have an opportunity to correct the deficiencies , which we refer to as a grace period , before the sanctions are imposed .

if a lab is unable to correct a deficiency during this grace period , cms determines whether to impose a sanction and the type of sanction .

cms , including its 10 regional offices , oversees state and accrediting organization survey activities .

cms reviews and approves initial and subsequent applications from exempt - state programs and accrediting organizations to ensure clia equivalency .

validation reviews are one of cms's primary oversight tools .

federal surveyors in cms regional offices are responsible for conducting validation reviews of state survey agency and exempt - state program inspections , but state survey agency staff conduct the validation reviews of accrediting organization inspections .

an objective of these reviews is to determine if all condition - level deficiencies were identified .

these reviews are conducted within 60 days of a state's or 90 days of an accrediting organization's survey of a lab .

starting in 1999 , cms required that at least one validation review be conducted simultaneously with an accrediting organization's survey , a step intended to encourage an exchange of ideas and approaches among surveyors .

cms also encourages the use of simultaneous reviews of state survey agency inspections .

by law , the number of labs selected for validation reviews must be sufficient to allow a reasonable estimate of the performance of each accrediting organization being assessed .

cms requires fewer validation reviews of state survey agency lab surveys ( 1 percent ) than for those of exempt - state programs or accrediting organizations ( 5 percent ) .

beginning in 2003 , cms regional offices began reviewing the activities of state survey agencies against a set of 13 performance standards .

the standards cover areas such as the timeliness of lab inspections , surveyor personnel qualifications and training , clia data management , and the handling of complaints .

cms's goal is to evaluate each state survey agency's ability to carry out its clia responsibilities and to make improvements .

cms is also developing performance standards for other survey organizations that inspect labs using their own clia equivalent requirements .

the extent of serious quality problems at labs is unclear because cms has incomplete data on condition - level deficiencies identified by state survey agencies prior to 2004 .

we also found that the lack of a straightforward linkage between clia requirements and the clia - equivalent requirements of some survey organizations makes it virtually impossible to assess lab quality in a standardized manner , such as identifying the proportion of labs with condition - level deficiencies .

such deficiencies indicate serious or systemic quality problems .

proficiency testing results — the one available data source that can be used to uniformly compare lab quality across survey organizations — raise questions about whether lab quality has improved in recent years .

cms's oscar database contains limited data on the quality of labs inspected by state survey agencies and , as a result , it is not possible to analyze changes in the quality of lab testing over time .

in january 2004 , cms implemented revised clia survey requirements and modified the existing oscar data — state survey agency findings — to reflect the changes .

the revisions affected approximately two - thirds of the clia condition - level requirements .

as a result of the data modifications , the findings for surveys conducted prior to 2004 no longer reflect all key condition - level requirements in effect at the time of those surveys .

based on the available 2004 oscar data ( which represent about one half of all labs surveyed by state survey agencies ) , we found that 6.3 percent of labs had condition - level deficiencies ( see app .

ii for data on all state survey agencies , including the district of columbia ) .

as will be discussed below , similar data are not available for labs surveyed by other survey organizations .

differences between the inspection requirements that state survey agencies use to measure lab quality and those of exempt - state programs and accrediting organizations make it virtually impossible to measure lab quality in a standardized manner .

because exempt - state programs and accrediting organizations do not classify inspection requirements and related deficiencies as either standard - or condition - level , they cannot easily identify the number of clia condition - level deficiencies cited at the labs they survey or the proportion of surveyed labs with condition - level deficiencies .

we asked exempt - state programs and accrediting organizations what percentage of their requirements , and any deficiencies cited for failure to meet those requirements , indicated serious problems that were equivalent to clia condition - level deficiencies .

while only 8 percent of clia requirements used by state survey agencies are classified as condition - level and therefore serious , the proportion of requirements that exempt - state programs and accrediting organizations classify as serious ranged from 20 percent up to 100 percent ( see table 1 ) .

cap and cola crosswalked their recent survey findings to clia condition - level requirements .

although their analysis suggested that from about 56 to 68 percent of labs surveyed during 2004 had a deficiency in at least one condition - level requirement , they acknowledged that these proportions overstated the subset of labs with serious problems .

jcaho did not crosswalk its inspection requirements to those of clia because staff would have had to manually review each survey report to determine which deficiencies were equivalent to deficiencies in clia condition - level requirements .

however , jcaho did tell us that in 2004 , about 90 percent of the labs it surveyed had a deficiency in at least one requirement and , as previously noted , jcaho classifies all its requirements as serious .

despite the difficulty of identifying clia equivalent condition - level deficiencies , two of the three accrediting organizations we reviewed have systems to identify labs they survey that have serious quality problems .

cola estimated that about 9 percent of labs it surveyed in 2004 were subject to closer scrutiny because of the seriousness of the problems identified .

according to jcaho , about 5 percent of the labs it surveyed in 2004 were not in compliance with a significant number of requirements .

the third accrediting organization , cap , has criteria for identifying labs that warrant greater scrutiny , but cap officials told us that identifying such labs had to be accomplished on a case - by - case basis rather than through a database inquiry .

as a result , cap plans to spend in excess of $9 million during 2006 and 2007 to develop an integrated data system that pulls together multiple factors — survey results , complaints , proficiency testing , findings of other inspection bodies , and changes in lab directors — to enable it to readily identify problem labs .

according to cap officials , such labs will be targeted for greater monitoring , and cms and other survey organizations will be notified about cap's actions .

although cms noted that proficiency testing trend data show a decrease in failures for labs as a whole , the data suggest that lab quality may not have improved at hospital labs for the period 1999 through 2003 .

proficiency testing is an important oversight tool for survey organizations because it is an objective indicator of a lab's ability to consistently produce accurate test results and is conducted more frequently than surveys — three times a year versus once every 2 years .

in the absence of comparable survey data , proficiency testing results provide a uniform way to assess the quality of lab testing across survey organizations .

our analysis of cms proficiency testing data for 1999 through 2003 suggests that there has been an increase in proficiency testing failures for labs inspected by cap and jcaho , which generally inspect hospital labs , and a decrease in such failures for labs surveyed by state survey agencies and cola , which tend to inspect physician office labs ( see fig .

2 ) .

cms defines failures as unsatisfactory performance in two consecutive or two out of three proficiency testing events .

for example , the percentage of labs with proficiency testing failures surveyed by cap and jcaho from 1999 through 2003 increased from 4.1 percent to 6.8 percent and from 6.6 percent to 7.8 percent , respectively .

it is unclear , however , whether the decrease in failures for physician office labs represents an actual improvement in lab quality or reflects the fact that some problematic labs are no longer surveyed .

specifically , many physician office labs now perform waived tests and therefore are no longer surveyed or participate in proficiency testing .

between 1998 and 2005 , the percentage of labs subject to surveys and proficiency testing decreased from about 30 percent to about 19 percent .

weaknesses in surveys , complaint processes , and enforcement mask real and potential quality problems at labs .

survey weaknesses include: ( 1 ) inspections that most organizations announce ahead of the visit , which allows labs to prepare for their inspections and portray themselves in a manner that may not accurately reflect their day - to - day quality assurance processes ; ( 2 ) variability in the proportion of labs with condition - level deficiencies in 2004 , which suggests surveys are not conducted in a consistent manner ; and ( 3 ) the goal of educating lab workers during surveys taking precedence over , or precluding , the identification and reporting of deficiencies .

furthermore , the significant increase in complaints since cap took steps to help ensure that lab workers know how to file a compliant suggests that some quality problems at labs inspected by other survey organizations may not be reported .

finally , sanctions are not being used effectively as an enforcement tool to promote labs' compliance with clia requirements , as evidenced by the relatively few labs with repeat condition - level deficiencies on consecutive surveys from 1998 through 2004 that had sanctions imposed .

because labs can and do prepare for surveys , cms regional office officials and most of the state survey agencies acknowledged that announced surveys may not always provide a realistic picture of lab quality .

as shown in table 2 , the amount of advance notice for surveys varies from as little as 2 weeks up to 12 weeks ; until recently , only the new york clia - exempt program conducted unannounced surveys .

survey agency officials in two states told us that surveyors had inspected labs where records documenting the implementation of periodic quality control procedures were completed in the same handwriting using the same colored pen .

this degree of uniformity raises a concern about whether the quality control occurred at all , or as frequently as the records suggested .

a cap surveyor told us that the pathologist at one lab had cleaned up , and signed off on , about 3-months worth of quality control records the night before the survey .

in hearings on the questionable test results at a maryland hospital lab , a worker testified that lab staff prepared frantically for their announced inspections .

in 2006 , both cap and jcaho began conducting unannounced inspections at most of the hospital labs they survey .

both cap and jcaho officials told us that the unannounced surveys will occur as early as 6 months prior to the anniversary of a lab's prior survey .

cms and survey organizations that inspect physician office labs provided several justifications for continuing to announce inspections at such labs , including ( 1 ) ensuring that the lab is open and that appropriate personnel are available to answer surveyor's questions , and ( 2 ) minimizing disruptions to patient care .

these justifications appear to be reasonable because they reflect the operating tempo at physician office labs .

it may not be appropriate , however , to provide such labs with 4 to 12 weeks advance notice , given that cms currently limits the advance notice provided by state survey agencies to no more than 2 weeks .

variability in oscar data for state survey agency inspections conducted in 2004 suggests that labs are not surveyed in a consistent manner , and interviews with cms and state survey agency officials confirmed this hypothesis .

as a result , available data likely understate the extent of serious quality problems at labs .

in 2004 , the percentage of labs that state survey agencies reported with condition - level deficiencies varied considerably by state , ranging from none in 6 states to about 25 percent of labs in south carolina .

these data only included findings for about one - half of the labs surveyed by state survey agencies .

of the 33 states that survey more than 100 labs , 16 found condition - level deficiencies at fewer than 5 percent of labs , while 6 states identified such serious deficiencies in more than 10 percent of the labs they surveyed ( see app .

ii ) .

based on interviews with cms and 10 state survey agencies , it appears that at least some of this variability is due to differences in states' approaches to surveys as opposed to true differences in lab quality .

for example , cms told us that , because there is not a prescriptive checklist to guide the survey process , the reliance on state surveyor judgment will result in variations in the citing of deficiencies .

to compensate for the unstructured nature of the state survey process , officials we interviewed from 2 state survey agencies told us that they created checklists to help ensure that surveyors looked at all of the critical elements during lab surveys .

furthermore , while some of the state survey agencies we spoke with told us that their surveyors always cite condition - level deficiencies that are identified during surveys , officials in other states said that there are circumstances under which condition - level deficiencies would not be cited .

for example , according to officials from a state survey agency we interviewed , surveyors prefer not to cite condition - level deficiencies .

rather , surveyors in this state prefer to cite multiple standard - level deficiencies instead of a condition - level deficiency because it allows the imposition of state law sanctions , avoiding what was characterized as a less efficient federal sanctions process .

additionally , officials from 2 other state survey agencies explained that surveyors consider a lab's compliance history when determining what deficiencies to cite , while officials from a third state told us that surveyors will educate lab workers , particularly new lab workers , about the clia requirements rather than citing clia condition - level deficiencies .

the goal of educating lab workers sometimes takes precedence over , or precludes , the identification and reporting of deficiencies that affect the quality of lab testing .

as a result , data on the quality of lab testing and trends in quality over time may be misleading .

although clia neither requires nor precludes an educational role for surveyors , the preamble to cms's implementing regulation noted that surveys are intended , in part , to provide an opportunity for on - site education regarding accepted laboratory procedures .

in addition , cms guidance and training encourage state surveyors to play an educational role .

many state survey agency officials we interviewed also told us that their surveyors play a major educational role .

as noted earlier , surveyors from one state survey agency do not cite condition - level deficiencies when lab workers are new but prefer to educate the new staff .

because cms revised its oscar database in 2004 , it is not possible to identify states that have consistently not cited condition - level deficiencies , data that would help to quantify the extent to which an educational role is substituting for appropriate regulation of labs .

an inappropriate balance between the educational and regulatory role is also evident in some accrediting organization practices .

one of the cap surveyors we interviewed with over 30 years of lab experience estimated that the majority of pathologists — individuals who generally serve as cap survey team leaders — view surveys as educational , rather than as assessments of compliance with lab requirements .

another surveyor told us that cap's survey process focuses heavily on education , and that some survey team leaders emphasize education more than others .

for cola , the process of educating labs begins even prior to a survey .

for example , cola encourages labs to submit a self - assessment for review prior to the scheduled survey so that the labs can identify cola requirements with which they are not in compliance .

about 20 percent of all labs surveyed during 2004 submitted a self - assessment ( 616 labs ) and , compared to labs that did not submit a self - assessment , fewer deficiencies were identified at these labs during on - site surveys .

cms appears to be inappropriately stressing education over regulation in its implementation of ( 1 ) 2003 lab quality control requirements for the clia program and ( 2 ) proficiency testing for lab technicians who interpret pap smears , a test for cervical cancer .

when state surveyors began assessing compliance with new lab quality control requirements in january 2004 , they were instructed to note deficiencies on a cover letter to labs rather than on the survey report itself for a period of 2 years .

thus , such deficiencies are not recorded in the oscar database .

in part because of a lack of lab “buy - in” for some of the new policies and procedures , cms officials have extended the educational period for about another 2 years .

cms has taken a similar educational approach to pap smear proficiency testing , which began in 2005 .

cms will not cite deficiencies or impose sanctions against labs in which staff fail the new pap smear proficiency testing in 2005 or 2006 , as long as the labs and individuals involved complete such testing , including following the regulatory protocol for subsequent testing in the case of an initial failure .

according to cms , this educational focus allows labs and their staff to become familiar with the proficiency testing program and to prepare themselves for such testing , since there was about a 13-year time lag between the 1992 regulations that implemented clia and the 2005 implementation of pap smear proficiency testing .

this educational approach seems questionable given cms's concern about some of the high initial proficiency test failure rates .

although state survey agencies , exempt - state programs , cola , and jcaho employ dedicated staff surveyors , cap relies primarily on volunteer teams consisting of lab workers from other cap - inspected labs to conduct surveys .

in contrast to the mandatory training and continuing education programs in place for the staff surveyors of other survey organizations , training for cap's volunteer surveyors is currently optional .

cap plans to establish a mandatory training program beginning in mid - 2006 .

as a condition of accreditation , labs inspected by cap must survey another cap - accredited lab of similar size and composition at least once every 2 years .

according to data provided by cap , two - thirds of volunteer surveyors who had recently participated in a survey had no formal training in the 3 to 5 years preceding the survey .

two cap surveyors we interviewed told us that they had not completed any training because it was optional .

two other surveyors told us that they had never been notified about the existence of optional cap training .

while full - time surveyors employed by other survey organizations conduct from 30 to about 200 surveys per year , cap volunteer surveyors have much less experience conducting surveys because they only survey about one lab each year .

three of the nine cap surveyors we interviewed stated that they believed that mandatory training was important , but some surveyors wondered when lab workers would have time to complete the courses because of their demanding work schedules .

according to cap officials , however , the required training will take only 1 to 2 days and surveyors will have a choice of live seminars and workshops or e - learning completed at their own computers .

for ongoing training requirements , cap plans to give surveyors a choice of taking additional training or passing a competency evaluation .

cap will track compliance with its new training requirements to ensure that surveyors successfully complete training and demonstrate competency within 2 years of participating in a survey .

cap's required training is less extensive than that required by other survey organizations .

for example , state survey agency inspectors must complete 5 days of basic training and periodic advanced courses afterwards while cola staff inspectors participate in a 5-week orientation program and an annual 20 hours of continuing education .

the use of volunteer inspectors by cap also raises concerns about the appearance of a conflict of interest .

these concerns arise because of the way cap survey teams are structured .

cap's commission on laboratory accreditation policy manual specifies that the inspection team leader is the individual responsible for the conduct of an ongoing site inspection , and must not be in a business , professional , or personal relationship that would preclude an objective inspection .

furthermore , the manual states that the inspection team leader is usually responsible for determining the size of , and assembling , the inspection team .

however , until april 2006 , cap policy did not preclude competing labs from surveying one another or lab survey team members from soliciting business , such as referrals , from a lab at the conclusion of the survey .

the policy was also silent about survey team members' business , professional , or personal relationships that could cloud their independence .

typically , inspection team leaders are pathologists who direct other labs in the community , and the inspection team is comprised of several employees from the team leader's lab .

we believe that the use of volunteers , including those from nearby labs , and the personal and professional relationships that may exist among lab staff and survey team members , creates the appearance of a conflict of interest and could undermine the integrity of the survey process .

comments from some cap surveyors we interviewed raise a concern about having survey team leaders who are also the day - to - day supervisors of team members .

for example , lack of agreement about the seriousness of a deficiency could result in the team leader instructing the team to downgrade the deficiency to a recommendation , a less serious finding that does not appear in the inspection report .

team members who are subordinates to the team leader may feel that they have no other recourse than to follow the team leader's instructions .

recognizing that team members' objectivity may be compromised in this situation , cap's revised conflict of interest policy instructs all parties to be cautious to retain objectivity in fact finding throughout the inspection process .

in discussing these findings with cap officials , they told us that they plan to institute a number of initiatives to help ensure survey objectivity , including ( 1 ) resurveying the same lab by an independent team to assess the consistency of inspections , ( 2 ) centralizing survey team assignments performed by cap staff , ( 3 ) not announcing surveys , and ( 4 ) not notifying labs of the survey team composition prior to the survey .

some lab workers may not be filing complaints about quality problems at their labs because of anonymity concerns or because they may not be familiar with filing procedures .

complaints about labs can come from a variety of sources , including lab workers .

complaints are an important tool in detecting quality problems between lab surveys .

for example , complaints about testing at a hospital lab were crucial because information had been concealed , complicating the detection of quality problems during the lab's surveys .

as a result of a complaint , surveyors were able to substantiate inadequate calibration of testing equipment that could adversely affect patient care .

based on oscar data and data obtained from exempt - state programs and accrediting organizations for 2002 through 2004 , few complaints were received about lab testing relative to the number of labs — significantly less than one complaint per lab per year .

the low volume of lab complaints may be related to complainants' concerns about anonymity and fear of retaliation for filing a complaint .

it may be easy for a lab to determine the source of a complaint filed by a lab worker .

for example , in some cases , either the nature of the complaint or the piece of testing equipment in question could narrow the list of possible complainants .

two cap surveyors we interviewed commented that , in their opinion , it would be easy to determine the identity of a complainant .

during congressional hearings in 2004 , a maryland hospital lab worker testified that she and her colleagues feared losing their jobs because of the complaints they filed .

because of the difficulty of protecting the anonymity of lab workers who file complaints , whistle - blower protections for such individuals are particularly important .

two of the three accrediting organizations we interviewed have whistle - blower protections — cap and jcaho .

for example , cap implemented a comprehensive whistle - blower protection policy in july 2004 that includes revocation of accreditation or other appropriate action for any lab that directly or indirectly threatens , intimidates , or retaliates against a lab worker .

while officials from new york and washington's exempt - state programs told us that whistle - blower laws in their states provide some protection for lab workers who file complaints , officials in most of the other 10 states we interviewed told us that they did not have any whistle - blower protections or were unable to identify specific protections that applied to lab workers in their state .

currently , there are no federal whistle - blower protections specifically for workers in labs covered by clia .

in 2005 , legislation was introduced to provide whistle - blower protections to workers in labs covered by clia .

we also found that lab workers may not know how to file a complaint .

cap experienced a significant increase in the number of complaints it received since october 2004 , when it began requiring cap - inspected labs to display posters on how to file complaints .

specifically , from october through december 2004 , cap received an average of 22 complaints per month , compared to an average of 11 complaints per month in the 9 months preceding the poster requirement .

as a result , the number of complaints about the quality of lab testing more than doubled in 2004 and the number substantiated increased by more than 40 percent — even though the poster was only displayed for the last 3 months of 2004 ( see table 3 ) .

in september 2005 , cola also began requiring labs to display a complaints poster similar to cap's .

it is too early , however , to determine the impact of cola's new complaints poster on the number , type , and substantiation rate of complaints .

neither cms nor jcaho plans to require a similar complaints poster .

few labs were sanctioned by cms from 1998 through 2004 — even those with the same condition - level deficiencies on consecutive surveys — because many proposed sanctions are never imposed .

our analysis of cms enforcement data from 1998 through 2004 found that 501 labs were sanctioned , which equates to less than 3 percent of labs inspected by state survey agencies .

the most common were principal sanctions , which may result in suspension or limitation of testing or termination from the clia program ; few labs were subjected to alternative sanctions , such as directed plans of correction or civil monetary penalties ( see table 4 ) .

appendix iii shows the number of labs surveyed by state survey agencies and the number of sanctioned labs from 1998 through 2004 .

although few labs were sanctioned from 1998 through 2004 , over 9,000 labs had sanctions proposed during that same time period .

before sanctions go into effect , labs are given a grace period to correct condition - level deficiencies , unless the deficiencies involve immediate jeopardy , that is , an imminent threat to patient health and significant hazard to public health .

most labs correct the deficiencies within the grace period .

cms officials told us that it was appropriate to give labs an opportunity to correct such deficiencies within a prescribed time frame and thus avoid sanctions .

however , a principal objective of the enforcement process — one reflected in cms guidance — is to motivate labs to comply with clia requirements , thereby helping to ensure the provision of accurate and reliable test results .

based on the large number of labs with proposed sanctions that were never imposed , it is unclear how effective the enforcement process is at motivating labs to consistently comply with clia requirements .

the number of labs with the same repeat condition - level deficiencies from one survey to the next also raises questions about the overall effectiveness of the clia enforcement process .

from 1998 through 2004 , 274 labs surveyed by state survey agencies had the same condition - level deficiency cited on consecutive surveys and 24 of these labs had the same condition - level deficiency cited on more than two surveys .

this analysis may understate the percentage of labs with repeat condition - level deficiencies because oscar data prior to 2004 no longer reflect about two - thirds of condition - level requirements and associated deficiencies at the time of those surveys .

we found that only 30 of the 274 labs with repeat condition - level deficiencies had sanctions imposed — either principal , alternative , or both .

according to the clia legislative history , congressional concern about labs with repeat deficiencies led to alternative sanctions to provide an enforcement option short of principal sanctions to encourage compliance .

from 1998 through 2004 , less than 1 percent of accredited labs ( 81 ) lost their accreditation ; few of these labs were subsequently sanctioned by cms and many still participate in the clia program .

our analysis of cms reports on sanctioned labs found that only 9 of the 81 labs had either principal and / or alternative sanctions imposed and that 1 of the 9 still performs moderate - to high - complexity testing .

based on a review of its clia certificate database , cms officials told us that about half of the 81 labs still perform moderate - to high - complexity testing but could not describe the actions taken by cms regional offices in response to the loss of accreditation .

we contacted state survey agencies or cms regional office officials to determine why 3 labs that cola concluded had cheated on proficiency testing by referring the samples to another lab to be tested had no sanctions imposed .

the purpose of proficiency testing is to provide an objective , external evaluation of the accuracy of a lab's test results , which is negated when another lab analyzes the sample .

by statute , the intentional referral of samples to another lab for proficiency testing is a serious deficiency that should result in automatic revocation of a lab's clia certificate for at least 1 year .

based on our interviews , we found that the 3 labs were allowed to continue testing because they had initiated corrective actions ; in effect , these labs were given an opportunity to correct a deficiency that appears to have required a loss of their clia certificate for at least 1 year .

a fourth lab was ultimately sanctioned for proficiency testing cheating by cms but was allowed to continue testing for almost 2 years after having its accreditation revoked .

we also attempted to analyze data on other actions , short of revoking accreditation , used by accrediting organizations to encourage lab compliance and , in particular , how they respond to labs with serious repeat deficiencies .

according to cms , this information is dispersed across cms regional offices .

cap officials told us that they could initiate four intermediate actions including probation ( lab is closely watched to ensure correction of problems ) , accreditation with conditions ( nonroutine inspection to be scheduled ) , suspension of a lab section , and cessation of a specific type of testing ; suspension and probation were instituted in 2004 .

according to cap , in 2005 , 28 labs were on probation , 106 labs were accredited with conditions , 1 lab was suspended , and 7 labs were required to cease a specific type of test .

in 2004 , jcaho awarded conditional accreditation to 3 percent of the labs it inspects because they were not in substantial compliance with its survey requirements , as evidenced by the number of requirements not met ; jcaho conducts an on - site follow - up survey at such labs .

from 2002 through 2004 , cola required about 30 labs per year to cease testing due to issues identified during surveys and about 217 labs per year to cease testing certain tests or specialties due to unsuccessful proficiency testing .

cms's oversight is not adequate to help ensure that labs meet clia requirements .

while clia requires proficiency testing quarterly , cms only requires such testing three times each year .

in addition , the agency is not meeting its responsibility to determine that accrediting organization and exempt - state requirements and processes continue to be at least equivalent to clia's .

cms attributed the delay in making equivalency determinations to having too few staff .

further , ongoing cms validation reviews do not provide an independent assessment of the extent to which surveys identify all condition - level deficiencies — primarily due to their timing .

finally , cms does not adequately use data , such as the results of surveys , to monitor survey organization activities and processes .

realizing that its existing oversight activities need to be strengthened , cms has begun instituting performance reviews to measure survey organization compliance with its standards and is developing protocols to ensure improved communication among survey organizations concerning complaints about lab quality .

cms's decision to require proficiency testing for almost all laboratory tests only three times a year is inconsistent with the statutory requirement .

clia requires that proficiency testing be conducted “on a quarterly basis , except where the secretary determines for technical and scientific reasons that a particular examination or procedure may be tested less frequently ( but not less often than twice per year ) .” the committee report on the bill that forms the basis for much of clia indicated that “proficiency testing should be the central element in determining a laboratory's competence , since it purports to measure actual test outcomes rather than merely gauging the potential for accurate outcomes.” in cms's 1992 rule implementing clia , the agency provided a rationale for reducing the frequency of proficiency testing , but did not provide a technical and scientific basis for reducing the frequency for particular procedures or tests .

according to cms's justification , experts were divided on the appropriate frequency of proficiency testing generally .

in addition , requiring fewer events of proficiency testing would give laboratories more time to analyze the causes of test failures before the next event of proficiency testing and also enhance proficiency testing's value as an educational tool .

because clia increased the number of labs that were required to undergo proficiency testing , cms believed that the number of organizations that provided proficiency testing services would not have been able to meet the anticipated increase in demand for testing services .

to help avoid anticipated delays in completing proficiency testing and reporting requirements , cms reduced the frequency of testing events to three times per year .

cms's requirement for proficiency testing does not meet the conditions specified in the statute that must be satisfied in order to require testing less frequently than quarterly .

the language of the statute , as well as relevant legislative history , indicate that a decision to reduce the frequency of testing should be in the nature of an exception made with regard to a particular test , not the norm for all tests , and must be based on “technical and scientific” considerations related to that particular test .

the reasons that cms gave for requiring only three events per year were not based on scientific and technical considerations relevant to particular tests .

instead , cms's decision was based on concerns of an administrative and logistical nature that cms wanted to alleviate by reducing the frequency of testing events .

we found that cms has been late in determining that exempt states' and accrediting organizations' inspection requirements and processes are at least equivalent to clia's .

cms must verify their equivalency and , by regulation , cms requires such survey organizations to seek reapproval at least once every 6 years , or more frequently if deemed necessary .

cms establishes the time frames for when the next reapproval should occur , which have ranged from about 15 months to about 6 years .

however , cms has not completed its equivalency reviews within these time frames and accrediting organizations and exempt state programs have continued to operate without proper approval .

equivalency reviews for cap , cola , jcaho , and washington due to be completed between november 1 , 1997 , and april 30 , 2001 , were an average of about 40 months late .

in august 1995 , cms determined that new york's next equivalency review should be completed by june 30 , 2001 , but was over 4 years past due as of december 2005 .

similarly , cola's equivalency review was about 3 years past due .

because accrediting organizations and exempt - state programs may choose to make changes to their inspection requirements between periodic equivalency reviews ( 1 ) accrediting organizations are required to submit changes to their inspection requirements and policies 30 days prior to changing their standards and ( 2 ) exempt - state programs are required to provide notice when they change their licensure or inspection requirements .

although federal regulations require cms to review equivalency when an accrediting organization or exempt - state program adopts new requirements , a cms official told us that the agency is not required to review such changes before their implementation to ensure equivalency .

as a result , such survey organizations may introduce changes that are inconsistent with clia requirements .

for example , jcaho made a significant change to its inspection requirements in january 2004 but did not receive cms approval until 6 months later ; cms did not begin an in - depth review of jcaho's revised requirements until early 2005 — over a year after they were implemented by jcaho .

according to cms , their review has identified several critical areas where jcaho standards are less stringent than those of clia .

jcaho acknowledged the need to make some adjustments to its revised requirements .

cms officials attributed delays in making equivalency determinations and reviewing interim changes to having too few staff .

the clia program , located in cms's center for medicaid and state operations ( cmso ) , currently has approximately 21 full - time - equivalent positions compared to a peak of 29 such positions several years ago .

the reduction occurred over time through attrition .

as required by statute , the clia program is funded by lab fees and since its inception the program's fees have exceeded expenses .

as of september 30 , 2005 , the clia program had a carryover balance of about $70 million — far more than required to hire an additional six to seven staff members .

however , cms officials told us that because the clia program staff are part of cmso , they are subject to the personnel limits established for cmso , regardless of whether or not the program has sufficient funds to hire more staff .

although cmso is at its authorized personnel allocation , the clia program could hire additional staff with approval from the administrator .

we were told that cmso has not requested such approval .

we also noted issues that raise a question about the thoroughness of cms equivalency reviews because some survey organizations' procedures or policies appear to be less stringent than those required by cms for the clia program .

for example: accrediting organizations provide labs more advance notice about upcoming surveys than cms allows state survey agencies to give to the labs they inspect .

jcaho surveyors focus their review of lab testing on the 12 months prior to the survey .

cms requires that state surveyors review the entire 24 months of testing since the last survey .

while cms requires initial and advanced surveyor training , cap encourages but does not require its volunteer surveyors to participate in surveyor training .

as of august 2005 , cap's policy manual indicates that complaint investigations may be announced or unannounced .

cms guidance requires that complaint investigations be unannounced .

prior to 2005 , cms's equivalency determination reviews focused on the inspection requirements themselves , and not the procedures and policies used by accrediting organizations and exempt - state programs in carrying out oversight of labs ; this focus on inspection requirements may explain the divergence from the policies and procedures cms requires for state survey agencies .

during 2006 , cms is simultaneously reviewing the equivalency of cola and jcaho inspection requirements and , for the first time , incorporating on - site observations of accrediting organization policies and systems into the review and approval process .

for example , cms is checking to ensure that accrediting organizations have adequate systems in place to track such things as ( 1 ) complaints , ( 2 ) correction of deficiencies , and ( 3 ) proficiency testing .

cms validation reviews that are intended to evaluate lab surveys conducted by both states and accrediting organizations do not provide cms with an independent assessment of the extent to which surveys identify all serious — that is , condition - level or condition - level equivalent — deficiencies .

cms requires its regional offices to conduct validation reviews of 1 percent of labs inspected by state survey agencies in a year .

in contrast , validation reviews of 5 percent of labs inspected by accrediting organizations during a year are conducted by state survey agency personnel .

cms does not specifically require that validations occur in each state and some states do not have validation reviews each year .

furthermore , many validation reviews occur at the same time a survey organization conducts its inspection and , in our view , the collaboration among the two teams during these simultaneous surveys prevents an independent evaluation .

the requirement to validate 1 percent of labs surveyed by state survey agencies in a year — roughly 100 validation reviews each year — does not ensure sufficient oversight of state survey agencies .

the validation review requirement , which is included in cms regional office annual budget memorandums , does not specify how many validation reviews must be conducted in each state .

while the 10 cms regional offices generally validated 1 percent of the state survey agency inspections within their region , they often did not validate 1 percent of inspections within each state and , in fact , performed none in some states .

from 1999 through 2003 , federal surveyors: validated less than 1 percent of labs surveyed by state survey agencies in an average of about 25 percent of states , ranging from 7 states in 2002 to 17 states in 2003 ; and did not conduct any validation reviews in an average of 16 percent of states per year , ranging from 3 states in 2002 to 12 states in 1999 .

in 11 states , no validation reviews were conducted in multiple years .

for example , no validation reviews were conducted in michigan and washington , d.c. during 4 of 5 years from 1999 through 2003 .

without validating at least some surveys in each state , cms is unable to determine if the states are appropriately identifying deficiencies .

seventy - five percent of validations of state lab surveys were conducted simultaneously from fiscal years 1999 through 2003 .

according to cms officials , the large proportion of simultaneous validation reviews provides an opportunity for federal surveyors to share information with state surveyors , monitor their conformance with clia inspection requirements , and identify training and technical assistance needs .

however , we found that such reviews do not provide an accurate assessment of state surveyors' ability to identify condition - level deficiencies .

of the 13 validation reviews that identified missed condition - level deficiencies , only 1 was a simultaneous review ( see table 5 ) .

validations of state surveys typically utilize one federal surveyor for either independent or simultaneous validation reviews ; therefore , increasing the proportion of independent validation reviews to strengthen cms oversight likely would not require additional federal surveyors .

moreover , conducting independent validation reviews eliminates the extra effort required to coordinate schedules to ensure that the validation reviews occur at the same time as the state survey .

according to cms guidance , at least one validation review of an accrediting organization's survey of labs should be conducted simultaneously each year , but not all validation reviews should be simultaneous because a combination of simultaneous and independent reviews provides a balanced view of surveyor performance .

cms officials were unable to tell us exactly how many of the roughly 275 validation reviews conducted each year from fiscal year 1999 through fiscal year 2003 were simultaneous .

however , one of the three accrediting organizations we reviewed told us that a significant proportion of their validation reviews are conducted simultaneously .

jcaho estimated that 33 percent of its validation reviews were conducted simultaneously .

cola estimated that 9 percent of validation reviews conducted in 2004 and 2005 were simultaneous .

finally , cap officials told us that , from 2002 through 2004 , 11 percent of validation reviews of cap - accredited labs were conducted simultaneously .

given the limitations of simultaneous reviews , conducting independent validation reviews are a more effective way of ensuring the equivalency of accrediting organization inspection requirements and processes between the equivalency determinations .

cms officials told us that the agency's intent in instituting simultaneous reviews was for state and accrediting organization surveyors to share best practices , to promote understanding of each other's programs , and to foster accrediting organization improvement .

they indicated that they considered it a learning experience both if an accrediting organization surveyor added a deficiency noted by a state surveyor to a survey report and vice versa .

however , most of the state survey agency officials we interviewed told us that simultaneous validation reviews do not provide a realistic evaluation of the adequacy of accrediting organizations' inspection process .

in fact , cms guidance encourages surveyors to discuss the survey findings prior to concurrent conferences with lab personnel to review their findings .

from fiscal years 1999 through 2003 , state survey agency surveyors found condition - level deficiencies missed by accrediting organization surveyors on 64 validation reviews , but only 6 of these validation reviews were simultaneous .

in contrast , 58 ( 91 percent ) of the validation reviews that identified serious deficiencies missed by accrediting organizations were independent validation reviews .

 ( see table 6. ) .

cms does not routinely collect and analyze data essential for effective oversight of the clia program but has initiatives to automate some available data to make them more accessible for analysis .

using data to analyze activities across survey organizations can be a powerful tool in improving cms oversight of the clia program .

such analyses include identifying and addressing inconsistencies in how surveys are conducted .

although cms tracks the most frequently cited deficiencies at labs in an effort to improve quality , it does not routinely track the proportion of labs , by state , in which state survey agencies identify condition - level deficiencies — those that denote serious or systemic problems .

according to a cms official , the agency has not evaluated variability in such deficiencies since 1999 .

as noted earlier in this report , variability in survey findings suggests inconsistencies in how surveys are conducted .

cms also does not require exempt - state programs and accrediting organizations to routinely submit data on serious deficiencies identified at the labs they inspect , unless the deficiencies pose immediate jeopardy to the public or an individual's health .

as noted earlier , the lack of a common vocabulary on what constitutes a serious deficiency would make it virtually impossible for cms to analyze such data .

we also found that cms does not effectively use available data to assess clinical lab quality in areas such as proficiency testing , sanctions , and complaints .

for example , cms's analysis of proficiency testing data for all labs showed improvements over time .

as reported earlier , proficiency testing failures have increased for labs surveyed by cap and jcaho .

comprehensive analysis of the proficiency testing database is particularly valuable because it provides a uniform way to assess the quality of lab testing across survey organizations , which is not currently available for survey results .

cms is now in the process of automating the annual registry of sanctioned labs , which should help it identify important trends , such as the infrequent use of alternative sanctions .

automating the registry , however , will not address the lack of data on ( 1 ) steps taken by state survey agencies and regional offices when labs have their accreditation revoked or ( 2 ) interim steps , short of revocation of accreditation , that accrediting organizations take to help encourage lab compliance .

cms also lacks a complaints database , and therefore was unable to assess the impact of cap's decision to require labs to prominently display a poster on how to file a complaint .

cms is developing , and plans to launch , a complaints database in march 2006 .

cms has implemented performance reviews for state survey agencies and is in the process of developing such reviews for accrediting organizations .

first implemented in 2004 , the annual clia state performance reviews evaluate each survey agency's ability to accomplish its lab oversight responsibilities .

the reviews , conducted on - site by cms regional office staff , measure performance in 13 areas , such as the timely conduct of surveys and the appropriate documentation of any deficiencies identified .

according to cms , the reviews are based on the performance - improvement model that characterizes much of the administration of the clia program .

consequently , the primary role of regional offices in conducting the reviews is to provide education and support for state survey agency improvement .

for the 2004 reviews , 38 states were required to submit corrective action plans to their respective cms regional offices in at least 1 of the 13 areas examined .

three areas required the most corrective action plans: principles of documentation , proficiency testing desk reviews , and survey time frames .

principles of documentation .

cms found that some state survey agencies lacked the supervisory personnel to conduct internal reviews intended to ensure the appropriate documentation of deficiencies .

it also found that some state survey agencies did not follow the protocol instructions on how to quantify such reviews .

proficiency testing desk reviews .

because of personnel shortages , some state survey agencies were unable to perform proficiency testing desk reviews between surveys , waiting instead until the next on - site survey to address unsuccessful proficiency testing .

cms plans to provide additional surveyor training on desk review requirements .

survey time frames .

cms regional office staff were inconsistent in scoring whether state survey agencies met the established time frames for initial surveys .

while some regions were lenient if a state missed the time frame by just 1 day or provided a reasonable explanation — such as staff turnover or illness — other regions were more stringent in scoring states against the standard .

however , it is not yet clear to what extent the 2004 scores represent state survey agency shortcomings or a learning curve for the states in understanding the performance review protocols .

in partnership with the accrediting organizations , cms is developing performance standards comparable to , but different from , those implemented in 2004 for state survey agencies .

for example , both the state survey agency review protocols and those proposed for accrediting organizations measure the timeliness of the surveys , but those proposed for the latter would also focus on several areas that are unique to accrediting organizations .

the performance standards would include ( 1 ) timely and consistent information sharing and ( 2 ) alerting cms about decisions to limit or remove accreditation in a timely manner .

according to a cms official , the agency plans to phase in the performance standards , starting with a standard on complaints .

for example , if the clia complaints database is activated in march 2006 , cms could begin to monitor accrediting organization responsiveness to , and outcomes of , complaints .

because the database will contain national lab complaint data , cms will be able to compare the volume and outcome of complaints across survey organizations .

according to cms , implementation of the accrediting organization performance standards will be a central — not regional — office responsibility .

clinical labs play a pivotal role in the nation's health care system by diagnosing many diseases , including potentially life - threatening diseases , so that individuals receive appropriate medical care .

given this important role , lab tests must be accurate and reliable .

cms and survey organization oversight is intended to ensure that labs produce reliable test results , a key objective of clia .

our work demonstrated that the oversight of clinical labs needs to be strengthened in several areas .

determining the quality of lab testing is difficult because it is virtually impossible to crosswalk inspection requirements across survey organizations .

without standardized survey findings across all survey organizations , cms cannot tell whether the quality of lab testing has improved or worsened over time or whether deficiencies are being appropriately identified .

lab oversight has weaknesses that make it difficult to determine the quality of lab testing because they mask quality problems .

to help surveys provide a realistic picture of day - to - day operations , cap and jcaho began unannounced surveys of the labs they survey — generally hospital labs — in 2006 .

while unannounced surveys at physician office labs may not be practical , washington's exempt program and cola currently give such labs more advance notice than the 2 weeks cms prescribes for labs inspected by state survey agencies .

similarly , the greater weight that cms and survey organizations sometimes place on their educational , as opposed to their regulatory role may lead to survey findings that do not accurately reflect lab quality .

educating labs to ensure high - quality testing should complement but not replace the enforcement of clia inspection requirements .

the low number of lab complaints may be the result of a lack of information about how to file a complaint and lab workers' fear of retaliation .

because protecting the anonymity of lab workers who file complaints is difficult , whistle - blower protections for such individuals are particularly important .

finally , labs with the same serious deficiencies on consecutive surveys often escape sanctions , even though congress authorized alternative sanctions to give cms more flexibility to achieve lab compliance .

without the threat of real consequences , labs may not be sufficiently motivated to comply with clia inspection requirements .

cms's oversight is not adequate to enforce clia requirements .

the agency is not requiring labs to participate in proficiency testing on a quarterly basis , as required by clia .

furthermore cms is not conducting clia - equivalency determinations within the time frames it established for such reviews , nor has it always reviewed changes to exempt - state and accrediting organizations' inspection requirements before their implementation , even though it requires their submission to ensure continued clia equivalency of their requirements .

although the clia program has generated funds , cms agencywide staffing limitations have prevented the program from hiring sufficient staff to complete equivalency reviews in a timely manner .

many validation reviews are conducted at the same time a survey organization conducts its survey , and such simultaneous reviews may not provide a true assessment of surveyor performance .

independent validation reviews of accrediting organization surveys are critical because cms has not conducted equivalency reviews within the time frames it established .

we also found that few validation reviews of state survey agency lab inspections are conducted each year and that none occurred in some states .

because state surveyors conduct validation reviews of accrediting organizations to ensure the continuing clia equivalency of their inspection requirements , conducting an appropriate number of validation reviews of state survey agency lab inspections is critical .

cms also has not yet taken the lead in ensuring the availability and use of data from survey organizations to help it monitor their performance — particularly the consistency with which surveys are conducted .

cms is creating a new complaint database , but its plan to automate the existing sanctions registry will not address the lack of data on enforcement actions taken by state survey agencies and regional offices when labs have their accreditation revoked .

to enable cms to track the nature and extent of lab quality problems across survey organizations , we recommend that the cms administrator take the following action: work with exempt - state programs and accrediting organizations to standardize their categorization and reporting of survey findings in a way that tracks to clia inspection requirements and allows for meaningful comparisons across organizations , such as the analysis of trends in the citation of condition - level deficiencies .

to ensure consistency in the oversight of labs by survey organizations , we recommend that the cms administrator take the following four actions: ensure that the advance notice of upcoming surveys provided to physician office labs is consistent with cms's policy for advance notice provided by state survey agencies .

ensure that regulation of labs is the primary goal of survey organizations and that education to improve lab quality does not preclude the identification and reporting of deficiencies that affect lab testing quality .

impose appropriate sanctions on labs with consecutive condition - level deficiencies in the same requirements .

require all survey organizations to develop , and require labs to prominently display , posters instructing lab workers on how to file anonymous complaints .

to improve oversight of labs and survey organizations , we recommend that the cms administrator take the following eight actions: consistent with clia , require quarterly proficiency testing , except when technical and scientific considerations suggest that less frequent testing is appropriate for particular examinations or procedures .

ensure that evaluations of exempt - state and accrediting organization inspection requirements take place prior to expiration of the period for which they are approved in order to ensure the continued equivalency of their requirements with clia's .

ensure that changes to the inspection requirements of exempt states and accrediting organizations be reviewed prior to implementation , as required by regulation , to ensure that individual changes do not affect the overall clia equivalency of each organization .

allow the clia program to utilize revenues generated by the program to hire sufficient staff to fulfill its statutory responsibilities .

ensure that federal surveyors validate a sufficient number of inspections conducted by each state survey agency to allow a reasonable estimate of their performance , including a minimum of one independent validation review for each state survey agency surveyor .

require that almost all validation reviews of each accrediting organizations' surveys be an independent assessment of performance .

collect and routinely review standardized survey findings and other available information for all survey organizations to help ensure that clia requirements are being enforced and to monitor the performance of each organization .

establish an enforcement database to monitor actions taken by state survey agencies and regional offices on labs that lose their accreditation .

we provided a draft of this report to cms , and to cap , cola , and jcaho — the three laboratory accrediting organizations included in our review .

cms strongly endorsed our overall conclusion that quality assurance for the nation's clinical labs should be strengthened and noted that the report provided insights into areas where it can improve , augment , and reinforce oversight of both labs and accrediting organizations to ensure quality testing .

overall , cms concurred with 11 of our 13 recommendations .

despite this endorsement , however , cms ( 1 ) provided an alternative assessment of lab quality , ( 2 ) disagreed that the phase - in of certain clia requirements inappropriately stressed education as opposed to regulation , ( 3 ) expressed concern about how to identify and sanction labs with repeat condition level deficiencies , ( 4 ) disagreed with our recommendation regarding the frequency of proficiency testing , and ( 5 ) stated that it was already meeting our recommendation to conduct almost all validation reviews of each accrediting organization independently .

we continue to believe that implementation of these recommendations is necessary for the effective oversight of labs .

 ( cms's comments are reproduced in app .

iv. ) .

cap indicated that it took seriously our findings and recommendations and intended to determine if there were additional measures it could take to strengthen its own oversight .

cola said that our recommendations to improve cms oversight of survey organizations had merit .

nonetheless , cap , cola , and jcaho disagreed with some of our findings and recommendations to cms .

 ( cap , cola , and jcaho's comments are reproduced in app .

v , vi , and vii , respectively. ) .

our evaluation first responds to cms's and related accrediting organizations' comments and then addresses additional comments by accrediting organizations .

cms and cola commented that lab performance has improved since the enactment of clia .

in particular , cms pointed to the substantial decline — from about 80 percent to about 42 percent — in the percentage of labs nationwide with deficiencies between 1994 and 2004 .

it is important to note that cms's data ( 1 ) do not distinguish between serious condition - level deficiencies and less serious standard - level deficiencies , ( 2 ) include the early start - up period when physician office labs were first regulated , and ( 3 ) exclude deficiency data on the substantial number of labs surveyed by accrediting organizations and state clia - exempt programs .

due to these shortcomings , we do not believe that cms's data provide an accurate assessment of lab quality nationwide .

based on the limited data available on state survey agency inspections of labs since 1998 and the lack of any comparable data on accrediting organization and exempt - state program survey findings , we concluded that insufficient data existed to identify the extent of serious quality problems at labs .

cms did not retain backup files of pre - 2004 data on deficiencies identified by state survey agencies .

although cms has determined that accrediting organization and exempt - state program lab requirements are at least equivalent to clia's , there is no agreement across survey organizations on how to distinguish serious from less serious deficiencies .

while cms concurred with our recommendation to standardize the categorization and reporting of survey findings in a way that tracks to clia and allows meaningful comparisons across survey organizations , it noted that a straightforward linkage of requirements is limited by cms's authority under the statute — that is , survey organizations are permitted by statute to have different requirements — and that it will approach implementation of our recommendation cautiously .

jcaho said that it agreed with the need for a common , agreed upon , taxonomy that could be used by all survey organizations to track serious deficiencies , but commented that it thought cms's implementation of our recommendation would require a revamping of jcaho's accreditation system .

that was not the intent of our recommendation and it is clear from cms's comments that its implementation of our recommendation would not require an overhaul of accrediting organizations' systems .

cap acknowledged the complexity and inherent challenges in measuring the quality of lab testing , but noted that it is committed to working to develop better systems to detect labs with serious quality problems — those that impact patient care .

the statutory authority that permits standards different from cms's ( provided they are at least as stringent ) does not impair the ability to develop a crosswalk that allows for meaningful comparisons across survey organizations — such as an analysis of trends in the citation of condition - level deficiencies .

in fact , cms regulations already require accrediting organizations and exempt - state programs to submit a crosswalk — detailed comparisons of their individual accreditation or licensure approval requirements with comparable clia condition - level requirements — when they apply and reapply for approval from cms .

such a comparison is possible because cms already identifies instances when accrediting organizations have missed condition - level requirements during validation reviews .

for example , cms should require survey organizations to ( 1 ) indicate which of their requirements relate to each clia condition - level requirement , and ( 2 ) explain which deficiencies in their requirements , if cited , should be considered equivalent to clia condition - level deficiencies .

cms also pointed to the steady increase in successful proficiency testing across all labs as an indication of improvements in lab quality .

our analysis of proficiency testing results suggested that lab quality had not improved at hospital labs in recent years .

cms correctly noted that the overall proportion of labs with no test failures increased from about 88 percent in 1998 to about 93 percent in 2003 — that is , fewer labs failed proficiency testing .

however , by focusing on overall proficiency testing results , cms data mask trends in failure rates for subsets of labs such as hospital labs .

for example , from 1999 through 2003 , the percentage of cap - surveyed labs with proficiency testing failures increased from 4.1 percent to 6.8 percent ; cap generally inspects hospital labs .

cms also commented that the overall improvement cannot be dismissed as a result of some labs being granted waived status because the more dramatic improvements predated the recent increase in the number of waived labs .

it further commented that removing waived labs from the data would not result in improved performance rates .

first , the number of waived labs — those performing waived tests or provider - performed microscopy — increased by about 26,600 from 1993 though 1998 and then increased by another approximately 33,700 labs from 1998 through 2004 .

second , cms's comment suggested that it had conducted an analysis of the impact of removing waived labs from the proficiency testing data .

however , it did not provide any data analysis when we subsequently asked to see the evidence behind its assertion .

cola also addressed this issue , and did not challenge our conclusion that the decrease in proficiency testing failures for physician office labs might not represent an actual improvement in lab quality , but instead could reflect the fact that some problematic labs are no longer surveyed .

cms agreed that it was important to maintain an appropriate balance between its regulatory and educational approaches to clia implementation .

while cms noted that objective review and feedback are the bedrock of education , it emphasized that the educational approach does not preclude surveyors from identifying lab deficiencies .

cap and cola offered similar comments .

however , we found evidence that the goal of educating lab workers sometimes takes precedence over , or precludes , the identification and reporting of deficiencies and recommended that cms take steps to ensure that regulation remains the primary goal of surveys .

to address this problem , cms stated that it will provide additional state agency surveyor training , improve guidance , develop an action plan to promote greater consistency among surveyors , and institute periodic performance and consistency reviews .

cms's comments did not address evidence we presented that an educational emphasis may also prevent fulfillment of regulatory responsibilities by some accrediting organizations .

cms disagreed that the extended phase - in periods for new quality control requirements and proficiency testing for lab technicians who interpret pap smears were inappropriate .

cola noted that federal requirements in many regulated industries are phased in to allow them time to understand and effectively implement the requirements .

cms reaffirmed that , in the case of significant new requirements and for the time period specified by cms , the educational approach may result in identified deficiencies being communicated to laboratories without a concomitant citation , as is the case with quality control and pap smear testing requirements .

as discussed in the report , we believe that cms's educational phase - in periods are excessive .

we found that the phase - in period for new quality control requirements was extended from 2 years to about 4 years , in part because of the lack of lab “buy - in” for some of the new policies and procedures .

similarly , the phase - in period for pap smear proficiency testing is 2 years , despite ( 1 ) cms's concern about some of the high initial test failure rates , ( 2 ) the consequences of inaccurate test results on patients' diagnoses and treatment , and ( 3 ) the approximately 13-year time lag between the 1992 implementation of the clia regulations and the commencement of pap smear proficiency testing .

in commenting on our recommendation to appropriately sanction labs with repeat condition - level deficiencies , cms acknowledged the need to carefully monitor repeat deficiencies but expressed concern that focusing on the condition cited may not indicate a true repeat deficiency because the underlying failures could have been different in the two consecutive surveys for those labs .

cms's assertion is inconsistent with its own policy on serious , repeat deficiencies for other providers , such as nursing homes .

in general , immediate sanctions must be imposed on nursing homes with consecutive serious deficiencies , regardless of whether the deficiencies are in the same care area .

as we have previously reported , allowing providers to avoid sanctions by correcting serious deficiencies contributes to an up - and - down pattern of compliance and undermines the deterrent effect of sanctions .

according to the clia legislative history , congressional concern about labs with repeat deficiencies led to the introduction of alternative sanctions such as civil money penalties as a substitute for more severe principal sanctions , which include termination from the clia program .

cms disagreed with our recommendation that it require quarterly proficiency testing except when technical and scientific considerations indicate that less frequent testing is justified for particular tests ; cms insisted that proficiency testing three times a year was “appropriate.” cms stated that cms and the centers for disease control and prevention had together determined that the reduced frequency was based on technical and scientific grounds .

we asked for a record of the agencies' deliberation supporting that decision .

cms supplied a brief , undated narrative , which it attributed to the centers for disease control and prevention .

it was not clear to us that this narrative was contemporaneous with the decision to reduce the frequency of proficiency testing .

moreover , the narrative focused on the relative costs and benefits of proficiency testing at various intervals .

there was no analysis of technical and scientific considerations with regard to particular tests that presented a basis for reducing the frequency .

based on cms's response , we maintain that cms's decision to require proficiency testing three times a year is not authorized by clia .

cms did not dispute that , according to clia , it must base the decision to reduce the frequency of proficiency testing on scientific and technical considerations relevant to particular tests , and that the decision to reduce the frequency is in the nature of an exception to the norm of quarterly testing .

cms also acknowledged that the “public explanation” contained in the preamble to the rule setting the proficiency testing requirement at three times a year referred only to general concerns about the perceived burden associated with quarterly testing .

for example , cms stated in its final rule that the prospect of reduced frequency would provide a “needed respite” to both laboratories and proficiency test providers .

in sum , cms has not adhered to the conditions set out in the statute for reducing the frequency of proficiency testing and has implemented a policy that is not supported by statutory authority .

cms acknowledged the need to complete timely equivalency reviews of accrediting organization and exempt - state requirements , which were an average of about 40 months late for the 3-1 / 2-year period we examined .

regarding interim changes made between periodic equivalency reviews , cms agreed with our recommendation and stated it would review such interim changes for both accrediting organizations and exempt - state programs prior to implementation , as required by regulation .

furthermore , cms indicated that changes to accrediting organization requirements did not necessarily impact clia equivalency determinations because accrediting organizations may have more stringent requirements than clia's .

while possibly true , cms must review the changes to determine whether clia equivalency is affected .

for example , in 2005 , when it reviewed jcaho's revised standards a year after they were implemented , cms identified several critical areas where jcaho's standards were less stringent than those of clia .

cms acknowledged that a significant increase in workload and the decline in clia program staff were factors which contributed to delays in making equivalency determinations and reviewing interim changes .

although cms stated that it reserved the right to manage the work within available resources and its assessment of priorities , it also made a commitment to explore our recommendation to utilize revenues generated by the clia program to hire sufficient staff to fulfill its responsibilities .

we believe that additional staff would not only improve the timeliness of equivalency reviews , but also their thoroughness .

cms stated that , consistent with our recommendation , 88 percent of accrediting organization validation reviews were conducted independently in calendar year 2005 .

however , our recommendation was to require that almost all validation reviews of each accrediting organizations' surveys be conducted independently .

cms's comments do not indicate the proportion of independent validation reviews conducted for each accrediting organization .

because cms did not begin collecting data on the number of simultaneous accrediting organization validation reviews performed until august 2003 , we relied on estimates from accrediting organizations .

cms did not challenge jcaho's estimate that 33 percent of its validation reviews were simultaneous , compared to about 10 percent for cap and cola .

we do not believe that performing an estimated 33 percent of jcaho's validation reviews simultaneously is consistent with our recommendation .

cola commented that simultaneous validation reviews are useful in assuring consistency and in providing an understanding of processes across survey organizations .

it also questioned the accuracy of most of the missed condition - level deficiencies identified by cms during independent validation reviews .

we did not assess the process cms uses to identify such missed deficiencies but based on a discussion with cms officials it appears that the process is thorough and time consuming .

jcaho commented that we had misinterpreted the results of simultaneous and independent validation reviews of accrediting organizations because , by jcaho's estimate , the proportion of missed condition - level deficiencies is roughly equivalent for both types of surveys .

we did not find the assumptions behind jcaho's estimate convincing , given the lack of data on the actual number of simultaneous versus independent validation reviews conducted for each accrediting organization .

furthermore , most of the state survey agency officials we interviewed , whose inspectors conduct accrediting organization validation reviews , told us that simultaneous validation reviews do not provide a realistic evaluation of the adequacy of accrediting organizations' inspection processes .

additional cap comments .

cap commented that we underestimated the value of using lab professionals in the inspection process and that we provided no factual evidence that their use was less effective than other models .

in contrast to cap , other survey organizations employ dedicated staff surveyors who have mandatory and continuing education requirements .

in addition , such dedicated surveyors conduct from 30 to about 200 surveys per year compared to cap's lab professionals who volunteer to perform about 1 survey per year .

cap partially addressed our concern about the lack of mandatory training for its volunteer surveyors .

it plans to begin requiring training for survey team leaders in july 2006 and for survey team members in 2007 .

however , cap's proposed new mandatory training is much less extensive than that required by other survey organizations .

moreover , we reported that some cap surveyors we interviewed raised a concern about having survey team leaders who are also the day - to - day supervisors of team members .

for example , lack of agreement about the seriousness of a deficiency could result in the team leader instructing the team to downgrade the deficiency to a recommendation , a less serious finding that does not appear in the inspection report .

team members who are subordinates to the team leader may feel that they have no other recourse than to follow the team leader's instructions .

cap recently revised its conflict - of - interest policy which now instructs all parties to be cautious to retain objectivity in fact finding throughout the inspection process .

we do not believe that this change in cap's conflict - of - interest policy addresses the concerns raised by the cap surveyors we interviewed .

in its comments , cap indicated that it would continue to closely monitor this issue to determine if further actions were necessary .

additional cola comments .

cola disagreed with our assertion that announced surveys may result in an unrealistic picture of lab quality — a conclusion supported by cms regional office staff and most state survey agency officials we interviewed .

we acknowledged that unannounced surveys of the physician office labs typically surveyed by cola and state survey agencies were not practical given the unpredictable operating hours of such labs and need to minimize disruptions to patient care .

however , we recommended that the advanced notice be limited to the 2 weeks permitted by cms for state survey agencies .

cola currently provides up to 12 weeks advanced notice .

cola contends that providing up to 6 months of advanced notice before a survey would only improve the lab's operation more quickly if the lab took that opportunity to review cola's self assessment questions and correct any missing or incorrect processes or documentation .

we believe that cola's example underscores the importance of our recommendation ; such actions should be an ongoing process at labs — not a reaction to an upcoming inspections .

additional jcaho comments .

jcaho said that our recommendation that all survey organizations develop and require labs to prominently display posters that instruct lab workers on how to file anonymous complaints was too narrow and prescriptive and may inadvertently limit organizations from using other , more effective ways to educate lab workers on this topic .

jcaho did not explain how implementing our recommendation would limit other initiatives .

in fact , cms's comments identified a number of promising approaches that it believed could supplement posters .

jcaho also said that our analysis of the increase in cap complaints after it required posters in the labs it inspects failed to recognize a broad national trend .

jcaho indicated that it also experienced a dramatic increase in lab complaints between 2004 and 2005 without the use of posters .

this increase may be related to jcaho's july 2005 requirement for labs to educate staff on how to report concerns .

cap told us that during the 3 months after they required a poster to be displayed they observed an immediate increase in the number of complaints .

thus , cap lab complaints increased by over 100 percent in 2004 compared to 2003 and by another approximately 71 percent in 2005 .

we continue to believe that cap's experience suggests that complaint posters can be an important way to encourage lab workers to communicate their concerns .

cms , cap , cola , and jcaho also provided technical comments which we incorporated as appropriate .

as arranged with your offices , unless you publicly announce its contents earlier , we plan no further distribution of this report until 30 days after its issue date .

at that time , we will send copies to the administrator of the centers for medicare & medicaid services and appropriate congressional committees .

we will also make copies available to others upon request .

in addition , the report will be available at no charge on the gao web site at http: / / www.gao.gov .

if you or your staff have any question s about this report , please contact me at ( 312 ) 220-7600 or aronovitzl@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix viii .

this appendix contains examples of lab errors and their consequences , illustrating the importance of the quality of lab testing and the effects of lab errors on patient health .

the examples in table 7 are summarized from case studies in the journal laboratory errors and patient safety .

number of labs ( 2005 ) number of labs ( 2005 ) .

in addition to the contact named above , walter ochinko , assistant director ; lucia p. fort ; dan lee ; kevin milne ; dean mohs ; elizabeth t. morrison ; michelle rosenberg ; and elizabeth scherer made key contributions to this report .

