this report responds to your request that we review the department of housing and urban development's ( hud ) use of its public housing management assessment program ( phmap ) .

specifically , the report discusses ( 1 ) hud's use and implementation of the program at its field offices , ( 2 ) public housing authorities' ( pha ) phmap scores over the first 4 years of the program , and ( 3 ) limits on any additional uses for the program .

we are sending copies of this report to the secretary of housing and urban development and will make copies available to others upon request .

major contributors to this report are listed in appendix vi .

please call me at ( 202 ) 512-7631 if you or your staff have any questions .

because public housing represents a $90 billion investment on the part of the federal government since the program's inception in 1937 and because the department of housing and urban development ( hud ) currently spends $5.4 billion a year on operating subsidies and modernization grants for this housing , interest remains keen in knowing how well local public housing authorities ( pha ) are managing their properties .

the phas , through which hud provides these subsidies and grants , house 3 million low - income people , many of whom are elderly or disabled .

the congress holds hud responsible for ensuring that the authorities provide safe and decent housing , operate their developments efficiently , and protect the federal investment in their properties .

the national affordable housing act of 1990 required hud to develop indicators to assess the management performance of phas .

this law became the framework through which hud developed one of its primary oversight tools for housing authorities , the public housing management assessment program ( phmap ) .

primarily , phmap establishes objective standards for hud to evaluate and monitor the management operations of all phas to identify those that are troubled .

according to hud , phmap also allows the department to identify ways to reward high - performing phas as well as improve the management practices of troubled phas .

the program also allows phas' governing bodies , management officials , residents , and the local community to better understand and identify specific program areas needing improvement .

to help improve public housing management , the national affordable housing act of 1990 , as amended ( the act ) , required hud to develop indicators to assess the performance of phas in all the major aspects of their management operations .

the act required hud to use certain indicators as well as provided discretion for the secretary of hud to develop up to five additional indicators that the department deemed appropriate .

hud implemented phmap by using the 12 indicators listed in table 1.1 , the first seven of which are those required by statute .

because some indicators are more important than others in measuring management performance , hud assigns them added weight in determining the overall score .

hud considers the indicators for vacancies , rents uncollected , annual inspection and condition of units and systems , and resident initiatives most indicative of good property management and delivery of services to residents , so each one has a greater weight than other indicators .

after reviewing existing procedures and extensively consulting with a group of phas , public housing industry groups , private management firms , resident groups , and hud staff in field offices , hud has significantly revised the phmap indicators .

hud's revisions to phmap , published december 30 , 1996 , eliminated three indicators ; consolidated four other indicators into two ; and added one new indicator , security .

these revisions primarily address the performance indicators on which housing authorities report data , not hud's use of phmap data .

annually , phas receive a grade of “a” through “f” for each of the twelve indicators that apply to their operations .

hud uses a formula that reflects the weights assigned to each indicator , converts indicator grades into points , totals each pha's points , and divides that total by the maximum total the pha could have achieved to arrive at a percentage .

that percentage , a number between 0 and 100 , is the phmap score .

hud draws data on the performance of a housing authority from two sources to determine the authority's phmap score .

first , the housing authority submits data to hud for about half of the phmap indicators and certifies that this information is accurate and complete .

hud assigns grades to each of these indicators according to a comparison of the authority's data and hud's criteria for grades “a” through “f.” the balance of the information hud uses comes from its own information system for tracking expenditures from major grants .

this system contains the financial and other types of data the field offices need to grade the remaining indicators for which the phas do not provide data .

the field offices use this data and the pha - certified data to determine indicator scores , the phmap score , and the pha's performance designation .

the phmap score is hud's starting point for both the performance designation it assigns to a pha and , depending on that designation , the extent of follow - up required of the pha to correct deficiencies identified during the phmap assessment .

generally , hud uses three designations to describe the performance of phas: troubled performers are those scoring less than 60 percent ; standard performers are those scoring between 60 and less than high performers are those scoring 90 percent or more .

hud has the discretion to withhold the troubled designation or award the high performer designation if a pha's score is within 10 points of the threshold for either designation and hud determines that its score results from the physical condition and / or neighborhood environment of that authority's units rather than from the pha's poor management practices .

if a housing authority is designated as troubled , it faces several mandatory follow - up activities and / or corrective actions to improve performance and remove the troubled designation .

specifically , the act requires hud to perform an independent management assessment of the troubled pha's overall operations to identify the causes of the deficiencies that led to its poor phmap score .

hud uses private contractors to perform these independent assessments .

hud expects the independent assessments to form the basis for the second requirement for troubled phas — the memorandum of agreement ( moa ) .

a memorandum of agreement is a binding contract between hud and a troubled pha to identify solutions to its management problems and pursue those solutions in a way that is significant , expeditious , and lasting .

among other things , hud requires that the moa address the specific responsibilities of hud and the pha , the resources each will commit to resolving the authority's problems , the annual and quarterly performance targets for improving its performance on phmap indicators , and the incentives for it to meet its performance targets as well as sanctions for failing to do so .

a pha's initial moa generally lasts 18 months so that it can complete a second - year agreement with hud , if necessary , before the first expires .

hud's regulations for implementing phmap require standard - and high - performing phas to develop improvement plans for every phmap indicator on which the pha received an “f,” unless the pha can correct the deficiency within 90 days ; hud may also choose to require these plans for indicators receiving scores of “d” or “e” when failure to raise the grade might pose significant added risk .

an improvement plan documents how and when the pha plans to correct deficiencies .

although similar in content and scope to a memorandum of agreement , improvement plans differ in that ( 1 ) phas develop and submit them to hud for approval rather than negotiate them with hud officials and ( 2 ) they are not a binding contractual commitment between the pha and hud .

when hud first implemented phmap , it offered high - performers a variety of incentives , primarily regulatory relief from various reporting requirements .

these incentives included less frequent reviews of changes to a pha's operating budget and , for those performing well on the modernization indicator , no prior hud review for architects' or engineers' contracts .

in addition to regulatory relief , high - performing phas receive a hud certificate of commendation and public recognition for their performance .

in its fiscal year 1997 budget request , hud proposed an additional phmap - based incentive for high - performing phas when it sought to create a $500 million capital bonus fund ( as part of the $3.2 billion it sought for its public housing capital fund ) .

to be eligible for a bonus , a pha would have to be a phmap high performer and have undertaken substantive efforts to obtain education and job training for its residents .

however , the congress chose not to fund the bonus proposal for public housing or any of hud's other major programs , in part because of concerns about hud's ability to accurately and reliably track the performance of bonus recipients .

with nearly 800 staff devoted to oversight of housing authorities and implementation of the full range of hud's public housing programs , its field offices have the bulk of the department's responsibility for the day - to - day implementation of phmap .

field offices' phmap responsibilities include determining the indicator grades and phmap scores , negotiating memorandums of agreement , approving phas' improvement plans , and monitoring their progress in meeting the goals the moa or improvement plan set forth .

to determine a housing authority's phmap score , a field office relies on that pha to provide about half the data that leads to the overall phmap score and certify the data's accuracy .

as a result , the overall phmap score and everything it influences — from incentives for high performers to sanctions for troubled phas — are very much a joint effort and a shared responsibility .

a pha may also request to exclude or modify the data hud should consider in computing its phmap score .

an exclusion means that the indicator ( or one or more of its components ) is entirely excluded from calculations to determine the phmap score .

for example , phas with no ongoing modernization or development programs are automatically excluded from being assessed on those indicators .

modifying the data for an indicator allows hud to consider unique or unusual circumstances by exempting some of the data hud usually requires the pha to consider .

the pha still receives a score for the indicator , but the score would not reflect the data associated with the pha's unique or unusual circumstances .

for example , a pha operating under a court order not to collect tenants' rent at specific developments until it corrects deficiencies the court had identified can seek to exempt those units in its developments from being considered in its indicator score for rents uncollected .

a pha always has the right to appeal a field office's decision about modifications , exclusions , indicator scores , or the performance designation .

however , after those appeals have been exhausted , the field office certifies the pha's phmap score , assigns a final performance designation , and proceeds with any required improvement plans , moas , or other necessary follow - up .

when a troubled authority's new phmap score is high enough to cause hud to remove its troubled designation , hud's policy is to require the field office to verify the accuracy and completeness of the new data submitted by the housing authority .

hud also requires the field office to conduct a confirmatory review to verify the data the pha had certified as well as the accuracy of the data hud had obtained from its own information system .

hud's guidance for implementing phmap stipulates that a confirmatory review must take place on - site at the pha and cannot be accomplished through remote monitoring .

hud's field offices may choose to conduct some confirmatory reviews of standard - and high - performing phas' phmap certifications .

hud expects its field offices to choose these phas according to the risk they pose and focus on those with the highest potential for fraud , waste , mismanagement , or poor performance .

some of the factors hud field offices may consider in analyzing the risk associated with a pha's phmap certification include size ( number of units ) , borderline troubled designation ( 5 percent above or below the percentage for the designation ) , and negative trends in overall or individual indicator scores over several years .

in may 1995 , hud expanded the scope of the annual independent audit each pha receives in order to improve the department's ability to determine whether pha - certified data are accurate .

the annual audit , conducted pursuant to the requirements of the single audit act , examines the housing authority's financial statements , internal controls , and compliance with hud's rules and regulations .

housing authorities are responsible for selecting their own auditors and submitting the results of the audits to their hud field office .

field offices are responsible for reviewing the audits to ensure they meet all of hud's requirements and , when they have approved the audit , reimbursing housing authorities for them .

in fiscal year 1995 , these independent audits cost hud about $8 million for all housing authorities .

hud now requires the independent auditors to determine whether a housing authority has adequate documentation for the data it submits to hud for its phmap certification .

according to hud officials , because the department's resources are too limited to conduct annual confirmatory reviews of most housing authorities , they expected to use the results of these audits to better focus hud's attention , oversight , and technical assistance .

in addition to paying for the audits , hud expects its field offices to use the results as part of a risk assessment to determine which housing authorities should get the most sustained attention and technical assistance .

stressing the need for hud to hold housing authorities accountable while making better use of the data that phmap produces , the chairman of the subcommittee on housing and community opportunity , house committee on banking and financial services , asked gao to review hud's use and implementation of phmap .

as agreed with the chairman's office , we reviewed whether hud's field offices are using phmap and complying with the program's statutory and regulatory requirements to monitor and provide technical assistance to housing authorities , whether phmap scores have increased and how hud uses the program to inform hud's secretary and the congress about the performance of housing authorities , and whether phmap scores are consistently accurate and can be considered a generally accepted measure of good property management .

we developed information from several different sources to address questions concerning the usefulness of phmap to hud and other uses for which phmap may not be appropriate .

to determine phmap's usefulness to hud , we interviewed officials and collected information on technical assistance activities at both the department's headquarters and field offices .

at hud's headquarters , we analyzed a variety of documents pertaining to phmap and discussed the program's use as a basis for technical assistance with the offices of the deputy assistant secretaries under hud's assistant secretary for public and indian housing .

at hud's field offices , our approach was twofold .

first , we surveyed them via fax questionnaire to obtain data on the use of phmap , such as the number of confirmatory reviews each field office performs and how useful such program tools as improvement plans have been .

this data reflect responses from all of hud's public housing field offices .

second , we visited five hud field offices to review their use of phmap in more depth and to supplement the information we had gathered in our survey .

we judgmentally selected the five field offices because of their geographic distribution , variations in the number of hud staff in each office as well as the number of phas each oversees , and variations in average phmap scores for the phas reporting to those offices .

to provide information on phas' phmap scores , we relied on existing data from hud sources , including hud's primary public housing database , the system for management information retrieval - public housing ( smirph ) .

from this database , we extracted the module containing housing authorities' phmap data , including the phmap scores and individual indicator grades .

our analysis covers federal fiscal years 1992 through 1995 because the first fiscal year in which the rules governing phmap took effect was 1992 and the most recent year for which all phmap scores were complete at the time of our review was 1995 .

we did not systematically verify the accuracy of hud's data or conduct a reliability assessment of hud's database .

in performing our analysis we found erroneous and incomplete information for a few phas , ranging from 1 to 3 percent of the total .

we confirmed this with hud officials , who attributed the errors to mistakes in data input or the field office's having entered incomplete scores .

however , because we used these data in context with additional evidence we obtained directly from hud's field offices and we did not focus on the scores of specific phas or small groups of phas , we believe our conclusions about overall trends in scores are valid .

throughout the course of our work , because the number of phas reporting phmap scores is too great for us to visit a representative sample , we consulted with several prominent groups representing the public housing industry to discuss hud's uses for phmap as well as their perspectives on the program's ability to measure the performance of public housing authorities .

these groups include the council of large public housing authorities , the national association of housing and redevelopment officials , and the public housing authorities directors association .

we provided a draft of this report to hud for review and comment .

hud's comments appear in appendix v and are addressed at the end of each applicable chapter .

we performed our work from january through december 1996 in accordance with generally accepted government auditing standards .

hud's field offices use phmap scores for their primary intended purposes: as a standard , objective means to identify troubled housing authorities ; to compare performance among phas ; and to identify when , where , and how to target hud's limited resources for technical assistance .

however , beyond identifying troubled authorities and what they need , the amounts and kinds of technical assistance hud provides varies because its field offices interpret their responsibilities differently — some choose to be actively involved while others adopt a hands - off approach .

furthermore , hud's 1995 reorganization of its field offices adversely affected some offices' ability to provide technical assistance while others adapted to changed expectations and resumed providing as much assistance as they did before the reorganization .

as part of hud's oversight of public housing , the phmap score is an important tool for identifying troubled authorities so hud can focus technical assistance and monitoring on them .

the most common types of technical assistance that hud's 49 public housing field offices provided all phas were telephone consultations , training , and participation in conferences .

however , we found differences in how field offices defined their roles in providing phas technical assistance as well as some innovations in how others provided that assistance .

for example , some field offices have encouraged high - performing phas to provide “peer assistance” to lower performers .

many of the differences in assistance were due to variations in field offices' interpretations of their roles and the impact of hud's 1995 reorganization of its field offices .

hud headquarters officials believe that more training for all field staff and leadership from field office managers would help achieve more quality and consistency among field offices in providing technical assistance .

officials in 40 of hud's 49 field offices rated phmap as being of “utmost” or “major” importance in identifying which housing authorities need the most technical assistance .

according to field office staff , phmap provides standard indicators to objectively measure an authority's performance .

in addition , some staff said that because phas have a strong aversion to failing performance scores and try to avoid failure , they are confident that when phas report information that results in low scores or failing grades , the data and the resulting scores are accurate .

because an accumulation of low or failing scores results in a pha's being designated troubled , hud staff are confident that those phas phmap identifies as the worst - performing housing authorities are accurately designated as troubled performers .

some field office staff also use declining phmap scores to provide an early warning of management problems and to identify which phas could need additional technical assistance .

in addition , the staff use phmap's 12 individual indicator grades to better focus their limited technical assistance resources and thereby maximize the benefits phas receive from hud's assistance .

for example , one field office developed a package of technical assistance for the “resident initiatives” indicator because many phas failed this indicator .

the package of assistance included sample policies and procedures for operating resident programs .

another field office developed assistance specifically for small housing authorities because many of them were having trouble renting their units when they became vacant ( thus failing phmap's unit turnaround indicator ) .

among other things , that field office provided its small phas an extensive list of suggestions on how and where to better market their units .

most technical assistance from hud's field offices consisted of telephone consultations , training sessions , and industry conferences .

hud also provided assistance — although limited because of time constraints — at the time of a phmap confirmatory review .

during telephone consultations , several offices we visited answered questions from housing authority staff and helped the executive directors of new housing authorities better understand public housing regulations and operations .

training sessions covered these and other topics and provided more details than telephone discussions .

in addition , to increase the amount of personal contact they have with housing authority staff and to provide technical assistance , field office staff said they regularly participate in conferences hosted by public housing industry associations .

field offices' interpretations of their obligation to improve the performance of housing authorities influences the type of technical assistance they provide .

for example , officials in one field office did not believe that it was hud's role to manage phas' operations .

instead , they believed that the role of their field office should be limited to providing information on compliance with federal rules and regulations and to suggesting solutions to management problems .

this field office avoids showing phas how to manage their developments because the staff believe that they do not have sufficient expertise and that the housing authorities would view this advice as intrusive .

in contrast , staff at other field offices that we visited believed they are obligated to tell phas what must be done to correct management deficiencies because hud is responsible for ensuring that phas use federal funds efficiently and effectively to provide safe , decent housing .

for example , staff from one field office spent several days at a troubled authority to help it set up proper tenant rent records and waiting lists .

in addition to differences in how they view their role to directly assist phas , we found differences in the extent to which field offices use outside resources to help their housing authorities .

some field offices told us that to compensate for a shortage of resources from hud , they help phas in their jurisdiction by encouraging technical assistance from other phas rather than providing it themselves .

for example , some of the field offices arranged for high - performing phas to provide peer assistance to authorities with management problems .

one field office persuaded staff from a high - performing pha to temporarily manage a small authority that unexpectedly lost its executive director .

another field office recruited a high - performing pha to help another one develop a system for inspecting its housing units .

in 1995 , hud reorganized the field offices and changed the responsibilities of the staff who oversee and assist phas .

before the reorganization , most field office staff were generalists and broadly understood federal housing regulations and pha operations .

after the reorganization , however , the responsibilities of individual field office staff became more specialized to focus on the rules and regulations of specific public housing operations.this specialization confused some staff in field offices and housing authorities as well as impaired the ability of some field offices to provide technical assistance .

for example , field office staff we visited said that some specialists do not have the skills needed to do their jobs because many of them did not have the work experience or requisite training for the specialists' positions ; the staff also noted that hud had not provided sufficient training for the staff to understand the reorganization and their new responsibilities .

the staff also said that the reorganization was a source of confusion for phas .

before the reorganization , a housing authority could call one employee at hud's field office to answer all its questions ; afterward , a housing authority generally needed to call several different staff at hud's field office to answer questions .

adjusting to the reorganization differed across field offices .

at one field office , staff resisted the reorganization because they did not want to become specialists and they recognized that technical assistance to the phas suffered as a result .

for example , the staff now disagree over who is responsible for overseeing certain pha operations .

they also have resisted working together to provide technical assistance and have not been sharing phmap information to develop the best plan for correcting management deficiencies .

other field offices we visited adapted to the reorganization .

staff in these field offices worked cooperatively to build on the skills of the experienced staff .

for example , one field office continues to assign each housing authority to only one staff member who provides or coordinates all technical assistance to that authority .

the responsible staff member , however , belongs to a team of staff from all operational areas who work together to solve each pha's problems .

officials at hud headquarters , including the deputy assistant secretary for public and assisted housing operations , acknowledged that some field offices had difficulty adjusting to the reorganization .

they stated that although adequate training was crucial to the reorganization's success , some field offices either did not seek it or did not take the need for it seriously , despite the availability of training funds for field staff .

hud officials continue to emphasize the importance and availability of training and expect field office management to assess the staff's skills and expertise and request the appropriate training .

these officials believe that because of limited staff resources , now and in the future , the reorganization is the best way for field offices to provide effective oversight and technical assistance to phas .

furthermore , they believe that managers of the field offices must take a more active leadership role in directing their staff to work together .

the act and hud's requirements for how field offices use phmap provide for several tools to guide improvements in a housing authority's performance and thereby raise its indicator grades and phmap score .

these tools include the memorandums of agreement ( moa ) , improvement plans , confirmatory reviews , and the annual independent audits .

while such tools as moas and improvement plans generally apply to phas designated as troubled or failing specific indicators , a confirmatory review is mandatory for any pha coming off hud's troubled list and an independent audit is mandatory for all phas .

nonetheless , we found that the compliance of field offices with statutory requirements and hud's guidance for using these tools has been inadequate and infrequent .

furthermore , hud has not determined whether these statutory or agency requirements are effective , adequately improve housing authority performance , or help the field offices better target limited technical assistance resources .

as a result , hud has little information to determine which of these tools best improve a pha's performance and which tools its field offices can use most effectively to offset their declining resources .

over 90 percent of the field offices we surveyed reported that on - site visits to the housing authorities were one of the most effective means to ensure compliance with phmap requirements and provide technical assistance .

officials at one field office responded that phas under its jurisdiction believed that on - site visits from hud staff to provide technical assistance were essential to maintaining effective operations .

yet , most field office staff we visited made fewer personal visits to housing authorities than they felt were necessary because of limited staff resources and travel funds .

field office staff told us , for example , that their workload has increased because their offices have been unable to replace staff who have left the agency .

with less time available for on - site visits , direct monitoring of the phas' performance has occurred less frequently .

in addition , some field office staff said that they could rarely justify to their management using limited staff and travel resources to visit a pha that is more than a 1-day trip from the office unless that authority's phmap score was below 60 .

although hud is required by law to enter into moas with troubled housing authorities to improve management performance , few field offices have done so .

figure 2.1 shows that the percentage of troubled phas operating under an moa has been decreasing since 1992 .

furthermore , in fiscal year 1995 , only 3 of hud's 32 field offices that had troubled phas were fully in compliance with the requirement to enter into an moa with each troubled authority .

the primary reason hud's field offices told us that they did not enter into these required agreements with troubled housing authorities is that the phas had already corrected or were in the process of correcting their management deficiencies .

however , hud headquarters officials told us they did not accept this as a valid reason for not meeting the requirement and questioned how the field offices could be sure the housing authorities were no longer troubled .

when a pha fails any of phmap's 12 performance indicators , hud requires the responsible hud field office to obtain a plan from that pha for improving its performance and to track its progress against the plan .

however , we found that nearly a third — 31 percent — of hud's field offices had not ensured that local housing authorities had developed these plans .

we also found examples of phas' plans lacking specific strategies and time frames for correcting management deficiencies .

for example , one pha's plan for a failing “rents uncollected” indicator simply stated that the housing authority would start collecting rent .

although field office staff acknowledged that the pha also needed to update its standard tenant lease and develop a rent collection policy to improve this indicator grade , they said that they had not yet had the time to contact the pha to revise its plan .

hud requires its field offices to monitor the progress of housing authorities in implementing improvement plans to ensure phas meet the quarterly and annual performance targets in their plans .

however , four of the five field offices we visited told us they do not follow up with the phas to determine the status of improvement plans or whether the plans had corrected the management deficiencies .

field office staff said that they did not have time to track the effectiveness of the plans because their workloads have been increasing due to decreasing numbers of staff .

hud headquarters officials confirmed that systematic tracking of the field offices' success in obtaining improvement plans or executing moas has not been done .

they emphasized that responsibility for implementing phmap rests with the field offices and said that limited efforts were underway to ensure field offices do more to use these tools and measure their effectiveness .

however , they could not tell us whether troubled phas without moas had improved their scores and left the troubled list without such oversight , nor could they tell us whether improvement plans are instrumental in improving indicator scores .

one of the key challenges hud faces in the coming years is effectively downsizing the department while maintaining the needed level of oversight at public housing authorities .

however , hud is currently not maintaining a consistent , minimally acceptable level of oversight at all housing authorities because of the variance in how field offices interpret their roles to provide that oversight as well as their lack of systematic compliance with follow - up requirements .

furthermore , because field offices are not making enough use of the independent audits' verification of phmap data to target their technical assistance , hud is not using the resources it has to effectively determine which housing authorities' scores are most likely to be inaccurate .

as a result , hud is not ensuring that the housing authorities most in need of oversight and assistance are receiving it and thereby improving their performance .

continued departmental downsizing likely will cause hud to leverage its existing resources to achieve a minimally acceptable level of oversight .

this oversight is needed for hud to be reasonably confident that all housing authorities are using federal funds appropriately , managing and maintaining their developments properly , and reporting accurately their performance information .

to make better use of the limited resources it has to devote to the oversight of public housing , we recommend that hud provide guidance to its field offices that clearly ( 1 ) articulates their minimally acceptable roles regarding oversight and assistance to housing authorities and ( 2 ) emphasizes the importance of using the results of the independent audits to better target hud's limited technical assistance resources .

hud agreed with our findings regarding oversight of public housing authorities and stated that it has begun taking steps to address this recommendation .

these steps include a wide variety of training and other activities to ( 1 ) explain the revisions hud is making to phmap ; ( 2 ) reemphasize the need for and importance of statutory and agency follow - up requirements , such as memorandums of agreement , improvement plans , and confirmatory reviews ; and ( 3 ) update hud's guidance to its field offices regarding their phmap and other oversight responsibilities .

according to a hud database of phmap scores , average phmap scores have increased over the life of the program from an average of 83 in 1992 to 86 in 1995 ( the last year of complete data ) .

the number of high - performing housing authorities increased , with more than half of all authorities designated high performers in 1995 , and the number of troubled authorities decreased .

however , the smallest housing authorities — those with fewer than 100 units — now make up a greater proportion of those designated troubled than when the program began .

during our analysis of this database , we found omissions of key data , such as the number of units under a pha's management and its performance designation .

we also found inconsistencies between phmap scores and the assigned performance designations .

notwithstanding these weaknesses , the database represents the most complete data available on pha performance over time .

nationwide , average phmap scores generally increased over the 4 years of the program for which we analyzed data .

by 1995 , over half of all public housing authorities were high performers .

subsequent analysis showed little regional variation in how well they scored on phmap .

while the overall increases in phmap scores held true for all sizes of phas , the largest ones had scores consistently lower than the national average .

with average scores increasing , the number of phas with scores low enough for hud to designate them as troubled also decreased .

the number of troubled authorities reached 83 in 1995 , with half of that total consisting of the smallest housing authorities ( those managing fewer than 100 units ) .

the average phmap score for all housing authorities rose from about 83 in 1992 to 86 in 1995 .

this increase held true for phas of all sizes , although large phas — those with more than 1,250 units — consistently scored lower than the national average ( see table 3.1 ) .

in fiscal year 1995 , 151 large phas accounted for approximately 5 percent of all phas reporting phmap scores , but they operated nearly 60 percent of all public housing units .

consequently , while more phas had higher scores , more units were under the control of phas with somewhat lower scores .

appendix i provides average phmap scores for phas for all of hud's field offices for fiscal years 1992 through 1995 .

by fiscal year 1995 , more than half — about 57 percent — of all public housing authorities were designated as high performers .

as shown in table 3.2 , the number of high performing authorities grew each year , rising from 1,033 ( 33 percent ) in 1992 to 1,791 ( 57 percent ) in 1995 .

also , by 1995 , nearly 50 percent of all public housing units were under the management of high - performing authorities .

our analysis showed little regional variation in phmap scores .

the regional differences we found were slightly greater than those associated with the size of housing authorities , but no region was significantly below the national average .

likewise , there was little variation among the regions in the percentage of troubled phas under their jurisdiction .

for example , in fiscal year 1995 , 5 percent of all phas nationwide were troubled , but within the 10 regions we analyzed , the percentage of troubled housing authorities ranged from 2 to 9 percent .

appendixes i - iv provide detailed information on average phmap scores as well as the number of troubled , standard - and high - performing phas , respectively , for each hud field office .

despite some improvement in overall scores , some indicators were more problematic for phas than others .

as shown in table 3.3 , with the exception of 1 year , phas consistently had the most difficulty with the energy consumption indicator — which had the highest failure rate for 1992 , 1994 , and 1995 .

similarly , the indicators for unit turnaround , tenants accounts receivable , and operating expenses proved troublesome , with 10 percent or more of all phas failing them in 1995 .

a hud official explained that the high failure rate in 1993 for the indicator measuring resident initiatives occurred because the phas were not paying attention to this indicator .

in 1992 , all phas received an automatic “c” for this indicator because hud had not provided enough information on the requirements for grades “a” through “f” until after the assessment period started .

this official said that many phas assumed they would receive an automatic “c” the next year as well , even though hud had stated in 1992 that the automatic grade was a one - time occurrence .

this official added that most field offices followed up by providing technical assistance to the phas with failing grades and were able to resolve the problems in the following year .

this appears to be supported by the decline of the failure rate over the following 2 years to less than 6 percent in 1995 .

while the total number of troubled housing authorities declined — 130 were troubled in 1992 compared to 83 in 1995 — more of those phas were concentrated among the smallest housing authorities than when the program began .

the percentage of troubled phas that were small — managing fewer than 100 units each — grew from 32 percent of all troubled authorities in 1992 to 49 percent in 1995 ( see fig .

3.1 ) .

we found missing , inaccurate , and inconsistent data in hud's smirph database , the primary database for storing phmap scores .

a hud official attributed these problems to data input problems at the field offices .

although hud headquarters makes regular , periodic use of this database , it must also manually verify much of the information before providing it to hud's secretary , members of congress , and others .

hud's general deputy assistant secretary for public and indian housing acknowledged that the smirph database , as currently implemented , does not produce a complete , accurate list of troubled phas and that hud is in the process of making it more reliable and useful .

we found that the number of troubled authorities ( 150 ) for fiscal year 1995 that we derived from the database was inaccurate when we compared it to the number reported ( 83 ) as of december 20 , 1995 , by hud's management assessment coordinator .

we also found performance designations that were inconsistent with phmap scores .

in 1995 , for the 150 phas we found to be troubled , hud had designated 42 as high performers , 7 as standard , and 51 had no designation .

among high - performing phas in 1995 , of the 1,791 phas that we found that had phmap scores of 90 or higher , hud had designated one as troubled , 43 as standard , and 325 had no performance designation .

we also found some omissions in the database .

data , such as the number of units and performance designations , had not been entered for all phas .

for example , we found that the database did not have size information on 18 phas from fiscal years 1992 through 1995 .

we also found that no designations had been entered for 132 phas with scores less than 60 and 1,037 phas with scores 90 or higher .

hud's management assessment coordinator stated that these problems with missing , inaccurate , and inconsistent data occurred because field offices either ( 1 ) did not enter the information at all or ( 2 ) entered it incorrectly .

these instances of inconsistent or missing data suggest that basic system safeguards do not exist to prevent field offices from making these data entry errors or omitting essential phmap data .

while hud officials who oversee phmap and the department's field offices acknowledged problems with the database , they added that the program's redesign includes changes that will address the problems with data accuracy and reliability .

hud officials told us they plan to change procedures for entering information on phas into the database to allow field offices to update pha data on a real - time basis and to make immediate corrections when they find errors or omissions .

these procedural changes will also enable hud headquarters staff to access field office data directly and allow ongoing reviews of the information for accuracy and completeness .

hud officials also believe that the changes will increase control over the information from the field offices and help ensure that the information in the smirph database is accurate .

hud expressed concern that our draft report used data from the smirph database that hud had not verified for accuracy .

hud noted that it is making changes to the database that will improve headquarters' ability to find and correct data errors that have been entered by staff at its field offices .

to address hud's concern that we used inaccurate , unverified data from its database to analyze phmap data on housing authorities' scores by size and region , we recalculated the number of troubled housing authorities by size category for 1995 using data hud verified with its field offices ; we also modified this report to reflect a more accurate and lower number of troubled housing authorities in 1995 .

recalculating the number of troubled authorities by size did not change our conclusion that a greater proportion of the authorities that hud verified as being troubled are those with fewer than 100 units .

in fact , while hud's database indicates that 44 percent of troubled authorities in 1995 were small , hud's verified list of troubled authorities indicates 49 percent were small .

furthermore , although hud officials told us that a manually - verified list of troubled authorities for 1992 was not available , they agreed with our conclusion that the smallest housing authorities make up a greater proportion of troubled housing authorities in 1995 than in 1992 .

because our draft report presented no analysis of data on a regional basis ( only data as drawn from hud's database ) and because we draw no conclusions in that regard in this report , we have retained appendixes i - iv , which show average phmap scores and the number of troubled , standard , and high - performers in hud's regions .

where hud provided us with manually verified data — particularly in appendix ii showing troubled authorities — we have modified the appendixes to reflect the more accurate data .

our review and those of others indicate that phmap scores are often inaccurate , imprecise , and must be changed when hud verifies the data that public housing authorities have submitted to support their scores .

furthermore , professional property managers and others in the public housing industry question whether phmap can capture all aspects of management operations .

although hud has taken some steps to help ensure that future scores are more accurate than they have been over the program's first 4 years , these steps will be resource - intensive and do not address all of the program's limitations .

in the past , both hud and the congress have proposed additional uses for phmap , such as deregulating and awarding bonuses to phas with high phmap scores .

however , until greater confidence exists that individual scores are accurate and hud brings greater validity to phmap as a comprehensive measure of management operations , such additional uses for the program may not be appropriate .

after performing on - site reviews of selected phas to confirm the accuracy of their phmap scores , hud's field offices changed half of the scores .

in commenting on this report , hud indicated that most confirmatory reviews involved high - risk phas , whose phmap data have been most susceptible to being found inaccurate .

in similar reviews , hud's independent assessment contractors as well as hud's ig found that many scores or grades for specific indicators were inaccurate .

to better identify phas that need oversight and technical assistance , hud staff often supplement their decision - making with other measures of management problems to get a more complete picture of an authority's performance .

professional property managers and industry representatives agreed that more information is needed than phmap provides to give a complete picture of how well a pha's management is performing .

after performing confirmatory reviews of 200 phas in fiscal year 1995 , hud's 49 field offices changed 98 phmap scores ( see table 4.1 ) .

in several cases , the changes hud made to phmap scores also meant hud would have to change the performance designation of those phas .

for example , hud lowered the scores of 14 phas enough to designate them as troubled , raised the scores of 4 troubled phas to 60 points or higher , and raised the scores of 10 standard - performing phas to 90 or higher .

both of hud's independent assessment contractors as well as hud's ig have reviewed phmap data to confirm the accuracy of phas' scores .

for example , in 1993 , the ig confirmed the scores of 12 housing authorities .

as a result of this review , the ig concluded that the phmap scores for 9 of the 12 phas should be lowered because 3 of them fell below 60 , a score which should have warranted the troubled designation .

in a second report on phmap , the ig reported that six of hud's field offices reduced over half of the scores they reviewed .

similarly , one of hud's independent assessment contractors reported that for the 30 assessments it has performed at troubled housing authorities , it found 21 indicator grades and / or phmap scores that were inaccurate .

over 50 percent of the contractor's assessments resulted in lowering the indicator grades to an “f.” the contractor most often lowered the indicators used to measure outstanding workorders and annual inspections of housing conditions and systems .

several reasons explain why hud and others changed so many phmap scores after performing a confirmatory review .

some field office staff said these scores changed because the phas did not understand all the requirements of phmap and therefore misreported their data .

they also told us that phmap is particularly difficult for smaller housing authorities whose limited staff can find hud's paperwork requirements overwhelming .

hud staff do not believe many phas intentionally try to deceive the department by reporting false phmap information .

instead , they , as well as the contractor staff , said that the phas often have insufficient documentation to support the data they must submit to the field offices or do not understand how hud wants them to report the information .

for example , while a pha may report the average number of days their housing units have been vacant , the pha may not have the tenant files to document when the previous tenants moved out and when the new tenants' leases took effect .

without supporting documentation or evidence of a system to track unit turnaround , hud assigns an “f” to this indicator .

similarly , a pha may be providing support programs for its residents , but fail to understand that its board of commissioners must approve those programs to receive a passing grade on phmap's indicator for resident initiatives .

typically , when hud's field office staff find examples , such as these , during a confirmatory review , they use the correct data to recalculate the housing authority's grade for each of the affected indicators .

hud's field office staff did not use phmap alone to assess the management performance of its public housing authorities .

although they agreed that phmap accurately identifies troubled authorities , several staff said that they consider other factors besides phmap indicators to supplement their decision - making for the other authorities they oversee .

they said that some phas with scores over 90 have management problems that the program's indicators do not measure .

other factors used by some hud staff to identify the potential for management problems at standard - and high - performing authorities include the failure of a pha to implement consistent and effective operating policies and procedures , the frequency of changes in the executive leadership and the continued interference into a pha's daily operations by its board of commissioners , the number and the type of telephone calls received from a pha's residents and staff , and any adverse news stories about a pha .

staff at the five field offices we visited said that they believed some housing authorities with high phmap scores were not operating their housing programs efficiently or effectively .

these field offices differed , however , in how they treated those phas .

staff at two field offices told us that although they use the scores to determine which phas need on - site reviews , they would not let a high score prevent them from visiting an authority they believed had serious management problems .

the hud ig also questioned whether or not phmap scores accurately measure the management performance of public housing authorities .

the ig's reviews of high - and standard - performing phas found instances of fraud and program abuse .

for example , the ig reported that the executive director of a high - performing pha had charged over $62,000 in ineligible expenses , including excessive compensatory time , unsupported travel costs , and health and insurance benefits for his divorced spouse .

another pha executive director falsified phmap data to obtain a high - performing designation .

after reviewing the operations of a standard - performing pha , the ig also cited numerous program abuses and mismanagement .

the ig concluded that although phmap could be a useful tool to assess phas , the program was too unreliable for hud to make oversight decisions .

other public housing professionals — property managers and those representing industry associations — agreed that more information is needed than phmap provides to give a complete picture of how well a pha is managed .

for example , they noted that phmap does not automatically include an on - site observation and inspection of a pha's housing developments .

one association noted that while a pha could improve its phmap score by simply writing off more past due rents from former tenants as uncollectible to improve its grade on the indicator for rents uncollected , its phmap score would not measure how diligent an effort it had undertaken to collect the rent .

another industry association official knew of several examples of phas that were making good property management decisions , such as choosing to perform deferred maintenance when a unit became vacant rather than rent it immediately , that ironically led to lower phmap scores .

citing a similar situation , hud has agreed that occasionally the best decision for a pha is to take an action that yields a lower phmap score , and that the score should not be the sole driving force influencing a pha's decisions .

while hud's primary use of phmap has been to identify troubled housing authorities and target technical assistance to them , the congress and hud have proposed to use this program for other purposes .

in 1994 , the senate committee on banking , housing , and urban affairs proposed some deregulation and additional flexibility for those authorities that had achieved phmap scores of 90 or above .

in addition , in its fiscal year 1997 budget request , hud proposed to give high - performing phas bonuses based in part on their phmap scores .

because phmap scores do not always measure the true management performance of the phas , the benefits of these proposals need to be weighed against the possibility of granting undeserved flexibility and awards .

to encourage individual phas to be more innovative , the banking committee proposed limited deregulation and additional flexibility for high - performing phas in two ways .

first , it proposed permitting a pha that generates income over a certain level to exclude that income from calculations of its need for a subsidy from hud to operate and manage its properties .

at that time , each dollar of extra income that a pha generated reduced its subsidy by a dollar , thereby creating a disincentive to generate additional income from sources other than rent .

second , the committee proposed to waive all but a few key regulations — such as nondiscrimination , equal opportunity , and tenant income eligibility — so high - performing phas could have more flexibility to bring innovative solutions to local problems and achieve more efficient operations .

in its fiscal year 1997 budget request , hud proposed to award $500 million to high - performing phas as bonuses based , in part , on their phmap scores .

as we reported in our testimony in june 1996 and as we found in the course of our work on this report , hud does not confirm the scores of high performers and generally accepts them .

in our june 1996 testimony , we recommended that the congress consider not appropriating the bonus funding until hud develops adequate performance measures and supporting information systems .

the hud appropriations bill which the congress approved and the president signed did not contain funding for performance bonuses .

the three associations representing the public housing industry and the professional property managers that we interviewed all opposed or had strong reservations about using phmap scores for purposes other than identifying troubled housing authorities and targeting technical assistance to them .

they also believed that other uses would be inappropriate because of the limited number of confirmatory reviews the field offices perform and the proportion of phmap scores that have been changed after a review .

two of the associations did not believe that phmap scores adequately measured the management performance of housing authorities because they thought some phas that received high scores did not provide their residents with decent , safe housing .

the professional property management firm that independently verified some scores also agreed that the usefulness of these scores is limited .

because this firm has recommended lowering many scores after an independent assessment , the firm lacks confidence in the scores' accuracy and does not believe that the program provides enough information about the management performance of phas for hud to make effective funding decisions .

in recent years , both the congress and hud have proposed additional uses for phmap , such as bonuses to reward those housing authorities with the highest scores .

while phmap has provided a quantifiable means to assess the management performance of housing authorities , the scores are not sufficiently accurate for detailed comparisons of performance .

although hud is currently working to enhance the accuracy of these scores , they do not yet provide a comprehensive , generally accepted way to assess the performance of phas .

to be useful for other purposes , not only would these scores have to be more accurate , but the program would have to be expanded to provide a more comprehensive measure of public housing authorities' management operations .

because hud does not frequently confirm most scores — confirmatory reviews have focused on troubled phas — hud does not know how many authorities are not receiving the proper designation .

when hud does confirm scores , it changes half of them — and more than half of these changes result in hud's lowering the score .

we found that when hud lowers a phmap score , it does so by an average of 14 points .

if this average change held true for housing authorities in general , then hud may not be properly designating as troubled those authorities currently scoring between 60 and the low 70s whose scores should be lower .

as a result , those authorities are not receiving the oversight and technical assistance hud should be providing to improve their performance .

we recommend that until it establishes a cost - effective means to ensure consistently accurate scores , hud should not consider additional uses for phmap , including using its scores as criteria for funding bonuses , until it determines that phmap meets an acceptable level of accuracy and more comprehensively measures property management performance and require its field offices to confirm the phmap scores of housing authorities with scores low enough that they are at risk of being designated troubled .

hud agreed with our findings and recommendations .

when we met with hud officials , including the general deputy assistant secretary for public and indian housing , to discuss a draft of this report , they told us that the department is no longer considering additional uses for phmap , such as using scores as criteria for funding bonuses .

even in the absence of using phmap for such purposes , we believe that it is important that hud works to ensure scores are more consistently accurate and have , therefore , retained this recommendation .

hud has begun taking steps to address our recommendation that it confirm phmap scores of those housing authorities that are at risk of being designated troubled but expressed concern that it may not have sufficient resources to fully implement this recommendation .

hud expressed three concerns relating to the information and conclusions presented in this chapter of our report .

hud believed that this chapter ( 1 ) assumes that phmap was intended to be an all - inclusive assessment system for property management , ( 2 ) does not place phmap in a historical perspective , and ( 3 ) reaches incorrect conclusions regarding the overall reliability of phmap scores .

we do not believe that we characterize phmap's purpose as being an all - inclusive measure of property management .

our discussion of the program does not state that this is the purpose of phmap .

rather , the report discusses how the program's limitations — including its intentional design not to be a complete performance measure — affect its suitability for additional purposes , such as those proposed in recent years by hud and the congress .

hud agreed that there is a perception that phmap is an all - encompassing system to assess the performance of phas and stated it is taking steps to address this misperception .

seeking to clarify the program's purpose , hud added language to its recently revised interim phmap rule ( published in the december 30 , 1996 , federal register ) , that the program's indicators reflect performance in only specific areas .

hud correctly states that this report does not provide a historical perspective of phmap by discussing previous hud systems for assessing and identifying troubled housing authorities .

we believe that such information would not contribute substantially to our report's three objectives to evaluate hud's use of the current program , provide trends in phmap scores from fiscal years 1992 through 1995 , and discuss limitations in the program's design and implementation that affect its usefulness for purposes other than identifying troubled housing authorities and targeting assistance to them .

therefore , we have not added the historical information hud suggested to the report .

finally , hud is concerned that we have incorrectly reached conclusions about the reliability of all phmap scores based on the results of confirmatory reviews of high - risk authorities .

hud noted that the accuracy of the scores of these phas does not necessarily represent the accuracy of all phmap scores because the data provided by these phas are most susceptible to being inaccurate .

our report did not reach a conclusion about the reliability of all housing authorities' scores because of the changes that resulted from confirmatory reviews .

this report discusses the reliability of phmap scores for housing authorities whose scores are low enough that they may be at risk of being designated troubled .

we have added language to the report to clarify this point .

