both the federal government and private entities are attempting to enhance the quality and efficiency of health care by shifting from rewarding physicians and other providers based on the volume of their services to rewarding them based on the value of those services — quality and efficiency of care .

however , finding a practical way to accurately and credibly identify and then promote high quality and efficient care is a complex task .

an approach adopted by some groups , such as medical specialty societies and regional health improvement collaboratives , has been to develop clinical data registries ( cdr ) .

cdrs are entities that collect and analyze detailed information on the therapies that patients receive and changes in their clinical condition over time in order to evaluate and improve care practices and outcomes .

in recognition of the potential of cdrs to promote the quality and efficiency of care in the medicare program , the american taxpayer relief act of 2012 ( atra ) instructed the department of health and human services ( hhs ) to establish a new program to designate “qualified” cdrs .

this program could encourage more physicians treating medicare beneficiaries to participate in cdrs and thereby engage in the process of collecting detailed clinical information and using it to improve the quality and efficiency of care .

cdrs can analyze variations in treatment and outcomes ; examine factors that influence prognosis and quality of life ; describe care patterns , including appropriateness of care and disparities in the delivery of care ; assess effectiveness ; measure the quality of care ; and study quality improvement .

proponents contend that qualified cdrs would generate data of greater relevance , depth , and credibility to physicians — particularly specialist physicians — than current federal performance assessment programs , and thereby improve quality and efficiency .

the new qualified cdr program will provide physicians with an alternative to participation in hhs's existing physician quality reporting system ( pqrs ) .

pqrs allows physicians to report quality data on services they provide to medicare beneficiaries using measures that physicians select from a menu of hhs - defined quality measures .

hhs provides incentive payments to physicians who satisfactorily report quality data to pqrs , and has announced that physicians who do not satisfactorily meet pqrs submission requirements in 2013 will have their medicare payments reduced by 1.5 percent for services provided in 2015 .

under the new cdr program , physicians who satisfactorily participate in a qualified cdr would also receive the incentive payments and would avoid the penalties without submitting data to pqrs .

hhs issued a final rule and preamble on december 10 , 2013 , that included information on how the qualified cdr program will function .

in the preamble , hhs set out plans for implementing the atra requirements and the definition of , requirements for , and process for being designated a qualified cdr .

the program is scheduled to take effect in january 2014 .

atra mandated that gao report on the potential of cdrs to improve the quality and efficiency of care in the medicare program and the role of health information technology ( it ) in facilitating cdrs .

for this report , we examined 1 .

ways cdrs have demonstrated the capacity to improve the quality and efficiency of physician care ; 2 .

hhs's plans for requirements and oversight of qualified cdrs to maximize cdrs' potential impact on the quality and efficiency of care ; 3 .

barriers , if any , to the development of qualified cdrs , and actions hhs can take to minimize their potential impact ; and 4 .

the potential of health it to enhance cdr operations and actions hhs can take to facilitate cdr use of health it .

to examine ways cdrs have demonstrated the capacity to improve the quality and efficiency of physician care , we conducted internet searches and reviewed literature to identify studies assessing the impact of cdrs on quality and efficiency of physician care .

we synthesized the results of these studies in terms of the type , scope , and magnitude of changes in quality and efficiency attributed to cdrs , and assessed the strength and limitations of the evidence produced by those studies .

we also interviewed officials from seven organizations that operate existing cdrs , including regional health care collaboratives , and officials from a major health plan .

these interviews generally included discussion of the type , scope , and magnitude of any changes in quality and efficiency of physician care that they have observed stemming from the activities of cdrs .

we selected cdrs that cover patient care across a range of medical conditions , focusing on those that have operated for a number of years and on organizations that have extensive experience using cdr data .

to examine hhs's plans for requirements and oversight of qualified cdrs to maximize cdrs' potential impact on the quality and efficiency of care , we interviewed hhs officials and reviewed hhs documents on the department's plans for implementing the qualified cdr program , including both a proposed and final rule and the accompanying preambles , which were published in the federal register during the period of our review .

in addition , we convened an expert meeting with the assistance of the national academies' institute of medicine ( iom ) to discuss potential requirements for qualified cdrs , the advantages and disadvantages of these requirements , and the oversight that hhs could provide to qualified cdrs to promote the quality and efficiency of care .

we worked with staff at iom to identify experts to participate in the meeting .

generally , participants were chosen for their expertise in operating or launching a cdr , as health plan officials or other users of cdr data , as health it professionals , or as clinical researchers .

representatives from the centers for medicare & medicaid services ( cms ) — the hhs agency charged with implementing the program — and hhs's office of the national coordinator for health information technology ( onc ) also attended the meeting .

to ensure that participants represented a broad range of views and interests and that we fully understood those interests , we required that participants complete a conflict of interest form .

see appendix i for a list of experts who participated in the meeting .

we synthesized the experts' comments at the meeting together with other relevant sources , including related published literature , to assess the potential impact of different program requirements and approaches to providing oversight of those requirements on the effectiveness of qualified cdrs in promoting quality and efficiency of care .

to identify barriers , if any , to the development of qualified cdrs and actions hhs can take to minimize their impact , we interviewed officials and reviewed documents from cms on its plans for implementing the qualified cdr program .

we also obtained input from participants during the expert meeting on barriers to the development of qualified cdrs and on what support hhs could provide to reduce these barriers .

we synthesized the experts' comments at the meeting together with other relevant sources , including related published literature , to assess the potential impact of selected actions hhs could take on overcoming the identified barriers to the development of qualified cdrs .

to examine the potential of health it to enhance cdr operations and actions hhs can take to facilitate cdr use of health it , we reviewed documents and interviewed officials from cms and onc on the agencies' plans related to it for the qualified cdr program .

we also interviewed officials to determine how cdrs interact with electronic health record ( ehr ) systems used by many providers .

in addition , we obtained input from participants during the expert meeting on the potential of health it to facilitate cdr operations .

in addition to receiving input from meeting participants , we also interviewed health it experts who have been involved in applying health it to the operations of existing cdrs .

we conducted this performance audit from march 2013 to december 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

over the past 25 years , a broad range of entities — encompassing the federal medicare and medicaid programs , private health insurers , and various provider organizations — have created different systems for assessing physician performance , of which pqrs and cdrs are examples .

early efforts largely focused on the quality of care ( i.e. , the extent to which patients received care that was likely to improve their health status ) .

more recently , the focus of many of these systems has expanded to include the efficiency of care ( i.e. , the extent to which high - quality care was provided without using more resources than necessary ) .

in concert with these performance assessment systems , some public and private payers have begun to provide incentives to physicians based on their performance to stimulate improvement over time .

these physician performance assessment systems have developed a wide range of performance measures .

some are process measures , which assess the extent to which physicians effectively implement clinical practices ( or treatments ) that have been shown to result in high - quality or efficient care .

others are outcome measures , which track the results of physician care , such as mortality , infections , and how patients experience that care .

to assess performance on such measures , these systems have collected information from administrative data sets , including billing data , as well as from patient medical records and patient surveys .

measures used to assess physician performance are composed of a number of clinical data elements , or pieces of data , that must be collected in order to determine performance .

for example , the performance measure endorsed by the national quality forum ( nqf ) for acute stroke mortality rate comprises two data elements — the number of stroke patients treated and the number of deaths among those patients.measures are more complex and require more data elements .

many of these assessment systems evolved independently and therefore are very different from one another .

for example , there is great variability among existing cdrs , which range from those developed by medical specialty societies to those developed by regional health care improvement collaboratives .

one of the longest - standing cdrs focused on physician care is the society of thoracic surgeons' ( sts ) adult cardiac surgery database , which was established in 1989 in response to hhs's publication of mortality rates for individual thoracic surgery programs .

according to the sts , hhs's published rates were misleading because they had not been adjusted adequately for variations in the complexity of patients treated by different programs .

the most complicated and highest - risk cases typically have the highest mortality rates , independent of the quality of the surgeon's performance .

so the sts developed nationally benchmarked performance data with empirically tested risk adjustment models based on detailed clinical variables .

since then , additional cdrs have been developed by medical specialty societies , such as the american college of cardiology ( acc ) and the american college of surgeons , as well as by regional health care improvement collaboratives , such as minnesota community measurement and the wisconsin collaborative for healthcare quality .

the profusion of these different systems has created difficulties for those involved in using and maintaining them .

for example , physicians , along with other providers , have found it burdensome to provide data on multiple performance measures to multiple public and private physician performance assessment systems , which has led to efforts to align these systems .

for example , cms has announced its intention to maximize the extent to which physicians can satisfy its different performance assessment programs by submitting one set of data .

there have also been efforts to develop a consensus among public and private groups concerning top priority objectives for improvement .

for example , in 2011 the secretary of hhs issued a national quality strategy based on input from major health care stakeholders , which established six broad priority domains .

however , efforts to bring various systems into greater alignment based on specific national priorities are complicated by the diversity of care that physicians provide .

for example , primary care physicians treat patients with conditions that fall under nearly 400 different diagnostic categories , making it difficult to assess their performance appropriately with a limited number of measures .

collectively , specialist physicians also encompass a broad range of conditions and treatments .

while some dimensions of quality and efficiency may apply broadly across most physicians , such as the extent to which they coordinate their care effectively with a patient's other care providers , other important aspects of physician performance are distinct for different medical conditions .

physicians are increasingly using ehrs to collect and report the data needed for performance assessments , in part as a result of direct governmental encouragement .

hhs's medicare and medicaid ehr programs provide incentive payments to eligible participants as they adopt , implement , or upgrade certified ehr technology and demonstrate its meaningful use .

to receive these incentives , eligible providers , including physicians , must first adopt ehr technology that is certified specifically for the ehr incentive programs .

certified ehr systems must meet specific criteria , including having the ability to store data in a structured format to facilitate retrieval and use of the data by other systems , and having the capability to collect and report data on a large number of clinical quality measures defined by hhs .

physicians must then demonstrate that they are using their certified ehr systems in meaningful ways that can positively affect the care of their patients , including conducting quality assessments using some of the clinical quality measures .

the ehr incentive programs , which began in 2011 , are scheduled to be implemented in three stages .

stage 1 is focused primarily on data capture and sharing .

stage 2 is scheduled to begin in 2014 and will focus on improving selected clinical processes .

stage 3 is expected to begin in 2016 and to focus on improving quality , safety , and efficiency outcomes .

cdrs have demonstrated a particular strength in assessing physician performance through their capacity to track and interpret trends in health care quality over time .

this strength derives from the fact that cdrs typically collect extensive , standardized clinical data on large numbers of patients that provide more clinical detail than can be obtained from administrative data .

those clinical data provide the basis for developing sophisticated risk models , which enable cdrs to compare physician performance with appropriate adjustments for variations in the severity level and other attributes of the patients they treat .

cdrs also collect extensive , standardized data on treatments provided to large numbers of patients over extended periods of time , which permits cdrs to explore in depth how treatment variations affect patient outcomes .

moreover , cdrs collect information about many different types of patients encountered by physicians , including those with complex combinations of medical conditions , who are often excluded from clinical research studies .

this enables cdrs to analyze trends for the full population of patients that participating physicians actually treat , and examine variations across many different subgroups of patients .

studies examining outcomes reported by several long - established cdrs demonstrate the utility of cdr data for analyzing trends in both outcomes and treatments .

for example , cdr data on treatment of acute myocardial infarction over 15 years show major increases in guideline - recommended treatment and a 39 percent reduction in overall mortality .

similarly , results from the sts adult cardiac surgery registry show substantial improvements in mortality and morbidity rates for coronary artery bypass graft surgery — 24.4 percent lower mortality and 26.4 percent lower postoperative stroke over 10 years — that were linked to refinements in data from other cdrs have highlighted clinical surgical techniques.areas where quality improvements have been more mixed , such as a medical oncology cdr that showed marked improvements over 5 years only on measures of whether providers had adopted new clinical practices , while other measures of clinical quality remained relatively high on some dimensions and low on others .

another study presented comparable results for a state - based cdr assessing primary care .

it found major improvements over 6 years on some measures , such as kidney function monitoring for diabetic patients , but considerably less improvement on others , such as lipid testing and control for patients with coronary artery disease .

cdr efforts to improve outcomes typically involve a combination of performance improvement activities , including feedback reports to participating physicians , benchmarking physician performance relative to that of their peers , and related educational activities designed to stimulate changes in clinical practice .

officials of the cdrs from which these results were reported described to us a range of educational materials and related activities that they have developed targeted to physicians who do relatively poorly on specific measures .

they generally view these additional education activities as essential to achieving improved performance .

using a within - registry , national - level randomized controlled trial , one study of the sts registry demonstrated a positive impact from providing surgeons with educational materials targeted to key process measures related to cardiac surgery .

another study used cdr performance data to assess the effectiveness of a health plan's interventions to promote changes in practice .

specifically , it found that physician groups participating in the health plan's regional collaboratives had lower risk - adjusted mortality and better composite quality scores over time than physician groups in other states who participate in these cdrs .

compared with their efforts related to quality , cdrs have typically provided less insight on ways to improve the efficiency of care .

for example , none of the studies of cdr results that we examined addressed changes in the cost of care directly .

however , studies of cdrs focusing on surgical care reported improvements on several measures related directly or indirectly to the use of resources , such as rates of complication .

the potential to draw inferences about costs from rates of complications was demonstrated by researchers affiliated with michigan blue cross and blue shield .

they used cdr data to estimate that their regional surgical collaborative had led to 2,500 fewer patients with surgical complications per year , which — when considered with the average cost of those complications — translated to annual savings of about $20 million .

one reason why cdrs have not typically assessed the cost of care is that their data have usually been limited to information available from patient medical records recorded during the course of treatment , including patient risk factors , process measures concerning the treatments provided , and short - term outcomes such as inpatient mortality and morbidity .

these data do not typically include information on costs as well as other information relevant to assessing longer term outcomes and changes in patient functioning ( eg , patient - reported outcomes ) .

to obtain this information , cdrs need to turn to other data sources , as some have started to do .

for example , the sts has begun , for specific research projects , to obtain medicare claims data and merge those data with its own cdr data to examine costs and long - term outcomes .

the results reported to date from existing cdrs are also limited in terms of their scope and capacity to determine the independent impact of cdrs on physician performance .

most of the studies examining the outcomes of cdrs that we found come from a relatively small number of cdrs run by certain medical specialty societies — including the sts for cardiac surgery , the american college of surgeons for general and vascular surgery , and the american society for clinical oncology for medical oncology — plus one ambulatory care cdr run by a regional health care improvement collaborative , the wisconsin collaborative for healthcare quality .

most of these are cdrs that have been in operation for close to a decade or more , and therefore have substantial longitudinal data from which to analyze trends over time .

even within the given specialty or region targeted by the cdr , the scope of care addressed by the studies we examined were typically limited .

for example , the study of cardiac surgery focused on one procedure — coronary artery bypass graft surgery — while the study of ambulatory care in wisconsin examined diabetes , coronary artery disease , and hypertension management plus three cancer screenings and a vaccine .

moreover , cdrs by design collect observational data with no predetermined designation of treatment and control groups , as would be done in a randomized controlled trial .

therefore , it is difficult to use cdr data to assess the independent effect of the cdr on physician performance , relative to other factors .

a few studies have compared cdr results to control groups and found that the cdrs had at least a modest impact on outcomes relative to the controls .

however , these analyses were limited to measures where the same data were available from other sources for both cdr patients and control groups , which means that the data used in those analyses did not have the clinical detail ( or validation ) of the cdr - collected data .

moreover , patients in the control groups also differed to some extent from patients in the cdrs in ways that may affect the results reported .

hhs's plans for cms's implementation of the qualified cdr program include little specificity on how cdrs will improve quality and efficiency .

setting key requirements , with greater specificity , for cdrs to become qualified could help promote improved quality and efficiency of care .

in addition , effective oversight of these requirements depends on expert judgment to take account of variation among cdrs in their circumstances and opportunities for improvement .

cms's plans for implementing the qualified cdr program , when it begins in 2014 , offer little specificity concerning cdr objectives or results and provide substantial leeway for cdrs seeking to become qualified .

cms's plans include certain minimal attributes for entities to be considered , such as having been in existence with at least 50 participants for no less than one year .

in addition , cms's plans include a number of largely procedural performance requirements that qualified cdrs would have to satisfy .

among the most important are data collection: a qualified cdr must collect and report to cms data for at least nine quality measures , at least one of which must be an outcome measure .

collectively , these measures must cover at least the three of the six domains of hhs's national quality strategy.measures should include patient data from multiple payers and be risk - adjusted , where appropriate .

data validation: a qualified cdr must attest to cms that all the data it submitted were accurate and complete , submit a data validation strategy for verifying the accuracy and completeness of data it collected , perform the steps described in its validation strategy and provide cms with evidence of successful results , and make available to cms samples of patient data that cms could use for its own audits of data validity .

data security: a qualified cdr must have a plan to maintain data security and privacy , have appropriate business associate agreements with participating physicians to satisfy federal patient privacy requirements , and use specified methods to transmit quality data to cms in one of two specified data formats .

transparency: a qualified cdr must make publicly available information about its measures , including their supporting evidence or rationale , data elements , and criteria for including and excluding patients .

improvement activities: a qualified cdr must provide feedback reports to participating physicians on their performance at least four times a year , with benchmarks derived from the cdr's own database or external sources .

as a whole , cms's plans provide substantial leeway in key areas regarding what could constitute satisfactory cdr performance .

for example , cms's plans grant cdrs wide latitude in selecting which measures they will collect , as long as they cover three of six national quality strategy domains and at least one is an outcome measure .

similarly , cms's plans state that cdr feedback to participating physicians should include benchmark information , but cdrs will have discretion to determine the appropriate benchmark , either derived from the cdr's own data or drawn from an external source .

the extensive leeway in cms's plans would allow diverse registries to become qualified .

because registries are typically designed to focus on a particular set of patients , defined by medical condition , type of treatment received , or geographical location , they will inevitably vary substantially in their opportunities to promote quality and efficiency of care .

therefore , the broad parameters in cms's plans are compatible with a wide range of cdrs potentially addressing diverse types of physician care .

however , the flexible approach for qualifying cdrs may at the same time provide minimal impetus to cdrs to take full advantage of their specific opportunities to promote the quality and efficiency of care .

for example , cms's plans do not include a process or criteria for assessing the extent to which the measures selected by a cdr in fact address the key opportunities that could result in improved care for its particular target population .

in addition , cms has not provided any details on how it plans to interpret or enforce program requirements for cdrs .

for example , cms has not described what cdrs would need to do to make their data validation strategies acceptable to cms .

nor has it described the minimal thresholds of accuracy and completeness that cdrs would need to attain , which could help cms to audit cdr data as necessary in the future .

cms has also not described how it intends to provide oversight to ensure that cdrs comply with the requirements , beyond having cdrs submit a self - nomination statement , initially on an annual basis .

greater specificity in both the requirements for cdrs and the mechanisms for enforcing them is likely to develop with time .

cms has not yet implemented the qualified cdr program , but in the preamble that accompanied its final rule , cms stated that , as it gains programmatic experience , it anticipates making changes in future rulemaking to the requirements for becoming a qualified cdr .

however , cms has not yet articulated the direction or ultimate goals that it seeks to accomplish through this evolution , except that , to the extent possible , it will seek to align the requirements for cdrs more closely over time with requirements for other federal quality programs .

we identified several key requirements for qualified cdrs that , based on our synthesis of the input from experts at the meeting we convened with the assistance of iom together with other relevant sources , would contribute to improved quality and efficiency of care for medicare patients .

such requirements could affect quality and efficiency both by determining which entities are designated as qualified cdrs and by encouraging certain activities by cdrs after they are designated as qualified .

we identified the following key requirements and assessed the extent to which they are addressed by cms's plans for implementing the qualified cdr program: 1 .

performance measures to address key opportunities: having qualified cdrs focus their data collection on performance measures that address specific opportunities to improve quality and efficiency for each cdr's target population enhances their effectiveness in promoting quality and efficiency overall .

input from experts and other relevant sources indicates that appropriate performance measures would encompass broadly defined measures of patient outcomes , such as patient experience and function , and consider the appropriateness of the chosen treatment , compared to available alternatives .

rationale: for any given patient population , defined by medical condition , treatments received , geographic location , or other attribute , there are a wide range of existing or potential performance measures on which a cdr could focus .

if those measures are not well selected , they may divert the attention of participating physicians to clinical issues that are overly narrow or fail to uncover actual differences in quality and efficiency .

every cdr faces the choice of where it should focus its data collection and analytical resources , though the specific clinical issues that offer the greatest opportunity for improved quality and efficiency will vary from one cdr to another , depending on their target populations and the depth of the evidence base currently established for its field of clinical practice .

cdrs need to make strategic choices that make the most of existing knowledge and strategies for improving quality and efficiency while also helping to incrementally expand that evidence base over time .

comparison to cms plans: cms plans to leave measure selection to the discretion of each cdr , within the broad parameters of covering three national quality strategy domains and including at least one outcome measure .

cms has not described expectations regarding how well targeted those measures are relative to the specific quality or efficiency deficiencies of that cdr's target population .

nor has cms required that cdrs collect information on patient experience and functional outcomes or address the appropriateness of treatments provided .

2 .

core set of measures: input from experts and other relevant sources indicates that having qualified cdrs collect data for a minimum set of core performance measures with standardized definitions and specifications as part of their overall data collection effort would enable cdrs to address broad , shared objectives regarding both quality and efficiency .

rationale: while cdrs are free to collect a wide range of measures reflecting quality and efficiency opportunities in their particular target populations , there are certain measures that apply across the patient populations covered by different cdrs .

some of these relate to national - level quality improvement objectives such as improving care coordination .

in order for cdrs to contribute to these broader national priorities , cdrs could collect the relevant data for their patients in a standardized fashion that permits sharing and aggregating of the data across cdrs and other sources of quality data .

a core measure set would align cdrs with key national level priorities on quality and efficiency , while still allowing for innovation and permitting cdrs to collect other data that address regional or specialty - specific concerns .

comparison to cms plans: cms has not established common measures across qualified cdrs .

to the extent that registries report on different measures within the six national quality strategy domains , they would not produce results that could be aggregated to assess progress overall .

in addition , results could not be compared across different cdrs , which may be useful , for example , to examine cardiac patients receiving medical or surgical treatments .

3 .

data accuracy and completeness: input from experts and other relevant sources indicates that the credibility of cdr results relies on having cdrs implement a systematic and rigorous process for ensuring the accuracy and completeness of the data they collect and analyze .

rationale: assessing physician performance with inaccurate or incomplete data is likely to produce misleading and invalid results .

therefore several existing cdrs have instituted regular external audits of the data submitted to their databases .

however , the appropriate form of systemic and rigorous checking of the data may vary depending on the cdr's focus and method of data collection .

for example , one long - standing cdr has annual external audits conducted of the data it collects , auditing 8 percent of participating physicians in 2013 , to ensure that reported data are accurate compared to the original records from which the data were collected .

auditors also check hospital logs to make sure that data on all eligible cases were submitted .

by contrast , an official for a different cdr that relies on electronic data extraction from ehrs described the use of statistical methods to identify outliers in the data that may indicate a data collection error .

comparison to cms plans: cms's plans state that cdrs must submit a data validation strategy that is acceptable to cms , but cms has not described either the approach or the intensity of the cdr efforts expected .

cms has also not detailed how it would evaluate the strategies for acceptability , or how it might evaluate cdr data for validity .

because data validation tends to be a labor - intensive and expensive activity for cdrs , the absence of specific validation requirements once the program is implemented may cause some cdrs to curtail their validation efforts .

4 .

participation levels: input from experts and other relevant sources indicates that cdrs need to achieve a substantial level of participation to ensure that their results represent the physicians that make up their target population , but for newly established cdrs it often takes time to achieve this level of participation .

rationale: registries that recruit a relatively low proportion of physicians within their target population may not have the data needed to support accurate risk adjustments and benchmarking .

however , historically it has taken time for registries to become well established .

rather than setting a minimum proportion , a requirement to disclose the level of participation in a cdr may partially compensate for low levels of participation by alerting potential users of the data to take those limitations into account .

comparison to cms plans: cms has not addressed the issue of how well a cdr represents physicians treating its targeted patient population .

the planned required minimum of 50 participants may constitute only a very small fraction of those physicians .

however , cdrs may use benchmarks developed with data from external organizations , such as the national committee for quality assurance , which could help registries with low participation to achieve more accurate benchmarking .

5 .

performance improvement: input from experts and other relevant sources indicates that cdrs improve quality and efficiency by supplementing timely feedback on physician performance with information that targets needed practice changes .

rationale: the potential for cdrs to promote quality and efficiency improvements depends in large part on their ability to provide physicians with “actionable information” that identifies not only where performance is deficient but also specific changes in behavior that a physician could take to improve their outcomes .

for example , one cdr official told us that in addition to performance feedback and benchmarking , the cdr teaches , provides leadership , and supports hospitals and providers in quality improvement and change management .

another cdr official explained that they use cdr data to determine where additional tools are needed for physician development .

the cdr provides virtual education programs and develops improvement tools for providers .

the cdr officials we spoke with generally agreed that it is vital for cdrs to use data to inform quality improvement initiatives , rather than simply collecting the data .

comparison to cms plans: cms's plans would require that qualified cdrs provide participating physicians at least four feedback reports per year with benchmarks of some kind , but they do not require qualified cdrs to undertake any quality initiatives beyond feedback reports .

6 .

public reporting: input from experts and other relevant sources indicates that having cdrs provide some form of public reporting can promote greater quality and efficiency .

however , to avoid unintended adverse effects the public reporting may be limited to selected measures that are particularly useful to patients and / or be phased in over time .

rationale: public reporting can often help to motivate quality and efficiency improvement , but under some circumstances may also diminish physicians' receptivity to negative information and their willingness to participate in cdrs .

for example , a cdr may encourage competing providers to collaboratively examine their performance data to identify patterns and sources of suboptimal care .

some of these providers may not be willing to participate in such quality improvement efforts if doing so involves publicly reporting data that could put them at a competitive disadvantage .

in this way , differences across cdrs in the kind of data they collect and how they use them may affect the results available to be shared with the public and the possible ramifications of doing so .

comparison to cms plans: cms initially proposed that qualified cdrs have a plan to publicly report results for individual physicians , with benchmarks .

in response to public comments that raised concerns about the cost and time associated with public reporting , cms did not adopt this requirement .

instead , the preamble to the final rule states that cms encourages qualified cdrs to move toward public reporting , and that it will revisit this proposed requirement in the future .

7 .

demonstrating results: input from experts and other relevant sources indicates that cdrs are more likely to achieve improvements in physician performance if they have specific incentives to do so .

therefore , requiring qualified cdrs to demonstrate improvement over time on the quality and efficiency measures that they collect would help to focus their attention on achieving results .

rationale: both the financial incentives that cdrs will extend to participating physicians and the flexibility allowed in how they choose to operate are intended to promote improved quality and efficiency of care .

therefore , successful cdrs will begin to realize their potential to improve care by demonstrating results on key improvement opportunities for the cdr's target population .

because those opportunities vary across cdrs , the magnitude of improvement that can be expected of different cdrs will also vary .

at a minimum , each cdr has the ability to identify its key targets for improvement and begin to make incremental progress toward them .

comparison to cms plans: cms has not described any expectations regarding the results of qualified cdr activities .

to effectively implement requirements for qualified cdrs that focus on improving quality and efficiency , expert judgment is needed to interpret those requirements in accordance with the cdrs' differing circumstances and opportunities for improvement .

in particular , according to experts and other relevant sources , assessing both potential and actual effects of individual cdrs on quality and efficiency of care requires an understanding of what those particular cdrs could do to change physician practice and achieve improved performance .

this will depend on the state of clinical research and other factors that affect what is currently known about opportunities to improve quality and efficiency in each cdr's area of medical practice .

for example , expert judgment is needed to determine whether the particular set of measures adopted by a cdr effectively addresses the key quality and efficiency opportunities for improvement for the target population of that cdr .

in addition , expert judgment could help to determine what adjustments to make in performance expectations for cdrs that have only recently been established , which compared to cdrs that have been in operation over a longer period and have achieved a higher level of physician participation , may need time to build their capacity to promote improvements in quality and efficiency .

experts and other sources we consulted suggest a range of potential sources that cms could draw on to provide this expert judgment for assessing qualified cdrs .

they include relying on staff within cms , contracting with outside experts , and delegating certain aspects of oversight to independent organizations .

for example , one variation of the latter option might be to set up a deeming process to select one or more outside entities that meet cms - determined criteria for carrying out all or part of this oversight function .

each of those options has strengths and limitations in terms of , for example , its resource requirements , adaptability to varying situations , and responsiveness to agency priorities ( such as promoting alignment with other quality programs ) .

cms could consider these different strengths and limitations in building an organizational structure for monitoring qualified cdrs that draws on expertise from one or more of these sources .

based on our synthesis of the input from experts at the meeting we convened with the assistance of iom together with other relevant sources , there are several actions that hhs could take that could help reduce potential barriers to the development of qualified cdrs .

reducing these barriers would make it easier for qualified cdrs to get started and expand the scope of their activities and thereby improve the quality and efficiency of physician care provided to medicare beneficiaries , according to the input from experts and other relevant sources .

concerns about complying with privacy regulations: some cdr officials report that the recruitment of new participants is made more difficult by widespread concerns among physicians that submission of data to a cdr risks violation of the health insurance portability and accountability act under the privacy rule , protected health ( hipaa ) privacy rule.information may be used or disclosed only for specified permitted purposes .

because cdr data are often used for the purposes of both quality improvement activities and clinical research , it may often not be clear whether , or which , permitted use or disclosure applies .

this lack of clarity can make it more difficult for cdrs to collect and analyze clinical data for either purpose .

cdr officials stated that a particular concern of potential cdr participants is the perceived need for individual patient authorization or approval by an institutional review board ( irb ) to ensure compliance with hipaa requirements .

cms has indicated that cdrs must enter into an appropriate business associate agreement with participating physicians that provides for receipt of patient data and public disclosure of quality measure results.physician concerns regarding the perceived need to meet hipaa privacy rule requirements for research uses and disclosures .

however , it has not addressed the hhs office for civil rights monitors compliance with hipaa requirements and issues various types of guidance to explain how those requirements apply under different circumstances .

input from experts and other relevant sources suggests that physicians and cdrs could benefit from guidance that provides a detailed explanation of what cdrs need to include in their business associate agreements with participating physicians and what activities would trigger the need for individual patient authorization or irb approval of their data collection and analysis activities .

attempts to implement a unique personal identifier as part of patients' records to enable matching were abandoned due to concerns about its potential impact on patient privacy .

alternative methods exist for matching patient data without using a unique patient identifier , including algorithms that make probabilistic matches based on several discrete data elements .

however , these approaches often fall short of matching data from multiple sources for all patients , due in part to variations in the algorithms themselves and the data elements they use for performing these matches .

input from experts and other relevant sources suggests that hhs could work on developing a standardized process for matching and linking patient data that does not require the use of a unique patient identifier , including a uniform algorithm and associated data specifications .

hhs could then work with other health care entities to adopt this standardized approach across the spectrum of relevant data sources to better address the need of cdrs to link data from other sources in order to perform a more complete assessment of physician performance .

lack of patient cost data: because cdrs derive most of their data from patient medical records , they typically lack information about the cost of patient care needed to address questions about the efficiency of care .

the most fundamental problem with obtaining cost data is that cost data are fragmented among the various public and private payers for health care , including private health insurers as well as medicare and medicaid .

even when cdrs limit their focus to the medicare population , they have had to negotiate with cms for access to medicare claims data for each particular research project .

to facilitate and encourage cdr analysis of the efficiency of physician care , input from experts and other relevant sources suggests that cms could make its cost data for medicare and medicaid patients generally available to qualified cdrs .

in addition , although hhs has less direct control over the cost data collected by private health insurers , some health insurers have begun to work with states , hhs , and others to assemble “all - payer” claims databases that combine public and private health care spending data .

hhs could examine the potential for making these “all - payer” claims databases available to qualified cdrs .

difficulty of funding cdrs: cdrs frequently have difficulty finding a sustainable flow of funding from the participating physicians to maintain the resource - intensive activities necessary for their work , including collecting and validating detailed clinical data , which requires highly trained staff .

under the new program , participation in a qualified cdr will entitle physicians to receive benefits of the same incentive payments and exemption from penalties provided to pqrs participants , which could help to encourage physicians to participate in cdrs and to fund their operations .

however , experts report that participation in pqrs remains a cheaper and easier way to obtain those benefits .

hhs is looking into expanding incentives for physician participation in cdrs by coordinating with additional federal programs , such as the ehr incentive program , as well as possible coordination with related nongovernmental activities , such as maintenance of certification requirements established by various boards of medical specialties .

an alternative approach for providing additional funding to qualified cdrs raised at our expert meeting would be to share with them some of the financial benefits that the cdrs may generate for the medicare program .

doing so could benefit cdrs that are successful in producing these benefits while promoting program savings for medicare .

for example , hhs could consider testing models of “shared savings” programs — possibly through cms's center for medicare and medicaid innovation — that would provide cdrs or their participating providers with a portion of any cost savings for the medicare program that resulted from their activities .

to do this , cms would have to develop a credible methodology for determining the extent of savings that a qualified cdr's activities had produced for medicare .

need for technical assistance: the first cdrs established by medical specialty societies reported taking many years to work out how best to accomplish the complex technical tasks needed to get a new cdr up and running .

these include procedures for deciding what measures to collect , appropriate and feasible data collection and submission processes , implementation of risk adjustment , provisions for maintaining data security and protecting patient privacy , and effective data validation procedures .

several cdrs that have followed have turned to those first cdrs for informal guidance , to learn from their experience .

input from experts suggests that hhs could consider creating or facilitating the development of a cdr resource center that would offer qualified cdrs , or cdrs seeking to become qualified , technical assistance in the initial phases of setting up a cdr .

such a cdr resource center could draw on expertise from existing cdrs or other relevant sources and could help new registries launch successfully and more quickly achieve an adequate level of physician participation .

in recent years , some cdrs have developed different approaches to electronically capture data from a wide variety of health it applications , particularly ehr systems .

input from experts and other relevant sources suggests that hhs could help cdrs overcome barriers that impede the electronic collection and transmission of clinical data by supporting standard setting and adjusting meaningful use requirements .

health it applications , including ehrs , could offer cdrs substantial support in collecting and transmitting large amounts of detailed clinical data from participating physicians' medical records .

cdr officials report that , without such it support , data collection is a time - consuming process where data must be manually abstracted from medical records by specially trained staff and formatted for transmission to the cdr , a process that includes training staff to synthesize information from patient charts and other records .

these trained data abstractors must often make judgments on how to interpret certain information in the record to meet the cdr's data specifications and definitions .

for example , the word “pneumonia” may not appear in the medical record for all patients with the condition .

therefore , an abstractor may need to interpret the record's data on patient encounters , chest x - ray results , or stethoscope breath sounds to determine whether a patient had pneumonia as defined by the cdr .

in addition , most data collection is performed days or weeks after care is provided , rather than at the time of the care , which can substantially delay feedback to physicians .

input from experts and other relevant sources suggest that ehr systems , if appropriately designed and implemented , have the potential to greatly increase the efficiency of extracting data from patient records and transmitting these data to cdrs .

the use of ehr systems across the country is growing ; the proportion of office - based physicians using any type of ehr system increased from 51 percent in 2010 to 72 percent in 2012 .

if cdrs could receive and aggregate electronically extracted data from ehr systems , the need for manual abstraction by trained professional staff could be reduced or eliminated .

reducing the burden of manual data abstraction could have a number of long - term benefits , including reducing costs for physicians to participate in the cdr , reducing the amount of time a practice spends on cdr data collection activities , and increasing overall participation of physicians in cdrs .

health it experts also note that automated data collection from ehr systems makes it possible for cdrs to provide physicians with more timely feedback on care they have recently provided , compared to manual data collection .

in addition , ehr systems as well as other health it applications have the potential to facilitate information sharing among cdrs and other potential users of health care quality and efficiency data , allowing for comparison across cdrs and providing a more comprehensive and long - term view of the outcomes of patient care .

some cdrs have adopted it approaches that allow them to automatically extract at least some information from their participating members' ehr systems into the cdr's database .

however , these approaches have some important limitations .

for example , experts reported that some cdrs use a method called retrieve form for data capture ( rfd ) , which informs the physician through a trigger in their ehr system when a patient may be eligible for inclusion in the cdr database .

the rfd uses data from the ehr system to automatically prepopulate the cdr's web - based data collection form .

however , the rfd then requires that the physician interrupt work to enter the remaining information that was not automatically captured from the ehr .

the rfd also works only with ehr systems from a few different vendors .

another example was described by an official from the acc's pinnacle registry , which has implemented a more comprehensive system for electronically capturing data from a wider variety of ehr systems .

within each physician practice , system integration software is installed on the same server that hosts the ehr system .

the software is designed , developed , and implemented to automatically extract data directly from the physician's ehr system for transmission to the cdr database .

after a period of testing and adjustment to adapt the software to the ehr system's specific data structure , it can automatically capture 75 to 90 percent of the desired information .

the acc has determined that this electronic data collection results in higher levels of physician participation , and therefore is worth the tradeoff of doing without the portion of data that cannot be captured electronically .

however , according to an acc official , the system does not work with ehr systems produced by certain vendors , has been costly to implement , and may not be feasible for cdrs in other fields of medicine , where there is less consistent use of clinical terminology than in cardiology .

experts and other relevant sources indicate that variation in ehr systems on several key dimensions impairs cdrs' ability to collect electronic data from participating physicians .

ehrs can differ in which data elements they collect.systems collect more information on some topics than others , because physicians in different specialties have different needs and interests .

ehr systems can differ in how they store data .

in order to automatically extract data from the ehr , cdrs must develop methods for converting the data in each ehr to a format that the cdr's it system can accept and accurately interpret .

for example , an acc official told us that one reason why their system has been costly to implement and does not work with ehr systems from certain vendors is because of differences in how data are stored in different ehr systems .

finally , even if ehr systems collect the same basic content and use compatible storage methods , their data elements may be specified or defined differently .

for example , an ehr may identify a smoker based on whether a person smoked any number of cigarettes in the last year , while another may count as a smoker anyone who has smoked at least 100 cigarettes in the past and still currently smokes .

while both of these definitions may serve various purposes , the information collected from each ehr on smoking would not be fully comparable .

these variations in ehr data content , storage , and specifications can impact a cdr's ability to extract data electronically from physician ehr systems .

in order to assess physician performance , cdrs have to collect all the data elements needed for their performance measures and ensure that those data elements are consistent with the cdr's data specifications .

consequently , cdrs cannot take full advantage of ehr systems to facilitate data collection and transmission unless they can overcome these variations in content , storage , and specifications across existing ehr systems .

one way to reduce variation across health it applications , including ehr systems , and thereby facilitate collection and transmission of clinical data , is to develop and implement relevant health it standards .

according to experts , cdrs could benefit from health it standards that reduce variation across ehr systems on the data elements needed for the measures used by cdrs .

where such standards are in place , they are available for vendors to use in designing and implementing ehr systems .

as a result , different vendors would be more likely to develop ehr systems with consistent clinical data , in terms of their content and specification .

such consistency could make it easier for cdrs to collect these data from different ehr systems , as long as the standards aligned with the cdr's own data specifications and needs .

however , standards may not always align with cdr needs .

for example , one cdr official reported that the existing health it standard for cancer staging does not provide the level of detail needed by the oncology cdr , quality oncology practice initiative , to assess physician compliance with treatment guidelines targeted by the cdr .

several independent organizations play a role in setting the health it standards that apply to physician ehr systems .

they include international standards setting groups , each of which creates detailed coding systems , such as snomed ct and loinc , designed to provide a standard way to electronically record one or more categories of clinical information .

according to agency officials , while hhs interacts with these groups and may be able to influence the development of new or revised health it standards , the process for doing so can be long , taking as long as 2 years .

therefore , at any given time , the extent of existing health it standards largely constrains what developers of ehr systems can do to implement standardized data elements .

a second major factor that experts report affects the design and implementation of ehr systems used by physicians is the meaningful use requirements established by hhs for its ehr incentive programs .

hhs establishes two sets of requirements for the ehr incentive programs that potentially affect cdrs: ( 1 ) a list of specific clinical quality measures ( cqm ) that physicians are required to collect using ehr - collected data elements , and ( 2 ) certification criteria that specify certain capabilities that ehr systems are required to demonstrate , including the ability to collect the data needed for physicians to report the specified cqms .

to receive an incentive payment , physicians must demonstrate , among other things , that they have used a certified ehr system to collect data for a minimum number of the specified cqms .

through its setting of these meaningful use requirements , hhs could influence the extent to which ehr systems are designed and implemented to collect data needed by cdrs to assess physician performance .

according to it experts at our expert meeting , ehr vendors place a high priority on developing ehr systems that are able to collect cqms prescribed by meaningful use requirements , without which the systems would not qualify for ehr incentive payments .

the current set of 64 cqms focuses predominantly on primary care and generally does not include measures relevant to cdrs , many of which focus on assessing specialty care .

hhs has stated its intention to consider revisions to the meaningful use requirements under stage 3 of the ehr incentive program implementation , scheduled to take effect in 2016 .

these revisions would give qualified cdrs greater flexibility in meeting the ehr programs' quality reporting requirements .

by also including the data needed by cdrs in its revised meaningful use requirements , hhs could increase the motivation for vendors to include the capacity to collect data elements for measures relevant to cdrs in their ehr systems .

qualified cdrs have the potential to improve the quality and efficiency of care for medicare beneficiaries by encouraging physicians to submit extensive , standardized data to cdrs , enabling the cdrs to provide feedback to physicians on their performance relative to that of their peers .

studies show that cdrs have great potential to improve quality , and to a lesser extent efficiency , but often that potential is not realized .

while implementation of the program is just getting under way and hhs plans to have its program requirements and structure evolve over time , a key question is the extent to which that evolutionary process focuses on harnessing the potential of cdrs to promote quality and efficiency .

the extent to which hhs's new program can help cdrs realize their potential to improve quality and efficiency will depend in large part on the content and oversight of the requirements that hhs sets for qualified cdrs and the support that hhs provides .

to date , hhs plans have focused on largely procedural requirements for cdrs that collectively would do little to base qualification of cdrs on their potential to affect quality and efficiency or hold them accountable for achieving improvements in those domains .

our analysis identified certain key requirements that hhs could adopt that would make it substantially more likely that qualified cdrs actually would improve quality and efficiency .

some of these key requirements are more important than others to have in place as the program is implemented .

from the beginning , the effectiveness of cdrs will depend on their selecting measures that focus the cdrs' assessment and performance improvement activities on the specific opportunities for improvement that exist for their particular target populations .

at the same time , cdrs can also collect a limited core data set that contributes to achieving national quality and efficiency objectives .

the credibility of those data depends on cdrs establishing from the start systematic and rigorous processes to validate their accuracy and completeness .

hhs can most clearly ensure that each qualified cdr focus on improvements in quality and efficiency by requiring that each cdr demonstrate improvements in key measures of quality and efficiency for its target population .

effective monitoring of these requirements will depend on applying expert judgment that can take account of the variation across cdrs in their target opportunities for improvement .

hhs can also enhance the effect of qualified cdrs on quality and efficiency by taking steps to reduce barriers to their development and , in particular , taking account of cdrs in its ongoing efforts to promote health it .

certain steps would be particularly useful as the program gets under way , including clarifying the application of hipaa privacy requirements to physicians participating in qualified cdrs , addressing the lack of access to multipayer cost data , expanding potential sources of funding to support sustained cdr operations , and providing technical assistance to newly established cdrs .

meanwhile , efforts by some cdrs to adapt health it to make their data collection less costly and more timely have run into significant barriers related both to gaps in existing health it standards and to the failure of many current ehrs to apply existing standards to collect data needed by cdrs in a structured format .

changes to ehr capabilities that would enable them to collect such data within existing standards are clearly feasible , but are not high priorities for providers and it vendors because they are not included in the current set of meaningful use requirements for the ehr incentive program .

as hhs determines what the next cycle of meaningful use requirements should comprise , identifying data elements for measures commonly needed by cdrs and including them in meaningful use requirements could substantially assist qualified cdrs in adapting health it to make data collection less costly and more timely .

to help ensure that qualified cdrs promote improved quality and efficiency of physician care for medicare beneficiaries , we recommend that the secretary of health and human services take the following five actions: direct cms to establish key requirements for qualified cdrs that focus on improving quality and efficiency .

these requirements could include , for example , having cdrs ( 1 ) identify key areas of opportunity to improve quality and efficiency for their target populations and collect additional measures designed to address them , ( 2 ) collect a core set of measures established by cms , and ( 3 ) demonstrate that their processes for auditing the accuracy and completeness of the data they collect are systematic and rigorous .

direct cms to establish a requirement for qualified cdrs to demonstrate improvement on key measures of quality and efficiency for their target populations .

direct cms to establish a process for monitoring compliance with requirements for qualified cdrs that draws on relevant expert judgment .

this process should assess cdr performance on each requirement in a way that takes into account the varying circumstances of cdrs and their available opportunities to promote quality and efficiency improvement for their target populations .

determine and implement actions to reduce barriers to the development of qualified cdrs , such as ( 1 ) developing guidance that clarifies hipaa requirements to promote participation in qualified cdrs ; ( 2 ) working with private sector entities to make relevant multipayer cost data available to qualified cdrs ; ( 3 ) testing one or more models of shared savings between medicare and qualified cdrs that achieve reduced medicare expenditures with improved quality of care , and ( 4 ) providing technical assistance to qualified cdrs .

determine key data elements needed by qualified cdrs — such as those relevant for a required core set of measures — and direct onc and cms to include these data elements , if feasible , in the requirements for certification of ehrs under the ehr incentive programs .

we provided a draft of this report to hhs for review , and hhs provided written comments , which are reprinted in appendix ii .

in its comments , hhs concurred with our recommendations and stated its intention to apply the experience it gains in implementing the qualified cdr program to facilitate changes that lead to improved quality and efficiency .

for example , hhs stated that it saw value in providing greater specificity in the expectations it sets for qualified cdrs , in particular with respect to having them demonstrate improvement in quality and efficiency , once hhs has sufficient experience with the program to establish a baseline against which to assess their performance .

hhs also stated its intention to establish a process to monitor the qualified cdr program that would draw on relevant and appropriate expert judgment and to do what it could to reduce barriers to the development of qualified cdrs .

in addition , hhs agreed to have cms and onc work together to consider the inclusion of key data elements for qualified cdrs as they develop enhanced health it criteria for the next stage of the ehr incentive programs .

meanwhile , hhs noted several other efforts that it currently has under way to improve health it systems in general , which can also provide assistance to qualified cdrs attempting to use health it to facilitate their operations .

while hhs concurred with each of our recommendations , its comments also noted some challenges that it expects to face .

for example , hhs stated that it will examine the possibility of establishing a core measure set for qualified cdrs , but it observed that doing so could prove difficult given the number of different clinical specialties on which qualified cdrs may focus .

as noted in the draft report , a minimum set of core measures — even if small — could help cdrs to promote national - level quality improvement objectives such as improving care coordination by permitting the sharing and aggregating of the data across cdrs and other sources of quality data .

hhs also provided us with technical comments , which we incorporated as appropriate .

we are sending copies of this report to the secretary of health and human services , the administrator of the centers for medicare & medicaid services , the national coordinator for health information technology , and other interested parties .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staffs have any questions about this report , please contact me at ( 202 ) 512-7114 or at kohnl@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix iii .

pacific business group on health network for regional health improvement national committee for quality assurance siemens medical solutions , inc .

in addition to the contact named above , will simerl , assistant director ; emily binek ; monica perez - nelson ; eric peterson ; and roseanne price made key contributions to this report .

