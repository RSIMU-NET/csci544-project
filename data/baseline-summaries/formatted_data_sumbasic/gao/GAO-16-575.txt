crashes in which a vehicle leaves the roadway are frequently severe and account for the majority of highway fatalities .

in 2014 , 17,791 fatalities — 54 percent of traffic fatalities in the united states — occurred as a result of roadway departures , according to the u.s. department of transportation ( dot ) 's data .

roadside safety hardware , such as guardrails and median barriers , is meant to reduce the risk of a serious crash .

because of the frequency and severity of these incidents , the standards and procedures by which roadside safety hardware is tested , installed , and evaluated after installation are integral to promoting highway safety .

in the last several years , there have been a number of serious injuries and deaths resulting from crashes into a type of roadside safety hardware , known as the et - plus guardrail end terminal , which is installed at the end of a guardrail and intended to prevent serious injury if it is struck .

these cases raise questions about the thoroughness of crash testing and oversight of roadside safety hardware in general .

this crash testing and oversight involves multiple parties including those that develop roadside safety hardware , laboratories that conduct roadside safety hardware crash testing , the american association of state highway and transportation officials ( aashto ) , the federal highway administration ( fhwa ) , and state departments of transportation .

you asked us to examine the framework for overseeing roadside safety hardware , including the roles played by fhwa , states , and other parties .

this report addresses: ( 1 ) how fhwa performs oversight of state policies and practices related to roadside safety hardware , ( 2 ) the thoroughness of the laboratory crash - testing process and fhwa's oversight of this process ; and ( 3 ) the extent to which information is available on roadside safety hardware performance once installed .

to address these topics , we reviewed relevant regulations , policy documents , and guidance memos from fhwa and selected states on roadside safety and design .

to determine how fhwa performs oversight of roadside safety hardware , we reviewed roadside safety hardware standards published by aashto and related fhwa guidance , and evaluated fhwa's policies and practices for conducting oversight of roadside safety hardware in comparison with federal internal control standards for monitoring , designing control activities , and communication with external stakeholders .

to gain perspective on what policies and procedures states use to oversee roadside safety hardware's testing , installation , and performance , we distributed a survey to all 50 states , plus the district of columbia and puerto rico , and received 44 responses .

our survey findings represent only the states that responded to our survey .

to assess the thoroughness and sufficiency of the crash - testing process we requested and reviewed documentation from the nine crash test labs in the united states that are accredited to international standards and conduct crash testing for the purposes of fhwa review .

we also reviewed crash - test lab guidance and policy documents .

to better understand the standards and processes labs are expected to have in place and how international laboratory and roadside safety hardware testing standards are implemented , we conducted structured interviews with officials from each of the nine labs and from three international accrediting bodies that accredit test labs .

we also reviewed 10 fhwa files selected to represent different types of roadside safety hardware for years between 1993 and 2014 to better understand the processes by which fhwa oversees the testing process .

to determine the state of knowledge of roadside safety hardware performance , we conducted a literature review of studies published by state , federal , and academic sources between 1993 and 2015 .

we interviewed officials at fhwa's office of safety , and office of safety research and development , as well as state departments of transportation and fhwa's division offices in five states ( virginia , ohio , texas , maryland , and california ) , to obtain non - generalizable examples of how federal and state roadside safety hardware policies intersect .

we selected these states based on the presence of an accredited crash - testing facility in the state and recommendations from outside experts regarding the quality of performance data collection efforts in those states .

we visited three of these states ( virginia , ohio , and texas ) to visit crash testing labs and spoke with lab personnel , state dot officials , fhwa division office representatives , and other roadside safety hardware stakeholders .

because of ongoing litigation , we did not review any issues related to the accidents involving the et - plus guardrail end terminal .

see appendix i for a full description of our objectives , scope , and methodology .

we conducted this performance audit from april 2015 to june 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

if a vehicle leaves the roadway , ideally , the roadside would be clear of all obstructions and be traversable .

however , because there are numerous roadside areas that cannot be practically cleared of all fixed objects or that have sharp declines , roadside safety hardware can be used to reduce the consequences of a departure from the roadway .

the goal of roadside safety hardware is met when the hardware contains , redirects , or decelerates the vehicle to a safe stop without causing serious injury to the vehicle's occupants or other people .

general categories for roadside safety hardware are: 1 ) longitudinal barriers , which include items such as guardrails and cable barriers and are intended to reduce the probability of a vehicle's striking an object or terrain feature off the roadway that is less forgiving than the barrier ; 2 ) bridge barriers , which function as longitudinal barriers but are specific to bridge design ; 3 ) barrier terminals / crash cushions , which include items like guardrail end terminals that are intended to absorb or divert the energy of a crash into the end of a longitudinal barrier ; 4 ) support structures , such as sign supports , which are designed to break or yield when struck by a vehicle ; and 5 ) work zone devices , which include a variety of items used in a work zone that are temporary in nature .

see figure 1 below for a depiction of these types of hardware .

dot's primary mission is to ensure the safety of the traveling public .

the strategic goals of the fhwa , within dot , are to provide safe , reliable , effective , and sustainable mobility for users of the nation's highway system .

fhwa distributes about $40 billion to the states each year through the federal - aid highway program ( generally providing 80 to 90 percent of projects' costs on designated federal - aid highways ) for highway and bridge infrastructure , a portion of which is spent on safety improvements including roadside safety hardware .

fhwa issues regulations and guidelines , and can perform direct oversight for projects that use federal funds , including those on the national highway system ( nhs ) .

the nhs consists of approximately 220,000 miles of the nearly 1- million miles of roadways eligible for federal aid .

the nhs includes the 47,000-mile interstate highway system as well as other roadways , connectors important to u.s. strategic defense policy , and connectors to major intermodal facilities , such as airports or transit hubs .

fhwa administers and oversees the federal - aid highway program through fhwa's division offices located in all 50 states , the district of columbia and puerto rico .

as part of fhwa's risk - based oversight , division offices and state dots have “stewardship and oversight agreements” that specify the terms under which states assume oversight responsibility for federally funded projects .

under fhwa's risk - based stewardship and oversight program , fhwa is responsible for determining projects that have an elevated risk or projects where fhwa involvement can enhance meeting program or project objectives .

this involvement may include conducting oversight of the entire project or a specific phase or element of the project .

for all projects that fhwa does not categorize as having an elevated risk , responsibility for oversight of design and construction of projects is generally assumed by the states .

for each federally funded project , fhwa enters into project agreements with the state in which the state agrees to adhere to all applicable federal laws and regulations .

section 109 of title 23 of the united states code directs dot to work in partnership with the state dots to develop standards for the nhs and other roadway systems .

to fulfill this responsibility , fhwa works in partnership with aashto to advance many of its mission areas .

aashto is an association representing highway and transportation departments in the 50 states , the district of columbia , and puerto rico .

aashto serves as a liaison between state departments of transportation and the federal government and develops and maintains design standards for roadways , bridges , and highway materials .

fhwa incorporates some aashto standards into federal regulation , for example , the policy on geometric design of highways and streets ( green book ) , which lists design criteria across a range of roadway types , from rural roads to freeways .

fhwa has an ex - officio , non - voting role on aashto committees .

in cooperation , aashto and fhwa sponsor research on common transportation issues through the transportation research board's national cooperative highway research program ( nchrp ) , including research on roadside safety hardware .

nchrp studies are funded by the states from federal - aid highway program funds apportioned to them .

roadside safety hardware is developed by manufacturers , states , and universities and can be crash tested to assess its safety performance .

the nine u.s. crash - testing labs that are accredited and recognized by fhwa can conduct full - scale crash testing where roadside safety hardware is hit by a vehicle to determine whether it meets aashto - accepted standards for roadside safety hardware .

of the nine labs , three labs are independently operated ; two are owned by companies that also develop roadside safety hardware ; three labs are affiliated with universities ; and the final lab is operated by a state department of transportation .

representatives from roadside safety hardware developers , crash test labs , academia , and state and federal transportation departments participate in task force 13 , a committee whose mission is to develop specifications for new materials and technologies identified for use in highway construction projects .

as part of this mission , task force 13 develops , recommends , and promotes standards and specifications for roadside safety hardware .

the two ways of assessing this performance are lab crash testing and in - service performance evaluations .

crash tests can quantify performance for specific conditions that represent the “worst practical conditions” in terms of the speed and angle of the vehicle hitting the hardware .

the performance of hardware is evaluated in terms of risk to the vehicle occupants and structural adequacy of the hardware , among other items .

aashto currently has two sets of crash - testing standards that it endorses for installing roadside safety hardware: nchrp report 350 standards adopted in 1993 , which are being phased out , and the manual for assessing safety hardware ( mash ) adopted in 2009 .

aashto developed the mash standards as an update to nchrp report 350 , and these standards contain revised criteria for crash tests of roadside safety hardware .

updates in mash include: increases in the size and weight of several test vehicles to better match the current vehicle fleet , changes to the number of tests and impact conditions , and more objective evaluation criteria .

aashto has also sponsored research on how to assess the performance of roadside safety hardware once it has been installed , an assessment that is referred to as in - service performance evaluation ( ispe ) .

in 2003 , nchrp report 490: in - service performance of traffic barriers , published findings of research and suggested practical procedures for conducting ispes .

in - service performance evaluations are a way of assessing roadside safety hardware's performance in “real - world” scenarios not captured in a crash - test setting .

for example , performance may be affected by installation factors , such as slope and grade of roadway and soil type , and maintenance conditions , including whether the hardware has degraded over time from weather or accidents , none of which are captured in crash - testing .

fhwa oversees and promotes the installation of crash - tested roadside safety hardware through guidance and policy directives to the states and by issuing letters to roadside safety hardware developers that submit crash - test results for review by fhwa .

we found that states generally require crash testing ; however , some inconsistencies across state policies and practices exist , and a movement to adopt the improved mash standards has been slow .

in 2016 , fhwa and aashto released a new joint implementation plan stating that states should transition to installing only mash - standard - tested roadside safety hardware in phases by 2019 .

however , some concerns have been raised , and fhwa has not developed a plan to track progress of the states and industry in meeting the new dates .

fhwa has contracted for a full examination of its roadside safety hardware oversight processes and expects a report with recommendations for potential changes to these processes in the summer of 2016 .

in line with its overall safety mission as well as that of dot , fhwa encourages states to install appropriately crash - tested roadside safety hardware .

by law , fhwa is required to ensure that highway projects designed and constructed with federal funds are safe .

fhwa's office of safety's specific mission includes advancing the use of scientific methods and data - driven decisions .

also , according to fhwa's office of safety website , roadway departure is one of its focus areas .

fhwa has issued policy that roadside safety hardware should demonstrate acceptable crashworthy performance in order to be used on the nhs and receive federal - aid reimbursement .

to encourage this outcome , fhwa issues guidance and policy directives to the states and industry .

for example , in 2015 fhwa issued a memo that encouraged state agencies to upgrade their existing installations of guardrail end terminals that had been tested to standards issued prior to the nchrp 350 standards , which were adopted in 1993 .

congress directs dot to work in partnership with the state dots to develop standards for the nhs and other systems .

fhwa works in cooperation with aashto to promote state adherence to crash - testing standards through joint implementation plans .

these plans are voted on and must be approved by a majority of aashto's member states .

fhwa and aashto issued joint implementation plans in 2009 and 2016 that provided guidance for states to follow in transitioning to updated crash test standards .

in addition to providing guidance to states , fhwa also issues federal - aid reimbursement eligibility letters to roadside safety hardware developers that submit their product information , crash test results and other supporting documentation for review .

although it is called a federal - aid reimbursement eligibility letter , fhwa's eligibility letter is not required , and federal - aid reimbursement is not contingent upon receipt of an eligibility letter .

fhwa issues these letters as a service to the states to provide states with information on the crashworthiness of roadside safety hardware .

fhwa posts the letters on its website creating a central repository of information for states to know which roadside safety hardware has been tested .

fhwa officials stated that when they receive a request from a developer for an eligibility letter , the request includes information on the design of the roadside safety hardware device , the crash testing report , pictures and videos of the crash testing , and other information .

fhwa officials told us that they follow up with the developer or test lab if they have questions about any of the data or video evidence .

fhwa also advises developers that if modifications are made to a roadside safety hardware device that has received an eligibility letter , the developer must resubmit information to fhwa for review .

though it is fhwa's policy that all roadside safety hardware installed on the nhs should be crash tested , crash testing is not a requirement for states to receive federal - aid highway program funds because this policy was never incorporated into regulation or other formal agreements with the states ( such as fhwa's project agreements with states ) .

according to fhwa officials , in the absence of a federal statutory or regulatory requirement for crash testing , fhwa cannot withhold federal funding for federal - aid highway - program projects' approvals to a state should the state choose to install roadside safety hardware that had not been tested to meet appropriate crash test standards .

during our review , we found a widespread misperception among state dot and fhwa division office officials we spoke with that crash testing of roadside safety hardware to applicable standards and obtaining an fhwa eligibility letter was required in order to receive federal reimbursement .

in 1991 , congress instructed dot to issue a final rule regarding revised standards for acceptable roadside safety hardware .

in 1993 , fhwa issued a rule that incorporated crash test standards into regulation by reference as guidance .

fhwa stated at the time that it lacked sufficient knowledge to be more prescriptive about roadside safety hardware in general and chose not to make crash testing mandatory through regulation .

fhwa has not issued a proposed rulemaking to require crash test standards since .

fhwa officials told us that they believe encouraging state compliance is more effective than requiring it through a rulemaking because the current partnership with aashto garners support from states , and a federal rulemaking can take many years to complete .

most states that responded to our survey told us that roadside safety hardware installed on the nhs is required to be crash tested , and many of those states said they had processes in place to limit installation of roadside safety hardware to those that have obtained fhwa eligibility letters .

nearly all , 43 of the 44 states that responded to our survey , told us that crash testing to mash or nchrp report 350 standards is required in their state for major categories of roadside safety hardware .

in addition , 38 of 44 states also responded that they maintain lists of “approved” or “qualified” products from which contractors can choose roadside safety hardware for installation .

furthermore , 32 of the 38 states with these lists responded that all roadside safety hardware on their qualified or approved product lists have an fhwa eligibility letter .

while our survey results indicate that fhwa's guidance has been widely implemented at the state level , they also indicate some inconsistencies in state policies and some misperception about fhwa policy .

first , 10 states responded that that they do not have a specific law , regulation , or policy document that establishes crash - testing requirements .

in follow - up responses , four of these states told us that they do not have documented requirements because they believe fhwa requires crash - testing of roadside safety hardware and that the fhwa requirement governs roadside safety hardware in their state .

if a state's policy is only to refer to a federal requirement that does not exist , then effectively no requirements govern crash testing in that state .

second , while most states approve installation of only roadside safety hardware that has received an fhwa eligibility letter , not all states do so .

for example , 11 states reported that they have conducted their own crash testing in the past 10 years , and 6 of the 11 responded that they do not always submit those roadside safety hardware devices for fhwa review prior to approving devices for installation .

officials from one state told us they only submit results for eligibility letter review when they believe the device is likely to be used by other states .

federal standards for internal control highlight the need for agencies to design control activities — policies , procedures , techniques , and mechanisms — to achieve objectives and address related risks .

in june 2012 , fhwa issued a memo indicating that division offices should encourage states to have written policies that incorporate aashto's guidance on current roadside safety information and operating practices .

however , fhwa has not directed its division offices to help ensure that states have policies governing crash testing of roadside safety hardware installed on their roadways as part of this procedural review .

officials in the five fhwa division offices we interviewed told us they have a procedure for reviewing states' standards and design specifications , which could include states' standards and requirements for roadside safety hardware .

however , officials in fhwa division offices we interviewed said that they generally do not examine roadside safety hardware practices on individual projects as part of fhwa's risk - based oversight .

officials in one division office noted that topics like pedestrian safety would be a higher priority for the division office because officials said there are more pedestrian deaths than there are deaths from roadside safety hardware .

division office officials stated that they rely on the state to ensure that what is incorporated in the project meets state standards , and officials from four out of five division offices stated that they do not verify that states are installing state - approved products .

furthermore , fhwa's office of safety officials told us that they do not monitor and collect information on state policies with respect to roadside safety hardware .

the absence of written requirements at the state level and inconsistencies in state practices could , in some cases , result in the risk of reduced assurance that states are fully implementing appropriate crash - testing standards .

according to fhwa and aashto , mash crash test standards are an improved set of standards because they better reflect the current vehicle fleet , which has become heavier and taller over the past 25 years .

two studies compared the nchrp report 350 standard testing to the mash test standards .

the results of these studies indicated that in some cases mash test standards provide a more rigorous evaluation for crash testing roadside safety hardware .

first , in 2010 , nchrp conducted an evaluation of existing roadside safety hardware devices approved under nchrp report 350 .

re - testing these devices and evaluating performance using the criteria in mash revealed that 6 of the 21 tests performed on nchrp report 350-compliant roadside safety hardware devices did not pass .

second , in september 2015 , a joint aashto / fhwa review of guardrail end terminals concluded that the mash crash test standards incorporate tests relevant for guardrail end terminals that are not included in nchrp report 350 test standards .

specifically , the study found that nchrp report 350 standards do not fully address performance issues in the areas of side and shallow - angle impacts .

the study recommended fully implementing mash for new installations of guardrail end terminals .

states have been slow in transitioning to implement the mash crash - test standards .

in 2009 aashto and fhwa issued a joint implementation plan adopting mash as the updated crash - test standards necessary for an applicant to receive an fhwa eligibility letter for a new roadside safety hardware device .

however , this plan said that states could continue to install roadside safety hardware tested to the previous nchrp report 350 standards .

therefore , manufacturers could continue to produce , and states could continue to install roadside safety hardware that had already received an eligibility letter without retesting to mash crash test standards .

in january 2016 , fhwa and aashto released a new joint implementation plan stating that states should transition to installing only mash - standard - tested roadside safety hardware .

according to the plan , fhwa will no longer issue eligibility letters for new or modified roadside safety hardware tested to standards other than the mash crash - test standards .

the 2016 joint implementation plan calls for states to complete the transition to the mash crash - test standards between december 2017 and december 2019 , depending on the type of hardware .

 ( see table 1 below. ) .

if states comply with the 2016 joint implementation plan's dates for transitioning roadside safety hardware installations to meet the mash crash - test standards , this transition will be 8 to 10 years after the 2009 joint implementation plan , and states may continue to install non - mash - tested hardware on the nhs until december 2017 at the earliest .

fhwa officials noted that roadside safety hardware often remains on the roads for at least 20 years before being replaced due to aging , so hardware tested to the older nchrp report 350 standards could be on the roads for years to come .

however , at this point it is not clear that states will be able to comply with the dates set in the plan .

in order to meet the transition dates , industry will have to develop and test products to the mash standards that have not previously been tested to these standards , and fhwa will have to review applications - for - eligibility letters for developers that request them .

states will then have to make changes to either their design and specification policies or approved lists of products to incorporate only mash - tested roadside safety hardware .

industry , to this point , has been slow to move to develop and test products to the mash standards .

using eligibility letters as an indicator , as of march 2016 , there are currently only two guardrail end terminals with eligibility letters that have been tested using the mash standards , compared to the13 guardrail end terminals tested to nchrp report 350 with eligibility letters .

in the category of longitudinal barriers , there were only 17 mash - compliant eligibility letters among the 348 active eligibility letters .

in an open letter to aashto , the american traffic safety services association , an association representing highway safety industries , expressed concern with the ability for industry to have enough hardware that meets the mash crash - test standards by the transitions dates , as well as the ability of states to approve new hardware and for fhwa to post new eligibility letters in a timely manner .

fhwa officials told us that states and manufacturers have responded positively to the new deadlines .

however , fhwa officials did express some concern as to whether states will be able to fully implement mash standards by the dates in the 2016 joint implementation plan .

their concerns included the need for the market to react in a timely manner and have enough products available to support competition , and to invest in testing categories of roadside safety hardware that have had little testing to mash standards to this point .

fhwa officials also told us that as industry reacts to the dates , fhwa will likely have an influx of requests to review eligibility letters ; fhwa officials told us that they already have a backlog of eligibility letter applications since fhwa stopped issuing eligibility letters for modifications to hardware tested to non - mash standards at the end of 2015 .

federal standards for internal control highlight the need for agencies to obtain information needed to achieve their objectives from external parties , including significant matters related to risks .

fhwa officials stated they will be in a better position in a year to say whether states are likely to be able to successfully transition to mash crash - test standards by the dates specified in the january 2016 joint implementation plan .

however , fhwa has not developed a plan to track progress of the states and industry in meeting the new dates .

moreover , we found that fhwa and states currently do not collect information that would assist in monitoring the transition to mash standards .

for example , as discussed in the following section , fhwa can interact with developers and crash test labs during the test process , but fhwa does not collect information from developers and labs to be informed when hardware that was previously tested to older standards is re - tested to mash and fails .

without this information on test failures , fhwa and states may be unaware of setbacks to the transition .

also , if states do not have this information , it may result in the states unknowingly installing failed hardware during the transition period .

in addition , 12 states responded to our survey that they currently do not require developers to notify them of modifications made to an approved device .

while fhwa requests such notification , 3 of the 12 states do not have eligibility letters for all approved devices and could be unaware of design changes .

federal standards for internal control also highlight the need for agencies to provide quality information to external parties , including the general public to help achieve agency objectives .

monitoring and reporting industry and state progress to the goal dates set in the 2016 joint implementation plan would allow fhwa to keep decision makers in both dot and congress aware of progress .

such monitoring and reporting of progress would also position fhwa to take corrective actions as needed to better assure that states and industry are successfully moving to meeting improved standards .

fhwa contracted in may 2015 with dot's volpe national transportation systems center to conduct a full review of its roadside safety hardware oversight process and expects a report with recommendations for potential changes to its oversight program in summer 2016 .

officials stated the review will include a full examination of the process by which roadside safety hardware is developed , evaluated , funded , and assessed , as well as recommendations for any improvements needed .

specifically , the report will include: documentation of existing laws , regulations , policies , standards , and guidelines associated with the roadside safety hardware process ; documentation and review of all the steps in fhwa's current crash - testing evaluation process ; and findings and recommendations to fhwa to improve its oversight .

fhwa officials told us that there may be ways to improve the agency's oversight of roadside safety hardware and that everything in the process , from the partnership relationship with aashto to the eligibility letter process , will be included in the review .

during the course of our review , fhwa implemented some changes to its program , such as clarifying the need for any modifications to hardware with eligibility letters to be reevaluated , but fhwa officials stated they were holding off on major changes to the current oversight program until the volpe national transportation systems center's review is complete .

at all nine u.s. labs accredited to conduct crash testing of roadside safety hardware for fhwa review , laboratory crash testing was well documented and thorough in terms of consistency in documentation and test procedures across labs .

as part of the crash - testing process , labs and test sponsors have discretion in making testing decisions in several important areas .

in addition , there is an inherent potential threat to independence in the testing process because employees in some labs can test devices that were developed within their parent organization .

the independence requirement in the standards used to accredit labs is general , and we found varying interpretations and differences in approaches for mitigating threats to independence across the labs .

fhwa does not require third party verification of crash testing and does not make its own pass / fail determinations or provide for independent pass / fail determinations for test results .

fhwa also does not provide additional guidance to labs and accrediting bodies on independence mitigation measures for crash testing roadside safety hardware .

we found that some other federal agencies with similar testing programs have more measures than fhwa has to mitigate potential risks to independence .

fhwa requires that crash test labs conducting testing for the purposes of fhwa eligibility letters be accredited to international organization for standardization ( iso ) 17025 standards , which contain management and technical requirements for labs to be deemed competent to run laboratory testing .

there are nine crash test labs in the united states that are accredited to these standards and conduct crash testing for the purposes of fhwa eligibility letters .

our review of the nine accredited u.s. labs found that individual crash tests were well documented and thorough because test reports contained documentation that would allow a third party to understand how the lab conducted the test and how the test results were interpreted .

to evaluate the thoroughness and documentation for labs' crash testing , we created both interview questions and a document request list for all the labs based on international accreditation requirements as well as the crash - testing guidelines in mash .

all nine example test reports we reviewed clearly identified the test standard and the test level the lab used to test the roadside safety hardware device .

the pass / fail criteria being used to evaluate the roadside safety hardware device was clearly identified , and all reports described the test results against each of the evaluation criteria .

in addition , all reports described the setup of the device and pre - test procedures , which could include verifying the integrity of the soil , when applicable , and structural integrity of the test vehicle .

each report also included between 20 and approximately 100 pictures of the testing process , along with a description of the results .

for more information on the documents we requested and reviewed , see appendix i. labs generally described using requirements specified in test or accreditation standards as the basis for their procedures .

labs described sending equipment out to a qualified calibration laboratory , or obtaining additional expertise and certification to calibrate their own equipment .

several labs also stated that they keep the test objects on site for a period of time , in case follow - ups were needed .

specifically , five labs told us that they kept test documentation on file for at least 2 years , and in three of these cases , kept records indefinitely .

labs also described going beyond what standards require in certain instances .

for example , five of the nine labs described using additional cameras or data recording devices to better capture data that would be useful to industry research or to the customer .

accrediting bodies are expected to use the iso 17025 standards , along with test standards specific to the industry , such as the mash crash - test standards in this case , as the basis for accrediting crash test labs .

officials from three labs said they had developed documentation practices specifically in reference to the accreditation process .

each accreditation body said that it conducts routine audits each year as part of its accreditation cycle , where accreditation bodies told us they evaluate such aspects of the testing process as setup , equipment calibration , competence of personnel , documentation , and record keeping .

one lab reported that its accrediting body assisted it with improved lab procedures by setting up calibration procedures ; two labs reported that accreditation requirements guide their policies on document retention .

in addition , accreditation standards require labs to collaborate and compare results in inter - laboratory collaborations , a procedure that labs do via task force 13 , in order to work toward greater consistency in test procedures and results interpretation .

although individual crash tests are well documented , full - scale crash testing to evaluate the performance of an individual piece of hardware is a complex process that requires labs to use professional judgment when deciding which tests need to be run , and how to interpret the results .

both nchrp report 350 and mash have a suite of tests in order to cover a range of crash speeds , angles , and size and weight of vehicles to assess the performance of the roadside safety hardware device .

a majority of labs ( five of nine ) reported that they usually recommend to test sponsors that they run the full suite of tests outlined in the test standard .

however , for modified devices that have previously been tested , there is some discretion on which tests to run .

because an individual full - scale crash test can cost about $55,000 ( according to a crash test lab we spoke with ) it is advantageous to only run what test sponsors think are the most critical tests for a given device .

for example , in one of the testing scenarios we reviewed , the lab engineers determined based on prior testing with a larger vehicle that the mash test for small cars would not be necessary for the tested device .

although this decision is documented in the test report , the reasoning is not detailed , and so it is hard for a reviewer to evaluate this decision .

of the nine labs we interviewed , four told us that they frequently consult with fhwa in the test - planning process , and that these labs generally run the tests in agreement with fhwa .

the other labs told us they either rarely or never consult with fhwa ; these labs encourage test sponsors to communicate directly with fhwa if they plan to seek an eligibility letter , and in these cases the lab runs the tests the sponsor requests .

as part of the eligibility letter process , labs can , but are not required to , consult with fhwa for advice on which tests to run .

labs have some discretion in interpreting the test results against the pass / fail criteria of the crash test standard .

according to mash crash test standards , some interpretation will be necessary for the criteria due to the “very complex nature of vehicular collisions and the dynamic responses of an occupant to the collision , as well as human tolerances to impact.” eight of the nine labs reported that engineering judgment was necessary to make a pass / fail decision in at least a small minority of tests , although one lab reported that up to 30 percent of all nchrp report 350 or mash crash tests require professional judgement .

one lab noted that mash has more specific criteria than nchrp report 350 , but leaves room for interpretation when it comes to defining failure limits for penetration , occupant intrusion , and deformation limits , which are all part of the occupant risk criteria .

for example , six of the labs reported that occupant intrusion standards were the main subjective parameter , because characteristics such as the amount , type , and location of the intrusion were important in determining whether the occupant could be harmed .

lab officials told us that mash standards , which specify maximum allowable levels of occupant intrusion , do not always address applied testing scenarios .

for example , officials in one lab described a test on a post that sliced and made holes in the floor pan of the test vehicle .

the lab officials said they interpreted this to be a failure , although lab officials suggested that mash crash test standards do not specify whether holes in the floor of the vehicle mean the test fails .

in the roadside safety hardware - testing community there is an inherent potential threat to lab independence because there is often not a formal separation between design and testing roles within a lab's parent organization .

specifically , six of the nine crash test labs we reviewed can test products that were developed by employees of the same parent organization .

two manufacturer - owned labs can test products created by another division of the same company ; three university - run labs can test university employees' designed products ; and a state - based facility tests products designed by the state department of transportation .

in order to be an accredited lab , the iso requires labs to identify any conflicts of interest and have policies to ensure labs are free from undue pressure .

the three accrediting bodies we interviewed told us that the iso requirements are usually met by documented conflict - of - interest policies and by having an organizational structure in which lab employees do not have conflicting lines of reporting to their parent organization .

however , documentation we obtained and interviews we conducted with labs and accreditation bodies revealed varying interpretations of the level of involvement of the device designer in the crash - testing process , and of the level of involvement of the lab in providing design feedback based on crash test results , that is appropriate to ensure independence .

for instance , while four labs told us they would offer advice on how to re - design the device if it failed a crash test , the other five labs said they did not make such recommendations , and one specifically said it interprets iso standards to mean that labs should not be involved in making design recommendations after testing .

the iso standards are intended to broadly cover testing and calibration laboratories across many industries to ensure technical competence .

varying interpretations suggest a lack of specificity in iso requirements to ensure independence in the testing of roadside safety hardware .

of the six labs that test devices developed within their parent organization , two labs told us they have policies that formally separate the role of the designer and the tester , although only one had this policy documented .

one of the two labs designates an independent approving authority to make the final determination of whether the hardware passed or failed each test and specifies that this person could not have been part of the design or development of the hardware .

the other told us that if a member of the lab was involved in the design of a device , that person would not be allowed to make the pass / fail determination .

however , the other four labs do not have a separation that is this clear .

two of these labs provided us with the general conflict of interest policies of their parent organizations , and two labs pointed us to conflict - of - interest policies in their quality manuals , which did not have information about separating design and testing .

the committee of sponsoring organizations of the treadway commission ( coso ) , a joint initiative of multiple private - sector - accounting organizations , publishes the internal control - integrated framework to help organizations design internal controls to achieve their objectives .

this framework highlights the importance of the separation of duties within an organization , to reduce the risk of inappropriate conduct in the pursuit of objectives .

the standard states that when selecting and developing control activities , management should consider whether duties are divided or segregated among different people to reduce the risk of error or inappropriate or fraudulent actions .

labs that do not have this formal separation between design and testing functions could have threats to the independence of their test analyses .

one of the three accrediting bodies told us that independence can be difficult to assess because it is not clear what labs that are affiliated with manufacturers , for instance , must do to mitigate any conflicts of interest .

officials from two accrediting bodies told us that other federal agencies provide them with additional guidance on independence and technical expertise , respectively , and one accrediting body told us that it is preferable when an agency provides guidance so that the accrediting body can better apply standards when accrediting labs in a specific industry .

for example , officials from this accrediting body provided an example of a federal agency that has developed more specific ethics and integrity requirements than the iso .

accrediting body officials told us that this agency requires the accrediting body to assess the labs to these more specific requirements .

federal standards for internal controls state that agencies should establish policies and procedures to respond to risks as part of their internal control system .

however , apart from the accreditation requirement , fhwa does not have other mitigation measures in place with regard to lab independence .

fhwa does not provide guidance to crash test labs or accrediting bodies on mitigating the risks posed by threats to independence .

providing such guidance could provide greater assurance that crash - testing is being performed in an independent , unbiased fashion .

fhwa reviews crash test results as part of its eligibility letter process ; however , fhwa does not have a process for formally verifying the testing outcomes and making or providing for an independent pass / fail determination .

fhwa relies heavily on the labs to determine whether the crash test outcome results in a pass or fail determination for roadside safety hardware .

according to iso standards for accreditation , when a lab states whether a product complies with requirements , it is offering an opinion , and it must be marked as such .

officials from one accrediting body said it would be preferable for labs to provide only the crash - test result data and have a third party apply criteria in mash crash test standards and make the pass / fail determinations .

officials at one lab we spoke to added that they prefer not to make pass / fail determinations , but they do so for each test .

in the eligibility letter process , fhwa requires that lab personnel apply the results to relevant crash - test standards and make a pass / fail determination of the test results .

fhwa officials explained that as part of their eligibility letter - review process , they examine the crash test lab report , including pictures , videos , and the test data summary sheets .

if fhwa officials have questions , they will contact the lab or developer .

however , eligibility letters state that fhwa is relying on the assessment of the lab .

moreover , we reviewed 10 case files for eligibility letters issued between 2005 and 2015 and found that documentation was not sufficient to determine the rationale behind fhwa's decision to issue these letters .

for more information on our review of fhwa's eligibility letter process , see appendix ii .

fhwa officials acknowledged that lab employees' testing devices that were developed within their greater parent organization poses the appearance of an independence threat .

in may 2015 , fhwa issued a memo directing the developer and test labs to submit financial conflict - of - interest information in order for a developer to receive an eligibility letter .

fhwa officials told us that this information will not influence a device's ability to receive an eligibility letter , but that the information could be published along with the final eligibility letter for the public to review , in an effort to increase transparency .

fhwa officials also told us that this was an immediate change they could make but that they are awaiting the results of the volpe national transportation systems center's review before deciding whether to take additional steps in this area .

according to federal internal control standards , agencies should ensure that they communicate quality information to external parties so they can help the agency achieve its objectives and address related risks .

however , as explained above , there is a potential threat to independence in the lab crash - testing environment for roadside safety hardware .

in other test settings we found that federal agencies require third party verification of test results or independent entities to make pass / fail determinations .

we found that both the environmental protection agency ( epa ) — in its energy star program — and the national highway traffic safety administration ( nhtsa ) — in its testing for federal motor vehicle safety standards and the new car assessment program — have stricter oversight over the lab - testing process and require third party certification and / or verification testing .

epa's energy star program is a voluntary program to identify and promote energy - efficient products and buildings .

lab testing of products is conducted to determine whether a product meets program specifications for efficiency .

as we've previously found , the testing requirements for epa's energy star program have evolved in response to weaknesses identified in the program by us in 2007 and epa's office of inspector general in 2008 , including a lack of assurance that tested products met the qualification criteria .

in response to these findings , epa and the department of energy signed a memorandum of understanding in 2009 to propose several program enhancements .

as part of a review of this program , before these changes had been implemented , gao submitted fictitious products for certification and found that the program was vulnerable to fraud and abuse because manufacturers could self - certify that their devices met energy standards without third - party verification .

in 2011 , we found that epa had made considerable progress in addressing these issues by including verification testing and third party certification in the approval process .

currently , in order to earn an energy star label , products must be tested by epa - recognized laboratories , and a subset of products is verified annually by third - party certification entities .

epa standards require labs , their accrediting bodies , and third - party certification body laboratories that verify test results to abide by respective sets of conditions and criteria in order to be recognized by the energy star program .

epa also has an application process for all three types of entities to receive energy star program recognition .

under this process , epa requires that labs test products for review by third - party certification bodies , which determine if the devices meet the program standards for a product to carry an energy star label .

epa's standards for energy star recognition also require certification bodies to verify lab test data and make a pass / fail determination , and epa officials added that the labs themselves are not supposed to make this decision .

in addition , certification bodies are to conduct verification testing for a sampling of devices , including off - the - shelf devices , across multiple categories each year .

epa officials told us they closely oversee the certification bodies through frequent communication and periodic audits .

we also interviewed officials at nhtsa regarding two forms of vehicle crash testing that they oversee .

first , nhtsa issues federal motor vehicle safety standards ( fmvsss ) , with which vehicle manufacturers must comply , and manufacturers must self - certify that their products meet these standards .

nhtsa then sponsors verification testing of some vehicle models , where they purchase vehicles from dealer lots and subject them to crash testing to confirm the manufacturer's certification .

the verification testing is conducted by labs selected by nhtsa .

nhtsa officials told us that they would not select a lab that has the potential conflict of interest of being a part of a manufacturer business .

once the testing is conducted , the raw data is sent to nhtsa and nhtsa officials make the determination as to whether the vehicle has met the fmvsss .

testing for nhtsa's new car assessment program is similar to that of the fmvsss in design , but rather than checking whether vehicles meet minimum safety standards , nhtsa awards vehicle models with up to 5 stars for their safety performance in crash testing to standards that , according to nhtsa officials , typically exceed those in the fmvsss .

officials stated that because these standards are not federal requirements , vehicle manufacturers do not have to comply or self - certify compliance .

officials noted , however , that because the new car assessment program provides safety ratings information to consumers the manufacturers have an incentive to receive the highest safety rating possible .

similar to testing under the fmvsss , officials said that nhtsa purchases vehicles from dealer lots and then tests them at selected labs .

the crash - test data is then sent to nhtsa where nhtsa officials determine the star rating for each test vehicle .

in contrast to these programs , fhwa does not require either third party certification or verification of crash testing ; nor does fhwa provide additional guidance on independence mitigation measures for crash testing roadside safety hardware .

establishing a process for third - party verification of crash test results could provide greater assurance that threats to independence are fully addressed .

fhwa officials told us that they would favor considering some form of third party review over crash test results .

these officials added that having fhwa conduct the third party review could be challenging and that fhwa would need to assess the resources , technical capacity , and legal capacity to perform that role .

according to fhwa and aashto - sponsored research , in - service performance evaluations ( ispe ) are recommended for effective roadside safety hardware oversight because real - world crash conditions , such as vehicle characteristics , as well as the terrain of the roadway , may vary widely from those experienced in crash testing .

moreover , crash testing cannot fully replicate the effects of installation conditions over time on roadside safety hardware's performance .

in establishing a methodology for conducting ispes , nchrp report 490 states that collecting crash data over multiple years and examining crash sites in real - time can enable researchers to report more information on roadside safety hardware's installation and maintenance issues , the costs associated with making repairs to damaged hardware , and the severity of injuries resulting from crashes that involve roadside safety hardware .

this can better equip states to make cost - benefit determinations regarding roadside safety hardware replacement or new product development .

ispes can also inform whether crash - testing standards are appropriately suited to assessing the effectiveness of roadside safety hardware .

based on our review of studies published since 1993 , when fhwa recognized nchrp report 350 testing standards , few formal ispes of roadside safety hardware have been conducted to fully assess the performance of roadside safety hardware in actual conditions .

after reviewing government , industry , and academic sources , we found 14 formal ispes that were published since 1993 .

while other studies included elements of an in - service performance evaluation , 14 studies in our review combined crash data analysis with real - time visits to crash sites to document and assess the damage , which is a key characteristic of a formal ispe as defined by nchrp report 490 .

additionally , these ispes tended to focus on longitudinal barriers , such as guardrails and cable barriers , and barrier terminals , such as guardrail end terminals , while other types of roadside safety hardware were generally not the subject of ispes .

a key challenge to states conducting ispes appears to be the lack of fully - developed data .

as nchrp report 490 indicates , having inventory data on the number of roadside safety hardware devices being studied and their location is critical to calculating rates of collision with roadside safety hardware within the study area .

in our survey of state dots , we asked officials to describe their data and inventory efforts , and states reported a general lack of established inventory data .

as table 2 shows , a majority of states indicated that they have inventory data - collection efforts for barrier terminals / crash cushions , for example , but many of these efforts are new or are ongoing and therefore are not fully established .

for instance , of the 29 states that reported in response to our survey that they have inventory data - collection efforts for barrier terminals / crash cushions , 18 said that their efforts are ongoing , and 12 of these said that they had only been collecting data since 2014 .

state dot officials we interviewed in four states also told us that inventory data they collect may not include information on condition or location of roadside safety hardware , which as nchrp report 490 notes is necessary for a full understanding of performance .

the other key piece of data is crash data .

the current state of crash data reporting may not facilitate conducting ispes of roadside safety hardware .

according to nchrp report 490 , police will likely not comment as part of their crash records on factors like soil conditions , which could influence how guardrail posts , for instance , function in a crash .

police crash records also do not capture any unreported collisions and may not consistently document the type of roadside safety hardware involved in an accident .

according to our survey , only 6 of 44 states that responded said that they had conducted any formal ispes in the last 10 years .

state officials we interviewed also described less formal efforts to evaluate roadside safety hardware's performance .

for instance , officials in one state told us that they perform a trial run for any new proprietary roadside safety hardware device in a sampling of locations and monitor on - site the in - service performance for 12 – 18 months prior to approving the device to be used by contractors across the state .

however , state officials told us this effort is not published in a report .

without published results that document a methodology that others can repeat , however , such results do not ultimately add to the broader knowledge base of ispes .

officials in four of the five states we interviewed indicated that they have cost and / or data constraints related to collecting the necessary data to conduct formal ispes .

officials from the fifth state we interviewed described a software application they developed to inventory all of the guardrail end terminals in their state .

according to state officials , local maintenance crews in the state use a custom web application on a mobile device to record the total number , along with data on the type and location , of guardrail end terminals in their state .

this data is then uploaded to a central database .

state officials said they were planning to make this a long - term project and apply it to other types of roadside safety hardware .

officials noted that they are still in the process of adding the capability for keeping the data up to date .

these officials also told us that the application was relatively inexpensive to develop , and fhwa officials noted that at least one state was interested in learning more about the application .

state officials told us that as of yet , however , this technology has not been shared across states .

fhwa has ongoing research to identify best practices for the collection of data on roadside safety hardware .

however , this research is limited to guardrail end terminals , and the planned scope of work may not be sufficient to fill the gaps created by the lack of ispe literature at the state level .

fhwa officials told us that in the summer of 2015 , fhwa began a pilot study on the collection of data on guardrail end terminals' performance .

according to fhwa officials , the first phase of this pilot study is expected to last through the end of 2016 .

officials plan to identify current challenges to conducting ispes as well as recommend best practices for: 1 ) the collection of real - time data on crashes involving roadside safety hardware ; 2 ) interagency communication at the state level regarding crash reporting ; and 3 ) data management regarding hardware maintenance and location .

fhwa is currently collecting inventory and crash data in four states ( missouri , pennsylvania , massachusetts , and california ) that have agreed to participate in this pilot .

fhwa officials stated that within a selected area of each state , data will be collected by examining crash sites for six different models of guardrail end terminals .

this data could produce information needed to assess the performance of the devices with respect to the risk of severe occupant injury if the study were to be continued .

according to fhwa officials , crash specialists from nhtsa , the agency that collects and reports data on fatal crashes for dot , will conduct detailed on - site investigations for fatal and serious injury crashes , generally within 24 hours of receiving notification of the crash .

data on crashes resulting in property damage only and other minor crashes will also be collected .

officials told us that they plan to continue collecting data through 2016 for this phase of the project .

according to fhwa officials , however , publishing findings on the effectiveness of guardrail end terminals' performance is not part of their current efforts because they first want to provide guidance to states on best practices for performance data collection .

officials noted that the time frame for the current phase of the pilot would be insufficient to collect enough data for statistically significant findings .

fhwa officials told us that they will not determine whether to include performance findings as part of future phases of the pilot study until this phase is complete at the end of 2016 .

as noted previously , fhwa's office of safety includes in its mission the need to advance the use of scientific methods and data - driven decisions in highway policy .

the current lack of in - service performance findings and established inventory data for roadside safety hardware poses challenges to states making data - driven decisions about highway maintenance .

fhwa officials told us they currently have no plans to include additional ispes for other types of roadside safety hardware as part of their broader highway - safety research portfolio .

officials cited cost concerns with gathering data and explained that ispes would take on greater relevance in the future as more mash - compliant devices are installed on roadways .

however , continuing this study and reporting on the performance of guardrail end terminals , or planning to make ispes part of other future research , could add to the limited body of knowledge regarding the in - service performance of roadside safety hardware .

fhwa officials also noted that hardware that was installed could still be on the roadways for 20 – 30 years .

ispes on current devices can therefore still provide states with critical information regarding how they might prioritize maintenance tasks — such as replacing older devices — to best ensure safety for their motorists .

without robust , ongoing in - service performance evaluations , less safe hardware may remain in use longer than is necessary .

fhwa's cooperation with aashto and state dots has resulted in states having policies to install crash - tested roadside safety hardware on the nhs .

however , challenges exist for states , industry and fhwa as the improved mash crash - testing standards are phased in over the next few years .

these changes will require cooperation and action from industry , the states , and fhwa .

fhwa has the opportunity to exercise more robust oversight to ensure greater consistency in the implementation of improved crash test standards .

first , fhwa , through its division offices' oversight of states' standards and design specifications , can help ensure that states have written policies in place that fully reflect the terms of the 2016 state - approved joint implementation plan to address inconsistent practices across states .

second , monitoring and reporting the states' and industry's progress transitioning to the mash crash test standards , as federal standards for internal controls suggest , and making this information available to congress and the public would facilitate transparency and position fhwa to consider midcourse corrections if required .

fhwa can also take steps to strengthen its role in the assessment of roadside safety hardware performance — both in the test lab and once installed on the roadways .

because fhwa's current oversight process does not include verification of lab crash - test results and no specific mitigation measures are in place to address potential threats to independence , the risks to ensuring the integrity of the crash - testing process remain unaddressed .

other agencies have introduced policies or processes into the testing process that mitigate these types of issues ; fhwa could take similar actions .

in addition , other agency practices provide a model for fhwa of closer cooperation with the labs and accreditation bodies to address the independence issues unique to roadside safety hardware's testing .

fhwa also has the opportunity to advance its mission in the scientific evaluation of roadside safety hardware .

fhwa has a pilot project underway that is examining data collection practices for in - service performance evaluations but currently has no plans to report on performance findings from either this study or other research in its portfolio .

continuing this study or planning to make ispes part of future research could add to what is currently a limited body of knowledge regarding the in - service performance of roadside safety hardware .

fhwa is poised to consider changes to its approach to roadside safety hardware through a full programmatic review to be completed in the summer of 2016 .

opportunities exist to address all these issues and to provide states , industry , and the traveling public greater assurance that fhwa is fulfilling its safety mission and advancing roadside safety .

to promote the transition to improved crash test standards , to strengthen fhwa's oversight of the roadside safety hardware's crash - testing process , and to make more information available to states and industry on how roadside safety hardware performs in actual conditions , we recommend that the secretary of transportation direct the administrator of fhwa to take the following five actions: 1 .

direct fhwa's division offices to help ensure , through their oversight of states' standards and design specifications , that states have written policies in place to require the installation of appropriately crash - tested roadside safety hardware on the nhs to address inconsistent practices across states .

2 .

monitor and periodically report to congress ( or report through the agency's publicly available website ) progress states and the industry are making in transitioning to the mash crash - testing standards for roadside safety hardware .

3 .

provide additional guidance to crash test labs and accreditation bodies to ensure that labs have a clear separation between device development and testing in cases where lab employees test devices that were developed within their parent organization .

4 .

develop a process for third - party verification of results from crash - test labs .

5 .

support additional research and disseminate results on roadside safety hardware's in - service performance , either as part of future phases of fhwa's current pilot study on guardrail end terminals' performance or as part of fhwa's broader research portfolio .

we provided a copy of a draft of this report to the department of transportation for review and comment .

in written comments , reproduced in appendix iii , dot concurred with gao's recommendations .

fhwa also provided technical comments which we incorporated , as appropriate .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to interested congressional committees and the secretary of transportation .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-2834 or flemings@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix iv .

this report addresses: ( 1 ) how fhwa performs oversight of state policies and practices related to roadside safety hardware ; ( 2 ) the thoroughness of the crash - testing process and fhwa's oversight of this process ; and ( 3 ) the extent to which information is available on roadside safety hardware performance once installed .

to assess fhwa's role in the oversight of roadside safety hardware and related state policies , we reviewed fhwa documentation including: internal memos on roadside safety and implementation of the current eligibility letter process ; guidance memos to the broader roadside safety hardware community ; and policy documents such as the template for stewardship and oversight agreements agreed to with states .

we also reviewed relevant laws and regulations governing fhwa's oversight of roadside safety hardware .

we interviewed fhwa officials in headquarters to understand how policies and practices are carried out .

we also applied federal internal control standards for monitoring , designing control activities and communication with external stakeholders when reporting on the agency's policies and practices for conducting oversight of roadside safety hardware .

to better understand fhwa's process in reviewing crash test information and issuing eligibility letters , we requested and received the fhwa files for 10 eligibility letters .

two case files were selected by fhwa as example files ; we accepted these files and then selected eight more files from the roughly 1,000 available .

to make our selection , we first limited the pool to only applications that came to fhwa since 2005 .

then we wanted variation in terms of the following variables: age of application ( variation across those 10 years ) ; new device versus modification to existing device ; type of device ; type of standard tested to ( mash or nchrp report 350 ) ; and proprietary versus generic .

once the files were received we reviewed each file to determine whether it had the information we would expect in order for a third party to understand how fhwa officials came to the conclusion to issue an eligibility letter .

to better understand states' roles in the oversight of roadside safety hardware , we developed and distributed a survey to all 50 states , plus the district of columbia and puerto rico .

survey questions addressed topics including policies on crash testing of roadside safety hardware , procedures for ensuring that only crash - tested hardware is installed on the national highway system , efforts to collect inventory data on roadside safety hardware , and what , if any , research states had conducted in the last 10 years to evaluate the in - service performance of roadside safety hardware after it is installed .

after developing the survey , we conducted four pre - test interviews with selected states to ensure that the questions were clear and appropriate for our research objectives .

we adjusted the survey questions as needed in response to feedback prior to survey distribution .

in october 2015 we distributed the survey to state departments of transportation representatives from all 50 states , plus the district of columbia and puerto rico .

we followed up and collected responses until january 2016 , at which point we had received responses from 44 out of 52 states and territories .

in instances where states did not supply complete responses to individual questions the answers to those questions were not included in the survey results , and those states were removed from the denominator for purposes of summary analysis .

for selected questions , we conducted brief follow - up interviews and solicited written responses , when appropriate , in order to seek clarification or elaboration of states' responses .

to get more information on how states oversee roadside safety hardware , we selected five states — maryland , virginia , ohio , texas , and california — with which to conduct interviews with state departments of transportation officials and the fhwa's division offices that oversee the state departments of transportation .

we selected these states based on the presence of an accredited crash - testing facility in the state and recommendations from stakeholders regarding the quality of performance - data collection efforts in those states .

in the cases of virginia , ohio , and texas , interviews with state officials were conducted on site , and we also conducted interviews with crash - testing lab personnel and roadside safety hardware developers in the cases of ohio and texas .

to gain information on the thoroughness and independence of the crash - testing process and the extent to which fhwa oversight helps ensure this , we interviewed the nine domestic crash labs that are accredited , as required by fhwa , to international crash test lab standards to test roadside safety hardware for fhwa eligibility letters .

to describe how labs are evaluated against international - testing standards , we reviewed the international - test lab accreditation standards in iso 17025 and interviewed the three accrediting bodies that accredit the nine domestic crash - testing labs .

to evaluate the thoroughness and documentation for lab crash testing , we reviewed the accreditation requirements in iso 17025 as well as the crash - testing guidelines in mash , and analyzed these documents to create both interview questions and a document request list for all the labs , in consultation with our technologist .

the questions addressed how labs ensure the quality of the testing environment , how they interpret test results , how they document each test , how they comply with conflict of interest requirements in the iso , and how communicate with fhwa .

we also asked labs to submit their accreditation reports , quality manual , any relevant conflict - of - interest or ethics policies , and a sample test report for us to review .

we then asked the nine labs to walk us through a recent example of a product tested for fhwa compliance , in order to describe how policies and requirements are implemented in practice .

we reviewed the conflict - of - interest policies to determine the extent to which there was variation in policies across the labs , and to evaluate whether there were mitigation measures for potential threats to independence .

we also visited four crash test labs and witnessed two full scale crash tests to gain a better understanding of the crash testing process .

to collect information on how other agencies oversee lab testing , we reviewed documentation and interviewed officials from the environmental protection agency's energy star program , as well as the national highway traffic safety administration regarding their vehicle crash testing .

both agencies were referenced in our discussions with accrediting bodies as examples of other agencies that oversee accredited testing programs .

to assess the extent of information available on roadside safety hardware performance once devices are installed , we conducted a literature search for in - service performance evaluations ( ispe ) using government , academic , and trade publication sources .

we also reviewed studies submitted to us by a highway design and roadside safety hardware engineering expert .

for both sources of studies , we used the national cooperative highway research program ( nchrp ) report 490's definition of an ispe to define criteria for determining whether the studies we reviewed constituted ispes for the purposes of our report .

specifically , we looked for studies that combined analysis of crash data with real - time site visits .

according to nchrp report 490 , studies that retroactively or contemporaneously examine crash data are known as historical studies and collision studies , respectively , whereas an ispe adds the element of real - time crash site analysis .

nchrp report 490 notes that this technique allows researchers to better determine what type of hardware was struck , whether there were installation techniques or other site - specific characteristics that contributed to the crash , and whether the exact device is something a state dot still uses .

we also stipulated that the study in question involve a specific type of roadside safety hardware , which we defined according to fhwa's categories of hardware for purposes of federal - aid eligibility letters .

moreover , we restricted our ispe classification to studies published between 1993 and 2015 , when nchrp report 350 crash - testing standards were published and when fhwa first recognized them .

as part of our literature search , we used online search terms that tailored the searches to specific types of roadside safety hardware as well as key methodological components , such as site visits .

to inform all of the research questions we also reviewed documentation and interviewed relevant officials from interested stakeholders .

we reviewed standards and relevant guidance from the american association of state highway and transportation officials ( aashto ) .

to collect information on how crash test standards are developed and are updated , we interviewed the aashto technical committee on roadside safety , as well as officials at the transportation research board's national cooperative highway research program .

to get more detailed perspective on how industry , states , and crash - testing facilities collaborate , we attended a semiannual meeting of task force 13 , a joint committee of aashto , the associated general contractors of america , and the american road and transportation builders association , which develops standards and specifications for bridges and roadside safety hardware .

we also interviewed two roadside safety hardware developers .

we conducted this performance audit from april 2015 to june 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

we reviewed 10 case files for eligibility letters issued between 2005 and 2015 and found that documentation was not sufficient to determine the rationale behind fhwa's decision to issue these letters .

fhwa officials explained that as part of their eligibility letter review process , they examine the crash test lab report , including pictures , videos , and the test - data summary sheets .

if fhwa officials have questions they will contact the lab or developer .

however , there is no structured protocol for documenting the steps fhwa reviewers took or the rationale behind the decision to issue an eligibility letter .

for example , in two cases where fhwa officials asked questions and received answers from the lab or test sponsor , it was not possible to trace how fhwa made its determination to issue an eligibility letter .

we also found three instances in which the full suite of testing was not performed , but no documentation was present explaining why the lack of testing was acceptable .

we provided this information to fhwa officials who acknowledged that the basis for those decisions was not documented but stated that in each case fhwa found the information and reasoning provided by the lab or test sponsor satisfactory .

fhwa officials also told us they made changes to the eligibility letter review process in 2015 including documenting communications with developers seeking an eligibility letter , a checklist for documenting reviews of eligibility letter requests , and updates to the eligibility letter request form to identify tests that are not critical or not relevant and the reasons why or why not .

fhwa officials told us that this checklist provides documentation from the submitter concerning why certain tests were not conducted or why modifications are considered non - significant to better document this information .

we did not evaluate the impact of these changes since they were made during the course of our audit work .

officials also characterized these changes as “interim” because the eligibility letter review process is part of the ongoing independent volpe national transportation systems center review of the program .

in addition to the contact named above , steve cohen ( assistant director ) , melissa bodeau , devin braun , william egar , sarah farkas , sarah gilliland , judy guilliams - tapia , david hooper , leslie locke , madhav panwar , malika rice , alexandra squitieri , jade winfree , and elizabeth wood made key contributions to this report .

