as you know , the food and drug administration ( fda ) regulates the manufacture and marketing of medical devices in this country .

some criticism has been expressed that fda's review of medical devices is excessively lengthy and can impose inordinate delays upon the introduction of new devices into the market .

at your request , we examined fda's review time and how it has changed from fiscal year 1989 to may 18 , 1995 .

we analyzed data provided by fda on applications to market new devices or to begin clinical research on unapproved devices .

we briefed your staff on the findings of our preliminary analysis in june 1995 , and we have since requested and received comments on these findings from fda .

medical devices can range in complexity from a simple tongue depressor to a sophisticated ct ( computed tomography ) x - ray system .

most of the devices reach the market through fda's premarket notification ( or 510 ( k ) ) review process .

under its 510 ( k ) authority , fda may determine that a device is substantially equivalent to a device already on the market and therefore not likely to pose a significant increase in risk to public safety .

when evaluating 510 ( k ) applications , fda makes a determination regarding whether the new device is as safe and effective as a legally marketed predicate device .

performance data ( bench , animal , or clinical ) are required in most 510 ( k ) applications , but clinical data are needed in less than 10 percent of applications .

an alternative mode of entry into the market is through the premarket approval ( pma ) process .

pma review is more stringent and typically longer than 510 ( k ) review .

for pmas , fda determines the safety and effectiveness of the device based on information provided by the applicant .

nonclinical data are included as appropriate .

however the answers to the fundamental questions of safety and effectiveness are determined from data derived from clinical trials .

fda also regulates research conducted to determine the safety and effectiveness of unapproved devices .

fda approval is required only for “significant risk” devices .

applicants submit applications for such devices to obtain an investigational device exemption ( ide ) from regulatory requirements and approval to conduct clinical research .

for an ide , unlike pmas and 510 ( k ) s , it is the proposed clinical study that is being assessed — not just the device .

modifications of medical devices , including any expansion of their labeled uses , are also subject to fda regulation .

applications to modify a device that entered the market through a pma are generally linked to the original pma application and are called pma supplements .

in contrast , modifications to a 510 ( k ) device are submitted as new 510 ( k ) applications .

references may be made to previous 510 ( k ) applications .

fda uses several measures of duration to report the amount of time spent reviewing applications .

in this letter , we use only three of those measures .

the first is simply the time that elapses between fda's receipt of an application and its final decision on it ( total elapsed time ) .

the second measure is the time that fda has the application under its review process ( fda time ) .

this includes both the time the application is under active review and the time it is in the fda review queue .

the amount of time fda's review process has been suspended , waiting for additional information from the applicant , is our third measure ( non - fda time ) .

our measures of review time are not intended to be used to assess the agency's compliance with time limits for review established under the federal food , drug , and cosmetic act ( the act ) .

the time limits for pma , 510 ( k ) , and ide applications are 180 , 90 , and 30 days , respectively .

fda regulations allow for both the suspension and resetting of the fda review clock under certain circumstances .

how review time is calculated differs for 510 ( k ) s and pmas .

if a pma application is incomplete , depending on the extent of the deficiencies , fda may place the application on hold and request further information .

when the application is placed on hold , the fda review clock is stopped until the agency receives the additional information .

with minor deficiencies , the fda review clock resumes running upon receipt of the information .

with major deficiencies , fda resets the fda clock to zero upon receipt of the information .

in this situation , all previously accrued fda time is disregarded .

 ( the resetting of the fda clock can also be triggered by the applicant's submission of unsolicited supplementary information. ) .

the amount of time that accrues while the agency is waiting for the additional information constitutes non - fda time .

for 510 ( k ) s , the fda clock is reset upon receipt of a response to either major or minor deficiencies .

for this report , we define fda time as the total amount of time that the application is under fda's review process .

that is , our measure of fda time does not include the time that elapses during any suspension , but does include time that elapsed before the resetting of the fda clock .

the total amount of time that accrues while the agency is waiting for additional information constitutes non - fda time .

 ( the sum of fda and non - fda time is our first measure of duration — total elapsed time. ) .

the act establishes three classes of medical devices , each with an increasing level of regulation to ensure safety and effectiveness .

the least regulated , class i devices , are subject to compliance with general controls .

approximately 40 percent of the different types of medical devices fall into class i .

at the other extreme is premarket approval for class iii devices , which constitute about 12 percent of the different types of medical devices .

of the remainder , a little over 40 percent are class ii devices , and about 3 percent are as yet unclassified .

in may 1994 , fda implemented a three - tier system to manage its review workload .

classified medical devices are assigned to one of three tiers according to an assessment of the risk posed by the device and its complexity .

tier 3 devices are considered the riskiest and require intensive review of the science ( including clinical data ) and labeling .

review of the least risky devices , tier 1 , entails a “focused labeling review” of the intended use .

in addition to the three tiers is a group of class i devices that pose little or no risk and were exempted from the premarket notification ( 510 ( k ) ) requirements of the act .

under the class and tier systems , approximately 20 percent of the different types of medical devices are exempted from premarket notification .

a little over half of all the different types of medical devices are classified as tier 2 devices .

tiers 1 and 3 constitute 14 and 12 percent of the different types of medical devices , respectively .

from 1989 through 1991 , the median time between the submission of a 510 ( k ) application and fda's decision ( total elapsed time ) was relatively stable at about 80 to 90 days .

the next 2 years showed a sharp increase that peaked at 230 days in 1993 .

although the median review time showed a decline in 1994 ( 152 days ) , it remained higher than that of the initial 3 years .

 ( see figure 1. ) .

similarly , the mean also indicated a peak in review time in 1993 and a subsequent decline .

the mean review time increased from 124 days in 1989 to 269 days in 1993 .

in 1994 , the mean dropped to 166 days ; however , this mean will increase as the 13 percent of the applications that remained open are closed .

 ( see table ii.1. ) .

of all the applications submitted to fda to market new devices during the period under review , a little over 90 percent were for 510 ( k ) s. between 1989 and 1994 , the number of 510 ( k ) applications remained relatively stable , ranging from a high of 7,023 in 1989 to a low of 5,774 in 1991 .

in 1994 , 6,446 applications were submitted .

of the 40,950 510 ( k ) applications submitted during the period under review , approximately 73 percent were determined to be substantially equivalent .

 ( that is , the device is equivalent to a predicate device already on the market and thus is cleared for marketing. ) .

only 2 percent were found to be nonequivalent , and 6 percent remained open .

other decisions — including applications for which a 510 ( k ) was not required and those that were withdrawn by the applicant — account for the rest .

 ( see appendix i for details on other fda decision categories. ) .

for applications determined to be substantially equivalent , non - fda time — the amount of time fda placed the application on hold while waiting for additional information — comprised almost 20 percent of the total elapsed time .

 ( see table ii.7. ) .

figure 2 displays fda and non - fda time to determine equivalency for 510 ( k ) applications .

the trends in review time differed for original pmas and pma supplements .

there was no clear trend in review times for original pma applications using either medians or means since a large proportion of the applications had yet to be completed .

the median time between the submission of an application and fda's decision ( total elapsed time ) fluctuated from a low of 414 days in 1989 to a high of 984 days in 1992 .

less than 50 percent of the applications submitted in 1994 were completed ; thus , the median review time was undetermined .

 ( see figure 3. ) .

except for 1989 , the means were lower than the medians because of the large number of open cases .

the percent of applications that remained open increased from 4 percent in 1989 to 81 percent in 1994 .

the means , then , represent the time to a decision for applications that were less time - consuming .

when the open cases are completed , lengthy review times will cause an increase in the means .

 ( see table iii.1. ) .

for pma supplements , the median time ranged from 126 days to 173 days in the first 3 years , then jumped to 288 days in 1992 .

in 1993 and 1994 , the median declined to 242 and 193 days , respectively .

 ( see figure 4. ) .

this trend was reflected in the mean review time that peaked at 336 days in 1992 .

although the mean dropped to 162 days in 1994 , this is expected to increase because 21 percent of the applications had not been completed at the time of our study .

 ( see table iii.7. ) .

applications for original pmas made up less than 1 percent of all applications submitted to fda to market new devices in the period we reviewed .

pma supplements comprised about 8 percent of the applications .

the number of applications submitted for pma review declined each year .

in 1989 , applications for original pmas numbered 84 .

by 1994 , they were down to 43 .

similarly , pma supplements decreased from 804 in 1989 to 372 in 1994 .

 ( see tables iii.1 and iii.7. ) .

of the 401 applications submitted for original pmas , 33 percent were approved , 26 were withdrawn , and nearly a third remained open .

the remainder ( about 9 percent ) fell into a miscellaneous category .

 ( see appendix i. ) .

a much higher percentage of the 3,640 pma supplements ( 78 percent ) were approved in this same period , and fewer pma supplements were withdrawn ( 12 percent ) .

about 9 percent of the applications remained open , and 2 percent fell into the miscellaneous category .

for pma reviews that resulted in approval , non - fda time constituted approximately one - fourth of the total elapsed time for original pmas and about one - third for pma supplements .

the mean fda time for original pmas ranged from 155 days in 1994 to 591 days in 1992 .

non - fda times for those years were 34 days in 1994 and 165 days in 1992 .

for pma supplements , fda review times were lower , ranging from a low of 105 days ( 1990 ) to a high of 202 days ( 1992 ) .

non - fda time for those years were 59 days ( 1990 ) and 98 days ( 1992 ) , respectively .

 ( see table iii.13. ) .

figures 5 and 6 display the proportion of fda and non - fda time for the subset of pmas that were approved .

for ides , the mean review time between submission and fda action was 30 days , and it has not changed substantially over time .

unlike 510 ( k ) s and pmas , ides are “deemed approved” if fda does not act within 30 days .

of the 1,478 original ide submissions from fiscal year 1989 to 1995 , 33 percent were initially approved ( 488 ) and 62 percent were denied or withdrawn ( 909 ) .

the number of ide submissions each year ranged from a high of 264 in 1990 to a low of 171 in 1994 .

 ( see table iv.1. ) .

our objective was to address the following general question: how has the time that 510 ( k ) , pma , and ide applications spend under fda review changed between fiscal year 1989 and the present ? .

to answer that question , we also looked at a subset of applications that were approved , distinguishing the portion of time spent in fda's review process ( fda time ) from that spent waiting for additional information ( non - fda time ) .

for applications that were approved , we present the average number of amendments that were subsequently added to the initial application as well as the average number of times fda requested additional information from the applicant .

 ( both of these activities affect fda's review time. ) .

we used both the median and mean to characterize review time .

we use the median for two reasons .

first , a large proportion of the applications have yet to be completed .

since the median is the midpoint when all review times are arranged in consecutive order , its value can be determined even when some applications requiring lengthy review remain open .

in contrast , the mean can only be determined from completed applications .

 ( in this case , applications that have been completed by may 18 , 1995. ) .

in addition , the mean will increase as applications with lengthy reviews are completed .

to illustrate , for applications submitted in 1993 , the mean time to a decision was 269 days for 510 ( k ) applications that have been closed .

however , 3 percent of the applications have yet to be decided .

if these lengthy reviews were arbitrarily closed at may 18 , 1995 ( the cutoff date for our data collection ) , the mean would increase to 285 days .

in contrast , the median review time ( 230 days ) would remain the same regardless of when these open applications were completed .

the second reason for using the median is that the distributions of review time for 510 ( k ) , original pma , and pma supplement applications are not symmetric , that is , having about the same number of applications requiring short reviews as lengthy reviews .

the median is less sensitive to extreme values than the mean .

as a result , the review time of a single application requiring an extremely lengthy review would have considerably more effect on the mean than the median .

figure 7 shows the distribution for 510 ( k ) s submitted in 1993 , the most recent year in which at least 95 percent of all 510 ( k ) applications had been completed .

the distribution is skewed with a mean review time of 269 days and a median review time of 222 days for all completed applications .

mean = 269 median = 222 to provide additional information , we report on the mean review times as well as the median .

the discrepancy between the two measures gives some indication of the distribution of review time .

when the mean is larger than the median , as in the case of the 510 ( k ) s above , it indicates that a group of applications required lengthy reviews .

another reason we report the means is that , until recently , fda reported review time in terms of means .

in appendix i , we provide the categories we used to designate the different fda decisions and how our categories correspond to those used by fda .

detailed responses to our study objective are found in tabular form in appendixes ii , iii , and iv for 510 ( k ) s , pmas , and ides , respectively .

we report our findings according to the fiscal year in which the applications were submitted to fda .

by contrast , fda commonly reports review time according to the fiscal year in which the review was completed .

although both approaches measure review time , their resultant statistics can vary substantially .

for example , several complex applications involving lengthy 2-year reviews submitted in 1989 would increase the average review time for fiscal year 1989 in our statistics and for fiscal year 1991 in fda's statistics .

consequently , the trend for review time based on date - of - submission cohorts can differ from the trend based on date - of - decision cohorts .

 ( see appendix v for a comparison of mean review time based on the two methods. ) .

the two methods provide different information and are useful for different purposes .

using the date - of - decision cohort is useful when examining productivity and the management of resources .

this method takes into consideration the actual number of applications reviewed in a given year including all backlogs from previous years .

alternatively , using the date - of - submission cohort is useful when examining the impact of a change in fda review policy , which quite often only affects those applications submitted after its implementation .

to minimize the effect of different policies on review time within a cohort , we used the date - of - submission method .

we conducted our work in accordance with generally accepted government auditing standards between may and june 1995 .

officials from fda reviewed a draft of this report and provided written comments , which are reproduced in appendix vi .

their technical comments , which have been incorporated into the text where appropriate , have not been reprinted in the appendix .

fda believed that the report misrepresented the current state of the program as the draft did not acknowledge recent changes in the review process .

fda officials suggested a number of explanations for the apparent trends in the data we reported ( see appendix vi ) .

although recent initiatives to improve the review process provide a context in which to explain the data , they were outside the scope of our work .

we were not able to verify the effect these changes have actually had on review time .

to the extent that these changes did affect review time , they are reflected in the review times as presented and are likely to be reflected in future review times .

the agency also believed that the draft did not reflect the recent improvements in review time .

we provided additional measures of review time in order to present the review times for the more recent years .

we have also included more information on the difference between the date - of - submission and date - of - decision cohorts , and we have expanded our methodological discussion in response to points fda made on the clarity of our presentation .

 ( additional responses to the agency comments are included in appendix vi. ) .

as agreed with your office , unless you publicly announce its contents earlier , we plan no further distribution of this report until 30 days after its date of issue .

we will then send copies to other interested congressional committees , the secretary of the department of health and human services , and the commissioner of food and drugs .

copies will also be made available to others upon request .

if you or your staff have any questions about this report , please call me at ( 202 ) 512-3092 .

the major contributors to this report are listed in appendix vii .

fda uses different categories to specify the type of decision for 510 ( k ) s , pmas , and ides .

for our analysis , we collapsed the multiple decision codes into several categories .

the correspondence between our categories and fda's are in table i.1 .

additional information requested ; applicant cannot respond within 30 days drug ( cder ) review required ( continued ) .

the following tables present the data for premarket notifications , or 510 ( k ) s , for fiscal years 1989 through may 18 , 1995 .

the first set of tables ( tables ii.1 through ii.6 ) presents the time to a decision — from the date the application is submitted to the date a decision is rendered .

we first present a summary table on the time to a decision by fiscal year ( table ii.1 ) .

the grand total for the number of applications includes open cases — that is , applications for which there had not been any decision made as of may 18 , 1995 .

as the distribution for time to a decision is not symmetric ( see figure 1 in the letter ) , we present the means and percentiles to characterize the distribution .

 ( the means and percentiles do not include open cases. ) .

the second table is a summary of the time to a decision by class , tier , medical specialty of the device , and reviewing division ( table ii.2 ) .

the next four tables ( ii.3 through ii.6 ) provide the details for these summary tables .

the totals in these tables include only applications for which a decision has been rendered .

the class , tier , and medical specialty of some of the devices have yet to be determined and are designated with n / a .

medical specialties other than general hospital or general and plastic surgery include anesthesiology ; cardiovascular ; clinical chemistry ; dental ; ear , nose , and throat ; gastroenterology / urology ; hematology ; immunology ; microbiology ; neurology ; obstetrics / gynecology ; ophthalmic ; orthopedic ; pathology ; physical medicine ; radiology ; and clinical toxicology .

the five reviewing divisions in fda's center for devices and radiological health are division of clinical laboratory devices ( dcld ) ; division of cardiovascular , respiratory and neurological devices ( dcrnd ) ; division of general and restorative devices ( dgrd ) ; division of ophthalmic devices ( dod ) ; and division of reproductive , abdominal , ear , nose and throat , and radiological devices ( draer ) .

the second set of tables ( tables ii.7 through ii.12 ) presents the mean time to determine equivalency .

we provide the means for total fda time , non - fda time , and total elapsed time .

fda time is the total amount of time the application was under fda review including queue time — the time to equivalency without resetting the fda review clock .

the total elapsed time , the duration between the submission of the application and fda's decision , equals the sum of the fda and non - fda time .

we deleted cases that had missing values or apparent data entry errors for the values relevant to calculating fda and non - fda time .

therefore , the total number of applications determined to be equivalent in this group of tables differs from that in the first set .

again , we have two summary tables , followed by four tables providing time to determine equivalency by class , tier , medical specialty , and reviewing division ( tables ii.7 through ii.12 ) .

in reviewing a pma application , fda conducts an initial review to determine whether the application contains sufficient information to make a determination on its safety and effectiveness .

a filing decision is made — filed , filed with deficiencies specified , or not filed — based on the adequacy of the information submitted .

the manufacturer is notified of the status of the application at this time , especially since deficiencies need to be addressed .

as part of the substantive review , a small proportion of pma applications are also reviewed by an advisory panel .

these panels include clinical scientists in specific medical specialties and representatives from both industry and consumer groups .

the advisory panels review the applications and provide recommendations to the agency to either approve , deny , or conditionally approve them .

fda then makes a final determination on the application .

to examine in greater detail those cases where the intermediate milestones were applicable , we calculated the average duration between the various dates — submission , filing , panel decision , and final decision .

the number of applications differs for each of the milestones as not all have filing or panel dates .

 ( see figure iii.1. ) .

the following tables present information on review time for pma applications for fiscal years 1989 through 1995 .

original pma applications are distinguished from pma supplements .

some observations were deleted from our data because of apparent data entry errors .

the first set of tables ( tables iii.1 through iii.6 ) presents the time to a decision for original pmas — from the date the application is submitted to the date a decision is rendered .

the second set of tables ( tables iii.7 through iii.12 ) provides similar information , in the same format , for pma supplements .

we first present a summary table on the time to a decision by fiscal year ( tables iii.1 and iii.7 ) .

again , the grand total for the number of applications includes the number of open cases — that is , applications for which there had not been any decision made as of may 18 , 1995 .

as with 510 ( k ) s , the distributions of time to a decision for original pmas and pma supplements are not symmetric .

thus we report means and percentiles to characterize these distributions .

 ( these means and percentiles do not include open cases. ) .

figure iii.2 presents the distribution for original pmas submitted in 1989 , the most recent year for which at least 95 percent of the applications had been completed .

figure iii.3 presents the distribution for pma supplements submitted in 1991 , the most recent year with at least a 95-percent completion date .

the second table is a summary of the time to a decision by class , tier , relevant medical specialty of the device , and reviewing division ( tables iii.2 and iii.8 ) .

the two summary tables are followed by four tables ( tables iii.3 through iii.6 and iii.9 through iii.12 ) presenting the details by class , tier , medical specialty , and reviewing division .

the totals in these tables include only applications for which a decision has been rendered .

the class , tier , and medical specialty of some of the devices have yet to be determined and are designated with n / a .

medical specialities other than cardiovascular or ophthalmic include anesthesiology ; clinical chemistry ; dental ; ear , nose , and throat ; gastroenterology / urology ; general and plastic surgery ; general hospital ; hematology ; immunology ; microbiology ; neurology ; obstetrics / gynecology ; orthopedic ; pathology ; physical medicine ; radiology ; and clinical toxicology .

the third set of tables provides information on the time to an approval , for both original pmas and pma supplements ( tables iii.13 through iii.18 ) .

four different measures of duration are provided — total fda time , non - fda time , total elapsed time , and fda review time .

total fda time is the amount of time the application is under fda's review process .

non - fda time is the time the fda clock is suspended waiting for additional information from the applicant .

the total elapsed time , the duration from the date the application is submitted to the date of fda's decision , equals the sum of total fda and non - fda time .

fda review time is fda time for the last cycle — excluding any time accrued before the latest resetting of the fda clock .

again , we first provide a summary table for time to an approval by fiscal year ( table iii.13 ) .

in this table , we also provide the number of amendments or the number of times additional information was added to the initial submission .

not all amendments were for information requested by fda as can be seen from the number of requests for information .

table iii.13 is followed by a summary by class , tier , medical specialty , and reviewing division ( table iii.14 ) .

tables iii.15 though iii.18 provide the details for these two summary tables .

the following tables present the average days to a decision for investigational device exemptions .

the first table presents the averages for the years from october 1 , 1988 , through may 18 , 1995 .

this is followed by summaries by class , tier , medical specialty , and then reviewing division .

the next four tables ( tables iv.3 through iv.6 ) provide the details for these summary tables .

we reported our findings according to the fiscal year in which the applications were submitted to fda ( date - of - submission cohort ) .

by contrast , fda commonly reports review time according to the fiscal year in which the review was completed ( date - of - decision cohort ) .

this led to discrepancies between our results and those reported by fda .

the following table illustrates the differences in calculating total elapsed time by the year that the application was submitted and the year that a decision was rendered .

comparisons are provided for 510 ( k ) s , pma supplements , original pmas , and ides .

our dataset did not include applications submitted before october 1 , 1988 .

consequently , the results presented in the following table understated the number of cases , as well as the elapsed time , when calculated by the year of decision .

that is , an application submitted in fiscal year 1988 and completed in 1989 would not have been in our dataset .

the following are gao's comments on the august 2 , 1995 , letter from fda .

1 .

the purpose of our review was to provide to fda's congressional oversight committee descriptive statistics on review time for medical device submissions between 1989 and may 1995 .

it was not to perform an audit of whether fda was in compliance with statutory review time , nor to examine how changes in fda management practices may have resulted in shortening ( or lengthening ) review times .

fda officials suggested that a number of process changes and other factors may have contributed to the trends we reported — for example , the increased complexity of the typical submission that resulted from the agency's exemption from review of certain low - risk devices .

we are not able to verify the effect changes have actually had on review time , and it may be that it is still too early for their impact to be definitively assessed .

2 .

in discussing our methodology in the draft report , we noted the differences between fda's typical method of reporting review time according to the year in which action on applications is finalized , as opposed to our method of assigning applications to the year in which they were submitted .

we also included an appendix that compares the results of the two different approaches .

 ( see appendix v. ) we agree with fda that it is important for the reader to understand these differences and have further expanded our discussion of methodology to emphasize this point .

 ( see p .

14. ) .

3 .

we agree with fda that our report “deals only with calculations of averages and percentiles” — that is , with means , medians ( or 50th percentile ) , as well as the 5th and 95th percentiles .

however , fda's suggested additions do not extend beyond such descriptive statistics .

we also agree that mean review times in the presence of numerous open cases may not be meaningful .

for this reason , we have included open cases in our tables that report review time , but we have excluded them from the calculation of means .

fda suggests that we include open cases in our calculation of medians .

we have adopted this suggestion and presented our discussion of trends in terms of the median review time for all cases .

it should be noted , however , that including open cases increases our estimate of review time .

 ( for example , including open cases raises the calculation of 510 ( k ) median review time from the 126 days we reported for 1994 to 152 days. ) .

figure vi.1 depicts the relationship among the three measures of elapsed time for 510 ( k ) submissions: the mean of closed cases , the median of closed cases , and the median of all cases .

the two measures of closed cases reveal roughly parallel trends , with median review time averaging some 45 days fewer than mean review time .

the two estimates of median review time are nearly identical from 1989 through 1990 since there are very few cases from that period that remain open .

the divergence between the two medians increases as the number of open cases increases in recent years until 1995 , when the median , including open cases , is larger than the mean of closed cases .

mean ( closed cases ) median ( closed cases ) median ( all cases ) 4 .

while we are unable to reproduce the calculations performed by fda , we agree in general with the trends indicated by fda .

specifically , our calculations , as presented in our draft report tables ii.7 and following , showed a decrease from 1993 to 1994 in fda review time for finding a 510 ( k ) submission substantially equivalent .

by our calculation , this declined from a mean of 173 days in 1993 to 100 days in 1994 .

the proportion of 510 ( k ) applications reaching initial determination within 90 days of submission increased from 15.8 percent in 1993 to 32 percent in 1994 and 57.9 percent between october 1 , 1994 , and may 18 , 1995 .

clearly , since 1993 , more 510 ( k ) cases have been determined within 90 days , and the backlog of undetermined cases has been reduced .

because a review of the nature and complexity of the cases still open was beyond the scope of this study , we cannot predict with certainty whether , when these cases are ultimately determined , average review time for 1995 cases will be shorter than for cases submitted in 1993 .

5 .

fda time was reported in our draft report tables ii.7 through ii.12 , and findings contrasting the differences between fda time and non - fda time were also included .

additional language addressing this distinction has been included in the text of the report .

6 .

fda's contends that 1989 was an atypical year for 510 ( k ) submissions and therefore a poor benchmark .

however , we do not believe that starting our reporting in 1989 introduced any significant bias into our report of the 510 ( k ) workload .

indeed , our draft report concluded that the number of 510 ( k ) submissions had “remained relatively stable” over the 1989-94 period .

if we had extrapolated the data from the first 7-1 / 2 months of 1995 to a full year , we would have concluded that the current fiscal year would have a substantially lower number of 510 ( k ) submissions ( 16 percent to 31 percent ) than any of the previous 6 years .

7 .

the tier classification was created by fda to manage its review workload ; however , it was not our intention to evaluate or in any way assess the use of tiers for such purposes .

the tier classification was based on “the potential risk and complexity of the device.” accordingly , both class and tier provide a rough indication of a device's complexity .

8 .

we agree that our draft report aggregated original pma submissions and pma supplements in summarizing its findings .

we have now disaggregated pma statistics throughout .

9 .

we interpret the figures presented by fda to represent the mean number of days elapsed between receipt ( or filing ) of a pma submission and a given month for cases that have not been decided .

we agree with fda that the average review time for open original pmas does not appear to have increased substantially since the beginning of calendar 1994 and that the average review time has decreased for pma supplements since late 1994 .

decreasing these averages is the product of either an increasing number of new cases entering the system or of closing out older cases in the backlog or both .

since the number of pmas ( originals and supplements ) submitted in recent years has declined , the evidence suggests that the drop in average time for pending pma supplements resulted from eliminating lengthy backlogged cases .

10 .

as noted earlier , assessing the impact of specific management initiatives is beyond the scope of this report .

however , we do agree with fda that the approval rate for initial ide submissions doubled between 1994 and 1995 ; by our calculations , it increased from 25 percent to 54 percent .

we have not independently examined the total time to approval for all ides .

robert e. white , assistant director bertha dong , project manager venkareddy chennareddy , referencer elizabeth scullin , communications analyst the first copy of each gao report and testimony is free .

additional copies are $2 each .

orders should be sent to the following address , accompanied by a check or money order made out to the superintendent of documents , when necessary .

orders for 100 or more copies to be mailed to a single address are discounted 25 percent .

u.s. general accounting office p.o .

box 6015 gaithersburg , md 20884-6015 room 1100 700 4th st. nw ( corner of 4th and g sts .

nw ) u.s. general accounting office washington , dc orders may also be placed by calling ( 202 ) 512-6000 or by using fax number ( 301 ) 258-4066 , or tdd ( 301 ) 413-0006 .

each day , gao issues a list of newly available reports and testimony .

to receive facsimile copies of the daily list or any list from the past 30 days , please call ( 202 ) 512-6000 using a touchtone phone .

a recorded menu will provide information on how to obtain these lists .

