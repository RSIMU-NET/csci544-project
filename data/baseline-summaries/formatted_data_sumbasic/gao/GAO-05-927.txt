the federal government is in a period of profound transition and faces an array of challenges and opportunities to enhance performance , ensure accountability , and position the nation for the future .

these 21st century challenges include the nation's large , long - term fiscal imbalance , evolving national and homeland security threats , increasing global interdependence , the global shift to market - oriented knowledge - based economies , an aging and more diverse population , and rapid advances in science and technology .

in the face of these pressures , it is vital to maximize the performance of federal agencies in achieving their long - term goals .

the government performance and results act of 1993 ( gpra ) planning and reporting requirements can provide the essential information needed to assess federal agencies' performance , hold agencies accountable for achieving results , and help the baseline review of federal programs , operating functions , and activities needed to respond to the nation's long - term structural fiscal imbalance .

gpra requires executive agencies to develop strategic plans , prepare annual performance plans , measure progress toward the achievement of the goals in the annual performance plans , and report annually on their progress in program performance reports .

for planning and performance measurement to be effective , federal managers need to use performance information to identify performance problems and look for solutions , develop approaches that improve results , and make other important management decisions .

a 2004 gao report that reviewed the effectiveness of gpra found that while the percentage of federal managers who report having performance measures for their programs has increased over time , their use of performance information in making key management decisions , such as adopting new program approaches or changing work processes , has not .

federal agencies also appear to differ considerably in the extent to which they use performance information to manage .

identifying practices associated with the increased use of performance information could be helpful to federal agencies seeking to better use performance information to inform their decisions and ultimately achieve results .

although performance information could also be helpful for external purposes , such as congressional decision making , transparency , and public accountability , this report focuses on use of performance information by federal agency managers .

this report responds to your request that we identify ( 1 ) how federal agencies can use performance information to make management decisions and ( 2 ) practices that can facilitate the use of performance information .

to address the objectives , we reviewed relevant literature , including previous gao reports , spoke to experts in using performance information , and held group discussions with federal program managers .

we also interviewed individuals within five federal agencies and reviewed documentation to illustrate in greater detail how program managers have used performance information to make decisions and specific agency practices that facilitated those uses .

we selected the five agencies — the departments of commerce , labor , transportation , and veterans affairs , and the small business administration — on the basis of a number of factors , including a relatively high agency score on our 2000 gpra survey regarding the extent to which agency managers reported using performance information , and relatively good agency marks in the september 2004 executive branch management scorecard ( president's management agenda ) .

we also considered information obtained from interviews with experts , and diversity in terms of program type and size .

it should be noted that we did not attempt to identify all agencies and programs that could have illustrated these uses and practices .

in addition , we reviewed existing relevant information regarding the quality of performance information where available but did not systematically assess the quality of the performance information used in the examples we cite .

finally , for most of the examples , we describe how performance information was used to make decisions , but we did not attempt to verify that the use ultimately resulted in improved outcomes .

 ( see appendix i for a more detailed discussion of our scope and methodology and for further information on the five agencies. ) .

we conducted our work in accordance with generally accepted government auditing standards from september 2004 through august 2005 .

gpra helped create a governmentwide focus on results by establishing a statutory framework for performance management and accountability , with the necessary infrastructure to generate meaningful performance information .

gpra introduced planning and reporting requirements that seek to shift the focus of federal management and decision making from a preoccupation with the number of program tasks or activities completed or services provided to a more direct consideration of the results of programs .

the act was intended to improve federal program effectiveness , accountability , and service delivery .

gpra requires federal agencies to develop strategic plans with long - term , outcome - oriented goals and objectives , annual goals linked to the long - term goals , and annual reports on the results achieved .

agencies are required to measure progress toward the achievement of the goals in annual performance plans and report annually on their progress in program performance reports .

as we reported in our 10-year retrospective report on the effectiveness of gpra , the act's requirements have laid a solid foundation of results - oriented agency planning , measurement , and reporting that has begun to address the purposes of gpra .

performance planning and measurement have slowly yet increasingly become a part of agencies' cultures .

according to three government - wide , random sample surveys of federal managers conducted by us in 1997 , 2000 , and 2003 , managers reported having significantly more of the types of performance measures called for by gpra , particularly outcome - oriented performance measures , in 2003 than in 1997 , when gpra went into effect governmentwide .

the benefit of collecting performance information is only fully realized when this information is actually used by managers to make decisions oriented toward improving results .

while our surveys found that managers reported having more performance measures in 2003 than in 1997 , the data showed that the use of performance information for program management activities did not increase significantly from 1997 levels .

in our survey , we asked managers about their use of performance information for specific purposes , such as “setting program priorities” , “allocating resources” , or “adopting new program approaches.” as shown in figure 3 , the majority of managers who expressed an opinion reported using performance information for these uses to a great or very great extent in 2003 .

while the reported use of performance information for these uses to a great or very great extent fluctuated somewhat between 1997 and 2003 , the extent of use in 2003 was not significantly different from 1997 levels for any category of use except “adopting new program approaches or changing work processes” , where use actually decreased .

from our 2000 survey , we also know that use of performance information has varied widely among agencies .

for example , while 56 percent of managers overall reported using performance information when setting program priorities in 2000 , the percentage of managers within specific agencies reporting this use to a great or very great extent ranged from 26 percent to 64 percent .

similarly , wide variation among agencies was seen in managers' reported use of performance information for other types of management decisions .

for example , the reported use of performance information to a great or very great extent in agencies ranged from 24 to 66 percent when allocating resources , from 25 to 64 percent when adopting new program approaches or changing work processes , and from 16 to 66 percent when setting individual job expectations .

federal agencies can use performance information to make various types of management decisions to improve programs and results .

we have previously reported that leading organizations that have progressed toward results - oriented management use performance information as a basis for decision making .

the full benefit of collecting performance information is realized only when managers actually use it to manage .

from our review of the literature , agency documents and interviews with experts and agency officials , we identified four categories of management decisions for which federal agency managers can use performance information .

 ( see fig .

4 ) .

managers can use performance information to identify problems in existing programs , to try to identify the causes of problems , and / or to develop corrective actions .

they can also use program performance information to develop strategies , plan and budget , identify priorities , and make resource allocation decisions to affect programs in the future .

agency managers can also use performance information to reward individuals or organizations who meet or exceed expectations .

finally , managers can use performance information to identify more effective approaches to program implementation and share those approaches more widely across the agency .

agencies can use performance information to identify problems or weaknesses in programs , to try to identify factors causing the problems , and to modify a service or process to try to address problems .

we have reported that leading organizations that have progressed toward results - oriented management have used performance information to identify gaps in performance , improve organizational processes , and improve their performance .

we found several examples where federal program managers used performance data to identify problems and corrective actions at the agencies we examined .

officials in the office of participant assistance ( opa ) at the employee benefits security administration ( ebsa ) in the department of labor ( dol ) told us that when data for a performance measure of customer satisfaction indicated a problem , they changed a process to try to improve performance .

one of ebsa's functions is to provide information and assistance for individuals covered by private retirement and health and welfare plans , plan sponsors , and members of the employee benefits community .

ebsa has contracted with an outside organization since 2003 to collect data through a specialized survey on customer satisfaction with ebsa services .

data indicated that customers whose cases were referred to the enforcement side of ebsa were reporting lower satisfaction rates .

an analysis of data for specific survey questions identified the need for improved communication .

investigating an inquiry or complaint could sometimes take up to 2 years , and a customer might not receive any information during that time .

as a result of the performance data , ebsa changed a standard operating procedure in january 2005 so that customers would be kept informed about the status of their open inquiries or complaints .

under the new procedure , when an inquiry is referred to the enforcement staff for investigation , the opa benefits advisor informs the inquirer about the referral and sets realistic expectations for future contact by an investigator .

investigative staff are to make initial contact with the customer no later than 30 days following receipt of the referral and maintain contact with the inquirer on a quarterly basis until the matter is resolved .

managers plan to continue to monitor customer satisfaction to see whether the changes lead to improved performance .

through the performance enhancement project ( pep ) , the office of workforce investment in dol has used performance information to identify the technical assistance needs of state and local employment and training programs and has then provided targeted assistance to try to improve performance .

the pep project , which began in october 2002 , has provided technical assistance and training for targeted state and local workforce organizations that receive funds under the workforce investment act ( wia ) .

poorly performing states , as shown by the performance measures ( supplemented by analysis from regional dol staff ) , have received technical assistance designed to improve their performance through pep .

dol's office of workforce investment sent a questionnaire to all the regional offices and held a conference with them at the close of the first pep project to assess the effectiveness of the technical assistance that had been given .

this information was used to improve the second year's project .

online tutorials have also been developed under pep in response to requests from states .

officials in the veterans health administration ( vha ) network that includes facilities located in maryland , virginia , west virginia , and pennsylvania , stated that in response to one of the network facilities not meeting the heart failure performance measure target , all of the facilities adopted a new process to improve the network's performance .

according to an official , in the first quarter of 2004 , the network was at risk of not meeting the entire set of 10 cardiovascular performance measures if one of its facilities did not improve its low score on the heart failure performance measure by the end of the year .

the heart failure performance measure is a cumulative performance measure that assesses whether discharged heart failure patients receive six types of instructions , including instructions for monitoring weight after discharge and taking medications .

the instructions are critical because patients' noncompliance with physicians' instructions is often a cause for rehospitalization .

an agency official stated that the entire network implemented a new set of mandatory data fields in patients' electronic medical records .

the data fields include the six types of instructions and have to be filled out when a facility discharges a heart failure patient .

according to this official , the result of the implementation of the new mandatory fields in the patients' electronic records was that the facility that was not meeting the heart failure performance measure target in the first quarter improved its score to the “fully satisfactory” category in the fourth quarter .

agencies can use performance information to make decisions that affect future strategies , planning and budgeting , identifying priorities , and allocating resources .

we have previously reported that outcome - based performance information should be used for the allocation of resources and in deciding among competing priorities in a results - oriented management system .

in addition , linking cost with performance information infuses performance concerns into planning and budgetary deliberations , prompting agencies to reassess their performance goals and strategies and to more clearly understand the cost of performance .

performance information also allows program managers to compare their programs' results with goals and thus determine where to target program resources to improve performance .

when managers are faced with reduced resources , the same analysis can help them target reductions to minimize negative impacts on program results .

we found a number of examples among our case agencies of managers using performance information to identify priorities and allocate resources , and to shape future program strategy .

the national highway traffic safety administration ( nhtsa ) has used performance information to set priorities in budgeting and to target resources .

the senior associate administrator for traffic injury control annually sends out a memo that identifies agency priorities that support the department of transportation's ( dot ) strategic goals and are based on performance information for traffic - injury - related measures , such as safety belt use and impaired driver rates .

the memo directs managers to focus their programs and proposals to support these priorities .

in addition , nhtsa used performance information on alcohol - related injuries and fatalities to target grant funding and specific program strategies to states with the highest impaired driver rates .

using information reported through the fatality analysis reporting system ( fars ) , nhtsa identified 13 states that represented 46 percent of the total number of alcohol - related fatalities in the united states .

officials said nhtsa worked closely with these 13 states to implement the impaired - driving program strategies it had designed .

the strategies involved state - sponsored , high - visibility law enforcement activities in conjunction with a nhtsa - designed media campaign .

a nhtsa official said that the agency brought senior policy and law enforcement officials from these states together and presented the performance information and evaluations showing impaired driving rates and the effectiveness of the high visibility law enforcement and media campaign .

in order to receive funding , the targeted states had to agree to implement the program that nhtsa had designed , including the media campaign .

after the publicized crackdown periods , nhtsa provided the targeted states with additional evaluation resources .

the small business administration ( sba ) used performance and cost information to reallocate resources to better meet priorities .

in the 1990s , sba created business information centers ( bic ) , a community partnership service to provide entrepreneurs with access to computers and the internet to help them access business information and develop business plans .

officials said that , as a partnership using hardware and software and library resources donated from private technology companies , the program was designed to require minimal sba employee support or capital costs .

however , after analyzing financial and human capital resources , including the data collected through their annual survey of how much support sba employees provide for various programs , they found that substantial employee resources were being devoted to the bics , on the order of $11 million .

this cost information led sba officials to reconsider the service .

since computers had become more accessible to entrepreneurs than when the bic program was designed , and because assistance to entrepreneurs could be provided more efficiently though other programs , sba decided to end its participation in the program and has phased out its role in the community partnerships .

agencies can use performance information to affect pay decisions and to reward individuals , and in some cases , grantees .

using performance information this way reinforces accountability and creates incentives for achieving results .

we have previously reported that high - performing public - sector organizations create a clear “line of sight” between individual performance and organizational success showing how team , unit , and individual performance can contribute to overall organizational results .

there is growing recognition that the government needs to transform how it compensates its employees to achieve greater results .

to this end , some agencies have implemented performance agreements as a vehicle for bringing results - oriented performance information into evaluations of performance .

a revised performance - based pay system for members of the senior executive service ( ses ) across the federal government has been in effect since january 2004 , as authorized by congress and overseen by the office of personnel management ( opm ) , where pay adjustments for ses members are to be based on the alignment of individual performance and contributions to the agency's mission and strategic goals , among other things .

the human capital reforms under way at the departments of defense and homeland security are intended to help them manage their human capital to achieve results .

we found several examples where case agencies used performance information to recognize and reward performance , as described next .

the federal aviation administration ( faa ) uses performance information to affect pay decisions .

faa has linked employee annual pay increases to the achievement of agencywide goals through the performance - based pay system .

at the end of fiscal year 2004 , 78 percent of employees were included in the agency's performance - based pay system , which allocates increases on the basis of individual and organizational performance .

at the individual level , employees can receive two types of increases .

employees earn the first increase for meeting individual goals and the second increase for achieving outstanding individual performance .

at the organizational level , employees are eligible for the organizational success increase ( osi ) .

this is an agencywide pay increase based on the performance of the agency as a whole on the 31 key performance measures in the agency's strategic plan , called the flight plan .

the osi funding pool consists of the amount of the general increase for general schedule ( gs ) employees in other federal agencies plus an additional 1 percent ( which reflects a portion of the funds previously spent on within - grade increases ) .

receiving the full osi depends on whether actual performance meets the goals .

in calendar year 2004 , faa employees received an osi increase of 2.13 percent .

faa also offers short term incentives to faa senior staff for achieving key performance targets and specified accomplishments in implementing flight plan initiatives .

vha uses performance information to create incentives for network directors .

we previously reported that the use of performance information in performance agreements helped vha define directors' accountability for specific goals and monitor progress during the year , and contributed to their evaluations .

vha accomplishes this through the performance - based review process , which links a director's performance rating and compensation to the performance of the network that he or she oversees .

specifically , a director's annual ratings and bonuses are based on how well he or she meets the goals in the performance contract .

as detailed in the contract , the network director's compensation is affected by that network's scores on performance measures , which include clinical waiting times , the percentage of patients receiving cancer screenings , and patient satisfaction .

half of the network director's performance evaluation is based upon the cumulative score on the network's performance measures .

the employment and training administration ( eta ) uses performance information to provide incentives for and apply sanctions to state programs that receive grants under title i of the workforce investment act .

the authority to hold grantees accountable for performance in this manner is provided for in the wia legislation .

each state negotiates performance goals with dol prior to the beginning of the program year for the 17 wia indicators measuring employment , retention , earnings , attainment of credentials , attainment of skills , and customer satisfaction .

states are eligible for incentive awards if they have exceeded performance goals set for programs funded under 3 separate programs , one of which is wia .

in general , financial sanctions may be levied if performance is less than 80 percent of the negotiated performance levels for 2 consecutive years or if the state fails to submit an accurate and complete annual performance report .

specific mitigating factors may be considered , such as performance relative to other states , improvement efforts , and economic conditions , among others .

we have reported that high - performing organizations continuously assess and benchmark performance and efforts to improve performance .

they evaluate their efforts using fact - based understandings of how their activities contribute to accomplishing the mission and broader results , and optimize their efforts through continuous improvement .

managers can use performance information to identify and increase the use of program approaches that are working well , and consider alternative processes in areas where goals are not being met .

pilots and demonstration projects can be used to identify innovative ways to improve performance — by allowing for experiences to be rigorously evaluated , and shared systematically with others , and by allowing for new procedures to be adjusted as appropriate — before receiving wider application .

organizations can also use the process improvement technique of benchmarking — comparing their processes with those of private and public organizations that are thought to be the best in their fields .

by benchmarking its own processes against those of leading business and government entities , an organization can learn how much change it needs to make and what changes might be the right ones .

we found examples of these types of uses of performance information in the case agencies , as described next .

on the basis of performance information from a pilot test , the national weather service ( nws ) adopted a more effective flash flood monitoring and prediction tool on a national basis .

nws provides flash flood warning services and verifies the timeliness and accuracy of its warnings .

it aims to improve its performance in this area through the flash flood performance goals entitled , flash flood warning lead time and flash flood warning accuracy , as outlined in its strategic plan .

a prototype flash flood monitoring application was developed and first tested at the pittsburgh weather forecast office ( wfo ) beginning in 1995 .

on the basis of improved performance data achieved with the prototype and case studies of several flash flood events in the pittsburgh area , nws decided to develop and test an enhanced version of the pilot system .

the enhanced version , called the flash flood monitoring and prediction ( ffmp ) program , continuously monitors rainfall rates and hydrologic conditions to provide automated alerts when a dangerous flood situation may be developing on a given stream or catchment .

in 2002 nws began implementing ffmp nationwide , with the aim of improving flash flood services and helping nws to meet its flash flood performance goals .

initial training on how to use the ffmp system was provided for all wfos and additional training is provided at routinely offered courses .

according to a recent survey , nearly all of the wfos were using the system .

it is expected that implementing the system will facilitate improvements in the accuracy and timeliness of official nws flash flood warnings , and enable forecasters to provide more specific location information within a flash flood warning .

eta has used performance information on state and local workforce investment areas to identify and nominate participants for the national business learning partnership's ( nblp ) peer - to - peer , mentoring initiative .

the nblp , which started in october of 2003 , links local workforce areas that want to improve their services ( protégés ) with workforce areas that have exceeded performance standards ( mentors ) .

the program focuses on the delivery of workforce services tailored to the needs of business and industry in that specific workforce area .

overall , 19 mentor sites and 25 protégé sites have participated .

examples of the types of performance and related information considered by eta in selecting workforce areas to nominate as mentors include the following: successful engagement with businesses to meet the workforce needs of local industry ; high performance on the 17 legislated wia performance indicators measuring employment , retention , earnings , attainment of credentials , attainment of skills , and customer satisfaction ; and the transferability of mentor practices to other areas .

protégés were selected on the basis of their desire to improve their performance and services to businesses , and also on the basis of whether they had problems meeting the wia performance measures .

each protégé site was matched with a mentor site to help it develop a work plan .

the protégés and mentors conducted at least two site visits to each other's respective areas to study the local workforce investment operations and share information .

in addition to peer - to - peer consultation , nblp case studies have been developed to provide a wider audience with access to participants' experiences and learning .

each case study includes practices and principles to improve performance outcomes by addressing the workforce needs of businesses and industries , as well as a guide to facilitate shared learning and promote action .

to assess the success of these partnerships , each protégé's performance on selected wia measures will be compared from performance year 2003 through performance year 2005 .

additional measures of success will include such considerations as contacts with businesses , resources leveraged , and workers trained and placed in high - growth careers .

agencies can adopt or apply a number of practices that can enhance the use of performance information for policy and program decisions aimed at improving results .

the concept of practices as used in this report includes administrative or management tools , systems , or processes that agencies can implement .

from our interviews with experts and agency officials and our review of related literature and agency documents , we identified five types of practices that can facilitate greater use of performance information .

as illustrated in figure 5 , the five types of practices are demonstrating management commitment ; aligning agency goals , objectives and measures ; improving the usefulness of performance information to better meet management's needs ; developing agency capacity to effectively use performance information ; and frequently and effectively communicating performance information within the agency .

we discuss the 5 practices in detail following the figure .

the commitment of agency managers to results - oriented management is critical to increased use of performance information for policy and program decisions .

as we previously reported , demonstrating the willingness and ability to make decisions and manage programs on the basis of results , and inspiring others to embrace such a model , are important indicators of management's commitment .

agency officials from our case illustration programs also identified management commitment as central to encouraging the use of performance information in decisions .

officials from these agencies described how management showed this type of commitment by leading frequent , regular performance review meetings to discuss progress made toward the achievement of results , and by involving staff from different organizational levels in performance review meetings .

these methods assisted agencies in identifying performance problems and in developing performance improvement plans based on collected performance information .

sba conducts monthly meetings with the associate administrator of each mission and functional office to review that office's performance .

the administrator , deputy administrator , and chief operating officer ( coo ) participate .

each sba office has performance measures organized along three components of performance — office strategic goals , production goals , and project goals — on a scorecard .

prior to meeting , the coo's staff review the monthly and cumulative performance information for each office and ask each office to respond in writing to questions or concerns based on the data .

this analysis is the basis for the regular performance review meetings .

officials said management's commitment to regularly reviewing performance increases performance ownership among staff and competition among the offices to meet performance targets .

similarly , faa management demonstrates commitment through monthly , day - long , agencywide performance review meetings that are led by the administrator and key associate administrators who serve as goal leads for each faa flight plan goal area: increased safety , greater capacity , international leadership , and organizational excellence .

at these meetings , officials said that they discuss performance for the agency's 31 key performance metrics and the strategic initiatives supporting each .

when a business line is not meeting the performance targets for specific metrics , officials report on efforts planned or under way to improve performance .

for metrics where performance targets have been met , officials discuss the actions that were taken to achieve the targets .

officials said that during this performance review , the administrator identifies ious , outlining agreed - upon actions to be implemented .

officials said that they provide updates on the status of these ious at the following performance review meeting .

at the department of veterans affairs ( va ) , managers are involved in reviewing performance at different levels of the organization .

senior management hold monthly departmentwide meetings to review performance .

according to officials , the meetings are chaired by the deputy secretary and are attended by the heads of the three administrations: vha , the veterans benefit administration , and the national cemetery administration , as well as all of the staff offices within va. each administration reports financial status , workload , and key performance measures .

the deputy secretary has recently implemented reporting by exception at the monthly performance review .

reporting by exception requires that administration and staff offices offer an explanation for less - than - desired performance , describe plans or ongoing efforts to improve performance and discuss when results were expected .

at the following month's performance review , status information is presented to demonstrate progress .

in addition , success stories and the activities used to achieve them are also reported .

according to officials , within vha , mid - and lower - level managers are also involved in regular performance review meetings , including meetings involving the deputy under secretary and the directors of the regional networks , meetings of network directors and their facility directors , and meetings between facility directors and their staff .

in addition , according to officials , each of the facilities in one of the networks we visited , which includes va facilities in california , nevada , hawaii and the philippines , assigns a “champion” who is responsible for monitoring and presenting results for a specific performance measure at weekly facility management meetings .

agencies can encourage greater use of performance information by aligning agencywide goals and objectives , and by aligning program performance measures at each operating level with those goals and objectives .

gpra requires that agencies use performance measurement to reinforce the connection between their long - term strategic goals and the day - to - day activities of their managers and staff .

as we reported previously , in order to meet the gpra requirements , an agency should cascade its goals and objectives throughout the organization and should align performance measures to the objectives from the executive level down to the operational levels .

this forms hierarchies of goals and objectives and performance information that are appropriate to the managerial responsibilities and controls at each level of the organization .

this alignment increases the usefulness of the performance information collected to decision makers at each level , and reinforces the connection between strategic goals and the day - to - day activities of managers and staff .

we have also reported that a greater focus on results can be created by cascading organizational goals and objectives down to the individual performance level .

earlier in this report , we described how agencies can use performance information to recognize and reward performance and encourage the achievement of results .

alignment facilitates the linking of individual performance to organizational performance .

faa promotes alignment by requiring that all organizations use the same alignment framework and approach in preparing their annual business plans .

goals cascade throughout each of faa's 16 organizations to each individual employee .

the agency goals detailed in faa's strategic plan ( or flight plan ) drive new strategic initiatives and the ongoing , day - to - day operations of faa , referred to as their core business functions .

key elements required in the business plans for each of faa's four lines of business and 12 offices are developed using a systematic alignment approach that guides the organizations through the step - by - step process of defining and developing performance elements that support the flight plan goals .

organizations align themselves with the flight plan through this process , and targets cascade down through the organization into employee performance plans .

these plans identify specific work expectations and outcomes , and are required for every faa employee .

this alignment facilitates faa recognizing and rewarding performance by using performance information to affect pay decisions , as described earlier in this report .

vha's performance measures are aligned through different levels of the organization .

the same performance measures are used to assess vha's performance from the vha - wide level down through the network levels to the individual facilities .

for example , the performance measure of the percentage of patients receiving breast cancer screening is used at all three levels .

as mentioned earlier in this report , the performance score of a facility can have an effect upon the entire network to which it belongs .

as an illustration of how performance is “rolled up,” officials stated that in order to get a fully satisfactory rating at the network level , 80 percent of the hospitals in that network must have met their goals .

officials stated that if any facility is at the failing level for a performance measure , the entire network will also be rated as failing the measure .

in addition , alignment contributes to vha's ability to use performance information to provide incentives for network directors , through the performance - based review process described earlier .

to ensure that performance information will be both useful and used in decision making throughout the organization , agencies need to consider users' differing policy and management information needs .

practices that improve the usefulness of performance information can help to meet those needs .

we reported previously that to be useful , performance information must meet users' needs for completeness , accuracy , consistency , timeliness , validity , and ease of use .

other attributes that affect the usefulness of information include , but are not limited to , relevance , credibility , and accessibility .

we have reported previously on a number of practices that improve the usefulness of performance information to different users .

measures should be selected specifically on the basis of their ability to inform the decisions made at each organizational level , and should be appropriate to the responsibilities and control at each level .

in that regard , involving managers in the development of performance goals and measures is critical to increasing the relevance and therefore the usefulness of performance information to their day - to - day activities .

agency officials in our case illustrations identified a number of practices that increased the usefulness of performance information , including its relevance , ease of use , timeliness , and accessibility .

as discussed earlier , ebsa contracted with an outside organization to collect more useful customer satisfaction information .

by increasing the scope and depth of customer satisfaction data , the information has been made more relevant , and therefore , more useful to management's day - to - day activities .

prior to this contract , ebsa used another contractor that provided a general high - level index of customer satisfaction that provided comparability to other organizations .

however , in order to provide this comparability , the survey questions had to be standardized in a manner that was not as relevant for ebsa as for other organizations .

in addition , the first customer satisfaction survey did not provide a means for ebsa to disaggregate data to identify specific aspects of its performance .

recognizing that the information did not fully meet their needs , ebsa staff identified a new contractor to create and conduct a specialized customer satisfaction survey of clients that will provide comparability from year to year even if it does not provide comparability among other organizations .

survey questions are now tailored to ebsa's needs .

specific questions can be added and data disaggregated and analyzed as needed to focus in on potential problem areas .

for example , data can be broken down by categories such as regional office , benefit advisor , and type of inquiry .

the enforcement office of the department of labor's ebsa office implemented a new enforcement management system ( ems ) that officials say improved the usefulness of performance information , making it more timely , accessible , and easy to use .

the system , implemented in 1999 , manages information related to investigations into the potential violation of benefits laws .

these investigations are conducted by 385 investigators located at ebsa field offices across the country .

prior to the development of the ems , officials said that the enforcement office had a simple database system located at headquarters and that field offices used a separate case management system .

the ems was custommade for the enforcement office .

it tracks information about every investigation nationwide throughout its lifecycle , providing both field and headquarters staff access to real - time information .

according to officials , not only does the system make information more timely and accessible , it has increased the ease of use and relevance of performance information by incorporating user - friendly windows technology and allowing users to define their own information needs with customized queries and reports .

in addition , over 30 standardized statistical and case reports are available .

standardized statistical reports allow managers to view , by selected geographic area , summaries of such information as the different investigation types ( eg , fiduciary and criminal ) , the cases referred for litigation , and closed cases along with the associated results .

headquarters provides additional analysis of the information regarding overall progress toward policy goals , allowing adjustments to be made in the field offices .

sba has involved its program managers in the development of the agency's performance measurement system , allowing offices to determine their own goals and measures .

this practice increases the usefulness of performance information to the activities of offices and programs , and sba officials credit it with creating buy - in and ownership of the performance measurement system .

measures and targets must meet certain requirements as overseen by the chief operating officer .

for example , measures should support the strategic goals ; measures should be valid , measurable , and verifiable ; and the set of measures as a whole should contain both qualitative and quantitative measures .

at the beginning of each year when the measures and targets are being selected , assistance is provided for any program upon request to help with selecting appropriate measures .

sba has also initiated a practice aimed at documenting and improving the overall usefulness of performance information and increasing its use .

programs are required to identify the intended use of each measure in decisions related to policy and to provide an assessment of how fit the information is for this use .

the importance of this practice is that it promotes the selection of performance measures that better meet managements' needs , providing information that is relevant , and sufficiently complete , accurate , consistent , and timely for management's decision - making needs .

to facilitate and document the practice , sba's office of analysis , planning and accountability developed an assessment tool for its indicators in the form of the data validation table,” shown in figure 6 .

these tables are updated annually for every indicator published in the sba performance and accountability report .

in addition to documenting the intended use , the office must provide an assessment of the information's completeness , accuracy , consistency , and timeliness .

validation tables also document the associated office and program ; what outcomes are being assessed ; how each outcome is aligned with agency goals ; the system in which the data are kept ; and any limitations to the use of the information in the intended manner and associated remedies , among other items .

the practice of building analytical capacity to use performance information — both in terms of staff trained to do analysis and availability of research and evaluation resources — is critical to using performance information in a meaningful fashion .

our 2003 gpra survey found that there was a positive relationship between agencies providing training and development on setting program performance goals and the use of performance information when setting or revising performance goals .

we have previously reported on the need for agencies to expend resources on effective training and professional development to equip federal employees to work effectively .

specifically , managers and staff need competencies and skills to plan strategically , develop robust measures of performance , and analyze what the performance data mean .

performance management literature also states that training is a key factor in improving employees' capabilities and enabling employee involvement in achieving performance improvements .

we found examples where our case illustration agencies built capacity through providing staff with training in the performance management system and by providing access to technical assistance , such as having designated evaluation support staff or performance measurement experts available .

the vha network that includes health care facilities located in california , nevada , hawaii , and the philippines builds agency capacity by providing annual training on performance measures for facility managers .

the training is coordinated by a performance measurement committee composed of clinical leadership and quality management staff from each of the facilities .

the committee's mission includes providing education on the performance measures beyond the annual training , as well as sharing and implementing strategies to facilitate meeting the performance measurement targets .

at the annual training conference , all of the performance measures are discussed , including existing measures as well as any new measures .

the training lasts for a day or two , and facility managers can participate in person , on the telephone , or by videoconference .

in addition , the performance measurement committee is also a resource throughout the year for questions on the performance measures .

nhtsa has established capacity to use performance information through its research and evaluation office .

according to one official , nhtsa has had internal analytic capacity through a research office for more than 25 years .

the evaluation office provides the capacity to conduct research and evaluations on the effectiveness of nhtsa's traffic injury control office programs and initiatives , which address issues such as safety related to alcohol - and drug - impaired driving , pedestrians , bicycles , motorcycles , school buses , emergency medical services , older drivers , and driver fatigue and inattention .

we previously reported that nhtsa's evaluation office provides the capacity for a three - phase evaluation process .

first , studies identify the nature of the problem and possible solutions .

second , cost - benefit analyses identify the expected consequences or alternative approaches .

third , follow - up studies assess the consequences of policy or regulatory changes , since effects of some changes may not be apparent until 5 or more years after the introduction of changes .

according to a nhtsa official , it is important to have this capacity because the traffic injury control office does not have any regulatory authority , and needs the analysis and evaluations to demonstrate that the proposed programs are effective in order to persuade states to implement them .

in addition , we have previously reported that evaluations can improve agency use of performance information by providing performance information that may otherwise be unavailable ; by validating the accuracy of performance data ; by explaining the reasons for observed performance ; or , finally , by identifying ways to improve performance .

improving the communication of performance information among staff and stakeholders can facilitate the use of performance information by agency managers .

improvements can be achieved through frequent and routine communication , and the use of effective communication tools , such as visual aids .

we previously reported that frequent , regular communication is key for managers to inform staff and other stakeholders of their commitment to achieve the agency's goals and to keep these goals in mind as they pursue their day - to - day activities .

frequently reporting performance information also allows managers to review the information in time to take action to make improvements .

program managers can also communicate performance information upward through the management hierarchy , and across operating units .

we found a number of vehicles through which agencies communicated performance information effectively .

for example , agencies maintained frequent , routine communication among managers and staff through visual tools such as poster displays , performance scorecards , and intranet sites .

some agencies provided performance updates through regular e - mail or the distribution of monthly performance review meeting minutes .

in addition , officials said publicizing performance information can inspire ownership of a unit's performance , as well as competition between units .

for example , scorecards or other visual presentations of performance information enable staff to compare and analyze performance , resulting in a competitive interest in improving performance .

we found examples in selected agencies of the practice of frequent and routine communication and using visual tools to communicate performance information .

nws uses a number of display tools to convey performance information to staff and management at different levels of the organization .

quad charts and display boards are two examples .

quad charts arose out of the national oceanic and atmospheric administration's ( noaa ) efforts to improve budgeting and planning systems , and have also been used at the nws .

they are one - page summaries that provide pertinent information for decision - making purposes .

one particular type of quad chart is prepared to inform agency executives about program performance .

these quad charts are prepared by each major program and presented during noaa's quarterly executive panels .

these panels are composed of the deputy under secretary of noaa and the deputies of the line offices .

a one - page chart is divided into four quadrants containing the following four areas: performance parameters ( metrics and threshold values for selected performance indicators ) ; schedule of activities ( including schedule status ) ; key issues and risks ; and funding ( budgetary issues ) .

for each of these topics , status is also color - coded in green , yellow , or red .

an example of this type of quad chart is shown in figure 7 .

similar types of quad charts are prepared by managers requesting program adjustments ( such as changes in funding ) and for selected nws and noaa programs .

some quad charts also include gpra performance measures when applicable to a noaa or nws program .

nws also uses display boards at all of its field and regional offices to communicate information to all staff .

as shown in figure 8 , display boards convey national , regional , and site performance information on gpra measures relevant to specific site activities .

these charts allow site personnel to compare the site's performance with performance measured at the regional and national levels .

sites can update their own performance measures as often as monthly , while national data are updated annually .

comparable site - level information is available for all sites on the noaa intranet .

faa communicates performance information to all staff through a monthly performance scorecard .

the scorecard is organized into a table , and includes the actual and targeted performance levels for the agency's 31 key metrics , as identified in faa's strategic plan , or flight plan .

each metric is color coded , using the stoplight system of red , yellow , or green , according to how closely actual performance met the targeted performance for each month .

the scorecard is posted on faa's intranet and is updated monthly .

the same information is reported in more detail on a quarterly basis on faa's external web site .

an example of one of the metrics in the quarterly report , runway incursions , is shown in figure 9 .

our 2003 survey of federal managers found that , despite the fact that managers reported having more performance measures , the use of performance information for program management activities did not increase significantly from 1997 levels when gpra was first implemented governmentwide .

creating results - oriented cultures in which performance information is routinely used to make key management decisions will require the sustained attention and commitment of top agency leadership and more widespread adoption of the practices identified in this report .

the five federal agencies that we examined for this report provide examples of how agencies can use performance information for key management decisions and practices that can facilitate such use .

the specific ways in which the case agencies used performance information or implemented the practices may not be appropriate for wholesale adoption throughout the federal government because agencies face different management conditions and challenges , and operate under different authorities .

nevertheless , the general uses and practices highlighted in this report are universal and could be adapted by each agency .

helpful next steps would be for the relevant experiences of agencies in using performance information and adopting practices that facilitate use of performance information to be more widely shared , and for agencies to be encouraged to adapt practices to their unique situations .

the departments of commerce , labor , transportation , and veterans affairs , and the small business administration provided technical comments that were incorporated where appropriate throughout the report .

as agreed with your office , we will send copies of this report to the director of the office of management and budget and other interested parties .

we will also make copies available to others upon request .

in addition , the report will be available at no charge on gao's web site at http: / / www.gao.gov .

please contact me on ( 202 ) 512-6543 if you or your staff have any questions about this report .

contact points for our office of congressional relations and public affairs may be found on the last page of this report .

other contacts and staff acknowledgments are listed in appendix ii .

to identify uses of performance information and practices that encourage the use of performance information , we reviewed our prior reports and other relevant literature and interviewed agency officials .

in addition , we interviewed experts in using performance information from the following organizations: the school of public policy at the university of maryland ; the school of policy , planning and development at the university of southern california ; the institute for the study of public policy implementation at american university ; the school of public policy and public administration at george washington university ; the urban institute ; the ibm center for the business of government ; and the mercatus center .

to identify examples of ways in which managers use performance information and practices that enhance their use of that information , we selected five federal agencies that were identified as having a greater likelihood of using performance information: the departments of commerce ( doc ) , labor ( dol ) , transportation ( dot ) , and veterans affairs ( va ) ; and the small business administration ( sba ) .

among the factors that we considered in guiding our selection processs were that the agencies received relatively high scores on the 2000 gao government performance and results act survey results regarding the extent to which managers reported using performance information , relatively good marks on the september 2004 executive branch management scorecard ( president's management agenda ) , and / or recommendations from interviews with experts .

we also considered diversity in terms of program type and size .

table 1 contains brief background information on the agencies within the selected departments that are highlighted in our case examples .

within each of the five selected agencies , we conducted interviews with program / policy management and staff to obtain their suggestions regarding specific programs in which performance information has been used for management .

we then interviewed staff involved with those programs in more detail and reviewed related documents to obtain further information about how those programs have used performance information and any associated practices that have contributed to those uses .

we selected specific examples to highlight each use and practice and to illustrate particular aspects of how that use or practice was implemented within specific agency program contexts and across various program types .

we did not attempt to identify all agencies and programs that could have illustrated these uses and practices .

in addition , while we did review existing relevant information regarding performance data quality where available , we did not systematically assess the quality of the performance information used in the examples we cite .

finally , for most of the examples , we describe how performance information was used to make decisions , but we did not attempt to verify that the use ultimately resulted in improved outcomes .

from our review of the literature and interviews with experts and staff from the five agencies , we developed a conceptual framework identifying four categories of uses of performance information and five categories of practices that contribute to using performance information .

the framework and categories of uses and practices are consistent with the themes identified in our march 2003 report on results - oriented cultures and effective performance management , and are consistent with additional gao reports on gpra and results - oriented government .

the four use categories in our framework that we identified through our independent analysis are similar to the four types of uses identified in how federal programs use outcome information: opportunities for federal managers , by harry hatry , elaine morley , shelli rossman , and joseph wholey , published by the ibm endowment for the business of government in may 2003 .

we recognize that alternative categories of uses and practices could have been developed and that there may be additional uses and practices that we did not identify .

to provide additional support and further illustrate the uses and practices , we conducted two discussion groups .

the first discussion group included about 15 agency officials from the 5 selected case agencies and was intended to gain further perspective on those agencies' uses and practices .

to broaden the range of experiences we could draw upon , we also conducted a second discussion group consisting of about 15 representatives from 5 different agencies that were not in the pool of selected case agencies: the departments of agriculture , health and human services , housing and urban development , the interior , and justice .

for each discussion group , we asked agencies to nominate potential participants who had hands - on experience with using performance information , at least 3 years of management experience , and were at a gs - 13 level or higher .

we selected participants on the basis of their self - described experience using performance information and selected them to reflect a range of programs within agencies .

we conducted our review from september 2004 through august 2005 in accordance with generally accepted government auditing standards .

bernice steinhardt ( 202 ) 512-6543 or steinhardtb@gao.gov .

in addition to the contact name above , elizabeth curda , assistant director ; maya chakko ; chelsa gurkin ; anne inserra ; anne marie morillon ; and susan wilschke made significant contributions to this report .

in addition , tom beall provided key assistance .

ammons , david n. municipal benchmarks: assessing local performance and establishing community standards .

thousand oaks , california: sage publications , 1996 .

fountain , james , wilson campbell , terry patton , paul epstein , mandi cohn , mark abrahams and jonathan walters .

reporting performance information: suggested criteria for effective communication .

governmental accounting standards board: norwalk , connecticut , 2003 .

hatry , harry p. , performance measurement: getting results .

washington , d.c.: the urban institute , 1999 .

 - - - - - - “public and private agencies need to manage for results , not just measure them.” washington , d.c.: the urban institute , august 31 , 2004. http: / / www.urban.org / url.cfm ? id=900731 hatry , harry p. , elaine morley , shelli b. rossman and joseph s. wholey .

how federal programs use outcome information: opportunities for federal managers .

washington , d.c.: ibm center for the business of government , 2003 .

morley , elaine , harry p. hatry and jake cowan .

making use of outcome information for improving services: recommendations for nonprofit organizations .

washington , d.c.: the urban institute , 2002 .

newcomer , kathryn , edward t. jennings , jr. , cheryle broom and allen lomax .

meeting the challenges of performance - oriented government .

washington , d.c.: american society for public administration , 2002 .

osborne , david and peter hutchinson .

the price of government: getting the results we need in an age of permanent fiscal crisis .

new york: basic books , 2004 .

wholey , joseph s. overcoming the challenges in managing for results .

washington , d.c.: ibm center for the business of government , 2004 .

workforce investment act: states and local areas have developed strategies to assess performance , but labor could do more to help .

gao - 04-651 .

washington , d.c.: june 1 , 2004 .

results - oriented government: gpra has established a solid foundation for achieving greater results .

gao - 04-38 .

washington , d.c.: march 10 , 2004 .

highlights of a gao forum: high performing organizations: metrics , means , and mechanisms for achieving high performance in the 21st century public management environment .

gao - 04-343sp .

washington , d.c.: february 13 , 2004 .

human capital: key principles for effective strategic workforce planning .

gao - 04-39 .

washington , d.c.: december 11 , 2003 .

results - oriented government: using gpra to address 21st century challenges .

gao - 03-1166t .

washington , d.c.: september 18 , 2003 .

program evaluation: an evaluation culture and collaborative partnerships help build agency capacity .

gao - 03-454 .

washington , d.c.: may 2 , 2003 .

results - oriented cultures: creating a clear linkage between individual performance and organizational success .

gao - 03-488 .

washington , d.c.: march 14 , 2003 .

human capital management: faa's reform effort requires a more strategic approach .

gao - 03-156 .

washington , d.c.: february 3 , 2003 .

pension and welfare benefits administration: opportunities exist for improving management of the enforcement program .

gao - 02-232 .

washington , d.c.: march 15 , 2002 .

results - oriented budget practices in federal agencies .

gao - 01-1084sp .

washington , d.c.: august 2001 .

managing for results: federal managers' views on key management issues vary widely across agencies .

gao - 01-592 .

washington , d.c.: may 25 , 2001 .

managing for results: federal managers' views show need for ensuring top leadership skills .

gao - 01-127 .

washington , d.c.: october 20 , 2000 .

performance plans: selected approaches for verification and validation of agency performance information .

gao / ggd - 99-139 .

washington , d.c.: july 30 , 1999 .

executive guide: effectively implementing the government performance and results act .

gao / ggd - 96-118 .

washington , d.c.: june 1996 .

results - oriented cultures: insights for u.s .

agencies from other countries' performance management initiatives .

gao - 02-862 .

washington , d.c.: august 2 , 2002 .

managing for results: efforts to strengthen the link between resources and results at the veterans health administration .

gao - 03-10 .

washington , d.c.: december 10 , 2002 .

results - oriented cultures: implementation steps to assist mergers and organizational transformations .

gao - 03-669 .

washington , d.c.: july 2 , 2003 .

human capital: senior executive performance management can be significantly strengthened to achieve results .

gao - 04-614 .

washington , d.c.: may 26 , 2004 .

workforce investment act: labor should consider alternative approaches to implement new performance and reporting requirements .

gao - 05- 539 .

washington , d.c.: may 27 , 2005 .

the government performance and results act: 1997 governmentwide implementation will be uneven .

gao / ggd - 97-109 .

washington , d.c.: june 2 , 1997 .

tax administration: irs needs to further refine its tax filing season performance measures .

gao - 03-143 .

washington , d.c.: november 22 , 2002 .

architect of the capitol: midyear status report on implementation of management review recommendations .

gao - 04-966 .

washington , d.c.: august 31 , 2004 .

managing for results: emerging benefits from selected agencies' use of performance agreements .

gao - 01-115 .

washington , d.c.: october 30 , 2000 .

human capital: observations on final dhs human capital regulations .

gao - 05-391t .

washington , d.c.: march 2 , 2005 .

managing for results: strengthening regulatory agencies' performance management practices .

gao / ggd - 00-10 .

washington , d.c.: october 28 , 1999 .

human capital: a self - assessment checklist for agency leaders .

gao / ocg - 00-14g .

washington , d.c.: september 2000 .

managing for results: challenges agencies face in producing credible performance information .

gao / ggd - 00-52 .

washington , d.c.: february 4 , 2000 .

human capital: preliminary observations on proposed dod national security personnel system regulations .

gao - 05-432t .

washington , d.c.: march 15 , 2005 .

