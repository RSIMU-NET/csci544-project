for years , congress has been concerned about the quality of service taxpayers received when calling the internal revenue service ( irs ) for help in understanding and meeting their tax obligations .

irs' goal is to make its telephone operation a “world - class customer service organization” that provides taxpayers with accessible and accurate assistance comparable to the best practices in the private and public sectors .

irs has taken steps intended to improve how it responds to the tens of millions of telephone calls received each year , such as expanding the hours of service and increasing the use of automation .

however , as we previously reported to you , irs has continued to struggle to provide accessible and accurate telephone assistance .

in the 2000 tax filing season , the quality of telephone assistance was mixed and below irs' long - term goal of providing world - class service .

because of your continuing interest in the quality of irs' telephone assistance , you asked us to assess the performance and management of irs' telephone operations in the 2001 tax filing season .

more specifically , our objectives were to ( 1 ) compare irs' performance in providing accessible and accurate telephone assistance in the 2001 tax filing season with the 2000 tax filing season and 2001 performance targets and ( 2 ) assess irs' efforts to determine the factors that affected performance in the 2001 tax filing season and its plans to evaluate the actions it took to improve performance .

to address these objectives , we collected and analyzed data on eight telephone assistance performance measures: four on taxpayers' ability to gain access to irs and four on the accuracy of irs's response to taxpayers .

we also interviewed irs officials involved in managing telephone operations and obtained and analyzed supporting documentation .

the interviews included surveys of the 10 field directors responsible for managing irs' 26 call sites , which employ about 10,000 telephone assistors .

our scope and methodology are discussed in greater detail in a separate section of this report .

in the 2001 tax filing season , irs received more than 70.7 million calls on its three toll - free assistance numbers and answered over 50.5 million calls — assistors answered 22.7 million calls and automated systems answered 27.8 million calls .

as in previous years , irs had three toll - free telephone numbers that taxpayers could call with questions about tax law , taxpayer accounts , and refunds .

located at 26 call sites , irs has about 10,000 assistors that help taxpayers with a variety of questions ranging from the applicability of tax laws to the status of their accounts .

irs' call sites are supervised by 10 field directors , each of whom oversees two to three sites .

irs has four measures to evaluate the extent to which taxpayers are provided with accessible telephone assistance , and four to evaluate the extent to which taxpayers are provided with accurate telephone assistance .

 ( for more information on irs' telephone assistance access and accuracy measures see app .

i. ) .

irs' measures of access are based on actual counts of calls using data collected by irs' telephone system .

irs' measures of the accuracy of assistance , the quality and correct response measures , are estimates based on representative samples of nationwide calls that quality assurance staff monitor and score for accuracy .

irs began collecting data on correct responses in june 2000 , so there are no data for the 2000 tax filing season to compare with 2001 .

over the years , irs has studied its telephone performance and made changes designed to improve it .

for example , in 1999 , irs extended its hours of service to 24 hours a day , 7 days a week .

by providing around - the - clock service , irs expected to distribute demand more evenly and thus improve taxpayers' access to service .

with the increased use of call - routing technology in 1999 , irs began to manage its telephone operations centrally at the joint operations center in atlanta .

routing calls to the first available assistor who had the necessary skills to answer the taxpayer's question was expected to improve taxpayers' access to service and lessen the disparity in the level of service across sites .

however , the level of service declined in 1999 , and the quality of service was mixed in the 2000 tax filing season and below irs' long - term goal of providing world - class customer service .

according to irs , some of the key factors that affected performance in the 2000 tax filing season were the demand for assistance , staffing levels , assistor productivity , assistor skills , and irs' guidance for assistors .

as we discussed in a previous report , irs' analyses did not cover all key management decisions or other key factors that could have affected telephone performance .

additionally , determining how each factor affected performance was made even more difficult because many of the factors are interrelated ; changes in one can affect another .

the irs commissioner has recognized the complex interrelationships within the telephone - operating environment and has stated that years of sustained effort will be required for irs to achieve its goal of providing world - class telephone service .

to address our objectives , we interviewed irs officials involved in managing toll - free telephone operations and obtained and analyzed supporting documentation as follows: to assess irs' performance in responding to calls on the three main telephone assistance toll - free numbers , we compared the 2001 tax filing season performance for accessibility and accuracy measures with irs' performance in the 2000 tax filing season and its 2001 performance targets .

to assess irs' efforts to determine the factors that affected performance in the 2001 tax filing season , including actions it took to improve performance , we used as criteria gpra and irs' own guidance on analyzing performance data .

we interviewed irs officials in the wage and investment and small business and self - employed divisions , and the joint operations center .

we also analyzed various documents , including reports on irs' efforts to determine the factors that affect telephone performance and the results of actions to improve performance .

in addition , we used a questionnaire to obtain information from the 10 field directors about their efforts to identify the factors that affected performance and assess the effectiveness of actions taken to improve performance .

while we did not independently assess the accuracy of irs' performance data , we verified that irs had procedures in place intended to ensure data reliability .

we did our work from february 2001 through october 2001 in accordance with generally accepted government auditing standards .

irs made limited progress in the 2001 tax filing season toward its long - term goal of providing world - class telephone service .

when compared with the 2000 tax filing season , access and accuracy performance improved by 2 percentage points or less in three of the six comparable measures .

the quality of responses to account inquiries increased 10 percentage points , and there was a 4 percentage point decline in callers who hung up while waiting to speak with an assistor ; however , taxpayers waited 15-percent longer to speak with an assistor .

when compared with 2001 performance targets , irs did not meet any of its accessibility goals .

these targets were intended to move irs toward its goal of providing world - class service .

although it met or exceeded the 2001 quality targets , irs did not meet the current year's higher targets for providing taxpayers with correct responses .

table 1 compares irs' actual 2000 performance levels with its 2001 performance levels and targets .

 ( see app .

i for more information on the measures. ) .

according to irs officials , the access measures are similar to those commonly used by world - class customer service organizations .

they are designed to focus efforts on enhancing taxpayers' experience in getting access to assistance .

for example , the “assistor level of service” measureis intended to show irs' effectiveness in providing callers with access to an assistor .

the “assistor response level” is to measure the percentage of taxpayers that waited 30 seconds or less to speak with an assistor .

the “abandon rate” measure is to show the percentage of taxpayers who hang up while waiting to speak with an assistor , while the “average speed of answer” measure is to show the average number of seconds taxpayers wait to speak to an assistor .

irs' accuracy measures are designed to gauge the taxpayers' experience in getting accurate assistance .

the “quality” measures are to show , for a representative sample of calls , the percentage for which assistors followed all procedures , such as properly identifying themselves at the beginning of calls , doing appropriate research on taxpayers' accounts , and providing accurate information to taxpayers .

the new “correct response rate” measures are intended to show the percentage of calls for which irs assistors provided correct responses to inquiries without taking into account procedural errors that would not affect the accuracy of the information given the taxpayer .

irs began collecting these data in june 2000 , so there were no data for the 2000 filing season to compare with 2001 .

irs also measures its performance in answering calls through the use of automation .

however , we did not consider this measure — “automated service completion rate” — in assessing irs' performance because it assumes that callers who get through to teletax are served .

the teletax system does not have data on how many callers hung up before completing an automated service .

although irs officials recognize that the measure had limitations , according to them , routing refund status calls to teletax allowed irs to answer about 11.3 million more calls made to its three main toll - free assistance numbers as compared with the 2000 tax filing season .

we are continuing to assess many of irs' new performance measures , including those used to evaluate telephone assistance .

irs missed some opportunities to better understand the factors that affected performance and to plan evaluations of the actions it took to improve performance .

gpra and irs guidance outline the benefits of first gathering and then analyzing data to help managers understand the reasons for performance .

to this end , irs collected performance data on access and conducted some analyses .

even so , irs missed opportunities to do other analyses of the factors affecting performance including actions to improvement it .

contributing to the missed opportunities was a lack of planning for the evaluation of those actions .

irs has a variety of systems in place to make data on the access and accuracy of telephone assistance available to managers .

two of these systems are its joint operations center in atlanta and centralized quality review system ( cqrs ) in philadelphia .

managers at call sites also collect data on factors affecting access and accuracy performance .

irs' joint operations center in atlanta manages the activities of the 26 call sites , including monitoring access data and routing calls to the next available assistor anywhere in the country .

the center collects data on various accessibility measures and makes those data available daily to irs managers through an internal web site .

according to irs officials , irs improved the collection of performance data in the 2001 tax filing season .

for example , irs implemented the enterprise telephone database to provide a central call information database .

the database was designed to provide irs analysts and management with the most accurate information for analysis and program decision - making by centralizing data collection and producing a standard set of management reports .

irs' cqrs staff in philadelphia are responsible for collecting data on the accuracy of telephone assistance .

cqrs provides call - site officials with daily access through its internal web site on the results of the sample of calls answered by their sites .

it also provides weekly and monthly reports on the quality of sites' responses to taxpayers' questions about tax law or about their accounts — two of the accuracy performance measures .

these data show the call sites what errors assistors are making so site managers can quickly take action to reduce these errors .

irs officials told us that they made better use of the data in the 2001 filing season .

they said that wage and investment division and site officials developed strategies to reduce assistor errors based on cqrs reports .

irs call sites collect data on factors affecting access and accuracy in various ways .

for example , supervisors use real - time data and historical reports available at the call sites on how assistors spent their time , including average handle time — the time an assistor spends talking with the taxpayer , keeping the taxpayer on hold , and finishing the call and indicating readiness to receive another call .

also , local staff monitor calls to provide more detailed information on what errors assistors are making and in what units the errors are being made .

irs , both at the national and call - site levels , conducted some analyses of performance data intended to determine the factors affecting performance .

gpra and irs guidance stress that analysis is a key part of understanding performance and identifying improvement options .

analysis of performance data is intended to help managers understand changes in performance , determine root causes , and identify improvement options .

we identified several examples of analytical efforts to determine the factors affecting performance at both the national and call - site levels .

in one example with regard to access , irs officials analyzed data provided by the joint operations center to determine the reasons for the lower - than - expected level of service in the first 3 months of fiscal year 2001 .

they concluded that declining assistors' productivity , as measured by average handle time , was the major reason for the decline in access .

officials from the operating divisions and the call sites conducted a series of assessments to determine the underlying reasons for the increase in average handle time .

the assessments included focus groups with managers and employees to solicit their views on productivity and monitoring of telephone calls to determine how assistors use the time between calls .

the assessments identified three major categories of factors that had negatively affected average handle time: management practices , work processes , and computer systems .

according to irs officials , some management practices adversely affected the level of service because managers did not take actions to improve assistors' use of time between calls , the primary factor that increased average handle time .

irs officials said that they took immediate corrective actions , such as briefing assistors and supervisors and eliminating unnecessary data entry and taxpayer notification requirements .

they also organized teams to further evaluate and resolve the more complicated work process and computer systems issues .

according to irs officials , irs improved the analysis of joint operations center performance data in the 2001 tax filing season .

for example , analysts studied the factors that affected the demand for live assistance regarding refunds , including the impact of increased electronic filing .

center analysts also began developing quantitative models of the time taxpayers and irs spend on telephone questions , with the intent to better match irs' resources with taxpayer needs .

regarding accuracy , cqrs staff analyzed assistor errors and made nationwide and individual site suggestions for addressing the causes of the errors .

the suggestions included changes to the assistors' training and guidance .

also , irs field directors conducted some analyses to determine the factors that affected access and accuracy .

for example , one director said analysis staff at one of her sites was doing a study to determine if the site's extensive use of faxing negatively affected access .

she said she believed the site's average handle time was longer than others owing to the site's policy to keep the taxpayer on the line until the accounts issue was resolved , even while the taxpayer faxed documents .

another director said he monitored assistors to determine whether the computer - based research tools assistors used to answer taxpayers' questions met assistors' needs .

although irs conducted some analyses of performance data , it missed opportunities to do other analyses at the field level that could have provided a better understanding of the factors affecting telephone assistance performance , including the actions it took to improve performance .

identifying the key factors that most affect performance is important , yet difficult because those factors that can affect telephone access and accuracy are often numerous and interrelated .

irs guidance recognizes that there are a variety of approaches to conducting analyses , such as hypothesis testing , which involves forming a tentative conclusion that is tested using the data .

we recognize that some analyses can be costly , but as already noted , gpra and irs guidance stress that analysis is a key part of identifying improvement options .

field directors sometimes reached conclusions about the factors affecting access and accuracy without conducting analyses to test their conclusions .

seven of 10 directors said that the relative inexperience of assistors , caused primarily by higher - than - usual attrition , was a key factor affecting performance in the 2001 tax filing season .

they said many experienced seasonal assistors had taken permanent positions in other parts of irs , and the new hires who replaced them tended to take longer on calls and make more errors .

the second most common factor they cited was problems with the computer - based research tools that assistors used to answer taxpayers' questions .

five of 10 directors cited such problems , including difficulties in using the servicewide electronic research project to search the internal revenue manual , the assistors' primary guidance for handling calls regarding taxpayers' accounts .

some directors said the computer systems were cumbersome and difficult to navigate , causing assistors to take longer on calls and make errors , and some said computer systems often failed and thus hampered assistors' ability to research questions .

although directors cited high attrition and computer problems as key factors affecting performance , only two directors identified a specific analysis to support their conclusions .

these directors said that focused monitoring was done at their sites that confirmed the limitations of a computer system assistors used to answer taxpayers' questions .

when we asked other directors whether they or their staff had conducted analyses to confirm or refute their conclusions about the factors that affected performance , they acknowledged that they had not .

we identified several opportunities to conduct analyses of performance .

one way directors could have analyzed the impact of high attrition on access and accuracy would have been to monitor a sample of calls handled by experienced and inexperienced assistors to compare error rates and average handle time .

one director acknowledged that her analysis staff could have done more to learn about how accepting additional calls from businesses affected performance , such as comparing the handle time for business taxpayer calls with individual taxpayer calls .

in another example , the program manager for the new accounts resolution guide , a computer - based , step - by - step guide on how to resolve an account - related telephone call , agreed that more could have been done to evaluate the guide's effectiveness .

for example , local managers could have observed and compared assistors who used and did not use the guide .

according to irs officials , additional analyses such as these could have been done at relatively low cost .

analyzing performance data can be important for several reasons .

first , there can be disagreement about which actions improve performance .

for example , some directors cited the accounts resolution guide as a reason for the significant improvement in their accounts quality rate .

however , another director said that the guide actually had a negative effect on accounts quality , saying that because the guide was new to some assistors , the “learning curve” to become proficient in using the guide caused assistors to make errors .

second , when multiple factors affect performance , knowing the extent to which each factor has an impact can help managers decide where to focus scarce managerial attention .

for example , the solutions for addressing high attrition and computer problems are likely to be different .

understanding the relative importance of high attrition and computer problems could help prioritize improvement actions .

in addition , in the case of multiple factors , irs' use of performance measures to determine the effect of one factor without controlling for other factors can be misleading .

in one case , a field director noted the risks of using average handle time as an indicator of the effectiveness of actions taken to improve the productivity of telephone assistors .

the director noted that other factors , such as the complexity of calls handled , could also affect average handle time .

third , the interrelationship among factors makes it difficult to determine which factors most affect performance .

for example , as we reported last year , the quality of guidance assistors use can affect not only the accuracy but also the accessibility of telephone assistance .

although step - by - step guidance on how to respond to questions would likely improve accuracy , it could also cause assistors to take more time answering calls , thereby negatively affecting taxpayers' access to service .

as we previously reported , conducting systematic analyses of program performance is important for determining the factors affecting performance and identifying opportunities for improvement .

irs guidance states that analysis to understand the underlying factors influencing the performance reflected in the balanced measures is necessary to determine how to improve performance and warns that managers should not “jump to conclusions” about the causes of performance problems .

as we said in a report on management reform , “an organization cannot improve performance and customer satisfaction if it does not know what it does that causes current levels of performance and customer satisfaction.” because the factors affecting telephone performance are numerous and are often interrelated , conducting analyses is essential to determining the factors that have the most effect on performance so that corrective actions can be targeted toward those factors .

we recognize that some analysis can be costly .

consequently , the costs need to be balanced against the benefits .

considering that irs devotes significant resources ( about 10,000 assistors ) to telephone assistance , the benefits of analysis — identifying ways to more effectively use resources and improve service — could be substantial .

irs missed opportunities to plan evaluations to determine the effectiveness of actions it took to improve the access and accuracy of its telephone assistance .

irs guidance presents a seven - step process designed to guide data collection and analysis to identify ways to improve performance .

the last step states that managers should establish a plan that tracks the effectiveness of actions taken to improve performance .

without such a plan , irs may not collect the data needed to judge the action's effectiveness .

additionally , planning to collect the data before the improvement action is implemented may be less costly than developing the data and evaluating the action later .

irs field directors cited several different actions they took to address factors that negatively affected access and accuracy in the prior filing season: assistor skill gaps ( the difference between the skills assistors had and the skills needed by irs ) .

to address skill gaps , field directors most frequently cited training as the action taken , with all 10 directors referring to training as the primary , and most often only , action taken .

although training was designed at the division level , field directors and managers were responsible for implementing it in the field , such as selecting the trainers and determining which assistors need to be trained .

errors caused by flaws in the guidance assistors used to respond to taxpayers' account questions .

to address the flaws in assistors' guidance for answering taxpayer calls , 5 of the 10 field directors cited the implementation and use of computer - based tools to improve guidance , including the accounts resolution guide .

declining assistor productivity .

all 10 field directors said that the primary actions taken to address assistor productivity declines were nationwide managers' training and employee briefings .

although field directors said all three of these actions were key to improving telephone assistance performance this year , none of the field directors cited specific evaluations or plans for assessing the effectiveness of these actions .

instead , field directors based their assessment of actions on performance trends , not taking into account the multiple factors or the interrelatedness of factors that can affect a performance measure .

one example of a missed opportunity to plan an evaluation of an improvement action on the national level is the lack of a systematic plan to assess the impact the accounts resolution guide had on access and accuracy .

the program manager for the guide said that irs did not develop such a plan because assistors were not required to use the guide and irs' remote monitoring system was unable to determine when the guide was used .

the program manager agreed that local managers could have done more to evaluate its effectiveness because they could have observed and compared the results of assistors who did or did not use the guide .

having an evaluation plan when the new accounts resolution guide was distributed to the field would have provided local managers with guidance on the type of data to collect .

another example of a missed opportunity is the lack of evaluation plans in filing season readiness plans .

irs field directors complete a standard plan each year , adding any items unique to their sites , to ensure that the sites have taken all the necessary steps to provide phone assistance in the tax filing season .

such steps include providing appropriate training and having the equipment and guidance assistors need to respond to taxpayer calls .

the readiness plans we reviewed , however , did not include steps to ensure that sites collect and analyze data to evaluate the effectiveness of any improvement actions .

irs officials noted that since some of the improvement actions were national in scope , field directors would not have been individually responsible for evaluating the effectiveness of the actions .

we recognize that evaluations of national improvement actions , such as the accounts resolution guide and managers' training and employee briefings , to address productivity may involve the higher levels in irs that are responsible for the action .

accordingly , as noted above , we discussed the guide with its national program manager and were told that no systematic evaluation was done .

we also discussed the actions to address productivity with division - level officials .

similar to the field directors , division officials evaluated the actions by monitoring trends in average handle time and comparing average handle time with previous performance .

irs made limited progress in the 2001 tax filing season toward its long - term goal of providing world - class customer service .

to speed progress toward its long - term goal , irs managers need to identify the causes for performance , plan strategies to improve performance , and evaluate how well those strategies worked .

unfortunately , irs sometimes missed opportunities to conduct analysis to help managers understand the reasons for performance and to evaluate actions taken to improve performance .

the decision on the type of analysis to be done and who will do it should consider the costs and benefits of the analysis and which organizational levels are most responsible for the factor or improvement action being analyzed .

we recognize that some analyses can be costly ; however , some of the missed opportunities were low - cost and some involved key factors affecting actions taken to improve performance .

in addition , there are costs in not using the 10,000 assistors as effectively as possible .

considering irs' limited progress , it cannot afford to miss opportunities without determining the most effective use of its resources to improve performance .

we recommend that the commissioner ensure that managers follow irs guidance on analyzing the factors that affect performance and evaluating improvement actions .

specifically , we recommend that ( 1 ) field directors be required to develop and follow written plans to collect and analyze data to test their conclusions about the key local factors affecting performance and , when appropriate , evaluate local improvement actions , such as actions involving training ; ( 2 ) field directors include in filing season readiness plans a step to ensure that site managers have plans to evaluate the effectiveness of any local improvement actions ; and ( 3 ) program managers and other appropriate national officials be required to develop and follow written plans to evaluate the effectiveness of key national improvement actions , such as the accounts resolution guide .

the commissioner of internal revenue provided written comments on a draft of this report in a december 3 , 2001 , letter , which is reprinted in appendix ii .

the commissioner stated that while the report categorized irs' progress toward providing world - class telephone assistance as limited , he is confident that irs is moving in the right direction .

he noted that irs had initiated a number of strategies to improve telephone assistance and agreed with our recommendation .

specifically , he agreed that irs needs “better testing , documentation , and analytical activities to determine the factors that affect performance and assess the results of our improvement actions.” in his comments , the commissioner noted that the report focuses on accessibility to telephone assistors and stated that irs also assists taxpayers through automated telephone services and other means , such as irs' internet web site and walk - in tax assistance centers .

as noted in the report , we did not assess irs' automated telephone services because irs' method of measuring its performance in providing automated services had limitations .

the measure assumed that all callers that go through one of its automated systems — teletax — were served because the teletax system does not have data on how many taxpayers hung up before completing an automated service .

other taxpayer services , such as walk - in assistance , are to be addressed in our upcoming report on various aspects of the 2001 tax filing season .

as agreed with your staff , unless you publicly release its contents earlier , we will make no further distribution of this report until 30 days after its issue date .

at that time , we will send copies of this report to the chairmen and ranking minority members of the senate committee on finance and the house committee on ways and means and the ranking minority member of the subcommittee .

we will also send copies to the secretary of the treasury ; the commissioner of internal revenue ; the director , office of management and budget ; and other interested parties .

we will make copies available to others on request .

if you have any questions or would like additional information , please call me at ( 202 ) 512-9110 or carl harris at ( 404 ) 679-1900 .

key contributors to this report are ronald w. jones and ronald j. heisterkamp .

