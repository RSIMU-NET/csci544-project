since 1990 , we have designated medicare as a high - risk program , given its size , complexity , and susceptibility to payment errors from various causes .

medicare's serious long - term financial challenges heighten the need for the centers for medicare & medicaid services ( cms ) to closely examine expenditures in the medicare advantage ( ma ) program — the private plan alternative to the medicare fee - for - service ( ffs ) program .

for the ma program , cms contracts with ma organizations ( mao ) to provide covered services to beneficiaries who enroll in one of their plans .

as of april 2014 , cms had 571 contracts with maos that served nearly 15.5 million enrollees , accounting for approximately 30 percent of all medicare beneficiaries .

the congressional budget office has projected that enrollment in ma plans will increase to about 21 million enrollees by 2023 and that medicare payments to maos will grow from about $154 billion in 2014 to about $250 billion in 2023 .

as the ma program expands , setting appropriate payments to maos and making medicare a more prudent purchaser of health care services will remain critical .

whereas medicare pays ffs providers who submit claims for reimbursement after services have been provided , medicare pays maos a fixed monthly amount per enrollee to cover all the services enrollees use .

cms adjusts payments to maos to reflect enrollees' expected health care costs , with higher payments for enrollees who are predicted to be sicker and lower payments for those predicted to be healthier — a process known as risk adjustment .

maos can incur losses if aggregate costs exceed payments but can retain savings if aggregate costs are less than payments .

since the 1980s , the methodology for setting mao payments has changed several times to better reflect the expected health care costs of plan enrollees and to mitigate the effects of potential favorable selection .

the tax equity and fiscal responsibility act of 1982 authorized payment for full - risk medicare plans on the basis of a fixed per beneficiary rate set at 95 percent of the estimated average cost of beneficiaries in medicare ffs .

we and other researchers criticized the accuracy of the adjustment , which resulted in excess payments to plans that enrolled healthier beneficiaries with below - average health care costs .

in an effort to refine the payment methodology , the balanced budget act of 1997 required cms to use health status measures to adjust plan payments and required the agency to collect inpatient hospital data for this purpose .

in implementing these requirements in 2000 , cms selected a risk adjustment method that relied on enrollee demographics augmented with hospital inpatient data to measure health status .

this risk adjustment method more accurately matched ma payments to enrollees' expected total medicare costs compared with the previous method .

in 2002 , cms transitioned to collecting a larger set of medical data — via the risk adjustment processing system ( raps ) — to risk adjust payments .

as required by law , the agency began using information on enrollee demographics and diagnoses collected from maos for services provided in physician office , hospital inpatient , and hospital outpatient settings to risk adjust payments in 2004 .

using these data in conjunction with ffs beneficiaries' cost and diagnosis information , cms developed the hierarchical condition categories risk adjustment model that uses one year's diagnoses to predict the following year's health care costs for each ma enrollee .

although this model is better than the previous model — which estimated an ma enrollee's health status from certain inpatient diagnosis and demographic factors — at predicting an enrollee's costs , it has led to overpayments to maos because of different diagnostic coding patterns between the ffs and ma programs .

in a 2008 final rule , cms reasserted its authority to collect more detailed data , referred to as encounter data .

such data include diagnosis and treatment information for all medical services and items provided to an enrollee , with a level of detail similar to ffs claims .

in january 2012 , after a multiyear rollout , the agency began collecting such data from maos via the encounter data system .

in the 2008 final rule , cms stated it would use these data for risk adjustment and may also use them for additional payment and oversight purposes .

the agency plans to discontinue raps after it begins using ma encounter data for risk adjustment purposes .

realizing the benefits of encounter data will depend on the quality of the data and the data's suitability for various uses .

cms has recognized the importance of ensuring that the data collected are complete — representing all encounters for all enrollees — and accurate — representing a correct record of all encounters that occurred — given the important functions to which the data will be put .

furthermore , cms has stated that the encounter data submitted by maos would be used once the agency has reviewed and analyzed the submissions to identify and address any data issues .

you asked us about cms's plans for using ma encounter data and its efforts to validate the completeness and accuracy of the data .

in this report , we examine 1. how the scope and reporting frequency of ma encounter data compare with cms's current ma risk adjustment data , 2. the extent to which cms has gathered ma encounter data and specified plans and time frames to use encounter data for risk adjusting ma payments and other purposes , and 3. the extent to which cms has taken appropriate steps to ensure the completeness and accuracy of ma encounter data .

for all objectives , we reviewed relevant laws , regulations , and guidance pertaining to ma encounter data collection and reporting and raps data submissions .

we also reviewed documents from meetings that cms has held with maos and from public presentations on ma encounter data collection requirements , the implementation schedule , and specific mao concerns .

in addition , we interviewed cms officials in the medicare plan payment group and other agency components , as well as cms contractors .

we also interviewed representatives of america's health insurance plans and its member maos .

to determine the extent to which cms has taken appropriate steps to ensure the completeness and accuracy of ma encounter data , we compared the agency's activities to the principal activities identified in its 2012 protocol for validating medicaid encounter data that states receive from managed care organizations ( mco ) — entities that provide medicaid benefits in exchange for a fixed monthly payment .

the protocol specifies a procedure for assessing the completeness and accuracy of encounter data that medicaid mcos are required to submit to state agencies .

because of the similarities in the type of data — encounter data — and entities gathering the data — managed care entities — we refer to the protocol in assessing cms's actions to ensure ma encounter data quality.external quality review organizations with experience using the protocol and reviewed their documents and other reports on medicaid encounter data validation .

to learn about the practical uses of the protocol , we interviewed we conducted this performance audit from july 2013 to june 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

although maos are responsible for collecting and transmitting encounter data to cms , they rely on the cooperation of providers to submit complete and accurate data that conform to agency requirements .

maos gather encounter data — which originate from the information in an enrollee's medical record — for their own management and payment purposes .

while medicare pays maos a fixed monthly amount per enrollee , maos may compensate providers for services rendered to enrollees under different contractual arrangements .

providers paid by their plans on a ffs basis submit claims for payment that include the amounts to be reimbursed by the mao.basis — that is , that receive a designated amount to cover all services for an assigned enrollee — record a zero if no payment amount information is available .

maos may include provisions in their contracts with providers that require submission of complete and accurate encounter data .

in contrast , providers paid by their plans on a capitated after collecting and reviewing these data , maos transmit the data to cms .

cms adopted the health insurance industry's standard claims format for reporting ma encounter data .

maos must use the health insurance portability and accountability act of 1996-compliant accredited standards committee x12 version 5010 format , which all providers and private and public health plans are required to use for electronic claim by using this standard format , cms generally avoided submissions.placing a new requirement on maos .

in january 2012 , cms began phasing - in ma encounter data collection by type of provider .

it began by receiving data on professional encounters ( such as services performed by physicians ) , then institutional encounters ( such as services performed during an inpatient hospital stay ) , and finally durable medical equipment ( such as hospital beds and wheelchairs ) .

by august 2012 , maos were submitting data from all types of providers .

although cms requires that maos submit encounter data for all items and services provided to enrollees , the file formats that cms currently uses preclude maos from transmitting data on the utilization of certain supplemental ma benefits , such as dental and vision services .

agency officials told us they are considering how to address this discrepancy .

to risk adjust payments to maos , cms calculates a risk score — the expected health care expenditures for an enrollee compared with the average health care expenditures of all beneficiaries — for each ma enrollee and medicare ffs beneficiary .

cms calculates risk scores for ma enrollees using diagnosis information provided by maos along with cost and utilization information from medicare's ffs claims systems .

this approach assumes that diagnostic coding practices are the same in ma and ffs .

risk scores for beneficiaries with the same diagnoses and characteristics should be identical , regardless of whether the beneficiaries are in ma or medicare ffs .

however , maos have a greater incentive than ffs providers to make sure that all diagnoses are coded , as this can increase enrollees' risk scores and ultimately the payments plans receive .

in part because of this incentive , risk scores for ma enrollees may tend to be higher relative to the risk scores of ffs beneficiaries who are in similar health and have identical characteristics .

to help ensure that maos are not overpaid as a result of these differences in diagnostic coding , cms makes a separate adjustment to payments to maos .

in 2012 and 2013 , we reported inaccuracies in cms's methodology for adjusting ma payments .

specifically , we estimated in 2013 that maos received excess payments of between $3.2 billion and $5.1 billion from 2010 through 2012 because cms's adjustment to account for differences in risk scores was too low .

we recommended that the cms administrator take steps to improve the accuracy of the adjustment made for differences in diagnostic coding practices between ma and medicare ffs .

the agency did not formally comment on this recommendation and , as of march 2014 , it has not improved the accuracy of this adjustment .

consistent with our finding that this adjustment was too low , congress has taken steps to increase the statutory minimum annual adjustment .

state medicaid agencies that contract with mcos typically require them to report encounter data to the state for various purposes.encounter data collection , the agencies may also establish requirements regarding the timeliness , completeness , and accuracy of medicaid encounter data in contracts with mcos .

for example , to encourage timely submission and promote data quality , they may require mcos to submit data within a certain time frame and attest that the data submitted are complete and accurate .

state medicaid agencies may then use these data for a variety of purposes , such as setting payment rates , evaluating the performance of mcos , and providing reports to their legislatures and the public .

state medicaid agencies may assess encounter data to determine whether mcos meet requirements for complete and accurate reporting .

for example , they may calculate the proportion of encounter data files denied or examine the rates of services used per enrollee against specific benchmarks — target rates .

as another example , they may require mcos to list encounter data that were corrected or voided and provide reasons for these actions .

they may also have the medical records examined to verify that the information submitted in encounter data is complete and accurate .

for example , this review may determine whether services submitted in encounter data were performed or confirm that enrollees have specific diagnoses .

compared with information available in raps data , ma encounter data , with more elements reported , provide cms with more comprehensive information on all enrollee diagnoses as well as the cost and types of services and items provided to enrollees .

each raps data file — an electronic record that contains an enrollee's diagnosis information from one or more providers — contains between 1 and 10 diagnosis groupings .

although all diagnoses are included in these groupings , not all groupings are used in cms's risk adjustment model .

for each diagnosis grouping , there are 9 raps data elements , including the “from” and “through” dates of service , the diagnosis code , and the provider type .

each raps data file also includes 31 other elements that are used for data processing and other purposes .

thus , depending on the number of diagnosis groupings , each raps data file contains between 40 and 121 data elements .

in contrast , each encounter data file — an electronic record that contains detailed information for each medical service and item provided to an enrollee — includes approximately 200 data elements .

these elements include information on the patients , providers , and payers of services and items , as well as the dates of service and procedure codes .

they also include information on the primary and supplemental diagnoses associated with the service or item .

whereas raps data are limited to 10 diagnosis groupings , encounter data can include up to 12 diagnoses for professional services and 25 diagnoses for institutional services .

table 1 summarizes the types and number of encounter data elements .

in addition , ma encounter data are more comprehensive than raps data because they include information that originates from a wider range of provider types .

specifically , only physicians and hospital inpatient and outpatient facilities report enrollee diagnoses for raps data collection .

of these provider types , physicians provide approximately 80 percent of the diagnostic information used for risk adjustment , according to one estimate .

as a result , cms's current risk adjustment model relies primarily on diagnoses that physicians report .

in contrast , more provider types report encounter data , significantly expanding the scope of sources for diagnosis and other information .

in addition to physicians and hospital inpatient and outpatient facilities , many other provider types — including ambulance providers , clinical laboratories , durable medical equipment suppliers , home health providers , mental health providers , rehabilitation facilities , and skilled nursing facilities — report encounter data .

the fact that cms has taken a comprehensive approach in collecting encounter data has raised concerns for some maos .

because maos generally gather such data from certain providers for payment and plan management purposes , the cms encounter data reporting requirements may not have significantly added to their ongoing data gathering activities .

however , industry representatives noted that submitting encounter data from a broad array of provider types may not add to information on diagnoses cms uses for risk adjustment .

agency officials acknowledged that many encounter data elements maos report will not be used for risk adjustment but will allow cms to more completely identify the services furnished to enrollees .

finally , cms requires maos to submit encounter data more frequently than raps data .

maos submit raps data at least quarterly to cms , with each submission representing approximately one - fourth of the raps data an mao submits during the year .

in contrast , cms requires maos to submit encounter data weekly , biweekly , or monthly depending on their number of enrollees .

maos with more than 100,000 enrollees must submit encounter data on a weekly basis , those with between 50,000 and 100,000 enrollees on a biweekly basis , and those with fewer than 50,000 enrollees on a monthly basis .

cms also requires maos to submit encounter data within 13 months from the date of service .

representatives of maos noted that they are able to meet cms's encounter data frequency requirements , and one mao told us that it sometimes chooses to submit encounter data more frequently — three times a week rather than once a week — to reduce the size of each submission .

cms is receiving ma encounter data from nearly all maos on all types of services at the monthly volume that cms officials told us they expected .

after increasing significantly from august 2012 — the first month that maos submitted encounter data on services from all provider types — through may 2013 , the volume of ma encounter data has had some fluctuations from month to month .

 ( see fig .

1. ) .

specifically , the volume of encounter data files — electronic records containing detailed information for each medical service and item provided to an enrollee — rose sharply from 2.0 million data files in august 2012 to 49.6 million data files in may 2013 .

from june 2013 through april 2014 , the volume has fluctuated between 34.2 and 54.2 million data files each month .

cms officials told us that they expect to continue receiving encounter data files at a rate of approximately 40 to 50 million files per month throughout 2014 .

in total , maos submitted about 497.9 million encounter data files in 2013 comprising approximately 416.5 million professional encounter data files , 64.9 million institutional files , and 16.5 million durable medical equipment files .

in april 2014 , cms announced that it will use ma encounter data as part of risk adjustment and no longer rely solely on raps data .

the agency will start using the diagnosis information from ma encounter data as well as the diagnoses in raps data from 2014 dates of service when calculating 2015 enrollee risk scores.both data sources to obtain diagnoses reported from hospital inpatient and outpatient facilities and physicians .

further , the agency announced specifically , cms intends to use that it will use all diagnoses equally , whether they came from raps data or ma encounter data , when calculating risk scores .

cms officials said that raps data generally have all ma enrollees' diagnoses , so they do not anticipate receiving a significant amount of additional diagnoses from ma encounter data .

cms officials described these efforts to begin using diagnoses from ma encounter data as a key step in making full use of the data in risk adjusting payments .

furthermore , officials stated that 2015 — and perhaps subsequent years — will serve as a time to transition from using raps data to using ma encounter data to calculate risk scores .

once ma encounter data are deemed sufficiently complete and accurate for use in risk adjusting payments , cms plans to discontinue raps data collection and transition entirely to using ma encounter data .

although cms identified a number of other potential uses for ma encounter data in the 2008 final rule , how it would use the data for any of these additional purposes .

adequately developing plans for encounter data , and communicating them to maos , may improve cms's efforts to manage aspects of the medicare program .

agency officials told us that they have deferred planning efforts to use ma encounter data for any purposes besides using it as a different way to collect diagnosis information for the current risk adjustment model .

accordingly , cms's plans remain undeveloped and it has not established specific time frames for any of the following potential uses outlined in 2008: the agency has yet to determine revise cms's risk adjustment model for ma payments .

cms intends to improve its model for risk adjustment using ma enrollee cost , diagnoses , and utilization information .

however , agency officials noted that developing such a model is an involved process and would take a number of years to complete .

in the 2008 final rule , cms listed the following potential data uses without further explanation: ( i ) updating risk adjustment models , ( ii ) calculating medicare disproportionate share percentages , ( iii ) conducting quality review and improvement activities , and ( iv ) medicare coverage purposes .

73 fed .

reg .

48434 ( aug. 19 , 2008 ) .

conduct quality review and improvement activities .

such activities refer to assessing the performance of providers and maos in delivering care .

for example , cms could use encounter data to develop new ma quality measures .

calculate medicare disproportionate share hospital percentages .

cms increases payments to hospitals serving a disproportionate number of low - income patients through the disproportionate share hospital adjustment .

the agency currently incorporates the number of hospital days for ma enrollees in its calculation of disproportionate share hospital percentages .

cms officials have not specified how the agency could use ma encounter data to modify how it calculates the disproportionate share hospital percentages .

monitor medicare coverage .

such monitoring may refer to using encounter data to determine whether an ma enrollee has reached the maximum out - of - pocket limit for an enrollee's cost sharing each year .

without developing plans for these additional uses of encounter data , cms cannot determine whether it is gathering the proper amount and types of information required for these purposes .

additionally , the agency would not be able to establish management priorities , and therefore cannot ensure that it is using the data to their full potential .

in a may 2014 proposed rule , cms identified a number of additional uses of encounter data designed to strengthen program management and increase transparency in the ma program .

these were the following: conduct program evaluations .

cms noted that it may use encounter data to assess the ma program and demonstration designs .

the data could also be used for government - sponsored public health initiatives and academic health care research .

support program integrity efforts .

cms indicated that encounter data could be used to conduct audits , investigations , and other efforts to combat waste , fraud , and abuse undertaken by the office of inspector general or cms .

aid program administration .

cms stated that it may use encounter data in reviewing the validity of mao bid submissions — projected revenue for providing standard medicare services to an average enrollee in an maos' service area .

it may also use the data to verify mao information on medical loss - ratios — the percentage of revenue used for patient care , quality improving activities , and reduced premiums — to determine whether maos have met minimum requirements .

as of may 2014 , cms had taken some , but not yet all , appropriate actions — as outlined in its medicaid encounter data validation protocol — to ensure that ma encounter data are complete and accurate before they are used .

 ( see fig .

2. ) .

cms's actions to date have focused on communicating with maos about data submission requirements , certifying maos' capability to transmit the data , and conducting automated checks for completeness and accuracy of the data .

however , the agency has not yet conducted statistical analyses , reviewed medical records , and provided maos with summary reports on data quality referenced in its medicaid encounter data validation protocol .

although cms intends to perform these additional quality assurance activities , cms officials have not specified a time frame for doing so .

cms has established certain requirements for the maos' collection and submission of encounter data .

the initial step in cms's medicaid encounter data validation protocol is to establish such features as the data submission format , the data elements to be reported , the time frames for data submission , and the benchmarks — target rates — for completeness and accuracy of the data .

cms required that maos use the reporting format that is standard in the health insurance industry , and maos began submitting files in that format in january 2012 .

cms also required that maos submit encounter data — including any corrections to the data — within specified time frames and at intervals determined by their size .

to enhance compliance with its encounter data requirements and thus promote complete and accurate data submissions , cms has engaged in regular and open communication with maos since 2010 .

agency officials have regularly held meetings with maos to discuss encounter data system enhancements , changes in data submission requirements , and concerns on specific encounter data topics .

although maos noted that they would like to continue receiving detailed information frequently — particularly on the more complex aspects of the encounter data submission process — cms reduced the frequency of the encounter data user group meetings during the summer of 2013 .

according to cms officials , maos' increased familiarity with data submission requirements reduced the need for ongoing guidance .

other outreach methods the agency has used include newsletters and bulletins with information such as the most common data errors , a technical assistance support desk to address specific reporting circumstances , and a website for posting summaries and questions from meetings with maos .

to maintain detailed guidance on data submission requirements , cms produced and updates an encounter data manual .

 ( see app .

i for more information about cms's outreach efforts with maos. ) .

while it has focused its efforts on educating plans about reporting requirements , cms has not yet established benchmarks for encounter data completeness and accuracy and does not have a timeline for developing such benchmarks .

as stated in the medicaid encounter data validation protocol , each data field submitted for each encounter type should have an acceptable rate of completeness and accuracy .

the protocol states that each plan's target error rate should be below 5 percent , composed of the percentage of missing , duplicate , or incorrect records .

in 2012 , cms stated it would develop error frequency benchmarks but has yet to do so .

in may 2014 , agency officials told us that as they gain more experience with the data submissions they will use that information to develop such performance benchmarks .

in contrast , state medicaid agencies have established various benchmarks for medicaid encounter data , which could help inform the development of similar benchmarks for ma encounter data .

for example , new jersey permits mcos to have no more than 2 percent of encounter data submissions denied each month .

alternatively , arizona does not allow the payment information in mcos' encounter data submissions to vary from the financial reports submitted by mcos by more than 3 to 5 percent.without benchmarks , as suggested by the protocol , the agency has no objective standards against which it could hold maos accountable for complete and accurate data reporting .

cms has certified nearly all maos to verify their capability for collecting under cms's protocol for validating and submitting encounter data.medicaid encounter data , each mco's information system should be assessed to see whether it is likely to successfully capture and transmit the encounter data .

such a review would determine where the plan's information system may be vulnerable to incomplete or inaccurate data capture , storage , or reporting .

to become certified for submitting encounter data , cms requires an maos' information system undergo complete end - to - end testing .

maos needed to separately demonstrate that they can successfully transmit encounter data collected from institutional , professional , and durable medical equipment providers .

during official testing , maos had to achieve at least a 95 percent acceptance rate for each type of encounter .

also , maos were required to sign an agreement with cms attesting that they will ensure that data in every submission can be supported by a medical record and that the data are complete and accurate .

cms performs automated checks to determine encounter data quality and identify submission issues , such as whether certain data elements are missing , and sends automated notifications to maos .

according to cms's protocol for validating medicaid encounter data , performing electronic checks on encounter data is a key step in verifying data quality .

such a data review should include basic checks of the data files by provider type and for each of the data elements in the files .

under the protocol , the standard data review process should be automated to verify that , among other things , critical data elements are not missing and are in the correct format , data values are consistent across data elements and are within the volume of data aligns with enrollment figures .

cms performs over 1,000 automated checks to verify that data elements are present , the values of data elements are reasonable , and the data are not duplicated .

according to cms , the number of errors returned to maos and the number of duplicate data files submitted per mao can illustrate , at least in part , the completeness and accuracy of the encounter data submitted .

for example , cms performs automated checks to flag missing data elements — such as a contract id number or a date of service — in encounter data files and returns files with missing elements to maos .

cms also determines whether encounter data elements have the correct alphanumeric values ( eg , that zip codes contain only numeric characters ) and verifies whether the values are consistent across data elements ( eg , the date of service is before the date of data submission ) .

in addition , cms ensures that the same data file is not accepted into the encounter data system more than once , which would result in duplicate data files .

after performing these automated checks , cms sends maos up to five types of automated reports with details about the encounter data submission , including information on the data received .

these reports provide information on whether errors occurred and whether encounter data processing can continue so that maos can identify problems with their data .

cms may provide additional reports if maos need to resubmit the data to meet cms's requirements .

 ( see app .

ii for a summary of cms's automated reports for maos. ) .

although representatives from maos noted that cms has not always produced the automated reports on a timely basis , cms officials told us that they now produce the reports within 1 week of encounter data submission .

according to the mao representatives , the reports are generally useful , straightforward , and easy to understand .

cms plans to develop four other automated reports related to data submission and processing but has not established a time frame for doing so .

these reports are expected to determine the number of encounter data files accepted and rejected identify encounter data submission errors and summarize the type of errors found , provide additional details on rejected encounter data submissions , ascertain diagnoses that cms accepted and will use to calculate risk scores .

although cms has had plans since at least october 2010 to develop a report that identifies those diagnoses that it will use to calculate risk scores , it still has not produced the report .

maos we interviewed expressed concern that cms has not developed this report , which could help them understand how encounter data will be incorporated into cms's risk score calculation .

although cms is aware of the need to perform statistical analyses of ma encounter data , the agency has not yet conducted these analyses .

according to cms's protocol for validating medicaid encounter data , analyzing values in specific data elements , generating basic statistics on the volume and consistency of data elements , and periodically compiling and reviewing statistics on utilization rates can help detect data validity issues .

in march 2014 , cms officials told us that they were able to only summarize the volume of encounter data files by ma plan .

the officials stated that they would like to be able to determine the frequency of diagnoses per encounter data file , examine the dates of service on encounter data files , and compare ma encounter data with ffs claims data by the summer of 2014 .

however , the officials noted that they have not developed a specific time frame for performing statistical analyses and that determining which analyses to perform will be an iterative process over the next year or two .

it appears that cms will use encounter data to calculate 2015 risk scores and pay maos before it performs statistical analyses of the data .

as cms begins to analyze the quality of ma encounter data , several types of statistical analyses outlined in its medicaid validation protocol may help detect potentially inaccurate or unreliable data .

such analyses include the following: determining whether the frequency of values within an encounter data element is reasonable .

for example , a frequency distribution for the place of service variable would be expected to include a reasonable distribution between inpatient hospital , outpatient hospital , and physician office visits .

this type of analysis can help detect whether a value is missing , underreported , or overreported .

generating basic statistics from the encounter data .

for example , analyzing the rates of outpatient services by provider zip code could help discover that encounter data files are missing certain zip codes , indicating a certain amount of underreporting .

to examine the completeness of medicaid encounter data , a cms contractor assessed the average number of encounter data files per enrollee and the percentage of enrollees with data files .

as another example , maos reporting an unexpectedly large number of a particular service may suggest overreporting .

analyzing encounter data elements by demographic group , provider type , and service type .

for example , analyzing encounter data by enrollees' gender would enable cms to verify that data files for gender - specific diagnoses and procedures are logical .

analyzing encounter data by provider type helps identify missing or erroneous data for specific provider types or discover fluctuations in enrollee visits .

for example , dramatic changes in utilization from one time period to another may indicate erroneous data .

finally , analyzing encounter data by service type also helps to examine the relationship between ( 1 ) ancillary services ( eg , laboratory tests and x - rays ) and enrollee visits , ( 2 ) primary care and specialty care visits , or ( 3 ) outpatient services and inpatient admissions .

comparing encounter data with other medicare data sources , maos' financial reports , or other benchmarks .

comparing ma encounter data with medicare ffs data may help determine whether differences exist in hospital admission rates between the ma and ffs programs .

in addition , comparing the volume of encounter data to financial reports helps reveal gaps in the data.monitoring maos' encounter data volumes for various service types against established benchmarks helps identify data submission problems , according to an actuarial firm that assessed medicaid furthermore , moreover , new jersey examines the encounter data for california.rate of services used per 1,000 mco enrollees against benchmarks for 28 service categories , such as laboratory services , to assess data completeness .

cms has not yet performed ma enrollees' medical record reviews , which typically involve comparing a sample of encounter data with the clinical information contained in enrollees' medical records .

according to cms's protocol for validating medicaid encounter data , medical record reviews can help confirm the findings generated in the encounter data analyses .

use of medical record reviews in a medicaid encounter data validation study in a 2010 medicaid encounter data validation study for georgia , the health services advisory group examined the extent to which services documented in enrollees' medical records were absent in their encounter data and the extent to which services documented in enrollees' encounter data were absent from their medical records .

it also evaluated the accuracy of the diagnosis and procedure codes in encounter data by comparing them with documentation in enrollees' medical records .

the findings showed that enrollees' medical records generally supported encounter data files in georgia .

specifically , 93.9 percent of the dates of service , 86.7 percent of the diagnosis codes , and 78.5 percent of the procedure codes from the encounter data had supporting evidence in the medical records .

however , not all services documented in the medical records were found in encounter data files .

specifically , 20.5 percent of the dates of service , 49.3 percent of the diagnosis codes , and 40.1 percent of the procedure codes documented in enrollees' medical records were omitted from encounter data files .

acknowledging the necessity of medical record reviews , cms officials noted that the agency plans to review medical records as part of its ma risk adjustment data validation auditing process when it begins using encounter data for risk adjustment purposes .

however , as of may 2014 , the agency has not developed specific plans or time frames to include these data in this auditing process .

cms currently uses this auditing process to validate the accuracy of raps data .

specifically , cms requires maos to provide medical records to substantiate the information in a selected sample of ma enrollees' raps data .

on the basis of the clinical information contained in enrollees' medical records that substantiates the information in their raps data , cms calculates corrected risk scores and calculates payment errors — which can represent a net overpayment or underpayment .

some maos may have been overpaid and may need to refund medicare payments when enrollees' medical records do not provide evidence for the risk - adjusted payment they had received from cms .

because cms has not yet conducted statistical analyses and reviewed medical records , it cannot report information from these activities to each ma plan .

cms's protocol for validating medicaid encounter data highlights the importance of summarizing information , reporting findings , and providing recommendations to plans for improving the completeness and accuracy of encounter data .

once the data are validated , maos could use summary reports from cms in several ways , such as monitoring quality improvement and service utilization and managing their enrollees and providers .

for example , the health services advisory group's 2010 encounter data validation study for georgia evaluated the completeness and accuracy of encounter data submitted by three mcos .

the study included plan - specific tables on the number and percentage of encounter files by place of service with statewide comparisons , the number and percentage of valid encounter files for age - and gender - appropriate diagnoses and services , and the number of encounter files by month of service .

without this type of information , cms and maos cannot ensure the completeness and accuracy of ma encounter data .

the collection of ma encounter data provides cms with the opportunity to improve the accuracy of medicare payments to maos and to monitor specific health care services used by enrollees .

for ma encounter data to reach its full potential , it is critical that cms develop a clearly defined strategy — which includes specific actions , priorities , and milestones — for using the information and validating the completeness and accuracy of the data .

deciding how the data are to be used influences which data elements need to be collected and , in turn , the extent of data reporting .

however , cms has yet to develop specifics on how or when it will use encounter data for a variety of program management purposes .

although cms has decided to use ma encounter data to supplement raps data in calculating risk scores in 2015 , this use may inappropriately increase payments to maos .

using diagnoses from both sources can only increase the number of diagnoses reported for ma enrollees .

this has the potential to widen the existing discrepancy between ffs and ma in the coding of diagnoses .

as we previously recommended , cms should take steps to improve the accuracy of the adjustment made for differences in diagnostic coding practices between ffs and ma to help ensure appropriate payments to maos .

as of march 2014 , cms has not acted on our recommendation .

to the extent that cms continues to pay maos under its current risk adjustment system and not adequately account for diagnostic coding differences , excess payments to maos could grow .

furthermore , cms's decision to use ma encounter data in 2015 may be premature because the agency has not yet fully validated the data .

cms has taken steps to validate the data , such as establishing certain reporting requirements and performing automated data checks .

however , the agency has not yet completed other steps in assessing whether the data are suitable for use , such as performing statistical analyses , reviewing medical records , and providing maos with summary reports of its findings .

without fully validating the completeness and accuracy of ma encounter data , cms and maos would be unable to confidently use these data for risk adjustment or any other program management or policy purposes .

until cms determines that encounter data are sufficiently complete and accurate to be used for risk adjustment and other intended purposes , the potential benefits of using these data will be delayed .

to ensure that ma encounter data are of sufficient quality for their intended purposes , the administrator of cms should establish specific plans and time frames for using the data for all intended purposes in addition to risk adjusting payments to maos and complete all the steps necessary to validate the data , including performing statistical analyses , reviewing medical records , and providing maos with summary reports on cms's findings , before using the data to risk adjust payments or for other intended purposes .

we provided a draft of this report to hhs for comment .

in its written response , hhs agreed that establishing plans for using encounter data and performing steps to validate the data are important activities .

however , it did not address the specific recommendations we made .

 ( see app .

iii. ) .

regarding our first recommendation — to establish specific plans and time frames for all uses of ma encounter data — hhs stated that it agreed that the agency should establish plans for using the data .

hhs noted that it has developed lists of the purposes for which it intends to use the data .

current regulations authorize four purposes — risk adjustment , quality improvement , medicare disproportionate share percentages , and medicare coverage monitoring .

hhs recently published a proposed rule that outlines several additional purposes — program evaluation , program integrity , program administration , and others .

hhs stated that once the proposed rule is finalized , cms will be in a position to establish specific plans and time frames for the list of additional permissible uses of ma encounter data .

however , cms has had the authority since 2008 to use ma encounter data for the initial four purposes , thus it remains unclear if and when cms will develop detailed plans for these earlier authorized uses .

regarding our second recommendation — to fully validate ma encounter data before use for any purpose — hhs stated that it will continue its data validation activities while it uses the data for risk adjusting payments to maos .

hhs agreed that performing statistical analyses and providing summary reports are important elements of data validation .

hhs stated that it will undertake medical record reviews — which are used to verify encounter data — through its ongoing risk adjustment validation audits of raps data .

we remain concerned , however , that cms intends to use 2014 ma encounter data to support its risk score calculations for 2015 before it completes all data validation activities suggested by the medicaid protocol .

furthermore , cms's reliance on risk adjustment validation audits of raps data may not be adequate to confirm the completeness and accuracy of encounter data given significant differences — in the volume and breadth of data elements — between the two data collection efforts .

as agreed with your office , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the administrator of cms , interested congressional committees , and others .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-7114 or cosgrovej@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix iv .

description cms organized this meeting with medicare advantage organizations ( mao ) to disseminate information on the requirements for encounter data submission , the transition to submitting encounter data , and the schedule for encounter data implementation .

cms prepared this reference guide to provide maos with information about collecting encounter data from health care providers and submitting encounter data to cms .

the reference guide also includes information about encounter data processing that cms performs .

cms prepared these guides , which it regularly updates , to provide technical assistance on conducting health insurance portability and accountability act of 1996- compliant electronic transactions .

december 2010 through march 2011 cms organized these meetings between cms and maos to discuss specific ma encounter data topics and concerns .

cms also published questions and answers from these meetings .

cms organized these meetings to provide maos with continued guidance on submitting encounter data .

cms also published questions and answers from these meetings .

cms organized these meetings to provide updates regarding decisions the agency made regarding encounter data implementation .

cms prepares bulletins with updated information on encounter data processing , such as the most common errors in submitting encounter data .

cms also prepares newsletters with information on policy updates .

the cssc help line provides encounter data assistance to maos by a toll - free telephone number .

maos receive updated information about encounter data submission through the cssc website .

palmetto gba is cms's contractor that manages the collection of ma encounter data and the cssc help line .

appendix ii: summary of automated reports for medicare advantage ( ma ) encounter data submissions report developer the accredited standards committee x12 notify ma plans about problems with the submission of encounter data files .

example the centers for medicare & medicaid services ( cms ) rejects an encounter data file that contains an error in a processing - related data element .

determine the syntactical accuracy of encounter data elements .

cms alerts an ma plan that letters appear in a numeric - only data element .

acknowledge the acceptance or rejection of encounter data files .

cms notifies an ma plan about a problem with an encounter data submission .

provide information on whether encounter data files and service - related data elements have been accepted or rejected for further processing .

cms informs an ma plan that an encounter data file was rejected for further processing while another one was accepted .

notify ma plans about duplicate encounter data files and service - related data elements .

cms tells an ma plan that an encounter data file includes duplicate services or is the duplicate of another data file .

in addition to the contact named above , rosamond katz , assistant director ; manuel buentello ; david grossman ; elizabeth t. morrison ; and hemi tewarson made key contributions to this report .

medicare: contractors and private plans play a major role in administering benefits .

gao - 14-417t .

washington , d.c.: march 4 , 2014 .

medicare advantage: 2011 profits similar to projections for most plans , but higher for plans with specific eligibility requirements .

gao - 14-148 .

washington , d.c.: december 19 , 2013 .

high - risk series: an update .

gao - 13-283 .

washington , d.c.: february 2013 .

medicare advantage: substantial excess payments underscore need for cms to improve accuracy of risk score adjustments .

gao - 13-206 .

washington , d.c.: january 31 , 2013 .

medicare advantage: cms should improve the accuracy of risk score adjustments for diagnostic coding practices .

gao - 12-51 .

washington , d.c.: january 12 , 2012 .

medicare advantage: changes improved accuracy of risk adjustment for certain beneficiaries .

gao - 12-52 .

washington , d.c.: december 9 , 2011 .

