the cost of the decennial census has steadily increased during the past 40 years .

for example , at about $12.3 billion , the 2010 census was 31 percent more costly than the $9.4 billion 2000 census ( in constant 2020 dollars ) .

given budgetary realities , that cost growth is difficult to sustain .

beginning in 1990 , we reported that rising costs and difficulties in securing public participation , among other challenges , required a new approach to taking the census — a view that was shared by the u.s. census bureau ( bureau ) and other stakeholders .

earlier this year the bureau conducted the 2016 census test in los angeles ( l.a. ) county , california , and harris county , texas .

a key objective of the test was to assess the methodology for non - response follow - up ( nrfu ) , where enumerators personally visit households that do not self - respond to the census .

nrfu is the largest and costliest of all census - taking activities because it is so labor intensive .

the bureau selected harris and l.a. counties as test sites for several reasons including language diversity , demographic diversity , high vacancy rates , and varying levels of internet usage .

there are around 225,000 housing units in each test area .

in november 2016 , we testified on the progress of the test as well as other key preparations , and described important lessons learned from the 2010 census that can apply to the 2020 census .

you asked us to review how selected nrfu operations performed during the 2016 census test .

the objective of this review was to review the test and identify any lessons learned that could potentially impact pending design decisions for the 2020 census .

to address this objective , we reviewed key documents including the 2016 census test plan that discussed the goals and objectives of the 2016 census test , as well as training manuals , respondent contact strategy documents and business rules for nrfu .

we interviewed census staff at both test sites including local supervisors of operations , enumerators , and office personnel .

at the test sites , we observed enumerators conducting nrfu interviews and we used the training manuals to determine whether enumerators collected information as prescribed by the bureau .

in total we conducted 31 in - field observations of bureau enumerators conducting nrfu .

we also interviewed bureau officials in headquarters to obtain information on the strategies and procedures for collecting data in the 2016 census test and what changes to procedures were made based on lessons learned from the 2015 census test .

we reviewed nrfu interview data from the bureau's workload case management system and looked for patterns in the data such as the number of refusals and completed interviews .

we performed a data reliability assessment on nrfu interview data collected from the workload case management system and found that the data was reliable for the purpose of our reporting objective .

we conducted this performance audit from april 2016 to january 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

for the 2020 census , the bureau intends to limit its per - household cost to not more than that of the 2010 census , adjusted for inflation .

to achieve this goal , the bureau is significantly changing how it conducts the census , in part by re - engineering key census - taking methods and infrastructure .

the bureau's innovations include ( 1 ) using the internet as a self - response option ; ( 2 ) verifying most housing unit addresses using “in - office” procedures rather than costly field canvassing ; ( 3 ) in certain instances , replacing enumerator - collected data with administrative records ( information already provided to federal and state governments as they administer other programs ) and , ( 4 ) re - engineering field data collection methods .

the bureau's various initiatives have the potential to make major contributions toward limiting cost increases .

in october 2015 , the bureau estimated that with its new approach it can conduct the 2020 census for a life - cycle cost of $12.5 billion , $5.2 billion less than if it were to repeat the design and methods of the 2010 census ( both in constant 2020 dollars ) .

table 1 below shows the bureau's estimated cost savings it hopes to achieve in 4 innovation areas .

sufficient testing , while important to the success of any census , is even more critical for the bureau's preparations for 2020 .

to help control costs and maintain accuracy , the 2020 census design includes new procedures and technology that have not been used extensively in earlier decennials , if at all .

while these innovations show promise for a more cost - effective head count , they also introduce new risks .

as we have noted in our prior work , it will be important to thoroughly test the operations planned for 2020 to ensure they will ( 1 ) produce needed cost savings , ( 2 ) function in concert with other census operations , and ( 3 ) work at the scale needed for the national head count .

the bureau's failure to fully test some key operations prior to the 2010 census was a key factor that led us to designate that decennial as one of our high - risk areas .

the 2016 test was the latest major test of nrfu in the bureau's testing program .

in 2014 , the bureau tested new methods for conducting nrfu in the maryland and washington , d.c. , area .

in 2015 , the bureau assessed nrfu operations in maricopa county , arizona .

in 2018 , the bureau plans to conduct a final “end - to - end” test which is essentially a dress rehearsal for the actual decennial .

the bureau needs to finalize the census design by the end of fiscal year 2017 so that key activities can be included in the end - to - end test .

the bureau plans to conduct additional research and testing through 2018 in order to further refine the design of the 2020 census but recently decided to alter its approach .

on october 18 , 2016 , the bureau announced plans to stop two field test operations planned for fiscal year 2017 to mitigate risks from funding uncertainty .

the bureau said it would stop all planned field activity , including local outreach and hiring , at its test sites in puerto rico , north and south dakota , and washington state .

the bureau will not carry out planned field tests of its mail out strategy and nrfu in puerto rico .

the bureau also cancelled plans to update its address list in the indians lands and surrounding areas in the three states .

however , the bureau said it will continue with other planned testing in fiscal year 2017 , such as that focusing on systems readiness and internet response .

further , the bureau said it would consider incorporating the stopped field activity elements within the 2018 end - to - end test .

the bureau maintains that stopping the 2017 field test will help prioritize readiness for the 2018 end - to - end test , and mitigate risk .

nevertheless , as we noted in our november 2016 testimony , it represents a lost opportunity to test , refine , and integrate operations and systems , and puts more pressure on the 2018 end - to - end test to demonstrate that enumeration activities will function as needed for 2020 .

nrfu generally proceeded according to the bureau's operational plans .

for example , the bureau demonstrated procedures for quality assurance and training .

on the other hand , according to preliminary 2016 census test data , there were 19,721 nrfu cases coded as non - interviews in harris county , texas and 14,026 in l.a. county , california , or about 30 and 20 percent of the test workload respectively .

according to the bureau , non - interviews are cases where no data or insufficient data were collected , either because enumerators made six attempted visits without success ( the maximum number the bureau allowed ) , or visits were not completed due to , for example , language barriers or dangerous situations .

in such cases for the 2020 census , the bureau may have to impute attributes of the household based on the demographic characteristics of surrounding housing units as well as administrative records .

according to bureau officials , they are not certain why there were so many non - interviews for the 2016 census test and are researching potential causes .

bureau officials told us that they expect higher numbers of non - interviews during tests in part , because , compared to the actual enumeration the bureau conducts less outreach and promotion .

while the 2016 census test interview rate is not necessarily a precursor to the 2020 non - interview rate , because of its relationship to the cost and quality of the census , it will be important for the bureau to better understand the factors contributing to it .

bureau officials hypothesized that another contributing factor could be related to nrfu methods used in the 2016 census test compared to earlier decennials .

for the 2010 and prior censuses , enumerators collected information during nrfu using pencil and paper .

enumerators may have visited a housing unit more than the six maximum allowable visits to obtain an interview but did not record all of their attempts , thus enabling them to achieve a higher completion rate .

for the 2020 census , and as tested in 2016 , the bureau plans to collect data using mobile devices leased from a contractor , and an automated case management system to manage each household visit ( see figure 1 ) .

the bureau believes that this approach will provide a faster , more accurate , and more secure means of data collection .

unlike previous censuses and one prior test , enumerators in the 2016 census test did not have an assigned set of cases that they alone would work until completion .

instead , the bureau relied on an enhanced operational control system that was designed to provide daily assignments and street routing of nrfu cases to enumerators in the most optimal and efficient way .

at the same time , the mobile device and automated case management system did not allow an enumerator to attempt to visit a housing unit more than once per day , reopen a closed case , or exceed the maximum allowable six attempts .

one factor we observed that may have contributed to the non - interview rate was that enumerators did not seem to uniformly understand or follow procedures for completing interviews with proxy respondents ( a proxy is someone who is a non - household member , at least 15 years old , and knowledgeable about the nrfu address ) .

according to the 2016 census test enumerator training manual , when an eligible respondent at the address cannot be located , the automated case management system on the mobile device will prompt the enumerator when to find a proxy to interview , such as when no one is home or the housing unit appears vacant .

in such circumstances , enumerators are to find a neighbor or landlord to interview .

however , in the course of our site visits , we observed that enumerators did not always follow these procedures .

for example , we observed that one enumerator , when prompted to find a proxy , looked to the left and then right and , finding no one , closed the case .

similarly , another enumerator ignored the prompt to find a proxy and explained that neighbors are usually not responsive or willing to provide information about the neighbor and did not seek to find a proxy .

enumerators we interviewed did not seem to understand the importance of obtaining a successful proxy interview and many appeared to have received little encouragement during training to put in effort to find a proxy .

proxy data for occupied households are important to the success of the census because the alternative is a non - interview .

in 2010 about one - fourth of the nrfu interviews for occupied housing units were conducted using proxy data .

we shared our observations with bureau officials who told us that they are aware that enumerator training for proxies needs to be revised to convey the importance of collecting proxy data when necessary .

converting non - interviews by collecting respondent or proxy data can improve interview completion rates , and ultimately the quality of census data .

the bureau told us it will continue to refine procedures for 2020 .

according to the bureau , its plans to automate the assignment of nrfu cases have the potential to deliver significant efficiency gains .

at the same time , improving certain enumeration procedures and communicating better could produce additional efficiencies by enabling the bureau to be more responsive to situations enumerators encounter in the course of their follow - up work .

enumerators were unable to access recently closed incomplete cases .

under current procedures , if an enumerator is unable to make contact with a household member , the case management system closes that case to be reattempted at a later date , perhaps by a different enumerator ; assuming fewer than six attempts have been made .

decisions on when re - attempts will be made — and by whom — are automated and not designed to be responsive to the immediate circumstances on the ground .

this is in contrast to earlier decennials when enumerators , using paper - based data collection procedures , had discretion and control over when to re - attempt cases in the area where they were working .

according to the bureau , leaving cases open for re - attempts can undermine the efficiency gains of automation when enumerators depart significantly from their optimized route , circling back needlessly to previously attempted cases rather than progressing through their scheduled workload .

during our test site observations , however , we found how this approach could lead to inefficiencies in certain circumstances .

for example , we observed enumerators start their nrfu visits in the early afternoon as scheduled , when many people are out working or are otherwise away .

if no one answered the door , those cases were closed for the day and reassigned later .

however , if a household member returned while the enumerator was still around , the enumerator could not reopen the case and attempt an interview .

we saw this happen at both test site locations , typically in apartment buildings or at apartment - style gated communities , where enumerators had clear visibility of a large number of housing units and could easily see people arriving home .

bureau officials acknowledged that closing cases in this fashion represented a missed opportunity and plan to test greater flexibilities as part of the 2018 end - to - end test .

programming some flexibility into the mobile device — if accompanied with adequate training on how and when to use it — should permit some interviews to be completed without having to deploy staff to the same case on subsequent days .

this in turn could reduce the cost of follow - up attempts and improve interview completion rates .

enumerators did not understand procedures for visits to property managers .

property managers are a key source of information on non - respondents when enumerators cannot find people at home .

they can also facilitate access to locked buildings .

further , developing a rapport with property managers has helped the nrfu process , such as when repeated access to a secured building or residential complex is needed on subsequent days by different enumerators .

in response to problems observed during the bureau's 2014 and 2015 census tests and to complaints from property managers about multiple uncoordinated visits by enumerators , the bureau's 2016 census test introduced specific procedures to conduct initial visits to property managers in large multi - unit apartment buildings .

the procedures sought to identify up front which , if any , units needing follow - up were vacant , eliminating the need for enumerators to collect this information from property managers with subsequent visits on a case - by - case basis .

according to bureau officials , the automated case management system was designed to allow for an enumerator to make up to three visits to property managers to remove vacant units .

according to the bureau , the 2016 census test demonstrated that vacant units could quickly be removed from the nrfu workload using these procedures in cases where a property manager was readily available ; however , in other cases the procedures caused confusion .

for example , whenever an initial visit was unsuccessful , all of the cases at that location — up until then collated into only one summary row of the enumerator's on - screen case list — would suddenly expand and appear as individual cases to be worked , sometimes adding several screens and dozens of cases to the length of the list , which the enumerators we spoke with found confusing .

furthermore , without the knowledge of which units were vacant , enumerators may have unnecessarily visited these units and increased the cost and the time required to complete nrfu .

during debriefing sessions the bureau held , enumerators and their supervisors identified training in these procedures as an area they felt needed greater attention in the future .

bureau officials said that they are pleased that the test demonstrated their progress in automating case management at multi - unit locations , but at the same time , they recognize the need to better refine the initial property manager contact procedures and integrate multi - unit procedures into the training .

during our field visits , we encountered several instances where enumerators had been told by a respondent or otherwise learned that returning at a specific time on a later date would improve their chance of obtaining an interview from either a household respondent or a property manager .

according to the bureau , while there was a mechanism for capturing and using this information , it was not uniformly available to the enumerators , nor did the enumerators always use the mechanism when appropriate .

as a result , the bureau's 2016 census test and automated case management system did not have an efficient way to leverage that information .

attempting to contact non - responding households at times respondents are expected to be available can increase the completion rate and reduce the need to return at a later date or rely on proxy interviews as a source of information .

the bureau's automated case management system used estimated hour - by - hour probabilities for the best time to contact people when making enumerator assignments .

the estimation relied on various administrative records , information from other bureau surveys that had successful contacts in the past , as well as area characteristics .

the 2016 census test did not have a way to change or update these estimates when cases were subsequently reassigned .

the assigned time windows were intended to result in more productive visits and reduce costs .

when enumerators identified potentially better times to attempt a contact , they were instructed to key this information into their mobile devices .

for example , one enumerator keyed in a mother's request to come back thursday afternoon when her kids were in camp , while others keyed in information like office hours and telephone contact numbers obtained from signs on the property they had seen for property managers .

however , according to the bureau this updated information went unused , and we met enumerators who had been assigned to enumerate addresses at the same unproductive time after they had written notes documenting other better times to visit .

another enumerator reported visiting a property manager who complained that the enumerator was not honoring the manager's earlier request made during a prior enumeration attempt that an enumerator return during a specified time window .

such repeat visits can waste enumerator time ( and miles driven ) , and contribute to respondent burden or reduced data quality when respondents become annoyed and may become less cooperative .

we discussed our preliminary observation with bureau managers at the test sites , who expressed frustration that the automated case management system did not allow them to use the locally - obtained data on when to contact people whom they found in enumerator notes in a way to affect future case assignment .

headquarters staff told us that while they have not fully evaluated this yet , they are concerned that providing local managers with too much flexibility to override the results of optimized case and time assignments would undermine the efficiency gains achievable by the automation .

they also explained that enumerators were provided the capability to record what day or what time of day for follow - up .

this information could have been used by the automated case management system to better target the timing of future assignments .

however , they acknowledged that this procedure may not have been explained during enumerator training .

reviewing the enumerator training manual , we confirmed that there were no procedures to allow enumerators to systematically record what day or what time of day to follow - up at a housing unit .

bureau officials have said that this is another area they are looking into and plan to address .

the key innovations the bureau plans for 2020 show promise for controlling costs and maintaining accuracy , although there are significant risks involved .

the bureau is aware of these risks , and robust testing can help manage them by assessing the feasibility of key activities , their capacity to deliver desired outcomes , and their ability to work in concert with one another under operational conditions .

going forward , to help ensure a cost - effective enumeration , it will be important for the bureau to improve its nrfu procedures by addressing the challenges identified during the 2016 test , updating related training materials as needed , and completing these efforts in time to be included in the bureau's end - to - end test scheduled for 2018 .

the challenges we observed include ( 1 ) reducing high non - interview rates , ( 2 ) difficulty accessing recently closed , incomplete cases , ( 3 ) the need to improve coordination with managers of multi - unit properties , and ( 4 ) the need to better leverage operational information collected by enumerators .

resolving these issues should help the bureau improve its ability to collect quality data and reduce the cost of unnecessary follow - up visits during nrfu .

we recommend that the secretary of commerce and under secretary for economic affairs direct the census bureau to take the following actions: 1 .

determine the cause ( s ) for non - interviews experienced during the non - response follow - up operation and revise and test what , if any , changes need to be made to operational procedures , training , or both , including making contact with proxy respondents .

2 .

revise and test operational procedures for accessing incomplete closed cases and revise and test training material to reflect when this flexibility to access incomplete closed cases should be used by the enumerator .

3 .

revise and test operational procedures and relevant training materials for initial property manager visits to ensure procedures and training material are communicated to and understood by enumerators and their supervisors .

4 .

revise and test procedures on how to better leverage enumerator - collected information on the best time or day to conduct interviews , and ensure enumerators are properly trained on these procedures .

we provided a draft of this report to the secretary of the department of commerce for comment .

in its written comments , reproduced in appendix i , the department of commerce agreed with our findings and recommendations .

the census bureau also provided technical comments that we incorporated , as appropriate .

we are sending copies of this report to the secretary of commerce , the counselor to the secretary with delegated duties of the undersecretary of commerce for economic affairs , the director of the u.s. census bureau , and interested congressional committees .

the report also will be available at no charge on our website at http: / / www.gao.gov .

if you have any questions about this report please contact me at ( 202 ) 512-2757 or goldenkoffr@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

the gao staff that made major contributions to this report are listed in appendix ii .

robert goldenkoff , ( 202 ) 512-2757 or goldenkoffr@gao.gov .

in addition to the contact named above , lisa pearson , assistant director ; mark abraham , shea bader , richard hung , donna miller , ty mitchell , cynthia saunders ; a.j .

stephens , and timothy wexler made significant contributions to this report .

