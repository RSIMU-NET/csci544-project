the defense logistics agency ( dla ) plays a critical role in supporting america's military forces worldwide .

to fulfill this role , dla employs about 28,000 civilian and military workers , located at about 500 sites in all 50 states and in 28 countries .

it also manages about 4 million supply items and processes about 30 million annual supply distribution actions .

in fiscal year 2000 , dla reported that these operations resulted in sales to the military services of about $13 billion .

dla relies on software - intensive systems to support this work .

an important determinant of the quality of software - intensive systems , and thus dla's mission performance , is the quality of the processes used to acquire these systems .

this report is one in a series of products to satisfy our mandate under the fiscal year 2001 defense authorization act .

the act directed that we review dla's efficiency and effectiveness in meeting requirements , its application of best business practices , and opportunities for improving its operations .

as agreed with your offices , the objectives of this review of dla's information technology ( it ) management were to determine ( 1 ) whether dla has the effective software acquisition processes that are necessary to modernize and maintain systems and ( 2 ) what actions dla has planned or in place to improve these processes .

carnegie mellon university's software engineering institute ( sei ) , recognized for its expertise in software processes , has developed models and methods that define and determine organizations' software process maturity .

together , these models and methods provide ( 1 ) a logical framework for baselining an organization's current process capabilities ( i.e. , determining what practices are effectively implemented , not effectively implemented , or contain mixed or inconclusive evidence ) and ( 2 ) a structured plan for incremental process improvement .

these models and methods are generally recognized as best business practices .

using sei's software acquisition capability maturity modelsm ( sa - cmm® ) and sei's software capability evaluation method , our staff ( trained at sei ) evaluated dla's software acquisition maturity in six of seven key process areas that are necessary to attain a “repeatable” level of process maturity.the repeatable level of process maturity is level 2 on sei's five - level scale .

an organization at the repeatable level of process maturity has the necessary process discipline in place to repeat earlier successes on similar projects .

organizations that do not satisfy the requirements for the repeatable level are by default judged to be at level 1 , the “initial” level of maturity .

this means that their processes are immature , ad hoc , and sometimes even chaotic , with few of the processes defined and success dependent mainly on the heroic efforts of individuals .

we also evaluated dla on one level - 3 , or “defined” level , process — acquisition risk management .

we included acquisition risk management because many software experts consider it to be one of the most important process areas .

our evaluation included dla's only ongoing software / system acquisitions: the business systems modernization ( bsm ) and the fuels automated system ( fas ) .

details on our objectives , scope , and methodology are contained in appendix i .

the department of defense ( dod ) provided us with comments on a draft of this report , which are discussed in the “agency comments” section .

dla is the department of defense's ( dod ) logistics manager for all dod consumable items and some department repair items .

its primary business function is to provide supply support in order to sustain military operations and readiness .

in addition to this primary function , which dla refers to as either “materiel management” or “supply - chain management,” dla performs five other major business functions: distributing materiel ordered from its inventory ; purchasing fuels for dod and the u.s. government ; storing strategic materiel ; marketing surplus dod materiel for reuse and disposal ; and providing numerous information services , such as item cataloging , for dod , the united states , and selected foreign governments .

dla consists of a central command authority supported by a number of field commands that manage the agency's six business functions .

until about 1997 , dla generally developed its systems in - house .

since then , the agency has begun to acquire systems , relying on contractors for system development and managing the acquisition of these systems .

currently , dla is in the process of acquiring two systems: business systems modernization ( bsm ) and fuels automated system ( fas ) .

bsm is intended to modernize dla's materiel management business function , changing the agency from being solely a provider and manager of physical inventory to being a manager of supply chains .

in this role , dla would link customers with appropriate suppliers and track physical and financial business practices .

it is planning to replace two large legacy systems , as well as several supporting programs , that are more than 30 years old and are not integrated .

bsm is based on commercially available software products .

dla plans to acquire and deploy its bsm system solution through a series of four system releases / increments .

first , it plans to demonstrate successful application of its new concept of doing business for selected commodities — namely , earth - moving equipment , medical / pharmaceutical supplies , and f / a - 18 engine components — at the three defense supply centers .

if this first release is successfully demonstrated , dla plans to expand the system solution to other commodities in three additional increments .

dla plans to invest approximately $658 million to acquire and implement bsm from fiscal years 2000 through 2005 .

fas is intended to help the defense energy support center manage about $5 billion in contracts with petroleum suppliers each year .

fas is to be a multifunctional system that provides for , among other things , point - of - sale data collection inventory control , finance and accounting , procurement , and facilities management .

fas , which relies on a commercially available software package , is being fielded incrementally .

increment 1 is the base - level operational module that is currently being deployed to base - level sites worldwide .

the second increment is the enterprise - level system , which is to be deployed to its direct delivery commodity business unit .

dla plans to invest $293 million in fas from fiscal year 1995 through 2002 .

sei's sa - cmm is used to measure an organization's capability to manage the acquisition of software .

sei's expertise in , and model and methods for , determining software process assessment are recognized and accepted throughout the software industry .

the model defines five levels of software acquisition maturity .

each level of maturity ( except level 1 ) indicates process capability in relation to key process areas .

for a maturity level to be achieved , all key process areas related to that level must be implemented effectively .

the second level of process maturity , level 2 ( referred to as the repeatable level ) , demonstrates that basic management processes are established to track performance , cost , and schedule , and the necessary discipline is in place to repeat earlier successes on similar projects .

organizations that do not effectively implement all key process areas for the repeatable level are , by default , at level 1 , the initial level of maturity .

level - 1 processes can be described as immature , ad hoc , and sometimes chaotic ; success in software acquisition for these organizations depends on the ability and commitment of the staff involved .

figure 1 further explains the five - level software acquisition model .

we evaluated dla against six of the seven level - 2 ( repeatable ) key process areas in the sa - cmm .

we did not evaluate dla on the seventh key process area — transition to support — because the contractors who are implementing bsm and fas will support these systems when they are operational , rendering transition to support irrelevant for these acquisitions .

we evaluated dla against one level - 3 ( defined ) key process area — acquisition risk management — because many software acquisition experts consider it to be one of the most important key process areas .

these key process areas are described in table 1 .

as established by the model , each key process area contains five common features — commitment to perform , ability to perform , activities to be performed , measurement and analysis of activities , and verification of activities' implementation .

these five features collectively provide a framework for the implementation and institutionalization of the key process areas .

the common feature definitions are as follows: commitment to perform: this feature describes the actions that the organization takes to establish the process and ensure that it can endure .

key practices typically involve establishing organizational policies and sponsorship .

ability to perform: this feature describes the preconditions that must exist in the project or organization to implement the software acquisition process competently .

key practices typically include assigning responsibility and providing training .

activities to be performed: this feature describes the roles and procedures necessary to implement a key process area .

key practices typically involve establishing plans and procedures , performing the work , tracking it , and taking appropriate management actions .

measurement and analysis of activities: this feature describes the steps necessary to measure progress and analyze the measurements .

key practices typically involve defining the measurements to be taken and the analyses to be conducted to determine the status and effectiveness of the activities performed .

verification of activities' implementation: this feature describes the steps the organization must take to ensure that project activities are performed in accordance with established processes .

key practices typically involve regular reviews by management .

each common feature consists of a number of key practices — specific actions such as developing an organizational policy for software acquisition , developing various plans for software acquisition activities , and tracking a contractor's progress .

when an organization is evaluated against the sa - cmm , comparisons of actual performance against a key practice can result in one of four possible outcomes or ratings: strength: the key practice involved was effectively implemented .

weakness: the key practice was not effectively implemented or was not implemented .

observation: the key practice was evaluated , but cannot be characterized as a strength because ( 1 ) the project team did not provide sufficient evidence to support a strength rating or ( 2 ) the key practice was only partially performed .

not rated: the key practice is not relevant to the project .

to achieve the repeatable level , dla would have to demonstrate that the key practices related to this level were implemented effectively in the software acquisition projects being evaluated , and thus the project successes can be repeated in future projects .

dla is not at level 2 ( the repeatable level of maturity ) when compared with the sa - cmm — meaning that dla does not possess an agencywide or corporate ability to effectively acquire software - intensive systems .

whereas dla's bsm project fully or substantially satisfied sei's sa - cmm requirements for the key process areas for level 2 , as well as requirements for one level 3 ( defined level ) key process area , its fas project did not satisfy all the criteria for any of these key process areas .

a discussion of how each system compared with the sa - cmm is summarized below .

bsm completely satisfied requirements for three of the level - 2 key process areas , as well as for the one level - 3 key process area , and substantially satisfied requirements for the remaining three level - 2 key process areas that we evaluated .

 ( see table 2 for the percentage of strengths and weakness for each area evaluated. ) .

according to bsm officials , satisfying the criteria for the key process areas is attributable to the following factors: allocating adequate resources ; following good program management practices , as defined in dod directive 5000 ; and working closely with relevant oversight groups .

to address those few weaknesses that we identified , project officials told us that they have initiated corrective action .

bsm satisfied all key practices in software acquisition planning , such as ( 1 ) having a written software acquisition policy , ( 2 ) having adequate resources for software acquisition planning activities , ( 3 ) developing and documenting the software acquisition strategy and plan , and ( 4 ) making and using measurements to determine the status of software acquisition planning activities .

project management , including ( 1 ) designating responsibility for project management , ( 2 ) having a written policy for the management of the software project , ( 3 ) having adequate resources for the duration of the software acquisition project , and ( 4 ) tracking the risks associated with cost , schedule , resources , and the technical aspects of the project .

contract tracking and oversight , including ( 1 ) designating responsibility for contract tracking and oversight , ( 2 ) including contract specialists in the project team , and ( 3 ) having a documented plan for contract tracking and oversight .

acquisition risk management , such as ( 1 ) having a risk management plan , ( 2 ) having a written policy for the management of software acquisition risk , and ( 3 ) measuring and reporting on the status of acquisition risk management activities to management .

bsm also satisfied all but one key practice in solicitation .

strengths included ( 1 ) designating responsibility for the software portion of the solicitation , ( 2 ) preparing cost and schedule estimates for the software products and services being acquired , and ( 3 ) having an independent review of cost and schedule estimates for the software products and services being acquired .

bsm's one weakness in this key process area was in not having a written policy for the software portion of the solicitation .

this is significant because , according to the sei , an institutional policy provides for establishing an enduring process .

bsm also satisfied all but three key practices in requirements development and management .

strengths included ( 1 ) having a written policy for managing the software - related contractual requirements , ( 2 ) having a group that is responsible for performing requirements development and management activities , and ( 3 ) measuring and reporting to management on the status of requirements development and management activities .

one of the three weaknesses was the lack of a documented requirements development and management plan .

such a plan provides a roadmap for completing important requirements development and management activities .

without it , projects risk either not performing important tasks or not performing them effectively .

the other two weaknesses involved the project office's appraisal of system requirements changes .

specifically , bsm did not appraise ( 1 ) requests to change system requirements for their impact on the software being acquired or ( 2 ) all changes to the requirements for impact on performance and contract schedule and cost .

these activities are critical to making informed , risk - based decisions about whether to approve requirements changes .

last , bsm satisfied all but one key practice in evaluation , and we do not view that practice as significant .

strengths included ( 1 ) designating responsibility for contract tracking and oversight , ( 2 ) documenting evaluation plans and conducting evaluation activities in accordance with the plan , and ( 3 ) developing and managing evaluation requirements in conjunction with developing software technical requirements .

by generally satisfying these key process areas for its bsm project , dla has increased the chances that the software acquired on this project will meet stated requirements and will be delivered on time and within budget .

see appendix ii for more detailed information on key process areas and our findings on bsm .

because of the number and severity of its key practice weaknesses , fas did not fully satisfy all the criteria for any of the five level - 2 sa - cmm key process areas or for the one level - 3 key process area that we evaluated .

 ( see table 3 for the percentage of strengths and weakness for each area evaluated. ) .

according to fas officials , these weaknesses are attributable to a lack of adequate resources for the process areas .

however , these officials stated that they are currently in the process of reorganizing and addressing resource shortages .

in the software - acquisition – planning key process area , fas had 12 strengths , 2 weaknesses , and 1 observation .

strengths included , among other things , ( 1 ) having a written software acquisition policy , ( 2 ) developing and documenting the software acquisition strategy and plan , and ( 3 ) having management review software - acquisition – planning activities .

weaknesses included ( 1 ) not having adequate resources for software - acquisition – planning activities and ( 2 ) not measuring the status of the software - acquisition – planning activities and resultant products .

the weaknesses are significant because they could prevent management from developing effective plans , from being aware of problems in meeting planned commitments , or from taking necessary corrective actions expeditiously .

in the requirements development and management key process area , fas had six strengths , six weaknesses , and two observations .

examples of strengths included ( 1 ) having a written policy for managing the software - related contractual requirements and ( 2 ) having a group that is responsible for performing requirements development and management activities .

however , we found weaknesses in important key practices that jeopardize effective control of the requirements baseline and can result in software products that do not meet cost , schedule , or performance objectives .

specific examples of weaknesses included ( 1 ) not having a documented requirements development and management plan , ( 2 ) not appraising requests to change system requirements for their impact on the software being acquired , ( 3 ) not appraising changes to the software - related contractual requirements for their impact on performance and contract schedule and cost , and ( 4 ) not measuring and reporting to management on the status of requirements development and management activities .

in the project management key process area , fas had 10 strengths and 6 weaknesses .

strengths included , among other things , ( 1 ) designating responsibility for project management , ( 2 ) having a written policy for the management of the software project , and ( 3 ) using a corrective action system for identifying , recording , tracking , and correcting problems .

examples of weaknesses included ( 1 ) not having adequate resources for the duration of the software acquisition project , ( 2 ) not documenting the roles , responsibilities , and authority for the project functions , and ( 3 ) not tracking the risks associated with cost , schedule , and resources .

these weaknesses are significant because they could jeopardize the project's ability to ensure that important project management and contractor activities are defined , understood , and completed .

fas had 11 strengths , 5 weaknesses , and 1 observation in the contract tracking and oversight key process area .

strengths included , among other things , ( 1 ) designating responsibility for contract tracking and oversight , ( 2 ) including contract specialists on the project team , and ( 3 ) ensuring that individuals performing contract tracking and oversight activities had experience or received training .

examples of weaknesses included ( 1 ) not having a documented plan for contract tracking and oversight and ( 2 ) not comparing the actual cost and schedule of the contractor's software engineering effort with planned schedules and budgets .

because of these weaknesses , fas contractor tracking and oversight activities are undisciplined and unstructured , thereby increasing the chances of fas software acquisitions being late , costing more than expected , and not performing as intended .

in the evaluation key process area , fas had nine strengths , two weaknesses , two observations , and two areas that were not rated .

strengths included , among other things , ( 1 ) designating responsibility for planning , managing , and performing evaluation activities , ( 2 ) documenting evaluation plans and conducting evaluation activities in accordance with the plan , and ( 3 ) developing and managing evaluation requirements in conjunction with developing software technical requirements .

weaknesses were ( 1 ) not ensuring that adequate resources were provided for evaluating activities and ( 2 ) not measuring and reporting on the status of evaluation activities to management .

these weaknesses are significant because they preclude dla decisionmakers from knowing whether contractor - developed software is meeting defined requirements .

fas performed poorly in the one level - 3 key process area that we evaluated — acquisition risk management — with 3 strengths , 11 weaknesses , and 1 observation .

examples of strengths included ( 1 ) having a written policy for the management of software acquisition risk and ( 2 ) designating responsibility for software acquisition risk activities .

weaknesses included , among others , ( 1 ) not having adequate resources for performing risk management activities , ( 2 ) not having a software risk management plan , and ( 3 ) not measuring and reporting on the status of acquisition risk management activities to management .

because of these weaknesses , the project office does not have adequate assurance that it will promptly identify risks and effectively mitigate them before they become problems .

by not satisfying any of these key process areas for its fas project , dla is unnecessarily increasing the risk that the software acquired on this project will not meet stated requirements and will not be delivered on time and within budget .

appendix iii provides more details on the key process areas and our findings on fas .

the quality of the processes involved in developing , acquiring , and engineering software and systems has a significant effect on the quality of the resulting products .

accordingly , process improvement programs can increase product quality and decrease product costs .

public and private organizations have reported significant returns on investment through such process improvement programs .

in particular , sei has published reports of benefits realized through process improvement programs .

for example , sei reported in 1995 that a major defense contractor had implemented a process improvement program in 1988 and by 1995 had reduced its re - work costs from about 40 percent of project cost to about 10 percent , increased staff productivity by about 170 percent , and reduced defects by about 75 percent .

according to a 1999 sei report , a software development contractor reduced its average deviation from estimated schedule time from 112 percent to 5 percent between 1988 and 1996 .

during the same period , sei reported that this contractor reduced its average deviation from estimated cost from 87 percent to minus 4 percent .

dla does not currently have a software process improvement program , and recent efforts to establish one have not made much progress .

we recently reported on dod's software process improvement efforts , including those within dla .

specifically , we reported that before 1998 , dla had a software process improvement program ; however , dla eliminated it during a reorganization in 1998 .

in response to our report , dla's chief information officer said that the software process improvement program was to be reestablished during fiscal year 2001 and that dla's goal would be for its system developers and acquirers to reach a level 2 on the cmm by fiscal year 2002 .

to date , dla has established an integrated product team for software process improvement that is tasked to study dla's software processes and , based on this study , to make recommendations on areas in which dla needs to improve .

dla has also dropped its goal of achieving level 2 by 2002 , and it does not intend to specify a cmm level for its contractors .

the software process improvement team has produced several draft papers and a draft policy , but it does not have a plan or milestones for achieving software process improvement .

according to an agency official associated with dla's process improvement effort , funding to develop and implement a software process improvement program has not been approved because of other agency it funding priorities , such as bsm .

dla does not have the institutional management capabilities necessary for effectively acquiring quality software repeatedly on one project after another .

this lack of agencywide consistency in software acquisition management controls means that software project success at dla currently depends more on the individuals assigned to a given project than on the rules governing how any assigned individuals will function .

that has proven to be a risky way to manage software - intensive acquisitions .

to dla's benefit , it currently has a model software acquisition project ( bsm ) that , albeit not perfect , is a solid example from which to leverage lessons learned and replicate effective software acquisition practices across the agency .

to do so effectively , however , dla will need to implement a formal software process improvement program and devote adequate resources to correct the weaknesses in the software acquisition processes discussed in this report .

it will also have to commit the resources needed to implement a software process improvement program .

to reduce the software acquisition risks associated with its two ongoing acquisition projects , we recommend that the secretary of defense direct the director of dla to immediately correct each bsm and fas software - acquisition – practice weakness identified in this report .

to ensure that dla has in place the necessary process controls to acquire quality software consistently on future acquisition projects , we recommend that the secretary also direct the dla director to issue a policy requiring that ( 1 ) dla software - intensive acquisition projects satisfy all applicable sei sa - cmm level - 2 key process areas and the level - 3 risk management key process area and ( 2 ) dla software contractors have comparable software process maturity levels ; and direct the chief information officer ( cio ) to establish and sustain a software process improvement program , including ( 1 ) developing and implementing a software process improvement plan that specifies measurable goals and milestones , ( 2 ) providing adequate resources to the program , and ( 3 ) reporting to the director every 6 months on progress against plans .

dod provided what it termed “official oral comments” from the deputy under secretary for logistics and materiel readiness on a draft of this report .

in its comments , dod stated that it generally concurred with the report and concurred with the recommendations .

in particular , dod stated that it will issue policy directives requiring the director of dla to ( 1 ) correct identified software acquisition practice weaknesses , except in circumstances in which corrections to past events make doing so impractical ; ( 2 ) implement a plan in all software - intensive projects to satisfy all applicable sei sa - cmm level - 2 and level - 3 key process areas , and require all dla software contractors to have comparable software process maturity levels ; and ( 3 ) establish and sustain a software process improvement program that includes a plan specifying measurable goals and milestones , provides adequate resources , and reports to the director of dla every 6 months on progress against the plan .

we are sending copies of this report to the chairmen and ranking minority members of the senate appropriations subcommittee on defense ; the subcommittee on readiness and management support , senate committee on armed services ; the house appropriations subcommittee on defense ; and the subcommittee on readiness , house committee on armed services .

we are also sending copies to the director , office of management and budget ; the under secretary of defense for acquisition and technology ; the deputy under secretary of defense for logistics and materiel readiness ; and the director , defense logistics agency .

copies will be made available to others upon request .

if you have any questions regarding this report , please contact me at ( 202 ) 512-3439 or by e - mail at hiter@gao.gov .

an additional gao contact and staff acknowledgements are listed in appendix iv .

our objectives were to determine ( 1 ) whether the defense logistics agency ( dla ) has the effective software acquisition processes necessary to modernize and maintain systems and ( 2 ) what actions dla has planned or in place to improve these processes .

to determine whether dla has effective software acquisition processes , we applied the software engineering institute's ( sei ) software acquisition capability maturity model using our sei - trained analysts .

we focused on the key process areas necessary to obtain a repeatable level of maturity , the second level of sei's five - level model .

we also evaluated against one level - 3 key process area — acquisition risk management — because of its importance .

we met with project managers and project team members to determine whether and to what extent they implemented each key practice , and to obtain relevant documentation .

in accordance with the sei model , for each key process area we reviewed , we evaluated dla's institutional policies and practices and compared project - specific guidance and practices against the required key practices .

more specifically , for each key practice we reviewed , we compared project - specific documentation and practices against the criteria in the software acquisition model .

if the project met the criteria for the key practice reviewed , we rated it as a strength .

if the project did not meet the criteria for the key practice reviewed , we rated it as a weakness .

if the evidence was mixed or inconclusive and did not support a rating of either a strength or a weakness , we treated it as an observation .

if the key practice was not relevant to the project , we did not rate it .

we evaluated dla's only two software acquisition projects underway at the time of our review: the business systems modernization ( bsm ) and the fuels automated system ( fas ) .

to determine what actions dla has planned or in place to improve its software processes , we identified the group within dla that is tasked with performing this function .

we interviewed agency officials who are involved in software process improvement , collected data , and analyzed draft policies and draft working papers describing planned work .

we performed our work from may through october 2001 , in accordance with generally accepted government auditing standards .

in addition to the individual named above , key contributors to this report were suzanne burns , yvette banks , niti bery , sophia harrison , madhav panwar , and teresa tucker .

