the medicare physician fee schedule specifies the payments to physicians for more than 7,000 services and procedures , ranging from a routine office visit to surgical removal of a brain tumor .

medicare's physician fee schedule payments totaled about $43 billion in 1997 .

since many other insurers base their payments on medicare's , the fee schedule allowances also influence physicians' non - medicare income .

before implementation of the physician fee schedule in 1992 , medicare based payments on each physician's charges and the charges of other physicians in the same locality .

the fee schedule system was instituted to relate payments to the resources physicians use to provide a service , rather than to physicians' charges for a service .

for each of three categories of resources — physician work , practice expenses , and malpractice expenses — each medical procedure is ranked against all other procedures according to the amount of resources used .

the fee schedule allowance for a procedure equals the sum of the three rankings , expressed as relative value units ( rvu ) , multiplied by a conversion factor that translates rvus into dollars .

currently , only the physician work rvus , which account for about half the total rvus for each procedure , are resource based .

the practice expense and malpractice expense rvus , which account for about 41 percent and 5 percent , respectively , of the fee schedule allowances , are still based on historical charges for physician services .

the reason for this is that a new system for calculating resource - based values for these components was not available at the time the fee schedule was implemented by the health care financing administration ( hcfa ) .

 ( app .

i provides additional information on the medicare fee schedule. ) .

the social security amendments of 1994 required the secretary of health and human services ( hhs ) to revise the fee schedule by 1998 so that the practice expense rvus would reflect the relative amount of applicable resources physicians expend when they provide a service or perform a procedure .

the congress required that the revision be budget neutral , so total medicare payments to physicians for practice expenses would not change .

however , medicare payments could increase for some services and procedures and decrease for others .

furthermore , depending upon their mix of services and procedures , members of different physician specialties could experience gains or losses in their medicare payments .

on june 18 , 1997 , hcfa published a notice of proposed rulemaking in the federal register that described hcfa's proposed practice expense revisions to the fee schedule .

hcfa estimated that the revisions would generally increase medicare payments to physician specialties that provide more office - based services .

for example , hcfa estimated that medicare payments to family practice physicians would increase by 12 percent , and payments to thoracic surgeons , who perform more hospital - based procedures , would decrease by 28 percent .

in total , hcfa estimated that its revisions , had they been in effect in fiscal year 1997 , would have reallocated $2 billion of the $18 billion medicare paid for physician practice expenses that year .

the revisions could also affect physicians' non - medicare income if other insurers adopt the medicare revisions .

some physician groups argued that hcfa based its proposed revisions on invalid data and that the reallocations of medicare payments would be too severe .

subsequently , the congress included provisions in the balanced budget act of 1997 that delay the resource - based practice expense revisions until 1999 ; establish a 3-year phase - in period for the revisions ; and require hcfa to publish a revised proposed rule by may 1 , 1998 .

the act also required us to evaluate hcfa's june 1997 proposed rule , report to the congress within 6 months , and consult with representatives of physicians' organizations during our evaluation .

this report provides our evaluation of hcfa's proposed practice expense revisions and also includes information on hcfa's ongoing efforts to refine its data and methodologies .

specifically , this report focuses on ( 1 ) hcfa's approach for estimating the practice expenses directly associated with each medical service or procedure , ( 2 ) two methodologies hcfa used to adjust the direct expense estimates , ( 3 ) practice expenses excluded or limited by hcfa , ( 4 ) hcfa's method for assigning indirect practice expenses to each medical service or procedure , and ( 5 ) the potential impact of the new fee schedule allowances on beneficiary access to care .

we reviewed hcfa's proposed revisions , comments received on the proposal , and selected documentation on the data and methodologies hcfa and its contractor used .

we also held extensive meetings with hcfa staff to gain an understanding of the methodologies they used and the rationale behind some of their key decisions and assumptions .

we did not gather new data on physician practice expenses , test the reliability of hcfa's data , or independently verify hcfa's data sources or calculations ; but we did our own calculations , using hcfa's data , to analyze some aspects of hcfa's methodology .

we also met with researchers , representatives of physician organizations , and others to obtain their views on hcfa's proposal and to discuss potential alternative data sources and methodologies .

we performed our evaluation from august through december 1997 in accordance with generally accepted government auditing standards .

the physician groups and others that we met with are listed in appendix ii .

a resource - based , relative - value payment system ranks procedures on a common scale , according to the resources used for the procedure .

the need to estimate and rank practice expenses for thousands of medical procedures , coupled with the complex structure of the medicare program , presented hcfa with some enormous challenges .

cost data for physician practices are available in the aggregate and for individual items , including the wages and salaries of receptionists , nurses , and technicians employed by the physician ; the cost of office equipment such as examining tables , instruments , and diagnostic equipment ; the cost of supplies such as face masks and wound dressings ; and the cost of billing services and office space .

for most physician practices , the total of each of these expenses is probably readily available .

however , medicare pays physicians by procedure , such as a skin biopsy .

therefore , hcfa had to develop a way to estimate the portion of practice expenses associated with each procedure — information that is not readily available .

another difficulty inherent in developing a resource - based fee schedule is that significant variations in practice expenses exist among physicians and their practice settings .

for example , a general practice physician in a solo practice likely has expenses different from those of a physician in a group practice .

both these problems — the difficulty in allocating expenses to procedures and the variation in expenses among physician practices — are mitigated somewhat by basing the fee schedule allowances on relative rankings of practice expenses .

even though the absolute expenses associated with a procedure cannot be precisely measured and will vary among physicians , the expense of one procedure relative to another is easier to estimate and less likely to vary across physician practices .

because of these issues , revising the practice expense component of the fee schedule has been a difficult task for hcfa , and the revisions hcfa proposed in june 1997 have been the subject of widespread controversy among physician specialty groups .

this controversy is not unexpected , since the legislative requirement that fee schedule changes be budget neutral means that some physician specialty groups would benefit from the changes at the expense of other groups .

among the physician specialty groups that we met with , groups representing physicians whose medicare payments were projected to increase generally supported hcfa's proposal , while groups whose members' payments were projected to decrease were far more critical of hcfa's approach and methodology .

in the spring of 1994 , hcfa staff and leading researchers discussed potential approaches for developing detailed estimates of the practice expenses associated with each medical procedure .

on the basis of these discussions , hcfa decided to use a variety of data gathering and mathematical methods to estimate the direct and indirect practice expenses at the procedure level .

hcfa used those estimates as the basis for its june 1997 proposed revision to the physician fee schedule .

the key aspects of hcfa's approach were the use of ( 1 ) expert panels to estimate direct costs , ( 2 ) a series of hcfa's own methods to adjust the direct cost estimates , and ( 3 ) another hcfa method to allocate indirect expenses to procedures .

since then , hcfa has continued to refine both its data and its methodologies .

to estimate the direct expenses for individual procedures , hcfa convened 15 clinical practice expense panels ( cpep ) , organized by specialty .

each panel included 12 to 15 members .

about half the members of each panel were physicians , and the remaining members were practice administrators and nonphysician clinicians such as nurses .

hcfa provided national medical specialty societies an opportunity to nominate the panelists , and over 60 specialties and subspecialties were represented on the panels .

hcfa and contractor staff identified more than 6,000 procedure codes for which direct expense data would be developed .

the contractor arranged these codes into families of clinically related codes .

within each family of codes , the contractor also selected “reference codes” that formed a basis for ranking the other codes within the family .

hcfa and its consultants reviewed the contractor's work and made the family grouping and reference code information available to medical specialty societies for their review and comment .

some codes , called “redundant codes,” were assigned to two or more cpeps so that hcfa and its contractor could analyze differences in the estimates developed by the various panels .

for example , hcfa included the repair of a disk in the lower back among the procedures reviewed by both the orthopedic and neurosurgery panels .

within each panel , the members attempted to reach consensus on the type and quantity of nonphysician labor , medical equipment , and medical supplies required to perform each procedure .

the cpep members were instructed to base their estimates on the typical patient — the patient who most frequently undergoes a particular procedure — not necessarily a medicare patient .

for example , most women receiving hysterectomies are in their 40s and 50s and are not medicare patients .

once the cpeps completed their work , hcfa's contractor calculated the dollar costs of the labor , medical equipment , and medical supplies that the cpeps had estimated for each procedure .

nonphysician labor costs were calculated using about 100 occupational categories of clinical and administrative staff .

for example , if a cpep estimated that a procedure required 10 minutes of a registered nurse's time , the associated cost was calculated from the salaries and benefits paid to registered nurses .

for equipment , the contractor estimated costs using the price of the item , an applicable finance rate , and a depreciation schedule for that item based on an assumed utilization rate .

for medical supplies , the contractor identified a representative cost for each item on the basis of information from catalogues , suppliers , and cpep members .

for several reasons , hcfa applied a series of adjustments to the direct expenses estimated by the cpeps .

first , hcfa reviewed the data to ensure that the costs arrived at were allowable under medicare policy and revised the costs where necessary .

next , hcfa used a process called “linking” to convert the direct expense estimates of the different cpeps to a common scale .

hcfa also adjusted the revised estimates for labor , equipment , and supply costs to make them consistent with national practice expense data collected by the american medical association ( ama ) , a process that hcfa called “scaling.” lastly , hcfa adjusted estimates that appeared to be unreasonable .

after making all these adjustments , hcfa used a mathematical process to rank the procedures by direct expenses and convert the rankings into direct expense rvus .

indirect expenses , such as the cost of general office supplies and utilities , cannot be associated with specific medical procedures ; therefore , hcfa had to develop a method to identify and assign indirect expenses to the procedures .

hcfa originally intended to survey a random sample of approximately 5,000 physician practices , obtain data on their direct and indirect practice expenses , and use those data to develop a method for allocating indirect expenses .

however , hcfa abandoned this effort because few practices responded with the detailed information hcfa requested .

after exploring several alternatives , hcfa decided to allocate indirect expenses to procedures on the basis of the physician work , direct practice expense , and malpractice expense rvus associated with the procedure .

thus , procedures that ranked high in each of these categories were allocated proportionately more indirect expenses .

since publication of the proposed fee schedule revisions , hcfa has been reviewing the comments on its proposal and reexamining its data and methodologies .

in october 1997 , hcfa convened “validation” panels , composed primarily of physicians , to review the direct costs estimated by the original cpeps for several hundred procedures and revise those estimates as they believed necessary .

in november 1997 , hcfa asked representatives of physician groups to review and comment on its methodology for estimating and assigning indirect expenses .

then , in december 1997 , hcfa convened a “cross - specialty” panel comprising 38 members nominated by various medical specialty societies .

hcfa asked this panel to develop standard time estimates for selected administrative tasks .

hcfa officials said they may change the methods they used to convert the direct expense estimates to a common scale as well as the method they used to compute and assign indirect expenses .

ideally , estimates of the relative resources associated with each medical procedure would be based on resource data obtained from a broad , representative sample of physician practices .

however , the feasibility of completing such an enormous data collection task within reasonable time and cost constraints is doubtful , as evidenced by hcfa's unsuccessful attempt to survey 5,000 practices .

after considering this option and the limitations of survey data already gathered by other organizations , hcfa decided to use expert panels to estimate the relative resources associated with medical procedures .

various medical specialty and physician groups , however , have criticized this methodology .

they advocate using other methodologies as the basis for the fee schedule revisions — methodologies that have their own limitations .

at this time , hcfa is considering what , if any , changes it will make to the cpep data before incorporating these data into its next proposed rule .

researchers we contacted who specialize in physician reimbursement issues support hcfa's use of cpeps to estimate direct practice expenses .

generally , they believe that bringing together knowledgeable physicians , practice administrators , and clinical staff to identify the direct inputs used in providing a service or procedure is an acceptable , cost - effective approach .

the physician payment review commission ( pprc ) , which advises the congress on health care policy issues , also supports hcfa's approach and asserts that the cpep process is an adequate way to collect credible direct expense data for use in developing practice expense rvus .

some of the national medical societies we met with also support the cpep process .

for example , ama representatives told us that they believe the use of expert panels is an acceptable method for estimating the direct expenses associated with a procedure .

also , american society of internal medicine representatives said that the feedback they received indicated that their members thought the cpep meetings were an effective way to develop direct expense data for procedures .

the american academy of family physicians has also been supportive of hcfa's use of practice expense panels .

some medical specialty groups have criticized hcfa's design and implementation of the cpep process .

as discussed below , these criticisms focus on three issues .

first , some physician groups stated that the panels were not representative of the different practice settings or types of physicians who provide a particular service .

that is , the panels did not contain a broad spectrum of small and large practices or those from rural and urban areas , nor did they include representatives from all of the medical specialties .

this criticism ignores the efforts hcfa made , working closely with the major medical societies , to constitute representative panels .

hcfa asked the societies to nominate physicians and others who the medical societies believed could appropriately represent their membership .

although the number of individuals representing each medical specialty was small , collectively the panels included about 180 physicians from 61 medical specialties and subspecialties , and those physicians worked in different types and sizes of practices .

the benefits to be gained by further expanding the panels could be outweighed by the problems that would be encountered in structuring and moderating much larger groups .

second , some groups believe the cpep data are invalid because they represent the “best guesses” of physicians rather than actual practice expense data .

this criticism implies that the panelists lacked the knowledge to make informed judgments about the nonphysician labor , medical supplies , and equipment associated with individual procedures and that they were not prepared to participate in the panel discussions .

however , panelists based their judgments on a wide variety of factors , such as their knowledge of their own practices and results of surveys conducted by medical specialty societies ; this demonstrates that the panelists' collective knowledge about practice expenses was broader than their individual knowledge about their own practices .

third , the cpep process has been criticized because some of the panels used different assumptions and definitions than other panels , leading to differences in the resources identified by different panels for the same procedures .

for example , one panel's estimates included time for staff to resubmit denied claims , while another panel did not include this activity in its estimates .

in another case , two panels differed on the type of patient on which to base their estimates ; one considered “typical” patients , while the other considered “problem” patients .

hcfa officials acknowledge these differences but note that each panel was consistent internally when it identified the resources associated with individual procedures .

because different panels identified different resources for the redundant procedures , and because hcfa believed that the panels used different scales to rank their procedures , hcfa made a number of adjustments to the data .

the adjustments hcfa made are addressed separately in this report .

several medical specialty groups have recommended that hcfa use actual practice expense data , rather than the cpep process , as the basis for estimating direct expenses and calculating rvus .

they propose that hcfa obtain these data by either asking physician practices to complete a survey instrument mailed to them or collecting data on - site .

these approaches have their own limitations , some of which they share with the cpep process .

starting over and using one of these approaches as the primary means for developing direct expense estimates , we believe , would needlessly increase costs and further delay implementation of the fee schedule revisions .

surveys to gather procedure - level information require either the physician or other practice staff to use their best judgment to identify the expenses associated with procedures , since cost accounting systems do not allocate expenses in this manner .

also , once the results of a survey are received , analysts must adjust the data in order to make valid comparisons among respondents , since responses will likely vary by the type and size of responding practice .

the cpep process shares both these problems — cpep members were asked for their best judgment on the resources associated with specific procedures , and hcfa staff adjusted the cpep data to ensure consistency in the data reported by different panels .

a greater problem with surveys of physicians and physician practices is low response rates .

hcfa and its contractor developed a lengthy survey that asked physician practices to provide detailed data on their direct and indirect expenses for the procedures they billed to medicare .

for example , the survey asked practices to provide information on the number and types of clinical and administrative staff they employed , the frequency with which they provided each service in a year , and the square footage of office space that they leased or purchased .

after an initial test involving approximately 1,700 practices , hcfa canceled the survey because only about a quarter of the practices surveyed responded .

low response rates have also been encountered in national surveys conducted by the ama and the medical group management association ( mgma ) .

the ama's annual socioeconomic monitoring system ( sms ) survey polls about 4,000 physicians and asks them for information on a number of topics ; the survey includes eight general questions about practice expenses .

for example , the survey asks respondents for their share of the practice's total nonphysician payroll expenses and total expenses .

about one - third of the respondents are resurveyed the following year .

generally , about 40 percent of the physicians surveyed respond and provide complete information on the practice expense questions .

mgma collects practice expense data through a membership survey .

its 12-page survey instrument asks for information on a practice's current assets and liabilities ; operating costs ; total number of patients treated in a year ; and percentage of income from medicare , medicaid , and managed care plans .

the response rate for this survey is less than 30 percent .

moreover , estimates derived from existing or specially designed surveys may be biased because the respondents may not be representative of the broader population of physician practices .

for example , the practice expense portion of the ama's sms survey is addressed only to self - employed physicians — about 60 percent of the total physician population , according to ama officials .

also , this survey is not sufficiently large to statistically project estimates to smaller medical specialties .

similarly , mgma's survey does not cover all types of physician practices and is sent only to mgma members .

regarding hcfa's own attempt to survey practices , hcfa officials told us they were concerned that the respondents may be primarily from larger practices .

as a result , any estimates derived from the survey would likely not have reflected the expenses incurred by smaller practices .

gathering expense data on - site at physician practices also has limitations .

in the early 1990s , pprc contracted with three multispecialty group practices to collect detailed data on the resources they used in delivering selected services .

staff at the practices filled out schedules showing the activities they performed and the time spent on these activities .

the practices also developed information on the medical equipment and supplies used for particular procedures .

the problem with this approach is its cost .

pprc spent about $135,000 collecting data at just one multispecialty group practice .

it is unlikely that hcfa could fund this type of data collection effort in sufficient magnitude to use the information as its primary data source .

and basing new practice expense rvus on data gathered at only a few practices would raise legitimate concerns about adequate representation of the diverse range of physician practices .

several medical specialty societies have urged hcfa to gather practice expense data using activity - based costing , a method that was developed for use by manufacturing companies in the 1980s and has subsequently been applied in some health care organizations .

using this approach to identify costs for individual procedures involves several steps .

first , all of a practice's costs are obtained from information such as financial statements and tax returns .

next , the major processes within a practice , such as serving patients in the office , maintaining medical records , and billing , are identified by conducting on - site interviews and having staff complete worksheets that capture the time staff spend on their daily activities .

costs are then identified with , or allocated to , each process and , in turn , to the procedure codes associated with the process .

activity - based costing generally does not distinguish between individual procedure codes ; rather , it groups codes together and then assigns costs to the group of codes .

as a result , it does not provide the specificity needed to adjust the medicare fee schedule .

after the june 1997 publication of hcfa's proposed fee schedule revisions , hcfa used additional expert panels to review some of the data obtained from the 15 original panels .

in october 1997 , hcfa convened 17 “validation” panels composed primarily of physicians and again organized by specialty .

each panel was assigned between 14 and 36 procedures for which to review the original nonphysician labor , equipment , and supply estimates .

the validation panels generally increased the estimates of nonphysician labor identified by the original cpeps .

then , in december 1997 , hcfa convened a cross - specialty panel that included representatives from all the major medical specialty societies and medical directors from hcfa's claims processing contractors .

hcfa asked this panel to reach consensus on the direct labor estimates for 57 high - cost , high - volume procedures previously reviewed by the cpep and validation panels .

the cross - specialty panel failed to reach consensus , but it did provide hcfa with some insight into the reasons for differences among the estimates of previous panels .

at this time , it is unclear what approach hcfa will take in preparing its next proposed role , which is due in may 1998 .

hcfa has not yet decided whether to rely on the direct cost estimates developed by the original cpeps , the refinements made by the validation panels , or its own adjustments to the data ( which have come under strong criticism from some specialty groups ) .

various physician groups have advocated that hcfa validate its cpep data through means other than the expert panel process .

given hcfa's time and resource constraints , using surveys and on - site data gathering methodologies as the primary means to estimate the direct expenses associated with procedures is not practicable .

however , these methods could be used on a limited basis to check the basic accuracy of the cpep data .

hcfa could conduct a small number of on - site reviews , similar to pprc's approach , to test the validity of the cpep data .

gathering some direct expense data through either surveys or on - site reviews would enable hcfa to identify any egregious problems with the direct expense relative rankings and help focus its efforts on correcting those problems .

hcfa officials told us that they are considering such a check of the cpep data but have not yet finalized their decision .

hcfa staff believed that each of the cpeps developed reasonable relative rankings of its assigned procedures but found that for some procedures the labor estimates often varied considerably across cpeps for the same procedures .

these observed variations in estimates suggest that adjustments to the cpep data are necessary .

to correct for these variations , hcfa used an adjustment process referred to as “linking” to place the estimates on a common scale .

although we consider linking to be desirable , we found that certain features of the cpep data cast doubt on hcfa's particular linking model .

hcfa also adjusted the cpep data so that they were consistent in the aggregate with national practice expense data developed from the ama's sms survey — a process hcfa calls “scaling.” it is not clear whether hcfa will use linking in its next proposed rule .

hcfa staff adjusted the cpeps' administrative and clinical labor estimates because different panels developed very different estimates for the same procedures .

for example , two cpeps reviewed procedure code 43117 — partial removal of the esophagus .

one cpep estimated the administrative labor associated with this code at 375 minutes and the clinical labor at 697 minutes .

in contrast , the other cpep estimated administrative labor at 465 minutes and clinical labor at 1,647 minutes .

such variations support the need for adjusting the cpep estimates .

hcfa staff believe that some cpeps had higher labor time estimates than others primarily because the cpeps included activities performed by physicians or because they double - counted some activities that staff may do simultaneously .

while recognizing these differences in labor estimates , hcfa staff concluded that the cpeps ranked the procedures similarly .

that is , while two cpeps may have developed different labor estimates for the same codes , hcfa staff believe that the ratios between the estimates were generally constant .

for example , one cpep's estimates were generally twice as high as those of another .

to correct for these differences between cpeps , hcfa used a statistical regression methodology to standardize the different cpep labor estimates and “link” them , that is , place them on a common scale .

hcfa's methodology separately adjusted the administrative labor estimates and the clinical labor estimates developed by the panels .

hcfa's linking significantly reduced some of the original cpep estimates .

for instance , linking reduced the administrative estimates for one cpep by 80 percent and the clinical estimates of another cpep by 50 percent .

as a result of these changes , linking also affected the ranking of codes among cpeps .

for example , before linking , code a might have had a higher ranking than code b ; but after linking , the two might have been ranked equally or code b might have been ranked higher .

hcfa officials told us that linking's impact on the rankings was appropriate because it adjusted for some of the incorrect assumptions used by the panels , such as the assumption that a staff person always performs tasks sequentially .

representatives from several medical societies believe that hcfa's linking methodology is seriously flawed and is unwarranted .

the american college of surgeons , for example , believes that the higher labor time estimates developed by the panels reviewing surgical procedure codes are not necessarily inflated and therefore do not need to be adjusted .

rather , the american college of surgeons believes that these estimates reflect higher practice expenses incurred by surgeons , such as expenses associated with the need to obtain prior authorization for surgeries and with updating referring physicians on a patient's status .

on the other hand , the american society of internal medicine believes that linking is necessary .

representatives told us that some cpep labor time estimates are overstated because panelists on some cpeps uniformly assigned higher labor time estimates to the codes they reviewed than did other cpeps and that hcfa therefore needed to adjust these estimates downward to make them comparable across all panels .

in developing its linking methodology , hcfa wanted to generate separate adjustment factors for a panel's clinical labor estimates and its administrative labor estimates .

for example , if a panel's clinical labor estimates were too high by a factor of two , they would all be cut in half .

according to hcfa , these linking adjustments are most appropriate when the actual relationships between cpeps conform to certain patterns .

hcfa staff told us that their review suggested that the data generally followed these patterns , but we found that in a number of cases the cpep data departed considerably from these patterns .

for example , the ratios between any two panels' estimates for redundant codes generally have to be similar .

an intuitive test of this assumption is to examine the related assumption: that the cpeps rank the redundant codes generally in the same order .

if this were true , all the cpeps would , for example , rank codes a , b , and c in the order first , fifth , and tenth .

we found that , on the contrary , some cpeps ranked redundant codes in very different orders .

as a second example , hcfa asserted that its linking methodology is more appropriate when the actual cpep data conform to a second pattern — that the ratios of estimates between cpeps are generally constant .

if two cpeps evaluated codes a and b , the first cpep's labor estimates might generally be twice those of the second cpep — 70 minutes versus 35 minutes for code a and 120 minutes versus 60 minutes for code b .

if roughly constant ratios were found for all pairs of cpeps , then all the labor estimates by a particular cpep could be adjusted by a constant percentage without significantly affecting their relationship or ratios .

however , we found a number of cases that did not display generally constant ratios .

hcfa believes that such discrepancies do not compromise its model's reliability .

rather , it believes these discrepancies reflect real - world deviations from its model as a result of random differences between the cpeps .

however , our review of an analysis of hcfa's statistical model identified potentially significant problems that signal omission of a systematic factor .

this suggests the regression estimates may be statistically biased — too high or too low .

this same analysis , though , points to modifications of the hcfa regression that might yield a satisfactory linking method .

hcfa staff acknowledge that their regression model has some anomalies , but they do not believe the anomalies are serious enough to negate the overall validity of the model .

in addition , hcfa's linking methodology relies on cpep estimates for redundant codes , but critics have questioned the characteristics of the redundant codes selected and hcfa's process for selecting them .

hcfa's linking methodology assumes that the practice expenses associated with a redundant code are the same , no matter which medical specialty provides the service .

for example , the methodology assumes that , for an office visit , a cardiologist and a primary care physician incur the same labor expenses .

several medical specialties criticized this assumption , noting that the higher labor expense estimates of some cpeps may reflect that different tasks are performed or that more time is needed for similar tasks .

for example , administrative labor expenses for an office visit to a cardiologist might be higher than those for an office visit to a primary care physician because the cardiologist's staff may have to spend more time obtaining precertification approval and handling a higher percentage of denied claims .

to select redundant codes , hcfa and its contractor identified codes that were frequently billed by two different specialties .

this approach differed from the one hcfa used to select redundant codes while developing physician work rvus in the late 1980s .

as part of that process , clinicians representing different medical specialties reviewed potential redundant codes to ensure that they involved equivalent physician work .

in some cases , the clinicians determined that , because a code did not involve equivalent physician work between two specialties , its use as a linking code in the regression was not appropriate .

hcfa staff told us that they did not use the same process for the practice expense rvus .

they believed that any code evaluated by two or more cpeps was an appropriate redundant code because medicare pays the same amount regardless of which specialty performs the procedure .

representatives from both pprc and the ama agree that hcfa needs to adjust the labor estimates from the different cpeps to make them comparable .

however , representatives from both organizations question the process hcfa used to select the redundant codes and believe that physician participation in the selection of redundant codes would have improved the linking adjustments .

nevertheless , pprc staff do not believe that hcfa should select new redundant codes , assemble a new set of cpeps , and estimate the linking regression on new data .

instead , pprc staff agreed that it might be useful for hcfa to have physicians review the redundant codes used , eliminate any questionable codes , and rerun its regression model on this subset of the original cpep data .

 ( app .

iii provides more detailed information regarding hcfa's linking methodology and its limitations. ) .

following linking , hcfa compared the aggregate cpep data with data from the ama's 1996 sms survey .

hcfa found that the aggregate cpep estimates for labor , supplies , and equipment each accounted for a different portion of total direct expenses than the ama data did .

for instance , labor accounted for 73 percent of total direct expenses in the sms survey data but only 60 percent of the total direct expenses in the cpep data .

to make the cpep percentages mirror the sms survey percentages , hcfa inflated the cpeps' labor expenses for each code by 21 percent and the medical supply expenses by 6 percent and deflated the cpeps' medical equipment expenses by 61 percent .

hcfa staff told us that they believe this scaling was necessary to ensure that the proportions of practice expense rvus devoted to labor , supplies , and equipment were consistent with an external benchmark .

for example , without scaling , hcfa would have no means to ensure that the labor expense estimates , as adjusted by linking and other steps in hcfa's methodology , represented the appropriate labor expenses .

in addition , inaccuracies in hcfa's estimates of supply and equipment prices , as well as hcfa's assumed equipment utilization rate , might have distorted the expenses among the three components .

as a result , expenses associated with supplies and equipment might be overrepresented in total practice expense rvus .

 ( app .

iv contains more details on hcfa's scaling methodology and its effects on the cpep data. ) .

the ama believes that scaling was appropriate because the cpeps , given their limited size , were not necessarily representative of all medical practices .

therefore , the cpep data needed to be adjusted to reflect national averages .

pprc staff , too , believe that scaling is warranted .

however , they said that modifications to scaling are needed to ensure that the cpep data are consistent with the sms survey data , because hcfa eliminated certain labor expenses developed by the cpeps that are contained in the sms survey data .

some physician groups believe that if hcfa utilizes a scaling methodology in the future , it should develop different scaling factors for each medical specialty , since the percentages of labor , medical supplies , and medical equipment to total practice expenses vary among medical specialties .

for example , physicians who provide equipment - dependent procedures , such as echocardiography , have a higher percentage of equipment expenses compared with other specialties , such as family practitioners , that are not as dependent upon medical equipment .

hcfa officials told us that they may eliminate linking in their may 1998 proposed rule because it is a complex and confusing methodology that has caused considerable controversy in the medical community .

instead , they may make other adjustments to the cpep data so that comparisons can be made among the different cpeps .

for example , hcfa officials told us that they may use standard administrative labor estimates , such as the time it takes a receptionist to schedule a patient's next appointment , across broad categories of codes .

this may reduce much of the variation in administrative labor estimates developed by the cpeps and eliminate the need for linking these estimates .

hcfa may also shift administrative labor devoted to billing and other administrative activities from the direct expense category to the indirect expense category .

this change too may eliminate the need for linking the administrative labor estimates .

at this time , however , hcfa has made no decisions on whether it will continue to rely on its linking methodology as part of its may 1998 proposed rule .

hcfa disallowed some direct expenses identified by the cpeps because it believes medicare pays for these expenses outside the physician fee schedule .

hcfa also limited some administrative and clinical labor estimates: hcfa believes these estimates were too high but did not test the basis for its reductions .

various physician groups have suggested that hcfa reclassify certain administrative labor activities as indirect expenses , a move that could eliminate the need for limitations on estimates developed by the cpeps .

further , hcfa made certain assumptions regarding equipment utilization rates — assumptions that it has not tested and that some physician groups believe have negative effects on rvus .

hcfa edited the cpep data for both policy considerations and reasonableness .

the most controversial policy edit concerned hcfa's elimination of nearly all expenses related to physicians' staff who accompany them in the hospital — primarily nurses .

such staff reportedly ( 1 ) assist physicians at surgery , ( 2 ) serve as scrub nurses at surgery or perform other nursing functions , ( 3 ) assess patients following surgery and provide patient education , or ( 4 ) communicate with hospital staff to arrange for patient discharge and posthospital care .

hcfa officials said that they disallowed the expenses for these services primarily because medicare pays for them through other mechanisms .

for example , medicare's policy is to pay for assistants at surgery only if they are either physicians or physician assistants ; medicare does not pay for other medical professionals serving in this role .

according to hcfa , hospitals are responsible for providing the nurses who work in the hospital setting , and medicare's payments to the hospital for surgical procedures already cover the expense of scrub nurses who participate in surgeries .

medicare pays for postoperative patient assessment and education through the physician work component of the medicare fee schedule ; paying again for these expenses through the practice expense component of the fee schedule would represent double payment , according to hcfa officials .

regarding physician staff who communicate with hospital staff , hcfa allowed 15 minutes of a nurse's time as a direct expense for surgical codes .

the american college of surgeons and several other physician groups argue that surgeons are not separately reimbursed for their hospital - related practice expenses and that medicare should therefore recognize them as a legitimate practice expense .

representatives from these organizations said that hospitals have been cutting back on their nursing staff , prompting physicians to bring their own nurses to the hospital to assist them with their work .

according to hcfa officials , however , neither the american hospital association nor any physician group has been able to provide hcfa with information on the extent to which this practice occurs or how often physicians absorb these expenses .

in an october 1997 federal register notice , hcfa asked for specific data from physicians , hospitals , and others on the extent to which staff accompany physicians to hospitals , ambulatory surgical centers , and other facilities and are not otherwise reimbursed by medicare .

subsequent to completion of our fieldwork , hcfa received some limited information on this issue , but we did not review or evaluate it .

hcfa officials said that they will review this information before deciding whether to change their decision in hcfa's next proposed rule .

hcfa staff also conducted reasonableness edits of the cpep data that resulted in reducing the allowed expenses for certain codes .

physicians and clinical staff within hcfa , in consultation with other government physicians and medicare claims processing contractor staff , reviewed the cpep data and identified two problems .

they found that ( 1 ) the administrative labor time estimates developed by the cpeps for many diagnostic tests and minor procedures appeared to be excessive when compared with the administrative labor time estimates for a mid - level office visit and ( 2 ) the nonphysician clinical labor time estimates for many procedures were excessive when compared with the time physicians spend performing the procedures .

therefore , hcfa capped the administrative labor time for several categories of services at the level of a mid - level office visit .

with certain exceptions , hcfa also capped nonphysician clinical labor time at 1-1 / 2 times the minutes used by a physician to perform a procedure .

hcfa has not , however , conducted tests or studies that validate these changes and thus cannot be assured that they are necessary or reasonable .

it is not surprising that hcfa staff believed an administrative labor time cap was needed , given the variation in administrative labor time estimates developed by the cpeps and the controversy surrounding estimates of administrative billing activities .

the ama reported that the cpep administrative billing estimates seemed unreasonable , as they were based primarily on guesses .

we observed that estimates of billing times were frequently the most contentious issue within the validation and cross - specialty panels .

representatives from different physician groups told us that physicians are more familiar with clinical tasks , and the time needed to complete them , than they are with administrative tasks .

consequently , physician estimates for administrative tasks would be less accurate than those for clinical tasks , they said .

others , however , told us that physicians deferred in some cases to practice administrators on the panels , resulting in administrative labor estimates that were more reliable .

both the ama and most participants in the cross - specialty panel recommended that hcfa treat billing activities as indirect expenses rather than as direct expenses — a shift that would be consistent with accounting standards in the federal sector .

hcfa officials told us that they are considering this recommendation but have made no final decision .

treating billing and other administrative expenses as indirect expenses could make a cap on administrative labor estimates unnecessary .

hcfa assumed that equipment associated with specific procedures , such as a treadmill used for a cardiology stress test , is used 50 percent of the time that a practice was operating , while equipment that supports all or nearly all services provided by a practice , such as an examination table , is used 100 percent of the time .

hcfa officials told us that actual data on equipment utilization rates were not available from the medical community .

therefore , hcfa had to make assumptions about the rate at which equipment is used .

hcfa officials also told us that they could eliminate all equipment expenses from their direct expense rvu calculations without significantly altering the final rvus for most procedures because equipment typically represents a small fraction of a procedure's direct expenses .

they acknowledged , however , that the equipment utilization rate affects each medical specialty differently and that they have not conducted a sensitivity analysis to determine the effect of different equipment utilization rates on the different specialties .

the ama and other physician groups that we contacted said that hcfa's estimates greatly overstate the use of most equipment , resulting in an underestimation of the equipment expenses used in calculating rvus .

the american academy of ophthalmology , for example , surveyed its members and found that argon lasers used in eye surgery are used no more than 10 percent of the time that offices are open .

these physician groups believe that hcfa should seek input from large group practices as well as data from mgma on equipment utilization rates .

in its october 1997 federal register notice , hcfa asked for copies of any studies or other data showing the actual use of equipment , by procedure code , that it could use to adjust its equipment utilization rate assumptions .

this is consistent with the balanced budget act of 1997 requirement that hcfa use actual data in setting equipment utilization rates .

direct expenses can be specifically identified for a service or procedure , whereas indirect expenses , by definition , cannot .

therefore , total indirect expenses must be identified and assigned in some manner .

recognizing that there is no one right answer , hcfa considered several methodologies for assigning indirect expenses to individual procedure codes and selected a method that is based on the three components of the medicare fee schedule .

physician groups we contacted criticized this methodology because they believe that it fails to recognize that indirect expenses , as a percentage of all practice expenses , differ among medical specialties .

according to hcfa's proposed rule of june 1997 , hcfa considered four assignment methodologies .

hcfa's selected methodology assigns indirect expenses on the basis of ( 1 ) physician work rvus , ( 2 ) direct practice expense rvus , and ( 3 ) malpractice expense rvus for each code .

to calculate the indirect expense rvus for a procedure , hcfa adds the values of the three rvu components and then multiples the total by a factor of .219 .

this factor is constant for all codes and ensures that the total pool of indirect expense rvus does not exceed 45 percent of all practice expense rvus .

pprc supports this approach , which is generally consistent with the method pprc proposed for assigning indirect expenses to procedure codes .

hcfa officials said that they selected this methodology for several reasons .

first , it assigns indirect expenses on the basis of the variables that hcfa believes are the primary drivers of indirect expenses .

for example , higher physician work rvus generally reflect greater complexity of a procedure and more time required to carry it out — meaning that a physician can perform fewer of these procedures in a day .

this , in turn , means that a physician's indirect expenses associated with operating a practice , such as rent and utilities , must be allocated over a smaller pool of procedures .

second , hcfa's methodology reduced the redistribution effects of the proposed rule on various physician groups .

for example , surgeons and other physicians who provide hospital - based services benefited because their commonly performed procedures typically have higher physician work rvus than the procedures performed by physicians who provide office - based services .

higher physician work rvus result in greater indirect expense rvus under hcfa's assignment methodology .

physician groups have criticized hcfa's methodology , saying that it fails to recognize that different medical specialties have different direct - to - indirect expense ratios .

the american college of surgeons , for example , reports data that indicate indirect expenses , as a percentage of total practice expenses , range from 54 percent for urologists to 71 percent for neurosurgeons .

these physician groups believe that it is inappropriate for hcfa to ignore these differences and assume a constant direct - to - indirect expense ratio across all medical specialties .

our review of hcfa's methodology shows that the ratio of direct to indirect expenses differs by procedure .

for example , procedure code 13100 — repair of a wound — consists of 1.39 direct expense rvus and 1.01 indirect expense rvus , resulting in an indirect expense ratio of 42 percent ( relative to total expenses ) .

in contrast , procedure code 24587 — repair of an elbow fracture — consists of 1.51 direct expense rvus and 4.12 indirect expense rvus , resulting in an indirect expense ratio of 73 percent .

depending upon the procedures performed , the indirect expense ratios will vary from physician to physician and will reflect their medical specialty .

what is not clear from hcfa's methodology is whether the indirect expense ratio for each procedure , and therefore each medical specialty , is correct .

the american society of internal medicine and other physician groups that we met with believe that hcfa should develop separate indirect expense ratios for each medical specialty and use these ratios when calculating indirect expense rvus .

hcfa could develop these ratios , they say , on the basis of data contained in the ama's sms survey and would not have to rely upon an assumption .

hcfa has already used the sms survey data in its proposed fee schedule revisions to determine that indirect expense rvus constitute 45 percent of the total pool of practice expense rvus .

hcfa officials told us that they will evaluate this alternative indirect expense assignment methodology before issuing hcfa's next proposed rule .

it is not clear if beneficiary access to care will be adversely affected by medicare's new fee schedule allowances for physician practice expenses .

this will depend upon such factors as the magnitude of the medicare payment reductions experienced by different medical specialties , other health care insurers' use of the fee schedule , and fees paid by other purchasers of physician services .

while beneficiary access to care has remained very good since implementation of the fee schedule in 1992 , the cumulative effect of prior and proposed changes to the fee schedule will need to be monitored to ensure that medicare beneficiaries are not denied access to needed care because of lower payment levels .

as part of its june 1997 proposed rule , hcfa prepared an impact analysis showing the rule's potential effect on physicians' income from medicare , by medical specialty .

generally , medicare payments to surgeons and some specialists would decrease , while payments to generalists would increase .

whether hcfa's final rule will result in similar effects is not known .

because a large number of public and private health care insurers base their payments on medicare's fee schedule , the total impact on physicians' incomes resulting from changes in medicare's fee schedule allowances could be greater than shown in table 1 .

yet , if other health care purchasers pay physicians about the same fees as medicare for the same services , physicians have little or no incentive to provide more care to privately insured patients and less care to medicare patients .

since medicare began paying physicians for their services on the basis of a national fee schedule in 1992 , both hcfa and pprc have monitored indicators of beneficiary access to care to determine if there have been adverse consequences .

hcfa surveys approximately 12,000 beneficiaries annually to gather information on such issues as beneficiary satisfaction with care , difficulties obtaining care , and whether beneficiaries ever had a medical problem but did not seek physician treatment .

pprc's analysis of these data , along with data from other sources , indicates that access for most beneficiaries remains very good and that indicators of access remain essentially unchanged since implementation of the fee schedule .

any decreases observed in selected services do not appear to be related to the fee schedule but rather to other factors , such as changes in medical practices .

some medical specialties that experienced reduced medicare payments after implementation of the fee schedule in 1992 would experience further reductions under hcfa's proposed rule .

for example , between 1992 and 1996 , cardiologists experienced a 9-percent reduction in their medicare payments ; gastroenterologists , an 8-percent reduction ; and ophthalmologists , a 12-percent reduction .

hcfa's proposed rule would result in further reductions of 17 percent , 20 percent , and 11 percent , respectively , once the new practice expense component of the fee schedule is fully implemented in 2002 .

total potential reductions of approximately 25 percent are significant and could affect physician decisions regarding their care of medicare beneficiaries .

to convert rvus into a dollar amount , hcfa uses a conversion factor .

between 1994 and 1997 , there were separate conversion factors for surgical services , primary care services , and other nonsurgical services .

the balanced budget act of 1997 established a single conversion factor for all physician services beginning in january 1998 .

as a result of this change , surgical services experienced a 10.4-percent reduction in medicare payments that are in addition to the proposed practice expense fee schedule changes .

the american college of surgeons reported that this change to a single conversion factor has already resulted in some surgeons concluding that they can no longer treat medicare patients .

however , there is no evidence on the extent to which this is occurring .

it also estimated that between 1997 and 2002 the combined effects of fully implementing the changes in medicare's practice expense payments as proposed by the june 1997 rule and projected declines in the single conversion factor would severely reduce medicare payments for some surgical procedures and could further reduce beneficiary access to care .

for example , medicare payments for a total hip replacement could decrease by 45 percent and by 34 percent for a laparoscopic removal of the gall bladder .

hcfa has made considerable progress in developing new practice expense rvus , but much remains to be done before the new fee schedule payments are implemented in 1999 .

although hcfa worked closely with the medical specialty societies both before and after issuing its proposed rule , considerable controversy remains within the medical community over hcfa's methods for developing direct and indirect expense data .

however , there is no need for hcfa to start over and utilize different methodologies for creating new practice expense rvus ; doing so would needlessly increase costs and further delay implementation of the fee schedule revisions .

hcfa will need to continue working with these societies as it refines its data and methodologies .

hcfa's use of expert panels is an acceptable method to develop direct cost estimates .

not only is this method supported by medical researchers and pprc , but other options for developing these estimates have practical limitations that preclude their use as reasonable alternatives .

however , data generated by the panels represent a starting point , not an end point , for developing the direct expense rvus .

collecting actual data on key procedures from a limited number of physician practices through surveys or on - site reviews during the 3-year phase - in period would enable hcfa to check the reliability of the cpep data and test the assumptions hcfa used for its adjustments .

medical specialty and physician groups need assurances that a process exists for periodically updating the practice expense rvus and identifying and correcting significant problems .

yet , hcfa does not have a plan to refine the practice expense data during or after phase - in of the new fee schedule revision .

while some adjustments to the cpep estimates are necessary to correct for differences in the estimates between panels , hcfa's adjustments to link the estimates of the expert panels raise some questions .

if hcfa plans to rely on a regression - based linking methodology , its regression model will need to be reevaluated as we found significant discrepancies in some cases between the cpep data and the assumptions underlying hcfa's particular model .

in addition , an analysis of the regression suggests a possible bias in the linking factors .

other nonregression approaches hcfa is considering may also be appropriate to deal with variations in the panels' estimates , but we cannot evaluate them until they are more fully defined .

scaling seems to be necessary because of various steps in hcfa's methodology that affected the proportion of rvus allocated to labor , medical supplies , and medical equipment .

without scaling , hcfa would not have an external benchmark to ensure that labor , supplies , and equipment were appropriately apportioned among the total direct practice expense rvus .

at the time of its proposed rule , hcfa appropriately disallowed nearly all of the expenses related to staff who accompany physicians to the hospital since there was no available evidence that these expenses are not already reimbursed by medicare or that this is a widespread , common physician practice .

information supplied by some physician groups indicates , however , that there may have been a shift in hospital and physician practices that medicare has not recognized in its methods for reimbursing nonphysician clinical labor expenses .

hospitals may no longer be providing the same level of nursing support that they did at the time medicare established its current method for paying hospitals for their expenses .

additionally , physicians may now be relying on their own staff to perform work in the hospital , work that medicare recognized as a physician responsibility when establishing the physician work rvus .

hcfa has not examined its assumptions regarding its capping of administrative and clinical labor time estimates to ensure that they are necessary and reasonable .

by including billing and other administrative labor as direct expenses — expenses that accounting standards in the federal sector typically include as indirect expenses — hcfa needlessly made it more difficult for the panels to develop reliable , consistent estimates .

hcfa's use of physician work , direct practice expense , and malpractice expense rvus is an acceptable option for assigning indirect expenses to procedures since these factors likely reflect the drivers of indirect expenses .

however , there are other alternatives .

for example , hcfa could use specialty - specific indirect expense ratios , based on the sms survey data .

this would be more clearly consistent with the balanced budget act of 1997 requirement that hcfa utilize actual data for its key assumptions .

despite its having made significant adjustments to the cpep estimates and its use of various methodologies to develop the new practice expense rvus , hcfa has done little in the way of performing sensitivity analyses to determine which of its data adjustments and methodologies have the greatest effects on rankings and the rvus .

having such information would enable hcfa to target its refinement efforts on those areas most susceptible to weaknesses in the data or methodologies .

while it is unreasonable to expect hcfa to conduct such analyses before it issues its may 1998 proposed rule , hcfa has time between the rule's issuance and implementation of the fee schedule revisions in 1999 , as well as early in the initial phase - in period , to conduct sensitivity analyses , gather needed data , and make necessary adjustments to the rvus .

the potential impact of the proposed new fee schedule allowances for physician practice expenses on beneficiary access to care is unknown at this time .

however , the combined impact of the proposed and prior fee schedule changes on physicians' incomes will affect some medical specialties more than others .

therefore , indicators of beneficiary access to care that focus on the medical specialties most adversely affected by the cumulative changes in medicare's fee schedule allowances will require continued monitoring .

we recommend that the administrator of hcfa take the following actions: use sensitivity analyses to test the effects of ( 1 ) the limits hcfa placed on the panels' estimates of clinical and administrative labor and ( 2 ) hcfa's assumptions about equipment utilization .

where hcfa's adjustments or assumptions substantially alter the rankings and rvus of specific procedures , hcfa should collect additional data to assess the validity of its adjustments and assumptions , focusing on the procedures most affected .

evaluate ( 1 ) classifying the administrative labor associated with billing and other administrative expenses as indirect expenses , ( 2 ) alternative methods for assigning indirect expenses , and ( 3 ) alternative specifications of the regression model used to link the panels' estimates .

since these three aspects of hcfa's methodology are interrelated , hcfa should determine how changes in one aspect of the methodology , such as reclassifying some labor from direct to indirect expenses , affect other aspects of the methodology , such as the specification of the regression model to link the panels' estimates of administrative labor and the method used to allocate indirect expenses .

determine whether changes in hospital staffing patterns and physicians' use of their clinical staff in hospital settings warrant adjustments between medicare reimbursements to hospitals and physicians .

similarly , hcfa should determine whether physicians have shifted tasks to nonphysician clinical staff in a way that warrants reexamining the physician work rvus .

work with physician groups and the ama to develop a process for collecting data from physician practices as a cross - check on the calculated practice expense rvus , and to periodically refine and update the rvus .

monitor indicators of beneficiary access to care , focusing on those services with the greatest cumulative reductions in medicare fee schedule allowances , and consider any access problems when making refinements to the practice expense rvus .

we provided a draft of this report for comment to hcfa officials .

we also gave copies of the draft to representatives of medical societies , physician groups , a medical group we contacted during our work , and medpac .

the following summarizes the comments and our responses .

hcfa officials agreed with our analysis regarding the use of cpeps for developing direct practice expense data and the use of an allocation formula to assign indirect expenses to individual procedures .

regarding our recommendations that hcfa collect and analyze additional data to test the validity for its adjustments and assumptions , they asked that we clarify the time frames in which we expect hcfa to conduct this work .

we provided this clarification in the report .

hcfa officials explained that they plan to analyze options on how to treat billing and other administrative expenses and that it would be premature to make a decision on this issue before they have analyzed their options .

we agree that hcfa should evaluate available options before making a final decision , and we therefore modified our recommendation on this issue .

hcfa officials disagreed with some of our discussions regarding their linking and scaling methodologies .

regarding hcfa's linking methodology , hcfa officials were concerned that the report's discussion was overly negative .

they believed that the report ignored the distinction between ideal data and real - world data , which typically deviate from the ideal .

specifically , hcfa officials stated that the linking process works best when the redundant codes have similar ranks across cpeps and when the relative spacing among the redundant codes across cpeps is the same .

they also emphasized , however , that not all cpep data will fit neatly into the assumptions or patterns that underlie their regression specification .

nevertheless , the officials said they recognize that their model would appear more appropriate if the cpep data conformed more closely with these patterns .

we agree that there is randomness in sample data .

random variation will cause predictions from even the best - specified regression model to deviate from the data on which the model is estimated .

nonetheless , we are not convinced that hcfa's linking model is free of statistical problems .

we did not expect to see such substantial and often striking deviations from the assumptions or patterns that hcfa staff had told us were the basis for their model .

this point holds , especially with regard to deviations of the ordinal ranks from the expected pattern .

although it is possible that these deviations exclusively reflect the randomness in the estimates of the various cpep panels , they may also reflect systematic factors that , omitted from hcfa's regression analysis , could make its linking factors too high or too low .

in any case , the observed discrepancies between the cpep data and the expected patterns suggest potential limitations of linking as well as the need for further analysis of the implications of these discrepancies for hcfa's statistical model .

moreover , analysis of the hcfa regression's residuals suggests that the linking factors estimated by the regression may be statistically biased ; that is , even if different samples of cpep data were used , the estimated linking factors drawn from the same model would deviate from the true coefficients .

specifically , the analysis of the residuals indicates that the broad types of procedure codes ( for example , invasive procedures versus lab tests ) reviewed by a cpep affect the size and sign ( positive or negative ) of the residual associated with a procedure code .

consequently , the mix of procedure codes reviewed by a cpep appears to affect the cpep's estimates .

since hcfa's model does not account for this effect , the estimated coefficients drawn from hcfa's model may be statistically biased .

despite these apparent difficulties , a statistical model is in principle an acceptable approach to linking .

however , we believe that hcfa should evaluate the issues highlighted by the residual analysis and revise the regression model as necessary .

hcfa officials did not believe that the draft provided a balanced discussion of its scaling methodology and provided new information to support their use of this methodology .

we included this information to clarify our discussion of scaling and concluded that scaling seems to be appropriate .

comments from these groups and our responses are provided below ; separate discussions are presented for each major section of our report .

regarding hcfa's approach to developing direct expense estimates , many of the representatives , including those from medpac and the american society of internal medicine , supported our conclusion that the expert panel process represents an acceptable method .

the ama agreed with us that starting data collection over would needlessly increase costs and further delay implementation .

both the ama and mgma support the need for hcfa to collect limited , additional data as a cross - check on the cpep data .

but mgma believed that , for developing direct expense estimates , surveys would be better than hcfa's informal , subjective method of convening panels .

mgma and the american college of surgeons questioned both the way hcfa convened and conducted its panels and the validity of the data they generated .

we continue to consider the expert panel process to be an acceptable method and believe that the limitations of surveys of physicians and their practices — low response rates , potential response biases , and answers based on the judgments of the respondents — preclude their use as hcfa's primary data gathering approach .

as we note in the report , however , data from surveys could help hcfa evaluate and , if necessary , modify its panel data .

we cannot comment on how well the panels were conducted , because hcfa convened them months before we began our work .

nonetheless , the panel - generated data represent only the first phase of hcfa's development of practice expense rvus .

that is why we recommend that hcfa validate its data by , for example , collecting actual data from physician practices and testing the sensitivity of the results to each of its key adjustments to the panel data .

the phase - in period authorized in law gives hcfa significant time to validate the data before the fee schedule revisions are fully effective .

regarding hcfa's linking and scaling adjustments , the representatives generally agreed that the cpep data need to be adjusted for differences between panels' cost estimates .

for example , a representative from the american academy of family physicians emphasized that the academy would consider hcfa's use of “raw” cpep data to be unacceptable .

the ama also favored adjustment , but not necessarily by using hcfa's linking method .

the ama preferred more targeted adjustments to the cpep data to improve their consistency .

however , representatives from the american college of surgeons disagreed with our conclusion that a linking adjustment is needed as they believe that the data are so flawed that after - the - fact manipulations , such as linking , cannot correct them .

we continue to believe in the necessity of adjusting the cpep data , given the substantial , often striking disparities in the estimates made by two or more panels for the same codes .

a linking regression is one way to do this .

hcfa is exploring alternative methods , but without more specifics , we cannot comment on them at this time .

representatives , other than those from medpac , had few comments on hcfa's scaling methodology .

medpac staff support scaling if done correctly , but they were concerned about hcfa's implementation of this methodology because they believe the raw sms data are not directly comparable with the cpep data .

hcfa adjusted the cpep data by removing the labor time estimates associated with staff that accompany physicians to the hospital , and medpac staff believe hcfa should remove such data from the sms data so that sms and cpep data are comparable .

hcfa believes , however , that physicians' bringing staff to the hospital is a relatively infrequent practice and has only a minor impact on the sms data .

we cannot comment on this issue , since information on it was unavailable when we conducted our work .

with respect to hcfa's other adjustments to the cpep data , the ama said that it would be particularly useful for hcfa to collect data on administrative and equipment costs from group practices , firms that provide billing and other administrative services to physician practices , and associations such as mgma .

we support hcfa's collecting additional data about its labor time caps and equipment utilization rates if its sensitivity analyses show that these adjustments and assumptions substantially alter the rankings and rvus of particular procedures .

representatives of the practice expense coalition and the american college of surgeons disagreed with our view that hcfa appropriately disallowed nearly all the expenses associated with staff that accompany physicians to the hospital .

the practice expense coalition contends that this represents a real , unreimbursed cost to physicians and that hospitals , in an effort to cut costs , are not paying for these services .

it also said that quality of patient care could suffer if hospitals are not forced to change their behavior or if other parts of the medicare program fail to reimburse physicians for these costs .

we continue to believe that , according to medicare policy , hcfa appropriately disallowed these expenses at the time of its proposed rule .

however , the information supplied to hcfa by some physician groups indicates that there may have been a shift in hospital and physician practices affecting medicare reimbursement policy for these expenses .

therefore , we modified our report to recommend that hcfa determine whether medicare needs to revise how it pays for these expenses .

regarding assigning indirect expenses to procedures , representatives of the different groups and medical societies generally believed that hcfa should evaluate using specialty - specific indirect cost ratios as opposed to its current assignment method .

ama representatives said that rather than using indirect expense ratios , they would prefer that hcfa assign indirect expenses to procedures on the basis of specialty - specific data derived from the sms survey .

we agree that hcfa should evaluate alternative methods for assigning indirect expenses , because there is no one best way to do so .

but , as noted in our report , we also believe that the method contained in hcfa's proposed rule is acceptable .

some representatives believed that hcfa should consider treating billing and other administrative labor time as indirect expenses rather than as direct expenses .

they believed that this is one of several possible options hcfa should study before making a final decision .

for example , mgma proposed that hcfa convene a separate expert panel composed of medical managerial and billing personnel to consider what administrative expenses can be defined as direct as opposed to indirect expenses .

the practice expense coalition cautioned that shifting billing and other administrative expenses to the indirect expense category could have serious implications for physician reimbursement unless accompanied by other corrections .

additionally , one representative noted that the cross - specialty panel convened by hcfa did not vote unanimously to treat these expenses as indirect expenses .

while representatitves of the american society of internal medicine supported the inclusion of billing expenses as indirect expenses , they believed these expenses should be assigned using a methodology that differs from how the other indirect expenses are assigned under hcfa's formula .

specifically , they believed that the billing expenses associated with each procedure are not reflective of physician work values , which are a primary determinant of other indirect expenses in hcfa's current formula .

on the basis of these comments and those expressed by hcfa , we modified slightly our recommendation on this issue .

concerning changes in beneficiary access to care , representatives of the different groups and medical societies supported our recommendation that hcfa monitor indicators of beneficiary access to care following implementation of the fee schedule revisions .

representatives from the american academy of family physicians said that other changes in medicare's fee schedule may also affect access and questioned whether hcfa can isolate changes in practice patterns that are attributable only to the practice expense fee revisions .

the american college of surgeons also commented that other changes in medicare's fee schedule payments will have especially serious consequences on medicare's payments for surgical procedures that could reduce beneficiary access to care and adversely affect faculty practice plans of teaching institutions .

the ama representatives said that evaluating access to care is only one part of analyzing the impact of changes in the fee schedule .

they said that while doctors may continue to treat patients , they may cut costs in other areas , such as salaries , equipment purchases , and satellite offices .

thus , quality of care may be adversely affected even if access remains generally good .

the practice expense coalition said that the fee schedule revisions may cause other changes in medical practice .

for example , specialists may no longer choose to perform certain medical procedures , resulting in only generalists performing such procedures and potentially affecting quality of care .

in response to the comments on access to care , we added additional information in our report on the potential effects of the proposed fee schedule revisions .

as agreed with your offices , we are sending copies of this report to the secretary of hhs , the administrator of hcfa , interested congressional committees , physicians' organizations , and other interested parties .

we will also make copies available to others upon request .

this report was prepared by robert dee , frank putallaz , suzanne rubins , and michelle st. pierre , with assistance from jonathan ratner .

please call me at ( 202 ) 512-7114 or william reis , assistant director , at ( 617 ) 565-7488 if you have any questions .

efforts to reform medicare physician payments began in the 1980s , prompted by concerns that the existing methods of physician reimbursement were flawed , that program costs were increasing , and that beneficiary access to care required monitoring .

medicare spending for physician expenses per beneficiary had been growing at almost twice the rate of the gross national product .

at the time , medicare reimbursed physicians through the “customary , prevailing , and reasonable charge” system .

this payment method had been criticized as inflationary and inequitable because it resulted in widely varying fees for the same service .

concerns were also raised that the payment levels favored surgical services at the expense of primary care services , resulting in distorted financial incentives .

limits on actual charges and a series of freezes and reductions in payment levels for particular services made the system increasingly complex .

the consolidated omnibus budget reconciliation act of 1985 required the secretary of the department of health and human services ( hhs ) to study and report to the congress on a resource - based , relative - value scale system for reimbursing physicians for their services .

such a system , as opposed to a charge - or cost - based payment system , ranks services on a common scale according to the resources expended in providing them .

payment for a service is dependent upon its ranking ; services with a high ranking receive greater payment than those with a low ranking .

in its 1989 report to the congress , the physician payment review commission ( pprc ) recommended that a resource - based , relative - value scale be adopted .

the omnibus buget reconciliation act of 1989 established a uniform national fee schedule with three relative - value components — physician work , practice expense , and malpractice expense — and required that the schedule be phased in over 5 years beginning in 1992 .

implementation was to be accomplished in a budget - neutral manner .

also included in the legislation were geographic adjustment factors for each component of the fee schedule , elimination of specialty - specific payment differentials for providing the same service , a process for calculating the annual update for the conversion factor that converts relative values into payment rates , and establishment of volume performance standards to track changes in the volume or intensity of medicare services .

the 1989 legislation relied upon the extensive work done by health care financing administration ( hcfa ) contractors at the harvard school of public health that responded to earlier legislation requiring development of a resource - based physician work component .

methods for calculating resource - based relative values for practice and malpractice expenses were not available at the time .

the development of resource - based relative value units ( rvu ) for the physician work component of the fee schedule took about 7 years to complete .

building on preliminary studies conducted earlier that decade , harvard researchers undertook a complex , multiphased process with the cooperation of the american medical association ( ama ) and the assistance of about 100 physicians organized into technical consulting groups .

these groups developed vignettes to describe standard scenarios for delivering services that were included in the ama's physicians' current procedural terminology ( cpt ) .

a national survey was conducted in which physicians were asked to rank services on the basis of four standard elements: ( 1 ) physician time , ( 2 ) mental effort and judgment , ( 3 ) technical skill and physical effort , and ( 4 ) stress due to risk of harm to the patient .

the researchers reported a high level of consistency in how physicians in the same specialty ranked the relative work required for services they performed .

cross - specialty panels drawn from the physician consulting groups chose procedure codes that represented equivalent or similar work within different specialties .

those codes then served as the basis for a statistical process to link all the codes ranked by each specialty along a common scale .

physician work rvus for about 800 procedure codes were developed through the survey process .

rvus for the remaining codes were extrapolated from these 800 codes .

for extrapolation , codes were assigned to families of codes and the relative work values were determined by small groups of physicians who had participated in the previous development stages .

before phase - in of the physician work rvus could begin in 1992 , hcfa had to create a process to both refine the existing values and create values for new procedure codes in the future .

hcfa's early refinement process involved using carrier medical directors to revise some of the newly created work rvus and to assign rvus to some low - volume codes and other codes not included in the harvard study .

today , a different refinement process is in place that includes a multispecialty committee known as the ama / specialty society relative value update committee ( ruc ) .

ruc , created in 1991 , makes recommendations to hcfa on the relative values to be assigned to new or revised procedure codes .

hcfa then convenes a meeting of selected carrier medical directors to review ruc's recommendations .

currently , hcfa accepts most of these recommendations .

according to pprc and ama representatives , the ruc process is supported by most physicians and has increased the medical community's confidence in the physician work rvus .

unlike physician work , the practice expense component of the fee schedule is still calculated according to a charge - based system set up in 1989 .

two main data sources are used: medicare claims and allowed charge data from 1991 , and information on the percentage of revenue expended on practice expenses from national surveys of physicians , specialists , and nonphysician practitioners reimbursed under the medicare fee schedule .

the rvus for practice expenses are computed as follows: 1 .

using national survey data , determine the average proportion of revenue devoted to practice expenses for physicians overall , for various specialties , and for the nonphysician practitioners paid under the medicare fee schedule .

2 .

using 1991 medicare allowed charges , multiply the allowed charge for each procedure code by the average percentage of revenue devoted to practice costs for the specialty that performs that procedure .

example: for a service with a 1991 allowed charge of $100 performed only by family practitioners ( whose practice expense - to - revenue proportion is 52.2 percent ) , the calculation would be as follows: $100 x 0.522 = 52 ( initial dollar ) rvus3 .

for procedures performed by more than one specialty , multiply the practice expense proportion by the frequency each specialty performs that service , then add the product and multiply by the 1991 allowed amount .

example: for a service with a 1991 allowed charge of $100 performed 70 percent of the time by family practitioners and 30 percent of the time by internists ( whose practice expense - to - revenue proportion is 46.4 percent ) , the calculation would be as follows: ( ( 0.522 x .70 ) + ( 0.464 x .30 ) ) x $100 = 50.5 ( initial dollar ) rvus malpractice rvus are computed under a similar statutory formula .

before the physician work , practice expense , and malpractice expense rvus can be converted to dollars , they are adjusted by hcfa .

specifically , hcfa computes a geographic adjustment factor for each of the three types of rvus ; each factor is designed to reflect variation in value or cost of the relevant component from the national average within fee schedule areas established by hcfa .

after the three rvu components for each service are multiplied by their respective geographic adjustment factors and combined , the uniform national conversion factor is applied .

this factor converts each total rvu into a dollar amount representing medicare's allowed charge for each service , including the 80 percent reimbursed to physicians and the 20 percent beneficiary coinsurance .

hcfa must compute the conversion factor in a manner that ensures budget neutrality: that is , the total medicare expenditures for physicians' services must not differ by more than $20 million from what the expenditures would have been if the current fee schedule had not been adopted .

the conversion factor is determined annually so that total expected medicare expenditures for physician services meet the performance standard ( the target rate of increase in expenditures ) established by the congress or by formulas in the original fee schedule legislation .

american academy of family physicians american college of emergency physicians american college of rheumatology american college of surgeons american hospital association american medical association american osteopathic association american society of internal medicine the cleveland clinic foundation the mayo foundation practice expense coalition ( which represents 43 medical specialty organizations , including the american college of cardiology , american academy of ophthalmology , and american society of general surgeons ) .

the development of an rvu system requires that all services be directly comparable on a common scale .

with different panels of physicians evaluating different codes , hcfa was concerned about whether the labor time estimates developed by its clinical practice expense panels ( cpep ) were , in fact , directly comparable .

in other words , if some cpeps overestimated labor times while others underestimated labor times , it might be necessary to normalize those estimates to make them comparable and ensure that the relative rankings among cpeps would be correct .

to assess the consistency of data from different cpeps , hcfa assigned several hundred codes to more than one cpep and referred to these as redundant codes .

hcfa found that the panel estimates for a redundant code often differed .

for example , for removal of the thyroid ( cpt code 60270 ) , the general surgery and otolaryngology cpeps differed in their estimates of total administrative labor time by 116 minutes — 375 minutes versus 259 minutes .

similarly , their estimates of the total clinical labor time differed by 109 minutes — 537 minutes versus 646 minutes .

in another example — the partial removal of an esophagus ( cpt code 43117 ) — the general surgery and cardiothoracic cpeps differed in their estimates of total administrative labor time by 90 minutes — 375 minutes versus 465 minutes .

the two cpeps' estimates of total clinical labor time required for this procedure differed by 950 minutes — 697 minutes versus 1,647 minutes .

hcfa staff believe that some cpeps had higher labor estimates than others because they included physician work in their estimates for practice expenses or because they double counted some activities that staff may do simultaneously .

while recognizing these differences in the labor estimates , hcfa concluded that the relationship among codes was generally constant from panel to panel .

specifically , after observing the cpeps and reviewing different cpeps' labor estimates for redundant codes , hcfa decided that , despite differences in the absolute labor time estimates for a given code , the relative rankings of redundant codes among cpeps were generally similar .

that is , the relationships or ratios between the estimates for pairs of codes were generally similar .

for instance , if two cpeps evaluated codes a and b , the first cpep's labor estimates might always be twice those of the second cpep ; for example , 70 minutes versus 35 minutes for code a and 120 minutes versus 60 minutes for code b .

this means that any given cpep's estimates for a set of codes would differ from another cpep's estimates by a generally constant percentage .

hcfa utilized a statistical approach called regression that used the redundant codes to normalize — or “link” — the labor estimates of all the cpeps to make them comparable .

a linking regression was also used during development of the physician work rvus .

researchers at the harvard school of public health obtained physician work estimates for different codes from panels of physicians in different medical specialties and used a similar linking regression to normalize the physician work estimates .

in the practice expense linking methodology , the regression analysis produced two adjustment factors for each cpep — one for clinical labor estimates and a second for administrative labor estimates .

for example , all of the clinical labor estimates for the ophthalmology cpep were reduced by multiplying them by an adjustment factor of 0.73 , while all the administrative labor estimates were reduced by multiplying them by a factor of 0.46 .

similarly , the clinical and administrative labor estimates for the obstetrics and gynecology cpep were reduced by multiplying them by factors of 0.88 and 0.51 , respectively .

generally , the adjustment factors produced larger reductions in the administrative labor estimates than in the clinical labor estimates .

for instance , the administrative labor estimates for cpeps 8 and 15 were reduced by 76 and 80 percent , respectively .

see table iii.1 for a listing of the linking adjustors .

the fact that the linking adjustments reduced the estimates for almost all cpeps is not inherent to this methodology but rather results from hcfa's choice of cpep 7 as the “reference panel.” had a different panel , say , cpep 12 , been chosen , the regression analysis would have produced factors that raised some cpeps' estimates and lowered others .

nonetheless , the relative relationships between these adjusted estimates would be the same as with the factors in table iii.1 .

additionally , using a different cpep as a reference panel would not have resulted in different rvus for any procedure under this methodology .

hcfa's linking adjustments significantly altered the relative ranking of codes among cpeps .

this follows from the large reductions in cost estimates for some cpeps after the linking adjustment was applied .

this change in ranking is illustrated in the following example .

on the basis of original cpep data , hcfa calculated the nonphysician labor expenses for application of a body cast ( code 29035 ) performed in the office at $71.52 and the nonphysician labor expenses for a vaginal hysterectomy ( code 58260 ) performed in a hospital at $56.21 .

without any adjustments , this means that medicare would pay about 27 percent more in nonphysician labor expenses for a full - body cast than it would for a vaginal hysterectomy .

however , as shown in table iii.2 , the labor expenses for these two procedures are about equal after hcfa applied its linking adjustment factors .

given some of the large differences in labor estimates for redundant codes observed among different cpeps , some adjustments to the cpep data are warranted to ensure they are comparable on a common scale .

a linking methodology based on a regression analysis for developing physician work rvus has been accepted by independent researchers , albeit with suggestions for improvements and alternative methodologies .

such a linking regression may be appropriate to use in developing adjustments to the cpep data for practice expense rvus .

however , the appropriateness of hcfa's selected linking methodology is related to a number of features about the data , for example , that cpeps generally ranked redundant codes in the same order .

our preliminary review of hcfa's methodology indicates that some of these assumptions are not true for all cpeps .

the remainder of this section compares the actual cpep data with the assumptions underlying hcfa's regression model .

the more the pattern of the cpep data correspond to the actual pattern , the more appropriate hcfa's regression model is likely to be .

some discrepancies are to be expected because of random variability in sample data .

however , our analysis of the cpep data indicates that portions of the panels' data differ considerably from the assumptions hcfa used in developing its regression model and that hcfa needs to evaluate alternative specifications to its regression model .

1 .

hcfa's linking methodology relies on the cpeps' ranking the redundant codes in generally the same order .

a preliminary review of the labor estimates for redundant codes indicates that this consistent ranking of the codes may not be true for all of the cpeps .

for some pairs of cpeps , we calculated correlation coefficients , which measure how strongly two cpeps' rankings of redundant codes are correlated .

the closer the correlation coefficient is to 1 , the more highly correlated the cpep rankings are .

table iii.3 shows the correlation coefficients for 18 pairs of cpeps .

8 + 10 ( ai ) 1 + 3 ( ai ) 12 + 13 ( co ) 5 + 9 ( co ) 8 + 10 ( ao ) 3 + 15 ( co ) 3 + 15 ( ao ) 7 + 10 ( ai ) 12 + 13 ( ao ) 8 + 12 ( ao ) 2 + 8 ( ao ) 1 + 8 ( ai ) 8 + 12 ( co ) 2 + 8 ( co ) 7 + 13 ( ai ) 10 + 12 ( ao ) 3 + 7 ( ai ) 6 + 13 ( ao ) the results of the correlation analysis for these 18 pairs of cpeps indicate that some panels ranked redundant codes very differently from other panels and that hcfa's assumption about consistent ranking is questionable .

overall , few of the 18 cpep pairs' rankings were strongly and positively correlated .

three of the cpep pairs had negative correlations , which means that codes ranked high by one cpep were ranked low by the other cpep — exactly the opposite of hcfa's assumption .

of the remaining cpep pairs , we judged the four with coefficients of 0.32 or less to be weakly correlated .

six other cpep pairs with coefficients of between 0.46 and 0.79 could be considered modestly correlated .

only five cpep pairs had coefficients of over 0.80 , which we would consider moderately to highly correlated .

while we did not develop correlation coefficients for all of the possible cpep pairs , the results from these 18 pairs contradict hcfa's assumption that the cpeps generally ranked redundant codes in the same order .

2 .

in developing the linking regression , hcfa also relies on the cpeps' having generally similar relative ranks for the redundant codes .

in other words , the relationships or ratios between the codes were assumed to be similar .

for example , if two cpeps ranked codes a and b , the estimates of the absolute time for each code might be different .

nonetheless , the two codes would have the same relative rank if the labor estimate for code a was about twice as high as that for code b for both cpeps .

if this similarity in ranking between cpeps were to hold for most codes , then the labor estimates of the two cpeps would generally differ by a constant percentage .

hcfa staff told us that they did a quick review of the redundant codes and observed , for example , that the estimates for redundant codes from one cpep were usually about 16 percent greater than the estimates from a second cpep .

however , because of time constraints and other factors , hcfa staff did not conduct a formal , comprehensive analysis to confirm that this relationship was true across all cpeps and all redundant codes .

if labor time estimates for redundant codes generally differ between cpeps by a constant percentage , then the ratios of the redundant estimates should be similar .

however , our comparison of the ratios for redundant codes for selected cpeps shows considerable variation .

for instance , cpeps 3 and 15 examined 81 redundant codes for their clinical , out - of - office estimates .

the ratios of cpep 3 to cpep 15's clinical labor time estimates were not constant over the 81 codes .

instead , these ratios ranged from 0.71 to 2.48 ( see table iii.4 ) .

not only is this a threefold difference in the ratios , but in some cases the labor estimates from cpep 3 are higher than those from cpep 15 , and in some cases they are lower .

this shift from ratios exceeding 1 to ratios of less than 1 indicates a lack of consistency in the relationship between the estimates of these two cpeps .

if the differences between cpeps are not consistent , then adjusting all estimates within a cpep by a fixed amount , as hcfa's linking regression does , may not be appropriate .

cpep 3 — orthopedics ( minutes ) cpep 15 — neurosurgery ( minutes ) we note that hcfa's linking regressions are expressed in terms of the natural logarithm of the cpep estimates , while our analysis is based on the actual cpep estimates .

a natural logarithm , or log , is a way of expressing a number as an exponent of a common base .

for our purposes , this difference has no effect .

the logarithmic transformation simply compresses the range of variation , when the ratio of the estimates is compared to the ratio of the log of those estimates .

the properties we focus on — ranking , ratios being greater than or less than one , and so on — do not depend on whether an estimate is expressed as 449 minutes or , in natural logs , as 6.11 .

in hcfa's regression equation , the coefficient on the cpep variable is critical , because hcfa uses that estimated coefficient as a linking adjustment factor .

under certain circumstances , statistical estimates can be inaccurate in a way statisticians term “biased.” a correctly specified regression equation can yield unbiased estimates of its coefficients .

these estimates then accurately reflect the average effect of an explanatory variable ( in this case , the variable denoting the cpep making the cost estimate ) on the dependent variable ( in this case , the cpep labor cost estimates ) .

while the predicted values ( of the dependent variable ) from any regression will differ from the actual values because of random variation caused by sampling error , differences between predicted and actual values should not be systematic — that is , correlated with factors not included in the regression .

however , when a factor omitted from the regression model is correlated with an explanatory factor that the regression does include , the estimated regression coefficients are biased .

the omission of a factor from hcfa's linking regression that is correlated with both the dependent variable and the cpep variable would mean that the estimated linking factors were biased .

in hcfa's linking regression , the cpep labor estimates should differ only by some constant percentage that reflects differences in cpeps' implicit scales , and other factors should not contribute to differences .

hcfa recently contracted with an external researcher to conduct a preliminary analysis of the residuals associated with the regression equation .

the researcher found that other factors may influence differences among cpep estimates .

because regression equations are based on a sample of data , their predictions are generally less than completely accurate , and their residuals signal the degree of accuracy and other properties of the regression equation .

for the regression estimates to be unbiased and have other desirable properties , a plot of the residuals against the dependent variable ( in this case , the natural log of the cpep labor time estimates multiplied by wage rates ) should be randomly distributed about the horizontal axis , which represents a residual equal to zero .

such a random pattern indicates that the actual data do not deviate from the regression model in any systematic way .

our review of the residual plots for hcfa's linking regressions indicates that , for some cpeps , the residuals corresponding to the services evaluated by the cpep are systematically related to the broad category within which a specific procedure code is found: a hernia repair belongs to the “invasive procedure” category , while a mid - level office visit belongs to the “evaluation and management” category .

for example , with respect to the clinical labor regression , when the residuals for cpep 8 ( general surgery ) are analyzed , the residuals for evaluation and management codes tend to be positive but those for invasive procedures tend to be negative .

this suggests that having fewer evaluation and management codes among the redundant codes would probably increase cpep 8's linking adjustor for clinical labor .

by contrast , the residuals for cpep 8's administrative labor estimates display the opposite pattern — more evaluation and management redundant codes would likely increase this cpep's linking factor for administrative labor .

the residuals for all cpeps did not exhibit these differences .

however , as the researcher points out , it appears that for some cpeps , the mix of redundant codes by category of service influenced the estimated linking factors .

consequently , selection of a different set of redundant codes would likely lead to different values for the linking factors .

the extent to which these values would differ from those that hcfa has published is unknown .

in addition to differences in cpep estimates related to the category of service , another factor may be the rating scales the cpeps explicitly used .

according to the researcher who conducted the residuals analysis , some differences among cpeps' estimates might indicate that some cpeps' rating scales were , in effect , more compressed , while other cpeps evaluated codes using a scale with a wider spread .

for example , in the regression for clinical labor costs , the residuals for invasive redundant codes for cpep 12 ( cardiothoracic and vascular surgery ) increase with the size of the dependent variable ( natural log of clinical labor costs ) .

this association between residuals and labor costs suggests that , for invasive procedures , this cpep underestimated costs for redundant codes whose estimated levels of clinical labor are small but overestimated costs for codes whose estimates of clinical labor are large ( relative to other cpeps ) .

that is , this cpep's scale is stretched out compared with those of other cpeps .

such associations between residuals and the dependent variable constitute a problem in the linking regression as currently specified .

in estimating and using its regression model , hcfa assumed that the difference between cpeps' estimates is a constant percentage for any cpep .

if , however , some cpeps rated the same services differently , depending on whether the service had high labor input or low labor input , then the cpeps' relative rankings for redundant codes may not be similar .

consequently , a linking process that adjusts all estimates within a cpep by a constant factor may not be appropriate .

although further analysis to replicate these preliminary findings would be desirable , alternate specifications of the regression approach to linking could mitigate the problems discussed above and could improve the accuracy and credibility of the linkage adjustment factors .

specifically , a more appropriate linking regression model would take into account potential differences in cpeps' ratings related to the category of service ( for example , invasive procedures ) and the level of estimated labor input ( low versus high ) .

in addition , it might account for some of the deviations we noted between the cpep data and the patterns identified by hcfa .

after it linked the cpep estimates , hcfa conducted a second series of data adjustments referred to as scaling .

in the aggregate , the cpeps' estimates imply that labor , medical supplies , and medical equipment constitute 60 percent , 17 percent , and 23 percent , respectively , of all direct expenses .

hcfa compared these estimates with the ama's socioeconomic monitoring system ( sms ) survey data — one of the few sources of national data on practice expenses — and found that they differed .

the sms data attributed significantly higher proportions of practice expense to labor and less to equipment .

according to the 1996 sms data , labor , medical supplies , and medical equipment represented 73 percent , 18 percent , and 9 percent , respectively , of total direct expenses .

to match the cpep percentages with the sms percentages , hcfa inflated cpep labor expenses for each code by 21 percent , inflated cpep medical supply expenses by 6 percent , and deflated cpep equipment expenses by 61 percent .

hcfa staff believed that scaling was necessary to ensure that the proportions of practice expense rvus devoted to labor , supplies , and equipment were consistent with an external benchmark .

for example , without scaling , hcfa would have no means to ensure that its total labor expense estimates , as adjusted by linking and other steps in hcfa's methodology , were appropriate .

the amount of the total labor expenses depends upon the cpep chosen as the reference panel because the labor expense estimates from all cpeps are linked to the reference panel .

if a different cpep had been chosen as the reference panel , total labor expenses might have been much larger .

scaling thus enabled hcfa to use any cpep as the reference panel and still arrive at the appropriate amount of total labor expenses .

hcfa officials also told us that scaling was necessary because of their concerns regarding pricing of labor , supplies , and equipment .

for example , hcfa used list prices as its basis for pricing both supplies and equipment , but officials believe that physicians and physician practices typically pay less than list price for these items .

as a result , total practice expenses for supplies and equipment were likely overstated .

scaling , however , eliminated the effects of using inflated pricing estimates .

hcfa officials also said that they needed to use scaling because the cpeps did not provide them with data on equipment utilization rates , thus requiring hcfa to make assumptions regarding how often an item of equipment is used within physician practices .

utilization rates , in turn , affect how much of medicare's practice expense payments relate to equipment expenses .

scaling provided hcfa with a cap on the total amount of practice expenses devoted to equipment that was not dependent upon the equipment utilization rate assumptions hcfa used .

table iv.1 illustrates the impact of the scaling adjustments by using a hypothetical example .

before scaling , both codes a and b have $100 of direct expenses , so they would receive the same number of direct expense rvus .

after scaling , however , code a's direct expenses increase to $109 , while code b's decrease to $85 .

these changes reflect code a's higher labor expenses and lower equipment expenses compared with those of code b .

because of scaling , code a now receives 1.3 times as many direct practice expense rvus as code b .

the first copy of each gao report and testimony is free .

additional copies are $2 each .

orders should be sent to the following address , accompanied by a check or money order made out to the superintendent of documents , when necessary .

visa and mastercard credit cards are accepted , also .

orders for 100 or more copies to be mailed to a single address are discounted 25 percent .

u.s. general accounting office p.o .

box 37050 washington , dc 20013 room 1100 700 4th st. nw ( corner of 4th and g sts .

nw ) u.s. general accounting office washington , dc orders may also be placed by calling ( 202 ) 512-6000 or by using fax number ( 202 ) 512-6061 , or tdd ( 202 ) 512-2537 .

each day , gao issues a list of newly available reports and testimony .

to receive facsimile copies of the daily list or any list from the past 30 days , please call ( 202 ) 512-6000 using a touchtone phone .

a recorded menu will provide information on how to obtain these lists .

