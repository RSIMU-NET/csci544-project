crime and violence perpetrated by transnational criminal organizations continue to raise security concerns on both sides of the u.s - mexico border .

a 2019 congressional research service report estimates that more than 150,000 people have been killed in mexico as a result of organized crime since 2006 .

u.s. drug demand , bulk cash smuggling , and weapons smuggling from the united states have fueled this violence .

furthermore , fighting among criminal groups in mexico intensified after the extradition of drug kingpin joaquin “el chapo” guzman in 2017 prompted battles between rival cartels to supply rising u.s. demand for heroin and other opioids .

in october 2007 , the united states and mexico created the mérida initiative and , in doing so , committed to working together to address crime and violence , and enhance the rule of law in mexico .

through this bilateral partnership , the united states has funded mérida initiative projects broadly related to the four pillars of the initiative — combating transnational criminal organizations , rule of law and human rights , border security , and building strong and resilient communities — with the goals of mitigating the effects of the drug trade on the united states and reducing violence in mexico .

since fiscal year 2008 , the united states has allocated about $3 billion for assistance for mexico under the mérida initiative .

you asked us to review issues related to mérida initiative implementation and objectives .

this report ( 1 ) examines the extent to which the department of state ( state ) , bureau of international narcotics and law enforcement affairs ( state / inl ) follows key practices in monitoring mérida initiative projects and tracks project performance data against established measures ; ( 2 ) examines the extent to which the united states agency for international development ( usaid ) follows key practices in monitoring mérida initiative projects and tracks project performance data against established measures ; and ( 3 ) describes how state / inl uses data from the government of mexico to help monitor the implementation of mérida initiative projects .

to address these objectives , we reviewed relevant state and usaid documents and interviewed agency officials from state , usaid , and the departments of defense ( dod ) , homeland security ( dhs ) , and justice ( doj ) in washington , d.c. , and officials from state and usaid in mexico city .

to determine the extent to which state / inl and usaid followed key practices in monitoring mérida initiative projects , we selected a nongeneralizable sample of 15 high – dollar value state / inl projects and five high – dollar value usaid projects that started between january 1 , 2014 , and december 31 , 2016 , some of which were still ongoing as of september 30 , 2019 , or later .

the value of the 15 state projects in our sample is about $88 million , and the value of the five usaid projects in our sample is about $107 million .

because state / inl implemented about 90 percent of mérida initiative projects during this period , we chose a larger state / inl sample than a usaid sample .

we assessed the agencies' monitoring of these 20 projects against eight key project monitoring practices , largely derived from leading practices for monitoring foreign assistance that gao had previously identified .

on the basis of our review , we assessed whether the key practices were “generally followed,” “partially followed,” or “not followed.” we rated the extent to which the agency followed each key practice as “generally followed” if we received evidence that all critical elements of the key practice were conducted and documented to a large or full extent , “partially followed” if we received evidence that some but not all critical elements of the key practice were conducted and documented , and “not followed” if we did not receive evidence that any of the critical elements of the key practice were conducted and documented .

to determine the extent to which state / inl and usaid track project performance , we chose a nongeneralizable subset of the 20 projects listed above .

specifically , we chose a smaller sample of six projects — four from state / inl and two from usaid — primarily based on their high – dollar values .

we reviewed these projects' latest year of quarterly and annual progress reports to assess the extent to which state / inl and usaid tracked data on performance measures in these reports .

these performance measures were established in other monitoring documents ( eg , monitoring plans and project narratives ) in accordance with one of the key monitoring practices .

to describe the type of government of mexico data state / inl uses to monitor mérida initiative implementation , we reviewed data related to mérida initiative projects collected by the government of mexico and shared with state / inl .

we conducted this performance audit from november 2018 to may 2020 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

there were 445 state / inl and usaid mérida initiative projects active from fiscal year 2014 through fiscal year 2018 , which includes some projects that started before this period and some that continued after this period .

state / inl funded 388 of the projects , and usaid funded 57 .

usaid's projects tended to be larger with higher funding amounts than state / inl projects .

state / inl projects generally focused on providing training and assistance to mexican officials from the justice sector , border security , military , and law enforcement , as well as equipment , including for forensic laboratories , drug detection , and border surveillance .

usaid projects were intended to engage with mexican government institutions , civil society organizations , and the private sector to address corruption , promote trust in government , or prevent crime and violence , such as through skill building for youth , efforts to advance human rights , or technical support for judicial system development .

state / inl allocated about $542 million and usaid allocated about $182 million for assistance to mexico under the mérida initiative from fiscal year 2014 through fiscal year 2018 .

state / inl and usaid are the lead u.s. agencies for developing the mérida initiative's programming .

in these roles , state / inl and usaid work with government of mexico officials to outline plans , goals , and objectives for mérida initiative projects .

state / inl and usaid both manage and fund the mérida initiative with the support of a wide range of project implementers , including doj , dhs , and dod , as well as private contractors , nongovernmental organizations , and international organizations .

state / inl and usaid implement mérida initiative projects primarily through contracts , grants , and agreements with international organizations .

state / inl also implements some mérida initiative projects through interagency agreements with other u.s. agencies ( eg , doj , dhs , and dod ) .

state / inl and usaid contracting , grant , and agreement officers , are responsible for administering and overseeing contracts , grants , and other agreements that the agencies award , including for mérida initiative projects .

they delegate the day - to - day monitoring responsibilities to agency officials located in mexico city , particularly state / inl and usaid contracting officer representatives ( cor ) for contracts , state / inl grant officer representatives ( gor ) for grants , state / inl agreement officer representatives ( aor ) for interagency agreements or letters of agreement with international organizations , and usaid aors for grants and cooperative agreements , according to agency officials .

key monitoring responsibilities of the cors , gors , and aors typically include reviewing quarterly , annual , and other progress reports submitted by project implementers ; ensuring other required documents are submitted ; communicating with the implementers on the status of assistance activities ; and conducting site visits , among other things .

in 2019 , we reported on 14 leading practices for monitoring foreign assistance that agencies should incorporate in their monitoring policies to help ensure that they effectively manage foreign assistance , address impediments , and meet their assistance goals .

from these leading practices we derived eight key practices that can help agencies monitor the implementation and performance at the project level .

to facilitate discussing these key monitoring practices , we grouped them into three areas: ( 1 ) assigning monitoring duties to qualified staff , ( 2 ) planning monitoring approach , and ( 3 ) monitoring project implementation .

 ( see table 1. ) .

these practices are generally consistent with the office of management and budget's guidelines for federal departments and agencies that administer united states foreign assistance and related guidance , as well as state's and usaid's monitoring policies .

we reviewed 15 of state / inl's high – dollar value mérida initiative projects to assess the extent to which state / inl followed key practices for monitoring foreign assistance projects in the areas of assigning monitoring duties to qualified staff , planning a monitoring approach , and monitoring project implementation .

for these projects , the agency generally followed the key practices about half of the time , as shown in figure 1 , and for a subset of four selected projects , it did not consistently track performance data or compare them to established performance measures .

state / inl does not have procedures in place for monitoring staff to consistently follow all the key practices .

instead , officials said they focused on tracking implementation of the projects' activities .

consistently following key monitoring practices would allow state / inl to stay well informed of projects performance , take corrective action when necessary , and help ensure that projects achieve their intended results .

state / inl generally followed key practices for assigning monitoring duties to qualified staff almost always .

assigning staff with the appropriate certification helps ensure that they have the necessary knowledge and skills to perform those duties .

establishing roles and responsibilities helps ensure that the assigned monitoring staff are aware of their monitoring duties .

state / inl requires that staff responsible for monitoring mérida initiative projects be certified as a cor , gor , or aor .

state / inl also assigns roles and responsibilities to monitoring staff through a designation letter in which a contract or grant officer designates a cor , gor , or aor to oversee each project .

however , of the 15 projects we reviewed , one had a gap in the documentation for staff certifications , and four had gaps in the documentation of designation letters .

for example , in one case state / inl could not provide documentation to demonstrate that the official responsible for monitoring a project on police training had been officially designated or that the official had a valid certification during the full implementation period of the project .

according to state / inl staff , the monitoring staff roles and responsibilities are also outlined in other documents such as the state department's foreign affairs manual and the aor handbook , of which staff are expected to be aware .

figure 2 illustrates the extent to which state / inl followed each related key practice for assigning monitoring duties .

state / inl generally followed key practices for planning a monitoring approach a third of the time .

two projects — one for helicopter pilot training and the other for aviation maintenance training — did not have monitoring plans and thus did not meet any of the three key practices for planning a monitoring approach .

according to a state / inl manager , state / inl is no longer working with this implementer due to long - standing difficulties in obtaining documentation needed to monitor the projects .

most of the other 13 projects partially met the key practices for planning a monitoring approach .

for example , goals and objectives were included in planning documents other than the monitoring plan .

furthermore , while only three of the projects had a monitoring plan that addressed risk , we determined that 10 of the projects partially addressed this key practice , because risks were assessed or considered , but the identified risks were not addressed in the monitoring plan .

in addition , almost all of the projects had relevant project - level performance measures .

developing a monitoring plan that identifies project objectives helps focus monitoring efforts on assessing projects outcomes .

in addition , identifying and addressing risks in that plan helps focus monitoring efforts on those aspects of project implementation that are most likely to threaten the success of the project in meeting its goals .

we did not see evidence that state / inl had procedures in place to ensure that monitoring officials consistently follow key practices in the area of planning monitoring approach .

figure 3 illustrates the extent to which state / inl followed each related key practice to planning a monitoring approach .

state / inl provided documentation to demonstrate that monitoring managers generally followed key practices for monitoring project implementation about half of the time .

monitoring project implementation helps ensure that projects are meeting their objectives , so that any necessary adjustments or corrective actions can be taken in a timely manner .

we found that state / inl did not generally collect all expected progress reports from implementers for seven projects , and of those seven , it did not collect any reports for three projects .

furthermore , state / inl did not provide documentation for eight projects demonstrating that monitoring staff had generally assessed and approved implementers' periodic progress reports .

we also found that for seven projects , state / inl did not provide documentation demonstrating that monitoring staff had generally conducted site or field monitoring visits or taken other steps to validate the partner's performance implementing the project .

for example , for one project that provided training to mexican immigration officers on the southern border , state / inl only provided one quarterly progress report of the four we requested for the period of our review .

for this project , state / inl also did not provide documentation that monitoring staff had taken steps to review and approve the report or that they had conducted any monitoring site visits .

a state / inl official explained that they requested the quarterly reports , but at times implementers did not submit them .

without implementing procedures to consistently collect , assess , and approve performance reports from implementers , monitoring staff may not have sufficient information to assess implementers' performance and determine whether corrective actions are needed .

we did not see evidence that state / inl had procedures in place to ensure that monitoring officials consistently follow key practices in the area of monitoring project implementation .

figure 4 illustrates the extent to which state / inl followed each related key practice for monitoring project implementation .

state / inl monitoring officials did not consistently track performance data against established measures for four mérida initiative projects we reviewed ; these four projects were a subset of the 15 state / inl projects discussed above .

tracking performance data — a key practice for monitoring project implementation — can provide meaningful information on projects' progress in achieving intended results .

the four projects we reviewed included two grants focused on police professionalization ; one interagency agreement focused on assistance to forensic laboratories ; and one agreement with an international organization focused on conducting a survey on police standards , training , and professionalization .

we reviewed how state / inl tracked performance data for these selected projects as part of its efforts to assess and approve implementing partners' periodic performance reports and data as outlined in the key monitoring practices .

specifically , we analyzed the extent to which state / inl tracked data contained in quarterly progress reports and compared these data to established performance measures .

state / inl and the project implementers outlined these performance measures in monitoring documents that these implementers developed and state / inl approved .

some of these projects' monitoring documents also included data sources , data collection frequency , and performance targets .

state / inl did not track performance data for two of the four selected projects and tracked such data inconsistently for the other two selected projects .

as a result , state / inl cannot ensure that it has accurate and reliable performance data for its mérida initiative projects .

such data could help state / inl determine whether projects are achieving intended results and take necessary corrective actions to improve project performance over time .

for the two police professionalization projects we reviewed , state / inl did not track performance data against established performance measures outlined in the project narrative at the start of the projects .

some of these projects' performance measures reflected outputs — such as the number of participants completing at least 25 hours of police training and the number of citizen surveys conducted on public trust of law enforcement .

other performance measures reflected outcomes — such as the percentage of law enforcement officials who feel ready for promotion after completing training and results of citizen surveys on perceived security where law enforcement trainings were conducted .

 ( see examples in table 2. ) .

however , state / inl did not clearly track or reference such performance measures in these two projects' quarterly progress reports .

instead , state / inl provided details in these reports on project activities and training that did not clearly link to the projects' performance measures .

for example , state / inl noted the number of participants who took a specific training course on a certain date , but did not provide the total number of participants' training hours to compare them to the performance measure on the total number of participants who completed at least 25 hours of training .

state / inl monitoring officials said they had not systematically tracked data on the performance measures of these projects over time , but instead focused on ensuring the trainings were conducted and the number of training participants were tracked .

these officials acknowledged the need to improve their tracking of these projects' progress against their performance measures .

we also identified information in quarterly progress reports for two projects suggesting that the reports did not accurately reflect project activities in those quarters .

for example , for one project , state / inl included identical information in two separate quarterly reports even though the implementer conducted different project activities in those two quarters .

thus , at a minimum , the information in one of the quarterly reports did not accurately reflect the project's activities conducted in that quarter .

we found the same issue with another project's reports .

state / inl officials said they were not aware that the project information in these reports were identical .

for the two other state / inl projects we reviewed ( one forensics laboratory accreditation project and one police survey project ) , state / inl tracked some performance data but did so inconsistently .

these projects' performance measures reflected outputs , such as the number of survey pollsters hired and trained and the number of accredited forensic laboratories that maintain their accreditation .

other performance measures reflected outcomes , such as the percentage of forensic laboratories trainees reporting improved knowledge of subject matter and satisfaction rates for training courses for the forensics laboratory project .

 ( see examples in table 3. ) .

in one of these two projects' quarterly reports , the project implementers inconsistently described and numbered some of the performance measures , and they did not explain the discrepancies .

also , the implementers mentioned different performance measures in different quarterly progress reports — with some measures dropping off in some quarters and new measures appearing in others — without providing a rationale in the reports .

as a result , state / inl could not consistently track progress of some of the performance measures over time .

state / inl officials stated that these two implementers only included activities in the quarterly reports that they conducted in that quarter , which would result in different and inconsistent performance measures in each report .

in addition , some of the reported project activities did not consistently and clearly align with the performance measures to allow state / inl to track the project's progress against these measures .

for example , some performance measures reflected percentages ( eg , 90 percent of authorities responsible for forensic laboratories routinely attend regional and national conferences ) , but the report listed the names of conference participants , dates , and locations in a table next to that performance measure .

when asked about these discrepancies , state / inl officials said that they did not ensure that implementers provided complete information to clearly track the project's progress against performance measures .

however , they said that they also conduct monitoring through informal methods not documented in the progress reports , such as through communication via phone calls and emails with the implementers .

such informal methods do not provide state / inl with the necessary data to assess a project's performance against its goals .

for the four state / inl projects we reviewed , state / inl monitoring managers did not establish procedures to collect and review project performance data , such as the number of people who completed a targeted number of hours of training , or the results of training surveys .

these managers said they did not prioritize establishing performance tracking procedures and instead focused on the implementation of the projects' activities , such as counting the number of participants who attended one training course for a particular month .

for example , while some monitoring staff sent monthly emails to their managers describing project activities , state / inl monitoring managers did not establish procedures — such as holding regular meetings with or requiring reporting from monitoring staff — that focused on tracking the projects' progress against established performance measures .

state / inl receives activity data from project implementers that it considers useful in helping the agency monitor the projects' implementation and activities .

state / inl officials told us that project activity data in the quarterly progress reports — such as when trainings were conducted and how many people attended — help keep them informed of and monitor the projects' implementation .

in addition , since 2015 , state / inl mexico has collected detailed data and information in tracking databases on ( 1 ) training events and related surveys on that training , and ( 2 ) forensic laboratory accreditations and correctional facility accreditations .

the training tracking database contains data on over 6,000 training events , 100,000 trainee records , and over 20,000 survey responses from training event participants .

this database can generate numerous reports covering the number of people who completed a specific trained course , which training courses a specific person completed , training survey results , and which implementer conducted the training , among other information .

state / inl databases also collect information on the status of forensics laboratories and correctional facilities across mexico that are being accredited through mérida initiative projects .

the forensics database includes pages for each laboratory with detailed information about the level of accreditation received , and types of trainings conducted , among other things .

the correctional facilities database is structured similarly to the laboratories database with pages for each facility with detailed information on accreditation status and timeline , among other things .

according to state / inl officials , like the training tracking system , the forensics and correctional facilities databases can generate reports , such as monthly progress reports .

finally , state / inl mexico is implementing a new cloud - based monitoring database — called devresults — that will consolidate and track data on activity , output , and outcome indicators for all mérida initiative projects .

according to state / inl officials , they implemented devresults so that state / inl could track a project's progress and trends in real time against its performance goals .

according to state / inl officials , devresults included data for 84 projects as of february 2020 .

they also noted that agency officials and implementers have completed training on devresults , and additional training will be provided as needed .

state / inl officials said they plan to continue adding data for past and present mérida initiative projects in 2020 .

we reviewed five of usaid's mérida initiative projects to assess the extent to which usaid followed key monitoring practices in the areas of assigning monitoring duties to qualified staff , planning a monitoring approach , and monitoring project implementation .

for these projects , usaid almost always followed key practices — as shown in figure 5 — and for a subset of two selected projects , it consistently tracked project performance .

according to usaid officials , usaid management conducted periodic portfolio reviews to ensure that monitoring staff adequately monitored mérida initiative projects and followed key practices .

however , for all five usaid projects we reviewed , monitoring plans did not address identified risks , which could help the agency allocate monitoring resources to those aspects of the projects that warrant closer scrutiny .

usaid generally established roles and responsibilities for technical staff responsible for monitoring projects , but for two of the five projects we reviewed it did not maintain documentation showing that it assigned staff with appropriate certifications .

like state / inl , usaid requires that staff responsible for monitoring mérida initiative projects be certified as cors or aors , which typically includes periodic training in monitoring projects .

usaid assigns roles and responsibilities to these staff through a designation letter in which a contract or agreement officer designates a cor or aor , respectively , to conduct technical oversight of each project .

for the five projects we reviewed , usaid properly designated monitoring roles and responsibilities to technical staff , however there were gaps in staff certification documentation for technical staff for two projects .

for example , we found that the person responsible for monitoring a project promoting justice reform and rule of law in mexico did not have a valid certificate for 9 months of the project's 4-year period of performance .

maintaining complete documentation of monitoring - related activities helps usaid management ensure adequate , continuous monitoring of projects .

according to usaid , the gaps in documentation were caused by staff turnover and trouble accessing the government - wide system for recording the certification of staff , which was difficult to access or down from december 2017 to march 2018 .

officials said that once the system to record certificates was brought back online , they were able to track certifications .

figure 6 illustrates the extent to which usaid followed each related key practice for assigning monitoring duties .

usaid generally developed monitoring plans that included program goals and objectives and project - level performance measures , but the monitoring plans did not address project risks .

all five projects generally had a monitoring plan that identified project goals and objectives , and relevant project - level performance measures .

however , none of the monitoring plans generally addressed identified risks related to achieving project objectives .

while usaid provided documentation showing that the agency had conducted various assessments considering risk for each project , the results of these assessments were not addressed in the projects' monitoring plans .

for example , for a project to promote justice and rule of law in mexico , usaid assessed risks relating to terrorism , environmental effects , sustainability , and gender equity in carrying out the project .

however , the project's monitoring plan did not address identified risk levels and related monitoring actions designed to mitigate risks identified in these assessments .

usaid explained that they address ongoing monitoring of risk through several other processes , such as project design , procurement actions , financial management , award management and administration , semi - annual project portfolio reviews , and annual risk - based assessments of the usaid's portfolio in mexico , among others .

however , identifying and addressing risks in the monitoring plan can help ensure that monitoring staff are aware of potential impediments to project success about which they need to be vigilant or take steps to mitigate as they monitor the projects .

additionally , determining which activities warrant greater oversight can also help agencies manage monitoring resources cost effectively .

figure 7 illustrates the extent to which usaid followed each related key practice for planning a monitoring approach .

usaid generally followed key practices for monitoring project implementation about two - thirds of the time .

we found that usaid collected all progress reports for four of the five projects we reviewed .

for two projects , usaid did not provide documentation demonstrating that monitoring staff had generally assessed and approved implementers' periodic progress reports .

for all five projects , usaid provided documentation demonstrating that monitoring staff had generally validated implementing partners' performance through site visits .

figure 8 illustrates the extent to which usaid followed each related key practice for monitoring project implementation .

usaid monitoring officials consistently tracked performance data and compared them to established performance measures for the two projects we reviewed ; these two projects were a subset of the five usaid projects discussed above .

to review the extent to which usaid assessed and approved implementing partners' periodic reports and data — one of the eight key monitoring practices — we determined whether usaid tracked performance data contained in quarterly or annual progress reports .

usaid funds one of the two projects through a cooperative agreement focused on strengthening human rights , and the other project through a contract focused on improving the criminal justice sector .

usaid and project implementers outlined these projects' performance measures in project - specific monitoring plans that both parties developed at the start of the project or revised after the project was in place .

project implementers developed these plans , and usaid approved them .

the plans included details related to the performance measures , such as data sources , data collection frequency , and targets .

in accordance with these plans , usaid and project implementers tracked performance measures in annual progress reports , while they primarily tracked detailed project activity in quarterly progress reports .

the two usaid projects' progress reports included tables that tracked project performance .

some of the projects' performance measures reflected outcomes , such as prosecution rates of mexican government prosecution units that received technical support and the number of improved measures to address serious human rights violations .

some performance measures reflected outputs , such as the number of mexican officials trained in human rights advocacy areas .

see table 4 for examples of performance measures and information in the progress reports we reviewed .

when the implementer and usaid changed performance measures , they also revised project - specific monitoring plans to document these changes .

for example , for one project we reviewed , the established measures were no longer effective in measuring progress toward the project's objectives , according to usaid officials .

as a result , the implementer and usaid modified the project's monitoring plan at least twice , revising the performance measures to better align with the project's objectives .

the subsequent progress reports we reviewed for these projects included data on the revised performance measures .

usaid has procedures to help ensure that monitoring staff track performance data .

according to usaid officials , usaid began sending out a standard spreadsheet to all mérida initiative implementing partners in 2018 that requires them to report performance data on a quarterly or annual basis .

usaid uses these spreadsheets to track mérida initiative project performance data .

since may 2017 , usaid has also conducted 6- month portfolio reviews in which monitoring managers and their staff review project activities and performance data collected for their projects and discuss project successes and challenges .

usaid managers told us that they implemented these reviews to help ensure that their staff monitor project performance .

according to state / inl , the government of mexico provides data to state / inl that help the agency monitor its mérida initiative assistance efforts and provides insights into the implementation of the initiative overall .

state / inl also noted that , in 2014 , the agency hired a contractor to work with both the u.s. and mexican governments to develop a comprehensive set of indicators to evaluate the progress and results of the mérida initiative .

in 2015 , mexico agreed that it would provide data to state / inl on this set of indicators to demonstrate the effects of the mérida initiative , according to state / inl officials .

these officials told us that they try to obtain the data on an annual basis .

they also noted that the purpose of collecting the data from mexico was to establish a mechanism to share information on the mérida initiative's effects and to improve u.s. - mexico cooperation on the initiative .

according to state / inl officials , various mexican agencies collect the data , such as the army , air force , navy , tax administration service / customs , attorney general's office , and national institute of statistics and geography .

the mexico data comprise about 170 indicators ( data points ) related to the overall goals and program areas of the mérida initiative: counternarcotics / special investigations , criminal prosecutions , border security and ports of entry , and security and law enforcement .

some data are closely linked to mérida initiative – funded projects , such as the accreditation status of mexican correctional facilities .

other data provide broader context , such as mexican civil society's perception of mexican agencies .

in addition , data , such as the number of accredited forensic laboratories and correctional facilities , may reflect progress in institution building .

other data , such as the number of accounts blocked by the mexican financial intelligence unit , may reflect operational capacity development .

see table 5 below for examples of the indicators , as reported by mexico to state / inl .

state / inl officials said they use the indicator data in discussions with mexican officials to help monitor the implementation and activities of the mérida initiative , including which best practices can be replicated across mexico .

state / inl officials said the data also inform the agency's internal decision making on which mérida initiative programs are effective and which programs it should modify .

for example , according to state / inl officials , the indicator data help track the use of equipment donated to mexico through the mérida initiative .

if the data show extensive use of equipment , state / inl can use the data to justify a request for additional equipment or to approve maintenance of the equipment , according to agency officials .

for over a decade , the mérida initiative has funded programs intended to address serious challenges to security and the rule of law .

as the united states continues to support hundreds of mérida initiative projects in mexico , it is important that state / inl monitor these projects carefully and stay well informed of the projects' performance to ensure that they are as effective as possible .

usaid has established procedures that help ensure that it follows most key monitoring practices , including those related to assigning monitoring duties to qualified staff and monitoring project implementation .

state / inl management has not established such procedures for the projects we reviewed , limiting its ability to stay well informed of project performance and make course corrections to improve performance when necessary .

while state / inl and usaid often conducted assessments to identify risks that may affect the achievement of project objectives , they generally did not address the results of the risk assessments in projects' monitoring plans .

developing monitoring plans to address risks would help establish the appropriate level of oversight needed for each project , which in turn could lead to more cost - effective management of these projects .

we are making the following two recommendations , one to state and one to usaid: the secretary of state should ensure that state / inl establishes procedures that verify that monitoring officials for mérida initiative projects follow the key practices .

 ( recommendation 1 ) the usaid administrator should establish procedures to ensure that monitoring officials for mérida initiative projects develop monitoring plans that address risks .

 ( recommendation 2 ) .

we provided a draft of this report to state , dod , dhs , doj , and usaid for review and comment .

some of the agencies provided technical comments , which we incorporated as appropriate .

state and usaid also provided formal comments , which are reproduced in appendixes iii and iv .

state agreed with our recommendation to establish procedures for staff monitoring mérida initiative projects to follow key practices .

state indicated that it is working to create new monitoring and evaluation guidance consolidated across state / inl , based in part on gao's leading practices .

according to state , the new guidance will address the areas highlighted in this report related to monitoring mérida initiative projects .

state / inl plans to institute annual program reviews in which monitoring staff will assess project performance , effects , and alignment with current and planned priorities .

state indicated that annually reviewing state / inl programming will help identify underperforming projects , give relevant staff a forum to discuss any issues or challenges to implementation and monitoring , and ensure the bureau follows the key monitoring practices outlined in this report .

usaid also agreed with our recommendation to establish procedures to ensure that staff monitoring merida initiative projects develop monitoring plans that address risk .

usaid indicated that usaid / mexico is revising its project and activity design mission order to incorporate recently issued usaid guidance and address our recommendation .

according to usaid , the mission order will provide a framework and guidance to ensure that usaid / mexico systematically addresses project risks and incorporates them into the respective monitoring plan .

we are sending copies of this report to the appropriate congressional committees , the secretary of state , and the usaid administrator .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-2964 or gurkinc@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made contributions to this report are listed in appendix v .

this report ( 1 ) examines the extent to which the department of state ( state ) , bureau of international narcotics and law enforcement affairs ( state / inl ) , follows key practices in monitoring mérida initiative projects and tracks project performance data against established measures ; ( 2 ) examines the extent to which the united states agency for international development ( usaid ) follows key practices in monitoring mérida initiative projects and tracks project performance data against established measures ; and ( 3 ) describes how state / inl uses data from the government of mexico to help monitor the implementation of mérida initiative projects .

to address these objectives , we reviewed relevant state and usaid agency documents and interviewed agency officials from the departments of state ( state ) , homeland security ( dhs ) , defense ( dod ) , and justice ( dod ) , and usaid in washington , d.c. , and officials from state and usaid in mexico city .

in 2019 , we reported on 14 leading practices for monitoring foreign assistance that agencies should incorporate in their monitoring policies to help ensure that they effectively manage foreign assistance , address impediments , and meet their assistance goals .

from these leading practices , which are focused on a high - level assessment of agency monitoring policies , we derived eight key practices that can help agencies monitor the implementation and performance at the project level , such as those implemented under the mérida initiative .

these eight key practices include those that in our judgment directly relate to monitoring project - level performance activities .

we did not address monitoring of financial activities , because our review focused on performance monitoring .

we made minor modifications to the key practices selected to reflect the focus of our review .

we also grouped the selected key monitoring practices into three areas: ( 1 ) assigning monitoring duties to qualified staff , ( 2 ) planning a monitoring approach , and ( 3 ) monitoring project implementation .

to determine the extent to which state / inl and usaid followed key practices in monitoring mérida initiative projects , we selected a nongeneralizable sample of 15 high – dollar value state / inl projects and five high – dollar value usaid projects that started between january 1 , 2014 , and december 31 , 2016 .

 ( see app .

ii for details on these 20 projects ) .

some of these projects were ongoing after fiscal year 2019 .

we selected the projects from a list provided by state / inl and usaid .

state's list included 388 projects , and usaid's list included 57 projects for a total of 445 projects under the mérida initiative .

we selected projects implemented through a variety of mechanisms .

for state / inl , we selected two letters of agreement with international organizations , four grants , three contracts , and two interagency agreements implemented by dod , two interagency agreements implemented by dhs , and two interagency agreements implemented by doj .

for usaid , we selected two contracts and three grants .

the value of the 15 state projects in our sample is about $88 million , and the value of the five usaid projects in our sample is about $107 million .

these 15 state / inl projects represent about 25 percent of the total value of the state / inl projects that started during this period .

these five usaid projects were the highest value contracts and grants cooperative agreements and represent about 70 percent of the total value of usaid projects that started during this period .

because state / inl implements about 90 percent of all mérida initiative projects , we chose a larger state / inl sample than usaid sample .

we assessed the agencies' monitoring of the 20 selected mérida initiative projects against eight key monitoring practices largely derived from gao's leading practices for monitoring foreign assistance .

we reviewed documents to determine the extent to which state / inl and usaid followed the eight key monitoring practices for each of the selected mérida initiative projects .

specifically , for each selected project , we requested monitoring plans ; work plans ; risk assessments ; contract , grant , or agreement officer representative certificates ; contract , grant , or agreement officers representatives designation letters ; implementer progress reports for the latest year of activity of each project ( at the time of our review ) ; samples of field or site visit reports ; and samples of monitoring emails between monitoring staff and the implementers .

we reviewed available documents as they related to each key practice to determine the extent to which the agency had taken steps to follow and document the key practice for each project .

on the basis of our review , we assessed whether the key practices were “generally followed,” “partially followed,” or “not followed.” we rated the extent to which the agency followed each key practice as “generally followed” if we received evidence that all critical elements of the key practice were conducted and documented to a large or full extent , “partially followed” if we received evidence that some but not all critical elements of the key practice were conducted and documented , and “not followed” if we did not receive evidence that any of the critical elements of the key practice were conducted and documented .

to perform these analyses , two analysts reviewed the documents to rate the extent to which each key practice was met .

the analysts worked iteratively , comparing notes and reconciling differences at each stage of the analysis .

in addition , gao staff independent of the two analysts reviewed the final analysis , and modified it as appropriate .

to determine the extent state / inl and usaid track project performance , we chose a nongeneralizable subset of the 20 projects listed above .

specifically , we chose six projects — four state / inl projects and two usaid projects — primarily based on their high – dollar values .

 ( see app .

ii for details on these six projects. ) .

we chose a small subset of state / inl and usaid projects to conduct a detailed analysis of data in the projects' annual and quarterly reports .

specifically , for the four state / inl projects , we chose high – dollar value projects for each of the following implementing mechanisms: grants , interagency agreements , and agreements with international organizations .

we excluded contracts from the state / inl subset sample , because the high – dollar value contracts generally did not have the project - level performance measures needed to assess state's tracking of performance data .

we included a second grant in our sample in place of a contract , because more mérida initiative state / inl projects are grants than interagency agreements or agreements with international organizations .

as a result , our state / inl sample consisted of two grants , one interagency agreement , and one agreement with an international organization .

for the usaid sample , we chose one grant or cooperative agreement and one contract .

we did not choose other types of implementing agreements because grants / cooperative agreements and contracts comprise over 98 percent of usaid projects for the timeframe of our review .

for both the state / inl and usaid selected projects , we reviewed project monitoring documents — such as project narratives , workplans , and monitoring plans — and identified the performance measures outlined in these documents for each project .

we then reviewed these projects' latest year of implementer quarterly and annual progress reports ( at the time of our review ) , and assessed the extent to which state / inl and usaid assessed and approved implementing partners' periodic performance reports and data in accordance with the key monitoring practice of assessing and approving performance information .

we also met with state / inl and usaid monitoring officials in washington , d.c. , and mexico to understand the process for how these officials track the performance of these selected projects , including in the projects' quarterly and annual reports .

we also reviewed the reports to identify any discrepancies or errors .

to describe the type of government of mexico data that state / inl uses to monitor mérida initiative implementation , we reviewed data from fiscal years 2015-2018 related to mérida initiative projects collected by the government of mexico and shared with state / inl .

we also met with state / inl officials in washington , d.c. , and mexico city to discuss the data , including how it is used and its reliability .

after our discussions with state / inl officials , state / inl selected some unclassified examples of the indicators , which we included in our report .

the purpose of this component of our review was to describe the nature and use of the mexico data .

we conducted this performance audit from november 2018 to may 2020 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

this appendix provides a list of the 15 department of state ( state ) , bureau of international narcotics and law enforcement affairs ( state / inl ) mérida initiative projects , and five united states agency for international development ( usaid ) mérida initiative projects selected for our review .

we assessed state / inl and usaid monitoring of these projects against key monitoring practices as described in appendix i .

the subset of these projects ( four state / inl and two usaid ) selected for our analysis of the agencies' tracking of performance data is noted below .

state / inl provided the details in table 6 , and usaid provided the details in table 7 .

in addition to the contact named above , james michels ( assistant director ) , francisco enriquez ( analyst - in - charge ) , terry allen , ashley alley , lilia chaidez , martin de alteriis , neil doherty , teresa heger , john hussey , and andrew kincare made key contributions to this report .

