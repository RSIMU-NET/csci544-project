with a cost of about $13 billion , the 2010 census was the most expensive population count in u.s. history , costing over 50 percent more than the $8.1 billion 2000 census ( in constant 2010 dollars ) .

some cost growth is to be expected because the population is growing and becoming more complex and difficult to count , which increases the workload of the census bureau ( bureau ) .

however , the cost of counting each housing unit has escalated from $16 in 1970 to $94 in 2010 ( in constant 2010 dollars ) .

for the 2020 census , the bureau intends to limit its per - household cost to not more than that of the 2010 census , adjusted for inflation .

to achieve this goal , the bureau is significantly changing how it conducts the census , in part by re - engineering key census - taking methods and infrastructure .

in october 2015 , the bureau estimated that with its new approach it can conduct the 2020 census for a life - cycle cost of $12.5 billion in contrast to its estimate of $17.8 billion to repeat the design and methods of the 2010 census ( both in constant 2020 dollars ) .

reliable cost estimates that appropriately account for risks facing an agency can help an agency manage large complex activities like the 2020 census , as well as help congress make funding decisions and provide oversight .

cost estimates are also necessary to support decisions about funding one program over another , to develop annual budget requests , to determine what resources are needed , and to develop baselines for measuring performance .

having a realistic estimate of projected costs makes for effective resource allocation , and it increases the probability of a program's success .

despite their importance , our work has shown agencies across the federal government have had difficulty developing reliable cost estimates .

too often , programs cost more than expected and deliver results that do not satisfy all requirements .

you asked us to evaluate the reliability of the life - cycle cost estimate the bureau submitted to congress in october 2015 .

we reviewed ( 1 ) the extent to which the bureau's life - cycle cost estimate met our best practices for cost estimation ; ( 2 ) the extent to which the bureau's key cost assumptions were supported by field tests , prior studies , and other evidence - based analysis ; and ( 3 ) the extent to which the bureau has identified and accounted for key risks facing the 2020 census within its risk and uncertainty analyses of its life - cycle cost estimate .

for all three objectives , we reviewed documentation related to the cost estimate and interviewed bureau officials responsible for developing the 2020 decennial life - cycle cost estimate .

for the first question we interviewed bureau cost analysts and evaluated whether the bureau's cost estimate was generated according to best practices of our cost estimating and assessment guide .

for the second question we inventoried cost assumptions documented by the bureau in support of its october 2015 life - cycle cost estimate and identified those associated with major changes from the bureau's historical census design and with significant cost - saving potential .

we then attempted to locate these key assumptions' sources in order to determine if they were supported by field tests , prior studies , and other evidence - based analysis .

finally , for the third question we analyzed the bureau's project and program risk registers to determine if the range of risks and how they are incorporated in the bureau's uncertainty analyses is adequate .

we relied on our cost assessment guide and standards for internal control in the federal government as criteria .

more information on our scope and methodology can be found in appendix i .

we conducted this performance audit from november 2015 to june 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

our work on the bureau's 2010 census life - cycle cost estimate found that it was not reliable , because it lacked adequate documentation and was not comprehensive , accurate , or credible .

for example , in our 2008 report on the bureau's cost estimation process , bureau officials were unable to provide documentation that supported the assumptions for the initial 2001 life - cycle cost estimate as well as the updates .

we reported that without improvements to the cost estimation process , the bureau's ability to effectively manage operations would be hampered and congress's ability to oversee the 2010 census would be constrained .

consequently , we recommended that the bureau establish guidance , policies , and procedures for conducting cost estimation that would meet best practices criteria .

the bureau agreed with the recommendation and said at the time that it already had efforts underway to improve its future cost estimation methods and systems .

moreover , weaknesses in the life - cycle cost estimate were one reason we designated the 2010 census a gao high risk area in 2008 .

bureau officials stated they have been working toward implementing the standards of our cost estimating and assessment guide since 2008 .

however , in a 2012 report , we found that while the bureau was taking steps to strengthen its life - cycle cost estimates , it had not yet established guidance for developing cost estimates , and we recommended that the bureau finalize its guidance , policies , and procedures for cost estimation in accordance with best practices .

in its response to that report the bureau agreed with the overall theme of the report , but did not directly comment on that recommendation , which remains open , as discussed later in this report .

to help control costs while maintaining accuracy , the census bureau is introducing significant change to how it conducts the decennial census in 2020 .

its planned innovations include reengineering how it builds its address list , improving self - response by encouraging the use of the internet and telephone , using administrative records to reduce field work , and reengineering field operations using technology to reduce manual effort and improve productivity .

the bureau estimates that if it succeeds with these innovations it can conduct the 2020 census for $12.5 billion in constant 2020 dollars .

by contrast , the 2020 census would cost $17.8 billion in constant 2020 dollars if the bureau repeats the 2010 census design and methods , according to the bureau's estimates .

major innovation does not come without risks and in order to manage and mitigate them the bureau has established a decennial risk management process governing two types of risks: project risks and program risks .

the bureau defines project risks as those that could jeopardize success of an individual project , such as the bureau's operation to collect responses door - to - door from households that do not respond to bureau mailings .

the bureau defines broader program risks as those that jeopardize the success of the 2020 census program , typically spanning several years with many potential risk events over the period .

these may have elevated from project level risks and include risks such as the possibility that external stakeholders do not support the planned design changes .

as early as 2011 , the bureau began developing preliminary cost estimates of the 2020 census in order to approximate potential savings from its plans to reengineer the census , and , according to the bureau , to begin developing the methodology for producing the decennial life - cycle cost estimates .

the bureau's october 2015 release of the latest cost estimate marked the transition from the “research” to “implementation” phases of the 2020 census .

according to the bureau , this was the bureau's first attempt to model the life - cycle cost of its planned 2020 census , in contrast to its earlier 2011 estimate which the bureau said was intended to produce an approximation of potential savings and to begin developing the methodology for producing decennial life - cycle cost estimates covering all phases of the decennial life cycle ( see fig .

1 ) .

according to bureau officials , they recently implemented a software upgrade they believe has better positioned them to deliver a quality cost estimate .

they stated that they relied primarily on a cost estimation team of five individuals in the decennial programs directorate to develop the 2020 census life - cycle cost estimate .

this team drew in part on subject matter specialists involved in the bureau's research and testing of its planned innovations in order to help develop a cost model and to obtain data to inform key assumptions within the model .

the specialists typically provided the cost estimation team with data on each assumption using a three - point method , whereby the cost estimation team received a “minimum,” “value,” and “maximum” input for each assumption , representing whatever uncertainty or risks the provider had considered .

figure 2 shows the bureau's cost estimation process .

because cost estimates predict future program costs , uncertainty is always associated with them .

for example , data from the past ( such as fuel prices ) may not always be relevant in the future .

risk and uncertainty refer to the fact that because a cost estimate is a forecast , there is always a chance that the actual cost will differ from the estimate .

one way to determine whether a program is realistically budgeted is to perform an uncertainty analysis , so that the probability associated with achieving its point estimate can be determined , usually relying on simulations such as those of monte carlo methods .

this can be particularly useful in portraying the uncertainty implications of various cost estimates .

consistent with prevailing cost estimation practices , the bureau's office of cost estimation , analysis , and assessment ( oceaa ) , in the deputy director's office ( see fig .

3 ) , began generating an independent cost estimate in fiscal year 2015 , and shared it with the cost estimation team in april 2016 .

oceaa and the cost estimate team worked together to examine the process they each used , an effort known as the reconciliation process .

according to bureau officials , reconciliation is a major step in the cost estimation process , and it may help identify areas of improvement for the bureau's cost estimation process .

officials also said that this reconciliation was to be shared with the department of commerce in june 2016 as part of its 2020 census budget process .

the bureau plans annual updates of its cost estimate , leaving three updates before the bureau begins implementing its earliest operations in 2019 for the 2020 census .

since our january 2012 report in which we reviewed the bureau's initial estimate of the total cost of the decennial census , the bureau has taken significant steps to improve its capacity for cost estimating .

for example , the bureau established oceaa as an enterprise - level cost estimation office and hired certified cost analysts .

despite this progress , the bureau's october 2015 cost estimate for the 2020 census does not fully reflect characteristics of a high - quality estimate as described in our 2009 cost estimating and assessment guide and cannot be considered reliable .

a reliable cost estimate is critical to the success of any program .

such an estimate provides the basis for realistic budget formulation and program resourcing , meaningful progress measurement , proactive course correction when warranted , and accountability for results .

according to the office of management and budget ( omb ) , programs must maintain current and well - documented estimates of program costs , and these estimates must encompass the full life - cycle of the program .

without this capability , agencies are at risk of experiencing program cost overruns , missed deadlines , and performance shortfalls .

the cost estimating and assessment guide describes best practices for the development of reliable cost estimates .

for our reporting needs , in the cost guide we collapsed these best practices into four general characteristics for sound cost estimating — comprehensive , well - documented , accurate , and credible — and identified specific best practices for each characteristic .

to reflect these characteristics , an organization must meet or substantially meet each best practice .

our review found the bureau partially or minimally met the cost estimating best practices .

more specifically , it partially met two characteristics and minimally met two characteristics ( see table 1 ) .

according to our best practices , an estimate is comprehensive if it has enough detail to ensure that cost elements are neither omitted nor double - counted , all cost - influencing assumptions are detailed in the estimate's documentation , and a single work breakdown structure ( wbs ) is defined and all wbs elements are described in a wbs dictionary .

while bureau officials were able to provide us with several documents that included projections and assumptions that were used in the cost estimate , we found the estimate to be partially comprehensive because it is unclear if all life - cycle costs are included in the estimate or if the cost estimate completely defines the program .

additionally , we found the bureau had four versions of wbss with inconsistencies among them .

for example , the bureau's standard wbs , operational plan wbs , decennial budget wbs , and the life - cycle cost estimate wbs contained differing numbers of major areas ( eg , program management and response data ) and we could not determine how all the different areas fit together .

bureau officials stated that they have worked to create an agency - wide standard wbs and that the different versions of the wbs they provided to us were similar .

yet the bureau did not provide evidence that demonstrated how the wbs related to each other .

these issues reduce the reliability of the bureau's current life - cycle cost estimate , because as a result , we could not determine if all life - cycle costs are included in the cost estimate , and decision makers and others cannot know whether the total estimate fully accounts for all costs .

however , the bureau's use of wbss is an improvement over what we found in 2008 when the bureau did not have a wbs in place at all .

in addition , about $3 billion , or one - quarter , of the total cost of the census is represented by cost breakouts that are not in the bureau's wbs .

these comprise dollar amounts for the annual 2020 census enacted or requested budget line for fiscal years 2012 through 2017 and their out year estimates for 2021 through 2023 .

bureau officials justified using such aggregate budget figures by describing much of these years' costs as staff cost at headquarters and as relatively fixed in nature — basic requirements to conduct a decennial census .

we reported on the limitations associated with relying on aggregate budget numbers instead of detailed actual costs to support cost estimation in 2008 and on the limitations of isolating cost drivers ( i.e. , cost of specific field operations ) within overly broad categories of cost in 2012 .

although the bureau generally agreed with the findings in both reports , it maintained that relying on appropriations figures within cost estimates was appropriate and expressed belief that the weaknesses we identified would not affect the bureau's ability to control future costs .

however , according to best practices , the description of the costs should be tied to the wbs so that the bureau or others can measure actual variances on specific cost elements from estimates , identify possible cost drivers , and inform life - cycle cost estimation activity for future censuses .

cost estimates are considered valid if they are well - documented to the point they can be easily repeated or updated and can be traced to original sources through auditing , according to best practices .

rigorous documentation also increases an estimate's reliability and helps support an organization's decision making .

the documentation should explicitly identify the primary methods , calculations , results , rationales or assumptions , and sources of the data used to generate each cost element .

one reason why our overall assessment is low is because the estimate is not well - documented .

while the bureau provided some documentation of supporting data , it did not describe how the source data were incorporated .

additionally , while officials provided documentation to show the estimating approach used for the majority of the cost elements and the estimate results , it did not show the estimate calculations .

moreover , the majority of methodologies used to develop the cost estimate relied on expert opinion instead of more quantitative methods of estimating .

while expert opinion can be valuable in the absence of other data , according to best practices it should be used sparingly because of its subjectivity , potential to introduce bias , and lack of supporting documentation .

similar to our findings , a contractor hired by the bureau to assess the bureau's cost estimate identified the bureau's primary estimation weakness as a lack of formal , stand - alone documentation .

the contractor's january 2016 assessment noted that cost estimate documentation was available to the cost estimate team , but not contained in a formal document accessible to outside analysts .

the contractor also noted that the cost estimate team acknowledged the lack of a documented cost estimating process .

while bureau officials discussed with us how they believe they implemented best practices in producing the bureau's 2020 life - cycle cost estimate , those efforts have generally not been well - documented .

best practices state that thorough documentation is essential for validating and defending a cost estimate .

a poorly documented estimate does not provide convincing support for the estimate's validity and fails to answer decision makers' and oversight groups' questions .

failure to document an estimate in enough detail for someone unfamiliar with the program to recreate or update the estimate makes it more difficult to detect possible errors in the estimate , reduces transparency of the estimation process , and can undermine the ability to use the information to improve future cost estimates or even to reconcile the estimate with another independent cost estimate .

bureau officials acknowledged throughout our review the importance of documenting the cost estimate and stated that facing resource constraints , they had prioritized their research and testing efforts , as well as completing the 2020 census operational plan with the associated cost estimate , over documenting the cost estimate .

in april 2016 , bureau officials provided us with a summary of a documentation strategy they plan to have implemented in summer 2016 .

that strategy includes a cost estimation plan and schedule for future updates , a framework describing the fundamental basis of the estimate , and a comprehensive list of artifacts and other documents to be created .

this strategy indicates that much progress might be made during the coming year to improve the bureau's documentation ; however , it contains insufficient details to assess the extent to which that progress may help the bureau meet documentation best practices .

according to best practices , an estimate that is accurate is unbiased , is not overly conservative or overly optimistic , and is based on an assessment of most likely costs .

few , if any , mathematical mistakes are present and those that are present are minor .

we found the estimate partially met best practices for this characteristic .

for example , bureau officials said that they only applied risk and uncertainty analysis to the portion of the 2020 census estimate for the years 2018 to 2020 .

officials said they focused on cost estimating methodologies and data collection and normalization for that period because the majority of costs , roughly 80 percent of the total estimate , occur in those 3 years .

however , it appears the balance of the estimate was not adjusted for any specific level of confidence , so we cannot determine the confidence level of the total life - cycle estimate .

therefore , we cannot determine if the estimate is unbiased , overly conservative , or overly optimistic .

additionally , we could not independently verify the calculations the bureau used within its cost model to ensure there were no major mathematical mistakes .

while the bureau's new cost estimation software upgrade contains the bureau's calculations within it , access to the software is limited , restricting the accessibility of these calculations or related notes .

in one example , bureau officials provided us with the inflation rates they used , but we could not verify the application of the rates because the documentation provided did not include the calculations .

credible cost estimates clearly identify limitations due to uncertainty or bias surrounding the data or assumptions , according to best practices .

major assumptions should be varied and other outcomes should be recomputed to determine how sensitive outcomes are to changes in the assumptions .

in addition , a risk and uncertainty analysis should be performed to determine the level of risk associated with the estimate .

finally , the results of the estimate should be cross - checked and an independent cost estimate should be performed to determine whether alternative estimate views produce similar results .

we found the estimate minimally met best practices for this characteristic .

bureau officials acknowledged that while a contractor they hired performed cross - checks of selected cost elements , overall cross - checks were not used .

also , although oceaa began generating an independent cost estimate in fiscal year 2015 and shared it with the cost estimation team in april 2016 , it was not made available to us at the time of this review .

bureau officials said they conducted a sensitivity analysis in order to identify cost drivers , but had not documented it by the time of our review .

additionally the bureau carried out its risk and uncertainty analysis only for a portion of costs in fiscal years 2018 to 2020 , telling us it scoped it narrowly by design to those 3 years when most of the census costs — and predominantly variable costs — occur .

we found that the bureau's risk and uncertainty analysis ( modeled costs ) covered $4.6 billion , only about 37 percent of the $12.5 billion total estimated life - cycle cost , and less than one - half of the total estimated future cost of the census , which would include fiscal years 2017 to 2023 ( see figure 4 ) .

based on its risk and uncertainty analysis , the bureau included a contingency of about $500 million to establish a total estimated value that it believed will equal or exceed the true cost with 80 percent certainty .

testified on our concerns about the management and progress of the cedcap program that could contribute to cost overruns .

other costs excluded from the modeling were costs of advertising ( $347 million ) , various operations such as coverage improvement ( $204 million ) and in - office canvassing ( $22 million ) , non - cedcap information technology systems ( $221 million ) , as well as nearly all decennial costs for fiscal years 2021 through 2023 ( $877 million ) .

bureau officials stated that much of the omitted costs are for fixed contracts or bureau headquarters staff that are not susceptible to cost - related risks ; however , these costs also include uncertain cost drivers , such as cedcap and other systems , which could have been included in the uncertainty analyses .

the bureau used management discretion to determine how much contingency to add on top of the remaining costs .

an additional 10 percent was added for fiscal years 2018 through 2020 , for a total additional contingency of $829 million .

however , officials were not able to justify the 10 percent factor and there was no bureau documentation justifying the additional contingency .

because the bureau only carried out its uncertainty analysis on a portion of the cost estimate , we cannot determine if it fully identified the level of risk associated with the estimate .

nor can we validate the bureau's reported confidence level of the total life - cycle cost estimate or how it relates to the bureau's total contingency .

we found the bureau had little planning information among its documents supporting its cost estimate .

early fundamental planning and guidance documents such as general policies and procedures for cost estimation — in contrast to polished final process descriptions that might be produced later — can contribute to consistent control over the process used to develop a cost estimate and help ensure that desired standards and practices are implemented .

internal controls for the federal government state that management should design control activities to achieve objectives such as the development of a reliable cost estimate .

these internal controls could take many forms , such as an operational plan , guidance on specific steps , and job aids for staff involved in the process .

internal controls would help the bureau ensure continuity of operations across turnover in staff during the decennial life cycle , ensure that its cost estimation process follows best practices , and help it meet its objective of a reliable cost estimate .

we recommended the bureau take these steps to put guidance , policies , and procedures in place in our 2008 and 2012 reports on the bureau's cost estimation process .

while the bureau has not yet implemented the recommendation , we continue to believe that it is valid in order to ensure the bureau improves the reliability of its cost estimate .

cost estimates typically include a number of unknowns because they are based on future events .

to account for these unknowns , cost estimators include various assumptions that are often built with limited information .

these assumptions represent a set of judgments about past , present , or future conditions .

best cost estimation practices state that assumptions should be realistic and valid , meaning that historical data should back them up to minimize uncertainty and risk .

analysts must ensure that assumptions are not arbitrary , and that they are founded on expert judgments rendered by experienced program and technical personnel .

further , well - supported assumptions should include documentation of an assumption's source .

recognizing that not all assumptions are equal in their impact on cost , we worked with the bureau's cost team to identify key bureau assumptions that were included within the bureau's model for its life - cycle cost estimate .

we identified 41 key assumptions: examples included staffing ratios , pay rates , and anticipated production rates for the major field operations address canvassing and nonresponse follow - up ( nrfu ) .

not all of these assumptions are likely to have the same impact on the cost model or are as directly testable in the field .

according to the bureau , it prioritized field testing for the most sensitive or high - impact assumptions , based on the availability of resources , and relied on subject matter expertise for assumptions that are more difficult to test or that affect relatively low - cost operations .

the bureau's model required each of these 41 assumptions to be associated with three inputs: a minimum , value , and maximum .

the cost team told us that many of the assumptions were developed by subject matter specialists who provided them to the cost team .

in other cases , the cost team said they developed the assumptions themselves .

we requested the source for each of the 41 key assumptions so we could determine if the key assumptions were based on historical data or expert judgments rendered by experienced program personnel .

figure 5 shows the sources of support for the assumptions we could determine .

of the 41 key assumptions , bureau officials provided evidence that 18 were supported by field tests , prior studies , other research , or a combination of these sources , as shown in the following examples: assumptions related to the use of administrative records were derived from the results of the 2015 census test .

nrfu assumptions relied on recent test results from the 2014 and 2015 census site tests .

address canvassing productivity assumptions drew on operational results from the 2010 census .

by contrast , in our 2008 assessment , we had difficulty linking any assumptions to specific evidentiary support .

the other 23 assumptions did not have evidence to which the assumptions could be fully traced , though the cost estimation team provided verbal explanations for the assumptions .

when we interviewed the subject matter specialists who developed the assumptions , they provided us with the research and information they used to develop their assumptions .

however , for 10 assumptions , data provided by subject matter specialists did not include minimum and maximum inputs or had been changed by the cost estimation team .

the cost estimation team did not record how and why it changed assumptions that were provided to it , how the range was determined if specialists had not provided a range , or specific sources of support for assumptions that were said to be 2010 actual census numbers , 2010 assessments , or management decisions .

according to standards for internal control in the federal government , management should design control activities to achieve objectives .

however , the bureau had no guidance for how the cost team was supposed to handle information provided to it .

in particular , the cost estimation team had no clear guidance for determining when to adjust or augment information provided to it .

nor did the team have procedures for recording its adjustments or their justification .

when we found that data in the cost model differed from what subject matter specialists provided , we were unable to determine why it differed and , in some cases , neither could the cost estimation team .

lack of a record of how and why changes were made introduces uncertainty as to the origin and credibility of the numbers in the cost estimate .

additionally , a lack of information on these changes makes it difficult to determine the significance or impact of the changes .

according to the cost estimation team , six of the assumptions were based on management decisions , such as staffing ratios for field operations , but the cost team could not provide documentation of these decisions .

the cost team said seven assumptions were based on “2010 actual” data and related assessments or from previously developed preliminary cost estimates .

for example , they said they used operational data ( such as 2010 nrfu pay rates ) and assessments of the 2010 census ( such as the 2010 address canvassing operational assessment ) to develop assumptions .

we tried to independently verify these assumptions but could not .

we asked the cost estimation team for the source or citation to the actual historical data or assessments that the team may have relied on , but it could not provide them .

in several cases the team instead directed us to the bureau's 2011 estimate .

documentation of that earlier estimate also referred to the 2010 census ( and assessments ) as a primary source , but did not provide specific citations or traceable references .

without support for these assumptions we cannot determine if they are in fact realistic and valid or if they are based on historical data .

the bureau identified 158 different project - level risks for the 2020 census .

for example , these risks include delays in the acquisition of imagery needed to help build the bureau's national address list , and schedule delays in the delivery of information technology systems .

the bureau ranked its project - level risks on a scale of potential impact in five different areas , including cost .

about 35 percent of the risks were identified as having a potential impact of at least “3” on a 5-point scale , equivalent to a potential cost impact of greater than or equal to 5 percent .

 ( bureau guidance does not specify against what cost element this impact rating potentially applies. ) .

of the 158 project - level risks , bureau officials flagged 55 as having a significant potential impact on cost ( see figure 6 ) .

a review of our prior work and department of commerce inspector general reporting on the decennial census , as well as our interviews with national academies of science staff selected for their involvement in study panels of the 2020 census , did not identify any risks not already included in the bureau's list of risks .

the bureau designed and documented risk identification processes .

for example , it has a risk management plan laying out roles , responsibilities , and processes and staff receive training on it .

project teams working on implementation of the census design , and research teams preceding them , had requirements to identify and report on risks potentially affecting their areas .

additionally , the decennial directorate has guidance for generating ideas about risks through brainstorming .

this guidance was designed to help ensure inclusivity .

a broad list of identified risks can help provide a solid basis for assessing and mitigating the susceptibility of project implementation to uncertain conditions facing the decennial program .

this can help the bureau make informed decisions to help control cost .

standards for internal controls in the federal government call for management to document in its policies or day - to - day procedures the responsibilities needed to attain its objectives .

clear guidance on what risks are being accounted for and how those are communicated through the cost estimation process will help ensure that resulting cost estimates reflect the best information available .

one of the objectives of a robust cost estimation process is to determine the uncertainty of the cost estimate with an understanding of how much of that uncertainty is introduced by significant risks .

this includes knowing what risks , if any , have been accounted for as part of any supporting sensitivity analysis or later management evaluation of risk and uncertainty .

however , we found the bureau had no guidance , policies , or procedures in place on how to account for risk , develop boundaries around key assumptions , or determine contingencies .

furthermore , subject matter specialists did not receive training or other guidance on what risks , if any , they were to consider as part of their support of the cost estimation process ; how to incorporate , document , or communicate what they had accounted for ; or how they would account for uncertainty within the assumptions .

in addition , specialists used a variety of methods to account for risk and uncertainty in the cost assumptions they were responsible for , but there was no standard methodology for doing this .

for example , one specialist reported providing the calculated standard deviations resulting from the supporting statistical analysis to the cost estimation team , assuming that the core estimation team would set ranges around the provided value according to whatever methodology the team used .

another reported setting the submitted parameter “conservatively” and described wanting to “include a buffer” or contingency so that the cost in that area was not estimated too low .

varying treatments of uncertainty , contingencies , or risk can make it difficult to determine later what risk has been fully accounted for already within cost estimates .

some of the subject matter specialists we spoke with had contributed directly to the identification of various risks within the bureau's risk management process , and they said that they had some of those in mind when determining ranges for assumptions they provided .

however , none had reviewed the range of risks covered in the 2020 census program or project risk registers when doing so or had communicated any risks that they may have considered to the cost estimation team .

none reported having received guidance or direction on what risk lists , if any , to consider .

the cost estimation team said that it was aware of the risk registers , but had not consulted them .

it also reported not having examined specific risks directly for accounting in the cost model .

the cost estimation team also said that it was unaware whether or what risk subject matter specialists may have considered ; what the basis for the range between minimum , value , and maximum inputs provided to it on each assumption may have been , or to what extent some specialists had already built contingency for general uncertainty into the data the specialist provided .

the absence of procedures for the cost estimation team and subject matter specialists could have led to the over - specification of some uncertainty around the cost estimates we observed , or to missing the potential impact of some key risks .

the bureau had mechanisms in place to make its identified risks known within the agency .

for example , the bureau's office of risk management and program evaluation told us that the bureau made available to bureau project managers — including some of the subject matter specialists — an online “risk dashboard” presenting risks documented across agency projects .

this is intended to function as a communication tool , increasing risk visibility across project teams .

yet according to bureau officials , the bureau relied on its certified cost estimators to account for risks and did not have requirements that they specifically consider these tools or the risk registers .

improved control over which risks and uncertainty are accounted for in cost estimates will better position bureau managers to know which risks among those the bureau has separately identified have or have not already contributed to the bureau's measured uncertainty in its cost estimate , and to know how much resources , if any , may thus be worth allocating to mitigate specific risks in order to control cost .

controls that can help with this accounting may include the implementation of processes or methods , for example institutionalized in the form of clearly documented guidance for those involved .

in the absence of such accounting , management cannot be confident that ( 1 ) the contingency it selected is adequate to cover significant risks in its risk registers , or ( 2 ) the selected contingency is not overly conservative , which ties up funding that could be allocated to other projects .

in order for the bureau to improve its ability to control the cost of the 2020 census , it will be critical for it to have better control over its cost estimation process .

according to bureau officials , an example of the steps they have taken to improve their cost estimation capabilities is the recent implementation of a software upgrade they believe has better positioned them to deliver a quality cost estimate .

while the bureau has taken significant steps toward improving its capacity to produce reliable cost estimates , those efforts have not yet resulted in a reliable decennial cost estimate .

among the four broad characteristics of a reliable cost estimate — none of which the bureau fully met — the bureau has reported it is focusing its attention on improving the documentation of the cost estimate , in order to help improve other characteristics as well .

while poor documentation has affected our ability to assess the reliability of the bureau's cost estimate's other characteristics , we believe the problems we observed relate to an absence of internal control procedures over the cost estimation process , which in turn have resulted in the weakness in documentation .

in june 2008 we recommended the bureau establish guidance , policies , and procedures for conducting cost estimation that would meet best practices criteria .

in response , the bureau agreed with the recommendation and said at the time that it already had efforts underway to improve its future cost estimation methods and systems .

eight years later , the absence of guidance to control the cost estimation process persists .

investment in the planning documents to help control and support cost estimation early in the estimation cycle , such as with an operational plan , guidance on key steps and process flows , assignment of responsibilities , and job aids for staff can help institutionalize practices and ensure that otherwise disparate parties in the process operate consistently .

we continue to believe that establishing guidance , policies and procedures could help the bureau incorporate the four characteristics of reliable cost estimates into future updates to the 2020 life - cycle cost estimate .

further , taking steps to ensure its cost estimate is reliable would help improve decision making , budget formulation , progress measurement , course correction when warranted , and accountability for results .

following the specific steps laid out in the four characteristics discussed in this report would position the bureau to produce a reliable cost estimate for the 2020 census .

in addition , we found that the cost estimation team did not record how and why it changed assumptions that were provided to it or traceable sources of all data it used .

the bureau lacked written guidance and procedures for the cost estimation team to follow .

clear guidance on when information for cost assumptions can and should be changed as well as the procedures for documenting such changes and traceable sources for information being used can reduce uncertainty on where data are coming from and improve their credibility .

finally , the bureau had risk management processes for identifying a broad range of risks that could affect the cost of the 2020 census .

yet this institutional awareness of risk was not fully leveraged in the bureau's cost estimation process .

as a result , the bureau is unable to determine with confidence what risks the bureau with its $12.5 billion cost estimate is prepared to mitigate or address .

the bureau determined that it is “80 percent” confident that its cost estimate will cover the actual cost of the 2020 census , but given the inability to know what risk is accounted for , we do not see how the bureau can be that sure .

the department of commerce will soon release its independent cost estimate as well as results of its reconciliation with the 2020 census program estimate as part of its budget formulation process .

whether the independent estimate is higher or lower than the $12.5 billion estimate , the concerns we have raised about management attention to cost estimation remain .

improving control over how risk and uncertainty are accounted for and communicated with the bureau's decennial cost estimation process , such as by implementing and institutionalizing processes or methods with clear guidance , will improve bureau and congressional confidence that the bureau's budgeted contingencies are at appropriate levels .

we recommend that the secretary of commerce and under secretary for economic affairs direct the census bureau to take the following actions: 1 .

to help ensure the bureau produces a reliable cost estimate for the 2020 census , take the following steps to meet the characteristics of a high - quality estimate: comprehensive — among other practices , ensure the estimate includes all life - cycle costs and documents all cost - influencing assumptions .

well - documented — among other practices , ensure that its planned documentation plan captures the source data used ; contains the calculations performed and the estimating methodologies used for each element ; and describes step by step how the estimate was developed .

accurate — among other practices , ensure the estimating technique for each cost element is used appropriately and that variances between planned and actual cost are documented , explained , and reviewed .

credible — among other practices , ensure the estimate includes a sensitivity analysis , major cost elements are cross - checked to see whether results are similar , and an independent cost estimate is conducted to determine whether other estimating methods produce similar results .

2 .

to further ensure the credibility of data used in cost estimation , establish clear guidance on when information for cost assumptions can and should be changed as well as the procedures for documenting such changes and traceable sources for information being used .

3 .

to ensure bureau and congressional confidence that the bureau's budgeted contingencies are at appropriate levels , improve control over how risk and uncertainty are accounted for and communicated with the bureau's decennial cost estimation process , such as by implementing and institutionalizing processes or methods for doing so with clear guidance .

we provided a draft of this report to the secretary of the department of commerce for comment .

in written comments , reproduced in appendix ii , the department of commerce agreed with our recommendations .

it also provided additional context that we incorporated , as appropriate .

the department of commerce also noted that while it fully recognizes the census bureau can further improve its process under the cost estimating and assessment guide as well as the standards for internal control in the federal government , it stands behind the quantitative integrity of the current life - cycle cost estimates for the 2020 census .

we maintain that the process used to develop a cost estimate is key to its quantitative integrity .

unless and until the bureau develops a cost estimate that fully reflects the characteristics of a high - quality estimate such as being comprehensive , well - documented , accurate , and credible , the estimate itself cannot be considered reliable .

we are sending copies of report to the secretary of commerce , the counselor to the secretary with delegated duties of the undersecretary of commerce for economic affairs , the director of the u.s. census bureau , and interested congressional committees .

the report also will be available at no charge on gao's website at http: / / www.gao.gov .

if you have any questions about this report please contact me at ( 202 ) 512-2757 or goldenkoffr@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

the gao staff that made major contributions to this report are listed in appendix iii .

the purpose of our review was to evaluate the reliability of the census bureau's ( bureau ) life - cycle cost estimate using our cost estimating and assessment guide ( gao - 09-3sp , or gao cost guide ) .

we reviewed ( 1 ) the extent to which the bureau's life - cycle cost estimate met our best practices for cost estimation ; ( 2 ) the extent to which the bureau's key cost assumptions were supported by field tests , prior studies , and other evidence - based analysis ; and ( 3 ) the extent to which the bureau has identified and accounted for key risks facing the 2020 census within its risk and uncertainty analyses of its life - cycle cost estimate .

for all objectives , we reviewed documentation from the bureau on the 2020 life - cycle cost estimate .

for the first objective , we relied on the cost guide as criteria .

for the cost guide , our cost specialists assessed measures consistently applied by cost - estimating organizations throughout the federal government and industry and considered best - practices for the development of reliable cost - estimates .

we analyzed the cost estimating practices used by the bureau against these best practices and evaluated them in four categories: comprehensive , well - documented , accurate , and credible .

comprehensive: the cost estimate should include both government and contractor costs of the program over its full life - cycle , from inception of the program through design , development , deployment , and operation and maintenance to retirement of the program .

it should also completely define the program , reflect the current schedule , and be technically reasonable .

comprehensive cost estimates should be structured in sufficient detail to ensure that cost elements are neither omitted nor double - counted .

specifically , the cost estimate should be based on a product - oriented work breakdown structure ( wbs ) that allows a program to track cost and schedule by defined deliverables , such as hardware or software components .

finally , where information is limited and judgments are made , the cost estimate should document all cost - influencing assumptions .

well - documented: a good cost estimate — while taking the form of a single number — is supported by detailed documentation that describes how it was derived and how the expected funding will be spent in order to achieve a given objective .

therefore , the documentation should capture in writing such things as the source data used , the calculations performed and their results , and the estimating methodology used to derive each wbs element's cost .

moreover , this information should be captured in such a way that the data used to derive the estimate can be traced back to and verified against their sources so that the estimate can be easily replicated and updated .

the documentation should also discuss the technical baseline description and how the data were normalized .

finally , the documentation should include evidence that the cost estimate was reviewed and accepted by management .

accurate: the cost estimate should provide for results that are unbiased , and it should not be overly conservative or optimistic .

an estimate is accurate when it is based on an assessment of most likely costs , adjusted properly for inflation , and contains few , if any , minor mistakes .

in addition , a cost estimate should be updated regularly to reflect significant changes in the program — such as when schedules or other assumptions change — and actual costs , so that it is always reflecting current status .

during the update process , variances between planned and actual costs should be documented , explained , and reviewed .

among other things , the estimate should be grounded in a historical record of cost estimating and actual experiences on other comparable programs .

credible: the cost estimate should discuss any limitations of the analysis because of uncertainty or biases surrounding data or assumptions .

major assumptions should be varied , and other outcomes recomputed to determine how sensitive they are to changes in the assumptions .

risk and uncertainty analysis should be performed to determine the level of risk associated with the estimate .

further , the estimate's cost drivers should be cross - checked , and an independent cost estimate conducted by a group outside the acquiring organization should be developed to determine whether other estimating methods produce similar results .

if any of the characteristics are not met , minimally met , or partially met , then the cost estimate does not fully reflect the characteristics of a high - quality estimate and cannot be considered reliable .

for the second objective we inventoried cost assumptions documented by the bureau in support of its october 2015 life - cycle cost estimate and identified those associated with major changes from the bureau's historical census design and with significant cost - saving potential .

additionally , we assessed the reliability of key assumptions by determining to what extent they are based on prior bureau experience and testing , such as related results of the 2014 and 2015 census tests and other historical support .

finally , for the third objective , we analyzed the bureau's project and program risk registers and leveraged prior gao work in this area to determine the range of risks and the adequacy of the bureau's uncertainty analysis .

we relied on our cost assessment guide and our standards for internal control in the federal government as criteria .

we conducted this performance audit from november 2015 to june 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

gao , standards for internal control in the federal government .

gao - 14-704g ( washington , d.c.: sept. 10 , 2014 ) .

in addition to the contact named above , ty mitchell , assistant director ; brian bothwell ; brett caloia ; robert gebhart ; jason lee ; andrea levine ; donna miller ; cynthia saunders ; and timothy wexler .

