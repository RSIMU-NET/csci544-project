drug court programs were established beginning in the late 1980s as a local response to increasing numbers of drug - related cases and expanding jail and prison populations nationwide .

a drug court is a specialized court - based program that targets criminal offenders who have alcohol and other drug addiction and dependency problems .

drug courts have implemented deferred prosecution or post - adjudication case - processing approaches , or have blended both in their organizational structures .

in drug courts using deferred prosecution , defendants waive rights to a trial and enter a treatment program shortly after being charged ; those who subsequently fail to complete the treatment program have their charges adjudicated , while those who complete the program are not prosecuted further , or have their charges dismissed .

in post - adjudication case processing , defendants are tried and convicted , but either have deferred sentences or suspensions of incarceration until they complete or withdraw from the treatment program .

the first approach offers individuals the opportunity to obtain treatment and avoid the possibility of a felony conviction , while the second provides a rehabilitation incentive because treatment progress is factored into the sentencing determination .

as of june 2010 , there were over 2,500 drug courts operating throughout the united states , of which about 1,400 of these target adult offenders .

drug courts are generally based on a comprehensive model involving  monitoring ( eg , drug testing ) and supervision ;  graduated sanctions and incentives ; and treatment services .

the department of justice ( doj ) , through its office of justice programs' ( ojp ) bureau of justice assistance ( bja ) , administers the adult drug court discretionary grant program , which provides financial and technical assistance to states , state courts , local courts , units of local government , and indian tribal governments to develop and implement drug treatment courts .

the total amount bja has awarded in grants through the program increased from about $2 million in fiscal year 2006 to $29 million in fiscal year 2010 , and the number of grants it has awarded during the same period increased 588 percent .

pursuant to the government performance and results act ( gpra ) , doj requires applicants that receive funding through the program to provide data that measure the results of their work .

in april 2002 , we reported that doj had not sufficiently managed its efforts to collect performance measurement and outcome data from federally funded drug courts .

we recommended that doj take actions to address these concerns , and doj agreed with our recommendations and took actions in response .

appendix i provides information on the status of these recommendations .

in february 2005 , we studied drug courts again and reported that in most of the 27 drug - court program evaluations we reviewed , adult drug - court programs led to recidivism reductions — that is , reductions in new criminal offenses — during periods of time that generally corresponded to the length of the drug court program .

we also reported that the evidence about the effectiveness of drug court programs in reducing participants' substance - use relapse was limited and mixed .

this report responds to the fair sentencing act of 2010 , which directed gao to report on drug court programs .

we briefed your offices on our preliminary results on july 18 , 2011 .

this report includes our final results related to the following questions: ( 1 ) what data does doj collect on the performance of federally funded adult drug courts , and to what extent has it used these data in making grant related decisions ? .

and ( 2 ) what is known about the effectiveness of adult drug courts in reducing recidivism and substance - abuse relapse rates , and what are the costs and benefits of adult drug courts ? .

in addition , appendix i of this report provides information on the extent to which doj has addressed the recommendations that we made in 2002 regarding drug court programs .

to address the first question , we analyzed: the reporting guidance and requirements that bja provided in fiscal years 2007 through 2011 to grantees applying for adult drug court discretionary grant program funds ; bja - generated grantee performance data reports from october to december 2010 ; and bja's guides for managing grants and enforcing grantee compliance that were issued in fiscal year 2011 .

we selected 2007 as the starting point for our review because bja implemented its performance measurement tool ( pmt ) — an online reporting tool that supports bja grantees' ability to collect , identify , and report performance measurement data activities funded by the award — in fiscal year 2007 .

we also reviewed our prior reports and internal control standards as well as other academic literature regarding effective performance management practices .

further , we interviewed cognizant bja officials about the extent to which they use grantees' performance data when engaging in these management activities , any challenges faced with ensuring grantee compliance , ongoing efforts to revise program performance metrics , and the extent to which bja's revisions incorporate best practices we previously identified .

to address the second question , we conducted a systematic review of evaluations of drug court program effectiveness issued from february 2004 through march 2011 to identify what is known about the effect of drug court programs on the recidivism of and relapse of drug involved individuals as well as the costs and benefits of drug courts .

we also reviewed doj's national institute of justice ( nij ) - funded multi - site adult drug court evaluation ( madce ) , a 5-year longitudinal process , impact , and cost evaluation of adult drug courts that was issued in june 2011 , a summary of which we provide in appendix ii .

we identified the universe of evaluations to include in our review using a three - stage process .

first , we identified evaluations by searching databases and web sites .

second , we selected evaluations of adult drug court programs in the united states that report recidivism , substance use relapse , and / or costs and benefits .

third , we screened the selected studies to determine whether each met criteria for methodological soundness based on generally accepted social science principles or cost - benefit analysis criteria .

from more than 260 studies in our initial group , we assessed the findings of 44 studies that met our criteria and reported on the effectiveness of 32 drug court programs or sets of programs .

see appendix iii for additional details on our scope and methodology .

we conducted this performance audit from november 2010 through december 2011 in accordance with generally accepted government - auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our objectives .

drug court programs are designed to address the underlying cause of an offender's behavior — alcohol , drug addiction , and dependency problems .

drug court programs share several general characteristics but vary in their specific policies and procedures because of , among other things , differences in local jurisdictions and criminal justice system practices .

in general , judges preside over drug court proceedings , which are called status hearings ; monitor offenders' progress with mandatory drug testing ; and prescribe sanctions and incentives as appropriate in collaboration with prosecutors , defense attorneys , treatment providers , and others .

drug court programs vary in terms of the substance - abuse treatment required .

however , most programs offer a range of treatment options and generally require a minimum of 1 year of participation before an offender completes the program .

practices for determining defendants' eligibility for drug court participation vary across drug court programs , but typically involve screening defendants for their criminal history , current case information , whether they are on probation , and their substance use , which can include the frequency and type of use , prior treatment experiences , and motivation to seek treatment .

in 2005 , we reported that based on literature reviewed , eligible drug - court program participants ranged from nonviolent offenders charged with drug - related offenses who had substance addictions , to relatively medium risk defendants with fairly extensive criminal histories and who had failed prior substance - abuse - treatment experiences .

appendix iv presents additional information about the general characteristics of drug court programs .

as shown in appendix v , bja , in collaboration with the national association of drug court professionals ( nadcp ) , identified the key components , which describes the basic elements that define drug courts and offers performance benchmarks to guide implementation .

bja administers the adult drug court discretionary grant program to provide financial and technical assistance to states , state courts , local courts , units of local government , and indian tribal governments to develop and implement drug treatment courts .

through the adult drug court discretionary grant program , bja offers funding in four broad drug - court grant categories .

see appendix vi for a more detailed discussion on each of the following grant categories .

implementation grants: available to jurisdictions that have completed a substantial amount of planning and are ready to implement an adult drug court .

 enhancement grants: available to jurisdictions with a fully operational ( at least 1-year ) adult drug court .

 statewide grants: available for two purposes: ( 1 ) to improve , enhance , or expand drug court services statewide through activities such as training and / or technical assistance programs for drug court teams and ( 2 ) to financially support drug courts in local or regional jurisdictions that do not currently operate with bja adult drug court discretionary grant program funding .

joint grants: in fiscal year 2010 , bja , in collaboration with the department of health and human services , substance abuse and mental health services administration ( samhsa ) , offered a joint grant program for the enhancement of adult drug court services , coordination , and substance - abuse treatment capacity .

from fiscal years 2006 through 2010 , congress appropriated about $120 million for doj's administration of all drug court programs .

of this amount , $76 million was used for the adult drug court discretionary grant program , which includes funding provided to grantees through the previously mentioned grant categories .

the grant award totals for the adult drug court discretionary grant program increased from $2 million in fiscal year 2006 to $29 million in fiscal year 2010 .

correspondingly , the number of adult drug court discretionary grant program awards increased from 16 in fiscal year 2006 to 110 in fiscal year 2010 — an increase of 588 percent , as shown in figure 1 .

with regard to drug courts' effectiveness , however , drug courts have been difficult to evaluate because they are so varied , and the resources required to conduct a study that would allow conclusions about the effectiveness of drug courts can be substantial .

in particular , while drug courts generally adhere to certain key program components , drug courts can differ in factors including admission criteria , type and duration of drug treatment , degree of judicial monitoring and intervention , and application of sanctions for noncompliance .

in february 2005 , we studied drug courts and reported that in most of the 27 drug - court program evaluations we reviewed , adult drug court programs led to recidivism reductions during periods of time that generally corresponded to the length of the drug court program .

several syntheses of multiple drug court program evaluations , conducted in 2005 and 2006 , also concluded that drug courts are associated with reduced recidivism rates , compared to traditional correctional options .

however , the studies included in these syntheses often had methodological limitations , such as the lack of equivalent comparison groups and the lack of appropriate statistical controls .

bja collects an array of performance data from its adult drug court grantees through its performance measurement tool ( pmt ) and ojp's grants management system ( gms ) .

since fiscal year 2008 , bja has required grantees to submit quantitative performance data on a quarterly basis and qualitative performance information on a semi - annual basis .

the quantitative information grantees submit to bja varies depending on the type of grant awarded .

for example , information that bja can calculate based on what implementation grantees have been required to submit quarterly includes “the percent of drug court participants who exhibit a reduction in substance use during the reporting period,” “the percent of program participants who re - offended while in the drug court program,” and “the number and percent of drug court graduates.” information that bja can calculate based on what enhancement grantees have been required to submit includes “the increase in units of substance - abuse treatment services” and “the percent increase in services provided to participants.” in addition to the quarterly reporting of quantitative performance data , all adult drug court grantees must submit progress reports semi - annually .

as part of these progress reports , grantees provide qualitative or narrative responses to seven questions .

table 1 shows the seven questions to which grantees must submit narrative responses when completing their semi - annual reports .

bja officials told us that grant managers regularly review individual grantees' quarterly performance data and semi - annual progress reports and use this information to determine whether additional training or technical assistance could improve their performance .

however , according to bja officials , resource constraints in the past had prevented staff from fully analyzing the performance data bja collects from all adult drug court grantees — specifically the analysis of grantees' answers to the seven narrative questions — to identify more effective program approaches and processes to share with the drug court community .

in early fiscal year 2011 , bja officials initiated a new process called grantstat to maximize the use of performance information by leveraging the resources of other bja divisions , bja's training and technical assistance partners , its contractor , and other key stakeholders .

grantstat provides an analytical framework to assess grantee performance data and other relevant information on a semi - annual basis to determine the effectiveness of the grant programs in bja's portfolio .

in september 2011 , bja officials applied grantstat to a review of the adult drug court discretionary grant program .

as part of the process , they collected , reviewed , and analyzed performance data and other relevant information from a cohort of implementation grantees to determine the overall effectiveness of the adult drug court program and to identify grantees that might need additional technical assistance to improve their outcomes .

bja officials told us that as part of the grantstat review , they and their technical - assistance provider's staff reviewed selected implementation grantees' responses to the seven narrative questions and discussed common issues they each identified .

for example , bja identified that a number of grantees had lower - than - expected capacity because drug court stakeholders ( eg , district attorneys ) were referring fewer drug - involved defendants to these drug courts .

bja also reported reviewing and discussing other qualitative information , such as the training and technical assistance provider's site - visit reports , to determine grantees' fidelity to the 10 key components .

bja officials acknowledged that prior to grantstat , they had not leveraged the summary data that its technical assistance providers had previously compiled from grantees' narrative responses to these seven questions and indicated that future iterations of grantstat would continue to include both qualitative and quantitative performance data reviews .

our prior work has emphasized the importance of using performance data to inform key decisions and underscored that performance measures can be used to demonstrate the benefits of a program or identify ways to improve it .

in addition , we also have reported that effective performance measurement systems include steps to use performance information to make decisions .

in doing so , program managers can improve their programs and results .

recognizing that bja is working through grantstat to improve its use of performance data in managing the drug court program , we identified six management activities for which performance information can be most useful to decision makers and benchmarked bja's practices against them .

the six activities are: ( 1 ) setting program priorities , ( 2 ) allocating resources , ( 3 ) adopting new program approaches , ( 4 ) identifying and sharing with stakeholders more effective program processes and approaches , ( 5 ) setting expectations for grantees , and ( 6 ) monitoring grantee performance .

see appendix vii for the definition of the six management activities .

as illustrated in table 2 , bja has current and planned efforts underway across all six activities .

according to bja officials , after the grantstat review , they identified trends and developed several potential findings and action items for program design changes .

however , bja officials added that since the action items originated from grantstat's first review , they are not implementing them immediately .

instead , bja plans to evaluate the action items over the next 6 months to ensure they are feasible and effective alternatives for improving grantee outcomes .

we are encouraged by bja's recent efforts to regularly analyze grantee performance data to determine whether the program is meeting its goals .

we also are encouraged that bja is using this information to better inform its grant - related management activities , such as setting program priorities , identifying and sharing effective processes and approaches , and setting expectations for grantees .

during the course of our review , bja revised its adult drug court program performance measures to improve their reliability and usefulness .

bja provided us with the revised measures on october 28 , 2011 .

according to bja officials , unclear definitions of some of the previous measures confused grantees about what data elements they were expected to collect .

for example , officials told us that grantees may have been confused with how to measure “the number of participants admitted” and “the number of drug court participants.” specifically , bja officials added that their analysis of several years of data shows that some grantees reported the same number for these two measures , some grantees reported a higher number than were admitted , a few grantees reported a lesser number for the number of participants than the number admitted , and some grantees reported these two measures in each of these three ways over multiple reporting periods .

according to bja officials , such a wide degree of variability made these measures unreliable , and bja was thus hindered from comparing grantee performance data across grantee cohorts .

bja's performance measure revisions resulted in the following:  all grantees are required to report on “participant level” measures .

examples of these measures include the demographic make - up of their drug court participant populations , the amount of service provided to their participants , and the geographic location of their drug courts ;  enhancement , joint , and statewide grantees are required to report on participant level outcomes , such as graduation rates , to ensure consistency with measures bja collects from implementation grantees ;  measures previously excluded from the pmt , such as retention rates and outcomes of participants once they complete the drug court program , are now included ;  bja has established two sets of benchmarks as points of reference against which to gauge grantees' performance .

the first set of benchmarks requires a comparison of grantees' performance against averages of drug court performance derived from research .

the second set of benchmarks requires a comparison of grantees' performance to historical performance data reported to bja by adult drug court grantees ; and  bja revised the descriptions and the definitions of the measures to help ensure their clarity .

to revise the performance measures , bja officials consulted with technical assistance providers and a drug court researcher to discuss possible improvements to the performance measures , reviewed drug court literature , and reviewed and analyzed bja grantees' clarification and information requests to identify the most common problems adult drug court grantees historically experienced submitting performance information to bja .

in addition , bja obtained comments on the proposed measures from bja staff and other doj stakeholders , as well as enhancement , implementation , joint , and statewide grantees .

bja officials also invited all current grantees to participate in four teleconferences to obtain their feedback on the feasibility of collecting and reporting the new measures and their suggestions to improve the clarity of the measures' definitions and descriptions .

bja officials finalized the new measures in october 2011 and plan to closely monitor grantees' performance data submissions to ensure the reliability and usefulness of the measures and then revise as necessary after the first reporting period .

bja officials also stated that they expected to review the measures' overall reliability and validity after the first reporting period — october 1 , 2011 , through december 30 , 2011 .

bja officials reported that the revised measures will strengthen the reliability and improve the usefulness of grantee performance data in making grant - related decisions .

for example , bja officials stated that reliable and useful data would help them to identify the most effective grantees and common characteristics these courts share to inform the types of drug courts the officials choose to fund in future grant solicitations .

bja officials also reported that as a result of the revision , they expect to be able to conduct more sophisticated analyses using grantstat that are needed to inform grant - related decisions .

for example , bja officials told us that implementing benchmarks and participant level measures will enable the agency to compare similar drug courts ( eg , large - urban jurisdictions of similar size , demographic make - up , and geographic context ) to one another and across jurisdictions , thereby improving bja's understanding of grantees' impact on the populations they serve .

bja's process to revise its performance measures generally adhered to some of the key practices that we have identified as important to ensuring that measures are relevant and useful to decision - making .

these key practices included obtaining stakeholder involvement and ensuring that the measures have certain key attributes , such as clarity .

the key practices also describe the value of testing the measures to ensure that they are credible , reliable and valid and documenting key steps throughout the revision process .

however , bja could take actions to improve its efforts in these two areas .

for instance , bja officials told us that after the grantees' first reporting period concludes , they plan to assess the data that grantees submitted to ensure that the measures produce reliable and useful data over at least the first quarter of fiscal year 2012 .

they stated that if necessary , at that point they will then further revise the measures .

nevertheless , bja officials have not documented how they will determine if the measures were successful or whether changes would be needed .

in addition , bja officials did not record key methods and assumptions used to guide their revision efforts , such as the feedback stakeholders provided and bja's disposition of these comments .

for example , bja officials provided a document generally showing the original performance measure ; whether it was removed , revised or replaced ; and bja's justification for the action , but this document did not demonstrate how bja had incorporated the stakeholder feedback it considered when making its decisions .

the document also did not include a link to a new performance measure in instances where an older one was being replaced .

further , bja's justification did not include the rationale for the changes it made to 22 of the 51 performance measures .

according to bja officials , they did not document their decisions in this way because of the rapid nature of the revision process and limited staff resources .

they also told us that maintaining such documentation and providing it to stakeholders held little value .

our previous work has shown the importance of documentation to the successful development of effective performance measures .

in the past , we have reported that revising performance measures involves a number of aspects needing to be carefully planned and carried out and that by documenting the steps undertaken in developing and implementing the revised measures , agencies can be better assured their revisions result in effective performance measures .

in addition , academic literature on the best practices for developing effective performance measures states that agencies should develop products to document and guide their revision efforts .

these products , among other things , can include plans for ensuring the quality and integrity of the data for full - scale implementation of the measures .

further , standards for internal control in the federal government call for clear documentation of significant events , which can include assumptions and methods surrounding key decisions , and this documentation should be readily available for examination .

as bja moves forward in assessing the revised measures and implementing additional changes , if it deems necessary , bja could better ensure that its efforts result in successful and reliable metrics and are transparent by documenting key methods used to guide revision efforts and an assessment of its measures .

this would also help bolster the integrity of its decisions .

in the evaluations we reviewed , adult drug - court program participation was generally associated with lower recidivism .

our analysis of evaluations reporting recidivism data for 32 programs showed that drug court program participants were generally less likely to be re - arrested than comparison group members drawn from the criminal court system , although the differences in likelihood were reported to be statistically significant in 18 programs .

across studies showing re - arrest differences , the percentages of drug court program participants rearrested were lower than for comparison group members by 6 to 26 percentage points .

one program did not show a lower re - arrest rate for all drug - court program participants relative to the comparison group within 3 years of entry into the program , although that study did show a lower re - arrest rate for drug court participants who had completed the program than for members of the comparison group .

in general , the evaluations we reviewed found larger differences in re - arrest rates between drug - court program completers and members of the comparison group than between all drug - court program participants and the comparison group members .

the rearrest rates for program completers ranged from 12 to 58 percentage points below those of the comparison group .

the completion rates reported in the evaluations we reviewed ranged from 15 percent to 89 percent .

included among the evaluations we reviewed was the madce , a 5-year longitudinal process , impact , and cost evaluation of adult drug courts .

the madce reported a re - arrest rate for drug court participants that was 10 percentage points below that of the comparison group ; specifically , 52 percent of drug court participants were re - arrested after the initiation of the drug court program , while 62 percent of the comparison group members were re - arrested .

however , the 10 percentage point difference between these rearrest rates for the samples of drug court participants and comparison group members was not statistically significant .

the madce study also reported that drug court participants were significantly less likely than the comparison group to self - report having committed crimes when they were interviewed 18 months after the baseline ( 40 percent vs. 53 percent ) , and drug court participants who did report committing crimes committed fewer than comparison group members .

we assigned a numerical rating to each evaluation to reflect the quality of its design and the rigor of the analyses conducted .

our methodology for rating the evaluation studies is detailed in appendix iii .

after assigning the rating , we grouped the studies into two tiers .

tier 1 studies were the most carefully designed and incorporated substantial statistical rigor in their analyses .

tier 2 studies , while still meeting our basic criteria for methodological soundness , were relatively less rigorous in their design and analyses .

both tier 1 and tier 2 studies reported differences between drug court participants and comparison group members and both sets of studies found that some but not all differences were statistically significant .

table 3 shows whether a difference in recidivism rates was reported for each program — expressed as the difference in the rate of re - arrest between all drug court program participants and the comparison group .

in some cases the difference in recidivism was reported as something other than a difference in the re - arrest rate , such as a difference in the number of arrests or the relative odds of an arrest .

in those cases , table 3 notes that a difference was reported , but does not include the difference in re - arrest rates .

for example , the evaluation of the queens misdemeanor treatment court reported that the re - arrest rate for program participants was 14 percentage points lower than the re - arrest rate of comparison group members up to 2 years after participants entered into the program , and 10 percentage points lower at 3 or more years after entry .

similarly , the evaluation of the hillsborough county adult drug court reported a statistically significant difference in the relative odds of an arrest after drug court program enrollment but did not report the difference in rearrest rates , therefore table 3 indicates a statistically significant reduction in rearrest rates but does not show the difference in rates .

the evaluations we reviewed showed that adult drug - court program participation was also associated with reduced drug use .

our analysis of evaluations reporting relapse data for eight programs showed that drug court program participants were less likely than comparison group members to use drugs , based on drug tests or self - reported drug use , although the difference was not always significant .

this was true for both within - program and post - program measures , and whether drug use was reported as the difference in the frequency of drug use or the proportion of the treatment and comparison groups who used drugs .

the madce concluded drug courts produce significant reductions in drug relapse .

specifically , madce reported that “drug court participants were significantly less likely than the comparison group to report using all drugs ( 56 vs. 76 percent ) and also less likely to report using ‘serious' drugs ( 41 vs. 58 percent ) , which omit marijuana and ‘light' alcohol use ( fewer than four drinks per day for women or less than five drinks per day for men ) .

on the 18-month oral fluids drug test , significantly fewer drug court participants tested positive for illegal drugs ( 29 vs. 46 percent ) .

further , among those who tested positive or self - reported using drugs , drug court participants used drugs less frequently than the comparison group.” regarding post - drug court program relapses , the madce concluded that participation in drug court — along with less frequent drug use among offenders prior to arrest , and the absence of mental health problems — were the strongest predictors of success against relapses .

table 4 summarizes the results of drug - use relapse reported in the evaluations we reviewed .

of the studies we reviewed , 11 included sufficient information to report a net benefit figure .

of these studies , the net benefit ranged from positive $47,852 to negative $7,108 per participant .

the net benefit is the monetary benefit of reduced recidivism accrued to society from the drug court program through reduced future victimization and justice system expenditures , less the net costs of the drug court program — that is , the cost of the program less the cost of processing a case in criminal court .

a negative net benefit value indicates that the costs of the drug court program outweigh its estimated benefits and that the program was not found to be cost beneficial .

eight of the studies reported positive net benefits — the benefits estimated to accrue from the drug court program exceeded the program's net costs .

three of the 11 studies reported negative net benefits .

we did not attempt to determine whether the differences in the reported values were because of differences in study methodology or the attributes of the drug courts themselves .

the environment in which the drug court operates may also be important .

for example , the largest net benefit reported was for kings county , in which members of the comparison group were incarcerated , in contrast to other programs in which members of the comparison group were given probation , which is less costly .

the more costly the alternative , such as incarceration , the more likely a drug court will have positive net benefits .

in this case , the study reported that society would accrue $47,852 in benefits relative to conventional court processing .

table 5 below shows whether , based on the available information , the study was shown to be cost beneficial .

it also shows the net benefits per participant of the drug court study .

for example , madce found that the drug court participants led to a net benefit of $6,208 per participant — within the range of the other studies .

the madce analysis of costs and benefits is discussed further in appendix ii .

during the course of our review , bja made strides in managing its adult drug court program , including implementation of the grantstat process and recent revisions to the grantee performance measures .

given that bja has committed to testing its new measures during this first grantees' reporting period , enhancements could be made to facilitate this assessment .

by documenting how it plans to assess the measures and determine any changes that may be needed and providing the rationale for future revisions , bja could bolster the transparency and integrity of its decisions .

doing so could also improve the reliability of the data it collects , its usefulness to managers in guiding the program , and the success of its measures .

recognizing that bja has recently revised the adult drug - court performance measures and has plans to assess their utility , we recommend that bja's director take the following action to ensure that its revision process is transparent and results in quality and successful metrics to inform management's key decisions on program operations:  document key methods used to guide future revisions of its adult drug - court program performance measures .

this documentation should include both a plan for how bja will assess the measures after conclusion of the grantees' first reporting period and a rationale for why each measure was refined , including a discussion of the scope and nature of any relevant stakeholder comments .

we provided a draft of this report to doj for review and comment .

on december 1 , 2011 , we received written comments on the draft report from doj , which are reproduced in full in appendix viii .

doj concurred with our recommendation and described actions under way or planned to address the recommendation .

doj also provided technical comments , which we incorporated as appropriate .

doj stated that bja will continue to document grantee feedback and will ensure that revisions to the measures are documented in accordance with gao's best practices standards .

in particular , doj stated that bja will document ( 1 ) whether the name and definition of the measure is consistent with the methodology used to calculate it ; ( 2 ) whether the measure is reasonably free from bias ; ( 3 ) whether the measure meets the expectation of the program ; and ( 4 ) its rationale for why each performance measure was refined , including the scope and nature of any relevant stakeholder comments .

we believe that such actions would improve the reliability of the information collected , its usefulness to managers in making key decisions on program operations , and the success of its measures .

we are sending copies of this report to the attorney general and interested congressional committees .

in addition , this report will be available at no charge on the gao web site at http: / / www.gao.gov .

should you or your staff have any questions concerning this report , please contact me at ( 202 ) 512-9627 or by e - mail at maurerd@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix ix .

the following provides the current status of the seven recommendations we made in 2002 — which have since been closed — on doj's collection of performance data .

specifically , doj has fully implemented six of them and partially implemented one .

doj has plans to fully address the remaining recommendation related to analyzing performance and outcome data collected from grantees and reporting annually on the results .

table 6 reflects this status .

nij's madce was conducted by the urban institute , center for court innovation , and research triangle institute .

data were collected from 1156 drug court participants in 23 different drug courts in 7 geographic clusters and from a comparison group of 625 drug - involved offenders in six different sites in four geographic clusters .

data collected included: three waves of interviews ; drug tests ; administrative records on treatment , arrests , and incarceration ; court observation and interviews with staff and other stakeholders ; and budget and other cost information .

the evaluation was designed to address the following four questions: ( 1 ) do drug courts reduce drug use , criminal behavior , and other associated offender problems ? .

 ( 2 ) do drug courts generate cost savings for the criminal justice system and other public institutions ? .

 ( 3 ) are drug courts especially effective or less effective for certain categories of offenders or program characteristics ? .

 ( 4 ) which drug court policies and offender perceptions explain their overall impact ? .

the madce's major findings can be summarized as follows:  drug courts produce statistically significant reductions in self - reported crime .

while both the drug court participants and comparison group participants reported large numbers of crimes in the year preceding the 18-month follow - up , drug court participants reported statistically significantly fewer than the comparison group members .

drug court participants were less likely than members of the comparison group to report committing any crimes ( 40 percent vs. 53 percent ) and drug court participants reported committing fewer crimes in the preceding 12 months than comparison group members ( 43 criminal acts vs. 88 criminal acts ) .

the difference between the two groups in the probability of an official re - arrest over 24 months was not statistically significant , though the percentage of individuals rearrested was lower for the drug court group than the comparison group ( 52 percent vs. 62 percent ) , as was the average number of re - arrests ( 1.24 vs. 1.64 ) .

 drug courts produce statistically significant reductions in drug use .

drug court participants were less likely than members of the comparison group to report using any drugs ( 56 percent vs. 76 percent ) and any serious drugs ( 41 percent vs. 58 percent ) , and less likely to test positively for drugs at the 18-month follow - up ( 29 percent vs. 46 percent ) .

furthermore , the large difference in self - reported relapse rates is evident at 6 months ( 40 percent vs. 59 percent ) , so the impact of drug courts on alcohol and other drug use is sustained .

the interview data also indicate that among the drug court participants and comparison group members that were using drugs , the drug court participants , on average , were using them less frequently .

 drug court participants reported some benefits , relative to comparison group members , in other areas of their lives .

at 18 months , drug court participants were statistically significantly less likely than comparison group members to report a need for employment , educational , and financial services , and reported statistically significantly less family conflict .

however , there were modest , non - significant differences in employment rates , income , and family emotional support , and no differences found in experiencing homelessness or depression .

 regardless of background , most offenders who participated in drug courts had better outcomes than offenders who were in the comparison programs .

however , the impact of drug courts was greater for participants with more serious prior drug use and criminal histories , and the impact was smaller for participants who were younger , male , african - american , or who had mental health problems .

 while the treatment and service costs were higher for drug court participants than treatment and service costs associated with the alternative “business - as - usual” comparison programs , drug courts save money through improved outcomes , according to the researchers , primarily through savings to victims resulting from fewer crimes and savings resulting from fewer re - arrests and incarcerations .

the authors of the study assert that their findings have strong internal validity — that is , that the findings were actually produced by the drug court programs — and external validity — that is , that the findings can be generalized to the population of all drug court participants and potential comparison group members .

the claim to strong internal validity is not without merit , given the high response rates , low attrition , propensity score adjustments , and conservative estimates produced by the hierarchical models used .

the claim of high internal validity is also supported by the sensitivity analyses undertaken for several outcomes using other models and methods of adjustments that produced little or no change in conclusions .

the claim to strong external validity , which relates to the generalizability of the results beyond the sample of courts and comparison sites and specific offenders considered , may be somewhat overstated .

the authors note that the 23 drug courts included in the study represent “a broad mix of urban , suburban , and rural courts from 7 geographic clusters nationwide,” but that doesn't assure that , collectively , the drug courts that were included resemble the hundreds of drug courts that were not included , especially since they were not chosen at random .

it also seems unlikely that the six comparison sites from four states are representative of all potential controls , or all alternative programs in all states , and it is potentially problematic that all of the selected sites , including drug court and comparison sites , were alike in their willingness and interest in participating .

those concerns notwithstanding , this is the broadest and most ambitious study of drug courts to date ; it is well done analytically ; and the results , as they relate to the impact of drug courts , are transparent and well described .

the madce cost benefit analysis approach differed from most of the other studies we reviewed .

in most of the other studies , the average cost and benefit of a drug court participant was compared to the average cost and benefit of normal court processing .

in contrast , the madce obtained a separate net benefit figure for each individual .

the net benefit was obtained by tracking each individual's use of resources , such as hearings or meetings with case managers , and program outcomes like use of public assistance .

the madce also tracked each individual's rates of re - arrest , number of crimes , and time of incarceration .

the crimes are multiplied by cost to victims per crime to obtain the cost to society .

the difference between the net benefits of the drug court participants and the comparison group were obtained using a hierarchical model similar to the one used for program outcomes .

after applying the method , the madce found that the drug court participants led to a net benefit of $6,208 to society per participant , as compared to the comparison group .

however , due to the variability in the estimate , the study did not find that the net benefits were statistically significant .

the lack of a statistically significant difference may be because of greater variability in the madce approach than the approach used in other studies .

specifically , the madce did not assume identical costs for each participant .

as a result , costs may be higher for individuals who have lower rates of re - arrest , perhaps because those individuals received more treatment .

according to the study's authors , by assuming identical costs for each participant , the standard approach understates the variance in the computed net benefit figure by not including the variability in cost .

however , the madce authors assumed that the prices of services were consistent across sites by using a weighted average .

in contrast , some studies generate site - specific cost figures .

in this way , the madce approach did exclude one source of variation that is present in some other studies .

in addition to tracking costs and benefits at the individual level , the madce also included some effects of drug court participation that some other studies omit .

this is consistent with omb guidance that states that studies should be comprehensive in the benefits and costs to society considered .

one of the benefits considered by the madce , sometimes omitted elsewhere , is the estimated earnings of the drug court participant .

however , it is unclear that the full value of earnings should have been considered a net benefit to society .

for example , to be comprehensive , a study should also consider the cost to society of providing that benefit .

the net benefit would account for the value of production from this employment less the wages paid .

although in this case , it is unlikely that this would affect the result of the analysis , as the earnings are similar for drug court participants and the comparison group .

to determine what data doj collects on the performance of federally funded adult drug courts and to what extent doj has used this data in making grant - related decisions , we analyzed the reporting guidance and requirements that bja provided in fiscal years 2007 through 2011 to grantees applying for adult drug court discretionary grant program funds ; bja - generated grantee performance data reports from october to december 2010 ; and bja's guides for managing grants and enforcing grantee compliance that were issued in fiscal year 2011 .

we selected 2007 as the starting point for our review because bja implemented its performance measurement tool ( pmt ) — an online reporting tool that supports bja grantees' ability to collect , identify , and report performance - measurement data activities funded by the grantees' awards — in fiscal year 2007 .

we also reviewed our prior reports and internal control standards as well as other academic literature regarding effective performance - management practices .

we then used this information and bja officials' statements to identify and define six management activities for which performance information can be most useful in making grant - related decisions .

further , we interviewed cognizant bja officials about the extent to which they use grantees' performance data when engaging in these management activities , any challenges faced with ensuring grantee compliance , ongoing efforts to revise program performance metrics , and the extent to which bja's revisions incorporate best practices we previously identified .

to determine what is known about the effectiveness of adult drug courts in reducing recidivism and substance - abuse relapse rates and what the costs and benefits of adult drug courts are , we conducted a systematic review of evaluations of drug - court program effectiveness issued from february 2004 through march 2011 to identify what is known about the effect of drug court programs on the recidivism of and relapse of drug - involved individuals as well as the costs and benefits of drug courts .

we also reviewed doj's nij - funded madce , a 5-year longitudinal process , impact , and cost evaluation of adult drug courts that was issued in june 2011 .

we identified the universe of evaluations to include in our review using a three - stage process .

first , we ( 1 ) conducted key - word searches of criminal justice and social science research databases ; ( 2 ) searched drug court program - related web sites , such as those of bja and nadcp ; ( 3 ) reviewed bibliographies , meta - analyses of drug court evaluations , and our prior reports on drug court programs ; and ( 4 ) asked drug court researchers and doj officials to identify evaluations .

our literature search identified 260 documents , which consisted of published and unpublished outcome evaluations , process evaluations , commentary about drug court programs , and summaries of multiple program evaluations .

second , we reviewed the 260 documents our search yielded and identified 44 evaluations that reported recidivism or substance use relapse rates using either an experimental or quasi - experimental design , or analyzed program costs and benefits .

third , we used generally accepted social science and cost benefit criteria to review the 44 evaluations .

to assess the methodological quality of evaluations that reported on recidivism or relapse rates , we placed each evaluation into one of five categories , with category 1 evaluations being the most rigorous and category 5 the least , as outlined in table 7 .

we excluded studies that were placed in category 5 in the table above or studies in which the comparison group was not drawn from a criminal court .

we were left with 33 studies , plus the madce , that reported on the effectiveness of 32 drug court programs or sets of programs .

as noted in our report , we then grouped the 34 studies , including the madce , into two tiers according to their quality category , tier 1 studies were those that fell into categories 1 or 2 , tier 2 studies were those that fell into categories 3 or 4 .

observed differences in recidivism could arise from measured and unmeasured sources of variation between drug court participants and comparison group members .

if comparison group members differed systematically from drug court participants on variables that are also associated with recidivism , such as the degree of their substance - abuse addiction problem and these variables were not accounted for by the design or analysis used in the evaluation , then the study could suffer from selection bias wherein observed differences in recidivism could be because of these sources of variation rather than participation in the drug court program .

as indicated in table 7 , our evaluation of the methods used to deal with selection bias was reflected in the quality categorization of each study .

to assess the methodological quality of evaluations that reported on drug court program costs and benefits , we assessed them according to the five criteria we developed and outlined in table 8 below .

we determined that an essential criterion for reporting a net benefit of drug courts was that the costs of the drug court were assessed against a baseline ( i.e. , “business - as - usual” or traditional court processing ) .

eleven studies met this essential standard and were used to report on program costs and benefits .

we excluded other studies not meeting this standard even though they may have met others .

to obtain information on our outcomes of interest — that is , recidivism , substance use relapse , and costs and benefits — we used data collection instruments to systematically collect information about the methodological characteristics of each evaluation , the drug court participants and comparison group members studied , and the outcomes of the participants and other comparable groups reported .

each evaluation was read and coded by a senior social scientist , statistician , or economist with training and experience in evaluation research methods .

a second senior social scientist , statistician , or economist then reviewed each completed data collection instrument to verify the accuracy of the information included .

part of our assessment also focused on the quality of the data used in the evaluations as reported by the researchers and our observations of any problems with missing data , any limitations of data sources for the purposes for which they were used , and inconsistencies in reporting data .

we incorporated any data problems that we noted in our quality assessments .

we selected the evaluations in our review based on their methodological strength ; therefore , our results cannot be generalized to all drug court programs or their evaluations .

although the findings of the evaluations we reviewed are not representative of the findings of all evaluations of drug court programs , the evaluations consist of those evaluations we could identify that used the strongest designs to assess drug - court program effectiveness .

to identify the extent to which doj has addressed the recommendations that we made in 2002 regarding drug court programs , we interviewed cognizant doj officials and obtained and reviewed documentation ( eg , drug - court program grant solicitations and grantee - performance reporting guidance ) on the actions taken to address and implement each of our prior recommendations .

we conducted this performance audit from november 2010 through december 2011 in accordance with generally accepted government - auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our objectives .

this appendix provides a general description of drug court program components ( see table 9 ) .

drug court programs rely on a combination of judicial supervision and substance - abuse treatment to motivate defendants' recovery .

judges preside over drug court proceedings , which are called status hearings ; monitor defendants' progress with mandatory drug testing ; and prescribe sanctions and incentives , as appropriate in collaboration with prosecutors , defense attorneys , treatment providers , and others .

drug court programs can vary in terms of the substance - abuse treatment required .

however , most programs offer a range of treatment options and generally require a minimum of about 1 year of participation before a defendant completes the program .

appendix v: ten key components of a drug court — developed by bja in collaboration with the national association of drug court professionals 1 .

integration of substance - abuse treatment with justice system case processing .

2 .

use of a non - adversarial approach , in which prosecution and defense promote public safety while protecting the right of the participant to due process .

3 .

early identification and prompt placement of eligible participants .

4 .

access to continuum of treatment , rehabilitation , and related services .

5 .

frequent testing for alcohol and illicit drugs .

6 .

a coordinated strategy governs drug court responses to participants' compliance .

7 .

ongoing judicial interaction with each participant .

8 .

monitoring and evaluation to measure achievement of program goals and gauge effectiveness .

9 .

continuing interdisciplinary education to promote effective planning , implementation , and operation .

10 .

forging partnerships among drug courts , public agencies , and community - based organizations generates local support and enhances drug court program effectiveness .

as mentioned , the adult drug court discretionary grant program provides financial and technical assistance to states , state courts , local courts , units of local government , and indian tribal governments to develop and implement drug treatment courts .

there are four different types of awards that bja makes to adult drug - court grantees through the program .

table 11 provides a description of the grant types .

how performance information may be used to support the activity performance information is used to set priorities in budgeting and to target resources .

agencies can also use this information to identify priorities on which to focus their efforts .

for example , targeting grants to address “underserved” client groups .

performance information is used to compare results of agencies' programs with goals and to identify where program resources should be targeted to improve performance and achieve goals .

when faced with reduced resources , such analyses can assist agencies' efforts to minimize the impact on program results .

performance information is used to assess the way a program is conducted and the extent to which a program's practices and policies have or have not led to improvements in outcomes .

such information is used to identify problems and consider alternative approaches and processes in areas where goals are not being met and to enhance the use of program approaches and processes that are working well .

performance information is used to identify and increase the use of program approaches that are working well and share these effective processes and approaches with stakeholders .

performance information is used to establish the targets and goals that grantees are expected to achieve .

these targets and goals can be used as the basis for corrective action ( eg , technical assistance , freezing of funds ) or to reward high performing grantees .

performance information is used to compare grantees' performance results with established targets and goals to determine the extent to which grantees have met them and , if necessary , target program resources ( eg , technical assistance ) to improve grantees' performance .

in addition to the contact named above , joy booth , assistant director and frederick lyles , jr. , analyst - in - charge , managed this assignment .

christoph hoashi - erhardt , michael lenington , and jerry seigler , jr. , made significant contributions to the work .

david alexander , benjamin bolitzer , michele fejfar , and doug sloane assisted with design and methodology .

pedro almoguera , carl barden , harold brumm , jr. , jean mcsween , cynthia saunders , jeff tessin , susan b. wallace , and monique williams assisted with evaluation review .

janet temko provided legal support , and katherine davis provided assistance in report preparation .

bouffard , jeffrey a. , and katie a. richardson .

“the effectiveness of drug court programming for specific kinds of offenders: methamphetamine and dwi offenders versus other drug - involved offenders.” criminal justice policy review , 18 ( 3 ) ( september 2007 ) : 274-293 .

carey , shannon m. , and michael w. finigan .

indiana drug courts: st. joseph county drug court program process , outcome and cost evaluation - final report .

portland , or: npc research , 2007 .

carey , shannon m. , and michael w. finigan .

indiana drug courts: vanderburgh county day reporting drug court process , outcome and cost evaluation - final report .

portland , or: npc research , 2007 .

carey , shannon m. , and michael w. finigan .

“a detailed cost analysis in a mature drug court setting: a cost - benefit evaluation of the multnomah county drug court.” journal of contemporary criminal justice , 20 ( 3 ) ( august 2004 ) : 315-338 .

carey , shannon m. , michael w. finigan , et .

al .

indiana drug courts: monroe county drug treatment court process , outcome and cost evaluation - final report .

portland , or: npc research , 2007 .

carey , shannon m. , michael finigan , dave crumpton , and mark s. waller .

“california drug courts: outcomes , costs and promising practices: an overview of phase ii in a statewide study.” journal of psychoactive drugs ( november 2006 ) .

carey , shannon m. , lisa m. lucas , mark s. waller , callie h. lambarth , robert linhares , judy m. weller , and michael w. finigan .

vermont drug courts: rutland county adult drug court process , outcome , and cost evaluation - final report .

portland , or: npc research , 2009 .

carey , shannon , and gwen marchand .

marion county adult drug court outcome evaluation - final report .

portland , or: npc research , 2005 .

carey , shannon m. and mark s. waller .

oregon drug court cost study: statewide costs and promising practices - final report .

portland , or: npc research , 2010 .

carey , shannon m. , and mark waller .

california drug courts: costs and benefits - phase iii .

portland , or: npc research , 2008 .

carey , shannon m. , and mark s. waller .

guam adult drug court outcome evaluation - final report .

portland , or: npc research , 2007 .

dandan , doria nour .

sex , drug courts , and recidivism .

university of nevada , las vegas: 2010 .

ferguson , andrew , birch mccole , and jody raio .

a process and site - specific outcome evaluation of maine's adult drug treatment court programs .

augusta , me: university of southern maine , 2006 .

finigan , michael w. , shannon m. carey , and anton cox .

impact of a mature drug court over 10 years of operation: recidivism and costs ( final report ) .

portland , or: npc research , 2007 .

gottfredson , denice c. , brook w. kearley , stacy s. najaka , and carlos m. rocha .

“how drug treatment courts work: an analysis of mediators.” journal of research in crime and delinquency , 44 ( 1 ) ( february 2007 ) : 3- 35 .

gottfredson , denice c. , brook w. kearley , stacy s. najaka , and carlos m. rocha .

“long - term effects of participation in the baltimore city drug treatment court: results from an experimental study.” journal of experimental criminology , 2 ( 1 ) ( january 2006 ) : 67-98 .

gottfredson , denice c. , brook w. kearley , stacy s. najaka , and carlos m. rocha .

“the baltimore city drug treatment court: 3-year self - report outcome study.” evaluation review , 29 ( 1 ) ( february 2005 ) : 42-64 .

krebs , c.p. , c.h .

lindquist , w. koetse , and p.k .

lattimore .

“assessing the long - term impact of drug court participation on recidivism with generalized estimating equations.” drug and alcohol dependence , 91 ( 1 ) ( november 2007 ) : 57-68 .

labriola , melissa m. the drug court model and chronic misdemeanants: impact evaluation of the queens misdemeanor treatment court .

new york , ny: center for court innovation , 2009 .

latimer , jeff , kelly morton - bourgon , and jo - anne chrétien .

a meta - analytic examination of drug treatment courts: do they reduce recidivism ? .

ottawa , ontario: department of justice canada , 2006 .

listwan , shelley johnson , james borowiak , and edward j. latessa .

an examination of idaho's felony drug courts: findings and recommendations - final report .

kent state university and university of cincinnati: 2008 .

logan , t. k. , william h. hoyt , kathryn e. mccollister , michael t. french , carl leukefeld , and lisa minton .

“economic evaluation of drug court: methodology , results , and policy implications.” evaluation and program planning , 27 ( 2004 ) :381 – 396 .

loman , anthony l. a cost - benefit analysis of the st. louis city adult felony drug court .

institute of applied research .

st. louis , mo: 2004 .

lowenkamp , christopher t. , alexander m. holsinger , edward j. latessa .

“are drug courts effective: a meta - analytic review.” journal of community corrections .

 ( fall 2005 ) : 5-28 .

mackin , juliette r. , shannon m. carey , and michael w. finigan .

harford county district court adult drug court: outcome and cost evaluation .

portland , or: npc research , 2008 .

mackin , juliette r. , shannon m. carey , and michael w. finigan .

prince george's county circuit court adult drug court: outcome and cost evaluation .

portland , or: npc research , 2008 .

mackin , juliette r. , lisa m. lucas , callie h. lambarth , mark s. waller , shannon m. carey , and michael w. finigan .

baltimore city circuit court adult drug treatment court and felony diversion initiative: outcome and cost evaluation - final report .

portland , or: npc research , 2009 .

mackin , juliette r. , lisa m. lucas , callie h. lambarth , mark s. waller , theresa allen herrera , shannon m. carey , and michael w. finigan .

howard county district court drug treatment court program outcome and cost evaluation .

portland , or: npc research , 2010 .

mackin , juliette r. , lisa m. lucas , callie h. lambarth , mark s. waller , theresa allen herrera , shannon m. carey , and michael w. finigan .

montgomery county adult drug court program outcome and cost evaluation .

portland , or: npc research , 2010 .

mackin , juliette r. , lisa m. lucas , callie h. lambarth , mark s. waller , theresa allen herrera , shannon m. carey , and michael w. finigan .

wicomico county circuit court adult drug treatment court program outcome and cost evaluation .

portland , or: npc research , 2009 .

mackin , juliette r. , lisa m. lucas , callie h. lambarth , mark s. waller , judy m. weller , jennifer a. aborn , robert linhares , theresa l. allen , shannon m. carey , and michael w. finigan .

baltimore city district court adult drug treatment court: 10-year outcome and cost evaluation .

portland , or: npc research , 2009 .

marchand , gwen , mark waller , and shannon m. carey .

barry county adult drug court outcome and cost evaluation - final report .

portland , or: npc research , 2006 .

marchand , gwen , mark waller , and shannon m. carey .

kalamazoo county adult drug treatment court outcome and cost evaluation - final report .

portland , or: npc research , 2006 .

marinelli - casey , patricia , rachel gonzales , maureen hillhouse , alfonso ang , joan zweben , judith cohen , peggy fulton hora , and richard a. rawson .

“drug court treatment for methamphetamine dependence: treatment response and posttreatment outcomes.” journal of substance abuse treatment , 34 ( 2 ) ( march 2008 ) : 242-248 .

mitchell , ojmarrh , and adele harrell .

“evaluation of the breaking the cycle demonstration project: jacksonville , fl and tacoma , wa.” journal of drug issues , 36 ( 1 ) ( winter 2006 ) : 97-118 .

piper , r. k. , and cassia spohn .

cost / benefit analysis of the douglas county drug court .

omaha , ne: university of nebraska at omaha , 2004 .

rhodes , william , ryan kling , and michael shively .

suffolk county drug court evaluation .

abt .

associates , inc. , 2006 .

rhyne , charlene .

clean court outcome study .

portland , or: multnomah county department of community justice , 2004 .

rossman , s. , m. rempel , j. roman , et.al .

the multi - site adult drug court evaluation: the impact of drug courts .

washington , d.c.: urban institute , 2011 .

shaffer , deborah k. , kristin bechtel , and edward j. latessa .

evaluation of ohio's drug courts: a cost benefit analysis .

cincinnati , oh: center for criminal justice research , university of cincinnati , 2005 .

wilson , david b. , ojmarrh mitchell , and doris l. mackenzie .

“a systematic review of drug court effects on recidivism.” journal of experimental criminology , 2 ( 4 ) ( 2006 ) : 459-487 .

zarkin , gary a. , lara j. dunlap , steven belenko , and paul a. dynia .

“a benefit - cost analysis of the kings county district attorney's office drug treatment alternative to prison ( dtap ) program.” justice research and policy , 7 ( 1 ) ( 2005 ) .

