the internal revenue service ( irs ) relies extensively on information technology ( it ) systems to annually collect more than $2 trillion in taxes , distribute more than $300 billion in refunds , and carry out its mission of providing service to america's taxpayers in meeting their tax obligations .

for fiscal year 2014 , irs expected to spend about $2.4 billion for it investments ; this is about 21 percent of irs's total budget for the year .

given the significant amount spent on irs's it investments and the challenges inherent in successfully delivering them , it is important that congress be provided ongoing , accurate , and objective information on the progress toward completion and the risks facing irs's projects .

accordingly , the senate appropriations committee directed gao to review the cost and schedule performance of irs's major it investments .

specifically , our objectives were to ( 1 ) evaluate irs's efforts to address our recommendations for improving the reliability and reporting of cost , schedule , and scope information ; ( 2 ) summarize the reported cost , schedule , and performance of irs's major it investments ; and ( 3 ) assess the status and plans of selected investments .

to address our first objective , we analyzed the four quarterly reports on the performance of it investments submitted by irs to the appropriations committees and us between december 2013 and september 2014 .

we also reviewed documentation of training provided to irs staff regarding monthly reporting of investment performance information , and cost estimation procedures that irs stated addressed the calculation of projected cost and schedule amounts .

to address our second objective , we analyzed documentation identifying the cost and schedule performance of irs's major it investments from october 2013 to september 2014 , and operational performance information as of september 2014 .

we identified significant recurring cost , or schedule variances and followed up with irs to obtain the reasons for these variances .

lastly , we reviewed the four quarterly reports on the performance of it investments submitted by irs to the appropriations committees and us between december 2013 and september 2014 , to identify the summary - level risk ratings assigned by the chief technology officer to major it investments , and analyzed these ratings to identify trends .

for our third objective , we selected the return review program ( rrp ) , customer account data engine 2 ( cade 2 ) , and information reporting and document matching ( irdm ) investments because the cost , schedule , or scope of these investments had changed from initial plans .

in addition , we selected the affordable care act administration ( aca ) investment due to its criticality to the 2015 tax filing season and the significant amount of resources expected to be expended .

for rrp , cade 2 , and irdm , we interviewed program officials and analyzed documentation such as performance work statements , business cases , and baseline change requests , to determine the initial and revised cost , schedule , and scope for these investments .

for aca , we interviewed program officials and analyzed program and testing documentation to identify the deployment plan for the investment , as well as the extent to which testing has been planned , conducted , and reported on for two new releases that are expected to be implemented for the 2015 tax filing season .

we conducted this performance audit from june 2014 to february 2015 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

details on our objectives , scope , and methodology can be found in appendix i .

the mission of irs , a component of the department of the treasury ( treasury ) , is to provide america's taxpayers top quality service by helping them understand and meet their tax responsibilities and enforcing the federal tax laws with integrity and fairness to all .

in carrying out its mission , irs annually collects over $2 trillion in taxes from millions of individual taxpayers and numerous other types of taxpayers and manages the distribution of more than $300 billion in refunds .

to guide its future direction , the agency has two strategic goals: ( 1 ) deliver high quality and timely service to reduce taxpayer burden and encourage voluntary compliance and ( 2 ) effectively enforce the law to ensure compliance with tax responsibilities and combat fraud .

it plays a critical role in enabling irs to carry out its mission and responsibilities .

for example , the agency relies on information systems to process tax returns , account for tax revenues collected , send bills for taxes owed , issue refunds , assist in the selection of tax returns for audit , and provide telecommunications services for all business activities , including the public's toll - free access to tax information .

irs's fiscal year 2014 budget was $11.3 billion .

of this amount , irs expected to spend about $2.4 billion on it investments .

irs expected to fund 19 major investments at a cost of about $1.7 billion , or 71 percent , of the total it request , and 135 non - major investments at a cost of about $700 million , or 29 percent , of the total it request .

for irs , a major investment is one that costs $10 million in either the current year or budget year , or $50 million over the 5-year period extending from the prior year through 2 years after the budget year .

table 1 provides high - level descriptions of irs's 19 major it investments and appendix ii provides detailed profiles of 7 investments critical to irs's mission for which we performed in - depth reviews in recent audits ( aca , cade 2 , e - services , irdm , irs.gov , modernized e - file , rrp ) .

the conference report accompanying the consolidated appropriations act , 2012 , directed irs to submit quarterly reports on the cost and schedule performance of its major it investments to the committees on appropriations and gao no later than mid - april 2012 .

these quarterly reports are to include detailed information on selected investments , including their purpose and life - cycle stage , reasons for cost and schedule variances , risks and mitigation strategies , expected developmental milestones to be achieved , and costs to be incurred in the next quarter .

irs's current reporting provides detailed information on eight investments , including six major investments that we have included in our reviews: cade 2 , e - services , irdm , irs.gov , mef , and rrp .

gao and the treasury inspector general for tax administration ( tigta ) have previously reported on irs's major it investments .

we reported in june 2012 that while irs reported on the cost and schedule of its major it investments and provided chief information officer ratings for them , the agency did not have a quantitative we measure of scope – a measure that shows functionality delivered.reported that having such a measure is a good practice as it provides information about whether an investment has delivered the functionality that was paid for .

we recommended that the commissioner of internal revenue develop a quantitative measure of scope , at a minimum for its major it investments , to have more complete information on the performance of these investments .

irs agreed with our recommendation at the time we made it .

in march 2014 , irs reported that it had practices and processes in place that addressed this recommendation , including quarterly reports to congress , and a baseline change request process .

however , we did not believe these practices addressed the recommendation , as neither approach included a quantitative measure .

for this reason , we believed the recommendation was still warranted .

we noted in april 2013 that the majority of irs's major it investments were reportedly within 10 percent of cost and schedule estimates and eight major it investments reported significant cost and / or schedule variances .

we also reported that weaknesses existed , to varying degrees , in the reliability of reported cost and schedule variances , and key risks and mitigation strategies were identified .

as result , we made recommendations for irs to improve the reliability of reported cost and schedule information by addressing the identified weaknesses in future updates of estimates .

we also recommended that irs ensure projects consistently follow guidance for updating performance information 60 days after completion of an activity and develop and implement guidance that specifies best practices to consider when determining projected amounts .

irs agreed with three of our four recommendations and partially disagreed with the fourth recommendation related to guidance on projecting cost and schedule amounts .

the agency specifically disagreed with the use of earned value management data as a best practice to determine projected cost and schedule amounts , stating that the technique was not part of irs's current program management processes and the cost and burden to use it outweigh the value added .

while we disagreed with irs's view of earned value management because best practices have found that the value generally outweighs the cost and burden of implementing it , we provided it as one of several examples of practices that could be used to determine projected amounts .

we also noted that implementing our recommendation would help improve the reliability of reported cost and schedule variance information , and that irs had flexibility in determining which best practices to use to calculate projected amounts .

for those reasons , we believed our recommendation was still warranted .

in september 2013 , tigta reported on cade 2 development challenges and changes to the planned schedule for this investment .

tigta reported , among other things , that the cade 2 database cross - functional triage team had effectively managed and resolved more than 1,000 data defects.that the downstream system interfaces had not been implemented due to data quality issues and the implementation date of these interfaces was revised to january 2014 .

however , tigta's review determined we reported in april 2014 , that 6 of irs's 19 major it investments were within 10 percent of cost and schedule estimates during fiscal year 2013 ; however , the reported variances were for the fiscal year only , and we therefore noted that irs's reporting would be more meaningful if supplemented with cumulative cost and schedule variances for the investments or investment segments .

in addition , the reported variances for selected investments were not always reliable because the projected and actual cost and schedule amounts on which they depend had not been consistently updated in accordance with omb and treasury reporting requirements .

further , irs was not working on developing a quantitative measure of scope ( i.e. , functionality ) as we recommended in 2012 , and we noted that reporting qualitatively in congressional reporting until a quantitative measure is developed would help provide congress with a complete picture of the agency's performance in managing its major investments .

lastly , irs continued to lack guidance that included best practices for calculating projected cost and schedule amounts .

we made three recommendations for irs to report more comprehensive and reliable cost and schedule information and improve the transparency of reported scope information for its major investments .

irs agreed with our recommendations and stated it believed it had addressed our recommendation to report cumulative investment and investment segment cost and schedule information in the quarterly reports to congress , as well as our prior recommendation to develop a quantitative measure of scope ; we disagreed , however , and maintained our recommendations .

in september 2014 , tigta reported on challenges faced by irs in implementing the irdm case management project .

more specifically , tigta noted that after a year of user acceptance testing , irs officials acknowledged that the irdm case management project could not effectively process business cases containing underreported income and could not be deployed into the irs production environment ; tigta identified insufficient project requirements as contributing to these challenges .

in addition , irs officials stated that budget constraints and difficulties encountered during user acceptance testing resulted in irs “strategically pausing” development of the irdm case management project .

in response to tigta's report , irs's chief technology officer stated that in january 2014 , irs decided to strategically pause development of the irdm case management project due to budget constraints and the inability to certify that the ongoing case management functionality deployment would not have an adverse impact on taxpayers .

irs has made limited progress in improving the reliability and reporting of cost , schedule , and scope performance information: it has partially implemented two of our five related recommendations and not yet addressed the remaining three .

irs's implementation of these recommendations is critical in ensuring that congress receives the reliable information it needs for effective oversight and decision making .

table 2 identifies the status of irs's efforts to address the recommendations .

in april 2013 , we reported that the cost and schedule performance information for the completed activities for six selected investments was updated within the 60-day time frame required by treasury guidance in 77 percent of the cases .

while the number of activities expected to be completed was relatively low and irs had updated the variance calculations for these activities in the majority of the cases , we noted that ensuring that updated actual information is consistently reported within the required 60-day time frame would strengthen the reliability of their variances and provide information that better reflects their performance .

consequently , we recommended that irs ensure its projects consistently follow guidelines for updating performance information 60 days after completion of an activity .

treasury and irs subsequently took actions to address our recommendation .

specifically , starting in fiscal year 2014 , treasury addressed the timeliness issue for schedule calculations by having the monthly reporting system automatically calculate a variance based on the current date for any activity where the planned completion date had passed and investment staff have not provided an actual figure within 45 days .

for cost , in june 2014 , officials in irs's strategy and planning group — which is responsible for overseeing monthly variance reporting — stated that they have been working closely with investment staff and program managers to ensure that reporting is completed within the 60- day requirement .

we reviewed the cost and schedule performance information for the six selected investments for fiscal year 2014 and found that the actions taken have resulted in actual cost and schedule amounts for completed activities being updated within the 60-day time frame required in 86 percent of the cases .

while this is an improvement from the 77 percent we previously reported , irs should continue its efforts to ensure full compliance with treasury's guidance and thereby provide reliable information on which to gauge its performance in meeting cost and schedule goals .

in april 2014 , we reported that irs did not consistently report updated variances for in - process investment activities for six investments in fiscal year 2013 even though omb and treasury require cost and schedule variances to be updated on a monthly basis .

this was partly due to an inconsistent understanding among investment staff of the information that was to be included in the monthly reporting .

as a result , we recommended that irs ensure that projected cost and schedule variances for in - process activities are updated monthly consistent with omb and treasury reporting requirements by ensuring investment staff have a consistent understanding of the information to be included in monthly reporting .

in response to our recommendation , irs's investment management and control office provided training in october 2014 , which focused on , among other things , the monthly update of investment performance information .

we believe this training will help to ensure investment staff have a consistent understanding of the information to be included in monthly reporting as the training outlines the specific information that is to be reviewed or updated for in - process activities .

however , since the training was provided in october 2014 , there have not yet been enough monthly reports to determine the extent to which this training has improved monthly reporting of variances for in - process activities .

adherence to irs's training on monthly performance reporting should help to ensure investments' cost and schedule variances are updated in accordance with omb and treasury guidance , and contribute to producing reliable information on which to gauge irs's performance .

in april 2013 , we found that irs had determined variances using — which comprised projected cost and schedule for in - process activities75 percent of all its activities .

however , treasury's guidance , which irs follows , did not specify how projected amounts should be determined when actual amounts are not available .

we therefore recommended that irs develop guidance for determining projected amounts .

in response , irs stated that the estimate variance reporting performed by its estimation program office applies the best practices we previously recommended , and the practices used are documented in its july 2014 cost and schedule variance reporting procedure .

we reviewed this document and found that , while it described the methodology for revising an estimate , it does not address the calculation of projected cost and schedule amounts used for the monthly reporting of cost and schedule variances for in - process activities , which was the subject of our recommendation .

at the conclusion of our review , officials sought clarification on what was needed to address our recommendation and agreed that the action taken did not address it .

developing and implementing the recommended guidance should provide greater assurance that projected amounts , when reported , are determined consistent with best practices and therefore more reliable .

this is particularly important given the high percentage of reported investment activities that we noted were in - process .

in april 2014 , we reported that irs's reporting of cost and schedule information in the quarterly reports to congress would be more meaningful for determining whether the agency is effectively managing its investments if it included cumulative cost and schedule variances for the investments or investment segments , consistent with omb's guidance for measuring progress towards meeting investment goals .

we noted that cost and schedule variances were for the fiscal year only in that they provide cost and schedule variance information for all projects and activities underway in any portion of the fiscal year.year focus did not provide cumulative cost and schedule information at the investment or investment segment level because it did not account for activities that were completed in previous fiscal years .

accordingly , we recommended that irs report cumulative performance information at the however , the fiscal investment or investment segment level .

at that time , the irs commissioner stated that the agency agreed with our recommendation but believed it had already been addressed in quarterly reports to congress .

we noted that while the reports provide cumulative information , it is for the fiscal year only , not for the investment as recommended , and we therefore maintained our recommendation .

in june 2014 , irs officials stated they believed the investment information reported in the office of management and budget exhibit 300 addressed our recommendation and , therefore , they had not taken additional steps .

however , the reported cost and schedule variances in the exhibit 300 are for the fiscal year only , and as a result , we believe our recommendation is still warranted .

providing congress with cost and schedule information at the useful segment level — in addition to the current fiscal year reporting — in the quarterly reports would provide a more meaningful gauge of whether investments are meeting cost and schedule performance goals .

in 2012 , we reported that irs did not have a quantitative measure of scope ( i.e .

functionality delivered ) that would provide a measure of whether an investment delivered the functionality that was paid for and recommended that the agency develop the measure , at a minimum , for its major it investments .

at the time , irs agreed with the recommendation but stated that it had other methods in place to document delivered functionality of a project throughout the life cycle .

we agreed that the methods identified addressed project functionality , but they did not provide a quantitative measure of performance .

in april 2014 , seeing that irs had not made progress on developing a quantitative measure of scope , we recommended the agency report qualitative scope information in the interim .

irs responded that it agreed with the recommendation and had practices and processes in place to assess and report on the delivery of scope in conjunction with cost and schedule management , and therefore , irs had not taken any additional steps to address our recommendation ; however , we did not believe that these practices and processes addressed our recommendation .

as of june 2014 , irs continued to assert that it had addressed the recommendation and therefore did not take any additional steps .

officials noted that the information reported in the office of management and budget exhibit 300 included information on changes in investment scope .

however , this reporting does not provide a quantitative measure of scope or qualitative information showing how delivered scope compares to what was planned .

until irs reports on progress in meeting scope in its quarterly reporting to congress , congress may lack important information that it needs to determine the extent to which the investments are delivering the functionality that was paid for .

this is particularly important given the major changes in development highlighted in the latter portion of this report .

most of irs's major it investments reportedly met cost and schedule goals , with 11 of 17 investments within 10 percent of cost estimates , and 13 of 17 investments within 10 percent of schedule estimates .

it is important to note that the cost and schedule information was not updated for two investments however , irs did not consistently indicate so in its reports to congress .

consistently disclosing when reported information is not updated would provide congress and other decision makers with improved information for oversight and decision - making purposes .

irs also reported “green” ratings for investments instead of their previous “yellow” ratings for chief technology officer summary - level risk assessments .

however , irs does not provide these ratings for the six investments for which it provides detailed information in the quarterly reports to congress .

providing summary - level risk ratings for all major investments would improve the visibility into changes in investment risk , and provide congress with the information to more easily determine the investments requiring greater attention .

finally , of the 85 operational performance metrics associated with the 17 major investments reporting operational performance information , irs reported meeting approximately 73 ( 86 percent ) of these metrics .

according to irs , 11 of 17 it investments were within 10 percent of cost estimates between october 2013 and september 2014 , and 13 of 17 investments were within 10 percent of schedule estimates between october 2013 and september 2014 .

while irs reports on the cost and schedule variance for its 19 major investments , the reports for two investments ( irdm and rrp ) were not updated to reflect actual performance throughout the fiscal year .

as illustrated in figure 1 , of the six investments that reported significant cost variances ( equal to plus or minus 10 percent variance from cost goals ) , four were significantly under planned costs for at least 1 month during fiscal year 2014 , one investment reported being over cost , and one investment reported being , at different times , both under and over cost during this period .

three investments – aca , e - services , and irs telecommunications systems and support – reported significant cost variances for a period of 3 or more consecutive months .

irs reported several reasons for these variances , including refinement of processes for allocating costs , fewer investment staff working on the investment during the 2013 government shutdown , overestimation of required contractor support , and reduction of planned funding .

in addition , as illustrated in figure 2 , one investment reported being significantly ahead of schedule for at least 1 month during fiscal year 2014 , while three investments reported being significantly behind schedule during this period .

as previously mentioned , treasury and omb guidance require cost and schedule variances to be updated on a monthly basis .

however , irs did not update information on cost and schedule variances to reflect actual performance for their rrp and irdm investments in its reports to congress .

officials said that updated cost and schedule performance information for these investments was not included following pauses in their development ( which occurred in january 2014 for irdm and february 2014 for rrp ) and during approval of baseline change requests .

irs officials stated they did not yet know how to include the pauses in development in their reports and that they had been instructed by treasury not to update monthly performance information until the change requests had been approved .

however , instances where information was not updated were not disclosed in a consistent manner for all investments .

specifically , while irs identified such instances for rrp , it did not provide similar disclosure for irdm following its development pause .

consistently disclosing reasons for why monthly updates are not being made ( such as during the baseline change request approval process ) would be helpful in providing decision makers with the information they need for oversight purposes .

during the third quarter of fiscal year 2014 , irs reported increased risks for the 13 investments for which it provides summary - level chief technology officer risk assessments to congress .

specifically , while the 13 investments had a risk rating of “green” during the second quarter of fiscal year 2014 , 12 of these investments reported a risk rating of “yellow” during the third quarter of fiscal year 2014 , and 1 investment reported a risk rating of “red.” according to the deputy chief information officer for strategy and modernization , the chief technology officer and deputy chief information officers meet quarterly to make a broad assessment of the major it investments , and as a result , assign summary - level risk ratings for 13 of the major it investments .

this assessment is based on these officials' knowledge of each of the major investments , as well as an assessment of six key performance indicators ( cost , schedule , scope , risk , organizational readiness , and technical ) .

a reason irs provided for the change in risk ratings for its major it investments was funding constraints as a result of additional legislative mandates , such as the aca and fatca investments , which irs noted it in addition , irs does not receive funding from congress to implement.noted that it has had to reallocate staffing to these investments , which has created a skill set gap for other investments .

to address this , irs stated that it is currently creating a skill set inventory to specifically identify gaps between available and required skill sets .

it is important to note that , while irs identified increased risks for the 13 major it investments via its chief technology officer risk ratings for the first time in quarter three of fiscal year 2014 , the assessments were not indicative of new risks .

rather , they better reflected risks irs had previously shared with us during quarterly briefings .

during the fourth quarter of fiscal year 2014 , the risk rating for 6 of the investments improved from “yellow” to “green.” irs's deputy chief information officer for strategy and modernization explained that this happened because the agency was able to draw resources from infrastructure investments deemed less critical for the upcoming filing season to address the risks associated with most of the investments previously rated “yellow.” this explains the “red” rating for the infrastructure investments in the fourth quarter , as illustrated in figure 3 below .

we have previously reported on the importance of providing summary - level risk ratings for major it investments .

specifically , we have noted that such ratings improve the visibility into changes in the risk level of investments over time .

while irs provides summary - level chief technology officer risk assessment ratings for 13 investments in quarterly reporting to congress , it does not provide such ratings for the 6 investments for which it reports detailed information – cade 2 ; e - services ; irdm ; irs.gov ; mef ; and rrp .

while the detailed information on the 6 investments is consistent with congressional reporting requirements , supplementing it with chief technology officer summary - level risk assessment ratings would improve the visibility into risks faced by these investments , and provide congress with the information to more easily determine the investments requiring greater attention .

figure 3 shows the chief technology officer risk assessment ratings for the four quarters of fiscal year 2014 .

according to omb , operational performance metrics are used to examine the performance of an investment in operation and demonstrate that the investment is meeting the needs of the agency , delivering expected value , or being modernized and replaced consistent with the agency's enterprise architecture .

as of september 2014 , irs had reported on the operational performance for 17 of its 19 major investments .

irs establishes operational metrics and associated targets for its investments , and on a quarterly , monthly , or annual basis reports on its performance in meeting the targets .

the operational metrics established for investments include , for example , percentage of scheduled system availability , percentage of individual tax returns processed electronically , and the percentage of refunds processed daily .

as illustrated in figure 4 , of the 85 operational performance metrics reported with associated actuals , irs reported meeting approximately 73 ( 86 percent ) of these metrics .

with respect to the 12 operational performance metrics that were not met , the difference between the target and actual performance was generally insignificant .

for example , half of the metrics were within 5 percent of the target .

selected investments experienced variances from initial cost , schedule , and scope goals that were not transparent in congressional reporting because irs has yet to address our prior recommendations for reporting at the investment level and on progress in delivering scope .

specifically , rrp has so far exceeded planned costs by $86.5 million and has yet to deliver functionality that was scheduled for september 2012 , in large part due to the need to implement new technology and a lack of adequate resources , including contracting expertise and staff ; a key phase of cade 2 was developed 10 months late and at $183.6 million more than planned ; and the irdm case management project was cancelled .

however , these variances were not all included in congressional reporting .

in addition , the reports on the status of testing for the aca investment are not comprehensive , making it difficult to determine whether all required testing is being performed .

irs delivered less functionality than planned for the rrp investment , and did so at a higher than planned cost and behind schedule .

specifically , irs exceeded initial planned costs for this investment by approximately $86.5 million and has yet to complete the first phase of the investment , which was originally planned to be delivered in september 2012 .

as early as may 2010 , irs issued several contracts to , among other things , plan and develop four transition states to complete the rrp investment ; these contracts had a total planned cost of $57.5 million .

figure 5 identifies the current and historical development plans for the rrp investment .

the planned schedule and functionality for the four rrp transition states are identified in table 3 .

in march 2012 , a baseline change request was approved for rrp that included a revision to the planned completion dates for transition states 1 and 2 to december 2013 and 2014 , respectively .

in addition , the planned cost for the rrp investment was revised to $136.2 million , an increase of approximately $79 million .

according to irs , these changes to initial plans were a result of irs's decision to implement new technology for delivering the rrp investment .

more specifically , irs began implementation of the rrp investment using existing technologies ; however , irs determined that new technology would be better suited to meet the goals of the investment .

in february 2014 , after developing most of the planned functionality for transition state 1 – a senior rrp official estimates about 70 percent – irs's executive steering committee made a decision to pause further development of this investment .

according to irs officials , factors contributing to this decision included budget constraints , as well as uncertainty about next steps from a business and a technology perspective , and the need to ensure alignment of rrp with the new senior leadership's strategic vision for identity theft and fraud detection .

in march 2014 , irs reported delivering the following transition state 1 functionality: improvements in data analytics and linked return analysis above current efds capabilities in order to detect more fraud .

leveraged new massive parallel processing technology , which irs noted has proven itself in data analysis , performance , and scoring improvements in analyzing 3 years of taxpayer data .

entity - based data model with a 3-year view of tax filer's data .

ability to add or modify rules and models in current processing year based on current fraud patterns .

in addition , in april 2014 , irs launched a limited deployment of one of rrp's planned fraud detection capabilities – the capability to detect identity theft in filed tax returns .

irs plans to use the rrp identity theft functionality in conjunction with the electronic fraud detection system ( the fraud detection system rrp is expected to eventually replace ) for all tax returns filed during the 2015 tax filing season .

irs also reported beginning requirements development activities for rrp transition state 2 .

in september 2014 , irs proposed additional changes to the rrp investment .

more specifically , it revised the planned completion dates for transition states 1 and 2 to march 2015 and 2016 , respectively .

in addition , the planned cost for the rrp investment was revised to $226.9 million , an increase of approximately $91 million .

irs identified several reasons for these changes in plans to include , among other things: lack of experience in integrating new technology required for rrp implementation ; the need for higher levels of contracting expertise ; and lack of staff to support the entire planned scope of rrp due to budgetary constraints and increased costs .

as illustrated in figure 6 , irs reported spending approximately $144 million for the rrp investment through fiscal year 2014 .

thus far , this amount exceeds the initial planned cost for the investment by $86.5 million .

with respect to future development of the rrp investment , irs stated that it has begun work on a plan for re - starting development which is heavily influenced by irs's small business / self employed and wage and investment concept of operations ( issued in july 2014 ) , and an it technical roadmap that is currently being developed .

irs's small business / self employed and wage and investment concept of operations identifies refund fraud and identity theft , as key drivers for transforming the agency's compliance efforts and services .

although irs has thus far exceeded the initial planned cost for the rrp investment by $86.5 million , the agency reported a zero percent cost variance for this investment in its fiscal year 2014 fourth quarter reporting to congress .

further , while irs noted that it had delivered about 70 percent of the planned functionality for transition state 1 of the rrp investment that was planned for september 2012 in march 2014 , this was not identified in congressional reporting .

if irs implemented our prior recommendations relative to cumulative reporting of performance information , and reporting of quantitative scope information , as previously mentioned , the variances from cost , schedule , and scope plans identified for rrp would be more transparent in congressional reporting .

irs has delivered a key phase of its modernized tax processing system ; however , in doing so , the agency exceeded planned costs by $183.6 million and fell behind schedule by 10 months ; this included an unplanned transition state with an associated cost of $101.1 million .

figure 7 identifies the current and historical development plans for the cade 2 investment .

in 2008 , irs began defining a new strategy – cade 2 – that was intended to deliver improved individual tax processing sooner , and move to a single tax processing database .

as shown in table 4 , irs planned to deliver the cade 2 investment through the completion of two transition states and a target state .

in 2012 , irs completed a cost estimate for transition state 1 of the cade 2 investment ; this cost estimate was $315 million .

irs reported completing functionality for the daily processing of individual taxpayer returns in january 2012 , and completing transition state 1 in november 2012 , at a cost of $397.5 million ; transition state 1 was completed 10 months behind planned schedule , and in excess of planned costs by $82.5 million .

further , while irs reported the completion of transition state 1 , this transition state completed “conditionally” meaning that the investment was approved to proceed to the next phase with outstanding issues remaining to be addressed .

in june 2013 , irs submitted a baseline change request to create a new transition state – transition state 1.5 – to address unfinished work from transition state 1 .

more specifically , this unfinished work included ongoing data assurance , performance tuning , and downstream systems efforts to prepare the cade 2 database for filing season 2014 production ; irs completed this transition state in july 2014 .

irs officials stated that the creation of this transition state did not affect the overall schedule for the cade 2 investment ; however , it was accompanied by $101.1 million in unplanned costs – $69.7 million in fiscal year 2013 , and $31.4 million planned for fiscal year 2014 .

irs officials stated that investment funding allocated for future work on transition state 2 was used to fund the unplanned transition state 1.5 activities .

irs began work on transition state 2 in october 2010 , and as of september 2014 , expected to complete this transition state by march 31 , 2015 .

however , irs noted that this planned completion date is likely to change as soon as a revised schedule estimate is completed for this transition state .

irs's delivery of cade 2 transition state 1 10 months behind its initial planned completion date and in excess of initial planned costs by $183.6 million is not identified in congressional reporting .

more specifically , irs's congressional reporting identifies cost and schedule performance for a 12-month period of time , and does not compare current investment performance to initial plans , as we have done in this report .

further , while irs's fiscal year 2014 fourth quarter reporting to congress identifies the scope delivered for cade 2 transition state 1 during fiscal years 2009 through 2012 , the reporting does not include a quantitative measure of scope , or qualitatively show how the delivered scope compares to what was planned for this transition state .

similar to rrp , the cade 2 schedule delays and challenges in meeting planned costs would be more transparent in congressional reporting if it contained cumulative reporting of performance information and reporting of quantitative scope information .

irs has cancelled its irdm case management project — one of five projects that make up the irdm investment — due to budget constraints , and is instead considering using an enterprisewide case management solution .

table 5 identifies the initial planned cost , schedule , and scope for the irdm case management project .

according to irs , the irdm case management project began beta testing in january 2013 ; however , further execution of the irdm case management project was cancelled in january 2014 , and irs noted that this project would be shut down after the existing cases being worked within the application were completed .

according to officials , irs made a decision to investigate an off - the - shelf system for case management that could be used as an enterprise - wide common service at irs .

irs noted that it has held three technical demonstrations to identify the extent to which a vendor - provided , off - the - shelf solution would meet the enterprise - wide need , and future development of a case management tool will be done using entellitrak technology .

irs officials stated they plan to execute enterprise case management solutions as soon as budget resources become available .

as previously mentioned , tigta identified challenges during user acceptance testing of the irdm case management project ; however , irs officials stated that these challenges were not a contributing factor in the agency's decision to pause development of this project .

as of october 2014 , irs reported spending $16.2 million on the irdm case management project — $8.8 million for irdmcm and $7.4 million for irdmcm r2 / release content management plan .

aca encompasses the planning , development , and implementation of it systems needed to support irs's tax administration responsibilities associated with certain provisions of the patient protection and affordable care act .

irs is developing this investment in 24 releases – 12 which are in production , 1 that is in production / in progress , 6 that are in progress , and 5 that are in planning .

irs's release plan for this investment is shown in table 5 .

releases 5.0 and 6.0 ( shaded in table 6 ) include development work that is critical in implementing aca requirements for the 2015 tax filing season .

the work associated with these releases impacts 66 irs systems via a system modification or by building a new system .

according to best practices , software testing should be guided by an organizational test strategy that defines different levels of testing required such as component , system , integration , and acceptance level testing .

in addition , the strategy should address how testing is to be managed and results reported.that defines various levels of testing for aca and has also assigned responsibility for testing to various organizations within irs .

consistent with these practices , irs has a test strategy aca systems testing is performed by each of the following organizations within irs , depending on the type of system work required .

according to irs officials , these organizations coordinate testing activities during systems integration testing .

the enterprise systems testing group is responsible for performing testing on systems that require modification to existing system functionality .

according to the enterprise systems testing director , the group performs ( 1 ) systems acceptability testing , ( 2 ) integration testing , and ( 3 ) final integration testing .

the implementation and testing group is responsible for performing project and integration testing on new and modified aca systems , and coordinates integration tests with enterprise systems testing for aca and existing tax return processing systems .

in addition , implementation and testing ensures testing for non - functional requirements such as performance , security , and accessibility through partnership with experts .

irs has performed various levels of testing for the aca releases that are now in production .

in addition , testing for systems currently in progress is underway .

according to the carnegie mellon university software engineering institute ( sei ) , a consolidated report drawing information from many sources is key to providing decision makers with the information they need to make timely and informed decisions .

this suggests that consolidated reporting would be critical for a complex process such as testing , where there are several organizations involved and a large number of systems and requirements being tested at different levels .

in addition , sei practices suggest that the status of all impacted systems and requirements should be accounted for in overall status reporting — whether or not they are tested .

although reports on the overall status of aca testing activities are provided to irs senior management via aca testing review checkpoint reports and filing season status reports , these reports are not comprehensive because they do not identify the status of testing for all systems impacted by aca releases 5.0 and 6.0 .

for example , irs's october and december 2014 aca testing review checkpoint reports did not identify the status of testing for 26 and 24 of the 66 impacted systems , respectively .

when asked about this , irs officials stated that all systems do not undergo the enterprise systems testing and implementation and testing group tests identified above .

specifically , the two organizations responsible for testing collectively identify systems deemed critical for testing and only those systems are included in the reports we reviewed .

nevertheless , including all impacted systems in reporting , including those that are not tested , as suggested by best practices , would ensure accountability for all systems .

it is important to note that irs's testing review checkpoint reports and filing season status reports are not always aligned with the manner in which aca testing is being performed .

for example , while irs noted that aca testing is conducted on requirements , the reports did not provide a status of requirements tested , making it difficult to determine whether all requirements have been tested .

without status reports that account for all impacted systems and are aligned with the manner in which irs performs testing , it will be difficult to determine whether all required testing is being performed to ensure aca is ready for the filing season .

irs has made limited progress in improving the reliability and reporting of cost , schedule , and scope performance information .

until the agency fully implements the prior recommendations highlighted in our review , the information congress receives will not be reliable for effective decision making and oversight .

while irs is required to provide monthly updates on the cost and schedule performance of its major investments , the information for two investments ( rrp and irdm ) was not always updated , and irs did not always disclose when this was the case in congressional reporting .

in addition , irs reports summary - level risk assessment ratings for 13 of its major investments in its reporting to congress .

providing similar ratings for its remaining 6 major investments would allow congress to more easily determine the ones requiring greater attention .

three selected investments had exceeded initial planned costs , fallen behind initial planned schedule , and had not produced all the expected functionally ; and two had been paused or cancelled .

however , these deviations were not transparent in congressional reporting because irs has yet to implement our prior recommendations regarding cumulative performance and scope reporting .

the magnitude of some of the changes to plans we identified underscores the criticality of implementing our prior recommendations in improving the transparency of congressional reporting so congress has the appropriate information needed to make informed decisions .

finally , the reporting of testing activities for the aca investment segments which are critical for the 2015 filing season showed that impacted systems were not all captured in overall status reports .

in addition , these reports were not aligned with the manner in which aca testing is being performed .

addressing these two issues would improve irs's and key decision makers' ability to determine whether all required testing to ensure readiness for the filing season is being performed .

to improve the reliability and reporting of investment performance information and management of selected major investments , we recommend that the commissioner of the irs direct the chief technology officer to take the following three new actions: for major investments included in congressional reporting , disclose instances where cost and schedule performance information reported to congress is not updated .

provide summary - level chief technology officer risk assessment ratings for all major investments in the quarterly reporting to congress .

modify reporting of aca testing status to senior management to include a comprehensive report on all impacted systems — including an explanation for why impacted systems were not tested at a particular level — and ensure this reporting is aligned with the manner in which testing is being performed .

we obtained written comments on a draft of this report from the commissioner of the irs , which are reprinted in appendix iii .

in his written comments , the commissioner stated that irs appreciated the acknowledgment of progress it had made to address two prior year recommendations to improve the consistency and timeliness in reporting cost , schedule and scope information for its major information technology ( it ) investments , but disagreed with our assessment of its efforts to address three prior recommendations for improving the reliability and reporting of cost , schedule , and scope information .

finally , he stated that irs agreed with our two recommendations related to disclosing instances where performance information is not updated in quarterly reporting to congress and expanding summary - level risk assessment ratings to all major investments .

further , the commissioner stated the agency would provide a detailed corrective action plan addressing these recommendations .

the commissioner also stated that irs disagreed with our third recommendation to modify the reporting of testing for the affordable care act administration ( aca ) investment to senior management .

regarding our prior recommendation to develop and implement guidance that specifies best practices to consider when determining projected cost and schedule amounts for in - process activities in the monthly reporting , the commissioner stated that this continues to be a work in progress for irs .

specifically , he stated that irs's information technology strategy and planning organization and members of various investment teams are currently collaborating on best practices and a centralized process for determining project cost and schedules for in - process activities .

as noted in our report , we reviewed a july 2014 cost and schedule variance reporting procedure that irs stated addressed our recommendation .

however , while the document described the methodology for revising an estimate , it did not address the calculation of projected cost and schedule amounts used for the monthly reporting of cost and schedule variances for in - process activities , which was the subject of our recommendation .

as a result , we believe the status of this recommendation stands as not addressed .

regarding our prior recommendation to report cumulative investment and investment segment cost and schedule information in the quarterly reports to congress , the commissioner stated that irs believed the recommendation was satisfied through its reporting of performance information in the department of the treasury's sharepoint investment knowledge exchange ( spike ) tool , which is also included in irs's quarterly reporting to congress .

however , as noted in our report , this performance information is for the fiscal year only and is not cumulative for the investment or investment segment , as recommended , and therefore does not account for activities that were completed in previous fiscal years .

as a result , we believe the status of this recommendation stands as not addressed .

regarding our prior recommendation to develop a quantitative measure of scope for irs's major investments , the commissioner identified several practices and processes that he stated are currently in place to assess and report on the delivery of scope .

he mentioned ( 1 ) irs's quarterly reporting to congress , and ( 2 ) the omb exhibit 300 baseline change request process as examples of such practices and processes .

however , as noted in this and prior reports , while these methods address project functionality , they do not provide a quantitative measure of progress in delivering this functionality .

in addition , the commissioner also mentioned the post implementation review process ; however , the post implementation review process does not provide a measure of progress in delivering scope as irs has noted that this process is performed at the close of each segment .

for these reasons , we continue to believe the status of this recommendation stands as not addressed .

regarding our recommendation to modify reporting of aca testing status to senior management , the commissioner stated that irs followed a rigorous risk - based process for planning the tests of aca - impacted systems , including the types and levels of testing .

in addition , he stated that irs had comprehensive reporting for the filing season 2015 release , which included aca impacted systems .

we acknowledge the various levels and types of aca testing that irs has performed and have noted this in our report .

however , as also noted in our report , our review of aca testing review checkpoint reports and filing season reports which officials stated were used to provide comprehensive reports to senior managers did not identify the status of testing for all systems impacted by aca releases 5.0 and 6.0 .

for example , we found that irs's october and december 2014 aca testing review checkpoint reports did not identify the status of testing for 26 and 24 of the 66 impacted systems , respectively .

including all impacted systems in reporting , including those that are not tested , as best practices suggest , would ensure accountability for all systems .

accordingly , we believe our recommendation is still warranted .

irs also provided us with technical comments that we have incorporated in the report as appropriate .

we are sending copies of this report to interested congressional committees , the commissioner of the irs , and other interested parties .

in addition , the report will be available at no charge on gao's website at http: / / www.gao.gov .

if you or your staffs have any questions on the matters discussed in this report , please contact me at ( 202 ) 512-9286 or pownerd@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iv .

our objectives were to ( 1 ) evaluate irs's efforts to address our recommendations for improving the reliability and reporting of cost , schedule , and scope information ; ( 2 ) summarize the reported cost , schedule , and performance of irs's major it investments ; and ( 3 ) assess the status and plans of selected investments .

for the first objective , we determined the status of actions taken to address each of five prior recommendations to improve the reliability and reporting of cost , schedule , and scope information we made in our 2013 and 2014 reviews of irs's major it investments .

they address ( 1 ) the timely reporting of cost and schedule variance information for completed activities ; ( 2 ) consistently updating cost and schedule information for in - process activities ; ( 3 ) developing guidance on best practices to consider when determining cost and schedule variances for in - process activities ; ( 4 ) reporting cost and schedule information at the investment or investment segment level ( rather than by fiscal year only ) ; and ( 5 ) reporting qualitatively on how delivered scope compares to what was planned for investments until a quantitative measure is developed .

for the first recommendation , we calculated the 60-day reporting time frame required by treasury for completed activities .

we then analyzed the four quarterly reports on the performance of it investments submitted by irs to the appropriations committees and us between december 2013 and september 2014 to determine whether completed activities showed updated cost and schedule information within those time frames .

for the second recommendation , we reviewed materials related to training that irs officials stated were provided to investment staff to ensure a consistent understanding of the information to be included in the monthly reports .

for the third recommendation , we reviewed the july 2014 cost and schedule variance reporting procedure and other guidance irs stated it was using to determine projected cost and schedule amounts to determine whether best practices were being included .

for the last two recommendations related to reporting cumulative performance information and progress in meeting scope expectations , we reviewed irs's reporting through the office of management and budget ( omb ) exhibit 300 process that irs stated addressed the recommendations .

we assessed a recommendation as being fully addressed if irs provided evidence that it fully addressed our recommendation ; partially addressed if irs provided evidence that it addressed our recommendation to some extent ; and not addressed if irs did not provide any evidence that it addressed our recommendation .

for our second objective , we obtained from irs a list of the investments classified as “major” during fiscal year 2014 .

we reviewed monthly cost and schedule variance reports for these investments from october 2013 through september 2014 , and followed up with irs officials to identify the reasons for investment - level variances that were significant ( equal to plus or minus 10 percent variance from cost or schedule goals ) and recurring ( reported for 3 consecutive months or more ) .

we assessed the reliability of the reported information by confirming our understanding of irs's process for reporting monthly cost and schedule variances , and by determining the extent to which irs had taken action to improve the reliability and reporting of this information .

we reviewed operational performance information reported for irs's major it investments as of september 2014 , to determine the extent to which each investment met its operational performance goals ; this information included , where reported , the performance target and actual results for each metric .

we compared this information to information reported for irs's major it investments on omb's it dashboard website .

lastly , we reviewed the four quarterly reports on the performance of it investments submitted by irs to the appropriations committees and gao between december 2013 and september 2014 , to identify the chief technology officer summary - level risk ratings assigned to major it investments .

we analyzed these risk ratings to identify trends , and interviewed irs officials ( including the deputy chief information officer for strategy and modernization ) to identify irs's methodology for deriving these ratings .

for our third objective , we selected return review program ( rrp ) , customer account data engine 2 ( cade 2 ) , and information reporting and document matching ( irdm ) because the cost , schedule , or scope of these investments had changed from initial plans ; and the affordable care act administration ( aca ) investment due to the investment's criticality to the 2015 tax filing season and the significant amount of resources expected to be expended .

for rrp , cade 2 , and the irdm case management project , we interviewed program officials and analyzed documentation such as performance work statements , business cases , baseline change requests , and the four quarterly reports on the performance of it investments submitted by irs to the appropriations committees and us between december 2013 and september 2014 .

from this documentation , we determined the initial cost , schedule , and scope plans for these investments , as well as any revisions to these plans , and the functionality delivered .

for aca , we obtained documentation and interviewed key officials – including those from the aca program management office , and irs's systems testing organizations – to determine the plan for deployment of the investment .

further , we identified the plans and status of testing for releases 5.0 and 6.0 , which are expected to be implemented for the 2015 tax filing season .

specifically , we analyzed the aca system architecture for releases 5.0 and 6.0 to identify associated systems impacted by the development of aca .

we then reviewed testing documentation , such as testing status reports and test plans to determine the extent to which these systems were tested .

lastly , we reviewed various test reports to determine the extent to which irs had a mechanism in place to comprehensively report on the status of testing for all systems related to aca releases 5.0 and 6.0 .

we compared the information against best practices for software testing promulgated by the international organization for standardization / international electrotechnical commission / institute of electrical and electronics engineers .

we conducted this performance audit from june 2014 to february 2015 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

this appendix contains the profiles for seven investments critical to irs's mission which we examined in greater detail in our prior reviews of irs' major it investments .

information contained within these profiles includes , but is not limited to: current life - cycle phase: life - cycle phases can be represented as planning ; development , modernization , and enhancement ; operations and maintenance ; or mixed .

planning refers to preparing , or acquiring the information used to design the asset ; assess the benefits , risks , and risk - adjusted costs of alternative solutions ; and establish realistic cost , schedule , and performance goals for the selected alternative , before proceeding to full acquisition or termination of a project .

development , modernization , and enhancement refers to projects and activities that result in new assets / systems or projects and activities that result in changes or modifications to existing assets that lead to substantive improvements , implement legislative or regulatory requirements , or meet an agency leadership request .

operations and maintenance refers to those projects and activities that are operating in a production environment .

finally , mixed refers to projects and activities that are a combination of development , modernization , and enhancement and operations and maintenance .

having detailed information allows for clear tracking of a program's costs as it moves through its various life - cycle phases .

development methodology: this is a framework that is used to structure , plan , and control the process of developing an information system .

there are a number of approaches that can be utilized by an investment .

irs's enterprise lifecycle methodology includes the following approaches: waterfall , planned maintenance , iterative , and managed services .

waterfall is a sequential development of a solution with planned reviews and formal approvals required before continuation of work .

the planned maintenance approach manages change in an organized manner , minimizes the disruption caused by frequent system changes , and increases the efficiency and effectiveness of the system change process .

additionally , the iterative approach is an adaptive development approach in which projects start with a conceptual vision of the solution and end with deployment , with repeated cycles of requirements discovery , development , and testing in between .

finally , the managed services approach is designed to capitalize on the benefits of managed services provided by either an outside service , internal business processes , and / or existing infrastructure service provider .

this provides useful information on the requirements of how a project is to progress through the life cycle .

contract type: for purposes of this report , this can be broken down into two categories .

the first is firm , fixed price contracts in which the price is not subject to any adjustments .

the second is cost reimbursement contracts which provide for the payment of allowable incurred costs , to the extent prescribed in the contract .

types of cost reimbursement contracts include , but are not limited to ( 1 ) a cost plus fixed fee in which actual costs and a fixed fee can be charged ; however , costs are not allowed to exceed the agreed upon estimate without approval ; and ( 2 ) a cost plus incentive fee that provides for an initially negotiated fee to be adjusted later by a formula based on the relationship of total allowable costs to total target costs .

number of rebaselines: rebaselines are changes to projects' cost , schedule , and performance goals ( i.e. , baselines ) .

according to officials , scope changes must go through a baseline change request process and be approved by treasury and omb .

according to irs , the affordable care act administration ( aca ) investment encompasses the planning , development , and implementation of it systems needed to support irs' tax administration responsibilities associated with certain provisions of the affordable care act .

initiatives that have already been deployed include the initial release of the branded prescription drug industry fee project ; an effort intended to secure connection between irs and the department of health and human services / centers for medicare and medicaid services ( cms ) to support health insurance exchange open enrollment for the fall of 2013 ; and 2014 non - marketplace provisions .

releases of the aca investment that are critical to the 2015 tax filing season include release 5.0 for filing season 2015 , and release 6.0 which includes compliance activities .

the customer account data engine 2 ( cade 2 ) investment began in 2010 as a new strategy for accelerating completion of a modernized database and converting to a single processing system sooner than was expected under cade ( which was the predecessor investment to cade 2 , intended to provide a modernized system of taxpayer accounts , with the ultimate goal of eventually replacing the individual master file ) .

cade 2 is expected to deliver its functionality incrementally through transition states .

transition state 1 includes: 1 .

daily batch processing of individual taxpayer returns provided by modifying the imf to run on a daily , rather than weekly , basis .

2 .

a comprehensive database for housing all individual taxpayer accounts and loaded with data from cade and imf to provide more timely updates of taxpayer information for use by irs employees for compliance and customer service .

irs reported completing functionality for the daily processing of individual taxpayer returns in january 2012 , and completing transition state 1 in november 2012 , at a cost of $397.5 million .

in july 2014 , irs completed transition state 1.5 , which included ongoing data assurance , performance tuning , and downstream systems efforts to prepare the cade 2 database for filing season 2014 production .

irs began work on transition state 2 in october 2010 , and expects to complete this transition state by march 31 , 2015 ; however , irs noted that this planned completion date is likely to change .

transition state 2 includes re - writing irs's legacy core tax processing applications in modern programming language , and is intended to increase flexibility , scalability , reliability , and security .

full operational capability: not applicable life - cycle costs: 193.644 million actual spent to date: $182.837 million current life - cycle phase: mixed ( development , modernization and enhancement , and operations and maintenance ) the e - services investment is a suite of web - based products that are intended to allow tax professionals and payers to conduct business with irs electronically .

these services are only available to tax practitioners , registered agents , and other third parties and are not available to the general public .

the program is available via the internet 24 hours a day , 7 days a week , and it contains products such as registration , an e - file application , a transcript delivery system ( a system which tax professionals may use to request and receive account transcripts , wage and income documents , tax return transcripts , and verification of non - filing letters ) , and taxpayer identification number matching ( a pre - filing service which allows authorized payers to match up to 25 payee taxpayer identification number and name combinations against irs records prior to submitting an information return ) .

the information reporting and document matching ( irdm ) investment is aimed at helping close the tax gap — the difference between what business taxpayers should have paid and actually did .

it is intended to improve voluntary compliance and accurate reporting of income by establishing a new business tax return and information returns that focus on merchant card payments and securities basis reporting .

irdm supports irs business using information systems that sort , match , identify , manage , and report on returns that are likely sources of tax gap - reducing revenue .

to accomplish this , irs requires operational resources and systems to be put in place to implement business and technology changes that are intended to expand and improve its automated matching of data on information returns to the data submitted on tax returns filed .

the investment consists of the following four projects .

as detailed in this report , this investment previously included a case management project that was cancelled in january 2014 .

data assimilation: identifies the link between tax forms and information returns filed for the same taxpayer to identify potential under - reporter cases .

the project then groups these into specific categories to support irs compliance programs associated with merchant card payments , securities cost basis , and government payments .

data correlation: matches tax return and information return data and applies business rules to identify potential under - reporter cases for use in the irdm case selection process .

after case selection , data correlation builds a complete case record for analysis by a tax examiner to support irs compliance programs .

business master file analytics: provides irs users the ability to define and execute logic for the intelligent selection of business taxpayer case inventory to ensure cases selected result in the largest financial return .

case inventory selection and analytics: provides irs users the ability to define and execute logic for the intelligent selection of individual taxpayer case inventory and creates an analytical environment that offers a greater ability to evaluate case data to improve the selection of cases worked .

the irs.gov investment consists of a public user portal — irs.gov , a registered user portal , and an employee user portal .

the key goals of the program include simplifying and transforming the user web experience , consolidating and advancing irs web technology to industry standards , implementing a high - performing contract structure and terms , and marketing competitive costs throughout the program's life cycle .

actual spent to date: $560.118 million current life - cycle phase: mixed ( development , modernization and enhancement , and operations and maintenance ) provide a cost effective and affordable program cost structure ; and transition successfully from the old programs to the new program .

the modernized e - file ( mef ) investment is the primary system to receive and process all tax returns submitted electronically .

when mef receives an electronic tax return , the system determines if it satisfies the acceptance rules required for further processing .

mef is intended to benefit the tax preparation community and enables the irs to answer questions quickly and helps to resolve issues .

mef is also intended to benefit corporations and tax - exempt organizations that must file tax returns or annual information returns electronically and is intended to reduce the handling / mailing of voluminous paper returns .

actual spent to date: $417.871 million current life - cycle phase: mixed ( development , modernization and enhancement , and operations and maintenance ) mef stores all tax return data in extensible markup language format in a modernized tax return database , allowing authorized irs viewers ( irs help desk personnel and tax examiners ) to see tax returns securely online .

according to irs , as of august 2014 , taxpayers used mef to submit over 228 million individual returns and over 14 million business returns .

irs deployed mef release 9.5 in may 2014 , for filing season 2015 .

according to irs , release 9.0 and 9.5 add the employment / unemployment tax family of forms ( forms 94x ) and the u.s. income tax return for estates and trusts ( form 1041 ) to the mef environment , as well as a new rrp interface , affordable care act and other legislative changes .

the return review program ( rrp ) investment is a web - based automated system that is intended to replace the legacy electronic fraud detection system ( efds ) built in the mid - 1990s .

it is intended to deliver functionality incrementally through transition states .

in september 2013 , irs officials adopted a risk mitigation approach that split transition state 1 into two releases .

the first release — called transition state 1 release 1.0 — occurred in march 2014 and contained functionality needed for processing filing season returns .

the second release — called transition state 1 release 1.1 — is planned to occur after filing season .

rrp is to , among other things: enable more effective routing of returns , detect noncompliant and fraudulent returns , ensure timely issuance of refunds and credits , prevent issuance of refunds and credits not legally due to filers , and streamline business processes used by the irs criminal investigative staff .

the new system is comprised of three major activities: detection .

intended to incorporate several existing models as well as new models to enhance detection of probable noncompliance .

using algorithms and business rule sets , the system is intended to detect questionable information on each return as the return is processed .

the system is also intended to detect returns with potential fraud characteristics , thereby allowing criminal investigators to link and analyze groups of returns to identify schemes for potential criminal prosecution .

resolution .

intended to accommodate existing treatment streams and new treatment streams .

returns will be routed systemically to the best treatment stream , opened into the treatment stream's inventory and , if applicable , the system will send an initial contact letter to the taxpayer .

prevention .

intended to automatically integrate the results of each return's resolution into the detection models .

the results can be used to help target education and outreach efforts to taxpayers and preparers on how to avoid unintentional noncompliance .

the system is also intended to allow analysis and identification of fraud and noncompliance not identified by the predictive detection models .

in addition to the individual named above , the following staff made key contributions to this report: sabine paul , assistant director ; chris businsky ; mary evans ; rebecca eyler , nancy glover , james macaulay ; paul middleton ; bradley roach ; and karl seifert .

