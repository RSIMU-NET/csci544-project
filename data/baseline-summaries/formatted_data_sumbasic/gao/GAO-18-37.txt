the social security administration ( ssa ) manages two disability benefit programs — disability insurance ( di ) and supplemental security income ( ssi ) — that together provide about 16 million americans with about $200 billion in benefits annually .

overall , more than 6 percent of the u.s. working - age population receives disability benefits from one or both of these programs , although the rate varies by state ( ranging from about 4 percent to more than 12 percent ) , according to ssa .

a claimant who is dissatisfied with the initial decision on his or her application can ultimately appeal at a hearing , where an administrative law judge ( alj ) reviews the case and any new evidence submitted by the claimant .

about 30 percent of the claimants who are ultimately allowed benefits are granted benefits at the hearings level or beyond .

for more than 15 years , the number of people applying for disability benefits has generally increased , along with the number of appeals .

at the same time , the percentage of appealed claims that have been allowed benefits has declined .

however , these rates — known as allowance rates — can vary widely across judges and hearings offices , raising questions about the reasons for this variation .

moreover , reports of improper decisions made by certain judges and a scheme between a judge and an attorney in one state to commit fraud , have raised questions about ssa's oversight of aljs .

you asked us to examine allowance rates and ssa's oversight of aljs .

this report examines ( 1 ) the extent to which allowance rates vary across administrative law judges , and any factors that are associated with this variation , and ( 2 ) the extent to which ssa has processes to monitor the accuracy and consistency of hearings decisions .

to address these objectives , we conducted a statistical analysis of data on adult disability decisions made by administrative law judges from fiscal years 2007 through 2015 and the factors that may be associated with variation in allowance rates .

specifically , we considered the following factors: claimant characteristics relevant to the disability determination process ( eg , age and primary impairment ) , participants in the process other than claimants ( eg , claimant representatives and medical and vocational experts ) , judge characteristics ( eg , year of appointment as a judge , and any prior related ssa experience ) , ssa administrative characteristics ( eg , hearing office where the case was decided and whether the hearing was conducted by videoconference ) , and economic characteristics ( unemployment and poverty rates in the claimant's state ) .

 ( appendix i provides more detail on our statistical analysis , including a complete list of the factors we analyzed. ) .

we assessed the reliability of ssa's administrative data on disability decisions and judge characteristics by ( 1 ) performing electronic testing of required data elements , ( 2 ) reviewing existing information about the data and the system that produced them , and ( 3 ) interviewing agency officials knowledgeable about the data .

we determined that the data were sufficiently reliable for the purposes of this report .

 ( appendix i describes our data in more detail. ) .

we reviewed relevant federal laws , regulations , and documentation and collected testimonial evidence from ssa officials to describe and evaluate the processes ssa uses to monitor hearings decisions , detect variation , and improve accuracy .

we assessed these monitoring efforts against federal internal control standards and our management and evaluation guide for assessing fragmentation , overlap , and duplication in government programs .

we also reviewed ssa's annual performance plans from fiscal years 2006 through 2017 to describe the performance measures the agency has established to improve the accuracy and consistency of its hearings decisions .

we evaluated the current performance measures using key attributes of performance measures identified in prior gao work and federal internal control standards .

we conducted this performance audit from december 2015 to december 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the social security administration's ( ssa ) disability insurance ( di ) and supplemental security income ( ssi ) programs are the two largest federal programs providing cash assistance to people with disabilities .

the di program , established in 1956 , provides monthly payments to working - age adults ( and their dependents or survivors ) who are unable to work due to a long - term disability .

the ssi program , established in 1972 , is a means - tested income assistance program that provides monthly payments to adults or children who are aged , blind , or have other disabilities and whose income and assets fall below a certain level .

individuals with low incomes and assets who also have a sufficient work history may qualify for the di and ssi programs concurrently .

in this case , the individual's ssi payment is generally offset by the amount of the di payment .

in fiscal year 2016 , according to ssa , about 10.8 million disabled workers and their family members received about $143 billion in di benefits , and an estimated 8.2 million individuals received almost $59 billion in ssi benefits ( of those , 2.6 million received ssi in addition to di or old - age and survivors benefits ) .

although di and ssi have different purposes and target populations , the disability criteria for adults are the same for both programs .

to be considered eligible for either program as an adult , a person must have a medically determinable physical or mental impairment that ( 1 ) has lasted or is expected to last for at least a continuous period of 1 year or result in death , and ( 2 ) prevents them from engaging in any substantial gainful activity ( sga ) .

the disability decision - making process includes five sequential steps ( see fig .

1 ) .

first , ssa determines if a claimant is working and screens out ( denies ) claimants who earn over a specified amount .

second , ssa determines whether the claimant has an impairment severe enough to significantly limit his or her ability to do basic work activities and expected to last more than 12 months or result in death , and denies claimants who do not meet these criteria .

at the third step , ssa determines whether a claimant's impairment meets or is equivalent to an impairment listed in ssa's listings of impairments .

if a claimant “meets” or “equals” one of the listed impairments , they are allowed benefits .

if not , ssa proceeds to the last two steps and assesses whether a claimant , given their impairment , can do their past work ( step four ) or other work that exists in significant numbers in the national economy ( step five ) .

over time , more of ssa's disability decisions have been made at the last two steps in the process , which require more judicial discretion than decisions made at steps 1 through 3 , according to ssa .

in 2000 , 29 percent of decisions were made at steps 4 and 5 , according to an ssa report .

by 2014 , nearly half — 49 percent — of all decisions were made at these steps .

to apply for benefits , a claimant must file an application online , by telephone , or mail , or in person at a local social security office .

if field office staff determine that the claimant meets the nonmedical eligibility criteria , they forward the claim to the appropriate state disability determination services ( dds ) office .

dds staff — generally a team comprised of disability examiners and medical consultants — review medical and other evidence provided by the claimant , obtaining additional evidence as needed , and make the initial disability determination .

in fiscal year 2016 , ssa received more than 2.5 million disability claims .

if the claimant is not satisfied with this determination , in most states he or she may request a reconsideration of the decision within the same dds office .

if the claimant is dissatisfied with the reconsideration , he or she may request a hearing before an administrative law judge ( alj ) .

in one of several initiatives to improve the disability determination process , ssa has eliminated the reconsideration step of the process in 10 states , allowing the claimant to appeal the initial decision directly to an alj .

in fiscal year 2016 , claimants appealed more than 698,000 decisions to the hearings level , and ssa issued more than 637,000 dispositions ( including allowances , denials , and dismissals ) .

 ( see fig .

2 ) .

within ssa's office of disability adjudication and review ( odar ) , there are approximately 1,500 aljs who are located in 166 hearing offices across the country , as well as at five national hearing centers .

in general , cases are randomly assigned to aljs within the area each hearing office serves , in the order in which the requests for a hearing are received .

the alj reviews the claimant's file , including any additional evidence the claimant submitted after the initial determination , and generally conducts a hearing .

at the hearing , the alj may hear testimony from the claimant , medical experts on the claimant's medical condition , and vocational experts regarding the claimant's past work and jobs currently available in significant numbers in the national economy .

the majority of claimants are represented at these hearings by an attorney or nonattorney representative , such as a professional disability representative , relative , or social worker .

if the claimant is not satisfied with the alj decision , he or she may request a review by ssa's appeals council , which is the final administrative appeal within ssa .

the appeals council may grant , deny , or dismiss a request for review .

if it agrees to review the case , the appeals council may uphold , modify , or reverse the alj's decision , or it may remand the case back to the alj to hold another hearing and issue a new decision .

in fiscal year 2016 , the appeals council reviewed more than 154,000 alj decisions and remanded 13 percent of them .

hearings - level backlogs and processing times have increased between fiscal years 2010 and 2016 .

the number of annual requests for a hearing before an alj peaked in fiscal 2011 , and declined in each subsequent year , through fiscal year 2016 .

despite this decline , ssa has not been able to keep pace with the demand , in terms of dispositions — the number of cases the agency decided or dismissed — in each of those years after 2010 ( see figure 3 ) .

by the end of fiscal year 2016 , ssa reported there were about 1.1 million pending cases .

average processing times for hearings - level decisions also increased during this same time period , from 426 days to 543 days .

during these years , the number of aljs declined , along with the number of case dispositions per month .

for example , ssa reported it employed 1,356 aljs in fiscal year 2013 , and these judges had an average of 48 case dispositions per month .

in fiscal year 2015 , 1,265 judges had an average of 44 case dispositions per month .

also during this time period , ssa reduced its reliance on senior attorney adjudicators ( saa ) to make fully - favorable , on - the - record decisions ( that is , decisions in which a hearing is not necessary because the documentary evidence alone supports a decision that is fully favorable to the claimant ) .

according to ssa , its backlog will be eliminated when the national average processing time for a hearing decision is 270 days .

in january 2016 , ssa issued a plan to achieve this goal by the end of fiscal year 2020 .

however , in its fiscal year 2018 performance plan , ssa set a goal for processing hearings decisions in 600 days ( up from a target of 485 days in fiscal year 2010 ) .

ssa reported that the increase in average processing times is due to the increase in the number of pending cases .

since ssa generally processes cases in the order in which they are received , they focus on the oldest cases first , which increases the average processing time for closed cases .

the role of alj was created by the administrative procedure act , which was enacted in 1946 to ensure fairness and due process in federal agency proceedings involving rulemaking and adjudications .

aljs serve in a number of executive branch agencies , although ssa employs the vast majority .

aljs preside and make decisions at formal adjudicatory proceedings .

one of the primary goals behind the creation of the alj position is to ensure that judges can conduct hearings free from influence or coercion from the agency .

although aljs are hired by and serve as employees of executive branch agencies like ssa , the office of personnel management ( opm ) is responsible for the initial examination , certification for selection , and implementation of the three levels of basic pay of aljs .

as part of its responsibilities , opm sets the minimum qualifications for aljs , which are that they generally must be licensed attorneys with a minimum of 7 years of experience in litigation and / or administrative law and pass the competitive examination .

the administrative procedure act gave aljs qualified decisional independence , with some oversight from agencies .

decisional independence means that aljs can make decisions independently .

federal law also excludes aljs from performance evaluations and generally requires that disciplinary actions against aljs be for good cause established and determined by the merit systems protection board ( mspb ) .

while aljs have qualified decisional independence , they must follow their agency's policies and procedures when making decisions .

the administrative procedure act also authorized agencies to review alj decisions .

if ssa determines that an alj has not followed its policies and procedures , it can issue a directive to the alj to comply and , if that is unsuccessful , bring a disciplinary action before the mspb .

allowance rates varied across administrative law judges from fiscal years 2007 through 2015 .

we defined the “allowance rate” for each judge as the number of claims in which a judge granted the claimant disability insurance ( di ) and / or supplemental security income ( ssi ) benefits divided by the total number of decisions issued by the judge ( excluding claims that were dismissed ) .

we analyzed about 3.3 million decisions made by administrative law judges on adult social security disability appeals over this period .

the average allowance rate across judges fell 15 percentage points over this period — from a peak of 70 percent in 2008 to 55 percent in 2015 — but the range in allowance rates across judges remained fairly constant ( see fig .

4 ) .

specifically , the range — the difference between judges with high allowance rates ( those at the 95th percentile ) and judges with low allowance rates ( at the 5th percentile ) — was 55 percentage points over this period .

this variation in allowance rates persisted , but fell modestly over time , even when we used multivariate statistical methods to hold constant a variety of factors related to the disability appeals process .

these factors included characteristics of claimants , judges , and hearing offices , as well as other factors such as the unemployment rates in a claimant's state , that could otherwise explain differences in allowance rates .

specifically , for the years 2007 through 2015 combined , our analysis estimated that the allowance rate would vary by 46 percentage points for a typical claim , depending on the judge who heard the case .

for example , we estimated that the allowance rate for a typical claim heard by a judge with low allowance rates would be 42 percent , compared to 88 percent for a judge with high allowance rates .

this estimated range fell from 50 percentage points in 2007 to 45 percentage points in 2015 ( see fig .

5 ) .

 ( appendix i describes this statistical analysis in more detail. ) .

allowance rates also varied across hearing offices during the same time period , but this variation was considerably smaller than the variation across judges in every year .

the estimated range across the entire period was 19 percentage points across hearing offices ( see fig .

6 ) , compared to a 46 percentage - point estimated range across judges .

accounting for differences in allowance rates across offices ensured that the variation across judges did not reflect characteristics of their offices ( such as the types or severity of disability claims received by their offices ) .

ssa officials noted that the variation in allowance rates we observed across judges was not surprising , nor was the modest narrowing in this range over time .

administrative law judges usually hear complex appeals that may not be clear - cut allowances or denials .

as a result , according to ssa officials , given judges' decisional independence , different judges could look at cases with similar fact patterns and circumstances and come to different conclusions .

at the same time , officials also pointed to several factors potentially related to the modest narrowing in the range of allowance rates .

first , they noted that ssa started conducting quality assurance reviews of a random sample of allowances in 2011 — previously , such cases were not reviewed .

in addition , they said that social security's disability programs and administrative law judges were under increased public and congressional scrutiny following a high - profile fraud case in 2011 involving a judge and an attorney representative .

further , officials said that the expanding use of electronic case files and data analytics within ssa made it possible for the agency to enhance monitoring of decision - making and share this information with judges .

finally , while ssa cannot direct judges to decide cases in a particular way , officials suggested that some judges may have “self - corrected” their approach to decision - making , given all of these factors .

our multivariate analyses had some limitations , but it provides more information than simple comparisons in allowance rates across judges .

for example , the ssa data we used for this analysis do not include a measure of the severity of a claimant's impairment or their remaining ability to work , which could help explain why one claim with a particular impairment was allowed while another was denied .

the data also do not include a standardized measure for the nature of claimants' prior work ( such as the skill level or extent of physical labor ) , which is also relevant for the disability decision .

nevertheless , our multivariate analysis enabled us to compare allowance rates across judges and hearing offices for typical claims .

in addition , ssa's practice of assigning cases randomly to judges makes it more likely that the remaining variation we found across judges reflects the unique effect of having a particular judge hear a case , rather than other factors .

as a result , even though we could not account for all factors that could explain differences in allowance rates , random assignment increases the chances that such factors were similar across all of the cases heard by individual judges .

although variation in allowance rates persisted across judges , even after controlling for certain factors , many of the factors we identified had meaningful associations with the chance that a claimant was allowed benefits .

these factors represent criteria in ssa's disability decision - making process , such as the claimant's age , impairment , prior work , and education .

we also identified factors that did not have such associations .

certain claimant characteristics — such as older ages or certain impairments — were associated with higher allowance rates .

age: claimants' chances of being allowed benefits increased with age , even holding constant other factors .

for example , a 55-year - old claimant was allowed benefits at a rate 4.3 times higher than a typical 35-year - old claimant .

this association is consistent with social security's vocational guidelines , which are generally more lenient for older claimants .

as part of ssa's five - step process to determine eligibility for adult disability benefits , ssa uses a set of rules to evaluate how a claimant's age , education , and work experience affect their remaining capacity for work .

ssa's criteria vary across four primary age groups — 45-49 , 50-54 , 55-59 , and 60 and older .

the criteria are less stringent for claimants in older age groups than they are for younger claimants , because the rules assume that individuals at older ages may be less able to transition to other work .

impairment: certain impairments were also strongly associated with the chance of being allowed benefits ( see fig .

7 ) .

for example , claimants with primary impairments recorded in ssa's data of heart failure or multiple sclerosis were allowed benefits at rates 4.2 and 5 times higher , respectively , than typical claimants with asthma .

from fiscal years 2007 through 2015 , the allowance rates for claimants with heart failure or multiple sclerosis were 78 and 80 percent , respectively , compared to 44 percent for asthma .

critical or terminal case: claimants with critical or terminal cases were allowed benefits at a rate 1.4 times higher than a typical claimant without a critical or terminal case .

critical and terminal cases are cases that require special processing , such as a terminal illness or a veteran with a 100-percent permanent and total disability compensation rating .

prior work: claimants reporting shorter work histories ( 4 years or less in the last 15 years before applying for disability benefits ) were allowed at a rate 0.8 times as high as a typical claimant with 10 or more years of work history .

as expected , given the nature of the work requirements for the di program , the association with prior work history was stronger for that program than for the ssi program .

college education: claimants who reported having a college - level education or higher were approved at a slightly higher rate ( 1.1 times higher ) than a typical claimant with a high - school education .

ssa officials suggested that this association could be an indirect measure of the severity of a claimant's impairment , a factor for which we did not have data .

they said that individuals with higher levels of education often have higher incomes and , therefore , may be less likely to forego their income to apply for disability benefits , were it not for the severity of their disability .

claim type: di claimants were allowed at a rate 1.7 times higher than a typical ssi claimant .

across judges , the average allowance rate for di claimants ( 67 percent ) was higher than for ssi claimants ( 52 percent ) from fiscal years 2007 through 2015 , with the allowance rate for claimants applying concurrently for di and ssi benefits falling in between ( 58 percent ) .

other participants in the disability appeals process claimants who had appointed a representative to present their case , or had a medical expert testify at their hearing , were associated with a greater chance of being allowed benefits , but the presence of a vocational expert had the opposite association .

claimant representative: similar to findings in our prior work , claimants who had a representative — either an attorney or a nonattorney representative — were allowed at a rate 2.9 times higher than a typical claimant with no representative .

ssa officials stated that representatives may have a screening process for potential clients , and under ssa's fee structure , representatives are paid only if the claimant is awarded benefits .

as a result , representatives may tend to take cases they believe will be successful .

officials also stated that a representative can help the claimant by ensuring that the medical evidence and other records are fully developed and help the claimant present their case at a hearing .

from fiscal years 2007 through 2015 , most claimants ( 77 percent ) had an attorney representative , and 12 percent had a nonattorney representative .

expert testimony: claimants whose hearings involved testimony from a medical expert were allowed at a rate 1.6 times higher than a typical claimant without a medical expert present .

medical experts include physicians , psychologists , and other types of medical professionals who provide impartial , expert opinion evidence for an alj to consider when making a decision about disability .

ssa officials said that the association of medical experts with an increased chance of allowance is expected , given that judges are required to seek the testimony of a medical expert in certain cases , for example , when the judge is considering allowing benefits because the claimant's impairment may be medically equivalent to one in ssa's listing of impairments .

in other cases , involving a medical expert is generally at the judge's discretion .

from fiscal years 2007 through 2015 , 12 percent of decisions involved a medical expert .

the presence of a vocational expert had the opposite effect — claimants with a vocational expert testifying were allowed at a rate 0.8 times as high as claimants without a vocational expert testifying .

vocational experts provide objective , expert opinion evidence to the alj , primarily at the last two steps of the disability decision - making process where ssa considers whether claimants can do their prior work or transition to other work available in the national economy .

although involving a vocational expert is generally at a judge's discretion , ssa officials said that they were not surprised by this result , because vocational experts are usually called upon at the final two steps in the disability decision - making process .

at that point , claimants had already not been allowed benefits at an earlier step because their impairment ( s ) did not meet or were not equivalent to an impairment in ssa's listings .

from fiscal years 2007 through 2015 , most hearings ( 85 percent ) involved a vocational expert .

judges with certain characteristics , such as those appointed in earlier years , were associated with a greater chance of allowing benefits .

appointment cohort: a claimant whose claim was heard by a judge appointed between 1995 and 1999 was allowed at a rate 1.5 times higher than a typical claim heard by a judge appointed after 2010 .

ssa officials said that , since 2010 , they have changed the way they train and mentor new judges , and introduced new tools to help provide a standardized decision - making template .

as a result , ssa officials said , more recently hired aljs may be more aware of agency policies and procedures .

certain characteristics of hearing offices and other factors also were associated with higher chances of allowance .

for example: hearing type: claimants whose hearings were held in person were allowed at a slightly higher rate ( 1.1 times higher ) than a typical claimant with a hearing conducted remotely using videoconference technology .

this is equivalent to a 2.8 percentage - point higher probability of being allowed benefits for a claimant whose hearing was held in person , compared to an otherwise typical claimant whose hearing was conducted by videoconference .

however , we did not seek to estimate the causal impact of videoconferences on allowance rates , and so did not design our analysis to account for all factors that could affect this relationship .

rather , we accounted for the use of videoconferences solely to further ensure that circumstances were similar across the judges and offices we analyzed .

expanding video service delivery is a key goal for ssa , including plans to partner with other agencies , such as the department of veterans affairs , to increase the number of available video hearing sites beyond those already available at hearing offices and the five national hearing centers .

year of decision: claimants whose appeals were decided in earlier years were associated with a greater chance of being allowed benefits .

while this trend is similar to the raw change over time shown in figure 4 , our multivariate analysis showed that this change held even for claimants in similar circumstances .

for example , claimants who received decisions in 2007 were allowed at a rate 2.0 times higher than a typical claim in 2015 .

this is consistent with other studies that have found trends of lower allowance rates in recent years .

factors not associated with differences in allowance rates some factors were not meaningfully associated with allowance rates when holding other factors constant .

workload measures: workload and productivity measures at the hearing office and judge level were not meaningfully associated with allowance rates .

this includes the annual percentage of cases that were backlogged ( that is , awaiting a judge's decision for more than 270 days ) at each hearing office , as well as the annual number of dispositions ( decisions plus dismissals ) each judge issued .

this may suggest that judges' decisions to allow or deny cases are not significantly influenced by the number of cases before them , similar to findings in prior research .

hearing office type: we found no meaningful differences in allowance rates between similar claims heard at one of ssa's national hearing centers or a traditional hearing office , after holding constant other factors ( including whether the hearing was held by videoconference ) .

ssa has five national hearing centers , which hear cases from across the country by videoconference in order to reduce backlogs in certain hearing offices .

economic characteristics: the unemployment and poverty rates in the claimant's state at the time of the alj decision were not associated with allowance rates .

higher unemployment rates can result in increased applications for social security disability benefits because workers with impairments that could qualify them for the program who experience job loss may find it more difficult to become re - employed during periods of high unemployment and apply for benefits .

however , the impact on allowance rates in the research we reviewed is mixed .

ssa has employed a range of efforts to monitor the accuracy and consistency of hearings decisions , but it lacks performance measures to report publicly on these efforts .

ssa's current strategic plan includes an objective to “improve the quality , consistency , and timeliness” of its disability decisions ; however , all of the hearings - level measures supporting this objective are related to timeliness .

in a previous report , we developed nine attributes of performance goals and measures based on previously established gao criteria , as well as relevant federal laws and performance management literature .

one key attribute states that an agency's suite of performance measures should be balanced to cover various priorities .

in addition , each measure should cover a priority such as quality , timeliness , and cost of service .

however , because ssa's performance measures do not fully reflect its goals , the overall success of ssa's efforts in this area may be limited .

ssa previously had performance measures related to hearings - level accuracy , which used data from alj peer reviews .

these measures were discontinued in fiscal year 2009 , when the aljs conducting the reviews were reassigned to hearing cases .

by comparison , ssa continues to have a measure for accuracy at the initial decision - making level ( see table 1 ) .

ssa officials stated that they have no plans to add new performance measures related to the accuracy and consistency of hearings decisions to the strategic plan .

they said that while they collect and monitor a wide variety of workload and performance measures for day - to - day operations , they have to select a few , representative measures that are meaningful to stakeholders and represent agency - wide efforts to achieve its goals .

they stated that the current performance measures meet these requirements .

although ssa officials said the agency does not publicly report performance measures related to the accuracy and consistency of hearings decisions , they said that ssa uses internal performance measures related to hearings decisions .

however , these internal measures to monitor quality and consistency of hearings decisions have limitations and are not shared with the public .

regional chief judges — who oversee the hearing offices and judges within each of ssa's 10 regions — and others told us that they use a measure known as the “agree rate” to help monitor the quality of a judge's decisions .

this measure is based on the number of cases that have been appealed to the appeals council by the claimant or representative as a request for review .

the agree rate reflects the percentage of cases in which the appeals council — the final level of appeals within ssa — concluded that the alj's decisions were supported by substantial evidence and contained no error of law or abuse of discretion .

however , the agree rate has some limitations .

for example , as noted earlier , it does not reflect the accuracy of alj decisions that the claimant did not appeal .

ssa's office of the inspector general ( oig ) found that this measure provided information on less than one - quarter of all alj dispositions and it is not representative of the alj's entire workload because it is based only on appeals council reviews of appealed cases .

in addition , a march 2017 ssa oig report found that ssa has not maintained historical data on agree rates , limiting the agency's ability to analyze agree rate trends .

ssa uses other internal measures to track consistency .

for example , ssa developed an internal early monitoring system that tracks 22 metrics of alj performance to identify outliers .

for example , three of these metrics ( average number of dispositions a judge issues per day , agree rate , and allowance rate ) have “alarm thresholds” to indicate when an alj's metrics fall outside of a given threshold .

based on these findings , ssa may conduct a focused quality review ( a type of quality assurance review ) to ensure the judge's decisions complied with ssa policies , or follow up with the regional chief judge to determine if additional policy guidance or training is needed .

although these internal measures are helpful for management to monitor and improve accuracy and consistency , without sharing this or similar information publicly , ssa lacks accountability for improving the quality of hearings - level decisions .

in addition , federal internal control standards state that management should externally communicate the necessary quality information to achieve objectives , including to external stakeholders such as congress and the public .

further , given the persistent variation in allowance rates , ssa may be missing an opportunity to provide the public with information on the results of its efforts to improve the accuracy and consistency of disability decisions .

ssa provides training and tools to all aljs and initiates disciplinary actions where needed , as part of its efforts to monitor and improve accuracy and consistency .

ssa also conducts multiple quality assurance reviews , but some of these reviews may overlap and ssa has not evaluated them .

training , tools , and policy guidance aljs receive ongoing training and guidance from several sources , including through judicial trainings , mentoring , and policy memorandums .

in 2006 , ssa implemented a three - phase training program for new aljs , which includes training on core competencies as well as a formal mentoring program in which new aljs are paired with experienced aljs for regular sessions over a nine - month period .

regional managers , judges , and stakeholders we spoke with had positive feedback on the training ssa provides to judges .

for example , officials from one stakeholder group told us that they believe training had created more consistency in allowance rates .

ssa's chief judge also issues guidance memorandums to clarify policies related to the hearings process .

for example , in july 2013 , ssa issued a memorandum establishing expectations for the instructions judges provide to decision writers , who are ssa staff who prepare the draft decisions .

ssa officials said that they issued the memorandum in response to an alj who was providing low - quality instructions to decision writers and ssa realized it had not provided formal guidance on the topic .

in addition , aljs also receive quarterly continuing education training and have a library of reference materials and on - demand video courses to use as needed .

ssa also uses internal metrics and provides electronic tools to judges to monitor and improve accuracy and consistency .

regional chief judges regularly review management information ( mi ) reports and develop strategies , such as recommending training , to address identified issues .

beginning in 2011 , ssa established an electronic tool called “how mi doing ? ” , which allows aljs to compare their productivity and timeliness metrics to hearing office , regional , or national metrics .

the tool also provides data on the agree rate for each judge as well as the hearing office , regional , and national agree rates .

using this tool , judges can also learn the reasons any prior decisions have been remanded , and access on - demand training pertaining to that reason .

regional chief judges we spoke with generally found “how mi doing ? ” to be a helpful tool , although ssa does not track judges' usage and has not formally evaluated its effectiveness .

in addition , ssa established the electronic bench book ( ebb ) , which is designed to assist users with documenting , analyzing , and making consistent and accurate decisions on hearings - level adult disability cases .

however , the ssa oig recently recommended that ssa evaluate ebb and determine whether to continue it .

regional chief judges we spoke with provided mixed feedback on the use of ebb and its usefulness for aljs .

in fiscal year 2016 , nearly 500 aljs ( about one - third ) used ebb .

in june 2017 , ssa officials said that while no formal evaluation of ebb was conducted , they recently received approval to proceed with plans to replace ebb with a similar tool as part of updates to ssa's case management system .

ssa also addresses identified issues with the accuracy and consistency of hearings decisions by taking disciplinary actions , as needed .

ssa can take non - disciplinary or disciplinary action to address performance concerns .

non - disciplinary actions include training and counseling ( known as “collegial conversations” ) .

another non - disciplinary action is a written directive , which ssa can issue to individual judges to improve performance on workload , scheduling or policy compliance .

from 2007 through 2016 , ssa issued about 1,330 such directives .

nearly all ( 95 percent ) were issued to improve timeliness , while about 2 percent were issued to improve policy compliance .

if an alj's conduct or performance does not change or becomes more egregious , ssa continues with progressive discipline including reprimand or seeking disciplinary action from the merit systems protection board , such as short - or long - term suspension or removal .

from 2007 through 2016 , there were 98 reprimands , 34 proposed suspensions , and 16 proposed removals , according to ssa .

ssa conducts various quality assurance reviews to improve accuracy and consistency .

ssa officials stated that the agency has been enhancing its quality review efforts since 2009 .

since then , it has added five types of quality assurance reviews that are conducted by three additional offices within ssa ( see fig .

8 ) .

ssa added quality assurance reviews for various reasons .

for example , in 2009 , ssa's regional staff under the office of the chief administrative law judge began conducting regional inline quality reviews , which involve assessing the extent to which hearing office staff are processing cases and preparing them for hearings in accordance with ssa policy , as well as the policy compliance and legal sufficiency of the draft decision .

ssa added this review to enhance its reviews of decisions before they are issued , in an effort to reduce remands .

also in 2009 , ssa's office of quality review began conducting disability case reviews to provide feedback on decision - making accuracy to aljs .

in addition , in 2010 , ssa created the division of quality under the appeals council , a unit focused on conducting reviews on a regular basis of decisions that claimants did not appeal .

prior to 2010 , ssa generally only reviewed decisions that claimants appealed through the appeals council .

while these quality assurance reviews have somewhat different focuses — for example , some assess aspects of how a case was processed while others review the accuracy of the decisions — they overlap in two key ways .

according to prior gao work , overlap occurs when multiple agencies or programs have similar goals , engage in similar activities or strategies to achieve them , or target similar beneficiaries .

some of ssa's quality review efforts fit the description of overlap in that they have similar goals and review similar cases .

for example: similar goals: several of the reviews have similar goals ( see table 2 ) .

for example , two of the four entities conducting reviews — the appeals council's division of quality and staff in ssa's 10 regional offices — both review decisions for policy compliance before those decisions go into effect ( known as pre - effectuation reviews ) .

while one review looks at the judge's decision and the other looks at the draft decision prior to the judge's review and approval , according to officials and documents we reviewed , these reviews share similar goals: to guide training and provide feedback to judges .

in addition , all the reviews are designed to assess compliance with ssa policy .

similar cases: ssa's five quality assurance reviews look at similar cases , and could potentially include the same cases ( see table 3 ) .

ssa takes some steps to prevent assessing the same claim in multiple quality assurance reviews .

officials told us that , in conducting focused quality reviews ( conducted after the decision is final ) , they exclude cases that were reviewed in a pre - effectuation review .

however , they said that the division of quality does not know whether cases it has selected were also subject to a regional inline quality review .

they said that additional efforts to prevent multiple reviews of a case are manual in nature , and thus there is still the potential for claims to be reviewed more than once .

further , ssa officials said they did not see a need to prevent multiple reviews of a case , in particular , because some reviews are conducted before the decision is final and others are conducted after the decision is final .

ssa officials stated that opportunities exist to improve coordination across offices conducting quality assurance reviews .

we found that several offices coordinated their work in some cases .

for example , ssa's division of quality and office of quality review participate in a multi - office workgroup that addresses such issues as policy compliance across the initial and hearings levels of the disability process .

in addition , they have also worked together on several studies , including a one - time quality review of 454 claims that were denied at the initial determination level , but were allowed as fully favorable at the hearings level .

the office of quality review also reviews the content of selected training for judges .

in addition , the division of quality provided some initial input when the regional inline review effort was being designed .

prior gao work has found that enhanced coordination can help to reduce overlap and improve efficiency .

effective october 1 , 2017 , ssa created a new deputy commissioner - level component , the office of analytics , review and oversight .

this agency reorganization moved six oversight offices into the new component , including the division of quality and office of quality review .

officials said the new component will create opportunities for improved coordination between these six offices .

while this reorganization creates the opportunity for ssa to assess many of its quality assurance reviews , the regional quality review staff will not be included in the new office , and it is too early to tell how this reorganization will help manage the overlap between ssa's various quality assurance reviews .

in addition , ssa has struggled to sustain all of its quality assurance reviews due to competing demands for the staff who perform them .

for example , ssa placed regional inline quality reviews on hold in september 2016 and again in december 2016 , because officials said that the agency needed staff to complete pending decisions before a change in the medical listings for mental impairments took effect in january 2017 .

decisions not completed before the new listings took effect would have to be redone .

also , the office of quality review curtailed its disability case reviews in fiscal year 2016 to help prepare the oldest cases for hearings .

as a result , only the appeals council's review of appealed alj decisions ( requests for review ) and the division of quality's quality assurance reviews were active in 2016 .

even as ssa has added quality assurance reviews , it has not systematically evaluated the efficiency and effectiveness of all the reviews to determine the extent to which they may be overlapping or complementary .

we found that reviews conducted by the four entities have resulted in similar findings , raising questions about the efficiency of these reviews .

for example , during the same 3-year period ( fiscal years 2013 through 2015 ) , quality reviews conducted by all four entities found problems with judges' assessment of a claimant's ability to perform work - related tasks , known as a residual functional capacity assessment .

in addition , all four entities found problems with the evaluation of medical opinion evidence .

moreover , ssa has not conducted a cost - benefit analysis of the five reviews .

officials said that there are no definite plans to do so , although they may consider conducting such an analysis in the future .

we found that costs for the quality assurance reviews conducted in fiscal year 2015 were at least $23.7 million , and in fiscal year 2016 were at least $11.7 million ( see table 4 ) .

by evaluating the quality assurance reviews to determine the extent to which each is needed to monitor and improve accuracy and consistency , ssa would be better positioned to meet its goals within its resources .

in addition , ssa continues to develop and implement initiatives aimed at improving hearing decisions , without evaluating the potential for overlap with existing quality assurance reviews .

for example , as part of its backlog reduction plan known as the compassionate and responsive services ( cares ) plan , ssa is using computer algorithms for natural language processing to analyze the text of disability decisions and flag potential errors .

although the agency is piloting this effort in the appeals council before expanding it to hearing offices , it did not conduct a cost - benefit analysis .

ssa officials said that natural language processing could be used to identify cases for further review , similar to its current selective reviews , and that decision writers could use the tool to conduct their own reviews of their draft decisions .

ssa officials said that they do not anticipate much overlap between the use of natural language processing and oao's pre - effectuation reviews .

however , there could be potential for overlap with regional inline reviews , which also review decisions drafted by decision writers .

federal internal control standards state that management should implement control activities through policies .

periodically reviewing policies , procedures , and related control activities for continued relevance and effectiveness in achieving objectives and addressing related risks can help agencies meet this standard .

ssa's disability programs provide more than $200 billion in benefits for tens of millions of americans annually , making it one of the largest components of the nation's social safety net .

the hearings and appeals level of the disability decision - making process is particularly important because about one in three people receiving social security disability benefits are granted benefits at this level .

given the number of people and the dollars at stake , it is crucial that claimants are treated fairly and their applications are evaluated accurately and consistently across the country , at all levels of the program .

some of the variation in allowance rates that we found across judges may be expected , given the complexity of the cases and judges' decisional independence .

however , the persistent variation we observed over time , even after accounting for various factors that could otherwise explain allowance rates , might warrant additional attention .

ssa is rightly focusing on oversight of judges , but our work suggests that the agency's emphasis on timeliness over accuracy in its public metrics and the potential overlap in its quality assurance efforts may offer opportunities for improving the accuracy and consistency of hearing decisions .

first , this amount of variation in allowance rates underscores the need for ssa to measure and hold itself accountable for accuracy and consistency .

however , without sharing performance information on the accuracy and consistency of its hearings - level decisions , such as the rate at which the appeals council agrees with a judge's decisions , ssa may not be providing the public with adequate information on progress toward its objective to improve the quality , consistency , and timeliness of its disability decisions .

developing a set of performance measures that includes the accuracy and consistency of hearings decisions will help ensure the overall success of the program .

second , ssa has not systematically considered how each of its quality assurance reviews helps the agency meet its objective to improve the quality of hearings - level decisions .

although the planned consolidation of multiple oversight and quality review offices is a positive step , it will be important for ssa to consider the usefulness of the information yielded by each quality assurance effort , as well as the costs associated with conducting the effort .

evaluating the efficiency and effectiveness of quality assurance activities can help ensure that ssa is using its resources for maximum benefit toward its objective to improve the quality , consistency , and timeliness of its disability decisions .

we are making the following two recommendations to ssa: the commissioner of ssa should develop a set of public performance measures , to include accuracy and consistency , as well as timeliness , of administrative law judges' ( alj ) disability decisions .

ssa could consider whether existing quality review or monitoring efforts could provide suitable data for such measures .

 ( recommendation 1 ) the commissioner of ssa should systematically evaluate the efficiency and effectiveness of its quality assurance reviews and take steps to reduce or better manage any unnecessary overlap among them to ensure strategic use of resources .

such steps could include enhancing collaboration where reviews overlap or only conducting the reviews that are most efficient and effective in achieving agency goals for improving accuracy and consistency of alj disability decisions .

 ( recommendation 2 ) .

in commenting on a draft of this report , ssa agreed with our two recommendations to ( 1 ) establish public performance measures for the accuracy and consistency of administrative law judges' decisions , and ( 2 ) systematically evaluate its various quality assurance reviews and take steps to reduce or better manage any unnecessary overlap among them .

ssa stated that it would address both recommendations as part of a comprehensive assessment and refinement of its oversight roles and processes .

ssa made several other comments about one of our conclusions and our analysis of variation in administrative law judge allowance rates , which we discuss below .

ssa also provided technical comments , which we incorporated into the report as appropriate .

in its comments , ssa described its evolving oversight activities at the hearings level , including providing policy guidance and training for judges , capturing and utilizing data to gain a better understanding of trends and challenges , and implementing additional oversight review processes , all of which we discussed in our report .

ssa's comments acknowledged that our report describes the steps that the agency has taken to improve oversight , but disagreed with our conclusion that ssa emphasizes timeliness over accuracy .

our final report clarifies that we came to this conclusion based on a review of the performance measures the agency shares with the public in its annual strategic plan and performance reports .

as we state in the report , ssa has employed a range of efforts to monitor the accuracy and consistency of hearings decisions , but it lacks performance measures to report publicly on these efforts .

regarding our analysis of variation in alj allowance rates , ssa raised a concern about our finding ( on page 26 of the final report ) that claimants whose hearings were held in person were slightly more likely ( by about 2.8 percentage points ) to be allowed benefits than a typical claimant with a hearing held by videoconference .

ssa cited its own internal analysis , which found a small ( 0.6 percentage - point ) difference in allowance rates between in - person and videoconference hearings after controlling for a number of factors .

it is not surprising , however , that our estimates are somewhat different , since ssa's internal analysis differs from ours in several ways .

the primary purpose of our statistical analysis was to isolate variation in allowance rates due to the unique judge or hearing office assigned to each claim .

to do this , we developed a multilevel model using 9 years of data that controls for judge , hearing office , and claimant - level factors associated with allowance rates .

on the other hand , ssa's analysis was specifically designed to look at the difference in allowance rates between in - person and video hearings .

ssa's analysis also covered a shorter , more recent period of time ( part of fiscal year 2015 , fiscal year 2016 , and part of fiscal year 2017 ) , than our study ( fiscal years 2007 through 2015 ) .

additionally , the version of the model ssa cited in its comments included hearings held in person or by videoconference only in regular hearing offices , whereas our analysis included hearings held in national hearing centers as well as regular hearing offices and controlled for the type of hearing office .

these differences notwithstanding , we agree with ssa that the estimated model - adjusted difference in allowance rates between in - person and videoconference hearings in both gao's and ssa's analyses could potentially be explained by unmeasurable factors .

in addition , ssa noted that our measure of variation in judge decisions focused on allowance rates at the extremes of the distribution .

given that our charge was to explore the extent of variation in allowance rates across judges , we believe it was appropriate and important to measure the range of allowance rates between judges with high allowance rates ( at the 95th percentile ) and those with low allowance rates ( at the 5th percentile ) .

this would be more conservative than an approach that looks at allowance rates across all judges , including potential extreme values ; and more nuanced than an approach that looks at the number of judges whose allowance rates are higher or lower than a given threshold .

further , our analysis shows that unadjusted allowance rates at the 95th percentile declined over the period of our analysis , from a high of 96 percent in fiscal year 2008 to 82 percent in fiscal year 2015 .

we saw a comparable decline in allowance rates after applying our multivariate model .

to provide additional context , our report figures also show the middle of the distribution ( the 25th and 75th percentiles ) , as well as the average allowance rates .

we have also added information to our report further describing this middle range .

finally , ssa noted that our analysis was not weighted by the number of determinations a judge made , suggesting that judges who decided very few claims , for example , could affect the range in allowance rates or the trends .

as we show in appendix i , table 7 , only 2.3 percent of the judges in our study population heard fewer than 250 claims per year .

this group of judges had an unadjusted allowance rate of 61.9 percent , very similar to the allowance rate among judges who heard 500-699 claims per year ( 61.6 percent ) .

furthermore , the statistical methods we used to estimate the distributions of allowance rates ( multilevel models ) adjust the estimates for judges with fewer claims by weighting them more heavily toward the overall approval rate .

this mitigates against judges with smaller caseloads , and therefore higher sampling variation , from contributing overestimated allowance rates that might have inflated our estimated variation across judges .

as agreed with your office , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the appropriate congressional committees , the commissioner of social security , and other interested parties .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-7215 or jeszeckc@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix iii .

our objectives were to assess ( 1 ) the extent to which allowance rates vary across administrative law judges , and any factors that are associated with this variation , and ( 2 ) the extent to which the social security administration ( ssa ) has processes to monitor the accuracy and consistency of hearings decisions .

to answer these objectives , we reviewed ssa policies and procedures related to administrative law judge ( alj ) disability hearings and decisions ; manuals and documents describing ssa's case processing systems for each level of ssa's disability decision - making process , and guidance and training provided to judges for making disability decisions .

we interviewed ssa officials in several offices within the office of disability adjudication and review ( odar ) , including the office of the chief administrative law judge and the office of appellate operations , as well as conducted semi - structured interviews with regional chief administrative law judges in each of ssa's 10 regions .

we also observed administrative law judge hearings in one of ssa's five national hearing centers , in falls church , virginia , ( hearings in these offices are conducted by videoconference ) , as well as in two of ssa's regular hearings offices , in washington , d.c. , and seattle , washington .

the purpose of these observations was to gain a better understanding of the hearings process in practice , and to inform our scope and methodology for this study .

we selected these sites , which are not generalizable to the population of all hearing offices , for a number of reasons , primarily: ( 1 ) to observe hearing offices in different geographic locations and observe both in - person and video teleconference hearings , and ( 2 ) to select sites at which a cross - section of cases with different types of disabilities and impairments were available .

we attended hearings involving both adult and child claimants with a mix of physical and mental impairments .

this appendix is divided into three parts .

the first describes our data sources and analysis of allowance rates across judges and associated factors , the second describes our multivariate statistical model , and the third describes our work related to our second research objective on ssa's processes to monitor the accuracy and consistency of hearings decisions .

for this objective , we analyzed data from two primary sources from fiscal years 2007 through 2015: ssa's administrative data systems for the initial and hearings levels of the disability decision - making process , and the agency's personnel data system .

we also obtained other ssa administrative data on staffing levels and numbers of pending cases in each hearing office .

finally , we obtained data on state poverty and unemployment rates from the u.s. census bureau and the bureau of labor statistics , respectively .

to analyze information on all adult disability decisions made by administrative law judges from fiscal years 2007 through 2015 — the most current data available at the time of our analysis — we compiled claims data from several ssa administrative data systems .

these data contained information on the outcomes of the disability decisions and the characteristics of claims associated with each decision .

specifically , the information was drawn from the following systems: 831 file and structured data repository: the 831 file pertains to the initial and reconsideration level of the disability determination process , within the state disability determination services ( dds ) .

data on claimant characteristics we used from this system include the date of the claimant's initial application for benefits and the claimant's self - reported years of education .

we also received a limited set of data captured from the claimant's disability application in ssa's electronic case folder system ( structured data repository ) , including the number of years a claimant reported being employed out of the 15 years before becoming disabled .

case processing and management system ( cpms ) : this system pertains to the hearings level and was our primary source of information on hearing outcomes , claim , and claimant characteristics .

specifically , this system provided information on claim type ( i.e. , disability insurance , di ; supplemental security income , ssi ; or concurrent claim ) ; the outcome of the claim ( i.e. , dismissed , allowed , or denied ) and the date the decision was made ; the unique identification number of the administrative law judge ( alj ) who made the decision ; whether a medical expert or vocational expert attended the hearing ; whether the claimant was represented ; the hearing office where the claim was decided and the type of hearing office ( i.e. , hearing office or national hearing center ) ; the claimant's date of birth ; the primary impairment at the time of the hearing level ; the presence of a secondary impairment ; and whether the case was classified as being a critical case — that is , a case requiring special processing , such as a terminal illness .

we used case identifiers to link the information from each of these databases that pertained to each disability decision we analyzed .

we obtained data from ssa's federal personnel and payroll system ( fpps ) database on all administrative law judges who were employed by the agency at any time during the period from january 1 , 2005 , through december 31 , 2015 .

we obtained information on each judge , such as their date of appointment as an alj and the type of appointment ( regular career appointment or non - permanent ) ; service computation date ; and prior position titles within ssa , if any .

we obtained summary - level data , as of january 2017 , from ssa on staffing levels ( numbers of aljs , decision writers , and other support staff ) at each hearing office for each fiscal year in our study period ( fiscal years 2007 through 2015 ) from ssa's payroll operational data store system .

we also obtained data on the numbers of cases left pending at the end of each fiscal year ( including the number of cases pending for more than 270 days ) .

ssa provided those data from a management information report that uses cpms data .

we used publically available estimates of state poverty rates for each year in our analysis ( calendar years 2007 through 2015 ) from the u.s. census bureau's american community survey ( acs ) .

we considered using estimates at the county level but that approach had limitations .

first , we would have been limited to using 3-year or 5-year estimates for all counties , because 1-year acs estimates are only available for areas with populations of 65,000 or more .

second , the census bureau cautions against using estimates for particular time periods that do not align with the periods of its estimates .

although using state - level estimates reduced the geographic precision of the estimates , we gained precision by having annual estimates and the ability to measure potential variation in poverty rates over narrower time intervals .

we also used publically available estimates of state unemployment rates in calendar years 2007 through 2015 from the bureau of labor statistics' local area unemployment statistics data .

this variable allowed us to control for labor market conditions over time .

ssa constructed custom files for gao from several ssa datasets in response to our data requests .

we assessed the reliability of the data used in our analyses through electronic testing , analyzing related database documentation , examining the sas code used by ssa to construct the custom files , and working with agency officials to reconcile discrepancies between the data and documentation that we received .

we determined that the 831 , structured data repository , and cpms data on alj decisions and claimant characteristics and the fpps data on alj appointments were sufficiently reliable for the purposes of describing the extent of variation in the outcomes of alj decisions .

we also determined that ssa's data on pending caseloads and alj and decision writer staffing , by year and hearing office , were sufficiently reliable for the purpose of describing hearing office characteristics .

finally , we determined that acs data on state poverty rates and bls data on state unemployment rates were sufficiently reliable for the purposes of describing these state economic characteristics .

our analyses of alj decisions excluded various types of decisions from the cpms data because they were out of scope for our research objectives ( eg , child cases , non - disability cases , or cases that were decided by ssa staff who were not aljs ) or were not typically randomly assigned to judges .

we selected cases that should have been assigned randomly to judges , according to ssa policy , because that random assignment made it more likely that variation in allowance rates across judges in our multivariate analysis reflects the unique causal effect of having a particular judge hear a case , rather than other factors that also vary across judges .

our exclusion criteria were similar to those used by an internal ssa study of alj allowance rates , conducted in 2017 .

we excluded cases that were: dismissed .

cases can be dismissed for reasons not related to the merits of the case and that are usually beyond the alj's control — for example , the claimant's failure to file a timely request or to appear at the scheduled hearing ( without good cause ) , or the claimant's death before the hearing .

in addition , data on key factors for these cases , such as the claimant's impairment , were missing .

from fiscal years 2007 through 2015 , 1,007,526 claims ( 16 percent of all claims ) were dismissed .

made “on the record” and not randomly assigned to judges .

while most appeals are decided after an alj hearing , aljs and senior attorney adjudicators ( saa ) have the authority to issue on - the - record decisions .

these are decisions where a hearing is not necessary because the documentary evidence alone supported a fully favorable decision .

ssa has created screening criteria , such as the claimant's age ( 50 and older ) and specific impairments , to help identify possible on - the - record decisions earlier in the process .

aljs and saas can also issue on - the - record decisions for cases involving critical need , and claimants and their representatives can request that the alj or saa issue an on - the - record decision .

these cases are not assigned randomly to judges .

from fiscal years 2007 through 2015 , 716,574 claims ( 11 percent of all claims ) were on - the - record decisions , although ssa has issued fewer on - the - record decisions in more recent years .

issued for children .

we excluded claimants younger than 18 at the date of the initial application .

we also excluded claimants with missing or invalid age values .

from fiscal years 2007 through 2015 , 492,158 claims ( 8 percent of all claims ) were for people under 18 or with missing or invalid age values .

we excluded child cases from our analysis because they involve different evaluation criteria .

remanded back to a judge from ssa's appeals council ( or federal court ) .

these cases represent decisions that were corrected after an order from the appeals council or a federal court after the original alj's decision .

in these cases , judges are often addressing a narrow set of issues identified in the remand order .

remanded cases are also not assigned randomly to judges , since the appeals council generally sends them back to the judge who originally issued the decision .

however , ssa's office of the inspector general ( oig ) in 2017 found that about half of the remanded cases in its sample were assigned to a different alj than the original alj .

from fiscal years 2007 through 2015 , 293,971 claims ( less than 5 percent of all claims ) were remands .

made by senior attorney adjudicators who were not administrative law judges .

we excluded decisions made by saas .

ssa implemented a program in 2007 whereby saas located in hearing offices across the country could issue fully favorable on - the - record decisions .

according to ssa , this allowed aljs to focus on cases that are more complex or require a hearing .

from fiscal years 2007 through 2015 , 227,133 claims ( 4 percent of all claims ) were decided by saas .

appeals of continuing disability reviews ( cdr ) .

these cases represent decisions about whether or not to continue benefits for claimants who were previously found eligible for the program .

as such , they involve different evaluation criteria .

from fiscal years 2007 through 2015 , 245,862 claims ( 4 percent of all claims ) were appeals of cdrs .

non - disability cases .

these cases include social security retirement and survivor benefit decisions .

we excluded such cases because they involve different evaluation criteria from disability claims and represent a small minority of decisions at the hearings level .

from fiscal years 2007 through 2015 , 25,293 claims ( less than 0.5 percent of all claims ) were for non - disability cases .

decided by judges with limited experience .

we excluded cases decided by judges within the first year ( 365 days ) after their appointment as an alj , as calculated by the difference between their date of appointment and the date of the decision on each claim .

we excluded these decisions to help ensure that variation we identified in allowance rates was not due to the judges' more limited experience deciding social security disability claims .

from fiscal years 2007 through 2015 , 574,307 claims ( approximately 9 percent of all claims ) were decided by judges with limited experience .

in total , our exclusion criteria reduced the number of records analyzed by about half .

specifically , out of a universe of about 6.3 million records , our study population included about 3.3 million decisions .

nevertheless , the overall allowance rate for our study population over fiscal years 2007 through 2015 was 62 percent , very close to the overall allowance rate for the entire population of claims during this period , which was 64 percent .

we calculated allowance rates by dividing the number of favorable decisions by the total number of decisions ( both unfavorable and favorable ) .

we calculated allowance rates for different units of analysis: overall , by program type ( disability insurance , supplemental security income , and concurrent ) and by year and for all years and program types pooled together , at the judge level , by year and for all years pooled together , and at the hearing office level , by year and for all years pooled together .

when analyzing our data at the case level , we identified whether the case was favorable or unfavorable to the claimant ( that is , whether the claimant was allowed benefits or not ) .

we did not include cases that were dismissed in our study population for two reasons .

first , as discussed above , these cases can be dismissed for reasons not related to the merits of the case , and without a review of the medical evidence .

second , ssa's data on dismissed cases are limited , partially because cases are dismissed without a review of medical evidence .

for example , the impairment code from the hearings - level decision was missing for virtually 100 percent of dismissed cases .

for concurrent claims — those in which an individual is applying for disability insurance ( di ) and supplemental security income ( ssi ) benefits — we considered a case an allowance if the claimant was approved for either or both programs .

our classification of allowances for concurrent cases differs from ssa's usual practice ( although a 2017 internal study of alj allowance rates used the same method as ours ) .

ssa officials said they usually allow the ssi decision to “control” the overall outcome of the case .

that is , ssa classifies a concurrent claim as an allowance if the ssi decision is an allowance , regardless of the outcome for the di claim .

officials said that they chose this method primarily for convenience .

this results in a different classification of some cases in which the ssi claim was denied but the di claim was allowed .

in such cases , the claimant is receiving a benefit as a result of their concurrent disability claim but would be classified in ssa's data as a denial .

however , the resulting differences in the number of allowances is very small — less than 4,000 claims over fiscal years 2007 through 2015 — and the different definitions did not substantively affect allowance rates in any year .

ssa policy states that cases are generally assigned on a “first in , first out” basis , meaning that cases are assigned to judges in the order in which they are received .

administrative law judges are assigned cases on a rotational basis , with the oldest case in the backlog given to a judge who most recently decided a case .

therefore , as noted in prior research , the initial assignment of cases to judges is random ( conditional on applying at a given hearing office at a given time ) .

judges do not select their cases , nor are claimants able to request another judge after one is assigned .

claimants are generally assigned to hearing offices based on their zip code , although some claimants in hearing offices with higher numbers of pending claims may be transferred to one of ssa's five national hearing centers .

in those cases , hearings are conducted by videoconference rather than in person , as is traditionally done in ssa's regular hearing offices .

however , the claimant may opt out of a video conference hearing within 30 days of receiving a written notice acknowledging the request for a hearing .

there are some exceptions to the “first in , first out” rule , such as cases that are likely to be dismissed or decided on the record ( without a hearing ) and critical cases ( including terminal illness cases and veterans who have a 100-percent permanent and total disability compensation rating ) .

however , as discussed previously , we have excluded all major categories of exceptions but critical cases from our analyses , and included a variable to identify critical cases in our analyses .

ssa's disability decision - making process includes five sequential steps , and one part of our analysis was to determine the step at which each decision was made .

in consultation with ssa officials , we used a code in cpms — called the regulation basis code — to assign each claim to a particular step .

each claim in cpms has between one and four regulation basis codes , depending on whether the claim was for a single program ( di or ssi ) , or a concurrent claim for both .

we assigned each claim to one of the five steps in ssa's disability decision - making process , based on its regulation basis code .

each regulation basis code is associated with one of five steps .

therefore , if a claim had just one regulation basis code , we assigned it to the corresponding step .

if a claim had more than one regulation basis code , we used a series of decision rules to select the most appropriate step .

specifically , claims for a single program have up to two regulation basis codes listed , and we used the code that matched the outcome of the case and / or the latest step .

we used a similar method for concurrent claims .

we found that approximately 19 percent of all allowances occur at step 3 , when ssa determines whether a claimant's impairment meets or is equivalent to an impairment listed in ssa's listing of impairments .

most ( 80 percent ) of all allowances are made at the final step ( step 5 ) , when ssa determines whether the claimant can do any work in the national economy , given the limitations of their impairment and their age , education , and work experience .

nearly a third ( 28 percent ) of denials are made at step 4 , where ssa determines whether the claimant can do their past work , and 62 percent of denials are made at step 5 .

there are some differences between di claims and ssi claims in the distribution of allowances and denials over the five steps .

ssi allowances occur at step 3 to a greater extent than di allowances , while ssi denials occur at step 5 to a greater extent than di denials ( see table 5 below ) .

we developed our multivariate statistical analyses in consultation with gao statisticians , economists , and social scientists and ssa officials and experts .

our analysis was also informed by a comprehensive review of the literature pertaining to judicial decision - making and , in particular , adjudication for ssa's disability programs .

specifically , we reviewed more than 90 potentially relevant peer - reviewed academic journal articles , government reports , and nonprofit association and think tank white papers .

we selected 39 of these studies or reports for a detailed review of the scope and methodology , key factors or variables used in any empirical analyses , and other relevant findings .

we also reviewed relevant ssa office of the inspector general ( oig ) reports and consulted with ssa and oig officials , and reviewed prior gao reports that modelled judicial outcomes .

our statistical model included variables that are either direct or approximate measures for: ( 1 ) claimant characteristics that represent criteria used in the disability decision - making process , ( 2 ) judge characteristics , ( 3 ) other participants in the decision - making process , ( 4 ) ssa administrative characteristics , and ( 5 ) economic characteristics of the claimant's state .

our analysis was purely statistical , in that we did not conduct the legal analysis needed to reach conclusions about what legal factors might have affected a judge's decision or whether the decision that was reached in any particular case was correct .

similarly , we are not making any predictions about the likely or correct outcome of future individual decisions .

each case is unique in both its facts and circumstances and must be examined on its own merits .

we included factors that represent criteria used in decision - making process , such as the type of claim ( di , ssi , or concurrent ) and the claimant's age , years of education ( grouped into equivalent levels: less than high school , high school , some college , and college or higher ) , and primary impairment .

we included factors related to the judge's employment as an alj , such as the year appointed as a judge , the type of appointment ( whether they had a career or temporary , non - permanent assignment ) , and any prior work history at ssa ( specifically , whether they were an attorney or held another position prior to being appointed as an alj ) .

other participants in the decision - making process we included factors that represent other participants in the decision - making process , such as the claimant's use of an attorney or non - attorney representative , or the testimony of a medical or vocational expert at the hearing .

our prior work has shown , for example , that claimants who were represented by an attorney or a person who is not an attorney ( such as a relative or professional disability representative ) were more likely to be allowed disability benefits than claimants who had no representative .

we included factors related to ssa's administration of its disability programs , such as the hearing office in which the claim was decided , whether the claim was heard in one of 10 states that do not have a reconsideration step between the initial state - level disability determination service decision and a hearing before an alj , and the percentage of pending cases at the hearing office that were pending for more than 270 days ( ssa's definition of a “backlogged” case ) .

finally , we assessed economic characteristics of the state in which the claimant resided because some prior research suggests that such factors may be associated with disability application and allowance rates .

specifically , we analyzed: the unemployment rate in the claimant's state as of the year of each decision in our analysis , from the bureau of labor statistics' local area unemployment statistics data .

we selected this factor in order to account for the labor market conditions where claimants live .

the poverty rate in the claimant's state as of the year of each decision in our analysis , from the census bureau's american community survey ( acs ) .

the primary goal of our analysis was to isolate variation in allowance rates due to the unique judge or hearing office assigned to each claim by controlling for multiple factors that could otherwise affect this variation .

some variation in allowance rates across judges and hearing offices could reflect the distribution of other factors that are correlated with allowances .

for example , judges who hear disability cases in regions of the country with higher obesity rates — a known risk factor for disability — may appear to have higher allowance rates than those in regions with low obesity rates .

because judges' decisions to allow benefits may be related to this or other factors , simple univariate comparisons of allowance rates across judges may reflect characteristics of the cases that judges hear .

to help isolate the potential unique effects of judges , we used multilevel , multivariate statistical models that held constant various factors that could have been associated with allowance rates .

we held constant variables available in ssa and other public data sources that were relevant to the claim appeals process , in order to estimate the amount of potential residual variation across judges .

the data we assembled had a multilevel structure , with applications for disability benefits clustered within the same judges and hearing offices .

judges were associated with multiple hearing offices , because judges sometimes decided cases in multiple hearing offices during the period of our analysis .

for example , judges could travel to more remote sites to hear cases on a part - time basis .

the data and outcome of interest suggested that a multilevel or mixed logistic regression model would adequately reflect the data generation process .

we developed a mixed model that represented the grouping variables — judge , hearing office , and primary diagnosis code — with random intercepts , similar to prior research .

we modeled group variation with random effects primarily for parsimony .

modeling group variation with fixed effects would have required estimating several thousand explicit parameters , one for each group level , which would have consumed many degrees of freedom .

estimating the amount of variation across groups then would have required interpreting many contrasts between pairs of fixed effect estimates .

in contrast , modeling group variation using random effects allowed us to represent the variation with probability distributions and a small number of summary ( hyper ) parameters , such as the standard deviation of the judge random effect .

substantively , random effects accurately represented the ssa policy of randomly assigning judges to cases in our study population , using a “first in , first out” method .

moreover , we modeled variation across judges and hearing offices as random , which implies that we seek to make inferences about a larger , hypothetical population of judges and hearing offices that could exist if we replicated the study in the future .

this seems appropriate , because the application review process could be repeated across many new judges and hearing offices in the future .

we do not seek to make inferences limited to the judges and hearing offices at the particular time we assembled data .

we held constant case , judge , and hearing office characteristics using covariates with fixed parameters .

the smaller number of parameters associated with these covariates made a fixed effects approach easier to apply and interpret .

we assumed that the covariate effects did not vary across groups , so that only the model's intercept varied randomly .

we had no prior expectation that specific covariate effects should have varied across groups .

moreover , increasing the number of random effects would have increased the complexity of the model and could have made it hard to estimate computationally .

we viewed the covariates primarily as controls for isolating variation across judges and offices .

we did not attempt to build a comprehensive model that correctly specified how all of the covariates were causally ordered and related to each other and the probability of an allowance .

as a result , our estimates of these parameters may not be consistent with those obtained from a more comprehensive modeling effort , or from analyses designed to estimate the causal effects of particular variables , such as the use of videoconferences .

in the body of the report , we present alternative explanations and provide context to avoid interpreting the covariate effects as with a high degree of causal certainty .

for example , we note that claims with legal representation may have higher approval rates if representatives accept claims with greater merit and , therefore , a greater chance of compensation .

below , we test alternative model specifications for covariates where the causal ordering may be ambiguous , in order to avoid biasing estimates of the judge and office parameters of primary interest .

certain variables and parameters were applied across multiple versions of the model ( described below ) .

let y denote the allowance or denial decision for claimant i at any step of the appeals process , with y = 1 if the alj allowed the claim and 0 otherwise .

each model took a typical hierarchical generalized linear form for a binary outcome: the probability of allowance , π , was a function of covariate vectors measuring characteristics of claims , xijo , characteristics of the aljs assessing those claims , xjo , and characteristics of the hearing offices where the decision occurred , x .

claimants were clustered in j = {1 , 2 , … , j} judges , and judges were clustered in o = {1 , 2 , … , o} offices .

g is the inverse logistic link function .

we included normally distributed random effects , ε ( .

 ) , for each judge , office , and the claimant's primary diagnosis , indexed by diagnosis codes d = {1 , … , d} .

random effects allowed the intercept for each group , α ( . ) .

= α + ε ( .

 ) , to vary around the population average intercept , α , as a function of the group's variance , σ ( .

 ) : to make interpretation and computation easier , we classified all continuous covariates into substantively meaningful categories , and set the omitted reference categories to the sample modes .

this transformation implied that the random effect variance , σ ( .

 ) , described variation across judges and offices for a claim that had the modal value of all other covariates in the model and sample .

the reference claim remained constant across models fitted to different subsamples , in order to make inferences about a claim that was typical for the study population .

the center of the data at the modes , α , may not necessarily correspond to an actual claim .

for example , all judges do not practice at the modal hearing office , and the modal age for the study population may not be typical for claims made in the modal office .

nevertheless , rescaling facilitates estimation and interpretation of the model , because all inference can be done on α and α ( . ) .

directly , using the random effect variance , σ ( .

 ) , without transformation .

this allowed us to concisely describe variation in allowance rates for a hypothetical , typical claim in the joint covariate distribution .

in the body of this report , we summarized variation across judges and offices , holding constant other covariates at their sample means , using the estimated distribution of group intercepts scaled in logits: to describe variation across groups on the probability scale , we estimated the quantiles bounding the middle 50 and 90 percent of the group density on the logit scale and then transformed them using the inverse logistic function , g. this reference case does not represent a feasible claim , because the means of the categorical covariates are just the sample proportions .

however , this approach complements the centering of the sample , which allows the group variance parameters , σ ( .

 ) , to represent variation across groups for a feasible reference case at the sample modes .

we fit a sequence of models using different covariates and subsamples , listed below .

fitting several models allowed us to assess how simplifying assumptions , such as ignoring the step at which aljs made allowance decisions , affected our results .

this approach also assessed the stability of estimates across multiple runs of the computational model estimation methods .

we describe the substantive meaning of the covariates above , and give their exact measurement when reporting results in table 7 below .

model 1: intercepts only model 2: add covariates ( unemployment and poverty vary at the state level , not at the office level , but we include them with the office covariates for simplicity. ) .

model 3: claims decided at steps 4 or 5 we estimated model 2 for only those claims decided at steps 4 or 5 , according to each claim's regulation basis code .

in these last two steps of the sequential disability decision - making process , the judge determines whether claimants retain the ability to perform their past work or other work in the national economy , given the limitations of their impairment and their age , education , and work experience .

ssa officials provided methods to map these codes to steps of the appeals process .

estimating the model for decisions at steps 4 or 5 allowed all parameters to vary at these steps versus all steps in the pooled sample .

for example , diagnosis may be less strongly associated with allowances at step 5 than at step 3 , while the claimant's age may be more strongly associated .

models 4-6: stratify by year of decision and claim type to assess how the amount of variation across judges and offices has changed over time , we estimated model 2 separately for each year of decision , claim type , and the cross - classification of these variables .

stratified models allowed all parameters to vary across claim types and years .

model 7: exclude potentially endogenous covariates we excluded covariates from model 2 that may not be exogenous to the probability of approval .

these include representation by an attorney or other person and the presence of a medical or vocational expert .

claims with legal representation may have higher approval rates if representatives tend to accept claims with greater merit and , therefore , a greater chance of compensation .

 ( representatives typically receive a share of their client's benefits as compensation. ) .

according to ssa officials , medical and vocational experts may be more likely to testify at a hearing , depending on the judge's expected ruling on the case .

although judges generally have discretion about whether to involve medical and vocational experts , judges are required to seek the opinion of a medical expert in certain cases .

for example , a judge must have a medical expert provide an opinion if the judge is considering allowing benefits because the claimant's impairment may be medically equivalent to one in ssa's listing of impairments .

excluding these covariates avoids potentially biasing estimates of the judge and office parameters of primary interest .

we provide the estimated distributions of allowance rates across judges , hearing offices , and primary diagnoses , holding all other covariates at their means , in table 6 below .

each row in the table lists results for one specification of the model described above .

we derived quantiles of the distributions across groups with the data and estimated model parameters , using the methods above .

the standard deviations of the allowance rates on the logit scale are explicit parameters in the model and were directly estimated with the fixed coefficients .

we used these distributions to describe variation across judges , offices , and diagnoses in the body of this report and in figures , where we interpret the results in more detail .

table 7 below provides estimated odds - ratios of allowances for the factors other than judge , hearing office , and diagnosis in our primary model of alj allowance rates ( model 2 above ) , along with sample distributions and raw allowance rates .

we used the primary model to support our findings in the body of this report , where we interpret the results below in more detail .

our model included variables that are measures or approximate measures for ( 1 ) claimant characteristics that represent criteria used in the disability decision - making process , ( 2 ) judge characteristics , ( 3 ) other participants in the decision - making process , ( 4 ) ssa administrative characteristics , and ( 5 ) economic characteristics of the claimant's state .

the interpretation of the odds ratio for a particular variable depends on whether the variable is a dummy variable or a categorical variable .

for dummy variables , a statistically significant odds ratio that is greater / less than 1.00 indicates that claimants with that characteristic are more / less likely to be allowed than claimants without it .

for categorical variables , a statistically significant odds ratio that is greater / less than 1.00 indicates that claimants in that category are more / less likely to be allowed than the claimants in the reference category .

for objective 2 , we reviewed relevant federal laws , regulations , and documentation , and collected testimonial evidence from ssa officials to describe and evaluate the processes that ssa uses to monitor hearing decisions , detect variation , and improve accuracy and consistency .

we interviewed ssa officials at different levels , including officials at headquarters , regional , dds , and field office levels .

we reviewed documents such as ssa's hearings , appeals , and litigation law ( hallex ) manual , policy memoranda issued by the chief administrative law judge , monitoring and quality assurance reports , user manuals and guides for electronic tools , ssa oig reports , and descriptions of processes that are under development .

we assessed these monitoring efforts against federal internal control standards and our management and evaluation guide for assessing fragmentation , overlap , and duplication in government programs .

we also reviewed ssa's annual performance plans from fiscal year 2006 through fiscal year 2017 to identify performance measures the agency has established to improve the accuracy and consistency of its hearings decisions .

we evaluated the current performance measures using key attributes of performance measures used in prior gao work and federal internal control standards .

in addition to interviews with agency officials , as described above , we also interviewed officials from organizations representing judges , disability claimants , and representatives to obtain their perspectives on ssa's efforts to monitor and improve accuracy and consistency .

in addition to the individual named above , erin m. godtland , assistant director ; rachael chamberlin , analyst - in - charge ; dana hopings , latoya king , stephen komadina , rhiannon patterson , and jeff tessin made significant contributions to the report .

in addition , daniel bertoni , deborah bland , david chrisinger , melinda cordero , holly dye , bill egar , alex galuten , benjamin licht , serena lo , mimi nguyen , samuel portnow , sheila mccoy , and shana wallace made valuable contributions .

