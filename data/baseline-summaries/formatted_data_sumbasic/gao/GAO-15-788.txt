the federal government is one of the world's largest and most complex entities .

to ensure that federal agencies are effectively meeting their missions , both top leaders and agency managers must have accurate and reliable performance information to monitor and track the progress they are making on achieving their goals .

for congress and the public to have confidence in the quality of the performance information that federal agencies are using to assess and achieve results , that information must be publicly reported in a clear and readily accessible way .

further , our work examining fragmentation , overlap , and duplication in federal government programs has demonstrated the need for more reliable and consistent federal data .

our previous work has shown that federal agencies do not always explain how they ensure the quality of their publicly - reported performance information .

credibility of performance information – such as agencies discussing data limitations and the actions they are taking to address these limitations .

to improve federal transparency and congress's and the public's ability to understand how federal agencies ensure the quality of performance information , the gpra modernization act of 2010 ( gprama ) requires agencies to provide this information on a public website – performance.gov – and in their annual performance plans and reports .

gao , performance reporting: few agencies reported on the completeness and reliability of performance data , gao - 02-372 ( washington , d.c.: apr .

26 , 2002 ) .

these gprama requirements expanded upon earlier requirements in the government performance and results act of 1993 ( gpra ) .

we are required by gprama to periodically report on the implementation of the act , and this report is part of that series .

report is to assess how well selected agencies publicly reported on the quality of performance information being used to measure progress for their highest priority performance goals – which gprama refers to as agency priority goals ( apgs ) .

to conduct our assessment , we selected six agencies' apgs for review based on responses to the following question from our 2013 federal managers survey: “i have sufficient information on the validity of the performance data i use to make decisions.” question was the strongest predictor of how a manager ranked his or her agency on its use of performance information .

we used responses to this question to select six agencies in the following manner: our analysis indicated that a manager's response on this ranked on their responses to this question , we selected two agencies from the top third of agencies: the national aeronautics and space administration and the department of labor .

gprama , § 15 ( b ) .

see , for example , gao , managing for results: executive branch should more fully implement the gpra modernization act to address pressing governance challenges , gao - 13-518 ( washington , d.c.: june 26 , 2013 ) , which summarizes our work on the initial implementation of gprama .

we will issue an updated assessment of gprama's implementation in september 2015 .

gao , managing for results: agencies' trends in the use of performance information to make decisions , gao - 14-747 ( washington , d.c.: sept. 26 , 2014 ) .

ranked on their responses to this question , we selected two agencies from the middle third of agencies: the departments of the interior and defense .

ranked on their responses to this question , we selected two agencies from the bottom third of agencies: the departments of agriculture and homeland security .

we reviewed all the apgs these six agencies had identified for fiscal years 2014 and 2015 .

this made for a sample of 23 apgs , which is approximately one - quarter of all federal apgs identified for fiscal years 2014 and 2015 .

to assess how well the selected agencies publicly reported on the quality of performance information for each of their apgs , we reviewed the information published on performance.gov concerning the apgs in our sample .

we also reviewed the information the selected agencies published in their annual performance plans and reports concerning these apgs .

we reviewed , if available , the agencies' most recent performance plans for fiscal year 2015 and agencies' updated performance plans for fiscal year 2014 .

we also reviewed , if available , agencies' performance plans for fiscal year 2016 and updated performance plans for fiscal year 2015 .

we also reviewed the agencies' most recent performance reports which covered fiscal years 2013 and 2014 .

we reviewed this information to see if it addressed the relevant requirements of gprama and office of management and budget ( omb ) guidance to agencies .

because both the act and guidance state that agencies should report on performance information quality for performance goals , including for each apg , we first looked for an explanation of how the agency ensured the quality of performance information for each of its apgs on performance.gov and in agency performance plans and reports .

for each apg , we determined whether the agency addressed all gprama requirements for its performance information quality discussion .

if we did not find the required performance information quality discussions for an agency's apg , we next looked for statements in performance plans and reports of how agencies said they were ensuring the quality of their agencies' performance information overall .

we focused on assessing agencies' public reporting .

therefore , our report makes no assessment of internal processes the selected agencies may have for ensuring the quality of their performance information .

we interviewed officials at each of the selected agencies and staff from the office of management and budget ( omb ) , who are responsible for working with agencies to implement gprama requirements , and staff from the performance improvement council ( pic ) , an interagency council comprised of agency performance improvement officers ( pio ) .

we shared the preliminary results of our review with agency officials and asked them to direct us to additional information , if they believed we had missed anything in our review .

we conducted this performance audit from august 2014 to september 2015 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

gprama requires agencies to publicly report on how they are ensuring the accuracy and reliability of the performance information they use to measure progress towards apgs and performance goals .

priority goals and performance measures: gprama requires agencies to identify their highest priority performance goals as apgs and have ambitious targets for these apgs that can be achieved within 2 years .

measures to track the progress they are making on achieving their apgs or identify alternative ways of measuring progress , such as milestones for completing major deliverables for the apg ( for more information on the measures and milestones the selected agencies identified , see appendix i ) .

31 u.s.c .

§ 1120 ( b ) .

gprama uses the term “measured values” instead of performance data .

we define verification as the assessment of completeness , accuracy , consistency , timeliness , and related quality control practices for performance information .

we define validation as the assessment of whether performance information is appropriate for the performance measure .

for more information , see , gao , performance plans: selected approaches for verification and validation of agency performance information , gao / ggd - 99-139 ( washington , d.c.: july 30 , 1999 ) .

the level of accuracy required for the intended use of the data ; any limitations to the data at the required level of accuracy ; and how the agency will compensate for such limitations ( if needed ) to reach the required level of accuracy .

gprama requires agencies to provide information to omb that addresses all five requirements for each of their apgs for publication on a website ( performance.gov ) .

agencies also must address all five requirements for performance goals in their performance plans and reports .

gprama states that performance.gov shall consolidate information about each apg , thereby making this information readily accessible to the public , members of congress , and congressional committees .

gprama makes omb responsible for performance.gov and requires agencies to provide omb with quarterly updates on their apgs , including how they are ensuring the quality of performance information , for publication on performance.gov .

further , gprama continues transparency requirements set in gpra that require agencies to publish annual performance plans and reports ( see text box ) .

while gprama requires certain information to be reported in performance plans and certain other information to be reported in performance reports , the reports consolidation act of 2000 authorizes agencies – with the concurrence of omb – to consolidate performance plans and reports into a single publication that covers past actual and future planned performance .

gprama's requirements for agencies' annual performance plans and reports performance plans should identify the planned level of performance for the current fiscal year and the next fiscal year , explain how the agency will ensure the accuracy and reliability of its performance information , identify the agency's priority goals ( apgs ) , and be published every february , concurrent with the president's budget .

summarize the actual level of performance agencies achieved during the previous five fiscal years , explain how the agency ensures the accuracy and reliability of its performance information , and be published every february .

guidance and information sharing on implementing gprama: omb provides guidance to agencies in circular a - 11 on how to implement gprama .

omb updates a - 11 annually , and the most recent update was published in june 2015 .

gprama also established in law an interagency council – the pic – chaired by omb and composed of agency pios to facilitate the exchange of useful practices to strengthen agency performance management , such as through cross - agency working groups .

the selected 23 apgs we reviewed are intended to drive progress in important and complex areas , such as assisting veterans , addressing climate change , and protecting workers .

given the significance and complexity of many apgs , congressional and public understanding regarding how federal agencies are measuring and assessing progress toward these goals is important .

gprama requires agencies to publicly report on how they are ensuring the accuracy and reliability of the performance information they use to measure progress towards these apgs .

however , our review found that overall , it would be challenging for congress and the public to understand how the selected agencies are ensuring that the performance information they report for their 23 apgs is accurate and reliable – that is , suitable for making judgments about agency progress or decisions for different courses of action .

we found limited information on performance.gov on the quality of performance information used to assess progress on the six selected agencies' 23 apgs .

while each agency has a section dedicated to its priority goals on performance.gov , there is no place on the website that is set aside to discuss the quality of performance information for each apg .

the six agencies we reviewed used various sections of performance.gov to discuss some of the performance information quality requirements for apgs .

but , none of the agencies addressed all five gprama requirements for their individual apgs .

moreover , while we found hyperlinks from performance.gov to the selected agencies' performance plans and reports , there was no explanation on performance.gov of where to find performance information quality discussions in these plans and reports .

we discussed our preliminary findings with omb staff in january 2015 .

in response , omb updated its a - 11 guidance in june 2015 to direct agencies to either provide information for publication on performance.gov of how they are ensuring the quality of performance information for their apgs , or provide a hyperlink from performance.gov to an appendix in their performance report that discusses the quality of their performance information .

omb staff stated that this information will likely not be available until agencies start reporting on the next set of apgs ( for fiscal years 2016 and 2017 ) .

this is because omb will need to update a template that agencies complete for their performance.gov updates .

omb staff confirmed in july 2015 that they are still using a version of this template that they provided to us in january 2015 that has not yet been updated to reflect this change .

five of the six agencies' performance plans and reports we reviewed did not describe how they ensured the quality of performance information for their individual apgs .

on the other hand , all six agencies did describe how they ensured the quality of their performance information overall .

of the 23 apgs in our sample , we could only find performance information quality discussions that addressed all five of the gprama requirements for 3 apgs , which belonged to the department of homeland security .

the u.s. department of agriculture ( usda ) provided some information for how performance information quality is ensured for one of three apgs , but did not address all requirements usda identified its apgs and briefly summarized the results achieved for each apg in its performance report for fiscal year 2014 .

further , usda's performance report provided data quality discussion for each of the performance measures presented in the 2014 report , which included the two performance measures usda used to measure progress on its reduce the number of foodborne salmonella illnesses apg .

however , usda did not address all of the gprama requirements for this apg or its two other apgs , as shown by table 1 .

for the reduce the number of foodborne salmonella illnesses apg , usda addressed two of the five gprama requirements .

for example , usda identified the centers for disease control and prevention ( cdc ) as the source of the data measuring the number of illnesses from products usda's food safety and inspection service regulates .

usda also noted that cdc receives information from state and local health agencies concerning outbreaks of illnesses .

usda acknowledges that the quality of the data can vary by reporting agency , which is an example of identifying a potential limitation .

while the fiscal year 2014 performance report did not explain how usda and cdc are compensating for this limitation , usda did provide a hyperlink in its performance report to a cdc web page that provided more detailed information about tracking and reporting of foodborne illnesses .

further , while usda described a number of steps it is taking to reduce illnesses and detect contamination in food products , usda did not explain to external audiences what level of accuracy it requires to make decisions related to this apg .

our prior work has identified improving oversight of food safety as a high - risk area , emphasizing the need to improve planning and collaboration among usda and other federal food safety agencies .

this makes it important for usda to expand its performance information quality discussion and address all requirements for this apg .

usda's performance plans and report did not address any of the five gprama requirements regarding the quality of the performance information for its two other apgs: create new economic opportunities and improve the health of our nation's soils .

the lack of information related to the two other apgs makes it more challenging for congress and the public to understand how usda is ensuring the quality of performance information , including potential limitations .

for example , usda's inspector general identified the need to develop effective performance measures as a management challenge facing the agency and raised concerns about the accuracy of some performance information .

but , usda's performance plans and report do not address this issue with regard to two of its apgs.officials in usda's office of budget and program analysis , and they acknowledged their agency could improve its public reporting on the quality of its performance information for apgs .

we shared our analysis with usda's performance report for fiscal year 2014 contained an explanation on how the agency ensures the quality of its performance information overall , which is reproduced below ( see text box ) .

this helps external audiences understand that usda's methodology for collecting performance information has been vetted by scientists and policymakers .

u.s. department of agriculture's statement on performance information quality – 2014 annual performance report the data used by the department to measure performance are collected using a standardized methodology .

this methodology has been vetted by federally employed scientists and policymakers , and , ultimately , the under secretaries of the respective mission areas .

all attest to the completeness , reliability , and quality of the data .

the department of defense ( dod ) highlighted progress for all apgs , but did not explain how performance information quality is ensured dod included performance discussions for all of its apgs and stated whether the agency had met its interim or final apg targets in its performance reports for fiscal years 2013 and 2014 ; however , it did not address the performance information quality requirements for each apg , as shown in table 2 .

while dod's fiscal year 2013 and 2014 performance reports do not describe agency - wide guidance for ensuring performance information quality , we found an explanation of dod's guidance regarding performance information quality in dod's “2014 performance plan update.” dod officials said this document was intended to serve as the agency's performance plan for fiscal year 2015 .

as reflected in table 2 , the document provided a description of dod's apgs for fiscal years 2014 and 2015 and contained a brief statement addressing agency - wide data verification and validation practices .

it states that , “at the beginning of the fiscal year , goal leaders provide action plans and verification and validation forms on each performance goal listed in the .” officials in the office of the deputy chief management officer said that dod's fiscal year 2014 performance plan update constituted their agency's fiscal year 2015 performance plan , although this purpose is not clearly explained in the document .

dod officials told us their agency would publish its 2016 performance plan as part of its agency strategic plan , which was intended for publication by the end of summer 2015 .

the secretary of defense signed this plan covering fiscal years 2015-2018 , which is dated july 31 , 2015 .

our review of the plan indicated that it described dod's performance management process .

however , it did not explain how dod will address all of the performance information quality requirements for each of the agency's apgs .

in addition , the plan did not make clear which sections of the plan were intended to address the requirement to publish a performance plan establishing performance goals for 2016 .

department of defense , annual energy management report: fiscal year 2014 ( may 2015 ) .

related to the gprama requirements , such as on their verification and validation processes .

improving the public reporting of performance information quality is important because dod's reform the dod acquisition process and dod financial statement audit readiness apgs address areas that we have identified as high risk .

for the acquisition apg , we reported in 2014 that dod expects to invest $1.5 trillion in its portfolio of major defense acquisition programs , making it particularly important that dod explains how it is ensuring the quality of performance information for this apg .

similarly , given that dod is responsible for more than half of the federal government's discretionary spending , we reported that it is particularly important dod has accurate , timely , and useful financial information .

the reliability of dod's financial information and ability to maintain effective accountability for its resources will be increasingly important to the federal government's ability to make sound resource - allocation decisions .

the department of homeland security ( dhs ) addressed gprama requirements in explaining how performance information quality is ensured for all apgs dhs presented information about performance information quality for all three of its apgs in its performance plans and reports , which included detailed discussion for 10 of the 14 performance measures used to measure progress on these apgs .

specifically , dhs published an appendix to its performance plans and reports with detailed performance information quality discussion for these measures .

for each measure , dhs's appendix describes the related program , the scope of the data , the source and collection methodology for the data , and an assessment of data reliability .

for example , for the number of convicted criminal aliens that immigration and customs enforcement removes from the country for the enforce and administer our immigration laws apg , dhs addresses the requirements for explaining verification and validation .

it explains how headquarters staff looks for unusual patterns in data field offices have entered into a database tracking removals .

dhs also states it conducts additional checks by cross - referencing data on removals reported by detention facilities and field offices , and says a statistical tracking unit does further checks .

related to the intended use of performance information , dhs explains for each performance measure discussed in this appendix how it uses the measure for decision making .

for example , dhs explains that its measure of the number of convicted criminal aliens removed from the country reflects the “full impact” of its program activities in this area .

this helps a reader understand that dhs will need a high level of accuracy to ensure that its programs are achieving its goals for this area .

we found examples of dhs acknowledging potential limitations for some apg performance measures .

for example , dhs acknowledged that the average number of days to process inquiries from individuals experiencing difficulties with travel screening for its aviation security apg does not include the time dhs is waiting for the traveler to submit all required documents .

this helps a reader understand that the performance measure may not reflect the total number of days it takes to resolve issues impeding an individual from traveling .

dhs addresses the final requirement – how the agency will compensate for limitations to reach the required level of accuracy , if needed – by stating that each apg performance measure discussed in the appendix is reliable .

further , dhs also provided more specific explanation of corrective actions for some performance measures .

for the ensure resilience to disasters apg , dhs acknowledges that there is some variation in how states and territories assess their capabilities for dealing with disasters .

but , it also explains that federal officials provide technical assistance and review the submissions from state and territorial officials to ensure that they align with guidance the federal emergency management administration provides to states and territories for how to assess their capabilities .

in addition , dhs's performance plans and reports explained how the agency ensures the quality of its performance information overall .

dhs states it has an agency - wide performance management framework , which includes a process for verifying and validating its performance information .

for example , dhs explains that one of the steps it takes is to have an independent review team assess the completeness and reliability of its performance measurement data .

by addressing the five gprama requirements for its apgs , dhs's performance plans and reports helped external audiences better understand how it ensures the accuracy and reliability of performance information for the agency's highest priority performance goals .

the department of the interior ( interior ) described how performance information quality is ensured overall , but did not address gprama requirements for its apgs interior's performance plan and report covering fiscal years 2014 through 2016 provided an overall explanation of how it verified and validated its performance information , which is reproduced in figure 1 .

interior's plan and report states that it requires component agencies to have verification and validation processes , and referred to a more detailed document on the website of interior's office of policy , management , and budget “data verification and validation standards.” these standards provide direction to component agencies on how to verify and validate performance information and other aspects of performance information quality .

for example , the standards explain that component agencies should document data sources , describe the accuracy limits of data , and identify data limitations .

interior shared these standards in june 2015 with other agencies participating in a performance improvement council cross - agency working group on data quality .

interior's performance plans and reports did not explain how performance information quality was ensured for its individual apgs .

as shown above , interior's statement on verification and validation is written at a high level and does not explain the specific steps component agencies took to ensure that performance information for each apg was accurate and reliable .

interior's deputy performance improvement officer noted that the performance plans and reports discussed the agency's performance in mission areas that relate to the apgs , and thereby provided contextual information that would allow the public to understand the quality of performance information for these apgs .

thus , they provided information on performance targets and past performance for some of the performance measures related to apgs .

the available contextual information in the performance plans and reports did not address all of the gprama performance information quality requirements for each apg .

for example , related to its water conservation apg , which aims to increase the available water supply in the western states , interior identifies the number of people and farmers the bureau of reclamation delivers water to , and reports on the acre feet of water conservation capability enabled through reclamation's programs .

while this helps external audiences understand the importance of this apg and the related mission area , interior does not explain how it is ensuring that it is accurately measuring the water conservation capability enabled through reclamation's programs .

interior explains that operating regulations require inspection of leases which produce high volumes of oil or natural gas and those leases that have a history of noncompliance at least once a year .

these inspections help ensure that hydrocarbon production on federally managed lands are properly accounted for and results in accurate royalty payments to the public and indian owners of such minerals .

federal leases .

also , this revenue is one of the federal government's largest nontax source of revenue .

the department of labor ( labor ) described the overall quality of its performance information , but not on how quality is ensured for its individual apgs labor's performance reports contained limited discussion of performance information quality for its apgs , as table 5 shows .

the reports referred readers to its summary of performance and financial information , which includes an attestation statement from the secretary of labor as to the reliability and completeness of the agency's performance information ( we reproduce these statements in the text boxes below ) .

these statements provide the reader with the secretary's assurance of the quality of labor's performance information .

however , these statements do not describe what practices are in place to ensure that the agency is using accurate and reliable performance information to measure and report on progress for its individual apgs .

department of labor's data completeness and reliability statement – fiscal year 2014 annual performance report the fiscal year 2014 summary of performance and financial information includes an assessment by the secretary of the reliability and completeness of dol ( labor's ) performance data reported under the gprama .

the department satisfies this requirement with agency head - level attestations that the data do not contain significant limitations that can lead to inaccurate assessments of results .

the secretary of labor's data quality attestation statement – fiscal year 2014 summary of performance and financial information secretary's attestation statement i attest that the summarized financial and performance data included in this document as well as the data in the agency financial report and the annual performance report are complete and reliable in accordance with federal requirements .

when we shared our analysis with labor officials , they said that they were not fully aware of the performance information quality requirements for apgs .

however , they emphasized that their agency places considerable emphasis on ensuring the quality of its performance information , and on conducting program evaluations to assess the effectiveness of its programs .

labor officials referred us to other agency publications – the department of labor fy 2014-2018 strategic plan and the department of labor fy 2016 congressional budget justification – for explanation to the public of the activities they said their agency was taking to ensure the quality of its performance information .

we confirmed that these publications do describe the agency's research and evaluation agenda .

for example , labor states in its strategic plan that it is committed to improving the quality of performance information by conducting future evaluations to ensure the outcome data it reports are accurate .

while labor's strategic plan does not explain the extent to which these data quality studies will focus on issues related to its apgs , labor does provide valuable information and important context on how it plans to ensure the quality of its performance information .

nevertheless , gprama's performance information quality requirements are important because our previous work on fragmentation , overlap , and duplication shows that labor needs to report more transparently on program performance for its veterans' employment and training programs .

this relates to one of labor's apgs on improving employment outcomes for veterans .

specifically , we reported in 2012 that labor provided congress with an annual veterans' program report that provided certain performance information , such as the number of disabled and recently separated veterans who received intensive services .

but , we found that labor was not reporting these results relative to the performance goals it had set .

we recommended in our prior work that labor report both performance goals and associated performance outcomes for its veterans' employment and training programs .

labor agreed with our recommendation and has made some progress in addressing it .

for example , labor has reported on how the results achieved for the performance measure it uses to measure progress on one of its apgs ( percent of veterans receiving intensive services served by disabled veterans outreach program specialists ) compare to the targets it set .

labor provided this information for this performance measure in both its performance report and on performance.gov .

the national aeronautics and space administration ( nasa ) described its overall approach for ensuring performance information quality , but does not explain how performance information quality for its apgs is ensured nasa's performance plans and reports characterize the agency as a performance - based organization committed to managing toward specific , measurable goals , and to using performance information to continually improve operations .

as shown in table 6 , these performance plans and reports explain how the agency ensures the quality of its performance information overall .

for example , nasa stated in its performance plans and reports that it held internal reviews for its projects , determined technology readiness levels , and required mission directorates and mission support offices to submit evidence supporting all performance measure ratings.such as scientific review committees and aeronautics technical evaluation bodies , to help it validate program performance .

these statements provide valuable insight into how nasa measures its performance and uses evidence .

further , nasa stated that it used external entities , however , nasa's performance plans and reports did not explain how the agency ensured the quality of performance information for individual apgs .

nasa presented concise summaries of each apg , progress updates , and next steps .

however , there was little explanation provided for external audiences which described how nasa took the approach it has outlined for ensuring the overall quality of its performance information , and applied this approach to individual apgs .

in our discussions with nasa officials , they emphasized that they do collect information related to all of the gprama requirements .

to illustrate this , nasa officials demonstrated their internal performance measure manager system to us in april 2015 .

nasa officials told us that the system functions as a warehouse for agency performance information and they upload information from the system to performance.gov for quarterly apg updates and to help develop their performance plans and reports .

they showed us that this system collects information on the quality of performance information for a range of performance measures , including for apgs .

for example , the internal database has a field for verification and validation materials for the james webb space telescope apg , and identifies a data limitation for it .

however , nasa does not publicly report all of the information the system collects on how it ensures the quality of performance information for its apgs .

nasa officials expressed concern about how well the gprama performance information quality requirements can be applied to their agency's performance reporting .

nasa officials said that they use what gprama and office of management and budget circular a - 11 refer to as an alternative form of performance measurement that , among other things , allows an agency to use milestones for completing major deliverables for the apg instead of performance measures .

they further explained that they use numerous milestones to measure progress on their apgs .

they added that nasa only reports on key quarterly milestones in its performance plans and reports and on performance.gov .

unlike other agencies , they noted they often do not have quantitative data sets for their performance information .

however , the gprama performance information quality requirements apply to all apgs , even if the agency is using milestones .

as we noted in our 2015 high risk update , nasa plans to invest billions of dollars in the coming years to explore space , understand earth's environment , and conduct aeronautics research .

we designated nasa's acquisition management as high risk in 1990 in view of nasa's history of persistent cost growth and schedule slippage in the majority of its major projects .

going forward , we noted in our february 2015 high risk update that it will be critical for nasa to ensure adequate and ongoing assessments of risks related to two of its apgs for developing new systems for exploring deep space and the james webb space telescope .

however , as our review shows , nasa has not explained to external audiences how it is ensuring the quality of performance information for these apgs related to these high - risk areas .

without such information , it will be more difficult for congress and the public to understand whether nasa is effectively measuring progress toward these apgs , and whether the billions of dollars being spent to accomplish these important efforts are being used effectively .

in 2015 , omb and the performance improvement council ( pic ) established the data quality cross - agency working group .

this group met for the first time in february 2015 ; and four other meetings were held in april , may , june , and july 2015 .

as of june 2015 , pic staff reported that a total of 12 agencies were participating , which is more than half of the agencies with apgs .

three of the six agencies we selected for review – the departments of defense and homeland security ( dhs ) and nasa – are participating .

dhs and nasa officials told us that they have made or plan to make presentations at these meetings on their agencies' performance information quality processes .

in addition , interior's deputy performance improvement officer shared his agency's verification and validation standards with the group .

an additional nine agencies – the departments of commerce , education , health and human services , justice , treasury , and veterans affairs , and the environmental protection agency , small business administration , and social security administration – are also participating in the group .

according to meeting notes for the may 2015 meeting provided by omb and pic staff , the group had identified several goals: improve the reliability and quality of performance information and of the reporting process ; set standards and develop consistency across agencies ; and highlight good performance measures and accurate and appropriate performance information .

the may 2015 meeting notes state the group's end product will be to identify solutions agencies have used to solve a data quality problem .

in june 2015 , the pic's executive director explained that while the group is still working on defining this end product , it wants to develop a collection of useful and leading practices that can be shared with agency officials .

the pic's executive director and her staff also noted that this end product could include providing recommendations to omb on changes that could be made to the a - 11 guidance on how to address gprama's performance information quality requirements .

omb staff also indicated to us that they would like to get input from the group on additional changes that could be made to a - 11 .

pic staff told us that the participating agencies met with omb staff in july 2015 to discuss additional changes that should be made to a - 11 .

for more than two decades , agencies have been required to publicly report on the quality of their performance information in annual performance plans .

more recently , agencies have also been required to report on performance.gov on how they will ensure the accuracy and reliability of the performance information used to measure progress on each of their highest priority performance goals , the apgs .

however , insufficient progress has been made .

while omb for several years has directed agencies to discuss the quality of apg performance information in their annual performance plans and reports , the selected agencies' plans and reports often did not .

omb recently changed its guidance to require agencies to provide this information for publication on performance.gov .

the next key step is to build upon this recent guidance to implement the change and make this important information readily accessible to the public and congress .

this overall lack of transparency means that members of congress , citizens , journalists , and researchers seeking information about agency performance related to priority goals have to search in multiple places , and often end up finding no explanation of the quality of performance information for apgs .

for agencies to maintain the confidence of congress and the public that they are indeed achieving their priority goals for the challenging and complex results they seek to achieve , agencies will need to provide more transparent explanations of how they are ensuring the accuracy and reliability of performance information for their apgs .

more broadly , our review shows that five agencies continue to provide limited information in their annual performance plans and reports concerning the quality of performance information for their apgs .

the same is true for all six agencies on performance.gov .

in some cases , the needed context and information may be available within the agency for the agency's use .

however , this information is not consistently provided to external audiences .

the performance improvement council's ( pic ) data quality cross - agency working group provides a potential forum for agencies to collaborate and share information on this topic , and the group is defining its intended end product .

given the shortcomings our review identified at the majority of the six agencies reviewed , the working group could help agencies identify practices that will help them more clearly explain to congress and the public how they are ensuring that the performance information for their highest priority performance goals is accurate and reliable .

omb could also work with this pic working group to continue updating its guidance to agencies to ensure that this information is readily accessible on performance.gov .

to improve the public reporting about how agencies are ensuring the quality of performance information used to measure progress towards their priority goals , we recommend the following actions: the secretaries of agriculture , defense , homeland security , interior , and labor , and the administrator of nasa should more fully address gprama requirements and omb guidance by working with omb to describe on performance.gov how they are ensuring the quality of performance information used to measure progress towards their apgs .

the secretaries of agriculture , defense , interior , and labor , and the administrator of nasa should more fully address gprama requirements and omb guidance by describing in their agencies' annual performance plans and reports how they are ensuring the quality of performance information used to measure progress towards their apgs .

to help participating agencies improve their public reporting , we recommend that the director of omb , working with the pic executive director , should: identify additional changes that need to be made in omb's guidance to agencies related to ensuring the quality of performance information for apgs on performance.gov .

identify practices participating agencies can use to improve their public reporting in their performance plans and reports of how they are ensuring the quality of performance information used to measure progress towards apgs .

we provided a draft of this report to the director of omb and the secretaries of agriculture , defense , homeland security , interior , and labor , and the administrator of nasa .

the department of the interior and nasa concurred with the recommendations directed to them , and discussed specific actions they plan to take to address these recommendations .

interior and nasa's written responses are reproduced in appendixes ii and iii .

in its response , nasa also shared a concern about how we portrayed its high - risk reporting in the draft report .

it stated that our draft report suggested that the select milestones identified as part of its performance reporting are the sole mechanisms nasa uses to assess risks and measure progress towards launching the james webb space telescope , and developing new systems for human exploration of deep space .

nasa further stated that to comply with reporting requirements related to apgs , it has opted to provide information on key quarterly milestones that the public can easily understand .

to address nasa's concern , we revised the report to recognize that nasa officials told us they use numerous milestones to measure progress on their apgs .

nasa also said that it only reports on key quarterly milestones in its performance plans and reports , and on performance.gov .

nasa also provided technical clarifications , which we incorporated as appropriate .

the department of homeland security ( dhs ) also concurred with the recommendation directed to it .

however , dhs stated that it has already taken action to implement our recommendation to work with omb to describe on performance.gov how dhs is ensuring the quality of performance information used to measure progress towards its apgs .

thus , dhs regards the recommendation as resolved and closed .

dhs stated that on july 1 , 2015 , agency officials in its office of program analysis and evaluation provided omb with several specific suggestions to consider as possible enhancements to the internal system that omb uses to gather agency data for public posting on performance.gov .

this will allow agencies to include more comprehensive data quality information on this public website .

dhs's efforts are an important step toward addressing our recommendation .

however , as our review found , and dhs recognizes in its response letter , more will need to be done to make dhs's explanations of performance information quality for its apgs accessible to external audiences on performance.gov .

for example , in our report we noted that omb's updated a - 11 guidance in june 2015 gives agencies the option of providing a hyperlink from performance.gov to an appendix in their performance reports containing their performance information quality discussion , which dhs could do .

we will continue to monitor dhs's efforts to work with omb to fully implement the recommendation .

dhs's written comments are reproduced in appendix iv .

the department of defense ( dod ) partially concurred with the recommendations directed to it .

dod stated that it has ongoing actions to improve the quality of performance information , and to make better use of that information in management .

however , dod stated that it did not agree that making discussion of the process of managing the quality of performance information a part of either the agency strategic plan or annual reporting has any major management value .

we disagree .

first , gprama does not require , nor did we recommend , that dod provide information on the quality of performance information for its agency priority goals in its agency strategic plan .

second , gprama does require that this information be provided in agency performance plans and reports and on performance.gov .

we continue to believe it is important for dod to fully address these gprama requirements because , as described in our report , two of dod's apgs address areas we have identified as high risk .

also , dod is responsible for more than half of the federal government's discretionary spending .

dod's written comments are reproduced in appendix v. the departments of agriculture ( usda ) and labor did not comment on the recommendations directed to them .

however , they both discussed specific actions they plan to take to improve the quality of their publicly - reported performance information for their agency priority goals .

in comments relayed to us in an august 14 , 2015 , e - mail from the associate director of usda's office of budget and program analysis , who is also the agency's performance improvement officer ( pio ) , he stated the agency would ensure that a description of the quality of performance information be added for each performance measure included in its apgs for fiscal years 2016 and 2017 .

he also stated that usda will work with omb to put this information on performance.gov or in its annual performance plan and report with a reference to that information on performance.gov .

he also stated a reference to this information would be provided in usda's annual performance plan .

he also provided us with a technical clarification , which we incorporated .

in its response , labor raised a concern about statements in our draft report regarding information on several of its programs that serve veterans , which were drawn from our prior work .

labor stated that the report incorrectly asserts that it does not report on the number of veterans receiving intensive services relative to performance goals .

rather , labor stated that it has used the veterans' employment and training services measure for the percent of veterans being served by the disabled veterans' outreach program as an apg for 4 years , and has included how results relate to performance goals .

additionally , labor asserted that outcomes for the veterans workforce investment program have been included in the annual report to congress in fiscal years 2013 and 2014 .

we revised the report to reflect labor's updated actions as appropriate .

labor's written comments are reproduced in appendix vi .

in an august 26 , 2015 , e - mail from omb's liaison to gao , omb did not comment on the recommendations , but provided technical clarifications , which we incorporated as appropriate .

we are sending copies of this report to the director of omb and the heads of the agencies we reviewed as well as appropriate congressional committees and other interested parties .

in addition , this report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff members have any questions about this report , please contact me at ( 202 ) 512-6806 or mihmj@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix vii .

j. christopher mihm , ( 202 ) 512-6806 or mihmj@gao.gov .

in addition to the contact named above , sarah e. veale , assistant director , and michael o'neill , analyst - in - charge , supervised the development of this report .

virginia chanley , emily christoff , erik kjeldgaard , and a.j .

stephens made significant contributions to all aspects of this report .

deirdre duffy and robert robinson provided additional assistance .

