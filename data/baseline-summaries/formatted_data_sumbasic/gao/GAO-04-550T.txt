i am pleased to be here today to discuss performance budgeting and the office of management and budget's ( omb ) program assessment rating tool ( part ) .

since the 1950s , the federal government has attempted several governmentwide initiatives designed to better align spending decisions with expected performance — what is commonly referred to as “performance budgeting.” the consensus is that prior efforts — including the hoover commission , the planning - programming - budgeting - system , management by objectives , and zero - based budgeting — did not succeed in significantly shifting the focus of the federal budget process from its long - standing concentration on the items of government spending to the results of its programs .

however , the persistent attempts reflect a long - standing interest in linking resources to results .

in the 1990s , congress and the executive branch laid out a statutory and management framework that provides the foundation for strengthening government performance and accountability , with the government performance and results act of 1993 ( gpra ) as its centerpiece .

gpra is designed to inform congressional and executive decision making by providing objective information on the relative effectiveness and efficiency of federal programs and spending .

a key purpose of the act is to create closer and clearer links between the process of allocating scarce resources and the expected results to be achieved with those resources .

we have learned that this type of integration is critical from prior initiatives that failed in part because they did not prove to be relevant to budget decision makers in the executive branch or congress .

gpra requires both a connection to the structures used in congressional budget presentations and consultation between the executive and legislative branches on agency strategic plans ; this gives congress an oversight stake in gpra's success .

this administration has made the integration of performance and budget information one of five governmentwide management priorities under the president's management agenda ( pma ) .

central to this initiative is part .

omb developed part as a diagnostic tool meant to provide a consistent approach to evaluating federal programs and applied it in formulating the president's fiscal years 2004 and 2005 budget requests .

part covers four broad topics for all “programs” selected for review: ( 1 ) program purpose and design , ( 2 ) strategic planning , ( 3 ) program management , and ( 4 ) program results ( i.e. , whether a program is meeting its long - term and annual goals ) as well as additional questions that are specific to one of seven mechanisms or approaches used to deliver the program .

gpra expanded the supply of performance information generated by federal agencies , although as the part assessments demonstrate , more must be done to develop credible performance information .

however , improving the supply of performance information is in and of itself insufficient to sustain performance management and achieve real improvements in management and program results .

rather , it needs to be accompanied by a demand for that information by decision makers and managers alike .

part may mark a new chapter in performance - based budgeting by more successfully stimulating demand for this information — that is , using the performance information generated through gpra's planning and reporting processes to more directly feed into executive branch budgetary decisions .

my statement today focuses on seven points: part helped structure omb's use of performance information for its internal program and budget analysis , made the use of this information more transparent , and stimulated agency interest in budget and performance integration .

moreover , it illustrated the potential to build on gpra's foundation to more actively promote the use of performance information in budget decisions .

the goal of part is to evaluate programs systematically , consistently , and transparently .

omb went to great lengths to encourage consistent application of part in the evaluation of government programs , including pilot testing the instrument , issuing detailed guidance , and conducting consistency reviews .

although there is undoubtedly room for continued improvement , any tool is inherently limited in providing a single performance answer or judgment on complex federal programs with multiple goals .

performance measurement challenges in evaluating complex federal programs make it difficult to meaningfully interpret a bottom - line rating .

the individual section ratings for each part review provided a better understanding of areas needing improvement than the overall rating alone .

as is to be expected with any new reform , part is a work in progress and we have noted in our work where omb might make improvements .

any tool that is sophisticated enough to take into account the complexity of the u.s. government will require some exercise of judgment .

therefore it is not surprising that we found some inconsistencies in omb staff interpreting and applying part .

part provides an opportunity to more efficiently use scarce analytic resources , to focus decision makers' attention on the most pressing policy issues , and to consider comparisons and trade - offs among related programs by more strategically targeting part assessments based on such factors as the relative priorities , costs , and risks associated with related clusters of programs and activities .

the first year part assessments underscored the long - standing gaps in performance and evaluation information throughout the federal government .

by reaching agreement on areas in which evaluations are most essential , decision makers can help ensure that limited resources are applied wisely .

the relationship between part and its process and the broader gpra strategic planning process is still evolving .

although part can stimulate discussion on program - specific performance measurement issues , it is not a substitute for gpra's strategic , longer - term focus on thematic goals and department - and governmentwide crosscutting comparisons .

part and gpra serve different but complementary needs , so a strategy for integrating the two could help strengthen both .

federal programs are designed and implemented in dynamic environments where competing program priorities and stakeholders' needs must be balanced continually and new needs must be addressed .

while part clearly serves the needs of omb in budget formulation , questions remain about whether it serves the various needs of other key stakeholders .

if the president or omb wants part and its results to be considered in the congressional debate , it will be important for omb to ( 1 ) involve congressional stakeholders early in providing input on the focus of the assessments ; ( 2 ) clarify any significant limitations in the assessments as well as the underlying performance information ; and ( 3 ) initiate discussions with key congressional committees about how they can best take advantage of and leverage part information in congressional authorization , appropriations , and oversight processes .

moreover , congress needs to consider ways it can articulate its oversight priorities and performance agenda .

my statement is based on our recently published report on omb's part in which we reviewed the first year of the part process — fiscal year 2004 — and changes in the part process initiated for fiscal year 2005 .

we have not reviewed or analyzed the part results for the fiscal year 2005 budget request .

for this testimony , this subcommittee asked us to discuss our overall findings and recommendations concerning part to help frame today's hearing .

we conducted our work in accordance with generally accepted government auditing standards .

through its development and use of part , omb has more explicitly infused performance information into the budget formulation process ; increased the attention paid to performance information and program evaluations ; and ultimately , we hope , increased the value of this information to decision makers and other stakeholders .

by linking performance information to the budget process , omb has provided agencies with a powerful incentive for improving both the quality and availability of performance information .

the level of effort and involvement by senior omb officials and staff clearly signals the importance of this strategy in meeting the priorities outlined in the pma .

omb should be credited with opening up for scrutiny — and potential criticism — its review of key areas of federal program performance and then making its assessments available to a potentially wider audience through its web site .

as omb and others recognize , performance is not the only factor in funding decisions .

determining priorities — including funding priorities — is a function of competing values and interests .

accordingly , we found that while part scores were generally positively related to proposed funding changes in discretionary programs , the scores did not automatically determine funding changes .

that is , for some programs rated “effective” or “moderately effective” omb recommended funding decreases , while for several programs judged to be “ineffective” omb recommended additional funding in the president's budget request with which to implement changes .

in fact , the more important role of part was not its use in making resource decisions , but in its support for recommendations to improve program design , assessment , and management .

our analysis of the fiscal year 2004 part found that 82 percent of the recommendations addressed program assessment , design , and management issues ; only 18 percent of the recommendations had a direct link to funding matters .

omb's ability to use part to identify and address future program improvements and measure progress — a major purpose of part — depends on its ability to oversee the implementation of part recommendations .

as omb has recognized , following through on these recommendations is essential for improving program performance and ensuring accountability .

currently , omb plans to assess an additional 20 percent of all federal programs annually .

as the number of recommendations from previous years' evaluations grows , a system for monitoring their implementation will become more critical .

however , omb does not have a centralized system to oversee the implementation of such recommendations or evaluate their effectiveness .

the goal of part is to evaluate programs systematically , consistently , and transparently .

omb went to great lengths to encourage consistent application of part in the evaluation of government programs , including pilot testing the instrument , issuing detailed guidance , and conducting consistency reviews .

although there is undoubtedly room for continued improvement , any tool is inherently limited in providing a single performance answer or judgment on complex federal programs with multiple goals .

omb recognized the complexity inherent in evaluating federal programs by differentiating its rating tool for seven mechanisms or approaches used to deliver services , ranging from block grants to research and development .

however , judgment is involved in classifying programs by these categories since many programs fit into more than one of these groupings .

omb guidance , for instance , acknowledges that some research and development programs can also be evaluated as competitive grants and capital assets .

performance measurement challenges in evaluating complex federal programs make it difficult to meaningfully interpret a bottom - line rating .

omb published both a single , bottom - line rating for part results and individual section scores .

it is these latter scores that are potentially more useful for identifying information gaps and program weaknesses .

for example , in the fiscal year 2004 part , one program that was rated “adequate” overall got high scores for purpose ( 80 percent ) and planning ( 100 percent ) , but poor scores in being able to show results ( 39 percent ) and in program management ( 46 percent ) .

in a case like this , the individual section ratings provided a better understanding of areas needing improvement than the overall rating alone .

in addition , bottom - line ratings may force raters to choose among several important but disparate goals and encourage a determination of program effectiveness even when performance data are unavailable , the quality of those data is uneven , or they convey a mixed message on performance .

any tool that is sophisticated enough to take into account the complexity of the u.s. government will always require some interpretation and judgment .

therefore it is not surprising that omb staff were not fully consistent in interpreting complex questions about agency goals and results .

many part questions contain subjective terms that are open to interpretation .

examples include terminology such as “ambitious” in describing sought - after performance measures .

because the appropriateness of a performance measure depends on the program's purpose , and because program purposes can vary immensely , an ambitious goal for one program might be unrealistic for a similar but more narrowly defined program .

without further guidance , it is unclear how omb staff can be expected to be consistent .

we also found inconsistencies in how the definition of acceptable performance measures was applied .

our review of the fiscal year 2004 part surfaced several instances in which omb staff inconsistently defined appropriate measures — outcome versus output — for programs .

agency officials also told us that omb staff used different standards to define measures as outcome - oriented .

outputs are the products and services delivered by the program whereas outcomes refer to the results of outputs .

for example , in the employment and training area , omb accepted short - term outcomes , such as obtaining high school diplomas or employment , as a proxy for long - term goals for the department of health and human services' refugee assistance program , which aims to help refugees attain economic self - sufficiency as soon as possible .

however , omb did not accept the same employment measure as a proxy for long - term goals for the department of education's vocational rehabilitation program because it had not set long - term targets beyond a couple of years .

in other words , although neither program contained long - term outcomes , such as participants gaining economic self - sufficiency , omb accepted short - term outcomes in one instance but not the other .

the yes / no format employed throughout most of the part questionnaire resulted in oversimplified answers to some questions .

although omb believes it helped standardization , the yes / no format was particularly troublesome for questions containing multiple criteria for a “yes” answer .

agency officials have commented that the yes / no format can oversimplify reality , in which progress in planning , management , or results is more likely to resemble a continuum than an on / off switch .

our review of the fiscal year 2004 part found several instances in which some omb staff gave a “yes” answer for successfully achieving some but not all of the multiple criteria , while others gave a “no” answer when presented with a similar situation .

for example , omb judged the department of the interior's ( doi ) water reuse and recycling program “no” on whether a program has a limited number of ambitious , long - term performance goals , noting that although doi set a long - term goal of 500,000 acre - feet per year of reclaimed water , it failed to establish a time frame for when it would reach the target .

however , omb judged the department of agriculture's and doi's wildland fire programs “yes” on this question even though the programs' long - term goals of improved conditions in high - priority forest acres are not accompanied by specific time frames .

the lack of program performance information also creates challenges in effectively assessing program performance .

according to omb , about half of the programs assessed for fiscal year 2004 lacked “specific , ambitious long - term performance goals that focus on outcomes” and nearly 40 percent lacked sufficient “independent , quality evaluations.” nearly 50 percent of programs assessed for fiscal year 2004 received ratings of “results not demonstrated” because omb decided that program performance information , performance goals , or both were insufficient or inadequate .

while the validity of these assessments may be subject to interpretation and debate , our previous work has raised concerns about the capacity of federal agencies to produce evaluations of program effectiveness as well as credible data .

in our report on part , we note that several factors have limited the availability of performance data and evaluations of federal programs , including the lack of statutory mandates and funding to support data collection and analysis .

our work has recognized that research programs pose particular and long - standing challenges for performance assessments and evaluations .

for instance , in both applied and basic research , projects take several years to complete and require more time before their meaning for the field can be adequately understood and captured in performance reporting systems .

these challenges can and have been addressed by federal and private research organizations .

one evaluation approach we have identified in our review of leading practices is the use of peer review to evaluate the quality of research outcomes .

for example , the national science foundation ( nsf ) convenes panels of independent experts as external advisers — a committee of visitors ( cov ) — to peer review the technical and managerial stewardship of a specific program or cluster of programs periodically .

the cov compares research plans with progress made , and evaluates outcomes to determine whether the research contributes to nsf mission and goals .

part was designed for and is used in the executive branch budget preparation and review process .

as a result , the goals and measures used in part must meet omb's needs .

by comparison , gpra — the current statutory framework for strategic planning and reporting — is a broader process involving the development of strategic and performance goals and objectives to be reported in strategic and annual plans and reports .

omb said that gpra plans were organized at too high a level to be meaningful for program - level budget analysis and management review .

omb acknowledges that gpra was the starting point for part , but as i will explain , it appears that omb's emphasis is shifting such that over time the performance measures developed for part and used in the budget process may also come to drive agencies' strategic planning processes .

the fiscal year 2004 part process came to be a parallel competing structure to the gpra framework as a result of omb's desire to collect performance data that better align with budget decision units .

omb's most recent circular a - 11 guidance clearly requires both that each agency submit a performance budget for fiscal year 2005 and that this should replace the annual gpra performance plan .

these performance budgets are to include information from the part assessments , where available , including all performance goals used in the assessment of program performance done under the part process .

until all programs have been assessed using part , the performance budget will also include performance goals for agency programs that have not yet been assessed .

omb's movement from gpra to part is further evident in the fiscal year 2005 part guidance stating that while existing gpra performance goals may be a starting point during the development of part performance goals , the gpra goals in agency gpra documents are to be revised , as needed , to reflect omb's instructions for developing the part performance goals .

lastly , this same guidance states that gpra plans should be revised to include any new performance measures used in part and that unnecessary measures should be deleted from gpra plans .

in its comments to another recently issued gao report , omb stated that it will revise its guidance for both gpra and part to clarify the integrated and complementary relationship between the two initiatives .

although there is potential for complementary approaches to gpra and part , the following examples clearly illustrate the importance of carefully considering the implications of selecting a unit of analysis , including its impact on the availability of performance data .

they also reveal some of the unresolved tensions between the president's budget and performance initiative — a detailed budget perspective — and gpra — a more strategic planning view .

experience with part highlighted the fact that defining a “unit of analysis” useful for both program - level budget analysis and agency planning purposes can be difficult .

for example , disaggregating programs for part purposes could ignore the interdependence of programs recognized by gpra by artificially isolating programs from the larger contexts in which they operate .

agency officials described one program assessed with the fiscal year 2004 part — projects for assistance in transition from homelessness — that was aimed at a specific aspect of homelessness , that is , referring persons with emergency needs to other agencies for housing and needed services .

omb staff wanted the agency to produce long - term outcome measures for this program to support the part review process .

agency officials argued that chronically homeless people require many services and that this federal program often supports only some of the services needed at the initial stages of intervention .

gpra — with its focus on assessing the relative contributions of related programs to broader goals — is better designed to consider crosscutting strategies to achieve common goals .

federal programs cannot be assessed in isolation .

performance also needs to be examined from an integrated , strategic perspective .

one way of improving the links between part and gpra would be to develop a more strategic approach to selecting and prioritizing areas for assessment under the part process .

targeting part assessments based on such factors as the relative priorities , costs , and risks associated with related clusters of programs and activities addressing common strategic and performance goals not only could help ration scarce analytic resources but also could focus decision makers' attention on the most pressing policy and program issues .

moreover , such an approach could facilitate the use of part assessments to review the relative contributions of similar programs to common or crosscutting goals and outcomes established through the gpra process .

we have previously reported that stakeholder involvement appears critical for getting consensus on goals and measures .

in fact , gpra requires agencies to consult with congress and solicit the views of other stakeholders as they develop their strategic plans .

stakeholder involvement can be particularly important for federal agencies because they operate in a complex political environment in which legislative mandates are often broadly stated and some stakeholders may strongly disagree about the agency's mission and goals .

the relationship between part and its process and the broader gpra strategic planning process is still evolving .

as part of the executive branch budget formulation process , part must clearly serve the president's interests .

some tension about the amount of stakeholder involvement in the internal deliberations surrounding the development of part measures and the broader consultations more common to the gpra strategic planning process is inevitable .

compared to the relatively open - ended gpra process , any budget formulation process is likely to seem closed .

yet , we must ask whether the broad range of congressional officials with a stake in how programs perform will use part assessments unless they believe the reviews reflect a consensus about performance goals among a community of interests , target performance issues that are important to them as well as the administration , and are based on an evaluation process in which they have confidence .

similarly , the measures used to demonstrate progress toward a goal , no matter how worthwhile , cannot serve the interests of a single stakeholder or purpose without potentially discouraging use of this information by others .

congress has a number of opportunities to provide its perspective on performance issues and performance goals , such as when it establishes or reauthorizes a new program , during the annual appropriations process , and in its oversight of federal operations .

in fact , these processes already reflect gpra's influence .

reviews of language in public laws and committee reports show an increasing number of references to gpra - related provisions .

what is missing is a mechanism to systematically coordinate a congressional perspective and promote a dialogue between congress and the president in the part review process .

in our report , we have suggested steps for both omb and the congress to take to strengthen the dialogue between executive officials and congressional stakeholders .

we have recommended that omb reach out to key congressional committees early in the part selection process to gain insight about which program areas and performance issues congressional officials believe warrant part review .

engaging congress early in the process may help target reviews with an eye toward those areas most likely to be on the agenda of congress , thereby better ensuring the use of performance assessments in resource allocation processes throughout government .

we have also suggested that congress consider the need to develop a more systematic vehicle for communicating its top performance concerns and priorities ; develop a more structured oversight agenda to prompt a more coordinated congressional perspective on crosscutting performance issues ; and use this agenda to inform its authorization , appropriations , and oversight processes .

the part process is the latest initiative in a long - standing series of reforms undertaken to improve the link between performance information and budget decisions .

although each of the initiatives of the past appears to have met with an early demise , in fact , subsequent reforms were strengthened by building on the legacy left by their predecessors .

prior reforms often failed because they were not relevant to resource allocation and other decision - making processes , thereby eroding the incentives for federal agencies to improve their planning , data , and evaluations .

unlike many of those past initiatives , gpra has been sustained since its passage 10 years ago , and evidence exists that it has become more relevant than its predecessors .

part offers the potential to build on the infrastructure of performance plans and information ushered in by gpra and the law's intent to promote the use of these plans in resource allocation decision making .

gpra improved the supply of plans and information , while part can prompt greater demand for this information by decision makers .

enhancing interest and use may bring about greater incentives for agencies to devote scarce resources to improving their information and evaluations of federal programs as well .

increasing the use and usefulness of performance data is not only important to sustain performance management reforms , but to improve the processes of decision making and governance .

many in the united states believe there is a need to establish a comprehensive portfolio of key national performance indicators .

this will raise complex issues ranging from agreement on performance areas and indicators to getting and sharing reliable information for public planning , decision making , and accountability .

in this regard , the entire agenda of management reform at the federal level has been focused on shifting the attention of decision makers and agency management from process to results .

although part is based on changing the orientation of budgeting , other initiatives championed by congress and embodied in the pma are also devoted to improving the accountability for performance goals in agency human capital management , financial management , competitive sourcing , and other key management areas .

in particular , we have reported that human capital — or people — is at the center of any serious change management initiative .

thus , strategic human capital management is at the heart of government transformation .

high - performing organizations strengthen the alignment of their gpra strategic and performance goals with their daily operations .

in that regard , performance management systems can be a vital tool for aligning an organization's operations with individual day - to - day activities , but they are currently largely unused .

as we move forward to strengthen government performance and accountability , effective performance management systems can be a strategic tool to drive internal change and achieve desired results .

the question now is how to enhance the credibility and use of the part process as a tool to focus decisions on performance .

in our report , we make seven recommendations to omb and a suggestion to congress to better support the kind of collaborative approach to performance budgeting that very well may be essential in a separation of powers system like ours .

our suggestions cover several key issues that need to be addressed to strengthen and help sustain the part process .

we recommend that the omb director take the following actions: centrally monitor agency implementation and progress on part recommendations and report such progress in omb's budget submission to congress .

governmentwide councils may be effective vehicles for assisting omb in these efforts .

continue to improve the part guidance by ( 1 ) expanding the discussion of how the unit of analysis is to be determined to include trade - offs made when defining a unit of analysis , implications of how the unit of analysis is defined , or both ; ( 2 ) clarifying when output versus outcome measures are acceptable ; and ( 3 ) better defining an “independent , quality evaluation.” clarify omb's expectations to agencies regarding the allocation of scarce evaluation resources among programs , the timing of such evaluations , as well as the evaluation strategies it wants for part , and consider using internal agency evaluations as evidence on a case - by - case basis — whether conducted by agencies , contractors , or other parties .

reconsider plans for 100 percent coverage of federal programs and , instead , target for review a significant percentage of major and meaningful government programs based on such factors as the relative priorities , costs , and risks associated with related clusters of programs and activities .

maximize the opportunity to review similar programs or activities in the same year to facilitate comparisons and trade - offs .

attempt to generate , early in the part process , an ongoing , meaningful dialogue with congressional appropriations , authorization , and oversight committees about what they consider to be the most important performance issues and program areas that warrant review .

seek to achieve the greatest benefit from both gpra and part by articulating and implementing an integrated , complementary relationship between the two .

in its comments on our report , omb outlined actions it is taking to address several of these recommendations , including refining the process for monitoring agencies' progress in implementing the part recommendations , seeking opportunities for dialogue with congress on agencies' performance , and continuing to improve executive branch implementation of gpra plans and reports .

our recommendations to omb are partly directed at fortifying and enhancing the credibility of part itself and the underlying data used to make the judgments .

decision makers across government are more likely to rely on part data and assessments if the underlying information and the rating process are perceived as being credible , systematic , and consistent .

enhanced omb guidance and improved strategies for obtaining and evaluating program performance data are vital elements .

the part process can be made more sustainable if the use of analytic resources at omb and the agencies is rationalized by reconsidering the goal of 100 percent coverage of all federal programs .

instead , we suggest a more strategic approach to target assessments on related clusters of programs and activities .

a more targeted approach stands a better chance of capturing the interest of decision makers throughout the process by focusing their attention on the most pressing policy and program issues and on how related programs and tools affect broader crosscutting outcomes and goals .

unfortunately , the governmentwide performance plan required by gpra has never been engaged to drive budgeting in this way .

improving the integration of inherently separate but interrelated strategic planning and performance budgeting processes can help support a more strategic focus for part assessments .

gpra's strategic planning goals could be used to anchor the selection and review of programs by providing a foundation to assess the relative contribution of related programs and tools to broader performance goals and outcomes .

finally , refining the part questionnaire and review process and improving the quality of data are important , but the question of whose interests drive the process is perhaps paramount in our system .

ultimately , the impact of part on decision making will be a function not only of the president's decisions , but of congressional decisions as well .

much is at stake in the development of a collaborative performance budgeting process .

not only might the part reviews ultimately come to be disregarded absent congressional involvement , but more important , congress will lose an opportunity to use the part process to improve its own decision - making and oversight processes .

this is an opportune time for the executive branch and congress to carefully consider how agencies and committees can best take advantage of and leverage the new information and perspectives coming from the reform agenda under way in the executive branch .

ultimately , the specific approach or process is not important .

we face a long - term fiscal imbalance , which will require us to reexamine our existing policies and programs .

it is all too easy to accept “the base” as given and to subject only new proposals to scrutiny and analysis .

the norm should be to reconsider the relevance or “fit” of any federal program , policy , or activity in today's world and for the future .

mr. chairman , this concludes my prepared statement .

i would be pleased to answer any questions you or the other members of the subcommittee may have at this time .

for future contacts regarding this testimony , please contact paul l. posner , managing director , federal budget issues , at ( 202 ) 512-9573 .

individuals making key contributions to this testimony included denise m. fantone , kristeen mclain and tiffany tanner .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

it may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

