in february 2005 , we issued a report that raised concerns about the effectiveness of oversight of the head start program .

we made a number of recommendations to improve the department of health and human services ( hhs ) administration for children and families' ( acf ) oversight of local organizations that receive head start program grants and the grantees' financial management .

head start is one of the largest federal early childhood programs .

in fiscal year 2007 , head start provided nearly $7 billion to 1,604 local organizations that provide a wide range of services to over 900,000 primarily low - income children , from birth to age 5 , and their families .

these services are aimed at improving the social competence , learning skills , and health and nutrition status of low - income children so that they can begin school ready to learn .

acf spent $25.6 million in fiscal year 2006 to conduct its oversight activities .

since our 2005 report , acf has implemented a number of changes designed to improve its monitoring and other oversight of grantees .

however , policymakers have raised new concerns about the scope of these changes and whether they are likely to strengthen the performance of head start grantees , suggesting a need to reassess acf's monitoring and oversight activities .

to respond to your request for more information about acf's monitoring and oversight of the head start program , we examined: 1 .

acf's progress in conducting a risk assessment of the head start program and ensuring the accuracy and reliability of data from its annual program information report ( pir ) survey of grantees , 2 .

acf's efforts to improve its on - site monitoring processes , and 3 .

acf's use of data to improve oversight and help grantees meet performance standards .

to address these objectives , we visited and interviewed office of head start and acf officials and their staff in washington , d.c. we interviewed staff from all of acf's 10 regional offices and reviewed relevant documentation from each of these offices .

we administered a web - based survey to a nationally - representative sample of head start and early head start program directors .

we selected our sample of directors from the population of directors whose programs were the subject of acf's on - site reviews from october 2005 through march 2007 using a newly revised on - site review process .

in total , we surveyed 329 program directors , asking them about their experiences during the most recent on - site reviews , and their views about the changes to the process .

of the 329 program directors , 261 responded — for a response rate of 79 percent .

throughout this report , when we refer to our survey results , we use the terms “program directors” and “grantees” interchangeably .

finally , we tested the reliability of two of acf's administrative databases — the first contains data on the results of each grantee's on - site review , and the second contains data from acf's annual pir survey of grantees .

to assess the reliability of on - site review data , we relied on our 2005 assessment of the reliability of these data , performed additional electronic tests of data elements used for an analysis of the extent of repeat on - site review findings , and reviewed new information about the database .

based on our previous and updated assessments , we find the on - site review data used for our analysis of on - site review findings to be sufficient for the purpose of this report .

however , we identified concerns about the overall reliability of data from acf's annual pir survey of grantees , which we discuss more fully in this report .

to further address objective 1 , we reviewed a recent acf study on the validity of pir survey data .

to further address objective 2 , we met with the contractor responsible for coordinating the on - site review process and tracking on - site review results , and representatives from the national head start association .

we also examined patterns of on - site review results in areas related to program governance , record - keeping and reporting , and fiscal management for all programs reviewed in both fiscal years 2003 and 2006 to assess the extent of repeat findings , and obtained the results of a study conducted by acf to evaluate its on - site review process .

for additional details about our scope and methodology , see appendix i .

our work was conducted from february 2007 through december 2007 in accordance with generally accepted government auditing standards .

the head start program was established in 1965 to promote the school readiness of low - income children by enhancing their cognitive , social , and emotional development by providing a range of individualized services to pre - school aged children and their families .

the program is overseen by acf , which awards grants directly to a network of about 1,600 public and private nonprofit and for - profit agencies to help pay for health , educational , nutritional , social , and other services to primarily low - income children from birth to age 5 , and their families .

acf monitors the success of local agencies that receive head start grants in meeting head start program goals and complying with program requirements by conducting on - site monitoring reviews of grantee programs every 3 years ; administering an extensive , annual pir survey of grantees ; and reviewing required financial reports and annual audit reports .

reviewers assess head start grantee compliance with all program requirements , including those specified in the improving head start act , the head start program performance standards , and other relevant federal , state , and local regulations .

these requirements consist of administrative , financial management , and other standards , such as using age - appropriate materials to help children learn to recognize letters and numbers , and providing safe play areas .

by law , each head start grantee must receive a full review at least once every 3 years .

new grantees must receive a full review after completion of their first year of providing head start services and at least once every 3 years thereafter .

acf's policy is to conduct these reviews on - site .

except for new grantees , head start grantees are reviewed on a rotating basis , and approximately one - third of all grantees are monitored each year .

reviews are conducted by a team of reviewers led by a federal head start program specialist from one of acf's 10 regional offices .

in our february 2005 report , we identified a number of weaknesses in acf's oversight of head start grantees .

specifically , we found that acf did not have a strategy for bringing information from its various monitoring processes together in order to comprehensively assess head start program risks , and identified problems with each of its strategies for monitoring grantees .

we found that acf did not have procedures to ensure that on - site reviewers performed their responsibilities in accordance with established guidelines or to ensure that managers and staff in acf regional offices were held accountable for the quality of the on - site reviews .

we also found that acf did not have procedures for independently verifying data submitted by grantees in its annual pir survey , which , in addition to providing information about grantee performance , is used to provide information to congress and the public about important program characteristics , such as program design and staffing , and numbers and characteristics of children enrolled and attending head start programs nationwide .

finally , we found that acf made limited use of financial reports and audits to ensure that all grantees effectively resolved financial management problems and had made little use of its authority to terminate grantees that did not meet program , financial management , and other requirements , and fund new grantees to replace them .

we made a number of recommendations to address the problems that we identified , including: 1. producing a comprehensive risk assessment of the head start 2. strengthening on - site reviewer training and certification procedures ; 3. developing a more consistent approach to conducting on - site reviews 4. implementing a quality assurance process that ensures on - site reviews are conducted within established guidelines and acf managers are held accountable for the quality of on - site reviews ; 5. ensuring the accuracy of pir survey data by independently verifying key data submitted by grantees , or ensuring that grantees have systems in place to collect and report accurate , verifiable data ; 6. making greater use of available information on the status and use of 7. taking steps to obtain competition for grants that are being refunded if it is determined that current grantees have failed to meet program , financial management , or other requirements .

in 2006 , acf reorganized its regional offices in order to streamline program operations .

 ( see fig .

1. ) .

currently , acf regional program staff report directly to its central program offices , rather than to regional office administrators .

the regional administrators no longer have direct authority to manage individual program activities .

as a result , head start program specialists are directly accountable to central office management .

also , financial management specialists , who monitor financial management of all acf grants , including head start grants , are now directly accountable to the central office of grants management , which is located within the acf office of administration .

the office of administration provides support to acf's program offices on a range of administrative issues , such as managing personnel , information resources , procurement , and grants .

the office of grants management carries out the office of administration's grants administration duties and provides leadership and technical guidance to acf program and regional offices on grant operations and grants management issues .

the head start program was revised and reauthorized in the december 2007 improving head start act .

prior to this , the program was last reauthorized in 1998 , for fiscal years 1999 through 2003 .

in the years between the 1998 and 2007 reauthorizations , the program remained funded through the annual appropriations process .

acf has not undertaken a comprehensive assessment of risks to the federal head start program , despite our 2005 recommendation , and little progress has been made in ensuring that the data from its annual pir survey of grantees , which could facilitate such an assessment , are reliable .

although acf has two systems in development to address risk assessment , neither system provides for a comprehensive , programwide risk assessment for the head start program .

further , both systems depend to some extent on unreliable data from the annual pir survey of grantees .

although acf has known about the problems with pir survey data , it has done little to address them .

acf has not undertaken a comprehensive assessment of risks to the federal head start program .

risk assessment is one of five internal control standards that together provide the foundation for effective program management and help government program managers achieve desired results through effective stewardship of public resources .

to carry out a comprehensive risk assessment , program managers need to identify program risks from both external and internal sources , estimate the significance of these risks , and decide what steps should be taken to best manage them .

although such an assessment would not assure that program risks are completely eliminated , it would provide reasonable assurance that such risks are being minimized .

for the head start program , this might include anticipating and developing strategies to minimize the impact of changes in resources available to oversee and assist local grantees , or to develop initiatives to address social and demographic changes that may result in changing service needs for families with young children .

in 2005 , we reported a similar finding , noting that despite efforts to collect information and assess risks , acf did not have a strategy for bringing this information together in order to comprehensively assess program risks , and recommended that acf produce a comprehensive risk assessment of the head start program .

to address our 2005 finding , acf has attempted to bring together information about local programs and to assess risk on a grantee - by - grantee basis ; however , it has yet to develop a systematic approach to assessing risks that may arise from other sources and , if undetected , could hinder acf's ability to achieve head start program objectives , or for developing strategies to prioritize and address risks proactively .

acf is in the process of developing two systems that may help it assess programwide risks ; however , significant limitations or uncertainty exist with respect to each that could constrain acf's ability to use them to conduct a meaningful risk assessment .

the first system , the refunding analysis system , is a process whereby acf evaluates the performance of individual grantees each year before it refunds , or renews , their grants .

the second system , the head start enterprise system ( hses ) , is still under development .

as envisioned by acf , the hses may one day integrate all available head start program data into a single , interactive database that may one day facilitate analysis across many program areas .

the first system is limited in how it could be used for risk assessment , and the completion of the second system is uncertain .

the refunding analysis system is limited because it assesses risk from only one source — grantee performance — and does not assess other types of risk , such as inadequate procedures for ensuring that staff follow policies for monitoring grantee activities or for minimizing payments that are not in accordance with program requirements .

although the planned hses has the potential for assessing a wider range of potential program risks , it has been in development for at least 4 years , and it is unclear when or how it will actually be used .

the refunding analysis system is an evolving system for evaluating grantee financial management and performance annually and determining which grantees require additional assistance .

each month , regional program staff who are responsible for overseeing head start grantees bring together and assess all available information about grantees that are scheduled to re - apply for their grants .

the information is reviewed by grants management staff and head start central office staff .

although the refunding analysis system is intended to provide analysis of grantee performance prior to refunding , it serves primarily as a means of identifying grantees that need assistance and not as a means of discontinuing grants for underperforming grantees .

although the refunding analysis system allows grantees that are considered high risk to be brought to the attention of head start program managers , it does not allow for a broader assessment of other sources of risk , such as those we previously identified .

for example , in 2005 , we identified improper payments to contractors as a source of potential risk for the head start program .

under the improper payments information act of 2002 , agencies are required to annually identify programs and activities that may be susceptible to significant improper payments ; provide congress with the annual estimated amount of improper payments ; and , for programs and activities with estimated improper payments that exceed $10 million , report on actions taken to reduce improper payments .

in addition , the improving head start act requires the secretary of hhs to submit a report to the appropriate congressional committees certifying that hhs has completed a risk assessment to determine which acf programs are at significant risk of making improper payments , and describing the actions hhs will take to reduce these improper payments .

since fiscal year 2004 , acf has taken limited action to minimize improper payments by collecting data on payments to grantees that do not meet the requirement that at least 90 percent of the children who are enrolled in head start programs must be from low - income families .

however , acf officials stated that , due to resource constraints , they do not have plans to track other types of improper payments , such as overpayments to grantees that serve fewer children than are reported to be enrolled in their local head start programs and excessive compensation paid to head start program staff .

overpayments to grantees with programs that have enrollment below their funded levels are not uncommon .

in april 2007 , the hhs inspector general reported that in the 2006 program year , fewer than half ( 40 percent ) of head start grantees were fully enrolled and that enrollment levels by grantee ranged from full enrollment to as low as 68 percent of funded enrollment .

overall , this translated into 5 percent of head start slots that were funded but not filled .

the hhs inspector general also found that only 11 percent of grantees had reported enrollment levels to acf that matched their actual enrollment levels , and questioned the ability of 26 percent of grantees to maintain accurate attendance records and to determine enrollment accurately .

the hhs inspector general has also conducted a series of audits of head start programs that identified unreasonable levels of compensation to head start program executives .

although acf requires grantees to provide information about head start program staff salaries and compensation as part of their annual refunding applications , acf has not estimated the extent to which excessive compensation may be a problem , or verified the extent to which information provided by grantees is accurate .

in developing its new systems , acf plans to use data from its annual pir survey of grantees , which several studies over the past 12 years have determined to be unreliable .

specifically , the refunding analysis system uses pir data on grantees' enrollment of children with disabilities and provision of medical and dental treatments as factors when determining the risk that an individual grantee will fail to meet program standards .

in addition , acf plans to use the pir database in the hses .

our february 2005 report found discrepancies in the 2003 pir database .

during our current review , we conducted similar tests to check for data consistency in the 2006 pir database and found that it continues to provide some inconsistent data .

our findings are consistent with a more recent study funded by acf that was undertaken in response to our 2005 recommendation to address the accuracy of pir data .

specifically , acf's 2007 study found that the pir data reported by individual head start grantees are frequently inaccurate and may be unreliable for grantee monitoring or risk assessment purposes .

the 2007 study found that data submitted by grantees for the pir survey may be unreliable due to the length and complexity of the survey .

the survey includes over 130 questions and provides data on program operations , enrollment , staff and their qualifications , services for children and families , and other information used for policymaking and accountability .

all head start grantees are required to submit pir data every year .

acf's 1995 study on pir data validity also suggested that the length of the survey reduced the accuracy of pir data submitted by grantees , and its 2007 study further suggested that instructions provided to grantees for completing the pir may be unclear and could lead to grantees submitting incorrect data .

based on our survey of program directors , we estimate that over half of all head start grantees spend more than 24 hours to complete the pir .

in our survey , we solicited comments from program directors about potential obstacles to completing the pir and they cited various obstacles , such as unclear instructions and questions that may change from one year to the next .

in addition to using the pir data to assess progress of individual grantees , acf aggregates the pir data to provide national , regional , and state - level statistics on head start .

acf uses the aggregate data to report to congress and the public on the performance of the head start program .

head start grantees report using the pir survey to help manage their programs .

a majority of grantees report using the pir survey to help ensure compliance with federal laws and regulations , compare the performance of their program to national or regional benchmarks , and observe trends in their own performance over time .

moreover , the improving head start act requires acf to use the pir as one determinant of whether grantees meet program and financial management requirements and standards , as part of a new system for renewing head start grants .

reliance on systems that contain inaccurate data can mislead policymakers and program managers and result in inappropriate decisions .

in its 2007 study , acf asserted that the national statistics produced by the pir present a reasonable estimate of the services provided by the head start program even though the data collected from individual grantees are unreliable .

however , if there are actual errors in grantee - reported data , the nationally - reported pir statistics might present a false picture of the services provided by the head start program .

for example , the study estimated that grantees over - reported the number of children that received medical exams by 3.6 percentage points and noted that problematic record - keeping on the part of grantees or physicians might account for some of the discrepancy between the pir statistics and the study's estimates .

given that the head start program provides services to more than 900,000 children , over - reporting in the number of children that received medical exams by 3.6 percentage points could mean that as many as 32,000 fewer children may be receiving medical exams than the nationally - reported pir statistics indicate .

the 2007 study found that acf lacked procedures to independently verify the accuracy of the data .

although acf has built internal consistency checks into the pir database , these checks will not detect inaccurate data as long as the grantee reports data consistently throughout its pir report .

in our 2005 report , we also found that acf lacked a data verification process and recommended that acf either ( 1 ) independently verify key data submitted through the survey or ( 2 ) ensure that grantees have systems in place to collect and report accurate , verifiable data .

the 2007 study offered several recommendations for enhancing the reliability of pir data .

most of the study's recommendations would address the accuracy of data reported by individual grantees , to allow acf to better assess grantee performance .

for example , the study recommends that acf perform regular validation of the pir data submitted by grantees , possibly during the triennial on - site monitoring reviews .

alternatively , one recommendation focuses on acf's use of the pir as a tool for generating national statistics , and suggests accomplishing this through a more limited survey to a random sample of grantees , thereby reducing the overall burden on grantees .

acf officials told us that they have not yet developed any plans to implement the specific recommendations from its 2007 study .

acf has implemented several changes aimed at improving the quality and consistency of its on - site reviews of head start grantees , in response to our 2005 recommendations .

these changes directly address our previous findings regarding the lack of procedures for ensuring that review teams were following on - site review protocols or for ensuring that managers and staff in acf regional offices are held accountable for the quality of the reviews .

specifically , acf has implemented a more rigorous process for certifying reviewers and new processes to improve the consistency of reviews , and is working to establish a system for evaluating reviews on an ongoing basis .

acf has implemented more rigorous procedures for ensuring that a sufficient number of qualified reviewers are available to help conduct required on - site reviews of head start programs .

danya international , inc. ( danya ) manages the on - site review process under a contract with acf and monitors whether reviewers meet all of the necessary qualifications , such as having a bachelor's degree and at least 3 years of work experience in a field related to early childhood development or public program management , and whether they comply with ongoing training and performance requirements .

danya's polices require that reviewers who do not satisfactorily meet the necessary qualifications or who fail to comply with ongoing requirements for reviewers cannot participate in an on - site review .

according to danya , 174 reviewers were placed on hold or removed from the reviewer pool in fiscal years 2006 and 2007 because they did not meet the necessary qualifications .

procedures for recruitment of on - site reviewers are more systematic than in the past .

previously , acf relied on informal networking among individuals affiliated with the head start program to recruit new reviewers .

now , danya procedures provide for an ongoing assessment of the composition of the current reviewer pool and the numbers of reviewers needed to carry out reviews in a given year , and a targeted recruitment strategy to address any shortfalls in the numbers or types of reviewers needed .

for example , to address a shortfall of reviewers who speak spanish or have experience in native american issues , danya representatives may attend conferences to recruit new reviewers with needed special skills and experience , such as conferences sponsored by the national hispanic head start association or the national indian education association .

each month , a three - person panel of qualified reviewers screens all new applications to determine which applicants appear to have the required skills and experience .

applicants who meet the initial screening requirements are asked to provide more detailed employment and education information , which is then verified by danya .

in addition to meeting the basic requirements for qualifying to become an on - site reviewer , danya procedures require that new and current reviewers alike must meet minimum training and performance requirements before they are assigned to a review team .

new reviewers are required to complete a basic training course and must successfully complete a head start monitoring review as a trainee under the supervision of an experienced coach .

all reviewers are required to complete any new training that may be specified during a given fiscal year , stay informed about changes to the review process , and successfully complete online tests in writing and computer literacy .

also , members of the reviewer pool who are employees of head start programs , known as peer reviewers , who work for programs that are in serious noncompliance with program requirements are not eligible to participate in on - site reviews .

acf also requires the review team leader and report coordinator to complete evaluations for all members of the review team ; in addition , each team member must assess the performance of several colleagues on the team .

if a reviewer's performance is rated as unsatisfactory by two or more raters on a single review , danya will follow up to verify the raters' assessments , if necessary , and consult with acf to decide whether the reviewer should be placed on probation and allowed to participate in an additional review for further assessment , or whether the reviewer should be dropped from the reviewer pool .

in fiscal year 2006 , acf implemented new procedures to improve the quality and consistency of on - site reviews .

concerns about the lack of independence of on - site review team leaders prompted changes in how team leaders are assigned .

as a result , each review team is now led by acf program staff from a region other than the grantee's home region .

concerns regarding inconsistencies in the findings cited by different teams of reviewers for the same grantees led to changes in how findings are developed and reported .

the review teams collect only data and facts during their review: they do not draw conclusions from the information they gather or prepare the final report .

instead , reviewers record their observations in a centralized , web - based system , noting any potential areas of noncompliance .

the reviewers' notes are then submitted for centralized review by acf .

the draft review report is prepared centrally and includes findings of noncompliance with program requirements or deficiency — a more serious form of noncompliance that can lead to termination of the grant .

the draft report is then forwarded to the grantee's home region and to the review team leader's region for review and comment .

any comments received are incorporated into the report as necessary to clarify the reviewers' observations , and the final report is signed by the director of the office of head start and then issued to the grantee .

acf has also revised its on - site review protocols to encourage a more efficient and uniform approach to conducting on - site reviews .

in fiscal year 2007 , acf implemented a more uniform set of on - site review protocols , under which every grantee is asked the same questions relating to 10 distinct program areas , such as health services , fiscal management and education and early childhood development services .

the protocols encourage a more targeted assessment of whether or not grantees are in compliance with program regulations , and no longer provide for reporting about program strengths , such as the provision of services that extend beyond what is required by regulation .

prior to the on - site review team's visit , grantees receive a 30-day notification and are asked to prepare a uniform set of documents for reviewers to examine before meeting with the grantee .

during the review , reviewers are required to enter the information they gather into a central , web - based system , which facilitates sharing evidence among reviewers and tracking whether reviewers have completed all necessary tasks .

acf has also implemented uniform corrective action periods and mandatory follow - up visits when grantees are found to be either noncompliant or deficient .

at the time of our previous review , acf relied on grantees to self - certify that they had corrected any problems identified during audits or on - site reviews and only made follow - up visits to grantees that had been found deficient .

now , when grantees are found to be noncompliant with head start program regulations , acf allows them 90 days to resolve the underlying problems and bring their programs into compliance .

if found deficient , grantees are given 6 months to fully resolve deficiencies before acf will take action to terminate their grants , though acf will allow additional time if a grantee can justify its request for an extension .

at the end of the relevant corrective action period , acf conducts follow - up reviews in order to verify that grantees have resolved the problems identified during the initial on - site review .

acf officials said that most grantees have adjusted well to the new on - site review process , although there were some initial negative reactions from the grantees when the new procedures were first introduced .

acf officials told us that they encourage grantees to provide feedback on the review process and on the conduct of on - site reviewers .

they have also established formal procedures for review team leaders to report violations of the on - site code of conduct by reviewers and to replace reviewers while the team is on - site , if necessary .

based on our survey results , we estimate that 9 percent of grantees encountered problems with reviewers during their most recent review that required outside intervention .

for example , one respondent reported several problems , including trouble scheduling the review , a reviewer with a conflict of interest , and overly aggressive reviewers .

our survey results suggest that grantees have mixed views about the revised on - site monitoring procedures .

generally , directors of programs reviewed under the revised procedures had positive views of the reviewers but had less positive views of specific changes in the procedures and the extent to which their most recent on - site review had led to improvements in their head start programs .

specifically , most directors of programs that were reviewed under the revised procedures were very or somewhat satisfied with how their most recent on - site reviews were conducted .

most directors also found that the review teams had adhered to the new protocols and that the review teams demonstrated an understanding of program requirements .

they were almost evenly split over whether having program specialists from outside their home region lead their review had a positive or negative effect on the review process , but about three - quarters thought that the focus on reporting only noncompliance had a negative or very negative effect on the on - site review process .

when asked the extent to which their most recent reviews led to program improvements in each of the 10 program component areas , directors generally reported that the review led to few or no improvements in most program areas , with the exception of health services and program design and management , which directors generally thought had improved to a greater extent than other program areas as a result of their most recent reviews .

although we cannot directly attribute any improvements in head start program management to these changes , our analysis of on - site review data does suggest that there may have been some improvements in head start program management since our last review .

in 2005 , we reported that about 76 percent of all grantees that had on - site reviews in 2000 had been found to be out of compliance with one or more standards in the areas of fiscal management , program governance , or record - keeping and reporting .

we also reported that , in subsequent reviews , 53 percent of those same grantees had been cited again for problems in these same program areas .

our more recent analysis of on - site review data shows that , for grantees reviewed in 2003 , about 71 percent were found to be out of compliance with standards in the same three areas of program management .

in 2006 , 29 percent of grantees reviewed were cited again for problems in these three areas .

in response to our 2005 recommendation , acf has begun to implement procedures for assessing the quality of on - site reviews .

in 2006 , acf conducted a one - time study of the consistency of on - site reviews .

this study revealed some differences in the findings identified by different teams of reviewers that visited the same grantees .

however , acf determined none of the non - duplicated preliminary findings identified by re - review teams were serious enough to meet the regulatory definition of a program deficiency .

the improving head start act further requires that on - site reviews are to be conducted in a manner that includes periodic assessments of the reliability of the process .

acf is currently working to establish an ongoing system for evaluating its on - site review process that would address this new requirement .

to improve head start grantee performance , acf uses data from multiple sources to identify underperforming head start grantees .

for example , it uses data to direct resources to grantees in need of training and technical assistance .

it also uses data to identify high - risk grantees that may need additional oversight .

however , acf's use of data to improve grantee performance has faced limitations .

for example , acf does not have clear criteria for determining which grantees need additional oversight .

in addition , acf had limits on its ability to obtain competition for grants prior to the recent reauthorization of head start .

acf uses data from multiple sources to track head start grantee performance and to identify grantees with program weaknesses .

in addition to findings from on - site monitoring reviews , acf also assesses grantees' performance through analysis of their audit reports , financial reports , and other sources of information .

one of the ways that acf uses data to assess grantee performance is by calculating risk levels for each grantee , through its refunding analysis system .

acf determines grantee risk levels by using various indicators , such as findings from on - site monitoring reviews , turnover of key program staff , pir survey data , and negative media coverage .

after acf identifies underperforming grantees , it targets resources from its training and technical assistance ( t / ta ) network to help these grantees address their program weaknesses .

acf gives grantees with deficiencies priority for receiving services from the t / ta network .

priority for receiving services is then given , in order , to other grantees in non - compliance or at risk for deficiencies , grantees new to providing head start services , and grantees with new directors or key staff .

grantees with deficiencies are sometimes offered on - site assistance to address their program weaknesses .

the t / ta network also assists grantees through workshops , cluster training for groups of grantee program staff and management , presentations at local and national conferences , and other activities .

for example , t / ta network staff members affiliated with acf's regional office in atlanta have provided clustered training to grantees covering topics like literacy , domestic violence , and guidance related to acf's on - site monitoring review process .

in addition , all grantees are required to submit an annual t / ta plan to acf , identifying their t / ta needs for the coming year .

grantees can use multiple data sources to identify their t / ta needs , including on - site monitoring review reports and community assessments .

acf uses the refunding analysis system as an opportunity to identify program weaknesses before it reviews grantees' annual grant applications .

if the process identifies an underperforming grantee — those designated as “high risk” — acf may decide to initiate a special on - site review to determine whether the grantee is deficient and whether the grantee should ultimately be terminated .

if the grantee is deemed deficient , acf can require the grantee to correct the deficiencies within specified time frames , or to begin a quality improvement process , after which acf will assess whether the grantee has corrected all deficiencies .

in all cases , grantees that do not correct identified deficiencies are subject to termination proceedings .

however , acf's criteria for deciding which grantees are subject to the special on - site review are unclear .

these decisions are typically made on an ad - hoc basis , which may result in grantees with similar problems receiving inconsistent levels of oversight .

we have reported that consistency is an essential component to ensuring performance accountability in federal grants .

prior to enactment of the improving head start act , statutory provisions limited acf's ability to terminate underperforming grantees at the time an on - site review or the annual refunding analysis showed inadequate performance .

acf was required to grant priority to existing grantees when making funding decisions , unless acf determined that the grantee failed to meet program , financial management , or other requirements established by acf .

however , before acf could terminate a failing grantee and open the grant to competition from other prospective grantees , acf was required to provide the grantee with official notice and an opportunity for a hearing on its termination — or convince the grantee to relinquish its grant .

moreover , if a grantee appealed acf's termination decision , acf was required to pay the grantee's legal fees until the hearing process was completed .

recent work related to grants management has pointed to competition for grants as a way to facilitate grant accountability .

for example , the domestic working group , chaired by the comptroller general of the united states , cited grant competition as a key area of opportunity for improving grant accountability .

it noted that grant competition promotes fairness and openness in the selection of grantees , and that agencies can better ensure that grantees have the capability to efficiently and effectively meet grant goals by incorporating evaluation criteria focused on factors indicative of success into the competition process .

the recent reauthorization of head start amends some of the requirements and procedures for refunding head start grantees , including the introduction of time limits for head start grants .

this will give acf the ability to open competition for head start grants to additional grantees , thereby enhancing acf's ability to remove severely underperforming grantees from the program , on a regular basis .

in light of federal budget limitations and increasing expectations for program accountability , acf's ability to demonstrate effective stewardship over billions of dollars in head start grants has never been more critical .

since our 2005 review , acf has made significant improvements in its procedures for monitoring local head start programs .

in particular , the agency has taken steps to bring together information about individual grantees from various sources in order to identify those that are struggling to meet head start performance standards , and to target assistance to help these grantees strengthen their programs .

this risk - based approach is promising and provides a foundation for a more strategic , comprehensive approach to managing the head start program .

nevertheless , acf's current initiatives do not yet constitute a comprehensive plan for managing program risks .

without a more comprehensive approach to identifying risks , threats to acf's ability to achieve head start program objectives will likely go undetected until a problem arises .

for example , undetected improper payments could result in a severe reduction in the funds available to pay for services for children .

although acf has made progress since we last reported in 2005 toward strengthening its oversight of the approximately 1,600 local agencies that receive head start program grants , its systems for doing so depend in part on data that are unreliable .

if acf does not act to address the weaknesses in its data , it cannot depend on its new systems to provide it with reliable information on grantee performance .

the lack of reliable information about local program activities further compromises acf's ability to manage risks by limiting its ability to understand whether problems are isolated or national in scope , as well as whether they arise from individual grantee failures or from weaknesses in the broader structure of the program itself .

a lack of sound information also calls into question the credibility of acf's reporting to congress and the american public on the services provided by the head start program .

even if acf conducts a comprehensive risk assessment of the head start program and works to improve the accuracy of its data , it will still face challenges addressing risks posed by the most severely underperforming grantees .

the annual refunding process could be used to link funding opportunities to performance .

for example , if acf develops clear and objective criteria for deciding which grantees are subject to a special on - site review , it could ensure that all grantees with similar problems receive similar levels of oversight .

without such criteria , special on - site reviews will continue to be conducted on an ad - hoc basis and , as a result , acf may continue to fund poorly performing grantees that do not receive special on - site reviews without providing them the additional oversight they need .

to improve its management and oversight of the head start program , we are making the following four recommendations to hhs's assistant secretary for children and families: more fully implement our 2005 recommendation by developing a strategic and comprehensive approach to assessing head start programwide risks .

a comprehensive , programwide risk assessment should take all program risks into account .

specifically , a comprehensive risk assessment should include an assessment of risks arising from external sources , such as social and demographic changes that may affect the availability or demand for head start program services , as well as from internal sources , such as underperforming grantees , differences in how regional offices implement program policies and procedures , or the availability of sound data to help manage the program .

a comprehensive risk assessment should also include strategies for minimizing risks that could significantly limit the ability of acf and grantees to help grantees deliver high - quality programs .

look for cost - effective ways to expand acf's efforts to comply with the improper payments information act of 2002 and to address our 2005 recommendation by collecting data on and estimating the extent of improper payments made for unallowable activities and other unauthorized purposes .

these should take into account various aspects of the program and should not be limited to improper payments to grantees that enroll too many children from families that do not meet the program's income eligibility requirement .

take additional steps to ensure the accuracy of pir data by determining which elements of the pir are essential for program management and focus resources on a streamlined version of the pir that would be required annually of all grantees , with the responses verified periodically .

if additional information is needed to produce national estimates of a wider range of head start program services , acf should include the relevant , additional data items in an expanded version of the pir , which could be administered to a random , representative sample of grantees each year .

develop clear criteria for determining which grantees require more thorough reviews — such as special , on - site reviews — as a result of its refunding analysis system .

we provided a draft of this report to acf for comment .

the full text of these comments appears in appendix ii .

acf agreed with two of our recommendations , and emphasized progress already made toward developing a comprehensive risk assessment process and toward reducing improper payments .

specifically , acf noted that it plans to implement a programwide risk management process in early 2008 .

acf also said that it has developed a new integrated data management system .

while we agree that acf's planned programwide risk management process and integrated data management system are important initiatives that may facilitate programwide risk assessment , both systems have yet to be fully implemented and it remains to be seen how these systems will actually be used to proactively manage the head start program nationally .

acf also emphasized the progress it has made to reduce the frequency and amount of improper payments arising from participants' ineligibility , and that its focus on eligibility is consistent with how acf has implemented the improper payments information act of 2002 for other programs , and was approved by hhs and omb management .

we agree that acf's progress toward reducing the improper payment error rate due to head start program ineligibility from 3.6 percent in 2003 to 1.3 percent in 2006 is commendable , and acknowledge acf's commitment to reducing improper payments for the head start program .

however , as noted in acf's comments , the agency's improved monitoring efforts and planned risk management initiatives may help acf to identify further areas for study related to improper payments , and we encourage acf to pursue these areas , as practical .

acf agreed with our recommendation to review and streamline its annual pir survey of grantees , noting that it will continue to use the results of its own pir validation study to inform the design of future surveys , take steps to periodically verify grantee responses , and leverage technological improvements to capture program data more frequently and consistently .

finally , acf said it will soon have the ability to define realistic criteria for determining which grantees require more thorough or special reviews , and noted that improvements in monitoring , and changes to the process for designating grantees resulting from reauthorization , should help enable it to do so .

we're encouraged that acf said it should have both its risk management process and its integrated data management systems operational this year .

both systems will play an important role in its efforts to better target its oversight efforts .

to answer our research objectives , we interviewed administration for children and families ( acf ) and office of head start officials and their staff in washington , d.c. , and in the acf regional offices in philadelphia and atlanta .

we conducted interviews with staff from all of acf's 10 regional offices , and reviewed relevant documentation from each of these offices .

we visited two regional offices — philadelphia and atlanta — to help us develop interview and data collection protocols and conducted telephone interviews with the remaining eight regional offices .

to obtain grantees' opinions on acf's oversight of the head start program , we administered a web - based survey to a nationally - representative sample of head start and early head start program directors .

our target population consisted of directors whose programs were the subject of on - site reviews from october 2005 through march 2007 , and were reviewed under acf's newly revised on - site review process .

based on data supplied by acf and the contractor responsible for coordinating the on - site reviews , we identified a total population of 598 head start grantees .

from this population , we selected a stratified random probability sample of 329 grantees .

we stratified the population based on whether or not the grantee has any delegate agencies and the acf region in which the grantee operates .

we also included in our sample all grantees that participated in acf's 2006 one - time study of the consistency of its on - site reviews .

with this probability sample , each grantee had a nonzero probability of being selected , and that probability could be computed for any grantee .

each grantee selected in the sample was subsequently weighted in the analysis to account statistically for all the grantees in the population .

because we followed a probability procedure based on random selections , our sample is only one of a large number of samples that we might have drawn .

since each sample could have provided different estimates , we express our confidence in the precision of our particular sample's results as a 95 percent confidence interval .

this is the interval that would contain the actual population value for 95 percent of the samples we could have drawn .

as a result , we are 95 percent confident that each of the confidence intervals in this report will include the true values in the study population .

all percentage estimates from this survey have margins of error of plus or minus 10 percent or less , unless otherwise noted .

we developed our survey questions based on feedback that we received during three focus group sessions that we conducted with head start program directors whose programs were reviewed under the revised on - site review process .

after we drafted the survey questionnaire , we conducted a series of six pretests by telephone to check that ( 1 ) the questions were clear and unambiguous , ( 2 ) terminology was used correctly , and ( 3 ) the information could feasibly be obtained .

we made changes to the content and format of the questionnaire as necessary during the pretesting process .

the survey was fielded between july 12 , 2007 , and august 20 , 2007 .

of the 329 program directors in our sample , 261 responded — for a response rate of 79 percent .

to assess the changes acf made to its on - site monitoring review process , we met with the contractor responsible for coordinating the reviews , as well as with representatives from the national head start association , and reviewed the results of a study conducted by acf to evaluate its on - site review process .

we also analyzed the extent to which acf's on - site monitoring reviews identified repeat noncompliance by head start grantees , using 2003 and 2006 data from the on - site review database that is currently maintained by danya international , inc. ( danya ) .

we used four data elements from this database for our analysis: grantee id , fiscal year , review type , and core area .

we further limited our analysis to three core areas: program governance , record - keeping and reporting , and fiscal management .

to assess the reliability of these data , we relied on both our 2005 assessment of the reliability of 2003 data , and performed additional tests .

specifically , we conducted electronic testing of both the 2003 and 2006 data and found no missing or out - of - range entries for any of the four elements that we used , and obtained additional information about the 2006 data from danya .

based on our previous and updated assessments , we find the 2003 and 2006 data sufficient for the purpose of this engagement .

we analyzed the on - site review data for 2003 and 2006 to obtain , for each year , the numbers of ( 1 ) all grantees reviewed , ( 2 ) grantees receiving triennial or first - year reviews only , and ( 3 ) grantees cited for deficiency or noncompliance in one , two , or all three of the core areas of interest ( program governance , record - keeping and reporting , and fiscal management ) .

to obtain the number of grantees with repeat noncompliance , we computed the number of grantees cited for noncompliance or deficiency in both 2003 and 2006 , in each of the same core areas .

the computer code used to derive these numbers was subjected to independent review within gao and was found to be accurate .

we reviewed acf studies from 1995 and 2007 on the validity and accuracy of pir data , the results of which are discussed in this report .

we also conducted consistency tests on pir data from the 2006 pir database , similar to the tests that we conducted on the 2003 pir database for our 2005 report on head start oversight .

overall we conducted 29 tests , across all three sections of the pir database: enrollment and program operations , program staff and qualifications , and child and family services .

in 9 of our 29 tests , pir data contained inconsistent data that did not sum to the expected totals .

in each of the nine tests that failed , less than 1 percent of the 2,696 data items failed .

our findings indicate that the pir database contains some inconsistent data .

our work was conducted from february 2007 through december 2007 in accordance with generally accepted government auditing standards .

the following individuals made important contributions to this report: bill j. keller , regina santucci , christopher w. backley , susannah compton , james ashley , cindy gilbert , alison martin , george quinn , jerry sandau , elizabeth wood , kimberly brooks , jacqueline nowicki , doreen feldman , alexander galuten , and james rebbe .

improper payments: incomplete reporting under the improper payments information act masks the extent of the problem .

gao - 07-254t .

washington , d.c.: december 5 , 2006 .

grants management: enhancing performance accountability provisions could lead to better results .

gao - 06-1046 .

washington , d.c.: september 29 , 2006 .

head start: progress and challenges in implementing transportation regulations .

gao - 06-767r .

washington , d.c.: july 27 , 2006 .

head start: comprehensive approach to identifying and addressing risks could help prevent grantee financial management weaknesses .

gao - 05-176 .

washington , d.c.: february 28 , 2005 .

head start: better data and processes needed to monitor underenrollment .

gao - 04-17 .

washington , d.c.: december 4 , 2003 .

head start: increased percentage of teachers nationwide have required degrees , but better information on classroom teachers' qualifications needed .

gao - 04-5 .

washington: d.c.: october 1 , 2003 .

managing for results: efforts to strengthen the link between resources and results at the administration for children and families .

gao - 03-9 .

washington , d.c.: december 10 , 2002 .

strategies to manage improper payments: learning from public and private sector organizations .

gao - 02-69g .

washington , d.c.: october 2001 .

standards for internal control in the federal government .

gao / aimd - 00-21.3.1 .

washington , d.c.: november 1999 .

