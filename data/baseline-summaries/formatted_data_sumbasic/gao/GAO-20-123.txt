the federal government exchanges a large variety of personally identifiable and other sensitive information with states to implement key federal and state programs .

for example , federal and state agencies exchange taxpayer , law enforcement , and health care data , among many other types of information .

because of the significant impact that such information can have on a broad array of government operations and assets , effective security controls to protect the information from growing and increasingly sophisticated cyber threats are essential .

the federal information security modernization act of 2014 ( fisma ) and guidance from the office of management and budget ( omb ) emphasize that federal agencies are to use risk - based processes for information security .

fisma provides a comprehensive framework for information security controls over information resources and requires each agency to develop , document , and implement an agency - wide information security program to provide risk - based protections for the information and information systems that support the operations and assets of the agency .

to protect and secure the sensitive information exchanged with states , each federal agency that exchanges data has specific regulations , guidelines , or other requirements for states to follow when accessing , storing , and transmitting the data .

further , federal agencies have established assessment programs to ensure that the state agencies comply with their cybersecurity requirements .

at your request , we evaluated federal agencies' cybersecurity requirements and related assessment programs for state agencies .

our specific objectives were to determine the extent to which ( 1 ) selected federal agencies' cybersecurity requirements for state agencies varied with each other and federal guidance , and ( 2 ) federal agencies had policies for coordinating their assessments of state agencies' cybersecurity .

to accomplish the objectives , we first selected a sample of federal agencies for our review .

to do so , we determined which of the 24 agencies covered by the chief financial officers act ( 1 ) shared data with state agencies ; ( 2 ) had a standard , minimum set of cybersecurity requirements to protect these data ; and ( 3 ) conducted regularly scheduled assessments of states' compliance with the requirements .

we identified four agencies that met these criteria: the centers for medicare and medicaid services ( cms ) within the department of health and human services , the federal bureau of investigation's ( fbi ) criminal justice information services ( cjis ) within the department of justice , the internal revenue service ( irs ) within the department of the treasury , and the social security administration ( ssa ) .

the results of our review of these four agencies are not generalizable to other federal agencies .

for the first objective , we reviewed the national institute of standards and technology ( nist ) special publication 800-53 ( revision 4 ) , to identify cybersecurity controls and control enhancements that we could use as a basis for comparing federal agencies' cybersecurity requirements for state agencies .

we specifically chose those controls and control enhancements where organizations , such as the federal agencies we selected , are to define specific values when tailoring their requirements .

based on this criterion , we identified a nonprobability sample of 616 ( out of 1,682 ) cybersecurity controls and control enhancements for our review .

then , for each of the four selected federal agencies , we identified its cybersecurity requirements that state agencies are to comply with when exchanging data with the federal agency .

these requirements were documented in: irs , publication 1075 , tax information security guidelines for federal , state and local agencies: safeguards for protecting federal tax returns and return information ; cms , mars - e document suite , version 2.0 , volume iii: catalog of minimum acceptable risk security and privacy controls for exchanges ; department of justice , federal bureau of investigation , criminal justice information services ( cjis ) security policy ; and ssa , electronic information exchange security requirements and procedures for state and local agencies exchanging electronic information with the social security administration .

we compared each selected federal agency's cybersecurity requirements for state agencies to the other three selected federal agencies' requirements , and to guidance associated with the 616 selected controls and control enhancements specified in nist special publication 800-53 .

in doing so , we considered three specific instances in which the federal agencies' requirements could vary: when a federal agency had a requirement that the other three federal agencies did not have .

we refer to such variances as unique requirements .

when a federal agency had in its requirements , specific values that are to be defined by individual federal agencies that differed from at least one of the other three federal agencies .

we refer to such variances as requirements with conflicting parameters .

when a federal agency did not fully address in its requirements the guidelines from nist for associated controls and control enhancements .

we refer to such variances as requirements that did not fully address nist guidelines .

we also reviewed omb circular a - 130 , managing information as a strategic resource , which identifies requirements for federal agencies to coordinate when establishing cybersecurity requirements for nonfederal entities , such as state agencies .

in addition , we reviewed practices that gao recommended regarding ways that federal agencies may enhance and sustain coordination and collaboration with each other .

we also reviewed practices that nist recommended on ways that federal agencies may coordinate on their development of cybersecurity requirements to satisfy common security objectives .

we then assessed whether the selected federal agencies were implementing the omb requirements and recommended practices .

to address the second objective , we reviewed relevant requirements in omb circular a - 130 that pertained to federal agencies' coordination on assessments of state agencies' cybersecurity .

we also identified practices recommended by gao for federal agencies to coordinate in an effort to better manage potential fragmentation , overlap , or duplication through coordination .

in addition , we identified practices recommended by nist related to federal agencies' coordination on assessments of cybersecurity .

based on our reviews of these guidance documents , we identified two broad areas of coordination that were relevant to federal agencies' assessments of state agencies' cybersecurity: ( 1 ) coordination with state agencies when assessing states' cybersecurity and ( 2 ) coordination with other federal agencies on the assessments of state agencies' cybersecurity .

using guidance from nist that pertained to coordination on assessments of cybersecurity and practices recommended by gao for enhancing coordination among federal agencies , we identified four supporting activities that were common to each of these two areas of federal agencies' coordination on cybersecurity assessments: assessment schedules and time frames , meeting and document requests , security test plans , and the use of findings from prior assessments .

we then analyzed the selected federal agencies' policies and related procedures for conducting assessments of state agencies' cybersecurity , as discussed in relevant documentation , such as assessment methodologies , pre - evaluation questionnaires , and report templates .

in doing so , we reviewed agencies' policies to identify whether there was discussion of the four activities supporting the two areas of coordination with state agencies and with other federal agencies .

we determined that an agency fully addressed an area of coordination if its policies included discussion about coordination on all of the four supporting activities ; partially addressed an area of coordination if its policies included discussion of some , but not all , of the supporting activities ; and did not address an area of coordination if its policies did not include any discussion of the supporting activities .

we supplemented our documentation review with interviews of cognizant officials from fbi's cjis information technology management section and the cjis audit unit ; irs's office of safeguards ; cms's office of information technology ; and ssa's offices of general counsel ; analytics , review , and oversight ; and deputy commissioner for systems .

we discussed with agency officials our observations of variances in agencies' cybersecurity requirements for state agencies , as well as their policies for coordinating with state agencies and other federal agencies when assessing state agencies' cybersecurity .

we also interviewed officials from omb's office of e - government and information technology to discuss the extent to which federal agencies have coordinated on their assessments of state agencies' cybersecurity .

in addition , for both objectives , we administered a survey to the offices of the chief information officer and chief information security officer ( ciso ) in the 50 states , district of columbia , american samoa , guam , puerto rico , and the u.s. virgin islands .

we received survey responses from 50 of these 55 states and territories , and the district of columbia .

the survey requested these officials' perspectives on the nature of any variances among federal cybersecurity requirements , the officials' experiences in implementing the requirements , and their views on oversight performed by federal agencies .

several questions from our survey requested that state cisos provide their subjective views based on a range of alternatives .

for example , regarding the question on the extent to which federal cybersecurity requirements varied , we asked state cisos to identify the extent of variation for three scenarios as very great , great , moderate , slight , none , or unknown .

see appendix i for a more detailed discussion of our survey methodology and results .

we conducted this performance audit from july 2018 to may 2020 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

federal agencies are dependent on information systems and electronic data to process , maintain , and report essential information .

virtually all federal operations are supported by computer systems and electronic data , and agencies would find it difficult , if not impossible , to carry out their missions and account for their resources without these information assets .

federal agencies exchange personally identifiable and other sensitive information with state agencies in the implementation of key federal and state programs .

the security of systems and data involved in this exchange of information is vital to public confidence and the nation's safety , prosperity , and well - being .

since federal agencies face computerized ( cyber ) threats that continue to grow in number and sophistication , it is imperative that such information is protected .

in recognition of this growing threat , we designated information security as a government - wide high - risk area in 1997 .

we further expanded this area in 2015 to include protecting the privacy of personally identifiable information .

several federal laws and policies establish requirements for protecting federal systems and managing cybersecurity risks .

specifically , fisma is intended to provide a comprehensive framework for ensuring the effectiveness of information security controls over information resources that support federal operations and assets , as well as the effective oversight of information security risks .

the act requires each agency to develop , document , and implement an agency - wide information security program to provide risk - based protections for the information and information systems that support the operations and assets of the agency , including those provided or managed by another entity .

fisma also assigns government - wide responsibilities to key agencies .

for example , omb is responsible for developing and overseeing implementation of policies , principles , standards , and guidelines on information security in federal agencies , except with regard to national security systems .

nist is also responsible for developing standards for categorizing information and information systems , security requirements for information and systems , and guidelines for detection and handling of security incidents .

for example , nist special publication 800-53 provides guidance to agencies on the selection and implementation of information security and privacy controls for systems .

further , omb circular a - 130 , managing information as a strategic resource , establishes minimum requirements for federal information security programs and assigns federal agency responsibilities for the security of information and information systems .

it requires agencies to implement a risk management framework to guide and inform the categorization of federal information and information systems ; the selection , implementation , and assessment of security and privacy controls ; the authorization of information systems and common controls ; and the continuous monitoring of information systems .

circular a - 130 also requires federal agencies to provide oversight of nonfederal entities — such as state agencies — that use or operate federal information systems , as well as nonfederal entities' information systems that collect or maintain federal information .

in doing so , federal agencies are to ensure that security and privacy controls for such information systems are effectively implemented and comply with nist standards and guidelines and agency requirements .

federal agencies may share data with one or more individual component agencies within a state , such as agencies that execute a state's tax administration , law enforcement , or human services functions .

the state's responsibility for protecting data shared by federal agencies may reside within an individual state agency or it may be a shared responsibility with the state's chief information officer and ciso .

for example , a state ciso may help to manage the protections over centralized information technology ( it ) resources that store , process , and transmit federal data for multiple component agencies within the state .

to protect federal data that are shared with state agencies in the implementation of key federal and state programs , federal agencies have developed cybersecurity requirements for state agencies to follow when accessing , storing , and transmitting federal data .

federal agencies are to obtain assurance that state agencies' security and privacy controls are effectively implemented through independent evaluations .

these evaluations include tests and assessments of the effectiveness of state agencies' information security policies , procedures , and practices .

such assessments are important inputs to decisions by federal officials to authorize or reauthorize a state agency's use of information systems that create , collect , use , process , store , maintain , disseminate , disclose , and dispose of federal information .

to protect federal data that are shared with state agencies , each of the federal agencies in our review have established their own policies that articulate cybersecurity requirements , as well as related compliance assessment programs , based in part on guidance from nist .

table 1 identifies the types of data that the four selected federal agencies share with state agencies and the cybersecurity policies that they have established to protect that data .

the selected federal agencies' had a significant number of variances in the cybersecurity requirements that they had established for protecting data exchanged with state agencies .

specifically , our review identified hundreds of instances in which the four agencies either had ( 1 ) included a requirement in its cybersecurity policy that was not a requirement of the other three agencies ( unique requirement ) ; ( 2 ) established a requirement with specific , organization - defined technical thresholds that differed from at least one of the other three agencies for a related control ( conflicting parameters ) ; or ( 3 ) did not fully address in its requirements the guidelines from nist for associated controls and control enhancements ( did not fully address nist guidelines ) .

table 2 summarizes the total number of requirements that each agency had included in its security policy and the extent to which the four agencies' requirements varied from each other and from the nist guidance .

collectively , the four selected federal agencies' policies included 86 unique cybersecurity requirements for state agencies with which they exchange data .

specifically , cms's policy included 54 requirements that the other three agencies did not include .

fbi's cjis's policy included 24 unique requirements , irs's policy included five unique requirements , and ssa's policy included three unique requirements .

for example , cms's security policy included a requirement that state agencies review their organization - wide information security program plan annually ; however , the other three agencies did not have such a requirement in their security policies .

as another example , irs had a requirement for state agencies to employ automated mechanisms to alert security personnel of inappropriate activities , while the other agencies did not have this requirement .

because each agency is addressing different legal requirements and risk management approaches for protecting information shared with states , certain requirements that are unique to an agency may be necessary .

nevertheless , agencies need to ensure that such requirements are necessary by documenting their decisions during the control selection process .

table 3 provides examples of the unique requirements that each agency included in its cybersecurity policies .

in total , the four federal agencies had identified 390 requirements for state agencies in their policies , where the parameters conflicted with at least one of the other federal agencies .

across the four agencies , cms had the largest number of requirements that had conflicting parameters , with 139 such requirements .

this was followed by irs with 131 , fbi's cjis with 72 requirements , and ssa with 48 requirements with conflicting parameters .

for example , each of the selected agencies identified a different time frame for the retention of audit logs related to audited events .

as another example , cms required state agencies to annually review and update their access control policies , whereas irs required this review every 3 years .

fbi's cjis and ssa did not have this requirement in their policies .

table 4 provides additional examples of cybersecurity requirements for state agencies that the four federal agencies identified in their policies , where the parameters conflicted with those of at least one other of the federal agencies .

the four selected federal agencies did not always fully address guidelines in nist special publication 800-53 ( revision 4 ) when establishing cybersecurity requirements for related controls , leading to additional differences among the four agencies' cybersecurity policies .

in total , the four agencies did not fully address guidelines from nist in 141 instances .

fbi's cjis had the most variances , with 63 requirements that did not fully address nist guidelines , followed by ssa with 30 variances , cms with 26 variances , and irs with 22 variances .

for example , fbi's cjis's requirement did not identify the time period to retain individual training records , as called for by nist guidance .

in addition , ssa did not define the frequency of how often agencies should assess the security controls in the information system and its environment of operation .

table 5 provides examples of the cybersecurity requirements for state agencies in which selected federal agencies did not fully address nist guidelines .

the perspectives of state cisos who responded to our survey reflected the variation we found among the selected federal agencies' cybersecurity requirements .

the majority ( at least 29 out of 50 ) of the state cisos that responded to our survey question regarding the ways in which federal cybersecurity requirements vary and the extent of the variation reported moderate to very great variation in the selected federal agencies' cybersecurity requirements .

specifically , of the 50 state cisos that responded to this question , 34 reported that the federal agencies had moderate to very great variation with respect to unique requirements , 38 reported that the federal agencies had moderate to very great variation due to conflicting parameters that were established , and 29 reported that the federal agencies had moderate to very great variation with respect to addressing nist guidelines for security controls and control enhancements .

figure 1 represents state cisos' perspectives on the extent of variation among selected federal cybersecurity requirements .

state agency officials that must comply with multiple federal agencies' cybersecurity requirements ( and related compliance assessments ) viewed variances as problematic and burdensome .

for example , in responding to a survey question about challenges or impacts that state officials experienced regarding federal requirements and assessment processes , an official from one state agency explained that addressing variances in cybersecurity requirements reduced the ability of state officials to focus on their primary mission of securing data across their state enterprise .

in response to the same survey question , another state official said that addressing the variances in federal agencies' cybersecurity requirements increased the complexity of automating the state's monitoring and reporting processes .

in addition , the same state official commented that staff were burdened by reports and reviews to ensure that the full range of federal agencies' requirements were met .

in responding to our survey , 46 state cisos reported the extent to which they had experienced a very great , great , moderate , slight , or no increase in calendar time ; staff hours ; and costs of acquiring additional materials , software , and equipment to address variances in selected federal agencies' cybersecurity requirements .

the majority ( at least 34 out of 46 ) of the state cisos that responded to this question in our survey reported moderate to very great increases in these types of impacts .

figure 2 represents the extent of impacts that state cisos reported as a result of variances in selected federal cybersecurity requirements .

omb circular a - 130 requires federal agencies to coordinate with nonfederal entities , such as state agencies , as well as other federal agencies as appropriate , to ensure that security and privacy requirements pertaining to these nonfederal entities are consistent to the greatest extent possible .

in addition , gao and nist have identified practices that can help federal agencies limit potential variation in security control selection and requirements , such as coordinating to develop compatible policies , procedures , and other means to operate across agency boundaries .

for example , according to nist , agencies can establish a tailored set of baseline requirements to satisfy common security objectives .

in addition , by applying practices recommended by gao for enhancing and sustaining coordination and collaboration , federal agencies could work towards establishing shared requirements with consistent terminology and parameters .

however , the four selected federal agencies have not ensured that their cybersecurity requirements for state agencies are consistent to the maximum extent possible through coordination with each other .

officials from irs , fbi , and ssa acknowledged that they had not coordinated with other federal agencies in establishing their current cybersecurity requirements for state agencies .

the agencies had not coordinated , in part , because they have prioritized addressing agency - specific responsibilities from relevant laws and agency policies as well as the needs of relevant communities of interest .

cms officials stated that the agency coordinated with other federal agencies in 2015 when cms originally established requirements for its security policy , the minimum acceptable risk standards for exchanges document suite 2.0 , volume iii: minimum acceptable risk standards for exchanges .

cms officials noted that the agency added controls that irs and ssa deemed essential to protecting data for which these agencies were responsible .

nevertheless , we found variances between cms's requirements and those established by irs and ssa .

further , cms last updated its security policy in september 2015 and irs , ssa , and fbi's cjis have each since updated their policies .

in addition to the insufficient coordination , the selected federal agencies identified two additional explanations for variances in their cybersecurity requirements for state agencies: ( 1 ) agencies' determination that selected requirements were necessary and therefore , that resulting variances are warranted and ( 2 ) agencies' requirements review processes that resulted in deviations from nist guidance .

each of the selected agencies noted that they determined the unique controls and competing parameters in their requirements were necessary and warranted .

for example , ssa noted that it has been conducting data exchanges with states since the late 1970s , predating nist special publication 800-53 .

according to ssa officials , the agency's security requirements retained certain legacy language that state agencies were already familiar with to reduce disruption to them .

irs officials also noted that their security controls incorporate disclosure restrictions from the internal revenue code and internal irs directives .

agency processes for reviewing their cybersecurity requirements have resulted in deviations from nist guidance .

for example , fbi's cjis officials stated that they started with nist terminology when developing their policy .

however , cjis's advisory policy board — which recommends the final cjis policy to the fbi director — suggested modifications to the wording of requirements during subsequent reviews .

as another example , cms noted that during the review process for its requirements , in certain instances it deviated from nist guidance to use terminology that would be more familiar to state agency users .

federal agencies may have legitimate reasons for having variances in their cybersecurity requirements .

for instance , agencies may need to apply different information security controls , a greater number of controls , or more stringent technical parameters to protect data for which they are responsible in a manner consistent with various security requirements originating in federal laws , executive orders , directives , policies , regulations , standards , or guidelines as well as the agency's risk assessments .

however , according to nist , organizations should document the relevant decisions taken during the control selection process , and provide a sound rationale for those decisions that is based on agency mission and business needs .

both fbi's cjis and irs had documented the agency's rationale for unique requirements .

ssa stated that their controls were developed before nist standards were created and they have mapped their current controls to nist .

however , ssa was unable to produce this documentation .

cms officials noted that the rationale for the requirements identified in the agency's minimum acceptable risk standards for exchanges security policy was documented in cms's acceptable risk standards .

however , the acceptable risk standards did not include all requirements that were included in cms's security policy .

for example , cms's requirements for organizations to review and re - evaluate privileges at least quarterly and for the information system to allocate resources by priority and / or quota were included in the security policy without a defined rationale and were also not included in cms's acceptable risk standards .

while agencies have identified various reasons for not coordinating on their cybersecurity requirements for state agencies , omb has not taken steps to evaluate whether agencies are coordinating .

omb officials acknowledged that they could encourage additional coordination among the selected agencies , but said that it is ultimately up to the agencies to set their requirements and determine how best to assess states' compliance with those requirements .

however , without omb's involvement and encouragement that federal agencies collaborate to make their cybersecurity requirements for state agencies consistent to the greatest extent possible , federal agencies are less likely to prioritize such efforts .

the selected federal agencies will soon have an opportunity to harmonize to the extent possible their requirements as they revisit and potentially update their existing security policies based on anticipated changes in nist guidance .

until these agencies coordinate , where feasible , to address the variances in their cybersecurity requirements , officials from state agencies may continue to experience cost , time , and other burdens resulting from these variances .

further , without documentation of the rationale for having requirements that are unique or parameters that conflict in comparison to other agencies , it will be more difficult for these agencies to achieve consistent requirements .

as previously discussed , omb circular a - 130 requires federal agencies to assess whether state agencies have implemented effective security and privacy controls on information systems that create , collect , use , process , store , maintain , disseminate , disclose , or dispose of federal information .

the circular also encourages federal agencies to coordinate on their approaches to authorizing the use of such systems whenever practicable .

for example , the circular notes that multiple agencies are encouraged to jointly plan and execute tasks in nist's risk management framework , which includes conducting security assessments .

according to the circular , agencies can also leverage information generated by another agency based on the need to use the same information resources ( eg , information system or services provided by the system ) by choosing to accept some or all of the information in an existing authorization package , including completed security assessments .

as previously stated , nist and gao have recommended practices that federal agencies can implement to help with their coordination on cybersecurity assessments , such as assessments of state agencies' compliance with federal cybersecurity requirements .

those practices fall in two broad areas: ( 1 ) coordination with state agencies when assessing states' cybersecurity and ( 2 ) coordination with other federal agencies on the assessment of state agencies' cybersecurity .

in addition , based on the guidance from nist that pertained to coordination on assessments of cybersecurity and practices recommended by gao for enhancing coordination among federal agencies , four supporting activities are common to each of these two areas of federal agencies' coordination on cybersecurity assessments: assessment schedules and time frames ; meeting and document requests ; security test plans — including testing techniques , location , and tools ; and the use of findings from prior assessments .

with regard to coordinating with state agencies when assessing their cybersecurity , two of the selected federal agencies — cms and irs — had policies that addressed all four of the activities supporting this area of coordination .

the two other agencies — fbi's cjis and ssa — had policies that addressed some , but not all , of the supporting activities for such coordination .

with regard to coordinating with other federal agencies on the assessment of state agencies' cybersecurity , none of the four federal agencies had policies that addressed the activities supporting this area of coordination .

table 6 summarizes the extent to which selected agencies established policies for coordinating with state agencies and other federal agencies when assessing cybersecurity .

see appendix ii for details on the extent to which selected agencies addressed individual activities supporting the two areas of coordination .

each of the selected federal agencies addressed at least three of the four activities for coordinating with state agencies when assessing cybersecurity .

cms and irs fully established policies for coordinating with state agencies by addressing all of the activities supporting such coordination .

however , fbi's cjis and ssa partially established policies for coordinating with state agencies by addressing some — but not all — of the supporting activities .

specifically , fbi's cjis and ssa fully addressed three of the activities: coordinating ( 1 ) assessment schedules and time frames , ( 2 ) meeting and document requests , and ( 3 ) security test plans .

for example , fbi's cjis policy included instructions for providing the date and time of assessment along with a schedule for the assessment process .

further , the policy stated that assessors should lay out the meetings that need to occur and documentation that state agencies need to provide cjis , including specifics about the state's network .

ssa's policy laid out each step of the assessment process , including the anticipated time frames .

further , ssa's policy identified certain meetings that should be held during the process and documentation to be provided before the assessment .

however , fbi's cjis and ssa did not fully establish policies for coordinating with state agencies because they did not address the activity associated with coordinating the use of findings from prior assessments .

specifically , while these two agencies' policies addressed using findings from prior assessments conducted by their individual agency , their policies did not address whether or how assessors should use findings from other security assessments conducted within the state .

officials from fbi stated that in practice they consider findings from independent security assessments conducted within a state , but had not documented this practice in their assessment policies due to the limited instances in which this information is available .

officials from ssa believed that their policy addressed how its assessors were to consider findings from other security assessments that are conducted within a state .

however , based on our review of ssa's policy , this information was not yet addressed .

none of the four agencies established policies for coordinating with other federal agencies when assessing state agencies' cybersecurity .

officials from the four selected agencies reported that this is because their priority is to assess compliance with their own security requirements and they are not comfortable relying solely on other federal agencies' assessments .

officials from each of the selected agencies provided additional perspectives on coordination with other federal agencies .

specifically: cms officials stated that while they do not coordinate with other federal agencies in conducting compliance assessments , they did coordinate with other federal agencies when establishing their cybersecurity requirements .

in addition , cms officials stated that they do not conduct assessments of compliance with their security policy and that states engage contractors to perform the assessments .

therefore , cms officials believed that the agency does not have a need to coordinate with other federal agencies .

however , cms did not include , where feasible , additional and detailed guidance to the state that it could use to inform its assessment contractors about coordination with other federal agencies .

cms guidance to the states could encourage additional coordination with other federal agencies such as planning the assessment , leveraging related efforts by other federal agencies , and sharing the state's documentation and findings with other federal agencies , as appropriate .

by not doing so , cms is not maximizing coordination with other federal agencies to the greatest extent practicable .

fbi's cjis officials stated that they schedule their security assessments 6 months ahead of time , but would be willing to reschedule the assessment if the state was unavailable due to another assessment being conducted .

in addition , cjis officials noted that while they test for security controls that other federal agencies are testing , they are not assessing the same information as other agencies because the fbi specifically requires criminal justice data to be logically separated from other data .

further , cjis officials stated their assessment results and audit findings cannot be shared and that other federal agencies would need to refer to a state's criminal justice agency for such information .

irs officials stated that they previously attempted to review assessment findings from other agencies , but since irs was not looking at the same systems , the findings were not helpful .

irs officials stated that they would be willing to review recent assessments conducted by other federal agencies to see if information can be leveraged .

ssa officials noted that it is their practice to reschedule an assessment if another federal agency has an assessment scheduled around the same time , but acknowledged that this was not in their policies .

further , according to ssa officials , they do not currently examine or consider findings from independent security assessments conducted within a state .

while agencies cited various reasons for not coordinating when assessing state agencies' cybersecurity , taking steps to coordinate , such as leveraging other agencies' assessments or conducting joint assessments whenever practicable , would be consistent with practices encouraged by omb .

however , omb has not taken steps to ensure that they do so .

omb officials noted that they believed several of the agencies had begun to coordinate on their own and acknowledged that they could take additional steps to encourage and promote coordination among the agencies .

omb officials further noted that it is ultimately the responsibility of the agencies to determine how they conduct their assessments .

nevertheless , federal agencies may be placing unnecessary burdens on state officials' time and resources in responding to similar requests and inquiries .

several state cisos told us that they have identified various instances in which multiple federal agencies' lack of coordination resulted in requests for similar documentation and interviews with it officials .

for example , according to three state cisos , the selected federal agencies have asked them to address similar questions regarding physical security controls , network configurations , and password policies in separate interviews .

three state cisos also noted that they have provided to multiple federal agencies documentation — such as network diagrams and incident response policies — related to the same it environment and have facilitated multiple federal assessments of the same physical environment .

state cisos identified additional opportunities for further coordination among federal agencies and impacts in dealing with federal cybersecurity assessments .

for instance , in response to our survey , 16 states' officials commented that the four federal agencies in our review could leverage additional opportunities to coordinate on their assessments within their states , particularly where the states had a consolidated data center or other centrally managed it infrastructure .

further , four state cisos noted that federal agencies could potentially leverage security compliance assessments and internal audits performed at the state or local level because they included reviews of controls from nist special publication 800-53 .

in addition , 11 states mentioned “duplication” in their response to a survey question about challenges or impacts related to federal cybersecurity requirements and assessment processes , while two states mentioned “overlap,” and one state mentioned “fragmentation.” for example: one state identified that assessors from different federal agencies generally ask for the same items from the state , requiring state agency officials to reproduce the same response .

another state identified that multiple federal agencies have been assessing the same state agencies with different scope , tools , and documentation requests .

in another example , a state concluded that federal assessors' interpretation of many technical controls was inconsistent and varied from one federal agency to another and across audit cycles .

the state noted that there were opportunities for the federal government to streamline how each agency applied different interpretations .

state cisos also identified impacts on their time and costs from responding to federal agencies' assessments .

seventeen respondents reported impacts to their time and six reported cost impacts .

further , in responding to questions in our survey and an in - depth interview , state cisos provided additional insights regarding impacts .

for example: one state mentioned that , due to the varying requirements from the selected federal agencies , the state is required to stand up multiple virtual and physical environments .

in doing so , the state is required to purchase additional software and hardware to maintain such environments .

another state explained that staff manage various state agencies' data in one central location and spend a considerable amount of time responding to each of the four selected federal agencies' assessments .

twenty - four states estimated that the four selected federal agencies conducted at least 188 assessments between calendar years 2016 and 2018 and that the states' best estimates of the total expenditures associated with those assessments ranged from $43.8 million to $67 million .

of 164 instances where states reported an average time spent on assessments by one of the four selected agencies between calendar years 2016 and 2018 , in 97 instances the average time expenditure per assessment was reported to be 301 staff hours or more , and in 67 instances it was less than 301 staff hours .

additionally , there were 34 instances in which the state did not know what its average staff hour expenditure was for a particular agency's assessment or said that it was not applicable to the state .

figure 3 represents the responses from 50 state cisos on the average state staff hours expended per assessment from across the four selected federal agencies as reported by state cisos .

while state agencies could benefit from additional coordination among federal agencies in conducting their security assessments , increasing coordination may also save the federal government money .

for instance , federal agencies may be able to reduce the number of assessments or the scope of the assessment conducted by each agency , the amount of time multiple federal agencies must spend reviewing state systems , and contractor services acquired to assist in performing assessments .

the selected federal agencies reported spending close to $45 million in fiscal years 2016 through 2018 on assessments of state agencies' cybersecurity .

figure 4 , an interactive figure , provides the selected federal agencies' reported spending for fiscal years 2016 through 2018 for assessing state compliance with cybersecurity requirements .

 ( see appendix iii for the cost breakdown of selected federal agencies' reported spending ) .

until fbi's cjis and ssa fully develop policies for coordinating with state agencies and all of the selected agencies develop policies for coordinating with other federal agencies when assessing state agencies' cybersecurity , as appropriate , they run the risk of spending more than necessary to assess the security of state systems and networks .

further , federal agencies may be placing unnecessary burdens on state officials' time and resources in responding to overlapping or duplicative requests and inquiries , retesting controls that have already been evaluated , or reporting similar findings multiple times throughout a state .

in addition , until omb takes steps to ensure agencies coordinate on assessments of state agencies' cybersecurity , it will not have reasonable assurance federal agencies are leveraging compatible assessments where practicable .

given that the federal government exchanges personally identifiable and other sensitive information with state agencies , it is critical to have effective coordination across the federal and state agencies to protect this information .

while the selected federal agencies have taken steps to secure information exchanged between federal and state agencies , they have not coordinated with each other in establishing cybersecurity requirements for state agencies .

the selected agencies' insufficient coordination has contributed to variances in the agencies' control selection , terminology , and technical parameters across hundreds of cybersecurity requirements imposed on states .

further , omb requires agencies to coordinate to ensure consistency among cybersecurity requirements for state entities , but it has not ensured that agencies have done so .

while federal agencies may have legitimate reasons for having variances in their cybersecurity requirements , states' compliance with multiple federal agencies' cybersecurity requirements has resulted in increased costs .

coordinating to address variances in federal agencies' cybersecurity requirements could help to significantly reduce these costs .

the selected agencies will soon have an opportunity to coordinate on any planned updates of their security policies that affect state agencies when reviewing their security policies against expected revisions in nist guidance .

accordingly , it is important that omb ensures that selected federal agencies coordinate with state agencies and each other to establish cybersecurity requirements that are consistent to the greatest extent possible .

selected federal agencies had partially established policies to coordinate with state agencies when assessing their cybersecurity , but did not have policies for coordinating with other federal agencies .

federal agencies have not been coordinating with each other on assessments of state agencies' cybersecurity , in part , because this has not been a priority for them .

further , federal agencies have been less likely to coordinate in their assessments of state agencies' cybersecurity without additional involvement from omb .

the lack of coordination among federal agencies has been a concern among state cisos who described instances of duplication and overlap in their cybersecurity assessments .

as with the cybersecurity requirements , coordinating with both state and federal agencies when assessing state agencies' cybersecurity may help to minimize additional cost and time impacts on state agencies , and reduce federal resources associated with implementing state - based cybersecurity assessments .

until omb takes steps to ensure federal agencies coordinate on assessments of state agencies' cybersecurity , it will not have reasonable assurance federal agencies are leveraging compatible assessments to the greatest extent possible .

we are making a total of 12 recommendations , including two to omb , two to cms , three to fbi , two to irs , and three to ssa .

the director of omb should ensure that cms , fbi , irs , and ssa are collaborating on their cybersecurity requirements pertaining to state agencies to the greatest extent possible and direct further coordination where needed .

 ( recommendation 1 ) the director of omb should take steps to ensure that cms , fbi , irs , and ssa coordinate , where feasible , on assessments of state agencies' cybersecurity , which may include steps such as leveraging other agencies' security assessments or conducting assessments jointly .

 ( recommendation 2 ) the administrator of cms should , in collaboration with omb , solicit input from fbi , irs , ssa , and state agency stakeholders on revisions to its security policy to ensure that cybersecurity requirements for state agencies are consistent with other federal agencies and nist guidance to the greatest extent possible and document cms's rationale for maintaining any requirements variances .

 ( recommendation 3 ) the administrator of cms should revise its assessment policies to maximize coordination with other federal agencies to the greatest extent practicable .

 ( recommendation 4 ) the fbi director should , in collaboration with omb , solicit input from cms , irs , ssa , and state agency stakeholders on revisions to its security policy to ensure that cybersecurity requirements for state agencies are consistent with other federal agencies and nist guidance to the greatest extent possible .

 ( recommendation 5 ) the fbi director should fully develop policies for coordinating with state agencies on the use of prior findings from relevant cybersecurity assessments conducted by other organizations .

 ( recommendation 6 ) the fbi director should revise its assessment policies to maximize coordination with other federal agencies to the greatest extent practicable .

 ( recommendation 7 ) the irs commissioner should , in collaboration with omb , solicit input from cms , fbi , ssa , and state agency stakeholders on revisions to its security policy to ensure that cybersecurity requirements for state agencies are consistent with other federal agencies and nist guidance to the greatest extent possible .

 ( recommendation 8 ) the irs commissioner should revise its assessment policies to maximize coordination with other federal agencies to the greatest extent practicable .

 ( recommendation 9 ) the commissioner of ssa should , in collaboration with omb , solicit input from cms , fbi , irs , and state agency stakeholders on revisions to its security policy to ensure that cybersecurity requirements for state agencies are consistent with other federal agencies and nist guidance to the greatest extent possible and document the ssa's rationale for maintaining any requirements variances .

 ( recommendation 10 ) the commissioner of ssa should fully develop policies for coordinating with state agencies on the use of prior findings from relevant cybersecurity assessments conducted by other organizations .

 ( recommendation 11 ) the commissioner of ssa should revise its assessment policies to maximize coordination with other federal agencies to the greatest extent practicable .

 ( recommendation 12 ) .

we provided a draft of this report to omb and the four other selected federal agencies for their review and comment .

in response , three of the agencies ( department of health and human services , fbi , and ssa ) stated that they agreed with the recommendations ; and one agency ( irs ) stated that it partially agreed with one recommendation and disagreed with one recommendation .

omb did not provide comments on our report .

the following three agencies agreed with the recommendations .

the department of health and human services provided written comments , in which it agreed with our recommendations and identified steps it said cms had taken or intends to take to address them .

for example , the department stated that cms intends to solicit input from the other federal agencies identified in this report and from state agency stakeholders when making updates to its mars - e security policy and when updating its assessment guidance to states on how to maximize coordination with other federal entities .

the department noted that cms had developed and implemented its suite of guidance and requirements , known as mars - e , based on the patient protection and affordable care act , fisma , and nist .

according to the department , variances in security requirements are to be expected because of the flexibility that nist allows in its guidance .

the department added that cms tailored some of the controls to allow flexibilities for states while keeping the overall intent of the nist guidance .

the department stated that it collaborated with federal agencies , including fbi's cjis , in developing mars - e and during subsequent updates of that security policy .

however , cms did not provide us with documentation as evidence of its collaboration with fbi's cjis on the development of mars - e .

in addition , as noted in this report , cms had not collaborated with the other agencies included in our review after the development of the most recent version of mars - e .

it is important that federal agencies collaborate to address variances in their cybersecurity requirements ; doing so could help to significantly reduce state agencies' costs in complying with multiple federal agencies' requirements .

the department's comments are reprinted in appendix iv .

the department also provided technical comments , which we incorporated as appropriate .

in written comments , fbi's cjis agreed with our three recommendations to the agency .

among other things , the agency stated that it would , to the greatest extent possible , collaborate with omb and solicit input from the other federal agencies identified in this report , as well as from state agency stakeholders , on revisions to its security policy .

with regard to our recommendation that fbi's cjis develop policies for coordinating with state agencies on the use of prior findings , the agency stated that it had implemented this recommendation and updated its security policy to include coordinating with state agencies on the use of prior findings from relevant cybersecurity assessments conducted by other organizations .

however , the agency did not provide documentation showing that it had updated the security policy .

as a result , we did not change our assessment of this practice .

we will continue to monitor the agency's progress in implementing the recommendation .

the agency's comments are reprinted in appendix v. the agency also provided technical comments , which we incorporated as appropriate .

in its written comments , ssa stated that it agreed with our recommendations .

ssa's comments are reprinted in appendix vi .

the agency also provided technical comments , which we incorporated as appropriate .

one agency partially agreed with one recommendation and disagreed with one recommendation .

specifically , irs partially agreed with our recommendation to , in collaboration with omb , solicit input from the four federal agencies identified in this report and state agency stakeholders on revisions to its security policy .

specifically , the agency agreed to participate in collaborative working sessions with omb and interested stakeholders to discuss the impact of inconsistent standards and the extent to which the standards might be harmonized .

however , irs stated that it must follow treasury directives and internal standards for systems that process tax data and , as a result , its ability to harmonize requirements may be limited .

as noted in this report , federal agencies may have legitimate reasons for variances in their cybersecurity requirements , such as applying different information security controls and more stringent technical parameters to protect data for which the agencies are responsible in a manner consistent with various security requirements originating in federal laws , directives , and regulations .

nevertheless , we continue to believe that it is important for all of the agencies in our review to identify opportunities where requirements can be streamlined or made more consistent while still achieving each agency's desired security outcomes because doing so may reduce potential burdens on state agencies , as discussed in this report .

thus , we maintain that our recommendation is still warranted .

irs disagreed with our recommendation to revise its assessment policies to maximize coordination with other federal agencies to the greatest extent possible .

specifically , irs stated that it has sole statutory oversight authority and enforces requirements for agencies subject to internal revenue code § 6103 .

as such , irs cannot solely rely on an assessment conducted by another agency .

however , as noted in this report , omb encourages federal agencies to coordinate on their assessments whenever practicable .

doing so would not necessarily require irs to solely rely on another agency's assessment nor conflict with its authority to conduct statutory oversight because irs could leverage and share relevant information and artifacts with other federal agencies while continuing to conduct its own required assessments and oversight .

further , as discussed in this report , state chief information officers identified a number of areas where federal agencies requested similar information through documentation requests and interviews , such as network configurations , password policies , and incident response policies .

leveraging and sharing relevant information that is collected by federal agencies could help those agencies , including irs , reduce some of their data collection needs while also helping to minimize burdens on state officials' time and resources .

we acknowledge that complete alignment of assessment policies may not be feasible in light of unique statutory responsibilities and requirements ; however , agency coordination and simplification of certain assessment logistics may be possible and could result in gained efficiencies from the perspective of the federal government .

thus , we maintain that our recommendation is still warranted .

irs's comments are reprinted in appendix vii .

we are sending copies of this report to the appropriate congressional requesters , the director of omb , the administrator of cms , the assistant attorney general for administration for the department of justice , the fbi director , the irs commissioner , and the commissioner of ssa .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-6240 or at dsouzav@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix vili .

we administered a survey to the offices of the chief information officer and chief information security officer ( ciso ) in the 50 states , district of columbia , american samoa , guam , puerto rico , and the u.s. virgin islands .

to administer the survey , we emailed each state a fillable pdf questionnaire .

we fielded the survey from february 19 , 2019 , through april 24 , 2019 .

we received usable survey responses from 50 of the 55 states and territories , for a response rate of 91 percent .

in developing , administering , and analyzing the survey , we took steps to minimize the five types of errors that may affect survey results — population coverage , sampling , measurement , nonresponse , and data processing .

our results are not subject to either of the first two types of errors — population coverage ( under - or over - coverage ) error of the study population or sampling error — because we defined all states and five territories as our study population , and sent each a questionnaire .

to minimize the third type of error ( measurement error ) , we pretested the questionnaire with cisos ( or their delegates ) in four states that varied over two characteristics related to our questions: whether or not the state took a “federated” or “consolidated” management approach to data center and other information technology ( it ) infrastructure , and the relative size of the state's it budget .

using cognitive interviewing techniques , such as nondirective probing of answers and asking respondents to think aloud when formulating answers , we determined whether ( 1 ) the questions were clear and unambiguous , ( 2 ) terminology was used correctly , ( 3 ) the questionnaire did not place an undue burden on state officials , ( 4 ) the information could feasibly be obtained , and ( 5 ) the survey was comprehensive and unbiased .

based on the pretests and interviews with external subject matter experts on questionnaire subjects , we modified the questionnaire .

during the survey , we also followed up by email or phone with some respondents to clarify unclear answers and edit them if necessary .

additionally , after the survey , our in - depth interviews with four responding states confirmed their answers to selected questions , or resulted in edits to those answers .

to minimize the potential for the fourth type of error ( nonresponse error ) , we emailed or called states that did not respond to the initial notice multiple times to encourage survey participation or provide technical assistance , as appropriate .

also , the follow up contacts made to clarify answers resulted in obtaining some answers to questions that had been left blank in returned questionnaires .

while the four states and one territory not returning questionnaires may have differed to an unknown extent in what their answers would have been , compared to the aggregate answers of those who did respond , the overall impact on our results from only five missing members of the population is unlikely to be material .

to minimize the possibility for the fifth type of error ( data processing error ) , all data entry , edits , and analysis were verified by a second , independent analyst on the engagement team .

to further understand the states' experiences with and views of selected federal agencies' cybersecurity assessments , we conducted in - depth interviews with four states .

in selecting the four states for in - depth interviews , we considered responses from 44 states that had submitted surveys prior to april 11 , 2019 .

from these states , we analyzed responses to survey questions 4 , 7 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , and 17 , and identified whether states' responses reflected a generally favorable opinion or a generally unfavorable opinion of federal cybersecurity requirements and assessments .

based on this information , we selected two states to interview that had a generally favorable opinion and two states that had a generally unfavorable opinion toward federal cybersecurity assessments and requirements .

in selecting states to interview from states that had favorable and unfavorable opinions , we chose to interview states that provided different responses about increases in costs and / or coordination with federal and nonfederal agencies .

we sent an email to each of the four states to ask for their participation and conducted follow up interviews with officials from the offices of the state cio and state ciso , state audit entities , and mission agencies from four states .

our interview questions concerned topics such as challenges states may have faced in complying with federal cybersecurity requirements , the impacts federal requirements and assessments may have had on states , the efficiency and effectiveness of assessments performed by each federal agency , and the nature and extent of any duplication in federal agencies' cybersecurity requirements .

although the results of these in - depth interviews are not generalizable to all of the states and territories that responded to our survey , they provide richer insight into some of the information we collected through our survey , such as the reasons for certain questionnaire responses or the sources of variation in states' perspectives .

the following identifies the survey questionnaire that we administered and the aggregated results from the responses are below under each question .

not all state cisos who completed the survey responded to all questions , and some questions were not discussed in the body of our report .

these questions ask about the federal agency cybersecurity requirements that set standards in any of the related general security control categories , and your experiences with those applicable to your state .

1 .

for how long has the current ciso of your state been in that role ? .

 ( check one box ) 2 .

please provide some background on your state's governance model for cybersecurity .

specifically , how is the responsibility for managing the following aspects of cybersecurity primarily assigned within your state ? .

 ( check the one box in each row which best represents your answer ) 3 .

is your state currently required to meet any security requirements by any of the following federal agencies in order to obtain and use federal data ? .

federal bureau of investigation ( fbi ) ( criminal justice information services ( cjis ) security policy cjisd - its - doc - 08140-5.7 , version 5.7 ) centers for medicare & medicaid services ( cms ) ( minimum acceptable risk standards for exchanges , version 2.0 ) internal revenue service ( irs ) ( irs publication 1075 , tax information security guidelines for federal , state , and local agencies , september 2016 ) social security administration ( ssa ) ( electronic information exchange security requirements and procedures for state and local agencies exchanging electronic information , version 8.0 ) 4 .

federal security requirements applicable to states may vary in a number of ways .

considering as a whole all of the federal agencies' requirements that your state is currently required to meet , how much do you think they vary from each other in each of the following ways ? .

5 .

consider again all the applicable federal cybersecurity requirements required of your state .

do one or more federal agencies have any requirements that most vary from other agencies ? .

within each of the following families of security controls , check all boxes that apply to tell us in what ways requirements vary , and which agency ( s ) vary the most from others .

 ( if “other ( s ) ” varying agencies selected , list in question 6. ) .

nist control family access control ( ac ) awareness and training ( at ) audit and accountability ( au ) security assessment and authorization ( ca ) configuration and management ( cm ) contingency planning ( cp ) identification and authentication ( ia ) incident response ( ir ) media protection ( mp ) physical and environmental protection ( pe ) planning ( pl ) personnel security ( ps ) risk assessment ( ra ) system and services acquisition ( sa ) system and communications protection ( sc ) system and information integrity ( si ) program management ( pm ) 6 .

if you indicated above that any other federal agencies have requirements that most vary from others , what are those other agencies and the control categories and way ( s ) they vary ? .

 ( narrative answers not displayed ) 7 .

if you identified any variation in the requirements of multiple federal agencies in question 5 above , what is your overall estimation of the degree of that variation in each of the following families of controls ? .

families of controls ( based on nist 800-53 ) access control ( ac ) awareness and training ( at ) audit and accountability ( au ) security assessment and authorization ( ca ) configuration management ( cm ) contingency planning ( cp ) identification and authentication ( ia ) incident response ( ir ) maintenance ( ma ) media protection ( mp ) physical and environmental protection ( pe ) planning ( pl ) personnel security ( ps ) risk assessment ( ra ) system and services acquisition ( sa ) system and communications protection ( sc ) system and information integrity ( si ) 8 .

do you have any comments on or explanations of your answers to the question above that would help us appropriately interpret those answers ? .

 ( itemize your comments by the row letters above , to the extent possible , in the box below ) ( narrative answers not displayed ) 9 .

has your state taken any of the following actions specifically to address variation ( s ) across agency requirements ? .

increased coordination with nascio and other non - federal agencies outside your state increased coordination with other agencies within your state any other action ( s ) 10 .

have the variations increased any of the following types of costs and / or challenges ? .

the following questions ask about assessments performed by federal agencies on your state on its compliance with the federal cybersecurity requirements covered above .

for the purposes of this survey , an “assessment” includes only the activities in the period between the date the state is notified of the assessment and the date the federal agency or entity carrying out the assessment ( eg , contractor ) completes its on - site work .

11 .

approximately how many assessments did each of the following federal agencies perform on your state's efforts to comply with its requirements in calendar years 2016-2018 ? .

 ( when counting assessments performed by one federal agency on more than one state mission agency or operational entity at the same time , please count each assessment individually. ) .

any other federal agency ( s ) 12 .

considering up to the last 3 assessments a federal agency performed in 2016-2018 , approximately how long in calendar time was taken per assessment , on average , to perform ? .

any other federal agency ( s ) 13 .

considering up to the last 3 assessments a federal agency performed in 2016-2018 , approximately how many of your state's staff hours were expended per assessment , on average , to comply ? .

any other federal agency ( s ) 14 .

and considering up to the last 3 assessments a federal agency performed in 2016-2018 , what is your best estimate of the range of cost in dollars ( including staff hour labor , travel , materials , and contract costs ) your state expended per assessment , on average , to comply ? .

estimated lower end of dollar cost ( mean value ) $77,103 ( 17 responses ) estimated upper end of dollar cost ( mean value ) don't know 28 ( 17 responses ) $623,650 19 responses ) $840,472 ( 19 responses ) $211,574 ( 21 responses ) $418,238 ( 21 responses ) $33,822 ( 16 responses ) $61,719 ( 16 responses ) 15 .

considering all the federal assessments performed on your state's implementation of requirements in 2016-2018 , how would you rate those assessments , overall , on the following factors ? .

16 .

in summary , how would you rate the efficiency of assessments performed by each federal agency on your state's implementation of requirements ? .

any other agency ( s ) 17 .

in summary , how would you rate the effectiveness of assessments performed by federal agencies on your state's implementation of requirements ? .

any other agency ( s ) 18 .

considering the issues covered in this questionnaire , what challenges or impacts , if any , has your state experienced regarding the federal requirements and assessment processes ? .

 ( list and describe up to 5 ) ( narrative answers not displayed ) 19 .

do you have any additional explanations of your answers or comments on any of the issues in this questionnaire ? .

 ( narrative answers not displayed ) 20. who is the person primarily responsible for completing this questionnaire whom we can contact in case we need to clarify a response ? .

if the state ciso did not complete this questionnaire , we recommend that the ciso review these answers .

the tables below identify the extent to which each of the four selected federal agencies established policies that addressed individual activities supporting two areas of coordination: ( 1 ) coordination with state agencies when assessing states' cybersecurity and ( 2 ) coordination with other federal agencies on the assessment of state agencies' cybersecurity .

in addition to the individual named above , josh leiling ( assistant director ) , lori martinez ( analyst in charge ) , gerard aflague , joseph andrews , david blanding , chris businsky , rebecca eyler , torrey hardee , andrea harvey , keith kim , monica perez - nelson , and carl ramirez made significant contributions to this report .

