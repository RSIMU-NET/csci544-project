a key goal of navy senior leadership is to transform the navy to better meet 21st century security challenges .

since 2000 , congress has appropriated about $50 billion annually for the navy to operate and maintain its forces and support around 376,000 active military personnel .

nonetheless , the navy recognizes it is facing affordability issues related to sustaining readiness while developing and procuring several types of new ships within its historical share of the defense budget .

one area where the navy has made significant changes is in its operational posture .

in march 2003 , the chief of naval operations initiated the development of a concept , which became known as the fleet response plan , to enhance the navy's deployment readiness status .

the fleet response plan , as implemented by fleet forces command in may 2003 , is designed to more rapidly prepare and then sustain readiness in ships and squadrons .

to achieve this capability , the plan alters prior manning , maintenance , and training practices to allow for a more responsive and ready naval force .

the navy expects this new readiness approach will enable its forces to provide not only presence and engagement in forward areas , but also surge a greater number of ships on short - notice in response to significant crises without increasing the readiness budget .

the fleet response plan modifies the navy's pre - 2001 rotational deployment policy , replacing 6-month routine deployments with more flexible deployment options for as many as eight carrier strike groups when and where needed .

the fleet response plan represents a major change in the way the navy manages its forces .

implementing large - scale change management initiatives , such as organizational transformations , can be a complex endeavor .

our prior work shows that failure to adequately address — and often even consider — a wide variety of management issues is at the heart of unsuccessful transformations .

we have identified a number of key best practices and lessons learned from major public and private sector organizational mergers , acquisitions , and transformations .

these sound management practices include , for example , establishing a coherent mission and integrated strategic goals to guide the transformation , including resource commitments ; setting implementation goals and a timeline to build momentum and show progress from day one ; and establishing a communication strategy to create shared expectations and report related progress .

we prepared this report under the comptroller general's authority and are providing it to you because of your oversight of defense issues .

we have previously reported on the maintenance aspects of the navy's fleet response plan .

this report focuses on the following two questions: ( 1 ) to what extent has the navy employed a sound management approach in implementing the fleet response plan ? .

 ( 2 ) to what extent has the navy tested and evaluated the effectiveness of its fleet response plan and shared results to improve its implementation ? .

to assess the navy's management approach in implementing the fleet response plan , we obtained and analyzed key messages , briefings , and instructions on the fleet response plan and interviewed department of defense ( dod ) and navy headquarters and fleet officials , and compared the navy's approach with best practices for transformations of large organizations .

to assess the extent to which the navy has tested the effectiveness of the fleet response plan and shared results to improve its implementation , we obtained briefings from and interviewed navy officials , reviewed and queried the navy lessons learned system to determine relevant lessons recorded , and examined navy guidance on test and evaluation efforts .

we reviewed and validated the navy lessons learned system data and determined the data were sufficiently reliable for our analysis .

we conducted our review from january 2005 through august 2005 in accordance with generally accepted government auditing standards .

the scope and methodology used in our review are described in further detail in appendix i .

carrier strike groups are typically centered around an aircraft carrier and its air wing , and also include a guided missile cruiser ; two guided missile destroyers ; a frigate ; an attack submarine ; and one or more supply ships with ammunition , fuel , and supplies ( such as food and spare parts ) .

these groups are formed and disestablished on an as needed basis , and their compositions may differ though they contain similar types of ships .

figure 1 shows a carrier strike group sailing in a group formation as it prepares to participate in an exercise .

prior to the september 11 , 2001 , terrorist attacks , only those navy ships and air squadrons at peak readiness were deployed overseas , usually for 6 months at a time .

most of the navy's remaining units were not available because they were in early stages of their maintenance or training cycles , or because the navy did not have good visibility of the readiness of these units .

this prompted the chief of naval operations in march 2003 to task the commander , fleet forces command , to develop the fleet response plan concept to enhance the navy's surge capability .

the chief of naval operations approved the concept in may 2003 and further directed the commander , fleet forces command , to be responsible and accountable for effectively implementing the plan .

the fleet response plan emphasizes an increased level of readiness and the ability to quickly deploy naval forces to respond to crises , conflicts , or homeland defense needs .

the plan applies broadly to the entire fleet ; however , it only sets specific requirements for carrier strike groups .

for example , the plan calls for eight carrier strike groups to be ready to deploy within 90 days of notification .

six of them would be available to deploy within 30 days and the other two within 90 days .

this is commonly referred to as the 6 + 2 goal .

under the fleet response plan , the navy has developed a surge capability schedule that it uses to manage and identify the level of training a ship has completed and its readiness to deploy .

the schedule contains three progressive readiness goals: emergency surge , surge - ready , and routine deployable status .

each readiness goal specifies phases of training that must be completed to achieve the goal .

to be placed in emergency surge status , a ship or an air squadron needs to have completed its unit - level phase training .

achieving surge - ready status requires the completion of integrated phase training .

attaining routine deployable status requires achievement of all necessary capabilities , completion of underway sustainment phase training , and certification of the unit for forward deployed operations .

the surge capabilities schedule provides a readiness snapshot for each ship , allowing decision makers to quickly determine which ships are available to meet the needs of the mission .

figure 2 illustrates how the navy notionally identifies the eight aircraft carriers available for surge deployments .

the carriers numbered 1 through 6 are expected to be ready to deploy within 30 days notice .

the carriers labeled “+1” and “+2” are expected to able to surge within 90 days notice .

the six surge - ready carriers include two carriers on deployment ( numbered 3 and 4 ) , one carrier that is part of the forward deployed naval force based in japan ( number 6 ) , and three carriers in the sustainment phase ( numbered 1 , 2 , and 5 ) .

these six carriers are expected to have completed postdeployment depot - level maintenance and their unit - level phase training .

the two additional surge carriers are expected to have completed depot - level maintenance but not to have completed unit - level phase training .

the remaining four carriers are in the maintenance phase or deep maintenance .

based on the navy's experiences during the past 2 years , fleet forces command has convened a cross - functional working group to develop a refined version of the fleet response plan .

this update , known as fleet response plan - enhanced , is intended to further define the fleet response plan , modify terminology for progressive readiness states to better reflect their meaning , tie in elements such as a human capital strategy , and expand the focus of the plan beyond carrier strike groups to the entire navy .

it may also extend the fleet response plan's current employment cycle length of 27 months .

the fleet response plan - enhanced is still under development at this time .

the navy's management approach in establishing the fleet response plan as its new readiness construct has not fully incorporated sound management practices needed to effectively guide , monitor , and assess implementation .

studies by several organizations have shown that successful organizations in both the public and private sectors use sound management practices to assist agencies in measuring performance , reporting results , and achieving desired outcomes .

these practices provide management with a framework for effectively implementing and managing programs and shift program management focus from measuring program activities and processes to measuring program outcomes .

sound management practices include ( 1 ) establishing a coherent mission and integrated strategic goals to guide the transformation , including resource commitments ; ( 2 ) setting implementation goals and a timeline to build momentum and show progress from day one ; and ( 3 ) establishing a communication strategy to create shared expectations and report related progress .

the navy's implementation of the fleet response plan has included some aspects of these practices .

for example , the navy has established some strategic goals needed to meet the intent of the plan , such as the progressive readiness levels of emergency surge , surge - ready , and routine deployable status .

the navy also has established specific training actions to support these goals , such as that carrier strike groups must complete unit - level training to be certified as emergency surge - ready .

however , other actions taken by the navy do not fully incorporate these practices .

for example , the navy has identified the 6 + 2 surge capability as a readiness goal and performance measure for carrier strike groups , but no such goal was established for the rest of the fleet .

the navy also has some unofficial goals and performance measures regarding manning and maintenance , but these unofficial goals and performance measures have not been formally established .

for example , briefings on the fleet response plan state that the navy desires and needs fully manned ships ( i.e. , manning at 100 percent of a ship's requirement ) for the program to be successful .

moreover , according to navy officials , the navy has not established milestones for achieving its results .

in addition , 2 years after initiating implementation of the fleet response plan , the navy still does not have an official written definition of the fleet response plan that clearly establishes a coherent mission and integrated strategic goals to guide the transformation , including resource commitments .

this definition would describe the fleet response plan's total scope and contain guidance with formal goals and performance measures .

the navy recently has taken some action to address this area .

in february 2005 , the navy directed the center for naval analyses to conduct a study to develop formal definitions and guidance as well as identify goals and performance measures for the plan .

however , it remains to be seen whether this study will be completed as planned by november 2005 ; if it will recommend developing and implementing sound management practices , such as goals , measures , milestones , and timelines ; and whether any management improvement recommendations made in the study will be implemented by the fleet forces command , the navy command responsible for implementing the fleet response plan .

without goals , performance measures , timelines , milestones , benchmarks , and guidance to help effectively manage implementation of the fleet response plan and determine if the plan is achieving its goals , the navy may find it more difficult to implement the fleet response plan across the entire naval force .

moreover , despite the navy's unofficial goal that the fleet response plan be budget neutral , as articulated in briefings and by senior leaders , the navy has not yet clearly identified the resources needed to achieve its goals or provided a rationale for how these resources will contribute to achieving the expected level of performance .

navy officials have said that current operations and maintenance funding levels , as well as manning at 100 percent of required positions , have contributed to successful implementation of the fleet response plan .

however , officials do not know what level of manning or funding is actually required for program success over the long term to avoid any unintended consequences , such as greater amounts of deferred maintenance .

according to navy officials , it is difficult to attribute costs to the plan because there is no single budget line item that tracks the costs associated with the fleet response plan .

without knowing the funding needed , the navy may not be able to assess the impact of possible future changes in funding on implementing the plan .

furthermore , without a comprehensive plan that links costs with performance measures and outcomes , neither the navy nor congress may be able to determine if the fleet response plan is actually achieving its unofficial goal of being budget neutral .

finally , the navy also has not developed a comprehensive communications strategy that reaches out to employees , customers , and stakeholders and seeks to genuinely engage them in a two - way exchange , which is a critical step in successfully implementing cultural change or transformation .

we looked for formal mechanisms that communicated the details of the fleet response plan and spoke with personnel from carrier strike groups , aircraft carriers , air wings and an air squadron , one surface combatant ship , and other command staff .

we found that while the fleet response plan was communicated extensively to senior - level officers , and the navy provided numerous briefings and messages related to the plan , communication and understanding of the plan did not flow through to the lower ranks .

while the concept of the fleet response plan is generally understood by some senior - level officials , many of the lower grade personnel on these ships were unaware of the scope , goals , and other aspects of the plan .

in the absence of clear communication throughout the fleet via an overall communications strategy that could increase employee awareness of the fleet response plan , its successful implementation could be impeded .

sound management practices , such as those noted above , were not fully used by the navy because senior leaders wanted to quickly implement the fleet response plan in response to the chief of naval operations' desires .

however , without an overall management plan containing all of these elements to guide the implementation of such a major change , it may be difficult for the navy and congress to determine the extent to which the fleet response plan is achieving the desired results , measure its overall progress , or determine the resources needed to implement the plan .

the navy has not fully tested and evaluated the fleet response plan or developed lessons learned to identify the effectiveness of its implementation and success over time .

the methodical testing , exercising , and evaluation of new doctrines and concepts is an established practice throughout the military to gain insight into how systems and capabilities will perform in actual operations .

however , instead of methodically conducting realistic tests to evaluate the fleet response plan , the navy has tried to demonstrate the viability of the plan by relying on loosely linked events that were not part of an overall test and evaluation strategy , which impairs the navy's ability to validate the plan and evaluate its success over time .

in addition , the navy has not used its lessons learned system to share the results of its fleet response plan tests or as an analytical tool to evaluate the progress of the plan and improve implementation , which limits the navy's ability to identify and correct weaknesses across the fleet .

methodically testing , exercising , and evaluating new doctrines and concepts is an important and established practice throughout the military .

dod has long recognized the importance of using tabletop exercises , war games , and experimentation to explore military doctrine , operational concepts , and organizational arrangements .

collectively , these tests and experiments can provide important insight into how systems and capabilities will perform in actual operations .

u.s. joint forces command , which has lead responsibility for dod experimentation on new concepts of operation and technologies , states that its experimental efforts aim to foster military innovation and improvement by exploring , developing , and transferring new concepts and organizational ideas into operational reality .

particularly large and complex issues may require long - term testing and evaluation that is guided by study plans .

joint forces command's joint warfighting center has an electronic handbook that provides guidance for conducting exercises and lays out the steps in an exercise life cycle: design ; planning ; preparation ; execution ; and analysis , evaluation , and reports .

the army also has well - established guidance governing service studies , analyses , and evaluations that the navy feels is representative of best practices for military operations research .

this provides an important mechanism through which problems pertaining to critical issues and other important matters are identified and explored to meet service needs .

as shown in figure 3 , the army's process involves six major steps that create a methodical process for developing , conducting , documenting , and evaluating a study .

following a formal study process enables data evaluation and development of lessons learned that could be used to build on the existing knowledge base .

in a roundtable discussion with the fleet forces command on the rationale behind summer pulse 2004 , the navy's major exercise for the fleet response plan , a senior navy official stated , “from the concept , … you need to exercise , … you need to practice , … you need to demonstrate it to know you got it right and what lessons are there to learn from how we did it.” other governmental agencies , like gao , and the private sector also rely on detailed study plans , or data collection and analysis plans , to guide the development of studies and experiments and the collection and analysis of data , and to provide a feedback loop that links the outcomes of the study or experiment event and subsequent analysis to the original goals and objectives of the study or event .

gao guidance states that data collection and analysis plans “should carry forward the overall logic of the study so that the connection between the data that will be collected and the answers to the study questions will become evident.” recent navy guidance also recognizes the need for a thorough evaluation of complex initiatives .

in april 2005 , the navy issued a study planning and conduct guide assembled by the navy warfare development command .

this guide stresses the importance of establishing a long - range plan for complex and novel problems and lays out the rationale for detailed study plans for exercises and experiments , as they establish a structure in which issues are explored and data are collected and analyzed in relation to the established goals or objectives for the event .

furthermore , the navy's guide notes that random , inadequately prepared events and a determination just to study the problem do not lead to successful resolution of problems that may arise in programs and concepts that the navy is testing and evaluating .

the navy has not methodically conducted realistic tests of the fleet response plan to demonstrate the plan's viability and evaluate its progress and success over time , instead relying on loosely linked events and some routine data to demonstrate the viability of the plan .

the events identified by the navy as successful tests of the fleet response plan are summer pulse 2004 , the emergency deployment of the u.s.s .

abraham lincoln , and global war on terrorism surge 2005 , but of these events only summer pulse 2004 was driven by the fleet response plan with the intent of demonstrating that large numbers of ships could be surged .

in addition , these events were not part of an overall test and evaluation strategy that yielded specific information from which to assess the value of the plan in increasing readiness and meeting the new 6 + 2 surge capability goal for carrier strike groups .

summer pulse 2004 encompassed a number of previously scheduled deployments , exercises , and training events that took place between june and august of 2004 .

the intent of summer pulse 2004 was to demonstrate the fleet response plan's new readiness construct and the navy's ability to deploy multiple carrier strike groups of varying levels of readiness .

however , summer pulse 2004 was not a methodical and realistic test of the fleet response plan for three reasons .

first , summer pulse 2004 did not follow best practices regarding study plans and the ability to evaluate the impact and outcomes of the plan .

the navy did not develop a formal study plan identifying study objectives , data collection requirements , and analysis , or produce a comprehensive after - event report describing the study's findings .

navy officials have stated that the elements of a formal study plan were there for the individual deployments , exercises , and training events constituting summer pulse 2004 , but were not brought together in a single package .

while the navy may have had the study elements present for the individual exercises , they were not directly linked to testing the fleet response plan .

without such a comprehensive study plan and overall evaluation , there is no ability to discern potential impacts on fleet readiness , maintenance , personnel , and other issues that are critical to the fleet response plan's long - term success .

second , summer pulse 2004 was not a realistic test because all participating units had several months' warning of the event .

as a result , five carriers were already scheduled to be at sea and only two had to surge .

because six ships are expected to be ready to deploy with as little as 30 days' notice under the plan and two additional carriers within 90 days , a more realistic test of the fleet response plan would include no - notice or short - notice exercises .

such exercises conducted without advance notification to the participants would provide the highest degree of challenge and realism .

without such exercises , the navy might not be able to realistically practice and coordinate a full surge deployment .

third , summer pulse 2004 was not a sufficient test because the navy involved only seven carriers instead of the eight carriers called for in the plan .

therefore , it did not fully test the navy's ability to meet deployment requirements for the expected force .

another event cited by the navy as evidence of the fleet response plan's success is the deployment of the u.s.s .

abraham lincoln carrier strike group while it was in surge status in october 2004 .

originally scheduled to deploy in the spring of 2005 , the lincoln was deployed early to support operations in the pacific command area of operation and provide aid to areas devastated by a tsunami in the indian ocean in december 2004 .

navy officials said that the fleet response plan enabled the navy to identify a carrier to send to the pacific and to quickly tailor its training package based on its progressive readiness status .

the navy touted this rapid response relief work by a strike group deployed during surge status as a fleet response plan success story .

we agree that the lincoln carrier strike group was able to respond quickly .

however , the extent to which this event realistically tested the fleet response plan's expectations for surging one carrier strike group is not known .

as with summer pulse 2004 , the lincoln deployment was not a methodical test of the fleet response plan because there was no plan to systematically collect or analyze data that would evaluate the outcomes of the lincoln deployment against fleet response plan - related study goals .

the navy also pointed to a third event , its recent global war on terrorism surge 2005 , as an indicator that the fleet response plan works .

the global war on terrorism surge was a response to a request for forces from which the navy is looking to glean fleet response plan - related information about what did and did not work when the ships return .

however , this is not a good test of the fleet response plan because there is no plan showing what specific data are being collected or what analytical approaches are being employed to assess the ships' experiences .

as of september 2005 , no other events had been scheduled to further test and evaluate the fleet response plan .

the navy has not developed the kind of comprehensive plans to test and evaluate the fleet response plan as recommended by dod and navy guidance and best practices because navy officials have stated that existing readiness reporting processes effectively evaluate the fleet response plan's success on a daily basis .

they said after - action reports from training exercises and the joint quarterly readiness review assist with this function .

navy officials explained that they implemented the fleet response plan the same way they had implemented the inter - deployment training cycle , the predecessor to the fleet response plan's fleet readiness training plan .

while this may be true , the inter - deployment training cycle was focused on the specific training needed to prepare units for their next deployment , not for implementing a new readiness construct that emphasized surge versus routine deployments .

furthermore , the inter - deployment training cycle did not contain stated goals whose validity the navy needed to test .

in addition , ongoing readiness reports do not provide information on important factors such as costs , long - term maintenance implications , and quality of life issues .

the summer pulse 2004 , lincoln surge deployment , and global war on terrorism surge 2005 testing events were not part of a methodical test and evaluation approach .

therefore , the navy is unable to convincingly use these events to evaluate the fleet response plan and determine whether the plan has been successful in increasing readiness or achieving other goals .

moreover , without effective evaluation of the fleet response plan , the navy may be unable to identify and correct potential problem areas across the fleet .

without a comprehensive long - range plan that establishes methodical and realistic testing of the fleet response plan , the navy may be unable to validate the fleet response plan operational concept , evaluate its progress and success over time , and ensure that it can effectively meet navy goals over the long term without any adverse , unintended consequences for maintenance , quality of life , and fleet readiness .

the formal navy repository for lessons learned , the navy lessons learned system , has not been used to disseminate fleet response plan - related lessons learned or to analyze test results to evaluate the progress of the plan and improve implementation .

the navy lessons learned system has been designated by the chief of naval operations as the singular navy program for the collection , validation , and distribution of unit feedback as well as the correction of problems identified and derived from fleet operations , exercises , and miscellaneous events .

however , there are no mechanisms or requirements in place to force ships , commands , and numbered fleet staffs to submit all lessons learned to the navy lessons learned system , although such mechanisms exist for the submission of port visit and other reports .

for the events that the navy cites as tests of the fleet response plan , it did not analyze and evaluate the results and produce formal lessons learned to submit to the navy lessons learned system for recordation and analysis .

any evaluation done of the testing events has not been incorporated into the lessons learned system , preventing comprehensive analyses of lessons learned and identification of problems and patterns across the fleet that may require a high - level , navy - wide response .

some ship and carrier strike group staff informed us that they prefer informal means of sharing lessons learned , because they feel the process through which ships and commands have to submit lessons learned for validation and inclusion in the database can be complex and indirect .

this may prevent ship and command staffs across the fleet from learning from the experiences of others , but it also prevents the navy lessons learned system from performing comprehensive analyses of the lessons learned and possibly identifying problems and patterns across the fleet that may require a high - level navy - wide response .

in addition , the lessons learned are recorded by mission or exercise ( eg , operation majestic eagle ) and not by operational concept ( eg , the fleet response plan ) , making identification of fleet response plan - specific lessons learned difficult and inconsistent .

over the last 10 years , we have issued several reports related to lessons learned developed by the military .

we have found that service guidance does not always require standardized reporting of lessons learned and lessons learned are not being used in training or analyzed to identify trends and performance weaknesses .

we emphasized that effective guidance and sharing of lessons learned are key tools used to institutionalize change and facilitate efficient operations .

we found that despite the existence of lessons learned programs in the military services and the joint staff , units repeat many of the same mistakes during major training exercises and operations .

our current review indicates that the navy still does not include all significant information in its lessons learned database .

therefore , navy analysts cannot use the database to perform comprehensive analyses of operational concepts like the fleet response plan to evaluate progress and improve implementation .

officials from the navy warfare development command stated that the navy is currently drafting a new chief of naval operations instruction governing the navy lessons learned system that will address some of these issues .

navy warfare development command officials hope that the new instruction will result in several improvements over the current system .

first , they would like to see a dual reporting system , so that lessons learned are simultaneously sent to the navy lessons learned system for preliminary evaluation when they are submitted to the numbered fleets for validation .

this would allow navy lessons learned analysts to look at unvarnished data for patterns or issues of interest to the chief of naval operations , without taking away the numbered fleets' validation processes .

in addition , officials would like to establish deadlines for the submission of lessons learned to ensure timeliness .

not only will these changes add value to the data stored in the navy lessons learned system , but they will keep the data flowing while ensuring that data are actually submitted and not lost as they move up the chain of command .

according to navy lessons learned officials , other branches of the military already allow operators in the field to submit lessons learned directly to their lessons learned systems , enabling value - added analysis and the timely posting of information .

by addressing these issues , the navy can help ensure that the lessons learned process will become more efficient , be a command priority , and produce actionable results .

two years after implementing a major change in how it expects to operate in the future , the navy has not taken all of the steps needed to enable the navy or congress to assess the effectiveness of the fleet response plan .

as the navy prepares to implement the fleet response plan across the entire naval force , it becomes increasingly important that the navy effectively manages this organizational transformation so that it can determine if the plan is achieving its goals .

the absence of a more comprehensive overarching management plan to implement the fleet response plan has left essential questions about definitions , goals , performance measures , guidance , timelines , milestones , benchmarks , and resources unanswered , even though sound management practices recognize the need for such elements to successfully guide activities and measure outcomes .

the absence of these elements could impede effective implementation of the fleet response plan .

furthermore , without a comprehensive plan that links costs with performance measures and outcomes , neither the navy nor congress may be able to determine if the fleet response plan is budget neutral .

more effective communications throughout the fleet using an overall communications strategy could increase employee awareness of the plan and help ensure successful implementation .

the navy also has not developed a comprehensive long - range plan for testing and evaluating the fleet response plan .

without a well - developed plan and methodical testing , the navy may not be aware of all of the constraints to successfully surging its forces to crises in a timely manner .

moreover , the absence of an overarching testing and evaluation plan that provides for data collection and analysis may impede the navy's ability to use its testing events to determine whether the fleet response plan has been successful in increasing readiness and to identify and correct problem areas across the fleet .

failure to document and record the results of testing and evaluation efforts in the navy lessons learned system could limit the navy's ability to validate the value of the concept , identify and correct performance weaknesses and trends across the fleet , perform comprehensive analyses of lessons learned , and disseminate these lessons and analyses throughout the fleet .

to facilitate successful implementation of the fleet response plan and enhance readiness and ensure the navy can determine whether the plan has been successful in increasing readiness and is able to identify and correct performance weaknesses and trends across the fleet , we recommend that the secretary of defense take the following two actions: direct the secretary of the navy to develop a comprehensive overarching management plan based on sound management practices that will clearly define goals , measures , guidance , and resources needed for implementation of the fleet response plan , to include the following elements: establishing or revising fleet response plan goals that identify what fleet response plan results are to be expected and milestones for achieving these results , developing implementing guidance and performance measures based on these goals , identifying the costs and resources needed to achieve each performance goal , and communicating this information throughout the navy .

direct the secretary of the navy to develop a comprehensive plan for methodical and realistic testing and evaluation of the fleet response plan .

such a comprehensive plan should include a description of the following elements: how operational tests , exercises , war games , experiments , deployments , and other similar events will be used to show the performance of the new readiness plan under a variety of conditions , including no - notice surges ; how data will be collected and analyzed for these events and synthesized to evaluate program success and improvements ; and how the navy lessons learned system will collect and synthesize lessons from these events to avoid repeating mistakes and improve future operations .

in written comments on a draft of this report , dod generally concurred with our recommendations and cited actions it will take to implement the recommendations .

dod concurred with our recommendation that the navy should develop a comprehensive overarching management plan based on sound management practices that would clearly define the goals , measures , guidance , and resources needed for successful implementation of the fleet response plan , including communicating this information throughout the navy .

dod noted that the navy has already taken action or has plans in place to act on this recommendation , and described several specific accomplishments and ongoing efforts in this regard .

dod also noted that the navy intends to communicate through message traffic , white papers , instructions , lectures , and meetings with navy leadership .

we agree that these means of communication are an important part of an effective communication strategy ; however , we do not believe that these methods of communication constitute a systemic strategy to ensure communication at all personnel levels .

we believe the navy would benefit from a comprehensive communication strategy that builds on its ongoing efforts , but encompasses additional actions to ensure awareness of the plan throughout the navy .

dod partially concurred with our recommendation to test and evaluate the fleet response plan .

dod noted that it plans to use a variety of events and war games to evaluate the fleet response plan , but it does not see a need to conduct no - notice surges to test the fleet response plan .

dod stated that it believes no - notice surges are expensive and unnecessary and could lead to penalties on overall readiness and the ability to respond to emergent requirements .

dod also noted that the navy has surged single carrier strike groups , expeditionary strike groups , and individual ships or units under the fleet response plan , and it cited several examples of such surges .

we commend the navy's plans to use a variety of events to evaluate the fleet response plan and its use of the navy lessons learned system to report and evaluate the lessons learned in the global war on terrorism surge 2005 exercise held earlier this year .

however , we continue to believe that no - notice surges are critical components of realistic testing and evaluation plans and that the benefits of such exercises can outweigh any additional costs associated with conducting such tests on a no - notice basis .

both we and congress have long recognized the importance of no - notice exercises .

for example , in a 1989 report , we noted that dod was instituting no - notice exercises to assess the preparedness of combatant commands' state of training of their staffs and components .

in addition , in 1990 the department of energy conducted no - notice tests of security personnel in response to our work and out of recognition that such tests are the best way to assess a security force's ability at any given time .

furthermore , in recent years , the department of homeland security , department of energy , and others have conducted no - notice exercises because they add realism and demonstrate how well organizations are actually prepared to respond to a given situation .

despite the importance of no - notice exercises , the navy has not conducted no - notice exercises to test and evaluate the centerpiece surge goal of 6 + 2 for carrier strike groups .

we believe that the smaller surges cited by dod can provide insights into the surging process , but we do not believe that such surges can effectively test the navy's readiness for a full 6 + 2 carrier strike group surge .

dod also provided technical and editorial comments , which we have incorporated as appropriate .

dod's comments are reprinted in appendix ii of this report .

we are sending copies of this report to other interested congressional committees ; the secretary of defense ; the secretary of the navy ; and the director , office of management and budget .

we will make copies available to others upon request .

in addition , the report will be available at no charge on the gao web site at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-4402 or stlaurentj@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iii .

to assess the extent to which the navy has employed a sound management approach in implementing the fleet response plan , we interviewed navy headquarters and fleet officials ; received briefings from relevant officials ; and reviewed key program documents .

in the absence of a comprehensive planning document , we compared best practices for managing and implementing major efforts to key navy messages , directives , instructions , and briefings , including , but not limited to , the culture of readiness message sent by the chief of naval operations ( march 2003 ) ; the fleet response concept message sent by the chief of naval operations ( may 2003 ) ; the fleet response plan implementation message sent by the commander , fleet forces command ( may 2003 ) ; the fleet response plan implementation progress message sent by the commander , third fleet ( september 2003 ) ; and the u.s. fleet forces command's fleet training strategy instruction ( may 2002 and an undated draft ) .

we also conducted meetings with several of the commanding officers , executive officers , and department heads of selected carrier strike groups , aircraft carriers , and air wings to obtain information on how the plan had been communicated , how the plan had changed their maintenance and training processes , the impact on their quality of life , the cost implications of the plan , and other factors .

to assess the extent to which the navy has tested the effectiveness of the fleet response plan and shared results to improve its implementation , we obtained briefings ; interviewed navy headquarters and fleet officials ; and reviewed test and evaluation guidance for both the navy and other federal agencies .

to evaluate the three fleet response plan demonstrations identified by the navy , we interviewed officials from the fleet forces command and the navy warfare development command , reviewed existing documentation on the demonstrations , queried the navy lessons learned system for lessons learned from the demonstrations , and compared our findings to accepted best practices for tests and evaluations .

further , we reviewed navy lessons learned system instructions and queried the system to determine recorded lessons learned pertaining to the fleet response plan .

we validated the navy lessons learned system data and determined the data were sufficiently reliable for our analysis .

we conducted our review from january 2005 through august 2005 in accordance with generally accepted government auditing standards at the following locations: the joint staff , washington , d.c. u.s. pacific command , camp h. m. smith , hawaii offices of the chief of naval operations , washington , d.c .

in addition to the contact named above , richard payne , assistant director ; renee brown ; jonathan clark ; nicole collier ; dawn godfrey ; david marroni ; bethann ritter ; roderick rodgers ; john van schaik ; and rebecca shea made significant contributions to this report .

