sexual assault undermines the department of defense's ( dod ) core values , mission , and combat readiness .

in 2008 we reported that historically , dod has not collected uniform data on the incidence of sexual assaults involving members of the armed forces .

we concluded that without consistent , accurate , and reliable department - wide data on incidences of sexual assault in the military , dod was limited in its ability to identify trends in sexual assault and develop targeted prevention and response efforts .

also , in 2008 , congress required the secretary of defense to implement a centralized , case - level database for the collection and maintenance of information regarding sexual assaults involving a member of the armed forces , including information , if available , about the nature of the assault , the victim , the offender , and the outcome of any legal proceedings in connection with the assault .

in 2008 , the house armed services committee noted that it intended for dod to use the database to improve the quality and utility of the analysis and recommendations included in dod's annual reports to congress on sexual assault .

in response to statutory requirements , the under secretary of defense for personnel and readiness assigned responsibility for developing the defense sexual assault incident database ( dsaid ) to dod's sexual assault prevention and response office ( sapro ) , and required that the military services use dsaid to collect sexual assault data .

in 2012 , dsaid became operational and the military services started to use it to capture incident , investigation , and subject disposition data for certain incidents of sexual assault that involved a service - member .

in 2010 , we made six recommendations aimed at ensuring that dod followed key practices for the acquisition and implementation of information technology systems — such as developing an economic justification and system requirements — were followed when developing dsaid .

dod concurred with these recommendations , but did not fully implement them prior to the implementation of dsaid .

our assessment of dod's efforts to address these recommendations is discussed further in the background section of this report .

house report 112-479 , accompanying a bill for the national defense authorization act for fiscal year 2013 , included a provision for us to conduct a review of dsaid once the database had been certified by the secretary of defense .

this report ( 1 ) describes the current status of dod's implementation of dsaid and steps dod has taken to help standardize dsaid's use , ( 2 ) assesses any technical challenges dsaid's users have identified with dsaid and any dod plans to address those challenges , and ( 3 ) assesses the extent to which dod's change management process for modifying dsaid aligns with information technology and project management industry standards .

for our first objective , we reviewed dod policies , processes , and procedures pertaining to dsaid operations , and interviewed dod program officials on actions that have been taken to implement dsaid .

specifically , we reviewed processes to train dsaid users and monitor dsaid data quality .

we limited our review to the processes dod and the services have to monitor data quality , and did not assess the accuracy and completeness of the data contained in dsaid because , at the time of our review , dsaid contained data for fiscal years 2014 and 2015 that had undergone extensive review by dod to ensure they were accurate and complete prior to their inclusion in dod's annual reports to congress .

lastly , we reviewed dod's dsaid quality assurance tool — the primary tool used to identify errors and omissions in dsaid data — and its methodology for identifying significant errors in dsaid data .

for our second objective , we reviewed dod documents , which included all dsaid help desk tickets generated between january 2015 and april 2016 ( which was approximately 600 tickets ) .

we selected this time period because we found that help desk tickets prior to january 2015 were generally related to the user's inexperience with the system , whereas tickets after that date largely related to technical issues with the system and thus were more germane to our review .

we also reviewed all change requests that were submitted between august 2013 and may 2016 by dod and service officials to the dsaid change control board but had not been implemented ( which was approximately 40 change requests ) .

we chose this time period because of our interest in system changes that had been requested and still under consideration , and all change requests submitted prior to august 2013 had already been closed .

we also interviewed dod officials as well as dsaid users and program managers for the army , the navy , the marine corps , and the air force at both service headquarters and at selected installations .

installations were selected to represent a range of user experience with dsaid including ( 1 ) number of cases in dsaid , ( 2 ) number of sexual assault response coordinators ( sarc ) , ( 3 ) number of dsaid data errors identified by sapro's quality assurance tool , and ( 4 ) geographic diversity .

specifically , we selected 9 installations — joint base langley - eustis , virginia ; naval station norfolk , virginia ; goodfellow air force base , texas ; fort hood , texas ; naval base san diego , california ; naval base coronado , california ; marine corps air station miramar , california ; marine corps base quantico , virginia ; and fort george g. meade , maryland .

at these locations , sarcs representing the following 4 additional installations were in attendance as well — marine corps base camp pendleton , california ; marine corps recruit depot san diego , california ; presidio of monterey , california ; and naval base point loma , california .

during site visits , we met with 42 sarcs representing 13 installations in the united states .

views we obtained from these sarcs were not generalizable .

we evaluated the information we obtained from these documents and interviews to identify any technical challenges users faced in operating dsaid , as well as any systemic challenges dod had identified with dsaid .

we interviewed dod officials to determine whether they had plans to address any challenges identified , and how costs for these plans were determined .

to assess the process dod used for estimating costs to modify dsaid , we compared the process dod used to estimate the costs of any planned modifications with best practices for cost estimating and assessment in the gao cost estimating and assessment guide .

we reviewed dod documents and interviewed dod officials to obtain information on its costs incurred since the initial dsaid contract was granted in august 2010 through october 2016 .

for our third objective , we reviewed elements of dod's change management and configuration management processes that were applicable to our scope .

specifically , we focused on elements that are managed by dod , such as processes for , managing change requests and configuration control activities for configuration status accounting , interface control , and release management .

we compared these elements with the project management institute's a guide to the project management body of knowledge ( pmbok® guide ) , fifth edition , 2013 and the institute of electrical and electronics engineers' ( ieee ) standard for configuration management in systems and software engineering to determine how dod's process for managing changes to dsaid aligned with project management and information management industry standards applicable for implementing and monitoring change and configuration management in established information technology systems .

we selected the project management institute's criteria because it provides guidelines that are relevant to project managers and project teams on the requirements and responsibilities of sound change management and configuration management systems for their project .

we have used the pmbok® guide in multiple reports that address a variety of topics for which project management standards are applicable .

we selected ieee's criteria because it establishes minimum process requirements for configuration management in systems and software engineering and because it can be applied to any form , class , or type of software or system .

we have used ieee standards as guidance for information technology best practices in previous reports that address a variety of topics .

we conducted this performance audit from november 2015 to january 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in october 2004 , congress included a provision in the ronald w. reagan national defense authorization act for fiscal year 2005 that required the secretary of defense to develop a comprehensive policy for dod on the prevention of and response to sexual assaults involving members of the armed forces .

in part , the legislation required dod to develop a uniform definition of “sexual assault” for all the armed forces and submit an annual report to congress on reported sexual assault incidents involving members of the armed forces .

the statute also required the secretaries of the military departments to prescribe procedures for confidentially reporting sexual assault incidents .

dod issued its first annual report to congress in may 2005 , and in august 2008 we conducted a review that , among other things , evaluated the extent to which dod had visibility and exercised oversight over reports of sexual assault involving servicemembers .

we found that dod's annual reports to congress may not effectively characterize incidents of sexual assault in the military services because the department had not clearly articulated a consistent methodology for reporting incidents and because the means of presentation for some of the data did not facilitate their comparison .

further , we found that while dod's annual reports to congress included data on the total number of restricted and unrestricted reported incidents of sexual assault , meaningful comparisons of the data could not be made because the offices providing the data to dod measured incidents of sexual assault differently .

as a result , we recommended that dod improve the usefulness of its annual report as an oversight tool by establishing baseline data to permit analysis of data over time .

dod concurred with this recommendation and has taken steps to develop baseline data through the development of dsaid .

also , in 2008 , congress mandated that dod implement a centralized , case - level database for the collection and maintenance of information regarding sexual assault involving a member of the armed forces .

additional mandates have since required the dod - wide collection of additional data , such as case disposition and military protective orders for annual reporting purposes .

we conducted a review of dod's efforts to implement a centralized sexual assault database , and in 2010 we reported that while dod had taken steps to begin acquiring a centralized sexual assault database it did not meet the statutory requirement to establish the database by january 2010 .

moreover , we found that dod's acquisition and implementation of dsaid did not fully incorporate key information technology practices related to the following: economic justification , requirements development and management , risk management , and test management .

dod concurred with all of our findings and recommendations and has taken some actions to address them .

economic justification: we found that dod's cost estimate for dsaid ( $12.6 million ) did not include all costs over the system's life cycle and had not been adjusted to account for program risks .

in 2012 , dod reassessed dsaid's costs to include additional expenses not included in the original estimate ; however , as of november 2016 , dod has not been able to provide dsaid life cycle documentation that would demonstrate that dod had taken steps to ensure that all costs and program risks were accounted for .

requirements development and management: we found that dod had taken initial steps to engage some users in the development of dsaid requirements and in 2009 had developed its initial requirements management plan .

dod's initial requirements management plan established processes and guidelines for requirements management activities .

this plan has been updated three times with the latest update in january 2016 .

dod has some systematic methods in place for tracking user feedback , which is a key step in identifying system requirements .

in addition , dod has elicited feedback on users' experience with dsaid since the database's implementation .

for example , in 2012 , 2013 , and 2015 dod collected non generalizable feedback from dsaid users , including sarcs , sapr program managers , and the military services legal officers .

risk management: we found that during development of the system , dod had begun to identify key risks such as staffing shortages and competing priorities among the military services .

in 2011 , dod developed a risk management plan that identified risks associated with dsaid .

in the risk management plan , dod assigned probability and impact ratings to some of the identified risks .

in addition , dod reported discussing program risks and technical risks to the database at its management meetings and has an issues tracker to track , among other things , risks to the database .

however , as of august 2016 , dod had not demonstrated that it had established and implemented defined processes for mitigating risks identified in its risk management plan .

test management: at the time of our review in 2010 , dod officials told us that they were planning , but had not started to work with a development contractor to establish an effective test management structure , develop test plans , and capture and resolve problems found during testing .

as of october 2016 , dod had developed several test management plans .

as of october 2013 , dod had implemented dsaid across the military services , and the military services were using it to track and collect data on sexual assault cases .

dsaid has since been used to generate data included in dod's annual reports on sexual assault in the military for fiscal years 2014 and 2015 , dod's fiscal year 2014 report to the president of the united states on sexual assault prevention and response , and dod's annual report on sexual harassment and violence at the military service academies for academic program year 2014-15 .

dsaid captures dod - wide data on reports of sexual assault that allow victims to receive treatment and services .

reports can be “restricted” ( i.e. , confidential reporting of alleged sexual assault without initiating an investigation ) or “unrestricted” ( i.e. , nonconfidential reporting that may initiate an investigation ) .

reports of sexual assault included are those in which either the victim of the assault or the subject of the investigation are members of the armed forces , or in some cases , when a victim is a servicemember's spouse or adult family member , or is a dod civilian or contractor .

data are input into dsaid through both manual and automated data entry processes , and include , as applicable , victim and referral support information ; investigative and incident information ; and case outcome data .

dsaid cases are originated by sarcs , based on a report of sexual assault made by a victim to a sarc , a military service sexual assault prevention and response ( sapr ) victim advocate , or military criminal investigative organization ( mcio ) investigator .

generally , victim data are manually input into dsaid by sarcs and investigative data are collected by each military service's mcio and transferred into dsaid through an automated interface process .

for details on dod's process for inputting data elements into dsaid , see figure 1 .

dsaid can be accessed only by authorized users , who are assigned different access rights depending on their roles and responsibilities pertaining to the collection of sexual assault data .

sarcs with dsaid access are required to have a valid dod sexual assault advocate certification , and all dsaid users must meet background check and privacy act / personally identifiable information training requirements as well as complete user - role specific system training .

according to dod officials , as of july 19 , 2016 , dsaid had 1,009 users , including 938 sarcs ; 34 program managers ; 11 sapro analysts ; 25 military service legal officers ; and 1 sapro super user see table 1 for a description of the roles and access rights for each of these user groups .

since 2012 , dod has taken several steps to standardize the use of dsaid throughout the department , including the development of ( 1 ) policies , processes , and procedures for use of the system ; ( 2 ) training for system users ; and ( 3 ) processes for monitoring the completeness of data .

since its implementation , dod has developed multiple policies , processes , and procedures to guide the use of dsaid .

specifically , dod's sexual assault prevention and response instruction requires that information about sexual assaults reported to dod involving persons covered by the instruction be entered into dsaid , and also established rules for dsaid access and procedures for entering data .

similarly , three of the services have added and officials from one of the services told us that they are in the process of adding language to their military service - specific sexual assault guidance requiring the use of dsaid .

to assist users , dod also developed a dsaid user manual that is revised with each new system update .

further , dod's instruction on the investigation of adult sexual assault requires mcios to ensure that data obtained through unrestricted reports of sexual assault , such as the investigative case number , are available for incorporation into dsaid .

according to dod officials , this instruction is currently being reviewed to provide more specific instructions to investigators .

further , dod has instituted formal processes to facilitate changes to dsaid .

in 2011 — prior to dsaid becoming fully operational — dod established its dsaid change control board , which provides a framework to formally manage updates or modifications to the system , and includes representation from each of the military services .

the board has a formal charter , is to use established processes and procedures , and members are to meet monthly to discuss proposed changes to the system .

in order for a change to be approved , a majority of members must agree to the modification unless there is a legislative or dod mandate for modification .

through its change control processes , the ccb approves , prioritizes , and implements change requests .

as of october 2016 , there have been 135 change requests submitted since the system became operational in 2013 — 56 of which have been implemented through the change control process .

dod has developed and conducted several training courses for dsaid users .

initially , dsaid users were required to attend in person training on dsaid prior to being granted access to the system .

however , as of april 2013 , dod converted this required training from in person to a web - based self - guided training that consists of simulations demonstrating dsaid's capabilities .

further , a dod official told us that sapro conducts in - person training for program managers as well as virtual training for military services' legal officers .

in addition , since june 2013 , dod has hosted a regular webinar series to inform and train users on a range of dsaid topics , including policy , new releases , or updates to dsaid .

according to dod officials , as of april 2016 , dod had implemented required annual refresher training for program managers and military service legal officers and , according to dod officials , they are considering conducting required refresher training for sarcs .

dod and each of the military services have developed processes for monitoring the completeness of data input into dsaid .

the primary tool used to monitor dsaid data is dod's dsaid quality assurance tool .

this tool allows users to run point - in - time reports that identify missing data in dsaid ; validate the accuracy of selected data fields ; and perform cross - checks of selected data fields to identify potential conflicts of information .

officials from each of the services' headquarters - level sapr offices said that they distribute quality assurance reports monthly to their installations and request that sarcs correct any issues identified before the next monthly report is generated .

according to dod and sapr officials for two of the military services , these reports allow them to identify trends in data quality issues .

sapr officials for two of the military services also told us that they use quality assurance reports to perform more targeted training to address installation - specific needs .

according to dod officials , data errors identified by the quality assurance tool provides dod and the military services the opportunity to fix or improve the data entry quality or processes .

for example , dod recently used the quality assurance tool to identify some cases without any subject record .

as a result , dod officials have made plans to meet and develop solutions .

additionally , dod officials conduct regular manual and automated data validation checks of dsaid to help ensure that sensitive information is protected as well as to help ensure the general integrity of the data .

sapr officials for three of the military services' sapr offices also told us that they conduct military service - specific reviews of dsaid data on an ongoing basis to help ensure their completeness and accuracy , and to identify any systemic issues .

dsaid users have identified a variety of technical challenges with the system and dod officials told us they have plans to spend approximately $8.5 million to address most of these issues in fiscal years 2017 and 2018 .

some of the key technical challenges users have reported experiencing with the system are related to dsaid's system speed and ease of use ; interfaces with mcio databases ; utility as a case management tool ; and users' ability to query data and generate reports .

dod has plans in place to implement modifications to dsaid that are expected to alleviate these challenges ; however , officials stated that they will not get approval to fund these modifications until after having conducted an analysis of alternatives in line with dod's acquisition policy framework .

this framework , and the gao cost estimating and assessment guide outline key elements that should be included in this analysis , such as relative lifecycle costs and benefits ; the methods and rationale for quantifying the lifecycle costs and benefits ; the effect and value of cost , schedule , and performance tradeoffs ; the sensitivity to changes in assumptions ; and risk factors for any proposed modifications .

dod plans to complete the first draft of this analysis by the end of november 2016 .

based on our review of the nearly 600 dsaid help desk tickets that were generated from january 2015 through april 2016 ; dsaid change requests ; user feedback reports ; interviews with sarcs , program managers , and dod officials ; and our first - hand observations made during visits to selected installations , we identified technical challenges that users reported with dsaid that hinder its use across the military services .

these challenges are related to , dsaid's system speed and ease of use ; interfaces with mcio databases ; dsaid's utility as a case management tool ; and users' ability to query data and generate reports .

system speed: according to our review of dsaid help desk tickets and interviews with service sapr officials and sarcs , dsaid's slow system speed presented a challenge in efficient use of the database .

specifically , users report that slow system speed caused them to spend an inordinate amount of time on data input , and limited their ability to save data and run reports because the system is programmed to time out after a certain period .

in our review of the dsaid developer's monthly system performance reports from december 2014 through january 2016 , we learned that dsaid is rebooted on an almost daily basis to prevent or minimize system slow down .

further , in our review of nearly 600 help desk tickets , we found that dsaid's slow system speed was one of the challenges cited by users .

users reported that , due to issues with system speed , it was cumbersome to perform their required dsaid functions along with other job responsibilities .

for example , sarcs we interviewed representing 7 of the 13 installations said that in their estimation , dsaid's slow system speed regularly resulted in data input taking up to two to three times longer than it should have .

additionally , according to interviews with military service officials and sarcs representing 8 of the 13 installations , computers would frequently time out during the lengthy period of time it took to input and save data in dsaid and , if all required fields to save were not complete , the time - out would result in the need to reenter the data .

in addition , officials from the department of the army told us they were unable to run all - army reports during the last half of 2015 because dsaid would time - out before a full report could be generated .

therefore , according to dod sapro officials , they ran the army's reports for them on a regular basis , and in february 2016 , they resolved this immediate issue by implementing a report scheduler capability in dsaid .

according to dod sapro officials , this capability allowed the army and the other military services to run the full report without timing out .

dod sapro officials acknowledge the latency issue overall and are addressing it with software and server upgrades that are designed to reduce page load time and ease the burden of data entry on sarcs .

dod sapro officials stated that the software upgrades are scheduled for completion in december 2016 and server upgrades in early 2017 , but dod officials emphasized that when dsaid users experience dsaid slow system speeds it can also be an issue with the user's local network , and not with dsaid .

ease of use: dsaid users we interviewed and dod documents that we reviewed cited the inability to easily navigate dsaid as a challenge .

according to a dsaid user feedback report , in 2015 the biggest issue sarcs reported to their military service headquarters officials was that the dsaid user interface and navigation could be improved .

this was supported by sarcs we met with from 7 of the 13 installations who said that it is easy to miss or skip data fields and pages because the logic flow from one page to the next in dsaid is not intuitive , often leaving those sarcs unsure of how much progress they have made in completing a case record .

for example , during our site visit to one installation , we observed instances in which the selection of certain data elements would trigger other data fields that needed to be completed , but the system did not prompt the user that additional data were required .

additionally , army headquarters officials raised concerns with dsaid's ease of use , stating that improvements to the system's flow would increase data accuracy by ensuring that users enter relevant information when a case was initiated and also decrease the frequency that “relevant data missing” is noted in dod's annual report .

however , dod officials stated that they are limited in their ability to make some changes to dsaid's workflow because dsaid is a commercial - off - the - shelf system , which does not allow for such customization .

automated interfaces with military service investigative databases: based on dsaid quality assurance tool reports generated by the military services for the first three quarters of fiscal year 2016 and discussions we had with dsaid users , we found that dsaid data that are populated through interfaces with mcio databases vary in completeness .

according to military service officials and sarcs , this is because mcio data systems are not required to capture the same information that is required for dsaid .

for example , an official from one mcio said that investigators are not required to complete the data field in their database for whether alcohol was used by the subject or victim ; however , this same data field in dsaid is designed to be populated automatically with data from the mcio databases .

further , in september 2014 , dsaid was modified to address technical issues with the interface by allowing sarcs or program managers to manually enter these data in instances where mcio data are regularly omitted .

however , according to dod officials , any additional data received from the mcios during the weekly interface will overwrite what the sarc or program manager has entered as the mcio is the authoritative source for such data .

utility as a case management tool: according to dod documents , dsaid is intended to be a case management tool , and according to dod's fiscal year 2015 annual report , dsaid enhances a sarc's ability to provide comprehensive and standardized victim case management ; however , users of dsaid told us that the system is of limited usefulness for case management .

according to the dsaid user manual , the system allows for case management in that it enables a victim's incident and referral data to seamlessly transition between locations or sarcs .

while dsaid is dod's system of record and the only system in which sarcs are permitted to maintain case data , according to headquarter - level officials from the army , the navy , and the air force , and according to marine corps sarcs , dsaid is of limited usefulness to the personnel working with victims .

specifically , officials stated that dsaid does not provide the requisite functionality , such as the ability to input case notes to manage individual cases .

officials from one service's headquarters - level sapr office said that this functionality would be helpful in ensuring continuity of victim case management .

however , according to dod sapro officials , as of december 2016 , a change request to the change control board to add the functionality has not been submitted .

sarcs we met with from 9 of the 13 installations similarly stated that dsaid is missing basic elements of standard case management systems , such as the ability to document victim outreach or record unique incident details that may inform referrals for care or other support services .

further , sarcs we interviewed from 8 of the 13 installations indicated they would , at a minimum , like the ability to document how and when they met with victims to track the level of service victims were provided .

dod officials told us that the decision to limit narrative information in dsaid was by design to protect the victim .

according to dod officials , there is concern that their phrasing of narrative information could inadvertently harm the victim were dsaid data subpoenaed in the course of legal proceedings .

additionally , dod officials noted that there have not been any change requests made to the change control board for the addition of case management elements to dsaid .

data query and reporting: according to dod officials , dsaid has been used to provide data for congressionally mandated reports , produce ad - hoc queries , facilitate trend analysis , and support program planning analysis and management .

however , officials from three services' headquarters - level sapr offices told us that dsaid's reporting capabilities are limited .

as a result , many users told us they have developed their own tools to track sexual assault outside of dsaid .

for example , the army's and the marine corps' sapr offices have each developed “dashboard” systems that use raw data from dsaid to identify specific trends that are useful to their leadership and accessible by sarcs for their military service .

further , sarcs we met with from 11 of the 13 installations told us that they keep informal “databases” or hard copy documents on their cases in order to brief their leadership , because they cannot run ad - hoc queries and reports of cases in dsaid for which they are responsible .

according to the sarcs , these trackers duplicate key data points input into dsaid ( eg , victim demographics , type of assault , involvement of alcohol , etc .

 ) , but do not include any personally identifiable information .

according to dod officials , they have planned to spend $8.5 million in funding for fiscal years 2017 and 2018 for dsaid modifications , which officials stated will allow them to implement specific modifications that should alleviate most of the technical challenges identified by users .

see table 2 for a complete list of dod's initiatives planned for fiscal years 2017 and 2018 and the purpose of these initiatives .

dod plans to spend $3.59 million in fiscal year 2017 and $4.916 in fiscal year 2018 for specific modifications to dsaid to support these initiatives , and officials are in the process of beginning to conduct a formal analysis to identify the costs and benefits of alternative options for implementing each modification .

 ( see app .

i for a list of modifications to dsaid that dod plans to implement to support the initiatives in fiscal year 2017. ) .

for example , a dod official stated that dod plans to implement an encrypted file storage mechanism for dsaid , but they have not yet determined how they plan to do this .

rather , this dod official stated that the analysis of alternatives will establish options for this mechanism and weigh the costs and benefits .

this dod official also stated that the defense human resources activity — which is responsible for funding dsaid — will not approve dod to spend resources on the individual modifications until an analysis of alternatives addressing each modification is conducted .

according to this dod official , the initial draft of this analysis will be completed by the end of november 2016 , and all planned modifications can be implemented within the planned available budgetary resources .

dod officials based these budgets on rough - order - of - magnitude cost estimates that were derived from costs they have experienced in recent years .

for example , costs for adding a module in dsaid to document reports involving retaliation were based on dod's costs for building dsaid's legal officer module , which was purchased in 2013.the gao cost estimating and assessment guide states that rough - order - of - magnitude estimates are useful to support “what - if” analyses and can be developed for a particular phase or portion of an estimate , but unlike an analysis of alternatives , they do not rise to the level of analysis recommended by best practices to support an investment decision and are not considered budget - quality estimates .

in addition to dod acquisition requirements , an analysis of alternatives is supported by the gao cost estimating and assessment guide .

these documents identify key elements that should be included in this analysis .

for example , an organization should identify relative lifecycle costs and benefits ; methods and the rationale for quantifying the lifecycle costs and benefits ; the effect and value of cost , schedule , and performance tradeoffs ; sensitivity to changes in assumptions ; and risk factors .

further , according to gao guidance , a comparative analysis of alternatives is essential for validating decisions to sustain or enhance a program .

because these elements are part of dod's acquisition requirements , if dod's analysis of alternatives complies with these requirements , it should incorporate these key elements .

conducting a comparative analysis of alternatives , including identifying and quantifying lifecycle costs and benefits and weighing the cost , schedule , and performance tradeoffs , is key to ensuring that dod appropriately manages its modifications to dsaid .

in 2010 , we found that dod had failed to demonstrate adherence to these key elements in the initial development and implementation of dsaid .

by the end of fiscal year 2018 , dod spending on dsaid will exceed initial cost estimates by over $13 million .

in 2010 , we reported that dod estimated development and implementation of dsaid to cost $12.6 million , but dod's estimate did not include costs for program management or sustainment and for lifecycle costs such as operations and maintenance .

in december 2012 , dod documentation shows that dod had adjusted its estimate to $17.9 million to reflect research and development costs for fiscal years 2011 and 2012 and operations and maintenance costs for fiscal years 2013 through 2018 .

dod projected it will have spent a total of approximately $31.5 million as of november 2016 on implementing and maintaining dsaid through fiscal year 2018 .

this is approximately $13 million more than the revised 2012 estimate .

if dod conducts an accurate and complete analysis of alternatives , it should result in more precise cost estimates for planned enhancements .

dod's plan to conduct an analysis of alternatives that adheres to the department's acquisition framework and adequately considers key elements identified in the gao cost estimating and assessment guide , as dod officials have stated that their analysis will do , should position dod to more accurately assess whether planned modifications to dsaid can be implemented within budget and with the desired outcome .

dod manages modifications to dsaid through its change management process , which we found , based on our review of dod documentation , substantially align with the elements described in the project management and information technology industry standards that we reviewed .

“change management” is the process of controlling changes requested to work products to help ensure that project baselines are maintained .

according to the pmbok® guide , the activity of change control allows for documented changes within the project to be considered in an integrated fashion while reducing project risk , which often arises from changes made without consideration to the overall project objectives or plans .

configuration management activities can be included as part of an organization's change control process .

while change control is focused on managing project change such as identifying , documenting , and approving or rejecting changes to the project documents , deliverables , or baselines , configuration management is typically focused on managing changes to a configuration item or system .

industry standards include descriptions of the following elements of change and configuration management that are applicable to dod's efforts to manage dsaid: ( 1 ) managing change requests ; ( 2 ) configuration status accounting , tracking and communicating to stakeholders the changes made to the database ; ( 3 ) interface control , managing the database interfaces ; and ( 4 ) release management , managing the publication and communication of updates to users .

 ( 1 ) managing change requests: according to the pmbok® guide , changes may be requested by any stakeholder involved with the project .

although changes may be initiated verbally , they should be recorded in written form and entered into the change management and / or configuration management systems .

every documented change request — which may include corrective actions , preventive actions , and defect repairs — needs to be either approved or rejected by a responsible individual who is identified in the project management plan or by organizational procedures according to the pmbok® guide .

when required , the change control process includes a change control board , which is a formally chartered group responsible for meeting and reviewing the change requests and approving , rejecting , or otherwise disposing of those changes and for recording and communicating such decisions .

according to the pmbok® guide , the roles and responsibilities of this board are to be clearly defined and agreed upon by appropriate stakeholders and documented in the change management plan .

further , the disposition of all change requests , approved or not , are to be updated in the change log that is used to document changes that occur during a project .

dod has established a change request process in the dsaid change control management plan and dod has documented and formally chartered its change control board .

the board's roles and responsibilities are defined in the dsaid change control board charter and board members include representation from sapro and each military service's sapr office .

change requests can be submitted only by board members or their designees .

the board meets monthly to evaluate and vote on change requests .

the dsaid change control board charter outlines the requirement that change requests will be captured through a change request form , which will then be uploaded to the board's website and made available to the dsaid community .

both the dsaid change control board charter and the dsaid change control management plan outline dod's procedures for evaluating these change requests .

during its evaluation of each proposed change request , dod conducts an impact analysis that includes an assessment of the change's potential impact on requirements , development , training , communications , policy , and testing .

this impact analysis also assesses the expected level of effort to implement the request .

documentation from the change control board meetings shows that dod considers approximate costs and time to implement in change request discussions .

dod also documents and tracks testing and implementation of approved changes in a requirements log .

the log includes the approval status , prioritization , and tracking notes for each change request as each moves through the approval process .

once a change request is implemented , dod updates the requirements log to note which baseline requirement was affected and which system release was included the change .

in the requirements log , dod also documents baseline requirement changes associated with the change requests that have been disapproved and closed .

 ( 2 ) configuration status accounting: according to the ieee standard on configuration management , the purpose of configuration status accounting is to track the status of configuration items .

in this process , organizations track baseline requirements and total changes requested and implemented .

this information should provide objective insights into a system's performance overtime and the status of the system as changes are implemented .

dod has documented and established baseline requirements for dsaid and , through the change request tracker , dod tracks total changes requested , implemented , disapproved , deferred , and pending .

as previously discussed , dod conducts an impact analysis of each proposed change request as part of the evaluation process .

dod tracks dsaid's requirements and change requests until release and monitors and documents identified defects at each stage until they are resolved , which allows dod to monitor the system's status as changes are implemented .

 ( 3 ) interface control: according to the ieee standard on configuration management , organizations use interface controls to manage the interfacing effects that hardware , system software , and other projects and deliverables have on the project .

interface control activities include identifying the product's key interfaces and controlling the interface specifications .

dod is currently managing interfaces between dsaid and the mcio databases to collect sexual assault case information , and dod plans to incorporate additional interfaces with other dod systems to collect more case information .

dod documentation shows that the department has identified dsaid's key interfaces and specifications .

specifically , dod sapro has established a memorandum of understanding with each service investigative agency that describe roles and responsibilities and data mapping parameters , which includes a technical description of the fields and types of data that will be interfaced between dsaid and each service investigative agency's system .

through these mechanisms , dod manages the parameters of these interfaces that provide key information to dsaid .

while dod has met industry standards for identifying key interfaces and controlling interface specifications , as discussed earlier in this report , some dod users reported some technical challenges with data from the mcio database interfaces overwriting manually input dsaid data .

according to dod documentation , dod is taking steps to mitigate them in enhancement efforts , which include improving how investigative data transferred into dsaid , and adding additional database interfaces .

 ( 4 ) release management: according to the ieee standard on configuration management , release management allows an organization to ensure that the proper deliverables such as changes and fixes to a system are delivered to the designated receiving party , in the designated form , and to the designated location .

release management activities include delivering approved releases and defining the following: a release policy , release planning , release contents , release format and distribution , and release tracking .

in line with defining release policy , dod's change control board charter defines board members as the authority for establishing dsaid release schedules and prioritize and assign changes to a release .

with respect to release planning , we found that dod has defined the types of releases it delivers and the activities conducted during dsaid's formal release process .

dod has also defined the content , format , and distribution materials to be included in each release .

communication of the release follows a defined process starting with limited distribution to select users and then distribution to the full user community .

dod uses its master project schedule for dsaid to track and monitor release activities .

we are not making recommendations in this report .

we provided a draft of this report to dod for review and comment .

dod provided technical comments , which we incorporated as appropriate .

we are sending copies of this report to the appropriate congressional committees and to the secretary of defense ; the under secretary of defense for personnel and readiness ; the secretaries of the army , the navy , and the air force ; and the commandant of the marine corps .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-3604 or farrellb@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix ii .

table 3 describes change requests to the defense sexual assault incident database ( dsaid ) that the department of defense ( dod ) has prioritized for implementation in fiscal year 2017 .

these change requests were approved through dod's change control process and determined to be priority modifications by the dsaid change control board .

in addition to the staff named above , key contributors to this report include kim mayo ( assistant director ) ; michael holland ; jim houtz ; mae jones ; anh le ; amie lesser ; oscar mardis ; shahrzad nikoo ; tida reveley ; monica savoy ; jasmine senior ; maria staunton ; and randall b. williamson .

sexual assault: actions needed to improve dod's prevention strategy and to help ensure it is effectively implemented .

gao - 16-61 .

washington , d.c.: november 4 , 2015 .

military personnel: actions needed to address sexual assaults of male servicemembers .

gao - 15-284 .

washington , d.c.: march 19 , 2015 .

military personnel: dod needs to take further actions to prevent sexual assault during initial military training .

gao - 14-806 .

washington , d.c.: september 9 , 2014 .

military personnel: dod has taken steps to meet the health needs of deployed servicewomen , but actions are needed to enhance care for sexual assault victims .

gao - 13-182 .

washington , d.c.: january 29 , 2013 .

military personnel: prior gao work on dod's actions to prevent and respond to sexual assault in the military .

gao - 12-571r .

washington , d.c.: march 30 , 2012 .

preventing sexual harassment: dod needs greater leadership commitment and an oversight framework .

gao - 11-809 .

washington , d.c.: september 21 , 2011 .

military justice: oversight and better collaboration needed for sexual assault investigations and adjudications .

gao - 11-579 .

washington , d.c.: june 22 , 2011 .

military personnel: dod's and the coast guard's sexual assault prevention and response programs need to be further strengthened .

gao - 10-405t .

washington , d.c.: february 24 , 2010 .

military personnel: additional actions are needed to strengthen dod's and the coast guard's sexual assault prevention and response programs .

gao - 10-215 .

washington , d.c.: february 3 , 2010 .

military personnel: actions needed to strengthen implementation and oversight of dod's and the coast guard's sexual assault prevention and response programs .

gao - 08-1146t .

washington , d.c.: september 10 , 2008 .

military personnel: dod's and the coast guard's sexual assault prevention and response programs face implementation and oversight challenges .

gao - 08-924 .

washington , d.c.: august 29 , 2008 .

military personnel: preliminary observations on dod's and the coast guard's sexual assault prevention and response programs .

gao - 08-1013t .

washington , d.c.: july 31 , 2008 .

military personnel: the dod and coast guard academies have taken steps to address incidents of sexual harassment and assault , but greater federal oversight is needed .

gao - 08-296 .

washington , d.c.: january 17 , 2008 .

