the complex and crosscutting nature of many challenges facing the federal government has highlighted the need for agencies to engage and collaborate with the public and different sectors of society to address them .

the advent of online technologies has enhanced the ability of federal agencies to make these connections and provide opportunities to address challenges through open innovation .

open innovation involves using various tools and approaches to directly engage with people and organizations in the private , nonprofit , and academic sectors ; and harness their ideas , expertise , and resources to address an issue and achieve specific goals .

the term “open innovation” was first widely used around 2003 to describe efforts by companies to solicit external ideas , product designs , and solutions .

since then , it has been used extensively in academia and the private sector .

in addition , the executive branch has used this term since at least 2011 to characterize efforts to access the skills and contributions of citizens and other external stakeholders .

in recent years , the executive branch and congress have taken actions aimed at encouraging and enhancing federal agency use of open innovation .

for example , the presidential memorandum on transparency and open government and the office of management and budget's ( omb ) open government directive directed agencies to describe how they would use new feedback mechanisms , technology platforms , and other innovative methods to obtain ideas from , and increase collaboration with , those outside the federal government .

in december 2010 , congress passed the america competes reauthorization act of 2010 .

this legislation , signed into law by the president in january 2011 , provides , among other things , government - wide authority for executive branch agencies to use public prize competitions to advance their missions .

additionally , bills have been introduced in the 114th congress related to other types of open innovation strategies .

for example , the crowdsourcing and citizen science act of 2015 , the american innovation and competitiveness act , and the aeronautics innovation act contain provisions on crowdsourcing or citizen science .

as part of the federal performance management framework originally put into place by the government performance and results act of 1993 ( gpra ) , and updated and expanded by the gpra modernization act of 2010 ( gprama ) , agencies are to identify the various strategies and resources they will use to achieve their goals .

gprama also includes a provision for us to periodically review how implementation of its requirements is affecting agency performance .

this report is part of our response to that mandate .

our specific objective for this report is to identify , and illustrate through selected agency examples , practices that promote the effective implementation of open innovation strategies and the effects , if any , the use of those strategies had on agency performance and opportunities for citizen engagement .

to identify practices that can facilitate the effective implementation of open innovation strategies , we analyzed and synthesized information gathered from: federal resources , including guidance with suggested practices for implementing various open innovation strategies released by omb , the office of science and technology policy ( ostp ) , and the general services administration ( gsa ) ; a review we conducted to identify literature with suggested practices for implementing open innovation strategies , which covered public and business administration journals , and publications from research organizations ; interviews we conducted with 14 open innovation experts with experience implementing open innovation initiatives , or with academic or consultative expertise in this area ; and interviews we conducted with officials involved in implementing open innovation initiatives at six selected federal agencies , as well as staff from omb , ostp , and gsa .

to illustrate aspects of the practices we developed , and identify how open innovation strategies can affect agency performance and citizen engagement , we selected 15 initiatives that involved the use of open innovation strategies at 6 agencies: the departments of energy ( doe ) , health and human services ( hhs ) , housing and urban development ( hud ) , and transportation ( dot ) ; the environmental protection agency ( epa ) ; and the national aeronautics and space administration ( nasa ) .

we selected these agencies based on various criteria , including the number and variety of open innovation strategies outlined in their individual agency open government plans .

these selections also aligned with suggestions from knowledgeable experts and staff at omb , ostp , and gsa .

we identified and selected initiatives that offered the greatest potential to illustrate a range of practices based on our review of the open government plans for the selected agencies , and input from knowledgeable agency staff .

these initiatives are listed below in table 1 .

to develop the illustrative examples in this report , we obtained and reviewed agency documentation related to the initiatives , and interviewed relevant agency officials .

the scope of this review was to identify practices for effectively implementing open innovation initiatives , and to describe actions agencies took in carrying out open innovation initiatives that reflect aspects of those practices .

while we present information on the implementation of agency open innovation initiatives , we did not assess the success of the underlying agency programs and activities that these initiatives were designed to support .

see appendix i for additional details about our scope and methodology .

we conducted this performance audit from july 2015 to october 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the federal performance management framework put into place by gpra and gprama requires agencies to develop long - term strategic plans that identify their missions , along with long - term goals and objectives ( often referred to as strategic goals and objectives ) aimed at achieving their missions .

agencies are to develop performance plans with near - term goals annually , to show progress towards their long - term goals and objectives .

these near - term goals are called performance goals .

in both of these plans , agencies are directed to identify the various strategies and resources they will use to achieve their goals .

in line with these requirements , the open government directive instructs federal agencies to develop open government plans detailing the strategies and initiatives they would use to improve public engagement and collaboration on the agency's core mission activities .

it directs agencies to describe how they would use innovative feedback mechanisms , technology platforms , and such methods as prize competitions to increase opportunities for public participation and collaboration with those outside the agency and in other levels of government .

these outside parties include those in the private , nonprofit , and academic sectors .

agencies were directed to release their initial plans in 2010 , and to update these plans every 2 years .

in july 2016 , omb released guidance for the development of 2016 open government plans , which were to be published in september 2016 .

the new guidance instructs agencies to describe their activities to increase the use of open innovation initiatives .

in early 2010 , omb also created an interagency open government working group to provide a forum for open government professionals to share best practices across agencies .

representatives from 41 federal agencies made up the initial working group .

omb , ostp , and gsa have taken additional steps to support and encourage agency use of open innovation strategies .

they have developed specific policy and guidance documents , built websites that facilitate their use , and supported knowledge sharing communities of practice .

for example: in july 2010 , gsa launched challenge.gov .

this site is designed to help agencies find participants for prize competitions and challenges by providing a centralized list of all competitions sponsored by federal agencies .

after the america competes reauthorization act authorized federal agencies to conduct prize competitions , omb issued guidance in august 2011 to help agencies use this authority .

gsa also hosts the challenges and prizes community of practice .

this group meets quarterly to discuss policies and procedures , and share ideas and practices .

according to information from challenge.gov , agencies have conducted more than 700 distinct prize competitions or challenges since the site was first launched in 2010 .

in may 2013 , the president released an executive order requiring omb to issue an open data policy .

this policy , also released by omb in may 2013 , directs agencies to collect or create information using open formats that are non - proprietary and publicly available , and to build or modernize information systems in a way that maximizes the accessibility of information .

the president's executive order also called for the creation of an open data cross - agency priority goal , which is designed , among other things , to provide support to help agencies release high priority data sets and facilitate the use of open data by those outside the agency .

in may 2014 , the administration also released an open data action plan .

this plan called on agencies to use online and in - person mechanisms to engage with open data users and stakeholders to prioritize open data sets for release , improve data based on feedback , and encourage its use .

omb and ostp have created a website called project open data to provide good practices and examples to assist agencies .

omb , ostp , and gsa also manage the open data working group , which meets every 2 weeks to share best practices and tools , and allow agencies to learn from one another .

in september 2015 , ostp released a memorandum that outlined principles agencies should use when designing a crowdsourcing or citizen science initiative .

the memorandum also outlined actions the agencies should take to build their respective agency capacity to use that type of strategy .

at the same time , ostp released the crowdsourcing and citizen science toolkit with practices , lessons learned , and case studies to inform agency efforts to design , implement , and sustain these initiatives .

gsa has also launched citizenscience.gov , which is a centralized repository of information on agency citizen science initiatives .

as of september 2016 , the crowdsourcing and citizen science catalog on citizenscience.gov lists 303 active crowdsourcing and citizen science projects across 25 agencies .

lastly , practitioners from across the federal government have come together to form the federal community of practice for crowdsourcing and citizen science , which meets monthly to share lessons learned and practices for implementing and evaluating crowdsourcing and citizen science initiatives .

in some agencies , this government - wide infrastructure has been supplemented by agency - level policies and organizations with dedicated staff and resources .

for instance , nasa has created the center of excellence for collaborative innovation ( coeci ) , which assists teams from nasa and other agencies with implementing open innovation strategies , particularly prize competitions and challenges .

based on our review of agency open government plans and other sources , we found that agencies have frequently used the five open innovation strategies shown below to collaborate with citizens and external parties , and encourage their participation in agency efforts .

figure 1 identifies and describes these strategies , and we provide further information about them in appendix ii .

agencies can use these strategies singularly , or in combination as part of a larger open innovation initiative .

for example , an open innovation initiative could primarily involve a prize competition or challenge that also has an idea generation component focused on the identification of promising new ideas or issues to be addressed .

it could also have a component where participants are asked to use open data to develop new products or applications based on those ideas .

we identified seven practices that federal agencies can use to help effectively design , implement , and assess open innovation initiatives .

these practices are detailed below .

we drew from our analysis of federal resources and relevant literature with suggested practices for the implementation of open innovation strategies .

we also interviewed experts and agency officials with expertise in implementing such initiatives .

while we present these practices in a certain order , this is not meant to imply they should be implemented in this sequence .

relevant literature , agency officials , and an expert we consulted emphasized that , in practice , agencies often take some of these actions concurrently or will use an iterative approach .

through our analysis of relevant literature and interviews with experts , we identified several factors agency officials should consider when selecting the most appropriate open innovation strategy or strategies to use for an initiative .

first , agency officials considering the use of an open innovation strategy should clearly articulate the purpose ( s ) they hope to achieve by engaging the public .

through our literature review and interviews we found that agencies generally used open innovation strategies to achieve one or more of five high - level purposes .

these purposes , which are not mutually exclusive , are summarized below in table 2. implement a strategy , including leadership support , legal authority , the availability of resources , and capacity .

description agencies can collect the perspectives of a broad group of citizens and external stakeholders to identify problems or challenges , gauge perceptions of a program or service , gather reactions to proposed actions , or better understand their priorities , values and preferences .

agencies can then use this information to inform decisions about policies , plans , and the allocation of resources .

agencies can efficiently engage a broad range of citizens and external stakeholders in developing new ideas , solutions to specific problems , or new products ranging from software applications to physical devices .

agencies can also have them evaluate the quality and feasibility of the ideas and solutions proposed by others , or test the products that were developed .

if it uses a successive or iterative process , the agency can help build the capacity of participants in these efforts to further develop or refine their ideas or products .

agencies can also use open innovation initiatives to stimulate the creation of new markets and companies that will then commercialize products and technologies developed for an initiative .

agencies can leverage the time , resources , and expertise of citizens and external stakeholders to supplement their own internal resources , data , and expertise .

these contributions enhance the agency's capacity , and therefore , its ability to achieve goals that would be more difficult to reach without this additional capacity or expertise .

open innovation initiatives may also allow agencies to achieve goals more efficiently and effectively than more traditional federal program types , such as grants or contracts .

agencies can establish or enhance collaboration among citizens and external stakeholders or organizations interested in an issue .

this can be done , in part , by developing relationships among involved individuals and organizations .

these relationships can then be leveraged to achieve common or complementary goals .

agencies can also enhance previously - established communities by using open innovation initiatives to strengthen existing relationships .

this also can be done to bring new individuals and organizations into the community .

an agency can provide participants or the broader public with balanced and objective information and data to help them understand an issue or problem .

information can also be provided to help them understand opportunities and various alternatives for addressing an issue or problem .

to determine how frequently agencies identified these as purposes for each type of open innovation strategy , we identified both the primary strategy and the purposes agencies articulated for each initiative in their most recent open government plans .

the results of this analysis are summarized below in figure 2 .

through this analysis , we found that agencies identified certain purposes more frequently for different types of strategies .

for example , we found that , of the 26 prize competitions or challenges identified in agency plans , agencies indicated that developing new ideas , products , or solutions was a specific purpose for 25 ( or 96 percent ) of the initiatives .

similarly , of the 74 open dialogue initiatives we identified in agency plans , agencies indicated that collecting information and perspectives was a specific purpose for 57 ( 77 percent ) of them .

in addition to the purpose ( s ) agency officials hope to achieve through open innovation , through our literature review and interviews we identified additional factors agency officials should consider when selecting the strategy or strategies that will be used: leadership support: the support and approval of agency leaders for the potential use of an open innovation strategy is particularly important .

such leadership support can lend credibility and visibility , help generate support from others throughout the agency , and increase the likelihood an initiative will receive necessary approvals and resources .

legal authorities: agency officials should work with their respective agencies' legal staff to ensure that they have appropriate legal authority to use a strategy , and are aware of any relevant requirements that need to be met as they work to implement a strategy .

for instance , the legal requirements that an agency must meet when conducting a prize competition or challenge can be more detailed and specific than those that apply to certain other open innovation strategies .

those considering a strategy should also be aware of any government - wide and agency - specific policies or guidance that can help guide planning and implementation of these tools .

resource needs and availability: agency officials should also work with other relevant staff to understand what financial and information technology resources are necessary and available to support the use of various open innovation strategies .

for example , agency officials could work with staff to understand whether they can design or leverage an existing website or other tool to engage and manage a community of widely - dispersed participants .

assessing resource needs and availability helps determine the costs and feasibility of implementing the selected strategy .

capacity to implement the strategy: agency officials should consider whether their staff has sufficient time and expertise to design and implement a strategy .

agency officials could work with staff with prior experience developing and implementing open innovation initiatives .

such staff can help ensure successful practices from previous initiatives are replicated and previously - identified problems avoided .

similarly , officials can also work with agency contracting and acquisition staff to contract for additional capacity and expertise to support implementation .

below we provide illustrative examples of how nasa , epa , and dot selected and used various open innovation strategies to achieve specific purposes .

as part of nasa's strategic goal to expand the frontiers of knowledge , capability , and opportunity in space , the agency is examining near - earth asteroids to determine whether any of these objects threaten earth .

in june 2013 , nasa also announced its asteroid grand challenge , which is a large - scale effort to use partnerships and collaboration to find all asteroid threats to human populations .

nasa officials also reported that the algorithm that astronomers have been using to analyze images of space to detect asteroids can produce false detections , and the process to screen out those false detections is labor intensive and inefficient .

according to nasa officials , beginning in january 2014 , staff working on the asteroid grand challenge began working with staff from nasa's coeci , who have expertise in executing prize competitions and challenges and are responsible for managing competitions launched through the nasa tournament lab .

to ensure they could access necessary technical expertise to develop an improved algorithm to identify asteroids in images captured by ground - based telescopes , officials decided to leverage an existing nasa contract with harvard university to carry out a series of competitions .

these competitions were conducted by harvard university's subcontractor topcoder , a private - sector company that administers contests in computer programming and has an existing community of expert developers and data scientists .

in march 2014 , nasa officially announced the asteroid data hunter challenge and citizen science effort to develop the more accurate algorithm .

the effort was also designed to develop a software application that would allow citizen scientists to genuinely contribute to asteroid detection , supplementing the efforts of professional astronomers .

according to an april 2015 report from ostp on the implementation of federal prize competitions and challenges , through the challenge's 10 months , more than 1,200 participants submitted 700 potential solutions .

this resulted in the development of a new algorithm and software package .

figure 3 provides a screenshot from the website where interested members of the public can download the application .

according to nasa , the improved algorithm has led to a faster , more accurate asteroid detection process .

nasa and planetary resources , inc. , a private - sector company also involved in the initiative , analyzed the results and found that the new algorithm resulted in a 15 percent increase in the positive identification of new asteroids in the main belt of asteroids that orbit between mars and jupiter .

furthermore , nasa also stated that the software application could increase the number of new asteroids discovered by citizen astronomers .

according to nasa officials , the application has been downloaded over 8,000 times as of march 2016 .

nasa obtained these results with a total project cost of less than $200,000 , which ostp reported and nasa officials confirmed is less than the fully loaded cost of employing an engineer for the same time period .

excessive levels of nutrients such as nitrogen and phosphorus can harm aquatic environments , according to epa .

governments , academic research organizations , environmental organizations , utilities , and the agriculture community are collecting data on nutrient levels .

however , epa and its partners say the general public cannot easily access or understand these data .

to raise public awareness and identify new and innovative ways to communicate data on nutrient pollution to the public , epa collaborated with the united states geological survey ( usgs ) and blue legacy international to conduct the visualizing nutrients challenge .

usgs is a scientific organization within the department of the interior that collects and distributes scientific data and information on the health of ecosystems and the environment .

blue legacy international is a non - profit organization focused on the protection of water resources .

the goal of the challenge , which ran from april to june 2015 , was to invite participants to design innovative and compelling web applications , images , and videos to help individuals and communities understand the causes and consequences of , and solutions to , nutrient pollution .

according to epa officials , as the idea came together for an effort to identify innovative ways to translate and communicate information about nutrient pollution , epa staff reached out to colleagues at usgs to gauge their interest in partnering .

epa officials said they did this because of the role usgs plays in collecting data on the nation's surface and ground waters , and their interest in seeing those data communicated and used more broadly .

according to epa officials , this relationship with usgs was important because of the additional expertise and capacity usgs staff provided , as well as their support in publicizing the challenge .

epa officials explained that because of blue legacy international's mission and interest in using digital media to build public awareness about the importance of local watersheds and more sustainable stewardship of water resources , it approached epa about becoming involved .

epa officials also stated that blue legacy international provided $10,000 to fund its own independently - selected awards to help incentivize participation .

according to epa officials , they determined that conducting a challenge with an open call for submissions would be the preferred approach to achieve the goals established for the effort .

before the challenge could move forward it had to be reviewed and approved by all members of epa's challenge review team .

epa officials explained that the review team consists of representatives from key offices throughout epa .

this includes individuals from the office of general counsel , who determine whether there is sufficient statutory authority to carry out a challenge , and the office of the chief financial officer , who ensure there are sufficient financial resources available to support the challenge .

to secure additional capacity to implement the challenge , epa contracted with innocentive , a private - sector contractor that manages prize competitions and challenges .

according to epa officials , they also used the contract to access innocentive's large existing network of potential challenge participants with expertise in relevant disciplines , including design , physical science , and data analysis .

innocentive played a central role by recruiting potential participants , assisting with design and development , and prioritizing issues that needed to be addressed each week by epa , usgs , and blue legacy international .

according to epa officials , a competition was selected because it offered a superior cost - benefit ratio to more traditional federal contracting .

according to an august 2016 report from ostp , using this approach , epa and usgs were able to collect 20 submissions .

epa officials said these submissions provided a wide range of examples for how to present and communicate data on nutrient pollution .

they also said they achieved this in approximately 3 months and at the cost of staff time — with responsibilities shared among epa and usgs , and blue legacy international — and $16,500 that epa paid to innocentive to administer the competition .

by contrast , epa officials estimated that using traditional procurement processes to produce a single visualization would have cost significantly more and taken longer .

in addition , they said a more traditional procurement may not have resulted in a product of the quality that was received through the competition .

the moving ahead for progress in the 21st century act ( map - 21 ) , signed into law in july 2012 , required dot to develop a national freight strategic plan in consultation with stakeholders .

as we have reported , involving stakeholders in strategic planning can help ensure that efforts and resources are targeted at the highest priorities , and that stakeholders appreciate how competing demands and resource limitations require careful balancing .

to inform the development of the freight strategic plan , dot officials , led by staff from the office of the secretary , the office of public engagement , and the federal highway administration ( fhwa ) office of freight management and operations , decided to engage a broad range of stakeholders through a series of both online and in - person open dialogues .

for example , beginning in 2012 , dot used an online platform called ideascale to launch an online dialogue and roundtables to leverage web - based communications technology to engage with stakeholders .

according to dot officials , the online dialogue session and online roundtables allowed stakeholders to comment and provide suggestions on various topics , including developing guidance for state freight plans and potential measures of conditions and performance for a national freight system .

fhwa has also continued to conduct monthly webinars to provide information on freight issues , technical assistance , and training for those in the freight and transportation planning communities .

since 2012 these webinars have been used to cover a range of topics , including freight - related provisions in map - 21 and other legislation , state freight planning , and improving freight system performance in metropolitan areas .

in addition to its web - based outreach , dot also used in - person meetings to engage with and collect recommendations from a range of stakeholders .

for example , in may 2013 the then - secretary of transportation chartered the national freight advisory committee ( nfac ) , which was comprised of 47 stakeholders from different organizations and groups with an interest in freight policy .

it included representatives from state and local governments , port and transportation authorities , transportation - related companies and associations , unions , and public interest groups .

dot officials emphasized that nfac was created to advise the department on matters related to freight transportation .

they added that it was critical to ensure a wide range of perspectives would be represented .

nfac met in person 7 times between june 2013 and november 2015 , and ultimately provided dot with nearly 100 recommendations .

dot leaders also conducted nearly 60 roundtables and public meetings across the country to collect the perspective of stakeholders at the regional and local levels on various freight policy issues .

according to dot officials , the insights collected through this outreach had a large influence on the development of the draft national freight strategic plan , which was released in october 2015 .

dot officials told us that they received substantial public input on issues such as freight transportation safety , the adoption of new technologies , workforce development , opportunities to strengthen connections between different modes of transportation , and the need for reliable funding for freight infrastructure .

each of these issues was then addressed in specific sections of the draft freight strategic plan .

dot officials stated that these insights also informed recent action by congress .

specifically , in december 2015 , congress enacted and the president signed into law the fixing america's surface transportation ( fast ) act which created a new grant program for nationally significant freight and highway projects and authorized appropriations for this new program as well as existing grant programs through fiscal year 2020 , among other things .

according to relevant literature and our interviews with experts and agency officials , once the agency has identified the high - level purposes it wants to achieve through an open innovation initiative and selected the strategy or strategies it will use , it should clearly define specific and measurable goals for the initiative .

specific goals can help guide the design and implementation of an initiative .

they also can help those involved maintain a sense of direction by providing a clear understanding of what they are working to achieve .

define specific and measurable goals for the initiative .

identify performance measures to assess progress .

align the goals of the initiative w ith the agency's broader mission and goals .

relevant literature , experts , and agency officials we consulted highlighted that the agency should also identify the performance measures it will use to assess progress towards the goals and overall results .

for open innovation initiatives , measures can be used to assess the achievement of specific outcomes , participation and engagement , and resources invested in the initiative .

outcome measures could include the successful achievement of a goal , improvements in the quality of a policy or process , or the improved delivery of a service .

participation and engagement measures could include the number or diversity of participants engaged in the initiative ; the number of ideas submitted ; the amount of time it takes to respond to participant questions , comments , or feedback ; and the satisfaction of participants with their experience .

measures of resources invested ( input measures ) could include the money , staff resources , and time dedicated to implementing the initiative .

this information can also help an agency determine whether it would be appropriate to expand — or “scale” — an approach if it is found to be successful .

lastly , the literature and experts also emphasized that the agency should seek to align the specific goals of an open innovation initiative with the agency's broader mission and goals .

aligning initiative - specific goals with agency priorities can help ensure the relevance and value of an initiative , by showing how its successful implementation could advance progress on the agency's mission and goals .

this alignment also reinforces the connection between the agency's mission and goals and the day - to - day activities of those carrying out an initiative .

the following two examples illustrate how doe and epa defined goals and performance measures for selected open innovation initiatives .

according to an official in doe's wind and water power technologies office ( wwpto ) , its wave energy prize ( wep ) competition is designed to dramatically improve devices that produce electricity by capturing energy from ocean waves .

wep began in april 2015 and is scheduled to conclude in november 2016 .

wwpto specified in its contest documentation that the effort could stimulate private sector innovation and contribute to energy security and international competitiveness in the wave energy conversion sector .

this was aligned with doe's strategic objective to support a more economically competitive , environmentally responsible , secure , and resilient u.s. energy infrastructure .

during the planning phase , wwpto established a specific , measurable goal in its rules for the competition .

the goal required that devices developed for the competition at least double the energy capture of current technology .

according to a doe national laboratories analysis , the average rate of wave energy capture for a group of current devices is 1.5m / $m ( or 1.5 meters per million dollars ) .

to be eligible for a monetary prize , which will range from $1.5 million for the winning team to $250,000 for the third place team , participants would have to develop a device that would achieve 3m / $m .

wwpto officials told us that this target gave participants a clear , achievable goal for which to strive .

they added that the goal also was aggressive enough to represent a ground - breaking advancement over current technology .

although the competition is still ongoing , according to information on the contest website , wep has demonstrated early success as a number of the teams are proposing innovative technologies and have demonstrated a potential to achieve or exceed wwpto's stated goal .

to help guide its outreach efforts , wwpto also established a goal to alert potential participants about the wep , and have them take action by registering to participate .

wwpto officials and the prize administration team developed a detailed communications and outreach plan for the competition .

the plan outlined the types of metrics that could be tracked to determine the effectiveness of its outreach efforts .

these metrics include the number of registered teams , and traffic to the competition website and social media pages .

according to wwpto officials , 92 teams registered to participate in the competition thanks to their aggressive communications and outreach strategy .

this number was three times more than they had initially expected .

epa has a strategic objective to protect and restore watersheds and aquatic ecosystems , and has reported that it is working with external partners and stakeholders to spur technological innovations to reduce costs and pollution through improved and less - expensive monitoring .

in 2013 , ostp convened the challenging nutrients coalition ( cnc ) .

cnc is a group of federal agencies , including epa , nongovernmental organizations , and academia , working together to address the issue of nutrient pollution .

in november 2013 , ostp hosted a meeting of agencies and experts familiar with nutrient pollution .

according to epa , experts found that more affordable and reliable sensors are needed to collect more data on nutrient levels to inform decisions about how to manage and reduce these levels .

in december 2014 , the nutrient sensor challenge was announced , led by epa and supported by the national oceanic and atmospheric administration ( noaa ) and other agencies .

the goal of the nutrient sensor challenge is to accelerate the commercial development of accurate , reliable , and affordable devices that will meet user needs and be available for purchase by 2017 .

according to epa officials , epa aligned the goals of the challenge with epa's strategic objective .

the challenge offers participants non - monetary rewards and incentives like visibility in an emerging market and access to testing services and other resources .

in june 2014 , the partnership on technology innovation and the environment , another member of the cnc , conducted a study to clarify the specific needs of potential sensor users .

through this study they identified standards for accuracy , precision , and cost that the vast majority of potential users would look for in devices .

these became the technical requirements that devices developed for the challenge must meet to be eligible for awards .

for example , most of the study's participants identified the $1,000-to - $5,000 price range as affordable for their purposes .

for this reason , epa required that the devices built for the competition have a purchase price of less than $5,000 .

as of august 2016 , epa and its partners are conducting final testing on the devices submitted by participants to determine if any meet the technical requirements , and plan to announce final awards in december 2016 .

however , epa officials stated that preliminary results indicate that the devices developed through the competition will meet the technical requirements that have been established .

they added that several companies are developing instruments of similar capabilities and price outside of the challenge .

another goal of the competition is to produce an identified , mobilized market of community organizations , state and federal agencies , and researchers .

according to epa officials , epa and other cnc partners , including usgs , noaa , and the national institute for standards and technology , are creating pilot programs that will allow organizations to deploy and test these sensors following the completion of the competition in late 2016 .

according to epa officials , as of march 2016 , 14 organizations have expressed interest in participating in epa's pilot program .

epa officials also stated that this pilot program will help identify organizations that may want to purchase and deploy the sensors in a more widespread way in the future .

epa officials stated that having these specific goals has been critical given the focus that they have provided .

for example , the goals will help ensure that the devices developed through the challenge serve as the reliable and affordable devices necessary to stimulate the market , and to expand how widely they are deployed .

identify and engage outside stakeholders interested in the issue addressed by the initiative .

look for opportunities to partner w ith organizations on the design and implementation of the initiative .

our literature review and agency officials highlighted the importance of identifying and engaging with external stakeholders who share an interest in the issue being addressed and may already be active in related efforts .

for a federal agency , external stakeholders can include representatives of relevant non - profit organizations and foundations , community or citizens' groups , universities and academic institutions , the private sector , members of congress and their staffs , other federal agencies , and state and local governments .

by engaging with outside stakeholders , agencies can gain their support for the initiative , gain insights from their prior experience working on an issue , and see how they might use the results ( eg , products ) of an initiative .

this can help clarify the goals and design of an initiative .

this engagement can also be used to determine what motivates stakeholders to get involved in an effort , and to identify additional stakeholders , partners , or potential participants to engage in the initiative .

the literature , experts , and agency officials also emphasized that agencies should look for opportunities to partner with other groups and organizations that would be interested in , or could benefit from , the results of an open innovation initiative .

partners are organizations and individuals that play a direct role in designing and implementing an initiative .

they provide staff capacity , resources , administrative and logistical support , assistance with communications and community building , or ongoing advice and expertise .

partner organizations provide these resources and assistance because they have missions or goals that overlap or align with what the agency wants to achieve through an open innovation initiative .

agencies can also consider the most appropriate and effective mechanism for formalizing these partnerships , such as collaboration agreements , contracts , or interagency agreements .

agency officials can identify partner organizations through discussions with external stakeholders , professional contacts , or research into organizations with complementary goals .

finally , agency officials we interviewed emphasized the especially important role that agency leaders can play with respect to this practice .

the support of agency leaders can be particularly important , as their involvement can lend credibility and visibility to an initiative to those outside the agency .

it can also help mobilize a broader community of external stakeholders and partner organizations .

below we provide illustrative examples of how dot , hud , epa , and hhs identified and engaged external stakeholders and partners for three open innovation initiatives .

the federal highway administration's ( fhwa ) every day counts ( edc ) is an example of an ideation initiative .

edc is designed to identify effective , market - ready innovations states could implement to improve highway project delivery .

according to an fhwa official , from the beginning of the initiative in 2009 , the then - fhwa administrator and deputy administrator ( who are now deputy u.s. secretary of transportation and fhwa administrator respectively ) established and supported edc as a state - based , stakeholder - driven program .

they established the center for accelerating innovation ( center ) to implement the program , and worked with internal and external stakeholders to promote the idea of using innovative practices to improve how highway construction projects are performed .

every 2 years , fhwa works with various stakeholders to identify innovative technologies and practices that merit more widespread deployment through edc .

the process begins when fhwa publishes a request for information inviting suggestions for new innovations to consider from state , local , tribal , and industry experts .

according to fhwa officials , the agency typically receives more than 100 suggestions and comments .

fhwa staff review these submissions to develop a list of those innovations that are market ready , could be implemented across the country , and have the greatest potential to improve efficiency and quality in highway transportation and construction .

according to an fhwa official , once this list of edc innovations is finalized , the center works with fhwa program offices to identify leaders for innovation deployment teams .

the deployment team leaders identify other team members , such as communication specialists , subject matter and technical experts from state transportation agencies , and key stakeholders like industry representatives .

the deployment teams work with state transportation agencies and other stakeholders to implement the innovations that best fit their needs by providing technical assistance , training , and outreach .

once the edc innovations are selected , transportation leaders from across the country gather at regional summits to learn about and discuss the innovations .

according to a march 2015 report from fhwa , the summits are used to disseminate information on innovations so states can identify those that best fit the needs of their highway programs .

the summits include interactive working sessions to foster connections among regional transportation professionals , and encourage longer - term collaboration on the deployment of innovative practices .

in 2014 , the summits introduced online broadcasts of the presentations and discussions so that a wider audience could participate .

the president's hurricane sandy rebuilding task force launched rebuild by design ( rbd ) , a prize competition overseen by hud , in june 2013 to generate innovative and implementable design ideas to rebuild communities affected by hurricane sandy .

according to hud officials , hud searched for external organizations and foundations with complementary missions to partner with on implementing rbd .

in particular , it sought established organizations with resources , capabilities to administer a design competition , and the ability to engage local residents and stakeholders in affected communities .

several philanthropic organizations , including the rockefeller foundation , provided financial support to fund the administration of the competition , $200,000 cash prize awards to finalist design teams , and project evaluation .

according to a 2014 evaluation of rbd conducted by the rockefeller foundation and hud officials , direct outreach to potential philanthropic partners by the then - secretary of hud played a key role in securing their financial commitments .

to help administer the competition , hud also partnered with four local research and advocacy organizations to support the work of rbd design teams at the local level .

figure 4 summarizes the network of organizations involved in rbd .

according to hud officials , each administering partner organization was chosen for its complementary resources and expertise in research , design competitions , community outreach , regional planning and design , and local ties to the region .

hud staff also established a management plan early in the process that outlined roles and responsibilities for how these partner organizations would work together through each stage of the competition .

according to hud officials , this partnership with local organizations supporting the competition's implementation was critical to rbd's success .

hud officials were unfamiliar with local networks of community groups and other relevant organizations in each region , so the ability to partner with those that had knowledge , networks , and skills that hud could leverage was valuable .

these networks helped facilitate community engagement by design teams , who used meetings , community design workshops , site visits , and social media to engage hundreds of local stakeholder groups from communities affected by hurricane sandy .

according to hud officials , this outreach was critical to meet hud's expectation that projects receiving support be co - designed with communities , have local support , and be financially viable .

they also said that rbd demonstrated the value that external partnerships can bring in providing expertise , capacity , and connections that help an agency achieve its mission and goals .

according to epa and hhs officials , both agencies shared an interest in developing affordable , wearable sensors that would provide wearers with information on air quality and the body's reaction to it .

the agencies jointly sponsored the my air , my health challenge , asking participants to develop a device that would do these things in tandem .

the challenge was held in two phases , and ran from june 2012 to june 2013 .

according to epa officials , epa and hhs created a cross - agency design team that included experts from epa's offices of air and radiation and research and development , and the national institutes of health ( nih ) , a medical research agency within hhs .

within that design team , one cross - agency work group focused on identifying the air pollutants and health concerns the competition would target , while another work group focused on the technology and how the devices would communicate health data .

according to epa officials , creating this collaborative design team helped ensure key subject matter experts from each agency could guide the development of technical requirements for the competition in a way that would address the shared goals of each agency .

according to an hhs official , for example , during the development of these technical requirements , epa staff identified what air quality data would need to be collected , while hhs staff identified what would need to be measured to determine the health effects of exposure to air pollution .

according to epa officials , the agencies shared responsibilities for implementing the competition's phases .

epa implemented the first phase of the competition , which was focused on developing plans and proposals for prototypes .

hhs then implemented the second phase , in which finalists developed and validated proposed prototypes .

epa and hhs officials told us that the agencies used the competition to communicate their shared interest in the technology and encourage further private - sector development .

the agencies used my air , my health to demonstrate that open innovation initiatives involving partnerships between agencies were feasible , and that collaboration between agencies and with the private sector can allow agencies to achieve goals that they may not have the capability to achieve alone .

relevant literature and agency officials highlighted how important it is for agencies to ensure that roles , responsibilities , expectations , and time frames are clear for all involved in implementing and managing an initiative .

the agency and any of its partners can do this by establishing and documenting a governance structure for the initiative that clarifies the processes that will be used to ensure regular communication ; raise , discuss , and resolve any pressing issues ; and make decisions .

according to our literature review and interviews with experts and agency officials , the agency and any partners should develop a detailed implementation plan for the initiative that clearly identifies the specific tasks and actions needed to carry out the initiative , the parties responsible for completing them , and the timeframes for doing so ; potential participant groups to engage in the initiative , including when and how the agency and any partners will reach out to various participant groups and encourage them to participate , and how they will engage with participants during and after the initiative's implementation ; and what data will be collected , and how , during and after implementation , and how the data will be evaluated to determine overall results and progress towards the initiative's stated goals .

the following two examples show how hud and hhs developed plans for implementing and recruiting participants for selected open innovation initiatives .

switchboard is an online idea generation initiative that hud uses to collect ideas from citizens , stakeholders , and hud staff on how the agency can improve its processes , programs , and administration .

hud officials can then consider these ideas for potential implementation .

hud drafted a charter in 2011 to guide the initiative's implementation that describes the overall team structure , defines the roles and responsibilities of each staff member involved in reviewing and responding to ideas submitted through the website , and names liaisons for program offices throughout hud to review and respond to ideas that fall within their programmatic jurisdiction .

see table 3 for a summary of the roles and responsibilities from the switchboard charter .

table 3 .

information on roles and responsibilities from hud's switchboard charter responsibility champion of the project .

approval and sign off of project components and requirements .

overall ownership of project from an organizational perspective ; management of budget .

overall management of the project timelines and scope .

oversight of internal and external communications ; sets direction for messaging .

manages day - to - day activities of project .

provide input into process , manage ideas and responses .

the charter also explains the process and criteria used to evaluate an idea , and determine whether it should be elevated for consideration and potential implementation .

hud supplemented this charter with a document outlining policies and procedures for investigating , responding to , and implementing an idea .

figure 5 summarizes these procedures .

according to hud staff , switchboard has become a tool for more effective customer service by providing an easy way for anyone to contact hud with ideas for how the agency could do things more effectively .

it has also provided the agency with a platform to host specific issue forums that are sponsored by various hud program offices and targeted toward specific segments of the public .

for example , in 2011 , the hud office of hiv / aids housing used switchboard ( then called hud ideas in action ) to ask for public input on how hud should update the housing opportunities for persons with aids program funding formula to better target resources to need .

in response to this request , hud received 17 submissions with ideas — many of which generated additional comments from participants in the forum — and a total of more than 500 votes .

hud then selected four of these submissions for further review , and incorporated recommendations from one of them into the department's fiscal year 2013 budget request .

the neuro startup challenge was created by nih and the center for advancing innovation ( cai ) , a non - profit organization with a mission to accelerate knowledge and technology transfer , and entrepreneurship .

conducted from april 2014 to august 2015 , the challenge was designed to generate promising start - up companies with business plans to commercialize nih inventions for use in treating brain and neurological disorders .

according to the collaboration agreement between nih and cai , the challenge supported nih's mission to advance research , innovation , and education to protect public health .

it also aligned with cai's goals to encourage the commercialization of new technologies .

nih and cai used this collaboration agreement to outline a detailed governance structure that specified the roles each organization would play in implementing the competition .

the agreement also identified the respective tasks each would be responsible for completing during the various phases of the competition , along with the timeframes for each phase .

for example , the agreement specified that during the planning phase of the competition , which was scheduled to run from april to august 2014 , cai would be responsible for identifying and engaging stakeholders and potential participants , as well as other deliverables , including the development of an advertising and marketing plan for the competition .

the agreement also specified that nih would provide input on the rules and criteria for the competition , the selection of inventions , and the identification of potential participants .

according to an nih official , this delineation of responsibilities was particularly important to help frame and focus efforts at the beginning of the project .

in the agreement , nih and cai also identified the potential participants they wanted to reach through the competition .

participants included graduate and post - doctoral students and experienced entrepreneurs .

according to an nih official , nih and cai particularly focused on engaging those affiliated with universities , given the focus on connecting university students with real - world experience in business planning .

prior to launching the initiative , cai planned for extensive contact with university faculty and students to get feedback on the concept and to make them aware of the challenge .

cai then conducted an extensive series of phone conversations and in - person meetings to connect with stakeholders and potential participants at 37 universities in 14 states .

through this outreach they reached approximately 1,500 people with information on the challenge .

according to nih officials , many of the more than 70 teams that participated in the competition were from those universities contacted through this outreach .

cai also reached out to local economic development groups and universities to identify entrepreneurs and business developers who would be interested in supporting participating teams .

relevant literature , experts , and agency officials emphasized that when agencies are ready to move forward with implementation , they should announce the initiative in a way that generates interest among potential participants .

this involves using multiple outlets and venues — including the initiative website , social media , press releases , press conferences , journals , newsletters , and professional conferences and networks — to ensure they reach the right potential participants and make them aware of the initiative .

the participants that an agency and any partners seek to engage , and how they decide to solicit participation , will vary depending on the purposes of the initiative .

for instance , if an agency wants to use an initiative to address a very specific technical issue it may attempt to identify and engage individuals with the requisite skills through an existing network of experts .

however , if an agency intends to use an initiative to collect a wide range of perspectives on an issue , it will likely need to be much more open and inclusive in its outreach and encourage diverse groups to participate .

efforts to promote the initiative are important because reaching the right participants and motivating them to participate is critical to the overall success of an initiative .

according to the literature and our interviews , the initial outreach to potential participants should be crafted and communicated in a way that responds to the interests and motivations of potential participants , and explains why it is important for them to participate .

in addition , the agency should also establish clear expectations for participants , describing in detail what they will be expected to contribute ; how and when their contributions will be collected , evaluated , and used ; and what participants must do to receive any monetary or non - monetary incentives that may be provided .

once the initiative begins , the agency and any partners should use websites , question - and - answer sessions , emails , and other forms of communication to keep participants apprised of progress .

through the literature and our interviews we also found that agencies and their partners can actively engage participants to solicit and respond to any questions , comments , and feedback , and provide any necessary assistance .

these actions can increase the likelihood that participants will have a positive experience , and can help show that their participation and contributions are valued .

according to experts and agency officials with whom we consulted , however , doing this can be a very resource - intensive activity , particularly if the initiative has a large number of participants and there is a high volume of communication from participants .

therefore , during the planning phase , the agency and any partners should work together to ensure that the party responsible for this aspect of implementation has sufficient capacity to respond in a timely fashion .

agency officials highlighted that the agency and any partners should also use regular check - ins to discuss the progress of the initiative .

such check - ins can help ensure those involved in implementation know the status of specific implementation tasks against established time frames , and any decisions that may be needed .

the agency and partners should also review the data and feedback that are being collected during implementation .

this will allow them to identify and make any necessary adjustments to improve implementation and the experience of the participants .

as illustrated below , hud , doe , and hhs engaged participants and partners during the implementation of three open innovation initiatives .

hud's objective for its outreach to potential participants for rebuild by design ( rbd ) , according to an april 2015 report from ostp on the implementation of federal prize competitions and hud officials , was to recruit world class design talent to participate in the competition .

it used its network of project partners , professional associations , university programs , as well as websites focused on planning , design , and urban issues , to promote the competition .

for example , the american institute of architects launched a communications campaign urging its membership to participate in rbd .

according to the april 2015 ostp report , this outreach was successful , as hud ultimately received high - quality proposals from 148 teams representing top engineering , architecture , and design firms .

according to hud officials , after 10 design teams were selected to participate in rbd , hud and its partners regularly communicated with the teams to identify challenges they faced and assistance that they needed .

hud officials explained that rbd was designed to allow more than one winner , as each finalist team worked to develop innovative approaches for rebuilding and resilience in a different community .

as a result , the rbd management team facilitated collaboration between the design teams .

this allowed the teams to share good practices and learn from each other's experiences .

according to a 2014 evaluation of rbd conducted by the rockefeller foundation , hud's local administering partners supporting rbd's implementation also worked closely with the design teams and provided logistical support and connections to community - based organizations and public officials .

to ensure clarity about reporting requirements and deadlines , those managing rbd also instituted other means of communication .

this included biweekly memorandums for the design teams and weekly phone and e - mail communications with partner organizations providing support to teams at the local level .

the rockefeller foundation also reported that effective management practices and regular communication allowed the design teams to meet all procedural deadlines and milestones despite the initiative's fast pace and logistical challenges .

in the communications and outreach plan developed for the wave energy prize ( wep ) , doe's wind and water power technologies office ( wwpto ) set a goal to expand the community of developers involved in wave energy conversion technology .

it sought to do this by drawing in both experienced energy device developers and newcomers representing a diverse group of companies , universities , and individuals .

according to wwpto officials , to generate a large pool of new and experienced developers for the competition , which began in april 2015 and is scheduled to conclude in november 2016 , they used multiple outlets and venues to encourage wep participation .

as outlined in the communications and outreach plan for the competition , this included the wep website , social media , email marketing , presentations , and outreach to various media outlets to reach a broad range of potential participants .

communications used to recruit participants also emphasized several key messages to motivate interested individuals and teams to participate .

these messages included the availability of a monetary prize , the opportunity to help solve a difficult technological problem , and the chance to work on technologies that could contribute to the nation's energy independence .

see figure 6 for examples of these communications .

according to wwpto officials , to ensure there would be participants with technical expertise in energy production technology , wwpto officials reached out to individuals who previously had contacted wwpto regarding other projects involving wind and water power .

wwpto also promoted the competition through specific industry publications , outreach to professional and academic organizations focused on relevant technical specialties , and presentations at energy technology - oriented conferences .

according to wwpto officials , through this outreach , they attracted both new and experienced developers to participate in wep .

of the 92 teams that registered to participate in wep , most were previously unknown to wwpto .

furthermore , out of the nine finalists and two alternates that were chosen to participate in the final phases of the competition , only two had received any prior funding from wwpto .

wwpto officials also reported that they were successful in reaching teams with sufficient technical expertise to reach aggressive technical goals .

according to information on the competition website from march 2016 , while the devices of finalist teams are currently undergoing final building and testing , preliminary evaluations indicate that many of them could achieve or exceed wwpto's goals for the competition .

according to wwpto officials , the prize administration team has also created processes to regularly engage with teams participating in the competition .

for example , the prize administration team holds biweekly calls with participating teams and technical experts .

these calls prepare them for the final testing program , solicit and respond to participants' questions and comments , and provide any necessary technical assistance .

according to wwpto officials , these interactions can be time - and resource intensive , so they planned for them during the early phases of the competition .

this ensured that the prize administration team allocated sufficient resources to fulfill their participant management responsibilities .

furthermore , wwpto and the prize administration team also hold weekly conference calls to discuss progress on key tasks and any adjustments that may be needed .

these check - ins help ensure that wwpto and the prize administration team are working from a common set of expectations .

it also allows wwpto to provide the prize administration team with any necessary information it needs to successfully implement wep .

openfda is an open data platform released by the food and drug administration ( fda ) in june 2014 .

fda , an agency within hhs responsible for assuring the safety of drugs , medical devices , and food , uses openfda to make several key datasets available in a format that allows researchers and developers to more easily use the data .

according to an august 2014 report from iodine , a private health data company that assisted fda in the development of openfda , as the platform was developed and became available for testing , fda officials actively engaged potential users .

the officials solicited input from a group of individuals and organizations that had expressed interest in the platform and were willing to contribute feedback .

the report also stated that fda officials observed that some of those testing the platform had difficulty using it .

as a result , fda took actions to make the platform more user friendly .

these actions included adding an interactive tool that allows users to filter and visualize the data more intuitively .

according to an fda official , these changes permitted openfda users without technical expertise to more easily use and benefit from the platform .

in addition , fda officials actively monitored the online forums created for users of openfda , and responded to any requests for clarity or information .

according to fda officials , engagement with users has been a priority .

through direct contact with the community of users , the agency has collected information to help ensure openfda will serve their needs .

for instance , in december 2015 , fda made the data on openfda available for direct download as a result of requests from users .

in june 2016 , fda also launched an updated version of openfda that was redesigned in response to user feedback .

this feedback included the need to improve the website's layout .

relevant literature and agency officials emphasized that after the initiative has concluded , or at regular intervals if it is a long - standing or continuous effort , the agency should assess whether the initiative has achieved its goals .

by analyzing the data it has collected , including quantitative performance data and qualitative data provided by participants on the effects of an initiative , the agency can determine if it has met its goals .

when a goal is unmet , the agency should conduct additional analyses to understand why .

in addition , because some outcomes may not be observable until months or years later , agencies can consider whether a long - term monitoring or assessment plan is needed and appropriate .

according to relevant literature we reviewed , the agency should also conduct an after - action review to analyze feedback from partners and participants .

such a review can help identify lessons learned and process improvements that could be applied in future initiatives .

for example , participant feedback may provide insights on parts of the process that went well and others that could have been executed better .

these can then be replicated or adjusted , accordingly , for reoccurring or similar initiatives in the future .

the agency can also engage with partners to review planning and implementation activities to identify what worked well and any notable gaps or challenges that may need to be addressed in future initiatives .

lastly , relevant literature and experts emphasized that once the agency has assessed the initiative it should publicly report on the results achieved and lessons learned .

this transparency can help build trust with partners and participants , demonstrate the value of open innovation initiatives to other stakeholders and the public , and build momentum for future initiatives .

reporting results while partners and participants are still engaged can also help sustain a dialogue and increase awareness within the community of interested organizations and individuals .

for the following three open innovation initiatives , we present how dot , nasa , and doe collected data , and assessed and reported results .

the federal highway administration's ( fhwa ) every day counts ( edc ) initiative focuses on ensuring that proven innovations to improve highway construction and safety are quickly and broadly deployed .

fhwa launched edc in 2009 .

fhwa tracks progress toward this goal primarily by measuring the number of states that are deploying specific innovations being supported by edc , along with whether the innovation is being developed , tested , assessed , or adopted as a standard practice .

according to fhwa officials , staff from the center for accelerating innovation ( center ) , which is responsible for implementing edc , and deployment teams use this data to track how the level of deployment compares with goals established at the beginning of each 2-year cycle .

figure 7 shows the january 2015 baseline data for the e - construction innovation , the progress made through december 2015 , and the overall goal the agency is working to achieve by december 2016 .

according to an fhwa official , staff from the center work with deployment teams to develop implementation plans for each innovation , which include identifying interim performance goals that will be used by the team to track implementation progress .

fhwa officials say setting specific performance goals for deployment helps to ensure accountability for the advancement of innovations .

for instance , the director of the center meets with the leader of each deployment team each quarter to review progress toward established goals .

according to an fhwa official , these review meetings can result in the provision of additional resources or assistance to deployment teams , or , in some circumstances , adjustments to team leadership .

fhwa has also established regular reporting cycles for edc .

it releases two progress reports each year that summarize the status of each innovation .

in addition , it has also produced a final report at the end of previous two - year cycles summarizing the highway community's accomplishments and progress .

the final report includes data on how widely each innovation was deployed , accomplishments in states where innovations were deployed , and explanations of benefits and lessons learned through implementation .

according to fhwa officials , publicly reporting results increases transparency and shows the effects of the edc program .

it also highlights successes achieved by state and local agencies in deploying innovations faster .

for instance , fhwa reported in its july to december 2015 edc progress report that the program has accelerated the deployment of innovations across the country .

every state implemented at least 8 of the 38 innovations promoted under the initiative since 2010 , while some have adopted over 20 .

furthermore , in august 2014 , fhwa released a report with examples demonstrating that implementing edc innovations has had significant and measurable effects in participating states .

for example , fhwa reported that deploying accelerated bridge construction as an edc innovation has allowed states to reduce the time it takes to plan and construct bridges by years .

this significantly reduces traffic delays , road closures , and often project costs .

in 2015 , congress enacted and the president signed into law a requirement that fhwa continue to use edc to work with states , local transportation agencies , and industry stakeholders to identify and deploy proven innovative practices and products .

nasa worked with expert and citizen assessment of science and technology ( ecast ) , a network of institutions that encourages public input on science and technology policy issues , to solicit the views of citizens on options for defending the earth against an asteroid strike and exploring asteroids .

these in - person and online forums , known collectively as the asteroid initiative citizen forums , took place in november 2014 and february 2015 .

the forums were used to obtain information on participant preferences , priorities , and values .

nasa officials used this input to inform , among other things , decisions about its future mission and technology investment goals .

this includes detecting asteroids , mitigating asteroid threats , and exploring asteroids with astronauts .

for example , after the forums were held , relevant results were shared with nasa managers to inform the selection of a specific technology and approach that would be used for a future mission to capture an asteroid .

according to nasa officials , the results of these forums provided nasa with insights into public understanding and views on nasa's asteroid work .

figure 8 illustrates the platforms used for both the in - person and online forums .

according to nasa officials , nasa also wanted to use the forums to identify lessons that could guide its future efforts to engage citizens .

to do this , ecast had participants complete post - forum surveys and provide written comments on their experience in the forum .

ecast then analyzed this information .

observers at selected tables also helped assess the meaning of written comments from participants .

through an after - action review , ecast identified a small number of issues to address in preparation for any future forums .

these included insights into the ability of citizens to understand complex information , and the need to provide clearer information to participants about how the forum results would be used .

members of ecast involved in designing and implementing the forums also summarized their observations on potential refinements in their final report to nasa .

for example , ecast found that connecting attendee background information to individual responses could have also provided context for interpreting the written results .

ecast members also found they needed more time to test background materials given to participants to read before the event , and needed to take additional steps to increase consistency across table facilitators .

doe's sunshot catalyst initiative ( catalyst ) was a series of competitions first begun in may 2014 .

it was designed to engage entrepreneurs , solar professionals , and software and data experts to help them rapidly develop start - up companies with viable technologies to address identified challenges in the solar and energy efficiency markets .

by providing intensive training and support to those with the most promising ideas , doe officials also wanted to ensure that teams would have market - ready innovations and viable business plans at the end of the competition .

according to doe officials , doe selected 35 teams to participate in the initiative .

according to a doe official , in order to determine the initiative's effectiveness , doe developed a long - term effort to monitor the status of the companies created through the competition .

doe officials said that they collected publicly - available information on the status of the 35 teams that participated in catalyst .

doe officials reported in june 2016 that through collecting this information they found that 28 teams were still actively pursuing their startups .

doe officials also invited all 35 teams to one - on - one discussions , and were able to meet with 24 of them .

through these discussions , doe collected information on the amount of capital the teams had raised , projected annual revenues , and the benefits they gained from participating in catalyst .

for example , the 24 teams reported that they had collectively raised a total of $6.4 million in private capital or public funding , had 95 full - time employees , and had total expected annual revenue of $5.6 million .

as doe also reported , officials also identified specific lessons learned at each stage of the catalyst process that can be used to inform how future competitions are conducted , and improve and expand the catalyst program .

for example , doe reported that the most effective way to reach potential catalyst participants was through the networks of previous participants , along with recruitment efforts involving local partners and events .

doe also reported that the 60-day period provided for participants to develop their prototypes was challenging , and that the department should consider adding time to that phase of the competition .

doe also compared the cost and time for product development under the catalyst approach to those supported through doe's traditional financial assistance awards , including cooperative agreements and grants .

according to doe officials , the agency had learned through earlier efforts to engage developers that the application process for traditional funding opportunities can create a barrier for those who may not be interested in or able to go through what can be seen as an extensive review and approval process .

doe wanted to use catalyst to test a faster , more open way of engaging developers and entrepreneurs .

through its assessment , doe found that , under a traditional funding opportunity , it typically takes 9 months to move from the announcement of the opportunity to the award being made , with minimum awards ranging from $300,000 to $500,000 for software or applications .

by contrast , for catalyst , this process was completed in 3 months , with $25,000 prizes awarded to rapidly test and validate prototypes .

given the time and resources that agencies may invest to build or enhance communities of partners and participants for open innovation initiatives , agencies can take steps to sustain these connections over time .

this is particularly important if one purpose of the initiative is to build a new , or bring greater coherence to an existing , community of interested organizations and individuals to work together on an issue .

however , this may be less applicable when an initiative is discrete in scope and intended to be a one - time occurrence .

seek to maintain communication w ith , and promote communication among , members of the community .

according to relevant literature and agency officials , agencies should acknowledge and , where appropriate , reward the efforts and achievements of partners and participants so that they feel their contributions are valued and appreciated .

this can be done in conjunction with reporting the results of and lessons learned from the initiative , or through separate venues such as announcements , award ceremonies , or recognition on the initiative website .

as part of this effort , it is also important for agencies to explain how the contributions of partners and participants helped the agency achieve , or progress toward , its goals , and to communicate the next steps that will be taken following an initiative .

relevant literature and experts we consulted also highlighted that agencies can seek ways to maintain communication with members of the community to keep them informed of future initiatives and other opportunities of interest , and facilitate communication within the community .

to ensure these activities receive sufficient attention over time , an agency may need to assign staff the responsibility of maintaining contact with these communities .

efforts to sustain a community over time can help enhance collaboration to continue progress on addressing an issue , and provide the agency with a network that could be more easily mobilized again for future initiatives .

at some point , these communities may become self - sustaining , with members continuing to collaborate with little or no involvement from the agency .

to illustrate how agencies have built and sustained communities of interested partners and participants by implementing open innovation initiatives , we provide the following three examples from epa , nasa , and hhs .

from 2012 to 2015 , epa's office of research and development held a series of air pollution sensor workshops that were , according to epa officials , designed to better understand the needs of governments and community groups interested in using these sensors , and to build a more coherent community of users and developers .

epa held the first workshop in march 2012 .

it provided a forum for the exchange of ideas and collaboration among people who use and research air pollution sensors to learn from their successes and challenges .

seventy people representing federal agencies , state and local governments , academia , private industry , and community - based organizations attended the workshop .

according to epa officials , workshop attendees agreed that it was helpful to have epa convene these groups so that they could learn from each other , and build greater trust and understanding through collaboration and communication .

subsequent workshops held from 2013 to 2015 focused on specific issues , including data quality , citizen science , and community - based monitoring .

in addition to in - person attendance , the workshops were also broadcast as webinars to allow those unable to attend in person to participate .

each year , there was increased interest in the workshops .

more than 800 people participated in the 2015 workshop , both in person and via the webinar .

the 2015 event , which was used to provide training on how to conduct community air monitoring , was , according to epa officials , designed to build on the three previous annual workshops , whose participants requested more hands - on training opportunities .

epa officials reported that these regular workshops helped sustain this growing community , providing opportunities to build partnerships and identify and address stakeholder needs .

in addition to these workshops , epa officials continue to share information and resources to keep individuals in the community engaged in efforts to develop and deploy improved air sensors .

for example , after the 2015 workshop , epa officials told us that they hosted regular follow - up conference calls with 30 in - person attendees chosen because of their involvement in air - monitoring projects in local communities .

epa officials also said they periodically e - mail past workshop participants to inform them about webinars , funding opportunities , and other items of interest .

in addition , according to documentation from epa , officials have regularly given presentations to stakeholder groups on community air monitoring .

epa has also made resources available to support sensor developers and citizen scientists , establishing a sensor technology testing program to provide feedback to developers and users , and an online “air sensor toolbox” that offers training videos and answers to frequently asked questions about community air monitoring .

according to epa officials , these efforts to build and sustain the community interested in air sensor technology have contributed directly to epa's strategic goal to improve air quality .

prior to the series of workshops , epa had little in terms of ongoing research related to the development , testing , and use of air sensor technology .

the workshops identified a need for , and inspired , a concerted research effort to identify promising technologies , evaluate technology performance in field and laboratory tests , and explore the use of these new technologies and the data they produce .

each year since 2012 , nasa has held an annual 2-day event called the international space apps challenge .

at this event , teams of scientists , developers and students use publicly - available data to design solutions to identified challenges .

according to nasa's report on the 2015 event , space apps is used to make the agency's open data and assets available to the public , with the aim of giving people new ways to produce relevant open - source solutions to global challenges .

according to a nasa report on the space apps challenge and a nasa official , beginning with local space apps events in 25 cities across the world in 2012 , each year the number of local events has increased .

in 2016 , local events were held in 161 locations spanning 61 countries .

nasa relies on local volunteer hosts to secure venues , manage logistics , and promote the events .

given the importance of sustaining relationships with those at the local level experienced in hosting these events , nasa has provided tools to help ensure local hosts have a positive experience .

for example , nasa created a toolkit that provides prospective hosts with practical advice , guidelines , and best practices for hosting a local event .

according to the nasa space apps report , three months prior to the event , nasa staff begins to actively engage with those organizing local events .

they provide weekly suggestions , reminders , and resources to help hosts plan and manage their local events .

nasa staff also convenes periodic planning conference calls with local hosts to communicate new information and answer questions .

according to a nasa official , actively engaging through planning calls makes a significant difference .

new hosts can ask questions of , and learn from , experienced hosts and nasa staff .

it also allows local hosts to share ideas and advice with one another .

this official also stated that , by engaging with the community , nasa can learn more about the support that local hosts need and collect their suggestions .

for example , rather than having one planning call each week , nasa holds three different calls to accommodate the varying schedules of local hosts in different time zones .

according to the nasa space apps report , after the completion of each year's event , nasa also acknowledges and honors hosts and winning participants by recognizing them on the space apps website , in public reports , and through other venues , like invitations to launches .

figure 9 provides an excerpt from the website used to acknowledge finalists and winners from previous challenges .

according to a nasa official , all of these elements combined have helped them maintain a strong level of involvement by hosts at the local level .

for example , she said 78 percent of the hosts for 2016 local events had returned after hosting events in previous years .

she also stated that , by regularly engaging with a community of people using the agency's data , space apps has helped nasa meet its open data goals and mandates .

for example , through feedback from space apps participants , nasa officials learned how difficult it could be to use the agency's open data .

this led to action to improve the usefulness of the datasets and house them in one location to make them more accessible .

nasa also used feedback from space apps participants to redesign the agency's websites and make it easier for visitors to understand and use nasa data .

according to fda officials , one of the key goals of the openfda initiative is to build an open community of users around fda data .

openfda developers emphasized the importance of direct contact with , and feedback from , external users .

however , due to resource limitations , the developers knew it would be difficult to actively monitor online feedback boards and regularly address individual questions or requests .

they wanted to create infrastructure to both support users and make the community somewhat self - sustaining .

according to fda officials , they believed that an engaged community would help provide resources and assist new users .

according to an august 2014 report from iodine , the private health data company that assisted fda with the development of openfda , the infrastructure that fda put in place relies upon two online forums , stackexchange and github .

these forums facilitate communication and information sharing among members of the community .

they allow developers and researchers who use openfda to ask questions of the broader community of users , and get answers to those questions .

this allows lessons learned and insights to be spread among the community .

according to fda officials , these forums also allow users to recommend fixes to problems with , and make improvements to , the openfda source code .

according to data available on the stackexchange and github websites , both forums have been actively used .

for example , since openfda's june 2014 launch , members of the community of users have submitted more than 100 questions on the stackexchange forum .

nearly 90 percent of those questions have been answered by other members of the community .

according to an fda official , since openfda's launch github has also been used to identify nearly 50 issues with the openfda platform .

as of june 2016 , 39 of those issues have been addressed .

we provided a draft of the report to the office of management and budget , the office of science and technology policy , the general services administration , the departments of energy , health and human services , housing and urban development , and transportation , the environmental protection agency , and the national aeronautics and space administration for comment .

these nine agencies provided responses via emails transmitted between september 16 and september 27 , 2016 .

all nine agencies concurred with the findings of the report .

in its response , provided in an email from the ostp general counsel transmitted on september 22 , 2016 , ostp raised a concern that the report does not include an example of an initiative that only involved the use of citizen science .

our primary objective for this report was to identify , and illustrate through selected agency examples , practices that promote the effective implementation of open innovation strategies .

therefore , our focus was on selecting those initiatives with the greatest potential to illustrate aspects of these practices .

in making those selections , we ensured that the sample covered the five types of open innovation strategies frequently used by federal agencies .

although we did not include an initiative that only used citizen science , we included initiatives that involved the use of citizen science in combination with other strategies , such as nasa's asteroid data hunter initiative and epa's efforts to encourage the use of air pollution sensors .

in addition , doe , hhs , hud , nasa , and ostp provided technical comments , which we have incorporated as appropriate .

we are sending copies of this report to interested congressional committees , the heads of the agencies identified above and other interested parties .

this report will also be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-6806 or mihmj@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of our report .

key contributors to this report are listed in appendix iii .

the gpra modernization act of 2010 includes a provision for us to periodically review how implementation of its requirements is affecting agency performance .

this report is part of our response to that mandate .

our specific objective for this report is to identify , and illustrate through selected agency examples , practices that facilitate the effective implementation of open innovation strategies and the effects , if any , the use of those strategies have had on agency performance and opportunities for citizen engagement .

to identify the various open innovation strategies federal agencies have used to facilitate participation by , and collaboration with , citizens and other non - profit , academic , and private sector partners , we reviewed documents , reports , and resources from the office of management and budget ( omb ) , the office of science and technology policy ( ostp ) , and the general services administration ( gsa ) , and analyzed the open government plans of federal agencies .

through our review of these reports , and the most recent open government plans from 35 agencies , we identified 5 open innovation strategies that agencies have frequently used to engage citizens and external stakeholders .

to identify practices that can facilitate the effective implementation of open innovation strategies , we analyzed and synthesized information gathered from a number of different sources .

first , we collected relevant federal resources , including guidance with suggested practices for implementing various open innovation strategies developed by omb , ostp , and gsa .

through a literature review of relevant publications from public and business administration journals , and research organizations we identified those with suggested practices for the design and implementation of open innovation initiatives in the public sector .

we then analyzed and synthesized suggested practices in these sources to identify areas of commonality between them .

we interviewed 14 open innovation experts with experience in implementing open innovation initiatives or with academic or consultative expertise in this area .

we also interviewed officials involved in implementing open innovation initiatives at six selected agencies , as well as staff from omb , ostp , and gsa .

we initially selected and interviewed experts based on the results of our literature review ( eg , the authors of relevant articles or books with suggested practices for the design and implementation of open innovation initiatives ) .

based on suggestions from those individuals , we expanded our list of experts and conducted additional reviews .

through our analysis and expert interviews , we developed a broad set of practices that facilitate the effective implementation of open innovation initiatives .

we refined the list of practices through our audit work at selected agencies ( see below ) ; reviewing our body of work on performance management and collaboration ; and incorporating feedback from the open innovation experts we had previously interviewed , and from knowledgeable federal officials at ostp , gsa , and other agencies .

to illustrate how actions that selected agencies have taken to carry out open innovation initiatives have reflected effective practices , and the effects the application of these practices had on agency performance and citizen engagement , we selected six agencies for more in - depth review: the departments of energy , health and human services , housing and urban development , and transportation ( dot ) ; the environmental protection agency ; and the national aeronautics and space administration .

we selected these agencies based on several criteria , including the number and variety of open innovation strategies outlined in their individual agency open government plans .

these selections were also in line with suggestions we independently obtained from knowledgeable staff at omb , ostp , and gsa that were familiar with agencies that have actively used such strategies .

we also identified and selected 15 specific open innovation initiatives led by these 6 agencies which would allow us to illustrate how these agencies have applied effective practices for implementing open innovation initiatives .

we selected these initiatives based on our review of the open government plans for the 6 selected agencies , and of ostp reports on the implementation of prize competitions and challenges .

suggestions from knowledgeable agency staff also contributed to our selection process .

these initiatives are listed below in table 4 .

at these agencies , we reviewed relevant agency documents and interviewed knowledgeable agency officials responsible for designing and implementing these selected initiatives .

we asked these officials how they defined goals and selected specific strategies , how they designed and implemented their initiatives , and what steps they took to collect data and assess results .

these interviews allowed us to capture detailed illustrations showing how agencies took actions that reflect aspects of effective practices in the implementation of their initiatives .

the scope of this review was to identify practices for the effective implementation of open innovation initiatives , and to describe actions agencies took in carrying out open innovation initiatives that reflect aspects of those practices .

while we present information on the implementation of agency open innovation initiatives , we did not assess the success of the underlying agency programs and activities that these initiatives were designed to support .

for example , while we examined the implementation of dot's open dialogues on freight transportation , we have ongoing work reviewing various dot activities related to issues mentioned in the draft national freight strategic plan and have not evaluated the plan nor determined its effectiveness in helping dot meet its freight goals .

we conducted this performance audit from july 2015 to october 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

based on our review of agency open government plans and other sources , we found that agencies have frequently used the five open innovation strategies below to collaborate with citizens and external parties , and encourage their participation in agency efforts .

crowdsourcing and citizen science .

in crowdsourcing , agencies submit an open call , generally through the internet , for voluntary assistance from a large group of individuals to complete defined tasks .

this can help the agency complete projects , such as transcribing large numbers of historical documents , while also producing usable products that benefit the broader community , like searchable databases .

similarly , agencies can use citizen science to encourage members of the public to voluntarily assist with science - related tasks .

such tasks can include conducting experiments , making observations , collecting and analyzing data , and interpreting results .

this can supplement an agency's own data collection efforts .

it also allows agencies to study complex issues by conducting research at large geographic scales and over long periods of time in ways that professional scientists working alone cannot easily duplicate .

idea generation ( ideation ) .

in idea generation , or ideation , an agency asks participants to submit ideas to address a specific issue or problem , and may allow them to provide comments on ideas submitted by other participants , and vote to express their support for an idea .

open data collaboration .

in open data collaboration , an agency mobilizes participants to share , explore and analyze publicly - available data sets .

examples of open data collaboration may include using open data to conduct research , design data visualizations , or create web and mobile applications and websites that help people access and use the data .

participants can also be mobilized through in - person or online events , often referred to as “data jams” or “hackathons,” or through websites that provide access to open data and facilitate ongoing communication .

open dialogue .

in an open dialogue , an agency collects and responds to information , observations , and perspectives provided by a range of citizens and other external experts and stakeholders .

they can do this using online tools , including websites or interactive webinars , and in - person meetings or forums .

the agency can also use open dialogues to request input and suggestions on a set of options under consideration , and to better understand the values , perspectives , and preferences of citizens and stakeholders .

prize competition or challenge .

when an agency identifies a problem to solve or a specific goal it wants to achieve with the assistance of members of the public , it can hold a prize competition or challenge .

in a competition or challenge , the agency invites interested members of the public to submit potential solutions to this problem or challenge .

the agency then evaluates these proposals and provides a monetary or non - monetary award for those that meet specific criteria and are selected as winners .

in addition to the contact named above , benjamin t. licht ( assistant director ) and adam miles supervised the development of this report .

theodore alexander , joyce y. kang , steven putansu , lauren shaman , erik shive , wesley sholtes , and andrew j. stephens made significant contributions to this report .

sarah gilliland , robert robinson and stewart small also made key contributions .

shea bader , giny cheong , jeffrey demarco , alexandra edwards , anthony patterson , and timothy shaw verified the information in the report .

ballentyne , perrie .

challenge prizes: a practice guide .

united kingdom: nesta , 2014 .

brabham , daren c. crowdsourcing in the public sector .

georgetown digital shorts .

washington , d.c.: georgetown university press , 2015 .

brabham , daren c. using crowdsourcing in government .

washington , d.c.: ibm center for the business of government collaborating across boundaries series , 2013 .

department of health and human services idea lab .

the hhs competes playbook , accessed on january 12 , 2016 , http: / / www.hhs.gov / idealab / what - we - do / hhs - competes .

desouza , kevin .

challenge.gov: using competitions and awards to spur innovation .

washington , d.c.: ibm center for the business of government using technology series , 2012 .

eggers , william d. and paul macmillan .

“a billion to one: the crowd gets personal.” united kingdom: deloitte review issue 16 ( 2015 ) .

federal public participation working group .

u.s. public participation playbook , 2015 , accessed on july 27 , 2015 , https: / / participation.usa.gov .

goldhammer , jesse , kwasi mitchell , anesa “nes” parker , brad anderson , and sahil joshi .

“the craft of incentive prize design: lessons from the public sector.” deloitte university press , june 2014 .

kannan , p. k. and ai - mei chang .

beyond citizen engagement: involving the public in co - delivering government services .

washington , d.c.: ibm center for the business of government collaborating across boundaries series , 2013 .

king , andrew and karim r. lakhani .

“using open innovation to identify the best ideas.” mit sloan management review , september 11 , 2013 .

lee , gwanhoo .

federal ideation programs: challenges and best practices .

washington , d.c.: ibm center for the business of government using technology series , 2013 .

lee , gwanhoo and young hoon kwak .

an open government implementation model: moving to increased public engagement .

washington , d.c.: ibm center for the business of government using technology series , 2011 .

luciano , kay .

managing innovation prizes in government .

washington , d.c.: bm center for the business of government collaborating across boundaries series , 2011 .

lukensmeyer , carolyn j. , joe goldman , and david stern .

assessing public participation in an open government era: a review of federal agency plans .

washington , d.c.: ibm center for the business of government fostering transparency and democracy series , 2011 .

mckinsey & company .

“and the winner is…” capturing the promise of philanthropic prizes .

mckinsey & company , july 2009 .

mergel , ines .

“opening government: designing open innovation processes to collaborate with external problem solvers.” social science computer review vol .

33 , no .

5 ( 2015 ) : 599-612 .

mergel , ines and kevin desouza .

“implementing open innovation in the public sector: the case of challenge.gov.” public administration review vol .

73 , no .

6 ( november / december 2013 ) : 882 – 890 .

nabatchi , tina and matt leighninger .

“participation scenarios and tactics,” public participation for 21st century democracy .

hoboken , nj: 2015 , 241 – 285 .

nambisan , satish .

transforming government through collaborative innovation .

washington , d.c.: ibm center for the business of government innovation series , 2008 .

nambisan , satish and priya nambisan .

engaging citizens in co - creation in public services: lessons learned and best practices .

washington , d.c.: ibm center for the business of government collaborating across boundaries series , 2013 .

noveck , beth simone .

smart citizens , smarter state: the technologies of expertise and the future of governing .

cambridge , ma: harvard university press , 2015 .

office of management and budget , executive office of the president of the united states .

the common approach to federal enterprise architecture .

washington , d.c.: may 2 , 2012 .

office of science and technology policy , general services administration , and federal crowdsourcing and citizen science community of practice .

“federal crowdsourcing and citizen science toolkit,” adaptation of bonney et al. , “citizen science: a developing tool for expanding science knowledge and scientific literacy.” bioscience 59 ( 11 ) , 977-984 ( 2009 ) , accessed on january 26 , 2016. https: / / crowdsourcing - toolkit.sites.usa.gov / howto .

tong , raymond and karim r. lakhani .

public - private partnerships for organizing and executing prize - based competitions , research publication no .

2012-13 .

cambridge , ma: the berkman center for internet and society at harvard university , june 2012 .

