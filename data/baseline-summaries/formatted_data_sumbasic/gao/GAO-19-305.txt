securing the nation's borders against illegal entries , smuggling of drugs and contraband , and terrorist activities is a key part of the department of homeland security's ( dhs ) mission .

according to dhs , the united states has approximately 6,000 miles of land borders , 95,000 miles of coastline , and 328 ports of entry ( poe ) .

dhs's ability to measure border security activities , outputs , and outcomes is essential for the department to make evidence - based decisions about resource allocation and investments and manage its border security responsibilities effectively and efficiently .

in our prior work , we have reported on the need for dhs to improve its measures for assessing its border security efforts .

the national defense authorization act for fiscal year 2017 ( ndaa ) requires dhs to provide an annual report to appropriate congressional committees , the comptroller general , and certain other entities , containing 43 specific metrics to measure the effectiveness of border security in four domains — between poes , at poes , the maritime border , and with respect to aviation assets and other air and marine operations in the land domain .

the majority of the 43 metrics are counts and rates of border security activities , such as the number of detected unlawful entries between poes and a rate that measures traffic volume at land poes against the physical and staffing capacity at each land poe .

the remaining metrics are estimates , such as the number of undetected unlawful entries , or were not specifically described .

dhs issued its first report to respond to the ndaa requirement in may 2018 , titled border security metrics report .

the ndaa also includes a provision for us , within 270 days of receipt and biennially for the following 10 years , to review and report to congress on dhs's report .

specifically , the provision directs us to analyze the suitability and statistical validity of the data and methodology contained in the report , and , as appropriate , include recommendations on improvements needed to the metrics and the feasibility of other suitable metrics .

this report addresses the following questions: 1 .

to what extent has dhs reported metrics as outlined in the ndaa using quality information ? .

2 .

to what extent has dhs validated the assumptions and conveyed statistical uncertainty for its unlawful entry metrics ? .

3 .

what , if any , other metrics have been identified that may be used to measure the effectiveness of border security ? .

to determine the extent to which dhs reported metrics outlined in the ndaa using quality information , we first determined which of the 43 metrics dhs included in its first annual report and which it did not .

for metrics dhs included , we identified the specific data sources and sets dhs used to develop them , such as administrative data collected by dhs components ( eg , data on apprehensions , poe wait times , drug seizures , and flight hours ) .

we also interviewed officials from dhs offices and components involved in developing the metrics , including the office of immigration statistics ( ois ) , u.s. customs and border protection's ( cbp ) office of field operations , u.s. border patrol ( border patrol ) , and air and marine operations ( amo ) ; and the u.s. coast guard ( coast guard ) .

in these interviews we obtained information about the methodologies dhs components used to develop the metrics , including any limitations they identified and their plans to update or revise existing metrics in the future .

to determine the extent to which dhs reported metrics as outlined in the ndaa , we assessed how , if at all , the metrics dhs presented and the methods dhs used to calculate the metrics were similar to , or different from , the metrics listed in the ndaa .

where we identified clear differences between the metrics dhs reported and those described in the ndaa , we reviewed documentation and obtained additional perspectives from dhs officials , as necessary , to determine the reasons for the differences .

to determine the quality of the information used for the metrics , we assessed the extent to which dhs has processes to ensure data reliability and quality .

specifically , we reviewed any of our ongoing or completed work relevant to the metrics , relevant dhs office of inspector general ( oig ) reports , and the metrics included in dhs's annual performance reports to determine which data we had previously assessed or which had been assessed by the oig or dhs , and the results of those assessments .

for data that had not previously been assessed , we collected information from dhs to determine what processes are in place to ensure the overall reliability and quality of the data .

we reviewed this information to determine the extent to which dhs's processes are consistent with standards for internal control in the federal government , good practices for verifying and validating performance information we have identified in our prior work , and dhs's management directive on information quality .

to determine the extent to which dhs validated the assumptions and conveyed statistical uncertainty for its unlawful entry metrics , we first identified the metrics for which dhs utilized a statistical model ( i.e. , the use of a capture - recapture model to estimate the number of undetected unlawful entries ) .

we interviewed officials from dhs office of immigration statistics ( ois ) and the institute for defense analyses , dhs's contractor , to obtain information on the statistical model used to estimate unlawful border entry metrics , including assumptions made and how , if at all , they were validated .

we further analyzed dhs's use of the statistical model and compared it against practices for the use of statistical models outlined in the office of management and budget's ( omb ) standards and guidelines for statistical surveys .

using omb's standards , we identified principles and practices to determine the extent to which dhs's modeling was consistent with them and what , if any , improvements could be made .

we also analyzed dhs's modelling assumptions on the composition of the unlawful migrant population to determine the extent to which assumptions dhs made about the unlawful migrant population reflect data on individuals apprehended between poes .

we interviewed border patrol officials and reviewed documentation to obtain information on possible alternative approaches dhs is considering for modelling unobserved events .

to identify other metrics that may be used to measure the effectiveness of border security , we reviewed our prior work and dhs oig reports related to border security to identify open recommendations focused on establishing border security measures in the four domains listed in the ndaa .

we focused our search for prior work on reports that we and the dhs oig issued from 2010 through 2018 .

we conducted this performance audit from may 2018 to march 2019 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the ndaa requires dhs to develop and implement 43 border security metrics in four domains — between poes , at poes , the maritime border , and air and marine security in the land environment .

within dhs , cbp and the coast guard have primary responsibility for border security within these four domains .

cbp and its subcomponents are to secure u.s. borders at and between poes by preventing inadmissible people and illicit goods from entering the united states , among other responsibilities .

within cbp , the primary offices and components involved in border security are the office of field operations at poes , border patrol between poes , and air and marine operations for air and marine security in the land and maritime domains .

the coast guard and cbp's air and marine operations share responsibility for security of the nation's maritime borders .

table 1 shows examples of border security metrics by domain and responsible dhs component .

according to dhs officials , within dhs , two subcomponents within the office of strategy , policy , and plans were responsible for coordinating the department's effort to develop the fiscal year 2017 border security metrics report .

a senior dhs official explained that the report was initially tasked to the unity of effort integration office , which was part of the unity of effort initiative started in 2014 to better understand border security efforts along the southwest border including exploring the development of border security metrics .

ois assumed responsibility for the report in 2017 .

according to ois officials , to prepare the report , they obtained data and information related to each ndaa metric from the administrative records of the dhs components with primary responsibilities for border security in the four domains .

for example , ois requested data and information on “turn backs” and “got aways” from border patrol — the lead component for the between poe domain — which records sector estimates of turn backs and got aways based on direct and indirect observations .

of the 43 metrics the ndaa listed for inclusion in the border security metrics report , the majority were counts and rates of border security activities .

the remaining metrics were estimates or were not specifically described .

for example , the number of apprehensions in each border patrol sector is a count metric .

in contrast , a rate metric compares one value or number against another .

for example , the wait time ratio compares the average wait times to total commercial and private vehicular traffic volumes being processed at a land poe .

an estimate is used for metrics of flows or activities that are largely undetected and therefore cannot be measured directly and must be estimated , such as the number of undetected unlawful entries .

a few metrics are a combination of counts or rates with an estimate .

for example , the metric for total inadmissible travelers at poes counts known inadmissible travelers that are intercepted at poes , and also requires an estimate of how many inadmissible travelers may have successfully entered at a poe without being detected , which cannot be directly measured .

the ndaa did not specifically describe some metrics .

for example , while the ndaa asked for an examination of each of the eight consequences under the consequence delivery system , it did not specify how this examination was to be carried out or what it was to include .

while many of the metrics required by the ndaa can be addressed with data from dhs's administrative records , certain metrics that rely on estimates necessitate the use of alternative methodologies and in some cases , specialized technical expertise .

for example , dhs contracted with the institute for defense analyses to assist with the development of a statistical model for estimating undetected unlawful entries .

in its fiscal year 2017 border security metrics report , dhs provided information on its methodological approaches , such as how it estimated undetected unlawful entries .

in its first border security metrics report , dhs reported information on 35 of the 43 metrics called for by the ndaa .

the metrics dhs provided spanned the four domains outlined in the ndaa and included a mix of counts , rates , estimates , or a combination thereof as shown in figure 1 .

for 18 of the 35 border security metrics dhs included in its report , we found dhs generally included elements listed in the ndaa .

for example , the ndaa asked for the number of detected unlawful entries between poes , and in its report dhs provided information on the number of detected unlawful entries over a 10-year period .

as another example , the ndaa asked for the number of cargo containers at sea ports that were identified to be potentially high - risk .

in response , dhs provided information on the number of potentially high - risk containers from fiscal years 2013 through 2016 and also provided contextual information about trends in the volume of such containers over time .

see table 2 for more information on these examples as well as other examples of the types of information included in dhs's fiscal year 2017 border security metrics report .

for some metrics , dhs also provided information in addition to the elements listed in the ndaa .

for example , the ndaa described the “amo apprehensions assisted” metric as a count of the number of apprehensions that were assisted by cbp's amo through the use of unmanned aerial systems and manned aircraft .

in addition to the counts for such assists , dhs also provided data on the flight hours expended to assist with these apprehensions .

for 17 of the 35 reported metrics , we identified differences between the metric as described by the ndaa and as reported by dhs .

the differences we identified generally fell into two categories: metric differed in scope or calculation .

some of the metrics dhs reported on differed in scope or in their calculation from what the ndaa described for reasons such as data availability , among other factors .

for example , dhs's fiscal year 2017 border security metrics report scoped three metrics on unlawful border crossings between poes ( the “attempted unlawful border crosser apprehension rate,” the “estimated undetected unlawful entries,” and the “probability of detection rate” ) to only include data for the southwest border .

in these instances , the report noted that a methodology for estimating data on unlawful crossings for the northern border had not yet been completed but that research was underway to do so .

as an example of a difference in calculation , dhs presented the interdiction effectiveness rate for each southwest border sector as an alternative to the metric “unlawful border crossing effectiveness rate in each border patrol sector.” according to dhs's report , the department used the interdiction effectiveness rate because it had not yet produced and validated sector - level estimates of unlawful entries required to calculate the unlawful border crossing effectiveness rate .

in its report , dhs stated it expects these estimates to be available for the 2019 report .

alternative metric provided .

for the situational awareness in the maritime environment metric , dhs stated that it is in a multi - year process to develop a metric that meets the intent of the ndaa .

as an alternative , dhs instead provided data on the number of aircraft and vessel operational hours that contributed to maritime domain situational awareness .

see appendix i for additional information about any differences we identified for each metric .

the eight metrics on which dhs did not provide information spanned all four domains .

in its report , dhs explained that the eight omitted metrics were either still in development , under review within the department , or officials were in the process of collecting data for them .

table 3 lists the eight metrics on which dhs did not provide information and the date dhs estimated it will report on each metric .

in general , dhs components responsible for collecting the data used in the metrics dhs reported have processes to help ensure the reliability of the data and the quality of the information provided .

dhs also identified and disclosed limitations with some of the data elements or methodologies used for the metrics in its report .

however , dhs does not have a systematic process for reviewing the reliability of data to identify limitations related to the metrics , and we identified at least one additional limitation for 21 of the 35 metrics on which dhs reported where dhs did not disclose such limitations or could have been more transparent about the limitations or assumptions in its report .

data are considered reliable when they are reasonably free from error and bias .

quality information is derived from relevant and reliable data and is considered to be , among other things , complete , accurate , and timely .

the specific processes dhs components use to ensure data reliability vary from metric to metric .

examples of processes dhs or its components have implemented to help ensure the reliability of the data and the quality of information provided include: issuing guidance and monitoring implementation .

in september 2012 , border patrol headquarters officials issued guidance to help provide a more consistent , standardized approach for the collection and reporting of turn back and got away data by border patrol sectors .

each sector is individually responsible for monitoring adherence to the guidance .

according to dhs's report , command staff at border patrol stations ensure agents are aware of and utilize proper definitions for apprehensions , got aways , and turn backs at their respective stations and also ensure that the necessary communication takes place between and among sectors and stations to minimize double - counting when subjects cross over multiple areas of responsibility .

supervisory reviews of data entries .

with regard to data on amo vessel and aircraft missions , amo guidance mandates that supervisors perform a review of all pre - and post - mission data entries to help ensure accurate entry of mission information .

amo officials confirmed that supervisors review the data being entered into the database .

additionally , officials said amo data teams run monthly validation checks of data entered to check for completeness and accuracy , such as out - of - range values .

using built - in electronic safeguards .

cbp's databases for entering and maintaining data elements — including travelers or passengers seeking admission , known inadmissible aliens at poes , referrals for secondary examinations , major infractions , and private vehicles processed at a poe — have built - in processes to detect and prevent potential data entry errors .

more specifically , as an officer enters a record , the systems check for valid entries into relevant fields and provide an error message to the officer for entries that appear to be invalid ( eg , if an officer leaves a mandatory field blank or enters contradictory information such as charging an individual with a crime while also entering a request for expedited removal ) .

in some cases , the systems will prevent a record from being saved if any required fields are blank .

comparing data against other sources .

as part of the coast guard's data reliability processes for data on maritime migrant interdictions used in the “known maritime migrant flow rate” metric , coast guard officials said that analysts cross - check the data entered into their database with other coast guard reporting documents , such as internal spreadsheets , to ensure accuracy .

independent assessment of performance measure data .

some border security metrics are similar to , or use the same data elements as , performance measures dhs reports annually in response to the government performance and results act modernization act ( gprama ) of 2010 .

for those performance measures , dhs annually assesses a subset of measures and their data for completeness and reliability using independent review teams .

for example , in may 2017 an independent review team assessed the “migrant interdiction effectiveness in the maritime environment” performance measure , which uses the same data as the border security metric , “known maritime migrant flow rate.” the review team found the measure to be complete and reliable and the data to be of good quality overall , but also recommended that the coast guard and dhs continue work on an improved database to enhance the consistency of data collection , among other things .

in addition to the components having processes to help ensure the reliability of the data and the quality of the information used in the report , dhs took steps to be transparent in its presentation of the metrics by identifying and disclosing known limitations with some of the data elements or methodologies used for the metrics in its report .

communicating the extent to which such limitations exist and their potential impact is important to help facilitate the appropriate use and understanding of the data and the metrics .

dhs identified and disclosed limitations related to the potential for misclassification of observations , the potential for cases not being entered or recorded correctly , and methodological limitations , among other things .

for example , one of the key limitations dhs's report identified for the data on turn backs and got aways is that they are based on potentially subjective observations of agents who have to make a determination on how to classify them based on what they observed or the available evidence ( eg , tracks , sensor activations , interviews with apprehended subjects , camera views , etc. ) .

further , dhs's report explained that agents may face challenges in making that determination because some unlawful border crossers may enter the united states to drop off drug loads or to act as decoys to lure agents away from a certain area and then return to mexico , and therefore may be misidentified as turn backs , for example .

as another example , dhs identified limitations due to cases not being entered or recorded correctly .

for the “known maritime migrant flow rate” metric , dhs used data on the total number of maritime migrants interdicted .

in its report , dhs explained that a potential limitation of this data element is that the coast guard relies on international and domestic partners to report their interdictions for compilation in its database .

consequently , the accuracy and completeness of the data depend on whether those reports are made by those partners and the accuracy of their reports .

see appendix i for additional information about the limitations identified for each metric .

even as dhs identified and disclosed limitations related to some of its metrics , we identified at least one additional limitation for 21 of the 35 metrics on which dhs reported where dhs did not disclose such limitations or could have been more transparent about the limitations in its report .

examples of such instances include: potential for cases not being entered or recorded correctly .

in our previous work we found that mission data for unmanned aerial systems were inconsistently collected across operation locations .

specifically , in february 2017 we reported that there were instances where no assist information was recorded in amo's data system even though such assets participated in investigations and operations .

because amo's data may not reflect all asset assists , we recommended that amo update and maintain guidance for recording mission information in its data collection system and provide training to users of the system .

for its fiscal year 2017 border security metrics report , dhs used asset assists data in metrics such as the “amo individuals detected,” “amo apprehensions assisted,” and “illicit drug seizures assisted by amo,” but did not disclose this limitation in its report .

potential for data to be changed over time .

border patrol officials told us that data on the apprehension of unaccompanied alien children may change over time because original apprehension records from a shared database have , in some instances , been updated by staff from u.s. immigration and customs enforcement ( ice ) enforcement and removal operations ( ero ) .

officials said that in january 2015 they noticed that ero staff were inadvertently overwriting border patrol's original data entries about the status of apprehended children when they made updates to those children's records .

for example , if a child was unaccompanied at the time of his or her apprehension and was recorded as such by border patrol in the initial record entry , ero may have changed the “unaccompanied” status in the system after they matched the child with a family member or sponsor .

as a result , data may not be reconcilable with initial apprehension counts over time .

dhs did not fully disclose limitations for some metrics .

we identified instances where dhs could improve transparency about the assumptions or limitations of the data presented in its report .

for example , in 2014 border patrol implemented a standard , southwest border - wide methodology to improve reporting of turn backs and got aways .

while dhs made mention of this change in the text of the report , the data for these metrics are presented in tables without any table notes or disclosures within the table about this change .

further , dhs's report does not discuss how the change may affect comparability of the data .

consequently , a reader may not be aware that data for before 2014 in a table are not necessarily comparable to the data for 2014 and after in the same table .

without a comprehensive identification of the limitations of the metrics and their associated data , and without an adequate disclosure of those limitations , the value of dhs's report as a source of information to congress , policymakers , and the public may be diminished .

the metrics in the report were specifically identified and requested by congress in the ndaa , and provide congress with important information about the outputs and outcomes of dhs's border security policies and investments that could be used to inform decision - making .

however , those reading the report may not be aware of important contextual information because dhs did not identify and disclose some limitations , thereby creating the potential for the data to be misinterpreted .

according to dhs officials who prepared the report , while they took steps to identify methodological limitations of the metrics , no process currently exists to systematically review the reliability of operational data used for public reporting purposes , such as in the metrics report .

specifically , dhs officials within ois told us that while they were responsible for leading and managing the preparation of the report , they largely relied on the dhs components from which they collected the data to assess the data's reliability and communicate identified limitations .

ois officials explained that many of the data elements used , such as those from amo or the coast guard , were ones with which they were not familiar or had not worked with previously in their area of immigration statistics .

ois officials also noted that in some cases , the data had previously been used in performance measures or had been collected and tracked for several years , so they trusted the components' processes for ensuring their reliability and identifying limitations , but reviewed the data provided where possible and consulted with the components as needed .

however , ois officials said that while they included as much information in the report as was known about identified limitations with the existing operational data , no additional effort was made to systematically review the underlying reliability of the data to comprehensively identify limitations that should be acknowledged when publicly reported because no department - wide process exists to do so .

standards for internal control in the federal government state that management officials should evaluate data sources for reliability and communicate quality information , including relevant data from reliable sources , to achieve an agency's objectives .

the quality information can then be used by agency management and external stakeholders such as policymakers , to make informed decisions and evaluate performance , among other things .

further , dhs's management directive on information quality states that data and information disseminated by the department should , among other things , have full , accurate , transparent documentation , and error sources affecting data quality should be identified and disclosed to users .

additionally , our previous work on approaches for verifying and validating performance information found that communicating significant data limitations and their implications allows stakeholders to judge the data's credibility for their intended use and to use the data in appropriate ways .

by developing and implementing a process to systematically review the reliability of the data or consider the results of assessments components have completed , comprehensively identify any limitations , and communicate the data or methodological limitations with the metrics , dhs would improve the quality of the information available to congress , dhs leadership , and the public .

doing so would also facilitate a better understanding and appropriate interpretation and use of the data in the context of the border security metrics report , thereby enhancing the report's value as a source of information for future decision - making .

based upon statistical modelling , dhs developed a model - based apprehension rate to calculate the total number of unlawful border entries between land poes , including entries both detected by border patrol and “estimated undetected unlawful entries.” dhs reported that in fiscal year 2016 there were about 624,000 detected entries ( which include apprehensions , turn - backs , and got aways ) and estimated that there were about 62,000 undetected unlawful entries .

dhs also used the model - based apprehension rate to develop two other metrics in the fiscal year 2017 border security metrics report: ( 1 ) a “probability of detection rate,” which is the estimated proportion of the number of detected unlawful border entries to the total number of unlawful entries between land poes .

dhs estimated that in fiscal year 2016 , 91 percent of unlawful border crossers were detected and 9 percent were not detected .

 ( 2 ) the “attempted unlawful border crosser apprehension rate,” which is the estimated proportion of unlawful border entrants apprehended by border patrol to the total number of unlawful entrants between land poes .

dhs estimated that in fiscal year 2016 , 65 percent of individuals were apprehended by border patrol and 35 percent of individuals attempting an unlawful border entry either got away or entered the united states undetected .

dhs based its statistical model upon research conducted by the institute for defense analyses that leveraged long - standing research using capture - recapture models .

originally developed and utilized in biological and ecological sciences , capture - recapture models have been applied to other disciplines , including social science .

according to the institute for defense analyses , capture - recapture models have been the core approach for academic efforts to model the process of unlawful entry into the united states across land borders for several decades .

to develop its statistical model , dhs used a capture - recapture methodology to calculate a probability of apprehension by counting the number of unlawful border crossers that were apprehended multiple times .

at a high - level , capture - recapture involves taking an initial sample of the population of interest , in this case individuals attempting to cross the border unlawfully .

then , separately , a second , independent sample of the same population is taken .

the samples are then compared to determine the number of individuals who appear in both samples .

when the number of individuals who appear in both samples ( eg , individuals who have been apprehended twice ) is low , it can be inferred that the overall population of interest ( eg , total unlawful border crossers ) is much larger than the total number of individuals in the two samples .

on the other hand , if the recapture rate is high , then it can be inferred that the overall population of interest is not much larger than the total number of individuals in the two samples .

in the context of unlawful border crossing , when an individual's first attempt at unlawfully crossing the border is successful , the individual enters the united states and no apprehension is made .

however , if an individual is apprehended , border patrol records an apprehension of this individual in a dhs data system and the individual is potentially subject to consequences for entering unlawfully , such as administrative enforcement and removal , criminal prosecution , or being barred from legally entering the united states in the future .

the individual is then returned to his or her home country , where the individual can then choose whether or not to make another attempt to unlawfully cross the border .

during a second attempt to unlawfully cross the border , the individual faces the same possible outcomes ( enter the united states unlawfully or apprehension by border patrol ) .

figure 2 provides the framework for dhs's model - based apprehension rate .

dhs modified the traditional capture - recapture methodology by calculating a deterrence rate of 60 percent in fiscal year 2016 to account for individuals who choose not to make another unlawful border crossing attempt .

the deterrence rate accounts for an individual being deterred from attempting to unlawfully cross the border again ; that is , dhs assumed that some percentage of apprehended individuals , once returned to their country , will remain in their home country .

dhs calculated the deterrence rate based upon a survey of mexican individuals who were apprehended and returned to the border region of mexico by u.s. immigration authorities .

dhs assumed the remaining 40 percent of individuals who were apprehended and removed to their home country in fiscal year 2016 remain undeterred and will attempt to unlawfully cross the border again .

historically , dhs ( and its predecessor the immigration and naturalization service ) did not use statistical models to calculate an apprehension rate but relied on apprehensions as a proxy measure for all unlawful entries ( both observed and unobserved ) between poes .

dhs also included in its report information on the apprehension rate using this method .

specifically , dhs also calculated an observational apprehension rate based on direct observations ( unlawful border crossers observed by border patrol ) and indirect observations ( residual evidence of a border crosser , i.e. , footprints ) of attempted unlawful border crossers .

using the observational apprehension rate , dhs calculated that in fiscal year 2016 , it apprehended 79 percent of unlawful border crossers .

dhs made assumptions about border crossers to develop its statistical model and described these assumptions in its report ; however , dhs did not validate some of these assumptions or determine how they potentially could affect the accuracy of the model - based apprehension rate through the use of sensitivity analyses .

more specifically , dhs's model incorporates several assumptions related to border crossers .

among others , these assumptions include: the rate at which individuals will be deterred from crossing again remains the same , regardless of the number of attempts an individual has made ; individuals who indicate an intent to stay near the u.s. - mexico border will attempt re - entry ; a single apprehension rate applies to diverse groups of border crossers , regardless of their nationality or the number of attempts an individual has made ; and certain individuals will not evade border patrol .

however , the validity of some of these assumptions — which affect the model - based apprehension rate — is uncertain .

for example , dhs's model estimates the rate at which a diverse group of border crossers attempting to evade detection will be apprehended by border patrol .

this group includes both mexicans and non - mexicans and individuals who attempt to cross again after varying amounts of time .

despite this diversity , the model assumes that all crossers have the same chance of apprehension on each attempt to cross the border .

this assumption allows dhs to apply the estimated apprehension rate developed based on a sample of mexicans re - apprehended within 90 days — the group for whom relevant data exist — to a broader population of individuals regardless of the number of attempts the border crossers have made or their nationality .

however , dhs did not make efforts to determine the extent to which an apprehension rate based on mexican citizens re - attempting entry within 90 days would reflect apprehension rates for non - mexicans and individuals crossing again after longer periods .

additionally , dhs assumes that the apprehension rate never varies between an individual's attempts at crossing the border .

for example , dhs assumes that an individual making a first attempt at crossing the border faces the same odds of apprehension as an individual making a fourth or fifth attempt at crossing the border .

however , dhs has not explored the possibility that , for example , individuals may gain experience and knowledge from border - crossing attempts that could help them better evade border patrol on subsequent attempts .

further , dhs's model assumes that certain individuals unlawfully crossing the border , such as those seeking asylum , will not evade apprehension and will turn themselves in to border patrol .

specifically , in addition to individuals who ultimately do seek asylum , dhs also includes within this group and applies this assumption to individuals apprehended as a family unit and unaccompanied minors .

under this assumption , 100 percent of such individuals are apprehended .

according to dhs's fiscal year 2017 border security metrics report , these individuals have historically been released into the united states with a notice to appear in immigration court for legal proceedings on a future date , rather than being subject to immediate dhs enforcement consequences such as voluntary return .

therefore , dhs assumes that 100 percent of these individuals will self - present to border patrol because , in doing so , they are able to claim asylum or other protection and potentially remain in the united states .

however , representatives from the institute for defense analysis stated that while anecdotally self - presenting rates of these individuals are high , more rigorous analysis is needed to accurately estimate a self - presentation rate .

for example , it is possible that not all families crossing the border unlawfully may seek to self - present to border patrol ; some may attempt to evade capture and enter the united states undetected .

in this case , dhs may be underestimating the number of individuals who unlawfully cross the border and enter the united states by assuming 100 percent of these individuals will self - present to border patrol agents .

additionally , dhs noted in its fiscal year 2017 border security metrics report that this assumption does not reflect the actual behavior of all border crossers in this group .

ois officials stated that they based this assumption on interviews with border patrol agents but had not done formal or quantitative analysis to support this assumption .

further , ois officials stated that they did not have a strong alternative assumption to use instead and therefore assumed that 100 percent of individuals within this group are apprehended .

dhs described these assumptions in its report but did not provide quantitative information on the extent to which these assumptions affected the model - based apprehension rate through the use of sensitivity analyses .

sensitivity analyses help to convey the extent to which changing the values of variables , assumptions , data , or other input affects statistical estimates .

for example , sensitivity analyses could provide information on how different assumptions about unlawful border crossers' behavior and other inputs to the statistical model could have affected the model - based apprehension rate .

ois officials stated that while they had started to run sensitivity analyses by modifying certain assumptions , they had not completed the analysis and did not include results of the sensitivity analyses in the report .

the office of management and budget's ( omb ) statistical standards for federal agencies include providing the results of sensitivity analyses for key methodological assumptions to ensure that these assumptions do not unduly affect the results of the model .

by including the results of sensitivity analyses in its border security metrics report , dhs would allow congress and the public to better understand the potential limitations associated with its model and make independent assessments on its accuracy .

dhs used a statistical model to develop the model - based apprehension rate but did not provide information on the level of uncertainty related to this estimate .

rather , the fiscal year 2017 dhs border security metrics report provided a single rate that does not fully convey the difficulty and uncertainty of estimating partially unobserved metrics , such as unlawful entries and the probability of detection .

specifically , using the model - based apprehension rate , dhs estimated that 65 percent of unlawful border crossers were apprehended in fiscal year 2016 , and the remaining 35 percent entered the united states .

however , like all statistical models , dhs's estimate is based upon a limited sample of data and may be affected by random variation , meaning that dhs does not have complete certainty that its rate is accurate .

dhs included a discussion of limitations in the report but did not quantify its degree of uncertainty .

according to the omb statistical standards for federal agencies , possible variation in estimates should be noted , such as by reporting the range of each estimate .

measures of statistical uncertainty , such as margins of error or confidence intervals , help to convey the amount by which estimates might vary due to randomness in the data and allows consumers of the estimates to evaluate their accuracy .

ois officials stated that they agree that providing measures of statistical uncertainty would help congress and the public better understand the model - based apprehension rate to evaluate border security .

officials told us that the office had begun to develop measures of statistical uncertainty but did not complete this effort because the staff member who was working on the analyses recently left the office .

further , ois officials stated that they were unsure when they would be able to provide measures of statistical uncertainty in future reports .

including measures of statistical uncertainty in future reports would allow congress , policy makers , and the public to more fully evaluate the extent to which the metrics that use the model - based apprehension rate are valid .

further , while dhs may ultimately adopt a new , simulation - based model in the future , described later in this report , it plans to use the current model - based apprehension rate for estimates in its border security metrics report for the foreseeable future .

therefore , providing this additional information about the estimates would allow dhs to more accurately convey how limitations in available data and methods could affect the results and provide more useful information about migration and border enforcement .

additionally , to the extent dhs adopts a new estimating metric , that estimate may have some level of uncertainty associated with it .

dhs is developing another model because its current statistical model may not sufficiently reflect conditions at the southwest border .

specifically , dhs's current statistical model does not fully account for the changing population of unlawful border crossers .

the capture - recapture methodology , which underlies the model - based apprehension rate , was developed to sample homogenous populations that behave in set , uniform ways .

however , those crossing the border have become increasingly diverse in recent years .

our analysis of dhs data used to develop the model - based apprehension rate shows that the number of unlawful border crossers whose characteristics and behavior are best reflected in the statistical model has declined .

for example , our analysis illustrated that the population that conforms best to the model's assumptions — adult mexicans travelling without dependents who do not plan to claim asylum and who are returned to mexico in a short amount of time — has fallen from over 60 percent of apprehensions in fiscal year 2000 to less than 25 percent of apprehensions in 2016 , as shown in figure 3 .

conversely , the number of individuals who are excluded from the statistical model such as non - mexicans , and individuals whose behavior may not reflect the model's assumptions , such as asylum - seekers or those who have not departed the united states ( eg , because they are awaiting immigration court proceedings ) have increased over time , as shown in figure 4 .

for example , the percentage of individuals apprehended at the border who are excluded from the model because they await immigration court proceedings increased from 26 percent in fiscal year 2000 to almost 70 percent in fiscal year 2016 .

dhs acknowledged these trends in its fiscal year 2017 border security metrics report and noted them as a limitation to the effectiveness of its model .

ois officials further noted that some of these limitations are difficult to address within the bounds of the statistical model .

for example , to properly account for non - mexicans , ois officials stated that they would need information on the rate at which non - mexicans are deterred from crossing the border .

however , it would be difficult and costly to obtain this information through the use of a survey and real - world data does not already exist , according to ois officials .

to help address limitations of its current statistical model , dhs has invested in another research project to estimate the number of unlawful border crossers between land poes , including unknown border entries .

border patrol contracted with johns hopkins applied physics laboratory to undertake a project that aims to use a combination of statistical modeling and data from sensors along the border to estimate the total number of unlawful border entries between land poes , including entries both detected by border patrol and those not detected by border patrol .

according to project documentation we reviewed , the project plans to leverage the cbp tactical simulation , an agent - based simulation of tactical border operations .

cbp tactical simulation incorporates information on terrain at the border based on geographic information systems and sensors along with probability models that reflect how border patrol agents and unlawful border crossers behave in given circumstances .

border patrol and ois officials told us that this project would be more adaptable to changing border conditions and could help the agency address limitations associated with the model - based apprehension rate .

specifically , according to ois officials , a simulation - based estimate would rely upon fewer assumptions about the types of individuals who unlawfully cross the border as compared to the current model - based apprehension rate .

however , border patrol officials noted that estimates of unobservable phenomena , such as unobserved border entries , always face some limitations in their accuracy and that the new model may still rely upon samples of data that would have associated uncertainty as well as assumptions that would need to be validated .

ultimately , though , border patrol officials stated that the simulation - based model may be an improvement upon the current model - based apprehension rate .

border patrol officials stated that the first iteration of the model would be presented to border patrol leadership for their review at the end of fiscal year 2019 and if at that time border patrol leadership approves the model , the earliest the simulation - based estimate could potentially be incorporated into the dhs border security metrics report would be for fiscal year 2020 .

exploring alternative models is a positive step for dhs , however given that the project is in the early stages , it is too early to tell if it will be able to address the limitations we identified associated with the current model .

in addition to the ndaa metrics , we have identified other metrics that dhs could use to help measure the effectiveness of border security .

in particular , based on the findings from our previous reviews of border security programs and efforts , we have recommended that dhs use metrics that are relevant to each of the four domains listed in the ndaa — between poes , at poes , the maritime border , and for air and marine security in the land domain .

for example , between poes domain .

in february 2017 , we reported on the use of border fencing along the southwest border and found that cbp collects data that could help provide insight into how border fencing contributes to border security operations , including the location of illegal entries .

for example , we found that cbp collects data it could potentially use to determine the extent to which border fencing diverts illegal entrants into more rural and remote environments , and border fencing's impact , if any , on apprehension rates over time .

however , cbp had not developed metrics that systematically use these data to assess the contributions of border fencing to its mission .

to better position cbp to make resource allocation decisions with the best information available to inform competing mission priorities and investments , we recommended that the chief of the border patrol develop metrics to assess the contributions of pedestrian and vehicle fencing to border security along the southwest border using cbp data .

dhs agreed with the recommendation and stated that it planned to develop metrics for use in its operational control framework for southwest border security operations .

as of october 2018 , dhs stated that the department planned to test the metrics and implement them in the framework by september 2019 .

at poes domain .

in july 2017 , we reported on the importer security filing ( isf ) program and found that while isf rule data have improved the program's ability to identify high - risk cargo shipments , cbp could collect additional performance information to better evaluate program effectiveness .

while evaluating the direct impact of using isf rule data to assess shipment risk is difficult , we identified examples of how cbp could better assess the isf program's effectiveness .

for example , cbp could track the number of containers not listed on a manifest — which could pose a security risk — it identifies through reviewing vessel stow plans .

collecting this type of additional information would help cbp better assess whether the isf program is improving its ability to identify high - risk shipments .

therefore , we recommended that cbp identify and collect additional performance information on the impact of the isf rule data , such as the identification of shipments containing contraband , to better evaluate the effectiveness of the isf program .

dhs agreed with the recommendation and reported that it is working to assess additional performance metrics to evaluate the effectiveness of the isf program and anticipates completing the assessment by end of december 2019 .

maritime border domain .

in october 2017 , we reported on the coast guard's performance goals and found that although the coast guard's performance goals are generally aligned with its statutory missions , the coast guard does not explain why certain aspects of mission performance are measured while others are not .

for example , we found that while the coast guard's mission is to interdict all illegal drugs , the agency's two performance goals related to that mission were for cocaine interdiction only , excluding many other substances .

we recommended that the coast guard either develop new performance goals to address mission activity gaps , or explain in the coast guard's annual performance report why certain aspects of mission performance are measured while others are not .

developing new goals to address missions , or describing how existing goals sufficiently assess mission performance , could better convey the coast guard's progress in achieving its missions .

dhs agreed with the recommendation and in february 2018 , the coast guard provided us with its updated fiscal year 2017 annual performance report .

we found that while the updated report explained why performance goals related to its drug interdiction mission focus solely on cocaine interdiction , for the four other performance goals we previously identified as not fully addressing all related mission activities , the updated report did not include additional goals or explain why certain aspects of mission performance are not measured .

we continue to believe that in instances in which performance goals do not fully address all of the respective mission activities , the coast guard's annual performance report should include an explanation .

air and marine security in the land domain .

in may 2017 , we reviewed dhs's efforts to address subterranean , aerial , and maritime smuggling of drugs and humans .

we found that while dhs established high - level performance measures and collected data on smuggling by ultralight aircraft , it had not assessed its efforts specific to addressing this smuggling method .

additionally , we found that dhs had similarly not assessed smuggling methods such as tunnels , panga boats ( a fishing vessel ) , and recreational vessels .

we recommended that dhs direct cbp , ice , and coast guard to establish and monitor performance measures and targets related to ultralight aircraft , cross - border tunnels , panga boats , and recreational vessel smuggling to help provide reasonable assurance that efforts to address these smuggling methods are effective .

by establishing measures and monitoring performance against targets , managers could obtain valuable information on successful approaches and areas that could be improved to help ensure that technology investments and operational responses to address these smuggling methods are effective .

dhs agreed with the recommendations for measures related to ultralight aircraft and cross - border tunnels .

dhs reported that amo and border patrol have drafted a performance measure for ultralight aircraft , however , reviews and approval of the measure will not be completed until november 2019 .

as of june 2018 , dhs reported that ice was leading the development of measures related to cross - border tunnels .

dhs did not agree with the recommendation to establish measures and monitor performance against targets for smuggling by panga boats and recreational vessels because the department believed measures and targets would not provide the most useful strategic assessment of operations to prevent all illicit trafficking , regardless of area of operations or mode of transportation .

we continue to believe that the recommendation is valid and recognize the value of high - level strategic performance measures .

however , such high - level measures may not provide sufficiently detailed performance information to allow dhs to identify successful approaches to addressing smuggling by panga boats and recreational vessels and areas for improvement .

further , establishing performance measures and targets related to smuggling by panga boats and recreational vessels could , in turn , better position dhs to understand the overall smuggling threat .

appendix ii provides additional information on these and other metrics we have previously recommended that dhs could use to help measure the effectiveness of border security in the four domains .

securing u.s. borders is a complex undertaking that spans multiple domains and locations .

it is also a key part of dhs's mission for which dhs has made significant investments over the years .

given the complexity and breadth of border security efforts , having data and information available on the state of border security is important for dhs as well as policymakers and the public to understand the effectiveness of those investments .

dhs's fiscal year 2017 border security metrics report makes an important contribution in providing such data and information .

dhs components generally have processes to help ensure the reliability of the data used in the metrics report and dhs identified and disclosed some data and methodological limitations with the metrics .

however , dhs did not systematically review the reliability of data used in all metrics to identify and disclose limitations and their potential implications for the metric .

without complete information about the limitations of the data or the metric methodologies used in the report , congress , policymakers , and the public may not be aware of important context or information needed to fully and appropriately understand the data being presented .

by developing and implementing a process to systematically review the reliability of the data , as well as comprehensively identify limitations and communicate limitations of the metrics , dhs would improve the quality of the data and information provided in the report which would facilitate a better understanding and appropriate interpretation of the data and information provided .

to develop three metrics in the report , dhs used a statistical model that incorporated untested assumptions about the behavior of unlawful border crossers that may not reflect real - world conditions .

dhs was transparent about the limitations of its model , but providing the results of sensitivity analyses and measures of statistical uncertainty related to the model would allow congress , policymakers , and the public to better understand its potential limitations and more fully evaluate the validity of dhs's metrics that use estimates .

we are making the following four recommendations to dhs: the secretary of homeland security should develop and implement a process to systematically review the reliability of the data used in its border security metrics report and comprehensively identify any limitations with the data and methodologies that underlie its metrics .

 ( recommendation 1 ) the secretary of homeland security should ensure the communication of the limitations of the metrics identified through the systematic review in the department's annual border security metrics report .

 ( recommendation 2 ) the under secretary for the office of strategy , policy , and plans should include the results of sensitivity analyses to key assumptions in its statistical models of unlawful entry estimates in its annual border security metrics report .

 ( recommendation 3 ) the under secretary for the office of strategy , policy , and plans should include measures of statistical uncertainty for all metrics based on estimates derived from statistical models in its annual border security metrics report .

 ( recommendation 4 ) .

we provided a draft of this report to dhs and the office of national drug control policy for review and comment .

dhs provided written comments , which are reproduced in appendix iii and discussed below .

dhs also provided technical comments , which we incorporated as appropriate .

the office of national drug control policy indicated via e - mail that it did not have any comments on the draft report .

in its comments , dhs concurred with our recommendations and stated that it planned to implement 3 of the 4 by october 2020 .

with respect to our second recommendation , dhs requested that we consider it closed as implemented because the department already detailed some of the limitations in its fiscal year 2017 report , and plans to continue to identify known limitations and the progress made to mitigate previously identified limitations in future reports .

as discussed in this report , we agree that dhs identified and disclosed limitations for some metrics in its fiscal year 2017 border security metrics report ; however , we identified at least one additional limitation for 21 of the 35 metrics on which dhs reported that dhs did not disclose or about which it could have been more transparent .

to address the intent of this recommendation , once dhs has implemented a process to systematically review the reliability of the data used in its report and comprehensively identified related limitations , it should disclose those limitations in its annual border security metrics report .

we are sending copies of this report to the appropriate congressional committees and the secretary of the department of homeland security .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

contacts points for our offices of congressional relations and public affairs may be found on the last page of this report .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-8777 or gamblerr@gao.gov .

gao staff who made key contributions to this report are listed in appendix iv .

this appendix provides additional information on our analysis of the suitability and validity of the metrics the department of homeland security ( dhs ) reported in its fiscal year 2017 border security metrics report for each of the four domains listed in the national defense authorization act for fiscal year 2017 ( ndaa ) — between ports of entry , at ports of entry , the maritime border , and air and marine metrics in the land domain .

specifically , this appendix provides information on the metrics including their status , descriptions , differences between what dhs reported for the metrics and how they were described or defined by the ndaa , limitations , and any additional information or planned actions by dhs , where applicable .

description this metric is a rate comparing apprehensions to the total number of attempted unlawful border crossers .

as such , this metric requires an estimate of the number of unlawful entry attempts that are not detected , which is added to the number of detected unlawful border crossers to create the denominator .

the department of homeland security ( dhs ) provided two methods for calculating this rate in its report .

the first method , called the model - based apprehension rate , uses a statistical model based on the capture - recapture methodology to estimate the rate.the second method , called the observational apprehension rate , calculates the ratio of apprehensions to the sum of apprehensions and got aways .

unlawful entries is limited to the southwest border .

according to the report , research is underway on methods to produce estimates for the northern border .

limitations the observational apprehension rate incorporates data on apprehensions , and got aways , while the model - based apprehension rate is based on an estimate for undetected unlawful entries .

consequently , the limitations for those metrics also apply here .

for more information on the limitations for those metrics , see the respective sections below .

dhs identified: the observational apprehension rate excludes unobserved got aways .

additional information and planned actions by the department of homeland security in its report , dhs noted that it has taken steps to improve situational awareness along the border and mitigate limitations .

these steps include investing in technology , refining observational estimates , and developing a methodology to estimate statistical reliability .

according to u.s. border patrol officials , investments in new technology have enabled u.s. border patrol to better detect cross - border activities .

for additional information on the data elements used for this metric and dhs's planned actions , see the respective sections below on apprehensions , got aways , and the estimate for undetected unlawful entries .

description this metric is a count of the total number of attempted unlawful border crossers between land ports of entry who were directly or indirectly observed or detected by u.s. border patrol .

the department of homeland security ( dhs ) calculated this metric by adding turn backs , got aways , and apprehensions of unlawful border crossers .

patrol officials , the northern border has different immigration dynamics than the southern border and accounts for a significantly smaller number of turn backs and got aways overall , so northern border data were not included .

limitations because this metric incorporates data on apprehensions , got aways , and turn backs , the limitations for those metrics also apply here .

for more information on the limitations for those metrics , see the respective sections below .

additional information and planned actions by the department of homeland security for additional information on the data elements used for this metric and dhs's planned actions , see the respective sections below .

description this metric is an estimate of the number of attempted unlawful border crossers that are not directly or indirectly observed or detected by u.s. border patrol ( border patrol ) .

the department of homeland security ( dhs ) used a statistical model , based on capture - recapture methodology , to estimate total successful unlawful entries , and subtracted detected got aways to calculate the total number of undetected unlawful entries .

unlawful entries is limited to the southwest border .

according to dhs's report , research is under way to produce this estimate for the northern border .

dhs does not currently have reliable data on the estimated share of migrants who , following an unsuccessful unlawful entry attempt , are deterred from making a subsequent reentry attempt .

for its model , dhs used data from a survey of recently removed mexicans , which asked them about their intentions to re - enter the united states .

according to dhs's report , a shortcoming of the survey is that it does not take account of shifting border enforcement efforts , potential changes in behavior by individuals who have been exposed to consequence programs , or other deterrent factors along the border .

consequently , any resulting undercount in the estimate of the deterred population results in a downward bias .

the population that conforms best to the model's assumptions represents a diminishing share of southwest border apprehensions .

specifically , in its report dhs said that mexican adults removed to the nearest border accounted for about 95 percent of apprehensions in the 1990s .

however , because of recent changes at the border , including changes in the composition of border flows ( i.e. , rising numbers of central americans and asylum seekers ) and in border patrol's enforcement strategy , the population best reflected in the model has declined to as few as 20 percent of apprehensions in recent years .

further , dhs noted that some alien populations , such as those seeking asylum and who do not evade detection by border patrol agents , are also excluded from the model .

however , these populations make up an increasing share of apprehensions in recent years .

the model uses restrictive assumptions about which re - apprehensions to include .

for example , the model excludes apprehensions occurring at check points and other remote locations and those occurring more than 4 days after an illegal entry .

according to dhs , these assumptions result in a downward bias .

we identified: dhs described assumptions it made in its report but did not provide quantitative information on the extent to which they affected its estimated undetected unlawful entries through the use of sensitivity analyses .

sensitivity analyses help to convey the extent to which changing the values of variables , assumptions , data , or other input affects statistical estimates .

by including the results of sensitivity analyses in its border security metrics report , dhs would allow congress and the public to better understand the potential limitations associated with its model and make independent assessments on its accuracy .

dhs did not provide information on the statistical level of uncertainty related to this rate , such as margins of error or confidence intervals .

this information would help convey how the estimates might vary due to randomness in the data .

instead , dhs provided a single rate that does not fully convey the difficulty and uncertainty of the estimate .

this metric incorporated data on apprehensions and got aways .

for more information on the limitations associated with those metrics , see the respective sections below .

additional information and planned actions by the department of homeland security according to dhs , officials are continuing to improve the accuracy of the existing statistical model for estimating unlawful border crossers but are also considering alternative methodologies .

u.s. customs and border protection has contracted with johns hopkins applied physics laboratory to develop a new model for estimating the flow of unlawful border crossers .

this model uses a combination of statistical modelling , data from sensors along the border , and probability models that reflect how border patrol agents and unlawful border crossers behave in given circumstances .

border patrol officials estimated that the earliest the simulation - based estimate could potentially be incorporated into the dhs border security metrics report would be for fiscal year 2020 .

description this metric is a count of the number of unlawful border crossers who , after making an unlawful entry into the united states , responded to law enforcement efforts by returning promptly to the country from which they entered .

these data came from u.s. border patrol ( border patrol ) records .

border patrol officials , the northern border has different immigration dynamics than the southern border and accounts for a significantly smaller number of turn backs overall , so northern border data were not included .

officials stated that while the current emphasis of reporting is on the southwest border , efforts are underway to identify and find ways to capture data that are important and reflective of the effectiveness in addressing threats specific to the northern border .

the estimate aggregates potentially subjective observations from thousands of individual agents .

some unlawful border crossers may enter the united states to drop off drug loads or to act as decoys to lure agents away from a certain area and then return to mexico , and therefore may be misidentified as turn backs .

in our previous work we identified differences in the procedures for reporting and classifying turn backs across sectors , and noted how factors such as terrain and weather may impact agents' abilities to accurately detect turn backs .

according to dhs , since 2014 , border patrol has implemented a standard , southwest border - wide methodology to improve reporting and mitigate the potential subjectivity of observations by agents .

therefore , data before 2014 are not necessarily comparable to data from 2014 and later .

dhs presented the data in a table without explaining that the methodology used to categorize and count turns backs changed in 2014 .

additional information and planned actions by the department of homeland security according to dhs's report , border patrol has taken steps to implement a standard , southwest border - wide methodology to improve reporting of potential turn backs .

in addition , dhs's report said that command staff ensure all agents are aware of and utilize proper definitions for apprehensions , got aways , and turn backs at their respective stations .

they also ensure necessary communication takes place between and among sectors and stations to minimize double - counting when subjects cross through more than one station .

dhs's report noted that border patrol headquarters components validate data integrity .

description this metric is a count of the number of unlawful border crossers who are directly or indirectly observed entering unlawfully , are not apprehended , and are not turn backs .

these data came from u.s. border patrol ( border patrol ) records .

border patrol officials , the northern border has different immigration dynamics than the southern border , so northern border data were not included .

officials stated that while the current emphasis of reporting is on the southwest border , efforts are under way to identify and find ways to capture data that are important and reflective of the effectiveness in addressing threats specific to the northern border .

limitations dhs identified: the count aggregates potentially subjective observations from thousands of individual agents .

in previous work we identified differences in procedures for reporting and classifying got aways across sectors , and noted how factors such as terrain and weather may impact agents' abilities to accurately detect got aways .

according to dhs , since 2014 , border patrol has implemented a standard , southwest border - wide methodology to improve reporting and mitigate the potential subjectivity of observations by agents .

therefore , data before 2014 are not necessarily comparable to data from 2014 and later .

dhs presented the data in a table without explaining that the methodology used to categorize and count turns backs changed in 2014 .

for information on limitations with the model - based estimate for undetected unlawful entries , see the section for estimated undetected unlawful entries above .

additional information and planned actions by the department of homeland security according to dhs's report , border patrol has taken steps to implement a standard , southwest border - wide methodology to improve reporting of potential got aways .

in addition , dhs's report said that command staff ensure all agents are aware of and utilize proper definitions for apprehensions , got aways , and turn backs at their respective stations .

they also ensure necessary communication takes place between and among sectors and stations to minimize double - counting when subjects cross through more than one station .

dhs's report noted that border patrol headquarters components validate data integrity .

as a comparison against the counts of documented got aways , dhs also provided an estimate of total successful unlawful entries along the southwest border using a statistical model based on capture - recapture methodology .

for more information on the methodology for this estimate , see the section titled “estimated undetected unlawful entries” in this appendix .

description this metric is a rate comparing the number of apprehensions and turn backs to the number of apprehensions , estimated undetected unlawful entries , turn backs , and got aways in each u.s. border patrol sector .

rate is not available because sector - level estimates of unlawful entries and attempts have not yet been produced and validated .

as an alternative , dhs presented data using the interdiction effectiveness rate .

with this rate , the estimated undetected unlawful entries measure is replaced with known got aways .

however , dhs does not have an interdiction effectiveness rate for the northern border so it solely provided data for the southwest border .

according to dhs's report , the department has not yet developed a northern border interdiction effectiveness rate because there are only a small number of attempted and successful entries along the northern border .

limitations none identified .

additional information and planned actions by the department of homeland security dhs reported that sector - level estimates of unlawful entries and attempts are projected to be available in its 2019 annual border security metrics report to congress .

authorization act for fiscal year 2017 ( ndaa ) defined this metric as a rate comparing the estimated total undetected unlawful border crossing attempts to the unlawful border crossing effectiveness rate .

the department of homeland security ( dhs ) calculated this metric by dividing the detected unlawful entries by the estimated total unlawful entries .

the number of detected unlawful entries is calculated by adding turn backs , got aways , and apprehensions .

estimated total unlawful entries is calculated by adding turn backs , apprehensions and estimated total successful unlawful entries derived from dhs's statistical model .

unlawful entries is limited to the southwest border .

additionally , dhs used detected unlawful entries as the numerator , instead of the estimated total unlawful border crossing attempts not detected as called for in the ndaa .

for the denominator dhs used the estimated total unlawful entries instead of the unlawful border crossing effectiveness rate , as called for in the ndaa .

limitations because this metric incorporates data on apprehensions , got aways , and turn backs , as well as the estimate for undetected unlawful entries , the limitations for those metrics also apply to this metric .

for more information on the limitations for those metrics , see the respective sections for those metrics .

additional information and planned actions by the department of homeland security for additional information on apprehensions , got aways , turn backs , and the estimate for undetected unlawful entries , and any planned actions by dhs for those metrics , see the respective sections for those metrics .

description this metric is a count of the number of apprehensions in each u.s. border patrol ( border patrol ) sector .

data come from border patrol records , and each apprehension of the same unlawful crosser in a fiscal year is counted separately , meaning these data do not represent a count of unique crossers apprehended .

border patrol officials , the northern border has different immigration dynamics than the southern border , so northern border data were not included .

officials stated that while the current emphasis of reporting is on the southwest border , efforts are under way to identify and find ways to capture data that are important and reflective of the effectiveness in addressing threats specific to the northern border .

limitations dhs identified: in its report , dhs said that apprehensions are not a useful indicator of successful unlawful border crossings over the long - term and across multiple locations because the relationship between apprehensions and successful unlawful entries depends on the apprehension rate , which changes over time and may differ by location .

additional information none .

description this metric is a count of the number of apprehensions of unaccompanied alien children ( uac ) , and the nationality of such children , in each u.s. border patrol ( border patrol ) sector .

a uac is a child under 18 years old with no lawful immigration status , and no parent present and available in the united states to provide care and physical custody .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report the department of homeland security ( dhs ) only included data for the southwest border .

limitations dhs identified: agents may not be able to reliably distinguish among older children and young adults or confirm whether children are traveling alone or in family groups .

we identified: we previously reported that it can be challenging to obtain accurate information about a child's country of origin because of absence of documentation , language barriers , and coached responses by smugglers , among other reasons .

border patrol officials said that the data on uac may have reliability issues because original data from a shared database had been changed .

specifically , officials said that in january 2015 they noticed that enforcement and removal operations staff were inadvertently overwriting border patrol's original data entries about the status of migrant children apprehended once those children were placed with relatives or a foster family .

additional information and planned actions by the department of homeland security according to border patrol officials , agents rely on statements provided by the child to determine the nationality of uacs when verifiable documentation is not available .

verifiable documentation could include biometric checks , birth certificates , state - issued identification cards , and passports .

however , officials noted that this list is not all - inclusive and the processing agent determines the validity of any presented documents .

border patrol officials said that a data integrity team regularly examines data on apprehensions and they conduct biweekly data reliability checks .

additionally , they are working with enforcement and removal operations to modify the data entry process so that updates can be made without overwriting the original apprehension data entered by border patrol .

description this metric is a count of the number of apprehensions of family units , and the nationality of such family units , in each u.s. border patrol ( border patrol ) sector .

a family unit is the number of individuals apprehended with a family member .

for example , a mother and child apprehended together are counted as two family units .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report the department of homeland security ( dhs ) only included data for the southwest border .

limitations dhs identified: dhs noted that the count of apprehensions for family units is considered reliable , but that agents may not be able to reliably identify family units .

we identified: according to border patrol officials , their data entry system did not have a dedicated field for agents to record apprehensions of persons within a family unit for all of the years presented in the report .

in december 2014 , border patrol added specific data entry fields to its data entry processes for agents to input information about family units .

these fields incorporated built in safeguards and edit checks to help ensure that agents make an appropriate family unit classification .

previously , border patrol officials said they used proxy data to identify family units .

given the additional safeguards and checks included with the new family unit data entry fields , border patrol officials stated that the data after december 2014 may be more reliable overall compared to previous years .

border patrol officials stated that they have high confidence in the proxy count for data pre - 2014 , but acknowledged that those data may contain misclassifications of family units .

additional information according to border patrol officials , agents are trained in interviewing techniques and the processing agent will consider all available evidence to determine the validity of claims to familial relationships .

border patrol officials also noted that in order to be categorized as a family unit , at least one member of the family unit must be at least 18 years of age .

consequently , related individuals younger than 18 years of age that are apprehended together would not be categorized as a family unit .

description this metric is a rate comparing the amount and type of illicit drugs seized between ports of entry in any fiscal year to the average of the amount and type of illicit drugs seized between ports of entry in the immediately preceding 5 fiscal years .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none identified .

limitations none identified .

additional information none .

description this metric was not specifically defined in the national defense authorization act for fiscal year 2017 ( ndaa ) ; the ndaa called for an estimate of the impact of the consequence delivery system ( cds ) on the recidivism rate of unlawful border crossers over multiple fiscal years .

the office of immigration statistics ( ois ) calculated this metric by providing the average annual recidivism rate for the 3 years prior to fiscal year 2012 — when the cds was implemented — and the average annual recidivism rate for the subsequent 3 years .

the annual recidivist rate is calculated by dividing the number of unique crossers apprehended multiple times in a fiscal year by the total number of unique crossers in the fiscal year .

to dhs's report , recidivism data for the northern border were not available due to the small number of attempted illegal entries along the northern border .

noting the findings from our january 2017 review , dhs stated that its current recidivism measure could be strengthened by using the date an unlawful border crosser is removed or returned instead of the date they are apprehended , as well as by counting re - apprehensions within a fixed period of time defined by the crosser's repatriation date instead of by the fiscal year .

in january 2017 , we reported that using a crosser's apprehension history beyond 1 fiscal year , and excluding crossers that have not been previously removed , among other things , produces a significantly different rate compared to how dhs currently calculates it .

consequently , we recommended that dhs calculate recidivism for a period of time longer than 1 fiscal year and that dhs exclude from the recidivism calculation aliens for whom there is no record of removal and who may remain in the united states .

as of december 2018 , this recommendation remained open .

dhs stated that changes in the recidivism rate after 2012 cannot be attributed solely to cds because enforcement is a complex , dynamic system .

we identified: given that dhs's methodology is to provide the 3-year average of the recidivism rate before and after cds was implemented in fiscal year 2012 , the data presented will remain static for subsequent annual reports because the periods of comparison for analyzing recidivism are fixed around a specific point in time .

according to ois officials , to help address this issue , in the next report they plan to provide individual rates for each year instead of the 3-year average .

additional information and planned actions by the department of homeland security in its report , dhs noted that future reports will include estimates of the impact of cds on both the annual recidivism rate and a longer - term recidivism rate .

for example , ois officials said they plan to update the way they calculate recidivism for future issues of the report and are developing a multivariate impact analysis that would take into consideration factors such as crossers' demographics and immigration history .

description this metric was not specifically defined in the national defense authorization act for fiscal year 2017 ( ndaa ) ; the ndaa called for an examination of each consequence under the consequence delivery system ( cds ) , including ( 1 ) voluntary return , ( 2 ) warrant of arrest or notice to appear , ( 3 ) expedited removal , ( 4 ) reinstatement of removal , ( 5 ) alien transfer exit program , ( 6 ) criminal consequence program , ( 7 ) standard prosecution , and ( 8 ) operation against smugglers initiative on safety and security .

the department of homeland security ( dhs ) presented data on the recidivism rates for each consequence between fiscal years 2012 through 2016 .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report as noted above for the metric “estimates of the impact of the consequences delivery system on recidivism,” dhs only included data for the southwest border because recidivism data for the northern border were not available due to the small number of attempted illegal entries along the northern border .

differences in recidivism rates among the consequences may also reflect differences in the propensity of the targeted populations to attempt to re - enter .

as with the metric for estimating the impact of the cds on recidivism discussed above , dhs noted the limitation that current recidivism data are based on apprehensions within a given fiscal year , and not the date when an individual was repatriated to their country of origin .

in january 2017 , we reported that some unlawful border crossers were incorrectly classified based on cds guidance .

u.s. border patrol ( border patrol ) agents implement cds by classifying apprehended aliens into one of seven noncriminal or criminal categories and then applying one or more of eight different consequences ; therefore , determining the correct classification of the unlawful border crosser is important for identifying and applying the appropriate consequence .

our analysis of border patrol apprehension data from fiscal year 2013 through 2015 showed that border patrol did not classify 11 percent of apprehensions in accordance with the agency's guidance .

we recommended that border patrol provide consistent guidance for classification and take steps to ensure the integrity of classification data .

border patrol implemented this recommendation as of december 2017 , but the issue could potentially have implications for the data dhs used in this metric , which was for fiscal years 2012 through 2016 .

additional information and planned actions by the department of homeland security according to its report , dhs is refining its analysis and will seek to specifically address the limitations discussed above in the fiscal year 2018 version of the border security metrics report .

ports of entry are u.s. government facilities that provide for the controlled entry into or departure from the united states .

there are 328 ports of entry in the united states .

specifically , a port of entry is any officially designated location ( seaport , airport , or land border location ) where u.s. customs and border protection ( cbp ) officers or employees are assigned to clear passengers , merchandise and other items , collect duties , and enforce customs laws ; and where cbp officers inspect persons seeking to enter or depart , or apply for admission into , the united states pursuant to u.s. immigration law and travel controls .

cbp's office of field operations ( ofo ) is the lead dhs component responsible for carrying out activities at poes .

the 15 metrics in this domain measure the number of travelers attempting to enter the united states at ports of entry , illicit drugs seized at ports of entry , and cargo entering the united states , among other things .

dhs included 11 of the 15 metrics called for in the ndaa for this domain in its fiscal year 2017 border security metrics report , as shown in table 5 .

dhs reported that the four metrics for which it did not provide information did not yet have a reliable methodology or were under review , and that dhs was in the process of developing methodologies to capture the data needed for the requested metrics .

dhs officials said these four metrics would not be ready for inclusion in the next annual report .

description this metric is a count of total inadmissible travelers , and requires an estimate of the number of inadmissible travelers who successfully enter at a port of entry without being detected .

the metric is the sum of the number of inadmissible travelers interdicted and the estimated number of inadmissible travelers who successfully enter at a port of entry without being detected .

inadmissible travelers who successfully enter at a port of entry without being detected .

therefore , dhs only presented data on known inadmissible travelers .

limitations none identified .

additional information and planned actions by the department of homeland security dhs projected that the department may be able to include estimates on the number of inadmissible travelers who successfully enter at a port of entry in its fiscal year 2019 border security metrics report to congress .

according to u.s. customs and border protection ( cbp ) officials , they are in the process of determining whether cbp's compliance measurement examination ( compex ) program could be used as a means to reliably measure undetected inadmissible travelers .

description these metrics are rates that require data on travelers seeking admission at a port of entry , interdictions of inadmissible travelers , and an estimate of the number of inadmissible travelers who successfully enter at a port of entry without being detected .

the refusal rate is calculated by dividing the number of inadmissible travelers interdicted by all people seeking admission at a port of entry .

the interdiction rate is calculated by dividing the number of inadmissible travelers interdicted by the total number of inadmissible travelers who attempt to enter at a port of entry .

inadmissible travelers who successfully enter at a port of entry without being detected .

therefore , dhs only presented data on the refusal rate .

limitations none identified .

additional information and planned actions by the department of homeland security dhs projected that the department may be able to include estimates on the number of inadmissible travelers who successfully enter at a port of entry in its next border security metrics report to congress .

according to u.s. customs and border protection ( cbp ) officials , they are in the process of reviewing data and program policies for cbp's compliance measurement examination program to determine if the program could be used as a means to reliably measure undetected inadmissible travelers , which would then be used in calculating the interdiction rate .

description this metric is a count of the amount in kilograms of illicit drugs seized by u.s. customs and border protection officers at ports of entry .

in an appendix to the report , the department of homeland security listed out 34 different types of illicit drugs and the amounts seized for each for fiscal years 2007 through 2016 .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none identified .

limitations none identified .

additional information none .

description this metric is a rate that compares the amount of illicit drugs seized ( in kilograms ) by office of field operations officials at ports of entry in 1 fiscal year to the average amount seized in the immediately preceding 5 fiscal years .

the metric .

the department of homeland security provided rates for cocaine , methamphetamine , marijuana , and heroin for fiscal years 2012 through 2016 .

limitations none identified .

additional information none .

description this metric is a count of the number of infractions related to travelers and cargo committed by major violators , and an estimate of the number of major infractions not interdicted .

the department of homeland security ( dhs ) calculated an infraction rate by dividing the number of major infractions by the total number of passengers at ports of entry for fiscal years 2007 through 2016 .

national defense authorization act for fiscal year 2017 ( ndaa ) .

as an alternative , for the purpose of its report , dhs defined a major infraction as an arrest , including arrests related to terrorism , drugs , criminal aliens , and currency , among other things .

dhs reported that it does not have a methodology in place to estimate the number of undetected major infractions .

therefore , only data on known infractions are included .

dhs only included data for passenger infractions and not cargo - related infractions .

although not requested by the ndaa , dhs provided an infraction rate by dividing the number of known infractions by the total number of travelers at ports of entry .

limitations we identified: given that dhs's alternative approach to this metric involves using arrests as a proxy for major infractions , it is unclear whether there is a one - to - one correspondence between the arrest of a major violator and the number of infractions committed .

additional information according to u.s. customs and border protection ( cbp ) officials , they plan to use data from cbp's compliance measurement examination program as a means to report estimated undetected major infractions starting with dhs's fiscal year 2019 report .

description this metric is a rate that compares the amount of cocaine seized at land ports of entry to the total estimated flow of cocaine .

the total flow of cocaine through land ports of entry .

the office of national drug control policy produces annual estimates for total cocaine flow into the united states , but does not have a methodology to estimate the flow of cocaine through land ports of entry alone .

therefore , the estimates the department of homeland security used included cocaine flow through all domains .

according to the u.s. drug enforcement administration's national drug threat assessment , the southwest border remains the key entry point for the majority of the cocaine entering the united states .

limitations none identified .

additional information none .

description this metric is a rate that compares the average wait time for vehicles to pass through a land port of entry to the total number of commercial and private vehicles at each land port of entry .

data were not available for every port of entry , such as small ones with negligible wait times .

limitations we identified: we reported in july 2013 that commercial vehicle wait time data were unreliable due to inconsistent data collection processes at ports , and made two recommendations to dhs to improve the reliability of the data .

while dhs implemented these recommendations in 2018 , older data , including the data for the years presented in the report ( fiscal years 2012 through 2016 ) , remain unreliable .

additional information and planned actions by the department of homeland security u.s. customs and border protection ( cbp ) officials clarified that the wait times shown in the report reflect the average of all hourly recordings for wait times at ports of entry rather than the average passenger or vehicle experience because cbp did not report a volume - weighted measure of wait times .

according to the report , cbp's wait time policy is currently under review and new guidance will be issued in the future to account for improvements in automation and recording .

description this metric is a rate that measures traffic volume at land ports of entry against the physical and staffing capacity at each land port of entry .

the department of homeland security ( dhs ) calculated the average number of vehicles processed per booth , per hour at each land port of entry .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none .

limitations none identified .

additional information in addition to reporting utilization at each port of entry , dhs provided the average utilization rate for all northern border land ports of entry and all southern border land ports of entry .

this metric is a rate that measures the frequency of secondary examinations at each land port of entry .

the department of homeland security ( dhs ) calculated the rate by dividing the recorded number of passengers sent for secondary inspection by the total number of recorded passengers at each land port of entry .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report dhs did not include data on secondary examinations of cargo or shipments .

limitations none identified .

additional information none .

description this metric is a count of the number of cargo containers at sea ports that dhs identified as potentially high - risk using national targeting center ( ntc ) security criteria .

according to the department of homeland security ( dhs ) , all international cargo shipments coming to the united states are screened to identify potentially high - risk containers , which may then be reviewed , scanned , or physically inspected prior to lading at a port of entry .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none identified .

limitations we identified: u.s. customs and border protection ( cbp ) officials said that the process of defining and identifying “high - risk” shipments can exclude some shipments , such as those in free trade zones .

additional information dhs's report said that the ntc periodically refines , improves , and revises the security criteria for high - risk shipments , which can affect the number of cargo shipments identified as high - risk .

description this metric is a rate comparing the number of potentially high - risk cargo containers scanned at each sea port of entry during a fiscal year to the total number of high - risk cargo containers that entered the united states at each sea port of entry during the previous fiscal year .

separate from cargo containers that were reviewed or assessed ; instead , dhs tracks these inspection methods collectively .

therefore , dhs also included data on potentially high - risk cargo containers that were reviewed or assessed as well as those that were scanned in its report .

limitations dhs identified: in its report , dhs noted that ratio data are not available for fiscal year 2014 because u.s. customs and border protection did not collect comparable container - level data ( as opposed to shipment - level data ) in fiscal year 2013 .

dhs also noted that the totals across the ports or field offices may include duplicate container counts .

we identified: ntc officials said that the definition of “high - risk” shipments excludes some shipments , such as those in free trade zones .

ntc officials noted that assessing , reviewing , and scanning containers are different activities and reflect different levels of inspection or review .

for example , ntc officials said that while all containers are “assessed” in order to determine their risk level , only higher risk containers may be scanned using radiation detection and nonintrusive inspection equipment .

consequently , when dhs included data on containers that were assessed or reviewed but not scanned , the resulting count was higher .

in an appendix to its report , dhs presented a column of data called the “percentage of potentially high - risk containers scanned ( same fiscal year ) ” for each fiscal year .

given dhs's inability to separate data on the different inspection methods , the data in this column included containers that were reviewed by all inspection methods , not just scanning .

in its appendix , dhs did not present data on the number of containers that “entered the united states,” even though it used those data to calculate the ratio and they are specified in the national defense authorization act for fiscal year 2017 .

as a result , it is not possible to verify the accuracy of dhs's ratio calculations .

additional information none .

the u.s. maritime border domain encompasses ports , internal or inland waters , and coastal waters , as well as the territorial sea ( waters 12 nautical miles seaward of the u.s. coast ) , contiguous zone ( waters adjacent to and seaward of territorial sea and extending 24 nautical miles from shore ) , and exclusive economic zone ( waters seaward of and adjacent to territorial sea and extending out to 200 nautical miles from shore ) .

u.s. coast guard ( coast guard ) , air and marine operations , and u.s. border patrol share responsibility for patrolling the u.s. maritime borders , and territorial sea .

the coast guard is a component of dhs and the lead federal maritime law enforcement agency on the high seas ( waters beyond 12 nautical miles seaward of the u.s. coast ) and all other waters under u.s. jurisdiction .

the coast guard responds to a variety of maritime border security issues , including trafficking of narcotics , people , illicit goods , unlawful migration , illegal exploitation of natural resources , potential terrorist activities , and the disruption of maritime commerce .

the metrics in this domain measure the number of migrants and illicit drugs removed , among other things .

dhs included 4 of 6 metrics called for in the ndaa for this domain in its fiscal year 2017 border security metrics report , as shown in table 6 .

description this metric was not specifically defined in the national defense authorization act for fiscal year 2017 ( ndaa ) .

the ndaa described situational awareness as the knowledge and understanding of current unlawful cross - border activity , including ( 1 ) threats and trends concerning illicit trafficking and unlawful crossings , ( 2 ) the ability to forecast future shifts in such threats and trends , ( 3 ) the ability to evaluate such threats and trends at a level sufficient to create actionable plans , and ( 4 ) the operational capability to conduct persistent and integrated surveillance of the international borders of the united states .

developing a measure for situational awareness in the maritime domain that meets the intent of the ndaa .

while this effort is in process , dhs presented data on u.s. coast guard and u.s. customs and border protection ( cbp ) asset ( aircraft and cutter or boat ) hours contributing to situational awareness or interdiction support and the number of vessel manifests screened .

limitations none identified .

additional information according to cbp air and marine operations officials , they did not have confidence that the data for years prior to fiscal year 2016 were consistent enough for making comparisons across years .

consequently , only data for fiscal year 2016 were included in dhs's report for the metrics related to cbp .

description this metric is a count of the total number of undocumented migrants interdicted , identified directly or indirectly but not interdicted , or otherwise believed to have unlawfully entered the united states through the maritime border .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none identified .

limitations department of homeland security ( dhs ) identified: the accuracy of migrant flow counts depends on partners to report interdictions and the ability to detect migrants .

according to the dhs report , the u.s. coast guard relies on partners to report interdictions for compilation in the u.s. coast guard's database .

interdictions may be double - counted by the u.s. coast guard and its partners because they cooperate during operations and some interdictions by partners may not get reported .

further , some migrants may not be apprehended and leave no evidence , and are therefore excluded from the known flow figures .

we identified: according to u.s. coast guard officials , there is no centralized database for tracking migrant interdictions , and the decentralized nature of the data collection could lead to errors .

additional information according to the u.s. coast guard , about 90 percent of the data on migrant interdictions and flow originate from u.s. coast guard records .

u.s. coast guard officials said that as part of a department - wide initiative to standardize illegal immigration statistics , they are in the preliminary stages of building a centralized database to enter and maintain information on migrant interdictions .

additionally , officials said they take steps to ensure the reliability of externally reported data such as communicating with partners and working together to reconcile any errors .

within the u.s. coast guard , meetings are held regularly to discuss and vet the accuracy of migrant flow data .

description this metric is a rate comparing the amount and type of illicit drugs removed by the department of homeland security ( dhs ) maritime security components in any fiscal year , including drugs abandoned at sea , to the average amount removed or abandoned in the immediately preceding 5 fiscal years .

by all dhs maritime security components , but dhs only provided data on removals by the u.s. coast guard .

dhs did not explain in its report why it only included data from the u.s. coast guard .

dhs officials said that the u.s. coast guard is the primary dhs component involved in this activity and was the only component that provided data for this metric , but this was not noted in the report .

according to u.s. coast guard officials , some of the data for fiscal 2013 was misreported .

specifically , the quantity removed for methamphetamine should be 0 ( report shows 17.4 ) while the value should be 7.9 kilograms for heroin ( report shows 0 ) .

additional information none .

description this metric is a rate comparing the amount of cocaine removed by the department of homeland security ( dhs ) maritime security components inside and outside the maritime transit zone to the total documented cocaine flow rate .

dhs used estimates of noncommercial maritime cocaine flow from the consolidated counter drug database , which are derived from intelligence reporting and case data .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none identified .

limitations dhs identified: there is less robust intelligence on noncommercial maritime cocaine flow outside the transit zone than inside the transit zone , so data for outside the transit zone are not considered reliable .

precise cocaine flow estimates through a particular mode or domain can be difficult to obtain .

in our prior work , officials with the office of national drug control policy and other departments and agencies involved in u.s. counternarcotics efforts told us that it is difficult to obtain precise estimates of cocaine flow because of the difficulty in obtaining specific information about the production of cocaine and how it gets to the united states .

we have also previously reported that when confronted with threats to their activities , drug - trafficking organizations use a variety of techniques to quickly change their modes of operation , thus avoiding capture of their personnel and seizure of their illegal drugs .

for example , when air interdiction efforts have proven successful , traffickers have increased their use of maritime and overland transportation routes .

additional information according to u.s. coast guard officials , dhs officials hold quarterly inter - agency meetings to review the reliability of performance data related to cocaine interdiction performance .

air and marine operations ( amo ) is a federal law enforcement agency within cbp that interdicts unlawful people and cargo approaching u.s. borders , investigates criminal networks , and provides domain awareness in the air and maritime environments , among other things .

the metrics in this domain measure amo's flight hours , individuals detected , and apprehensions , among other things .

dhs included 7 of 8 metrics within this domain called for in the ndaa in its fiscal year 2017 border security metrics report , as shown in table 7 .

dhs reported that the “amo actionable intelligence” metric was under review and estimated that the department would provide information on this metric in its 2019 annual report to congress .

description this metric is a rate comparing the number of flight hour requirements to the number of flight hours flown by air and marine operations ( amo ) in the land domain .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none identified .

limitations department of homeland security ( dhs ) identified: data prior to fiscal year 2016 were unavailable .

according to amo officials , this is because amo did not collect these data prior to fiscal year 2016 , or because older data were not comparable .

we identified: dhs used the terms “funded flight hours,” “unfunded flight hours,” and “unconstrained flight hours” in the report without clearly defining them .

amo officials stated that a definition of these terms will be included in the next report .

additional information amo officials said they have taken steps to improve how they track flight hour data , such as by adding new data fields to amo's system and providing training to staff .

description this metric is a rate comparing the number of funded flight hours appropriated to air and marine operations ( amo ) to the number of actual flight hours flown .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none identified .

limitations department of homeland security ( dhs ) identified: data prior to fiscal year 2016 were unavailable .

according to amo officials , this is because amo did not collect these data prior to fiscal year 2016 , or because older data were not comparable .

additional information amo officials said they have taken steps to improve how they track flight hour data , such as by adding new data fields to amo's system and providing training to staff .

description this metric is a rate comparing the number of aviation missions flown by air and marine operations ( amo ) to the number of aviation missions cancelled by amo due to maintenance , operations , or other causes .

the number of missions cancelled due to causes within amo control , such as maintenance , personnel , and asset availability .

however , the department of homeland security ( dhs ) used the total number of mission requests , which also includes the number of missions flown in addition to the number of missions cancelled for reasons within amo control .

limitations dhs identified: data prior to fiscal year 2016 were unavailable .

according to amo officials , this is because amo did not collect these data prior to fiscal year 2016 , or because older data were not comparable .

additional information amo officials said they have taken steps to improve how they track flight hour data , such as by adding new data fields to amo's system and providing training to staff .

description this metric is a rate comparing the number of missions cancelled by air and marine operations ( amo ) due to weather compared to the total planned missions .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none identified .

limitations department of homeland security ( dhs ) identified: data prior to fiscal year 2016 were unavailable .

according to amo officials , this is because amo did not collect these data prior to fiscal year 2016 , or because older data were not comparable .

additional information amo officials said they have taken steps to improve how they track flight hour data , such as by adding new data fields to amo's system and providing training to staff .

description this metric is a count of the number of individuals detected by air and marine operations ( amo ) through the use of unmanned aerial systems and manned aircraft .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none identified .

limitations department of homeland security ( dhs ) identified: data prior to fiscal year 2016 were unavailable .

according to amo officials , this is because amo did not collect these data prior to fiscal year 2016 , or because older data were not comparable .

dhs data on detections from manned aircraft were limited to those that led to apprehensions and arrests , and data from unmanned aircraft were limited to the number of vehicle and dismount exploitation radar ( vader ) detections .

amo did not track data from all sensors on unmanned and manned aircraft , and considers this metric to be a work in progress .

we identified: in february 2017 we reported that some mission data ( such as asset assists ) for unmanned aerial systems were collected inconsistently across operation locations , which could affect the accuracy of the counts provided .

we recommended that u.s. customs and border protection — of which amo is a component — update and maintain guidance for recording mission information in its data collection system , and provide training to users of the system .

dhs completed implementation of these recommendations in july 2018 .

although the recommendations have been implemented , this limitation is relevant because the data presented ( for fiscal year 2016 ) were collected prior to their implementation .

additional information and planned actions by the department of homeland security dhs expects to provide more comprehensive data for this metric in the next annual report .

amo officials said they have taken steps to improve how they track flight hour data , such as by adding new data fields to amo's system and providing training to staff .

description this metric is a count of the number of apprehensions assisted by air and marine operations ( amo ) through the use of unmanned aerial systems and manned aircraft .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none .

limitations department of homeland security ( dhs ) identified: data prior to fiscal year 2016 were unavailable .

according to amo officials , this is because amo did not collect these data prior to fiscal year 2016 , or because older data were not comparable .

we identified: in february 2017 we reported that some mission data ( such as asset assists ) for unmanned aerial systems were collected inconsistently across operation locations , which could affect the accuracy of the counts provided .

we recommended that u.s. customs and border protection — of which amo is a component — update and maintain guidance for recording mission information in its data collection system , and provide training to users of the system .

dhs completed implementation of these recommendations in july 2018 .

although the recommendations have been implemented , this limitation is relevant because the data presented ( for fiscal year 2016 ) were collected prior to their implementation .

additional information in addition to the number of apprehensions assisted , dhs also provided the number of enforcement flight hours used for the assists .

amo officials said they have taken steps to improve how they track flight hour data , such as by adding new data fields to amo's system and providing training to staff .

description this metric is a count of the number and quantity of illicit drug seizures assisted by air and marine operations ( amo ) through the use of unmanned aerial systems and manned aircraft .

differences between the national defense authorization act for fiscal year 2017 and the department of homeland security's report none .

limitations department of homeland security ( dhs ) identified: data prior to fiscal year 2016 were unavailable .

according to amo officials , this is because amo did not collect these data prior to fiscal year 2016 , or because older data were not comparable .

we identified: in february 2017 we reported that some mission data ( such as asset assists ) for unmanned aerial systems were collected inconsistently across operation locations , which could affect the accuracy of the counts provided .

we recommended that u.s. customs and border protection — of which amo is a component — update and maintain guidance for recording mission information in its data collection system , and providing training to users of the system .

dhs completed implementation of these recommendations in july 2018 .

although the recommendations have been implemented , this limitation is relevant because the data presented ( for fiscal year 2016 ) were collected prior to their implementation .

additional information in addition to the drug seizures assisted ( in pounds ) , dhs also provided the number of enforcement flight hours used for the assists .

amo officials said they have taken steps to improve how they track flight hour data , such as by adding new data fields to amo's system and providing training to staff .

based on findings from previous reviews of border security programs and efforts , we have recommended other metrics that the department of homeland security ( dhs ) could use to help measure the effectiveness of border security .

the tables that follow provide information about these recommended metrics in each of the four domains listed in the national defense authorization act for fiscal year 2017 — between ports of entry , at ports of entry , in the maritime border domain , and the air and marine security in the land domain .

the recommendations listed in the tables below remain open ; however , implementing them would provide dhs with additional indicators and metrics that could provide important insights into the state of border security .

in addition to the contact named above , taylor matheson ( assistant director ) , david alexander , kelsey burdick , lilia chaidez , kathleen donovan , michele fejfar , sally gilley , christopher hatscher , eric hauswirth , mikaela meyer , sasan j .

“jon” najmi , kevin reeves , and jeff tessin made key contributions to this report .

