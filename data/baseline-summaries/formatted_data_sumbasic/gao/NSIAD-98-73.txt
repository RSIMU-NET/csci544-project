command , control , communications , computers , and intelligence ( c4i ) systems relay critical information to u.s. forces during joint operations .

if joint operations are to be successful , c4i systems must be “interoperable” — capable of exchanging information and operating effectively together .

to help ensure interoperability , the defense information systems agency ( disa ) — under the direction of the joint chiefs of staff — established the current certification process in 1992 .

according to joint staff guidance , commanders in chief , the four services , and department of defense ( dod ) agencies are required to use this process to test and certify existing and newly developed systems for interoperability .

generally , newly developed systems are to be denied production approval if they have not been certified .

after a system has been fielded and a modification is made that affects interoperability , the system must be recertified .

in response to your request , we determined ( 1 ) whether dod organizations are complying with interoperability testing and certification requirements and ( 2 ) what actions , if any , are needed to improve the current certification process .

we also identified initiatives that affect interoperability ; they are discussed in appendix i .

the military services have a long history of interoperability problems during joint operations .

for example , the success of the persian gulf war in 1991 — a major joint military operation — was hampered by a lack of basic interoperability .

the current certification requirement was established to help address these problems .

the joint staff's director for c4 systems ( j - 6 ) is assigned primary responsibility for ensuring compliance with the certification requirement .

disa's joint interoperability test command is the sole certifier of c4i systems .

according to joint staff guidance , commanders in chief , the services , and dod agencies are required to adequately budget for certification testing .

they can either administer their own tests with test command oversight or ask the test command to administer them .

certification is intended to help provide the warfighter with c4i systems that are interoperable and to enable forces to exchange information effectively during a joint mission .

specifically , certification by the test command is confirmation that ( 1 ) a c4i system has undergone appropriate testing , ( 2 ) the applicable requirements for interoperability have been met , and ( 3 ) the system is ready for joint use .

however , while a system may pass certification testing , it may not have been tested against all systems with which it may eventually interoperate .

this is because some systems with which they must interoperate become available later and commanders sometimes use systems in new ways that were not envisioned during testing .

dod guidance requires that a system be tested and certified before approval to produce and field it .

depending on the acquisition category and dollar threshold of the program , the approval authority may be the under secretary of defense ( acquisition and technology ) , with advice from the defense acquisition board ; the assistant secretary of defense ( command , control , communications , and intelligence ) , with advice from the major automated information system review council ; or the dod component head ( such as the commander in chief of a unified combatant command , the head of a military service , or a dod agency head ) .

a dod directive established the military communications electronics board to provide guidance on interoperability issues referred to it by the secretary of defense and the chairman of the joint chiefs of staff .

the board addresses interoperability issues through two subpanels: ( 1 ) the interoperability improvement panel monitors c4i interoperability issues surfaced by the commanders in chiefs , military services , and dod agencies and ( 2 ) the interoperability test panel resolves testing disputes ( such as appeals of test command certification decisions made by commanders in chief , military services , and dod agencies ) .

the test panel may waive the certification requirement to support developmental efforts , demonstrations , exercises , or normal operations .

the waiver is not intended to be permanent , and is typically granted for 1 year .

commanders in chief , services , and dod agencies are generally not complying with the certification requirement .

as a result , we found instances in which existing , newly fielded , and modified systems are not certified for interoperability .

test command analysis showed that a significant number of existing c4i systems had not been submitted for certification as required .

according to test command officials , as of december 1997 , the dod defense integration support tool database of c4 systems listed about 1,000 systems that may exchange information with another system .

in addition , there are about 1,176 unclassified intelligence systems , according to the office of the assistant secretary of defense , c3i .

test command officials said they did not know precisely how many of these systems require certification .

nor did the office of the assistant secretary of defense know which intelligence systems would require certification because they were unable to determine which of these systems were outdated ( i.e. , legacy systems ) , stand alone systems , or one - service - only systems .

while the test command has generally certified increasingly more systems during the past 4 years , officials acknowledged that “they have not even begun to scratch the surface” of the universe of systems that may require testing and certification .

during fiscal years 1994 through 1997 , the test command certified 149 c4i systems .

according to test command officials , dod's defense integration support tool database attempts to list all c4 systems and other mission critical systems , but it does not contain all c4 systems or indicate whether the systems have been certified .

according to disa documentation , the purpose of the defense integration support tool is to support a dod - wide information management requirement for data collection , reporting , and decision support in areas such as planning and interoperability .

after discussions with dod officials regarding this issue , dod has recently included certification status as part of the database and , as of january 1998 , 44 systems reflected this information .

we recently reported in two separate reports that the defense integration support tool database is incomplete and inaccurate .

in response to our october 1997 report , dod acknowledged that this database is its official automated repository and backbone management tool for dod's inventory of systems .

accordingly , dod said that it had begun to take major actions to enhance the database by instituting a validation and data quality program to ensure that the database contains accurate and complete data .

dod further stated that it would closely monitor this program to ensure that the data quality is at the highest level as required for reports to senior defense managers and the congress .

since this database is an important management tool , it is essential that it be complete and accurate .

in several instances , new systems have been fielded without consideration of the certification requirement .

two recently fielded air force systems — a weather prediction system and a radar system — were not tested for certification by the test command , despite june 1996 memorandums from the joint staff stating that the service must plan for testing to ensure compliance with interoperability guidelines .

further , since 1994 , the assistant secretary of defense ( command , control , communications , and intelligence ) has approved three of nine major automated information systems for production and fielding that had not been certified for interoperability .

for example , the recently fielded defense message system was not certified by the test command .

test command officials stated that the system has undergone some interoperability testing but , because of shortfalls , was not certified .

a decision was made to field the system while the shortfalls are resolved .

test command officials believe the system will eventually be certified .

no newly developed systems purchased through the command and control initiatives program were tested by the test command .

 ( this program allows commanders in chief to purchase low - cost improvements to their command and control systems. ) .

according to disa officials , disa had assessed these systems' interoperability requirements and reminded the users to submit the systems for testing .

in addition , during the last 3 years , no systems purchased through the advanced concept technology demonstrators program were tested and certified .

 ( this program allows a new capability to be quickly developed , purchased , and exercised in the field before an acquisition commitment is made. ) .

according to test command officials , previously certified systems that were later modified are not consistently submitted for recertification as required .

although test command officials do not know the exact number of modified systems that require recertification , they are aware of several systems — such as the navy's aegis shipboard weapon system and the air force's airborne warning and control system .

joint staff officials believe that , although the certification requirement is outlined in several dod and joint staff guidance documents , some system managers are unaware of it .

in a study chartered by j - 6 and completed in january 1996 , only 12 of 424 ( less than 3 percent ) surveyed acquisition managers and defense system management college students knew about the dod and joint staff interoperability requirements .

the study team found that this lack of knowledge prevented users from placing interoperability in the initial requirements documents and acquisition managers from building interoperability into approved programs .

as a result , the joint staff began an effort in 1996 to better educate system managers about the requirement .

however , the study points out that education is not a panacea for all interoperability problems .

our analysis showed that some dod organizations , although aware of the requirement , did not submit fielded systems for testing .

for example , some program managers did not submit their modified systems for certification because they believed their design , although fielded , was not mature enough for testing .

the program managers did not seek a waiver for their systems and ignored the certification requirement .

test command officials told us that they lack the authority to compel program managers to bring their systems in for testing and must rely on the managers' cooperation .

in addition , in fiscal year 1995 , only three intelligence systems were certified by the test command .

because test command officials believed that dod's intelligence community was ignoring the certification requirement , in 1996 the command negotiated an agreement with dod's intelligence information systems management board ( which has responsibility for a portion of intelligence systems ) to facilitate better participation in the certification process .

in fiscal year 1997 , the number of intelligence systems tested and certified increased to 14 .

test command officials believe that the increase is a direct result of the agreement .

further , according to test command officials , dod officials do not always budget the resources needed for interoperability testing as required by joint staff guidance .

in certain cases , the services do not budget sufficient funds to cover secondary c4i systems that are used to test the primary c4i system for interoperability because the services cannot afford to pay for all the testing dod policy requires .

for example , the services are required to provide secondary systems for 10 tactical data link interoperability tests a year .

in this case , however , according to a test command official , the army budgets for only seven or eight tests a year .

the services are responsible for acquiring systems that satisfy service - unique requirements , and this responsibility sometimes takes precedence over satisfying joint interoperability requirements .

in his 1996 report to the secretary of defense , the chairman of the joint chiefs of staff recommended that funding for dod c4i systems be reviewed , since the services' funding decisions may not further dod's overall goal of promoting c4i joint interoperability .

finally , the various approval authorities are allowing some new systems to be fielded without verifying their certification status .

according to a joint staff j - 6 spokesman , the joint staff j - 6 representative is to ensure that interoperability certification is addressed at the approval authority acquisition meetings .

if the joint staff j - 6 representative is unable to attend these meetings , the issue of certification is not raised .

however , j - 6 coordination is obtained on all acquisition decision memorandums granting production and fielding approval .

nevertheless , systems receive approval for production and fielding even though they may not have been certified or obtained waivers .

in several instances , the test command identified interoperability problems in systems that dod organizations had not submitted for testing .

the following are examples: in 1996 , the test command expressed concerns to the air force that its joint tactical information distribution system , a computer terminal used to provide surveillance data on f - 15 aircraft , had not been certified .

the system ( a proof of concept demonstration ) had operated for 3 years .

according to a test command memorandum , command representatives witnessed numerous interoperability problems caused by this system during joint exercises .

the memorandum indicated that if the exercise had been a real world situation , the system's interoperability problems could have resulted in numerous deaths of pilots and enemy penetrations of u.s. airspace .

in a written response , the air force stated that it disagreed with the test command's assessment of the problems .

furthermore , the air force said that certification of the system was not the best use of resources because the air force planned to eventually replace it .

according to test command officials , the system is scheduled for testing in 1998 .

still not certified , the system has been operational for over 1 year since the air force's response .

test command officials have been unable to persuade the navy's aegis program office to submit all fielded versions of the ship's weapon system for interoperability testing .

command representatives have observed the weapon system experiencing significant interoperability problems in several recent joint exercises .

the test command is aware of five fielded versions of aegis software , and the program office states there are many more .

however , the test command has tested and certified only the oldest version ( in may 1995 ) , the most basic of the five versions .

the need for interoperability certification testing of the uncertified versions has been discussed at joint interoperability meetings and with disa .

the responsible disa official requested , under test command letterhead , that aegis submit uncertified versions for joint testing .

however , according to aegis program officials , none of these versions has been jointly tested because the newer versions either have not yet been tested with other navy - only systems or are not yet demonstrating adequate interoperability performance in testing with navy - only systems .

the test command has been unable to persuade users to test dod's air defense system integrator , which provides tactical data link translation and message - forwarding functions .

the system has been acquired outside the normal dod acquisition process .

about 30 versions of this system have been fielded ; none has been jointly tested .

according to test command officials , the system is experiencing significant interoperability problems because it does not conform to required standards .

interoperability problems with this system could result in hostile systems leaking through u.s. defenses or friendly systems being attacked .

without certification of the interfaces that translate and forward messages among systems , for example , the proper tracking and targeting information may not be provided to our theater air missile defense system .

at several 1997 meetings with representatives from all the services , the joint staff , and the test command , problems with the system were discussed .

solutions are still being developed and implemented .

noncompliance with interoperability testing and certification stems from weaknesses in the certification process itself .

for example , dod lacks a complete and accurate listing of c4i systems requiring certification and a plan to prioritize systems for testing .

as a result , the test command may not be focusing its limited resources on certifying the most critical systems first .

the process also does not include a mechanism to notify the services about interoperability problems identified in joint exercises , and the test command has only recently begun to contact the services regarding the noted problems .

finally , according to a test panel official , the panel does not have a formal process to inform dod organizations that systems with expired waivers require an extension or certification .

neither the joint staff nor disa has given the test command a priority list for testing c4i systems .

as a result , the command tests systems without regard to systems that should receive a high priority for testing .

test command officials believe that such a list would help them better plan their test schedule .

generally , the command develops a master test schedule based on the notification of systems ready for testing by the commanders in chiefs , services , and dod agencies .

as these notifications are received , the command updates its schedule .

furthermore , dod has not identified the exact number of systems to be certified .

a command official told us that , even if systems are identified , it is difficult to test all c4i systems required to be certified .

according to test command officials , they are able to test no more than 200 systems per year .

our analysis shows that the command generally reviews about 100 systems per year and in 1997 certified 44 individual systems for interoperability ( not including systems receiving multiple certifications due to modifications or testing with additional systems ) .

according to the official , a list prioritizing systems for testing would assist the command to use its scarce resources to test the most important systems first .

in june 1996 , the military communications electronic board reviewed existing command and control systems submitted by the services and determined that 42 were crucial to the needs of military commanders .

our analysis showed that , as of october 1997 , 23 had not been tested or certified .

according to test command officials , the 23 systems were not certified for various reasons .

the officials stated that they did not know about 13 of the systems ; 7 are scheduled or are to be scheduled for testing , but the schedules could slip ; 2 were not submitted for testing by the commanders in chief , service , or dod agency because 1 is a low priority for testing and the other needs redesign ( although both have been operational for several years ) ; and 1 was considered too immature to test .

without an approved dod - wide testing strategy , the test command's scarce resources may not be best used to test the right c4i systems at the right time .

joint staff , test command , and commander in chief officials believe that one area that should receive high priority in any plan for interoperability testing is theater air and missile defense systems .

this functional area is heavily dependent on systems being interoperable .

according to test command officials , about 100 major systems are involved in theater air and missile defense , and about 45 percent of these have not been tested or certified for interoperability .

dod officials stated that significant interoperability problems in these defense systems could have dire consequences for joint and coalition forces .

some joint exercises conducted during the last 2 years have demonstrated the need for better interoperability in this functional area .

interoperability problems in these exercises resulted in the simulated downing of friendly aircraft in one exercise and in the nonengagement of hostile systems in another .

test command officials stated that they do not generally advise services' system program managers on interoperability problems identified in exercises .

while not required to do so , the test command is in the best position to advise the commanders in chief , services , and dod agencies because according to command officials they discover , evaluate , and document these problems .

as part of its mission and apart from certification testing , the command provides operational support and technical assistance to the commanders in chief , the services , and dod agencies during exercises .

in reports summarizing the results of four joint exercises during 1996 and 1997 , the test command noted that 15 systems experienced 43 “significant interoperability problems” — defects that could result in the loss of life , equipment , or supplies .

the vast majority of these problems were caused by system - specific software problems .

specific problems experienced included failure to accept changes in mislabeled data identifying a friendly aircraft as a hostile aircraft , thereby causing the simulated downing of a commercial airliner ; excess messages overloading systems , causing system crashes and the loss of command and control resources during critical periods ; improper track identification , creating the potential for either a hostile system to penetrate defenses or a friendly system to be inadvertently destroyed ; and duplicate tracks distorting the joint tactical picture , denying vital information to battle managers and shooters .

in table 1 , we list the 15 systems that experienced significant problems and indicate their certification status .

when the services' program managers are not advised , significant interoperability problems may arise in subsequent exercises and operations .

according to test command officials , after our inquiries the command began exploring ways to formally track and follow up on these problems .

after our visit , command officials stated they were beginning to identify the problem systems and contact the program managers to request that systems be retested .

however , as of december 1997 , command officials had contacted only three system managers , and none of the systems have been tested .

according to a test panel official , the panel does not have a formal process to ensure that fielded systems with expired waivers are tested .

as a result , most systems with expired waivers were allowed to operate without testing or an extension of the waiver .

according to panel documents , 13 waivers have been granted since may 1994 .

of the 13 waivers granted , 3 have not expired and 1 was recently extended after the original waiver had been expired for 4 months ( even though the system has caused interoperability problems ) .

the remaining nine waivers have expired .

of these nine , only three are for systems that have had some interoperability testing and certification by the test command .

of the remaining six systems with expired waivers , two were expired for less than a year , two were expired for more than a year , and two were expired for more than 2 years .

commanders in chief , the services , and dod agencies are generally not complying with the c4i certification requirement .

inadequate compliance with this requirement increases the likelihood that c4i systems will not be interoperable , thereby putting lives , expensive equipment , and the success of joint military operations at greater risk .

improvements to the certification process are needed to provide better assurance that c4i systems most critical to joint operations are certified for interoperability .

better information is needed to track the status of waivers .

finally , the risks associated with operating uncertified systems in joint operations is heightened when systems are permitted to proceed into production and fielding without full consideration of the certification requirement .

to ensure that systems critical to effective joint operations do not proceed to production without due consideration given to the need for interoperability certification , we recommend that the secretary of defense require the acquisition authorities to adhere to the requirement that c4i systems be tested and certified for interoperability prior to the production and fielding decision unless an official waiver has been granted .

to improve the process for certifying c4i systems for interoperability , we recommend that the secretary of defense , in consultation with the chairman of the joint chiefs of staff , direct the service secretaries , in collaboration with the director of disa to verify and validate all c4 data in the defense integration support tool and develop a complete and accurate list of c4i systems requiring certification and director of disa to ensure that the status of system's certification is added to the defense integration support tool and that this database be properly maintained to better monitor c4 systems for interoperability compliance .

we also recommend that the secretary of defense request that the chairman of the joint chiefs of staff direct the joint staff ( in collaboration with the commanders in chief , the services , and the director of disa ) to develop a process for prioritizing c4i systems for testing and certification and joint staff ( in collaboration with the commanders in chief , the services , and the director of disa ) to develop a formal process to follow up on interoperability problems observed during exercises , report the problems to the relevant dod organization , and inform organizations that the systems are required to be tested for interoperability .

we recommend that , to improve dod's information on the status of waivers from interoperability certification , the chairman of the joint chiefs of staff establish a system to monitor waivers .

the system should inform dod organizations when waivers expire and request that they either seek an extension of the waivers or test their systems for interoperability .

in written comments on a draft of this report , dod generally concurred with all of our recommendations noting that a number of efforts are underway to improve the interoperability certification process .

to improve the process , dod is revising relevant policy and procedures to enhance their adequacy ( in terms of clarity , enforcement , and integration of effort ) and is improving the accuracy and utility of its defense integration support tool database .

agreeing with the need to prioritize systems for testing , dod stated it will develop a process to set priorities for testing and certification .

to follow up on interoperability issues learned during exercises , dod intends to use several sources of information to develop a formal process to ensure identified problems are adequately addressed by the appropriate organizations .

dod also intends to revise the charter of the test panel to require quarterly review of waivers from certification testing .

dod's comments are reprinted in appendix ii .

dod also provided technical comments , which we have incorporated where appropriate .

to determine whether dod organizations were complying with the certification requirement , we analyzed dod data on c4i systems to identify systems' certification status .

specifically , we obtained a listing of all c4 systems in the defense integration support tool from disa headquarters in arlington , virginia , and the number of unclassified intelligence systems from the office of the assistant secretary of defense , c3i in arlington , virginia .

we compared the systems on these lists with a list of all systems certified from october 1993 through september 1997 obtained from the joint interoperability test command in fort huachuca , arizona .

we also obtained a list of c4i systems included in command and control initiatives program budget proposals from october 1994 through september 1997 and a listing of c4i systems included in dod's advanced concept technology demonstrators program .

we compared these lists with the test command's list of certified systems .

we did not verify the accuracy or validity of any dod list .

we also obtained , reviewed , and analyzed dod policy , joint staff instructions , and other documents regarding compatibility , interoperability , and integration of c4i systems .

we obtained these documents and discussed interoperability issues in the washington , d.c. , area in interviews with cognizant officials from the office of the deputy under secretary of defense ( advanced technology ) ; the office of the assistant secretary of defense , c3i ; the office of the director , operational test and evaluation ; the joint chiefs of staff directorate for c4 ( j - 6 ) ; the directorate for force structure , resources and assessment ( j - 8 ) ; and disa .

in addition , we reviewed documents and interviewed cognizant officials regarding interoperability issues , including certification of c4i systems , from the u.s. atlantic command , norfolk , virginia ; u.s. central command , macdill air force base , florida ; u.s. pacific command , camp smith , hawaii ; u.s. european command , germany ; the naval center for tactical systems interoperability , san diego , california ; u. s. army communications and electronics command , fort monmouth , new jersey ; and individual system program offices or support activities in each of the military services , including the navy aegis program office , dahlgren , virginia ; the air force air combat command directorate of operations for command and control and intelligence , surveillance , and reconnaissance , langley air force base , virginia ; the army communications and electronics command software engineering center , fort monmouth , new jersey ; and the naval air warfare center , weapons division , point mugu , california .

to determine whether improvements were needed in the certification process , we interviewed test command officials on interoperability and certification issues , including testing priorities and exercise problem follow - up , and compared the command's list of certified systems from october 1993 through september 1997 with a june 14 , 1996 , list of dod's crucial c2 systems .

we also reviewed reports on lessons learned and demonstrations and exercises obtained from the joint staff j - 8 and the test command , respectively , to identify c4i systems with interoperability problems .

we then compared the problem c4i systems with the test command's certification list to analyze whether the systems were certified , uncertified , or modified and not recertified .

we also interviewed officials and obtained and analyzed waiver documents from the military communications electronics board's interoperability test panel .

we reviewed the waivers to determine the reasons for them and the time period involved .

finally , to determine initiatives that affect interoperability , we reviewed dod's c4i for the warrior concept ; the defense information infrastructure master plan ; the 1996 assessment of combat support agencies report by the chairman of the joint chiefs of staff ; the 1996 command , control , communications , computer , intelligence , surveillance , and reconnaissance task force reports ; and the levels of information system interoperability reports by the task force .

we conducted our review from january 1997 to january 1998 in accordance with generally accepted government auditing standards .

we are sending copies of this report to the secretaries of defense , the army , the navy , and the air force and other appropriate congressional committees .

copies will also be made available to others on request .

please contact me at ( 202 ) 512-5140 if you or your staff have any questions concerning this report .

major contributors to this report are listed in appendix iii .

improving ways of complying with the certification process alone will not solve all of the issues related to interoperability .

the department of defense ( dod ) has a number of initiatives underway that address various aspects of interoperability: the c4i for the warrior concept ; the command , control , communications , computers , intelligence , surveillance , and reconnaissance architecture framework ; the defense information infrastructure strategy ; and the levels of information systems interoperability initiative .

initiated in 1992 , the c4i for the warrior concept is to provide a global command , control , communications , computer , and intelligence system that directly links and supports the combat troops of all services who engage in military operations .

the system will display anywhere around the world a real - time , true picture of the battlespace , detailed mission objectives , and a clear view of enemy targets .

this advanced technology concept is to support dod's vision for the evolution of the u.s. armed force's capabilities to the year 2010 .

the command , control , communications , computers , intelligence , surveillance , and reconnaissance architecture framework , published in june 1996 by the dod integration task force , is to address a dod - wide lack of a shared understanding of the architecture process and insufficiently precise terminology .

according to the task force , architectures can be a key factor in guiding and controlling the acquisition and evolution of interoperable and efficient c4i systems .

if adopted , the framework will provide a common approach for the commanders in chief , the services , and dod agencies to follow in developing their c4i architectures .

the task force report stated that the framework has , in part , the ultimate potential of “facilitating , improving , and ensuring compatibility , interoperability , and integration among command , control , communications , computers , intelligence , surveillance , and reconnaissance capabilities.” while a final report was issued in june 1996 , the framework has not been implemented as dod policy .

currently , adoption of the framework in dod policy is not planned according to a joint staff official .

a current version of the framework itself was issued in july 1998 .

however , a j - 6 official expects full implementation to take 1 to 2 years after its publication .

dod issued a defense information infrastructure master plan in november 1994 to integrate its communications networks , computers , software , databases , applications , weapon system interfaces , data , security services , and other services that meet dod's information processing and transport needs .

the plan is updated periodically and provides a description of the defense information infrastructure's major components .

the infrastructure is largely an unintegrated collection of systems with unique characteristics .

these systems support a hierarchical , vertical military chain of command structure .

they were not designed to support joint operations and are therefore limited when information requirements are based on horizontal or functional sources .

the current infrastructure inhibits interoperability necessary to give commanders a unified picture of the battlespace , reduces ability to provide links between the battlefield and the support base , and limits connection to the u.s. industrial base .

one part of the defense information infrastructure plan is to establish a common operating environment that provides integrated support services and corresponding software for standard functional applications .

the idea for the common operating environment originated with an observation about command and control systems .

certain functions ( mapping , track management , and communication interfaces , for example ) are so fundamental that they are required for virtually every command and control system .

yet , in stand - alone systems across dod , these functions are built over and over again in incompatible ways , even when the requirements are the same or vary only sightly between systems .

the common operating environment is intended to standardize the underlying computing infrastructure used to process information .

it is to improve interoperability by creating architecture principles that , if adhered to , will allow for the sharing of software products and services and information across the defense information infrastructure .

both the defense information infrastructure plan and the common operating environment are long - term strategies that extend through the year 2010 .

finally , dod's 1993 levels of information systems interoperability initiative is to improve c4 and intelligence systems' interoperability .

system developers are to use this tool to assess interoperability , determine capabilities needed to support system development , and determine the degree of interoperability needed between c4i and other systems .

the tool has not yet been fully tested or implemented .

major testing is planned for july 1998 .

concerns regarding the success of some of these initiatives have been expressed by various dod organizations .

specifically , in its june 1996 report , the dod integration task force stated that compliance with the common operating environment standards will not ensure that systems will be interoperable because , in part , it does not eliminate the problems of data translation , remapping , and duplication .

further , test command officials and others believe the dod information infrastructure and common operating environment requirements need refinement before they can ensure interoperability .

for example , these officials believe that the level of compliance with the infrastructure and the common operating environment must be higher than currently required to ensure interoperability .

in addition , in a december 1996 report , the chairman of the joint chiefs of staff listed several challenges to achieving interoperability through dod's initiatives , including security of the infrastructure , overall integration of the dod organizations into a common operating environment , and the lack of a formal enforcement mechanism to ensure the services conform to the standards .

george vindigni yelena k. thompson david g. hubbell the first copy of each gao report and testimony is free .

additional copies are $2 each .

orders should be sent to the following address , accompanied by a check or money order made out to the superintendent of documents , when necessary .

visa and mastercard credit cards are accepted , also .

orders for 100 or more copies to be mailed to a single address are discounted 25 percent .

u.s. general accounting office p.o .

box 37050 washington , dc 20013 room 1100 700 4th st. nw ( corner of 4th and g sts .

nw ) u.s. general accounting office washington , dc orders may also be placed by calling ( 202 ) 512-6000 or by using fax number ( 202 ) 512-6061 , or tdd ( 202 ) 512-2537 .

each day , gao issues a list of newly available reports and testimony .

to receive facsimile copies of the daily list or any list from the past 30 days , please call ( 202 ) 512-6000 using a touchtone phone .

a recorded menu will provide information on how to obtain these lists .

