as you know , in 1989 , the department of defense started its corporate information management ( cim ) initiative in an effort to save billions of dollars by streamlining operations and deploying standard information systems to support common business operations .

a key part of this initiative is defense's migration effort , which involves replacing its functionally duplicative and inefficient automated information systems with the department's best existing information systems .

concerned that the billions of dollars projected to be spent on cim - related technology efforts are at high risk , you asked that we provide information on the status and progress of defense's migration effort and assess whether defense has effective controls in place to manage and oversee the initiative .

this report also highlights the implications of our findings for defense as it responds to investment management requirements of the clinger - cohen act of 1996 .

we are sending copies of this report to the chairman of the senate committee on governmental affairs and to the chairmen and ranking minority members of the senate committee on armed services ; subcommittee on defense , senate committee on appropriations ; house committee on national security ; subcommittee on national security , house committee on appropriations ; and senate and house committees on the budget ; the secretary of defense ; the acting assistant secretary of defense for command , control , communications and intelligence ; the acting under secretary of defense ( comptroller ) ; and the director , office of management and budget .

copies will also be made available to others upon request .

if you have any questions about this report , please call mickey mcdermott , assistant director , at ( 202 ) 512-6240 .

other major contributors to this report are listed in appendix v .

the department of defense ( dod ) began its corporate information management initiative ( cim ) in october 1989 to help meet the challenge of effectively managing its diverse operations as it downsized its forces and activities .

at the time , the department believed that the thousands of systems and numerous administrative and mission - related processessupporting dod functions were redundant and inefficient and that they should be standardized and made more efficient .

to address these problems , defense planned to simplify and improve business processes ; centralize responsibility and authority in functional areas , such as finance , personnel , communications , health affairs , logistics , command and control , and intelligence ; and develop an integrated communications and data processing infrastructure based on departmentwide standards .

from the outset , dod recognized that implementing cim would be difficult because the basic tenet of the initiative — managing and implementing business improvements and building corporate systems along functional lines — represented a major shift in the way defense traditionally did business .

whereas each military and defense agency had historically managed its own business functions and information systems , cim called on senior functional officials , known as principal staff assistants ( psas ) ,together with their defense component counterparts to be responsible for implementing improvements and information systems within the department's business functions across service and agency lines .

as cim was implemented , defense emphasized two ways of achieving process improvements and addressing problems associated with its disparate and stovepiped information technology environment .

the first was to improve , or reengineer , business processes first and then apply technology to the new processes .

the second involved selecting the best dod information systems from pools of existing , or legacy , systems that provide similar automated support services and eventually replacing the duplicative systems with the best systems .

a few years into the cim effort , this became known as migration .

defense believed that if done properly , migration could cut costs associated with developing and maintaining disparate systems supporting the same functions .

it also believed that migration would help to standardize business processes and allow defense to achieve savings that could be put to better use in advancing warfighting capabilities .

figure 1.1 illustrates how migration would work in one functional area .

for its finance and accounting functions , defense's goal is to reduce the number of systems from the 324 that the services and agencies operated in 1991 to 32 systems .

as of the end of fiscal year 1996 , the defense finance and accounting service's strategic plan stated it had reduced the number of finance and accounting systems to 217 .

the migration strategy for accounting and finance is to ( 1 ) identify a single migration system for each of the department's finance and accounting functions , such as civilian pay , ( 2 ) standardize the procedures and practices used to perform these functions , and ( 3 ) migrate from existing service - unique systems to the migration systems .

for some of these functions , such as general fund accounting , defense established a two - pronged approach: ( 1 ) migrate initially to a single interim system or set of systems within ( 2 ) migrate from the service systems to a departmentwide system or set of systems .

while defense began cim emphasizing the need to improve , or reengineer , processes before applying technology , it ended up placing more priority on obtaining quick savings through an accelerated migration strategy , which began in october 1993 .

this strategy called for selection of migration systems in 6 months and departmentwide transition to selected systems in the following 3 years .

defense believed that setting tight time frames for migration with some potential slippage would allow it to “harvest the low - hanging fruit” of potential savings before reengineering .

by default , this meant that the increased emphasis on migration would postpone the dramatic gains that could be achieved through reengineering .

the risks involved with postponing reengineering efforts were significant .

reengineering identifies , analyzes , and redesigns an organization's core business processes , aiming to achieve dramatic improvements in critical areas of performance , such as cost , quality , service , and speed .

it focuses on redesigning the business process as a whole in order to achieve the greatest possible benefits to an organization and its customers .

migration , on the other hand , focuses on standardizing existing processes and information systems .

this can yield some benefits , such as reducing the need to maintain disparate systems that support the same functions , but seldom yields dramatic improvements .

in addition , if the process is inefficient or outmoded , migration only serves to perpetuate a bad process .

finally , choosing migration before reengineering may cause future reengineering efforts to be more difficult by entrenching inefficient and ineffective work processes .

we raised these concerns both before and after defense decided to embark on the accelerated migration strategy .

we believed that the shift in emphasis toward migration seriously endangered cim's chances for success .

for this reason , and because cim - related technology investments , which are expected to total billions of dollars each year , are vulnerable to waste and mismanagement , we designated cim as a high - risk government information technology initiative .

nevertheless , defense proceeded to concentrate on migration even in areas where it had recognized that there was a significant need to change business processes .

one such area was transportation .

we reported in 1996 that even though defense recognized that its military transportation processes were fragmented , outdated , inefficient , and costly , it focused on technology solutions rather than the need to identify and correct the root causes of its transportation problems .

because reengineering took a backseat to migration in other business areas as well , cim has never been able to achieve the level of cost savings and process improvements originally intended .

a recent reportconducted by rand , a consulting organization , notes that “the cim effort is today widely viewed as a failure in most quarters of the dod .

it has not resulted in either significant process reengineering or visible savings in the hardware and software required to support all the varied information systems in the defense infrastructure.” defense is still planning to invest at least $18 billion in its migration effort from fiscal years 1995 through 2000 .

because this investment is significant , we were asked for information on the status and progress of migration and whether defense has significant controls in place to manage and oversee the effort .

defense reported that it has selected 363 systems for migration .

forty - nine of the 363 migration systems are large - scale , or major , systems that are expected to cost at least $13 billion — or about 72 percent of the total $18 billion cost estimate — to develop , deploy , and maintain over fiscal years 1995 through 2000 .

defense has identified 1,938 legacy systems for potential termination .

as of april 1996 , its defense integration support tools ( dist ) database showed that 281 had already been terminated , 886 were scheduled for termination by the year 2000 , and 771 more were identified for potential elimination after the year 2000 .

table 1.1 provides the number of systems selected by each functional area , the number of legacy systems identified for potential termination , and dod's estimated costs of developing , deploying , and maintaining the migration systems .

we excluded costs for 27 systems for which dod collected costs because the systems were classified .

and costs for the remaining 121 of 363 systems were not included in the table because the office of the asd c3i had not collected the costs for these systems .

table 1.2 provides the name , status , and cost for each of the 49 major systems .

we were asked ( 1 ) for information on the number and cost of systems designated for migration , the number of legacy systems already terminated or scheduled for termination , and savings resulting from terminations of legacy systems and ( 2 ) whether defense's management control and oversight processes for migration systems are ensuring that the investments are economically sound and in compliance with defense's technical and data standards .

to assess the status of defense's overall migration strategy and obtain available information on the number and cost of systems designated for migration , the number of legacy systems already terminated and scheduled for future termination , and savings resulting from terminations of legacy systems , we analyzed a defense april 1996 report to the congress containing information on the schedule , cost , and status of the migration systems .

defense prepared this report in response to a requirement in section 366 of the national defense authorization act for fiscal year 1996 .

we also obtained and analyzed a copy of the dist database as of april 1996 that defense used to develop the report to the congress , as well as to provide its own senior managers information on migration system selections and legacy system terminations .

additionally , we reviewed — but did not independently verify — cost information that defense reported to congress as part of the april 1996 section 366 report .

we also interviewed senior dod officials to determine if additional cost and performance information on migration systems existed at the office of the secretary of defense ( osd ) level .

we assessed the reliability of the data presented to the congress in two ways .

first , we identified missing and conflicting information in the april 1996 section 366 report to the congress and requested that the asd c3i staff to clarify conflicting information .

second , we compared the data reported to the congress for three functional activities ( business areas ) — transportation , civilian personnel , and clinical health — against data provided to us by the functional area managers at these activities .

we then established and analyzed a database containing schedule and available cost information for the migration and legacy systems and modified the database to reflect updated schedule , costs , and other descriptive data defense provided to us during the course of the audit .

to assess defense's management control and oversight processes for migration systems to determine whether the investments are economically justified and comply with defense technical and data standards , we reviewed the department - level management and oversight processes for approving the psas' migration system selections and for overseeing major migration systems' acquisitions by the major automated information system review council ( maisrc ) .

our review did not focus on the process by which the psas select , develop , and manage their migration systems .

nor did we examine acquisition review processes within the individual functional areas employed for nonmajor system projects .

to analyze defense's oversight processes for reviewing and approving the psas' migration system selections , we reviewed department - level approval of the psas' selections .

we obtained a list of migration systems that psas had selected for their functional areas .

we then visited the office of the asd c3i and the defense information systems agency ( disa ) and reviewed the business case analysis documentation , technical analysis documentation , and other documentation provided to those offices for department - level approval of the psa's migration and interim system selections .

we also interviewed officials from the office of the asd c3i , disa , and the offices of selected psas regarding the documentation supporting the selections .

to review defense's acquisition oversight processes for major migration systems , we first identified the major migration systems , as defined by defense regulations .

we then obtained and analyzed the progress reports and other documentation provided to maisrc for those systems .

we also interviewed defense representatives and officials responsible for information systems oversight in the office of the asd c3i and offices of disa , the defense acquisition board ( dab ) , maisrc , and program analysis and evaluation ( pa&e ) .

we also interviewed representatives of the program offices or oversight offices for selected systems for which oversight had been delegated by maisrc .

through document reviews and interviews , we determined whether economic analyses for major migration systems had been independently reviewed and if so , whether the reviews had identified problems in the analyses .

we also determined whether dod guidance existed on preparing economic analyses for information systems .

a gao economist met with pa&e analysts , reviewed problems that were identified with economic analyses , and verified the validity of the problems reported .

additionally , we determined whether maisrc had information on alternative analyses performed for major migration system selections .

lastly , we determined whether maisrc has sufficient oversight information to ensure that major migration systems are complying with applicable technical and data standards that are necessary to achieve an interoperable systems environment .

we reviewed defense's policies and guidance for migration systems to ensure that information technology is acquired , managed , and used in the most efficient and effective manner .

our assessment included analyzing the national defense authorization acts , committee reports , and conference reports for fiscal years 1993 through 1997 ; defense office of inspector general reports ; our prior studies of cim and the migration system strategy , other available evaluations of the cim and the migration strategy , and existing legislation affecting these efforts .

the major studies reviewed included studies by rand and the defense science board.pertinent existing legislation includes the clinger - cohen act , the government performance and results act , the paperwork reduction act , and the chief financial officers act .

we conducted our review from august 1996 through july 1997 in accordance with generally accepted government auditing standards .

we requested comments on a draft of this report from the department of defense .

the acting secretary for command , control , communications and intelligence provided us with written comments .

these comments are discussed in chapter 4 and reprinted in appendix i .

embarking on the migration strategy was an extremely risky endeavor for the department of defense .

first , in developing standard systems within functional areas , the department had to carefully consider complex technical issues , such as interfacing migration systems with other systems and contending with nonstandard data formats and definitions .

for defense , such complexities were compounded by its sheer size and the numbers of disparate systems .

we believe an even tougher obstacle facing defense , however , was the prevailing culture , which was based on decentralized department organizational structure , nonstandard processes and procedures .

in general , each military service and defense agency has historically managed its own business functions and information technology projects , whereas cim and migration required business improvements and information systems to be managed on a departmentwide , or corporate basis .

therefore , to ensure the strategy's success , it was vital for defense to establish an effective decision - making and oversight environment for making migration investments .

it would need controls and processes that ensured inefficient administrative and mission - related work processes were modernized before significant technology investments were made to support them .

it would also need controls that ensured that the migration projects themselves were effectively managed as investments so that the department could target resources and attention to priority areas and stop those projects that failed to meet their goals .

finally , defense needed life cycle management controls that ensured , on a system - by - system basis , that sound management and development practices were followed .

however , defense's primary corporate - level control mechanism for ensuring that sound management and development practices were followed for each migration investment has not been effective .

this control requires that all selections to be submitted for approval by the assistant secretary of defense for command , control , communications and intelligence ( asd c3i ) , who is also the department's chief information officer ( cio ) .

in approving the systems , the assistant secretary is to review data , technical , and programmatic factors relating to the selection .

we found , however , that most migration selections never came in for this approval and those that did were approved in the absence of critical technical and programmatic supporting documents .

 ( a description of the migration decision process is provided in appendix ii. ) .

because this control was playing a marginal role in ensuring the success of migration , we assessed whether defense's acquisition oversight processes — which are designed to augment management oversight for the department's most expensive information systems — were helping to ensure that the major migration investments were economically and technically sound .

these processes have also broken down where migration is concerned .

had there been more rigorous attention to oversight in both areas , defense may well have avoided the migration problems we identified in previous reviews that cost the department hundreds of millions of dollars .

in implementing the migration strategy , defense did not ensure that it had adequate visibility over status , costs , and progress .

as a result , it has not been able to ( 1 ) demonstrate whether the migration strategy has been successful , ( 2 ) provide the congress with accurate and reliable information needed for oversight purposes , and ( 3 ) provide its own decisionmakers at the headquarters level with information needed to oversee the strategy .

after selecting a migration system , the principal staff assistant ( psa ) responsible for a functional area is to submit the system for approval by the assistant secretary of defense for command , control , communications and intelligence — the senior information management official and chief information officer in dod .

in his memorandum setting forth the requirements for selecting and reviewing migration systems , the asd c3i stated that in approving the selections , he would consider data , technical , and programmatic factors .

for example , the asd c3i review would include such issues as whether the migration systems will lend themselves to data sharing and whether they conform to dod's technical standards — which act as a set of “building codes” for constructing systems to ensure they will be compatible with its information infrastructure and technically interoperable with each other .

this approval is important because , as the department's chief information officer , the assistant secretary needs to ensure that the migration systems help facilitate the sharing of information across service and agency lines .

however , both the psas and the asd c3i did not adhere to this oversight process .

first , 245 selections , or about 67 percent , were never submitted for this oversight even though all 363 system selections should have been.4 , 5 of the 49 major , or large scale , migration systems , only 16 were submitted for this review .

thus , for the bulk of migration systems , the assistant secretary was unable to ensure that defense technical standards would be met and that the best system development practices were being followed .

nine of the systems that were submitted for approval were grandfathered into approval because development for them was well underway at the time the accelerated migration system strategy began in 1993 .

forty - two of the systems that were approved by the asd c3i as migration systems did not follow dod's migration system approval process described in appendix ii .

instead , the asd c3i approved these 42 command and control systems based on reviews by the military communications electronics board .

oversight have been approved — whether adequately supported by technical and business case justification or not — the asd c3i oversight has essentially become a meaningless process .

because the asd c3i oversight control over the migration strategy played a marginal role in ensuring that sound management and development practices are followed , we assessed whether defense's traditional major information systems acquisition oversight processes were doing so for 43 of the major migration systems .

these review processes are designed to assess whether projects are affordable and financial and operational risks have been minimized .

once under acquisition oversight , systems are normally reviewed and approved at each of four milestones .

the reviews involve assessing such matters as whether the proposed system is being developed in accordance with defense policies , procedures , and regulations ; whether the systems' program managers took steps to minimize the cost of a new system by ensuring full and open competition ; and whether the program managers will effectively use advanced system design and software engineering technology to minimize software and maintenance costs .

however , these reviews have not been effective for the migration effort .

as discussed in the following section , maisrc could not provide sufficient assurance that the major migration systems are economically justified and comply with defense's technical and data standards .

a principal tool of acquisition oversight is the economic analysis because it helps to ensure that the system chosen for development is cost - effective .

if done properly , it can enable reviewers to determine whether dod has sufficient funds in its budget to pay for the system , that is , whether the system is affordable .

it can also reveal potential conflicts between available funding and the planned schedule for deployments .

to arrive at these conclusions , the economic analysis establishes baseline life - cycle costs and benefit estimates for the project and calculates the project's return on investment .

the importance of developing complete and accurate economic analyses is underscored by several governmentwide requirements .

for example , the office of management and budget's ( omb ) circular a - 130 , management of federal information resources , calls on agencies “to conduct benefit - cost analyses to support ongoing management oversight processes that maximize return on investment and minimize financial and operational risks for investments in major information systems on an agencywide basis.” likewise , omb's circular a - 11 , part 3 , planning budgeting and acquisition of fixed assets , ( july 16 , 1996 ) , and its bulletin no .

95-03 , planning and budgeting for the acquisition of fixed assets , state that “the planning for fixed asset acquisitions should be based on a systematic analysis of expected benefits and costs.” however , even though economic analyses play a critical role in assessing whether system development efforts will be cost - effective and beneficial , defense has not yet established a set of minimum standards that an economic analysis must meet to be considered valid .

in addition , it has not published official guidance for preparing an economic analysis .

pa&e developed and published an unofficial economic analysis guide that recommended , but did not require , standard methods and formats for preparing an economic analysis for an information system development / modernization project .

according to a pa&e representative , this unofficial guide is no longer adequate because it does not require the degree of standardization in methodology and analytic techniques needed to support a portfolio management approach for managing information technology investments , as required by the clinger - cohen act of 1996 .

for example , the guide does not require that returns on investment for systems development / modernization projects be calculated in a standard manner using a standard definition .

this lack of standardization results in economic analyses for different systems that are not comparable enough for dod managers to have a good basis for deciding which systems offer the highest payoffs .

the pa&e official stated that in conjunction with dod's implementation of a portfolio management approach , it plans to officially publish appropriate documents and provide minimum standards and guidance for the economic analyses process .

our review also found that dod decisionmakers do not view economic analyses as key tools for deciding whether to invest in an information system development or modernization project .

as a result , dod often lacks complete and accurate information on system development / modernization projects' estimated costs and benefits at the time decisions are made to invest in the projects .

specifically , as the following examples show , we found that ( 1 ) economic analyses for many systems have not been submitted for independent review and ( 2 ) a significant portion of those that were submitted were inadequately prepared .

thus , many of the benefits that could be derived from this tool have not been realized .

twelve of the 43 major migration systems have not yet submitted an economic analysis , or an update of a previously prepared economic analysis , for independent review .

these systems were under development or modernization and dod had invested hundreds of millions of dollars in them in total .

these included 5 systems that were under direct maisrc oversight and 7 systems for which maisrc delegated oversight responsibility to a service or agency .

these 12 systems , or components of them , are all in the second development phase or beyond .

delaying the preparation or updating of a previously prepared economic analysis to the later stages of development for these 12 systems defeats the purpose of the economic analysis , which is to demonstrate that a proposal to invest in a new system is valid before that investment is made .

four systems that were under direct maisrc oversight , were in the first development phase — concept exploration — and were , therefore , not yet required by dod's acquisition regulations to submit an economic analysis or an update of a previously prepared economic analysis for independent review .

although these four systems were technically in compliance with defense's acquisition regulations , dod had already made major investments in them without the benefit of knowing whether returns on investment are going to be acceptable .

even though defense has not established standards for the required analyses , program analysis and evaluation ( pa&e ) staff who review the economic analyses that are under direct maisrc oversight told us that 10 of the 19 economic analyses reviewed had problems .

these problems included the following: understating or omitting the costs of standardizing data , implementing the standard data in the systems , and developing system interfaces .

failing to estimate the amount of savings expected for terminating duplicative legacy systems .

relying on professional judgment to make unsupported assumptions rather than making objective analyses to estimate the value of benefits and costs .

for example , in one case , the economic analysis estimated a cost avoidance associated with replacing an old system by assuming that both the old and the replacement systems' software maintenance costs could be accurately estimated using two different rates per line of code , but the analysis provided no data supporting the validity of either rate .

after identifying problems with these 10 economic analyses , pa&e staff worked with maisrc analysts and the systems' program managers to address the problems .

however , dod continued to develop the systems in spite of the fact that the investments had not been justified by complete and accurate economic analyses .

pa&e analysts told us that there were other problems that impeded their review and verification of the economic analyses .

for example , economic analyses are often not updated and provided to pa&e for review after major changes occur in the project , such as significant cost growth or redirection of the project .

a second problem is that economic analyses are often not supported by analyses of alternatives that weigh the cost and benefits of various technical options , such as whether to buy commercial off - the - shelf software or develop a system in - house .

this analysis would help defense decisionmakers make sound decisions on whether the proposed alternatives offer sufficient military or economic benefits to be worth their cost , and to determine which alternative is the best approach .

it would also identify alternatives that dod may want to reconsider at a later time if the selected approach runs into difficulties .

defense has established several sets of standards that are designed to ensure that systems developed are compatible with its communications and computing infrastructure and that they are technically interoperable with each other .

some defense leaders consider systems interoperability and the ability to exchange data across functional lines to be the most important consideration in migration system development , transcending economic benefits .

these standards include the technical architecture framework for information management ( tafim ) , defense information infrastructure common operating environment ( dii coe ) , and dod standard data .

dod system acquisition directives call on maisrc and dab to ensure that program managers comply with the department's policies and procedures and use best practices in developing and modernizing individual information systems .

these best practices include building systems and databases that comply with applicable technical standards and use dod standard data .

however , maisrc and dab do not have adequate assurance that the major migration systems are complying with applicable technical standards and are using standard data .

for example , out of 43 major systems under maisrc oversight , program managers reported to maisrc that ( 1 ) only 19 were in compliance with the tafim standards or had plans to comply with the tafim standards and ( 2 ) 9 systems were using dod standard data or had plans to use standard data .

we found similar results for compliance with dii coe standards .

specifically , program managers reported that only 25 systems were in compliance or had plans to be in compliance with dii coe .

these self - reports by program managers are questionable because they are not independently verified .

in addition to obtaining information on technical and data standards directly from program managers , maisrc and dab also obtain such information from the defense information systems agency ( disa ) .

disa supports maisrc and dab oversight of major systems by performing technical reviews of system documentation to determine if it indicates that interoperability issues are being addressed or will be addressed as the system is developed .

according to a disa representative , disa reviewed system documentation that had been prepared for 37 of the 43 maisrc migration systems and all 6 of the dab systems and found that the documentation indicated interoperability issues were planned to be addressed for each of them .

disa also provides feedback , advice , and assistance on interoperability and related issues during integrated product team meetings with maisrc , dab , and system program managers .

during these meetings and on other occasions when it is asked to do so , disa provides maisrc and dab general information on compliance with standards , such as whether the major systems' program managers have contacted disa and appear to be making reasonable attempts to bring their systems into compliance with applicable standards .

disa also assists program managers in developing strategies and cost estimates for achieving compliance with standards .

however , disa does not regularly report detailed information to maisrc and dab that would enable these oversight organizations to ensure that each major system is adequately complying with applicable technical and data standards .

for example , disa does not regularly report to maisrc and dab such detailed information as ( 1 ) each system's current compliance with applicable standards — that is , each system's current status relative to the eight levels that dod has defined for the dii coe , and each system's number and percentage of data elements that have been approved as dod data standards in the defense data dictionary system , ( 2 ) whether each program office prepared sound strategies , schedules , and cost estimates for achieving compliance with applicable standards , ( 3 ) whether each system's compliance strategy and cost estimate were approved by disa , ( 4 ) each system's current schedule and cost status for achieving compliance compared with its baseline schedule and cost estimate , and ( 5 ) whether each system has been independently certified by disa's joint interoperability testing command to be in compliance with the technical and data standards .

maisrc analysts responsible for overseeing the major migration systems confirmed that they did not know many of the systems' current status regarding compliance with applicable technical standards and use of dod standard data , or whether the program managers had developed and were following sound strategies for bringing the systems into compliance .

the technical and data standards are supposed to help pave the way to an interoperable systems environment .

however , without complete and accurate data on individual systems' compliance with standards , maisrc and dab cannot assure defense's chief information officer that the department's major information systems are complying with the standards .

without this information , as well as standards compliance information from the managers of dod's nonmajor systems , the cio cannot gauge the department's progress toward achieving its goal of an interoperable systems environment .

additionally , this information is critical if the cio is to successfully implement an integrated technical architecture for the department as required by the clinger - cohen act of 1996 .

the lack of rigorous oversight for the migration strategy has increased the risk that defense will pursue flawed system strategies .

in fact , our previous reviews of migration systems identified a number of problems that could have been prevented had there been better oversight by maisrc and the asd c3i .

for example , in several reviews , we found that functional areas did not account for various categories of significant costs when making their migration decisions .

these findings are highlighted as follows .

in reviewing the depot maintenance standard system migration effort , we found that defense did not address the full costs of developing interfaces needed to allow system components to exchange data with information systems currently used by the services to accomplish their missions .

one official estimated that this represented $70 million in costs.in analyzing what it would cost to develop its standard accounting and reporting system ( stars ) , we reported that defense neglected to consider internal project management costs and costs to enhance all of the stars components to bring them into compliance with dod's standard general ledger , key accounting requirements , and the standard budget and accounting classification code .

in reviewing the transportation migration effort , we found that defense did not include all costs associated with its evaluation of in - house systems when analyzing costs and savings for its 28 migration systems .

these included $16 million for its analysis of candidate migration systems and $2 million for maintaining migration system hardware .

we also found that if these costs were included in its systems selection analyses , defense would have found that the overall return on investment would have decreased and that it may actually lose money on its investment .

in previous reviews , we also found that defense functional areas did not adequately consider other alternatives to developing systems in - house .

for example , while the transportation area reviewed commercial off - the - shelf transportation software projects for some transportation business areas , this review was inadequate because it did not ( 1 ) analyze the degree to which unmodified software could meet unique defense requirements , ( 2 ) identify the expected cost to make necessary software modifications , ( 3 ) determine the time required to make the modifications , and ( 4 ) provide for a hands - on view of the software in operation .

in addition , defense concluded that software packages that could provide some degree of transportation functionality would require modifications that were too costly .

however , defense could not provide documented analysis to support this conclusion .

further , defense planned on making $13 million worth of software modifications to just five of its in - house selections .

we believe better oversight by the cio ( then referred to as the senior information management official ) may well have forced greater consideration of commercial packages in the transportation area .

finally , our review of defense's effort to develop a standard suite of migration systems for materiel management showed that the department spent hundreds of millions of dollars without achieving the expected benefits because it did not adequately anticipate and mitigate risks .

from 1992 to late 1995 , defense spent about $714 million developing standard systems with minimal results .

during that time , there were dramatic changes in the goals and expectations for the program and only one application was partially deployed .

because of changes in objectives and scheduling and problems in development , prospects for achieving the original objective of implementing a standard suite of integrated materiel management systems appeared dim .

in 1996 , defense finally abandoned its strategy to develop a standard suite of materiel management systems because of funding cuts , cost overruns , and schedule delays and embarked on a new strategy that involved individual deployment of nine system applications at selected sites as the applications were developed .

however , the decision to drastically change the course of the strategy was initiated without first conducting critical economic and risk assessments that would estimate the costs , benefits , and risks of alternative strategies and having the analyses independently reviewed by maisrc and pa&e .

the need for department - level review of analyses supporting this decision was important , given the fact that the new strategy represented a departure from defense's goal of eliminating redundant legacy systems and varied business processes .

a successful information technology investment process cannot operate without accurate , reliable , and up - to - date data on project costs , benefits , and risks .

it is the basis for informed decision - making .

however , in implementing the migration strategy , defense neglected to provide visibility over progress and costs .

the absence of reliable and accurate performance , cost , and schedule information on the migration effort has been debilitating in several respects .

first , it has impaired the department's ability to demonstrate whether the migration strategy has been successful .

second , it has kept defense from providing the congresswith accurate and reliable information needed for oversight purposes .

third , it has prevented defense from providing its own senior managers with information needed to oversee the migration effort .

since it embarked on the migration strategy , defense has not tracked overall departmentwide savings or validated improvements to operations resulting from the migration strategy .

in particular , it has not been systematically tracking such key performance issues as ( 1 ) administrative and operational cost savings resulting from elimination of redundant systems , ( 2 ) cost reductions resulting from improved information systems support to functional areas , ( 3 ) management or staff productivity improvements , and ( 4 ) benefits accruing to mission effectiveness that are attributable to information technology support .

having this type of information is the only means of ensuring that the billions of dollars being spent on the migration are producing sufficient returns and achieving departmentwide progress .

without it , defense cannot justify whether the migration strategy has been a worthwhile investment or support the need to continue pursuing migration .

at one point in the migration effort , as directed by the congress , defense developed performance measures .

however , it did not regularly collect data on all the measures , and the accuracy of much of the information it collected was questionable because of the data integrity problems plaguing the database defense relies on for migration inventory and schedule - related information .

in 1995 , the house committee on national security directed defense to reevaluate its measures .

in march of 1997 , a defense working group proposed a revised set of performance measures relating to migration systems and other information technology issues within the department .

however , senior defense management did not approve the measures and instead tasked the working group to redo them to ensure that they are linked to the department's strategic information technology management goals .

the working group has not established a schedule for completing this effort and finalizing the measures .

having performance measures will help to validate individual reports of migration successes , such as the migration systems characterized as successful in defense's report to the congress pursuant to section 381 of the national defense authorization act for fiscal year 1995 .

these are the standard procurement system , the distribution standard system , the defense civilian personnel data system , and the defense medical logistics standard support system .

we could not determine the full cost of the migration effort because defense's migration cost information is incomplete and may be significantly understated .

for example , when defense provided migration cost data to us in december 1996 , it could only provide costs for 242 of 363 migration systems .

we did not include costs in this report for 27 of 242 systems for which dod collected costs because the systems were classified .

however , the remaining 121 systems were not included because the office of the asd c3i had not collected the costs for these systems .

when we obtained cost information directly from three of the functional areas , we found that at least $1.6 billion in costs had been excluded from the approximately $18 billion total .

this included about $1.4 billion for clinical health systems , $56 million for civilian personnel systems , and $111 million for transportation systems .

we also found that the $18 billion total cost estimate does not account for some very important costs related to developing , deploying , and maintaining migration systems both before and after a project has been initiated .

for example , the transportation functional area has an office designated to oversee the development and deployment of its migration systems .

but , when accounting for costs for the systems , dod does not factor in the cost to maintain this oversight responsibility .

in addition , our previous reviews of finance and logistics migration efforts have found that dod did not account for costs for these projects relating to such activities as project management and developing interfaces with other systems .

our detailed analysis of dod's migration cost information is provided in appendix iii .

we could not accurately determine how many legacy systems have been terminated and how many are scheduled for termination because the database defense uses to track information systems is plagued with data integrity problems .

defense's own analyses of the database have shown that it cannot readily provide simple descriptive information for many systems .

for example , a february 1997 dod analysis of dist showed that 55 percent of the migration systems in the database had incomplete information on interfaces with other systems and 77 percent had incomplete data on installations where the systems operated .

our analysis of dist found that 61 percent the migration system implementation dates and 32 percent of legacy system termination dates were questionable .

in addition , when we compared dist scheduling information to information maintained by three functional areas we reviewed , we found that most of the migration systems implementation dates and legacy system termination dates in dist were incorrect .

for example , dist showed that 92 legacy systems were terminated by april 1996 in the clinical health , civilian personnel , and transportation areas , while functional area managers told us that only 43 had actually been terminated .

also , for the three functional areas , dist showed that 53 legacy systems were scheduled for future termination while functional area managers told us that 91 were slated for future termination .

we also found that defense has not ensured that the data definitions and formats used in dist are fully compatible with data maintained in other defense information systems that track and report on systems .

while dod is attempting to address this issue , disa provided us information showing that only 66 of the 218 data elements contained in dist have been approved as standard data elements in the defense data dictionary system .

without standard definitions and data formats , data cannot be easily transferred to dist from the other systems that may be used by functional area managers and other decisionmakers .

defense officials acknowledge that dist is incomplete and inaccurate , and the department has begun efforts to make the database more accurate and more user friendly .

however , defense officials also stated that they still used dist to generate reports to the congress because it was the only departmentwide database containing schedule and other descriptive data on all defense migration and legacy systems .

a detailed analysis of dist's integrity problems is provided in appendix iv .

defense has begun implementing division e of the clinger - cohen act of 1996 ( public law 104-106 ) , which the congress passed in an effort to put an end to problems associated with the development and implementation of government information systems — such as those evident in the migration effort .

under this legislation , defense is required to establish additional controls to ensure that more attention is devoted to the selection , control , and evaluation of information technology projects and that the department's technology investments are managed from a portfolio perspective .

implementing the clinger - cohen act in dod can bring meaningful reform to the management of migration and other information technology investments .

however , the current structure of the chief information officer ( cio ) position in the department will not permit the cio to devote full attention to reforming information resources management within dod .

and it will continue to impose responsibilities on the cio that conflict with the cio's obligation to provide independent oversight over the development and implementation of information systems .

the clinger - cohen act recognizes that the key to successfully managing information technology projects is ensuring that investment processes provide for the continued identification , selection , control , life - cycle management , and evaluation of information technology investments .

best practices on which the act is based have shown that to ensure an investment process is successful , top executives need to periodically assess all major projects — proposed , under development , and operational — then prioritize them and make funding decisions based on factors such as cost , risk , return on investment , and support of mission - related outcomes .

once projects are selected for funding , executives need to monitor them continually , taking quick actions to resolve development problems and mitigate risks .

after a project is implemented , executives should evaluate actual versus expected results and revise their investment management process based on lessons learned .

as our guide , assessing risks and returns: a guide for evaluating federal agencies' information technology investment decision - making , points out , a key to success in this type of management is considering all the major technology investments that are vying for funding at a designated level ( departmental , functional area , or service / agency level ) as a total package , or portfolio , of possible technology investments .

once this perspective is adopted , an organization can focus scarce information technology resources on the projects with the greatest impact on mission and concentrate management attention on those high - impact projects that become troubled projects .

it can also establish performance goals and stop or replace those systems or initiatives that fail to meet those goals .

this type of decision - making process can be applied to almost any organization , even one that is as highly decentralized as dod .

according to our investment guide , separate information technology investment decision - making processes can exist at various levels .

in dod , such processes could exist at the departmental level and the functional area or service / agency level , provided that the department can identify which major projects and initiatives should be managed at each level .

criteria for determining projects that should be managed at the various levels may include the dollar amount of the investment , the degree of risk associated with the project , and whether the system is to be shared across functional area lines or service / agency lines .

the clinger - cohen act contains the following additional requirements that are important for dod to implement in order to address problems evident in its migration strategy .

agencies are to determine whether their administrative and mission - related business processes should be improved before investing in major information systems to support them .

the investment process is to provide a means for senior management to obtain timely information regarding progress ( at established milestones ) in terms of cost , capability of the system to meet requirements , timeliness , and quality .

it should also provide for the evaluation of the results of information technology investments .

performance measures are to be prescribed for information technology used by or to be acquired for the agency .

the cio is to monitor the performance of information technology programs ; evaluate the performance of those programs on the basis of applicable performance measures ; and advise the agency head regarding whether to continue , modify , or terminate the program or project .

the cio is to be responsible for providing advice and other assistance to agency heads and senior managers to ensure that information technology is acquired and information resources are managed for the agency in a manner that implements the policies and procedures of the act and the priorities of the agency head .

the cio is to develop , maintain , and facilitate the implementation of a sound and integrated information technology architecture for the agency .

the architecture is an integrated framework for evolving or maintaining existing information technology and acquiring new information technology to achieve the agency's strategic and information resources management ( irm ) goals .

as a first step in implementing the clinger - cohen act , on june 2 , 1997 , the secretary of defense outlined his expectations for improvements in information technology - related management processes and information resources .

we believe the expectations identified by the secretary are an excellent starting point for implementing the clinger - cohen act and bringing meaningful change to the current information technology management process .

for example , the secretary has called on the cio to design and implement a process for maximizing the value and assessing and managing the risks of dod information technology acquisitions .

this process is to provide for the selection of information technology investments to be made by the department , the management of such investments , and the evaluation of the results of such investments ; be integrated with processes for making budget , financial , and program management decisions ; include minimum criteria to be applied in considering whether to undertake a particular investment in information systems , including criteria related to the quantitatively expressed projected net , risk - adjusted return on investment , and specific quantitative and qualitative criteria for comparing and prioritizing alternative information system investment projects ; identify , for each proposed investment , quantifiable measurements for determining the net benefits and risks of the investment ; and provide the means for senior managers to be able to obtain timely information regarding the progress of an investment in an information system , including the milestones for measuring progress on an independently verifiable basis , in terms of cost , capability of the system to meet specified requirements , timeliness , and quality .

in addition , the secretary has called on the cio to institutionalize performance - based and results - based management for information technology .

in doing so , the cio is to work with the chief financial officer , the principal staff assistants ( psas ) , and the defense components .

the cio is to establish goals for improving the efficiency and effectiveness of dod operations and issue instructions to functional areas on performance measurements .

the cio is also to monitor the performance of information technology programs , evaluate the performance of those programs on the basis of applicable performance measurements , and advise the secretary of defense regarding whether to continue , modify , or terminate programs or projects .

additionally , the secretary established a chief information officer council for dod to serve as the principal forum for discussing improvements in dod practices for the management of information technology .

in outlining his expectations , the secretary noted that the act poses questions that should be answered before investing in information technology , including: what functions are we performing and are they consistent with the mission ? .

if we should be performing particular functions , could they be performed more effectively and at lower cost by the private sector ? .

the secretary further stated that if a function should indeed be performed by the department , the law requires that the function be examined and redesigned or reengineered before applying new technology .

proper implementation of the clinger - cohen act would help to address a number of weaknesses that are currently standing in the way of defense's ability to provide a good decision - making and oversight environment for information technology projects .

for example , with full implementation of the act , defense could begin considering information technology investments as a total package of possible projects so that it can target resources to those projects having the greatest impact on mission and concentrate management attention on troubled areas .

it could also strengthen visibility over project performance , costs , and schedules so that senior managers can begin comparing the results being achieved against projected , costs , benefits , and risks and to identify actual or potential managerial , organizational , or technical problems .

moreover , in implementing the act , defense has an opportunity to ( 1 ) begin enforcing compliance with data and technical standards to ensure that dod's goals for interoperability and the sharing of information are met and ( 2 ) increase oversight for functional area assessments of whether to reengineer , migrate , or undertake some other path toward improvement .

however , the current structure of the cio position in defense will not permit the cio to effectively serve as a bridge between top management , line management , and information management support officials and identify opportunities to use information technology to enhance performance .

the clinger - cohen act requires that information resources management be the cio's primary responsibility and that the cio be involved in key decisions regarding the application of information technology in support of the agency's missions .

currently , the assistant secretary of defense for command , control , communications and intelligence ( asd c3i ) also acts as the cio .

by asking the cio to also shoulder a heavy load of programmatic responsibility , defense has made it difficult , if not impossible , for the cio to devote full attention to irm issues .

these issues go well beyond the development and modernization of information systems .

for example , defense needs its cio to be heavily involved with implementing a more aggressive and proactive computer security program .

as we reported in may 1996 , attackers have seized control of entire defense systems , many of which support critical functions , such as weapons systems research and development , logistics , and finance .

attackers have also stolen , modified , and destroyed data and software .

in addition , defense needs its cio to help ensure that year 2000 corrections are made to all of dod's information systems .

if systems are not corrected on time , the impact on defense operations could be widespread , costly , and debilitating to important warfighting and administrative operations .

while dod has delegated year 2000 responsibility to its components , it still needs to ensure , at the department level , that sufficient priority and resources are being devoted to the problem and that all systems have been identified and corrected .

there is also a direct conflict of responsibilites between the oversight and programmatic obligations associated with the two positions .

the asd c3i serves as the principal staff assistant for command , control , communications , and intelligence systems .

these systems represent about 45 percent of the migration system investment — about $8.5 billion of the total $18 billion migration investment .

this poses a conflict for both control mechanisms we assessed .

for the first control — the asd c3i approval process — the same individual is responsible for both selecting a system and approving the selection .

for the second control — acquisition oversight — defense's acquisition executive is also responsible for developing 14 of the 43 major automated information systems under the major automated information system review council ( maisrc ) .

a second challenge confronting dod in implementing the clinger - cohen act is the prevailing organizational structure and embedded culture found throughout the department .

specifically , the three military services have clearly defined roles and responsibilities and separate budget authority , program execution , and functional authority for the enforcement of national defense policy and objectives .

as we have reported throughout the cim initiative , this environment has promoted stovepipe systems solutions in each component agency and has made it difficult to implement departmentwide oversight or visibility over information resources .

this same condition has contributed to the difficulty that has limited the department in modernizing business processes and implementing corporate information systems across service and agency lines .

this is most evident in the perceived failure of the corporate information management initiative ( cim ) , which was intended to reengineer business processes throughout the department .

in doing so , the department expected to save billions by having more efficient , effective business processes running across service and component lines .

however , these benefits have yet to be widely achieved after 8 years of effort .

without the secretary's strong and continued support for management processes and controls designed to improve information management initiatives , clinger - cohen act implementation could well suffer similar results .

in taking its initial steps to implement the clinger - cohen act , defense has recognized that it needs a better information technology investment environment .

however , implementing the act will not be easy given weaknesses pervading the current decision - making and oversight environment .

examples included the following: dod's management and oversight processes over information technology projects are not effectively integrated to enable the department to manage from a portfolio perspective .

considering investments as a total package of possible projects is important because it forces an agency to decide which projects are the most critical to meeting mission needs and thus should receive the most resources and attention .

life - cycle management controls that provide oversight on a system - by - system basis can supplement and enhance this process , but they cannot be a substitute for it .

dod still has not established information technology performance measures .

these need to be in place before a new investment process can begin so that senior managers can begin comparing results being achieved against projected costs , benefits , and risks .

as far as visibility over costs and schedule are concerned , dod has fragments of a mechanism for collecting and maintaining all project information .

however this mechanism — dist — does not maintain cost information and its accuracy and reliability are questionable .

further , as we have recently reported to the director of the defense information systems agency , efforts to improve the dist have been slow - moving .

while the clinger - cohen act requires agencies to conduct post - implementation reviews , dod's oversight processes have concentrated on projects prior to their implementation .

thus , in addition to focusing on the pre - implementation stages of system life - cycles , dod will have to ensure that more attention is given to whether implemented systems are achieving the forecasted benefits and continuing to meet mission needs after they are implemented .

currently , dod does not have an effective mechanism in place to ensure that the cio has complete and accurate information on dod - wide compliance with technical and data standards .

such a mechanism is necessary to enable the cio to achieve the department's goals for systems interoperability , effectively implement an integrated technical architecture for the entire department , and ensure the efficient exchange of standard data among systems .

moreover , our review of the migration strategy suggests that a real threat to successful implementation of the clinger - cohen act is the department's consistent lack of adherence to sound decision - making and oversight processes .

for example , at the oversight level , systems that clearly lacked key pieces of technical , programmatic , and economic justification were allowed to go forward .

at the decision - making level , many functional areas did not even bother to submit their systems or analyses that supported their decisions to department - level oversight controls .

if they were effectively followed , the life - cycle management controls would have helped ensure that sound business and development practices were followed for the migration systems .

perhaps , the greatest challenge to successful operation , however , will be operating in an organizational environment that has resisted departmentwide oversight and visibility over information resources .

for example , the department's cim effort largely failed in meeting its original goals of bringing widespread efficiencies to its business processes .

the department was unable to create meaningful change across organizational lines and management support was insufficient to overcome initial resistance to new ways of doing business .

efforts to implement the clinger - cohen act will require unwavering top - level commitment to overcome both organizational resistance and to institute meaningful controls .

to ensure that dod's continued investment in migration systems provides measurable improvements in mission - related and administrative processes , we recommend that the secretary of defense require the defense components to rank development / modernization migration systems justifications and complete them on an expedited basis .

further , the secretary should require the chief information officer to review these justifications and certify that they include the following: a business case of operational alternatives for each functional area that clearly demonstrates that continued development and deployment of the migration system is the best solution for improving performance and reducing costs in the functional area it serves , when compared to other available alternatives .

the alternatives analyzed should include reengineering the functional area's processes before making investments in information systems and using , when appropriate , the private sector to perform major functions now performed by government personnel and information systems .

an economic analysis showing a return on investment or other results - based benefits to the department that justify further investment in the migration system .

current compliance with applicable defense technical standards and uses standard data , or a schedule and plan for bringing the system into compliance with these standards .

lastly , the secretary of defense should require the chief information officer to establish routine procedures for reporting on the status of reviews of migration system justifications to the deputy secretary of defense so the information can be used in the department's planning , programming , and budgeting system .

any exception to the accomplishment of these reviews should be approved by the deputy secretary of defense .

further , we recommend that the department's chief information officer revise defense's policies , practices , and procedures to institutionalize the management of information systems and technology expenditures as investments and ensure that these investments provide measurable improvements in mission performance .

in the course of taking action on these matters , we recommend that the secretary direct that the chief information officer , in coordination with the chief financial officer and other appropriate defense officials take the following actions: ensure that defense's strategic information technology planning and investment control policies , practices , and procedures include requirements that principal staff assistants document that they and the key stakeholders for their functional areas ( including the services , agencies , and major commands ) have ( 1 ) conducted thorough economic and risk analyses of alternative operational approaches ( business case analyses ) for accomplishing the mission of the functional area , ( 2 ) examined trade - offs among the competing proposals , and ( 3 ) prioritized the alternative proposals based on mission impact , risk , and return .

finalize and issue guidance for developing and using analyses of alternatives and economic analyses for information system decision - making .

once this guidance is issued , the cio should require that all defense program managers and defense managers , as appropriate , be trained in using the guidance .

also , the cio should ensure that the guidance defines a standard return on investment definition for defense information systems and require that this definition be used to calculate all returns on investment for information systems efforts .

additionally , the cio should require that all major migration and other information systems under direct review by the major automated information system review council ( maisrc ) , and those delegated by maisrc to other oversight organizations for review , have their alternatives analyses and economic analyses independently verified by defense's program analysis and evaluation ( pa&e ) office , or another qualified independent review organization , in accordance with this guidance before major investments are authorized for system development / modernization .

require post - implementation reviews of migration and other information systems and ensure that these reviews are designed to compare actual systems' costs , benefits , risks , and returns against the original baseline estimates / projections and determine the causes of any differences between planned and actual results .

expedite the definition , coordination , testing , and implementation of information management performance measures in the department and establish milestones for evaluating progress in implementing these performance measures .

modify the dist system or acquire / develop a new defense - wide management information system or systems for tracking and reporting key schedule , progress , and performance information on migration systems and other defense information systems and ensure the system or systems contain complete , current , and accurate schedule data necessary to track the progress of each migration system's development / deployment and each legacy system's termination ; budgeted and actual cost data on each system for which the department maintains such data ( an alternative to putting budget and cost data in dist is to establish the capability to directly interface with other systems in the under secretary of defense ( comptroller's ) office or other defense organizations containing systems' budget and / or cost data ) ; data necessary to track the progress of each migration system in complying with applicable defense technical and data standards , including whether each system has been independently certified to be in compliance with applicable technical and data standards ; data for tracking progress in accomplishing the mission - based performance goals and information management performance goals for the functional areas supported by each system once these data have been identified ; information determined to be needed for oversight by the defense acquisition board ( dab ) , maisrc , and pa&e ; and other information determined to be needed for management and oversight by the defense cio , the cio council , other defense senior managers , and the congress .

develop and implement management controls and a quality assurance program to ensure the dist data's accuracy and completeness since these data are used to track and report to senior defense managers and the congress on the overall status of the migration initiative and on other defense information management initiatives .

the department of defense provided written comments on a draft of this report , which are reprinted in appendix i .

the acting assistant secretary of defense for command , control , communications and intelligence concurred with five of our recommendations and partially concurred with two recommendations .

defense did not concur with the remaining five recommendations and expressed concerns about certain aspects of our report .

defense's concerns are highlighted and discussed below .

appendix i also provides detailed responses to dod's views on our recommendations and to other specific comments on our findings .

generally , the department concurred with our recommendations that the department revise or develop internal policies and procedures to conform to the clinger - cohen act and to improve the performance of information systems management .

defense also noted that the issues we reported are in the process of being or will be addressed as it implements the clinger - cohen act , the federal acquisition streamlining act , the government performance and results act , and the paperwork reduction act .

however , it did not agree to a recommendation in our draft that it limit further investments to expenditures that meet mission critical needs until the investments are economically , functionally , and technically justified and such justifications are independently reviewed .

in dod's view , limiting migration system spending would adversely affect military readiness , system development , and government contract obligations and increase system obsolescence .

we understand dod's concerns regarding readiness and contract obligations .

that is why our recommendation in the draft report recognized that critical needs still need to be met .

our point is that greater management attention needs to be placed on the decision - making process for approving and funding the development and modernization of migration systems to achieve intended benefits and minimize unnecessary costs .

in order to clarify this position , we modified our recommendation to focus on strengthening the controls for the migration system decision - making process so that these investments can be better considered in the department's budget process .

in addition , defense did not concur with a proposal in the draft report that it consider separating the cio and the asd c3i positions so that the cio can devote full attention to departmentwide information resource management issues and provide independent oversight .

it noted , however , that all asd c3i functions are being reviewed by the department's task force on defense reform as part of its review of the office of the secretary of defense's organizational structure .

we withdrew the proposal because dod is now considering this matter .

nevertheless , our concern that the current structure of the cio position does not allow the cio to devote full attention to critical irm issues — such as computer security , the year 2000 problem , and the need to develop and implement an integrated information technology architecture — remains valid .

defense also stated that our report overlooked one of the key cost reduction aspects of the migration effort — that is , modernizing multiple systems within each service and defense agency is more expensive than simply modernizing one or a few departmentwide migration systems .

while these cost reductions may be possible , defense has not yet demonstrated that it has achieved such savings .

further , our review determined that defense does not know , or track , cost reductions that result from its migration efforts .

finally , the achievements that defense refers to in its comment letter are mostly the results of process reengineering , not the migration of automated systems .

defense also stated that our report negatively portrays the role and benefits of acquisition streamlining within the department .

defense reported that it uses a “best - value” approach to modernizing its systems that balances the functional and technical capabilities while still considering cost .

we disagree with defense's characterization of our report .

we fully support acquisition streamlining efforts in dod because they promote economy , efficiency , and effectiveness in the procurement of property and services .

however , these three elements must be carefully balanced in order to achieve the results intended by the division d of the clinger - cohen act of 1996 which covers federal acquisition reform .

such a balance is particularly important to achieve prudent decisions for an investment as substantial as the multibillion dollar migration initiative , and it is contemplated by the clinger - cohen act of 1996 to properly control these investments .

in our view , for the migration effort , it appears that expediency was achieved at the expense of economy and effectiveness .

in conducting our review , we sought to examine whether the department of defense was following its own policy for controlling migration investments .

when we found that these policies were not executed as intended , we turned to the department's acquisition review process , which should have supplemented oversight for the major migration systems .

however , even here , we found that dod for the most part , was not providing sufficient assurance that migration investments were worthwhile .

specifically , we found that controls that defense built into this process would not ensure success .

in addition , the migration strategy is a high - risk endeavor because it requires defense to carefully consider complex technical issues that are compounded by the sheer size of the department , the number of disparate systems , and the prevailing culture , which promotes stovepiped systems solutions and hampers departmentwide oversight or visibility over information resources .

as such , the success of the strategy hinges on whether practical and sound management practices — such as conducting economic , risk , and alternative analyses and providing rigorous oversight over the selection process — are followed .

as we note in the report , these practices are required by executive branch policies ; congressional reform initiatives , including the clinger - cohen act , which took effect august 8 , 1996 ; and / or defense regulations .

under the clinger - cohen act , for example , defense is required to implement a process for selecting information technology investments using specific criteria for comparing and ranking alternative information system projects .

the best practices on which the act is based have shown that to ensure the success of an investment process , top executives need to make funding decisions based on factors such as cost , risk , return on investment , and support of mission - related outcomes .

thus , unless defense promptly embraces the need to develop and review economic , risk , and alternative analyses , it stands little chance of successfully implementing the clinger - cohen act .

in its comments , defense also expressed concern that the scope of our report was unnecessarily broader than it was when we began our review .

we were originally asked for information on the status and cost of the migration effort .

however , when we found that defense could not provide accurate and reliable information on migration or convincingly demonstrate whether the strategy has been successful , our congressional requester asked that we review whether defense's management control and oversight processes for migration were ensuring that the investments are economically sound and complied with technical and data standards .

we reviewed the reliability of the acquisition process controls over migration investments because they are the leading defense - recognized controls over major investments .

our congressional requester also asked that we focus on dod's implementation of the clinger - cohen act because it offered a chance for dod to bring meaningful reform to the management of migration and other information technology investments .

many information technology investments for systems in the department are , in fact , migration systems .

finally , defense's comments on our report identify a number of other disagreements with our findings and conclusions .

we reviewed these comments , incorporated them into our report where appropriate , and followed up with defense on additional information it provided after submitting its response to us .

