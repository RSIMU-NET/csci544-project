conducting research and development ( r&d ) on technologies for detecting , preventing , and mitigating terrorist and natural threats is vital to enhancing the security of the nation .

since it began operations in 2003 , the department of homeland security ( dhs ) has obligated billions of dollars researching and developing technologies used to support a wide range of missions , including securing the border , detecting nuclear devices , and screening airline passengers and baggage for explosives , among others .

within dhs , the science and technology directorate ( s&t ) is responsible for coordinating and integrating r&d activities across the department while dhs components may also conduct r&d to support their respective missions .

since 2003 , questions have been raised regarding s&t's ability to oversee and coordinate r&d activities across the department as well as to demonstrate the value of these investments over time .

in 2012 , we found that dhs efforts to coordinate r&d across the department were fragmented and overlapping , which increased the risk of unnecessary duplication .

we also reported that dhs did not know how much all of its components invested in r&d , making it difficult to oversee these efforts across the department .

we recommended , among other things , that the secretary of homeland security develop and implement policies to include elements such as a definition of r&d that provides reasonable assurance that reliable accounting and reporting of r&d resources and activities are achieved .

in response to our recommendation , dhs issued a memorandum in april 2014 that included a definition for r&d .

furthermore , dhs implemented a common appropriations structure to accurately identify the resources it is expending on r&d projects .

you asked us to evaluate dhs's efforts to coordinate and monitor r&d activities across the department .

this report addresses the following questions: ( 1 ) how much has dhs obligated for r&d from fiscal years 2010 through 2017 and what types of r&d does dhs conduct ; ( 2 ) to what extent does s&t coordinate r&d across dhs ; and ( 3 ) how , if at all , does dhs track and identify r&d efforts and assess r&d performance department - wide .

to determine how much dhs has obligated for r&d , we analyzed federal budget data to identify r&d - related obligations for fiscal years 2010 through 2017 .

we selected this time frame to analyze multiple years of obligation trend data , and 2017 was the most recent year of available data at the time of our review .

to identify the r&d obligations data , we searched the office of management and budget's ( omb ) max database for dhs accounts with the term “research” in the account title and extracted total obligations for those accounts from the database for fiscal years 2010 through 2017 .

we assessed the reliability of the data by reviewing omb guidance and procedures that govern omb max data inputs .

we determined that the data were sufficiently reliable for reporting general trends .

however , because we previously found that some dhs r&d - related obligation data were not properly identified , and because r&d - related obligations could potentially be reported in other accounts that may not contain the term “research,” we report the data as a minimum of the amount that dhs could have obligated for fiscal years 2010 through 2017 .

we also interviewed dhs officials , including those from the dhs office of the chief financial officer ( ocfo ) and the s&t finance and budget division to obtain and corroborate information about r&d - related obligations , budget and expenditure tracking tools and reports .

to identify what types of r&d dhs conducts , we reviewed dhs documents including congressional budget justifications and fact sheets .

to learn more about the types of r&d activities that dhs components conduct , we also interviewed officials from each of the 10 components that are involved in the integrated product teams ( ipt ) , which is dhs's primary r&d coordination mechanism .

based on ipt charter documents and s&t ipt guidance , we identified the components that are to participate in the ipt process .

these components were: the countering weapons of mass destruction ( cwmd ) office , the federal emergency management agency , the cybersecurity and infrastructure security agency , the u.s. secret service , the office of intelligence and analysis , the transportation security administration ( tsa ) , the u.s .

citizenship and immigration services , the u.s. coast guard , the u.s. customs and border protection ( cbp ) and the u.s. immigration and customs enforcement .

to determine the extent to which s&t coordinates r&d across dhs , we analyzed dhs guidance documents , such as management directives , instructions , and memoranda , which assign r&d - related roles and responsibilities and govern certain r&d coordination practices .

the guidance documents included a memorandum establishing the ipt process and how the ipt process should coordinate r&d efforts across dhs .

we also interviewed dhs officials with roles and responsibilities related to r&d to obtain their perspectives on r&d coordination and the relevant guidance documents , including officials who manage ipt operations .

to further understand the ipt process , we conducted interviews with officials from the 10 dhs components that participate in the ipt process to obtain their perspectives on the benefits and challenges of the process .

furthermore , we analyzed ipt - related documentation including charter documents , ipt meeting agendas and minutes , and ipt guidance documents to determine how the process facilitates r&d coordination efforts .

we also interviewed dhs officials responsible for department - wide requirements identification .

to examine the extent to which dhs tracks and identifies r&d efforts , we interviewed s&t officials to determine what tracking mechanisms are used .

we also reviewed existing lists of dhs r&d projects , such as dhs's report of coordinated r&d , dhs's responses to congressional inquiries regarding r&d project lists , outputs from electronic tracking systems , such as s&t's project tracker database , and r&d projects listed in congressional budget justification documents , among other things .

we also interviewed s&t officials involved in developing the r&d project information sources to determine how the lists are compiled , how information is entered into the sources , and what the benefits and challenges are for each source of r&d project information that we identified .

in addition , we interviewed officials from dhs's ocfo and reviewed departmental financial management policies to learn about how the recently - implemented common appropriations structure has affected the transparency of r&d efforts across dhs .

to determine the extent to which dhs components with r&d budget authority collected and reported performance information to assess their r&d efforts , we reviewed applicable laws governing performance reporting in the federal government , including the government performance and results act of 1993 ( gpra ) , as updated and expanded by the gpra modernization act of 2010 ( gprama ) , and guidance for implementing these laws .

we also reviewed leading practices , identified in our prior work , used by organizations related to r&d performance indicators .

in addition , we reviewed leading practices for project , program and portfolio management and reviewed dhs documents related to its processes for collecting and reporting its performance information .

the documents reviewed included policies and guidance regarding how these processes are to operate , the information to be collected , as well as documents used to communicate performance information , including dhs's annual performance report , as well as dhs's congressional budget justification documents .

to illustrate how dhs uses one method to track r&d progress , we analyzed selected milestones in the congressional budget justification documents for 7 of dhs's approximately 132 reported r&d projects .

to conduct our analysis , we identified two milestones each from the selection of seven r&d projects that s&t officials consider to be high priority .

we selected the two milestones from the most recent year for each project ; if there were more than two milestones , we randomly selected two .

the milestones , selected from the fiscal year 2018 budget documents , were assessed against dhs guidance that its components are to utilize to develop the milestones .

two analysts independently reviewed the milestones and resolved any disagreements in their assessments .

to further understand the information used to assess r&d performance , we interviewed officials from the seven ipt - participating dhs components with r&d budget authority to learn how they collect and report performance information .

we also examined guidance to components for collecting and reporting performance information , such as performance goals and milestones , and customer feedback mechanisms .

we also interviewed officials from various dhs offices that are involved in managing , collecting or using r&d performance information from across the department .

specifically , we interviewed officials from dhs's office of program analysis and evaluation , office of policy , and ocfo .

dhs's office of program analysis and evaluation coordinates performance management across dhs components .

dhs's office of policy develops strategies , operational plans , and leads the development of operational and resource allocation guidance for the department , among other things .

further , we reviewed performance information and documents related to dhs's process for assessing and reporting its annual performance goals .

this included performance information reported in dhs's annual performance report for fiscal years 2016 through 2018 and in congressional budget justification documents for fiscal year 2018 for the dhs components that conduct r&d .

to conduct our analysis , we compared performance information in the dhs annual performance report and congressional budget justification documents to gpra requirements and omb guidelines for agency performance information .

we conducted this performance audit from october 2017 through january 2019 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the homeland security act of 2002 , as amended , designates the under secretary for science and technology as responsible for coordinating all r&d activities of dhs .

the act also provides that nothing in it precludes other department components from carrying out r&d activities as long as the activities are coordinated through s&t .

as of september 2018 , seven dhs components have budget authority to conduct r&d activities — s&t , the coast guard , the cwmd , the secret service , the cybersecurity and infrastructure security agency , tsa , and the office of the chief information officer within the office of the undersecretary for management .

figure 1 provides an organizational overview of dhs components and offices that are involved in the r&d process as of december 2018 .

s&t reorganized its structure in september 2018 and currently has three technical divisions responsible for managing r&d programs related to improving border , immigration , and maritime security ; supporting first responders ; and countering physical and cybersecurity threats among others , as shown in figure 2 .

most of s&t's r&d portfolio consists of applied and developmental r&d , which can be transitioned to use within 3 years , as opposed to longer - term basic research .

in addition to conducting projects for its dhs customers , s&t conducts research for other federal agencies and first responders .

s&t is also responsible for conducting basic and applied research , and collaborates with other government agencies , academia , the private sector , and others .

questions have been raised about s&t's ability to demonstrate the impact of its investments — in terms of value , tangible products , and advances toward the homeland security mission .

accordingly , for example , house appropriations committee report language has directed s&t to demonstrate how its r&d efforts are timely , with results relatively well defined and to make investment decisions based on clear and sensible priorities .

in 2016 , congress passed the national defense authorization act of 2017 ( ndaa ) which requires dhs to report annually to congress on the department's r&d projects including details such as the project name , the component carrying out the project , associated funding levels , and expected objectives and milestones for each project , among other items .

since dhs began operations in 2003 , we have made multiple recommendations designed to improve dhs efforts to manage and oversee r&d efforts , as described later in this report .

in september 2012 , we reported that dhs did not have a department - wide policy defining r&d or guidance directing its components how to report r&d activities .

as a result , dhs did not know its total annual investment in r&d , which limited the department's ability to oversee components' r&d efforts and align them with agency - wide r&d goals and priorities .

we also reported that dhs's r&d efforts were fragmented and overlapping , which increased the risk of unnecessary duplication .

we recommended that dhs develop policies and guidance for defining , reporting and coordinating r&d activities across the department , and that dhs establish a mechanism to track r&d projects .

as of august 2017 , dhs had implemented these recommendations by , among other things , issuing guidance defining research and development activities and establishing integrated product teams ( ipt ) as a primary mechanism for coordinating r&d .

these actions and others are described in more detail later in this report .

figure 3 provides a summary of key events related to s&t since its inception .

after the consolidation in 2002 of 22 agencies into a single department , dhs had , until recently , different appropriation structures and budget management practices based on agencies' funding structures prior to dhs consolidation .

in 2018 , we found that , with over 70 different appropriations and over 100 formal program , project , or activity accounts , dhs operated for over a decade with significant budget disparities and inconsistencies across its components .

the lack of uniformity hindered visibility , inhibited comparisons between programs , and complicated spending decisions , including for r&d - related programs .

for example , in 2012 we reported that s&t , the domestic nuclear detection office , and coast guard were the only three dhs components with budget authority to conduct r&d .

however , in 2012 , we identified an additional $255 million in r&d obligations by other dhs components at that time .

further , we found in 2012 that the domestic nuclear detection office did not report certain r&d budget data to omb , and r&d budget accounts included a mix of r&d and non - r&d spending , which further complicated dhs's ability to identify its total investment in r&d activities .

within dhs , ipts – established in 2015 – are to identify and prioritize technological capability gaps , and identify current or future r&d efforts or other solutions to close the gap , among other things .

specifically , the ipt process consists of three activities: 1 ) identifying r&d activities in progress , funded , planned , or recently completed ; 2 ) prioritizing technological capability gaps and corresponding r&d efforts to address those gaps ; and 3 ) validating and reporting the gaps .

the dhs ipt effort is led by s&t , but the individual ipts are composed of senior - level officials from across dhs .

ipt members prioritize r&d gaps based on departmentwide needs and requirements , and align current and planned r&d efforts to the identified gaps .

in prioritizing and evaluating the capability gaps , four pre - defined criteria and rating scales are used and are discussed below: strategic alignment: assesses the r&d gaps alignment with dhs - level and component - level strategic priorities .

impact: assesses if addressing the r&d gap would result in enhanced risk or threat reduction capability , among other things .

feasibility: assesses the feasibility of addressing the r&d gap , given its technical complexity .

considerations include feasibility related to technology , time , and transition .

r&d needs: assesses whether the r&d gap would provide a critical r&d solution in an otherwise unaddressed area .

the ipt's role in coordinating r&d is discussed later in this report .

gpra , as updated and expanded by gprama , requires agencies to establish annual performance goals with target levels of performance against which to measure progress towards those goals .

in addition , gpra requires executive agencies to prepare an annual performance report on program performance for the previous fiscal year .

dhs has developed goals and targets to assess and communicate r&d performance .

as shown in figure 4 , dhs's performance assessment process also includes identifying performance gaps and implementing corrective actions to address unmet performance goals .

dhs uses strategic and management performance goals and measures to assess and communicate on the performance of its r&d efforts .

in addition , dhs uses milestones to track and communicate progress of its r&d project activities .

milestones: a milestone is a scheduled event signifying the completion of a major deliverable or a phase of work .

milestones can help agencies demonstrate that they have clear and fully developed strategies and are tracking progress to accomplish their goals .

milestones are often used as the basis of an alternative form of performance goal .

milestones related to dhs r&d efforts are reported to congress and publicly available through the dhs congressional budget justification .

strategic goals: a type of performance goal used to reflect achievement of missions that are publicly reported in the dhs annual performance report .

as part of dhs's annual performance report , these goals are subject to gpra and gprama requirements .

management goals: a type of performance goal used to gauge program results and tie to resource requests that are reported to congress and publicly available through the dhs congressional budget justification along with the strategic goals .

as we previously reported in 1997 , experts in research measurement have tried for years to develop indicators that would provide a measure of the results of r&d .

however , the very nature of the innovative process makes measuring the performance of science - related projects difficult .

for example , a wide range of factors determine if and when a particular r&d project will result in commercial or other benefits .

it can also take many years for a research project to achieve results .

dhs is required to report department - wide r&d - related funding to omb on an annual basis .

dhs uses several mechanisms to report the r&d - related funding , including budget authority ( the legal authorization to obligate funds ) , obligations ( binding agreements to make a payment for services ) , and outlays ( payments to liquidate obligations representing amount expended ) .

further , omb requires agencies to submit data on r&d programs as part of their annual budget submissions on investments for basic research , applied research , development , r&d facilities construction , and major equipment for r&d using omb's definition of r&d .

based on our analysis of omb's federal obligations data , we identified r&d - related obligations data for dhs components for fiscal years 2010 through 2017 .

figure 5 depicts the r&d related obligations that were reported for fiscal years 2010 through 2017 , which , on average , were about $1.3 billion annually or more than $10 billion overall for that time frame .

additionally , s&t obligated nearly 80 percent of all dhs r&d funds for that time period .

s&t may conduct or fund r&d activities on its own or jointly with other entities .

in addition to s&t , six other dhs components currently have budget authority to conduct r&d — the coast guard , cwmd , tsa , secret service , cybersecurity and infrastructure security agency , and the undersecretary for management .

in august 2018 , s&t reported that there were at least 132 ongoing r&d projects across the department .

some r&d projects aim to produce a specific prototype or piece of technology for an end user , while others might be for developing it systems , conducting specific training , or providing written reports , or knowledge products .

according to s&t officials , s&t generally leads or funds r&d projects by providing technology and knowledge products for four homeland security areas: disaster resilience .

improving community resilience to natural disasters through technology and tools that support planning , decision - making and mitigation efforts ; critical incidents .

improving technological capabilities during all stages of critical incident response ; border security .

improving the nation's ability to detect , interdict and prosecute illegal activity across air , land and sea .

cybersecurity .

developing technologies , tools and techniques to defend , mitigate , and secure current and future systems , networks and critical infrastructures against cyberattacks .

figure 6 illustrates the types of r&d projects that are either led or funded by s&t for each category .

for more in - depth examples and descriptions of s&t projects , please see appendix i .

in its efforts to determine how to best support the dhs components and first responders , s&t seeks first to identify the end user's needs by discussing operational challenges with components and first responders ; then develop prototypes or leverage existing technologies to find solutions ; and finally to test and evaluate potential solutions to ensure that they meet the end user's needs and ultimately deploy solutions to the field .

the other six dhs components with r&d budget authority typically lead and fund r&d projects tailored to support their specific operational requirements and respective missions .

examples of r&d projects conducted by dhs components other than s&t are listed below in table 1 .

dhs established its ipt process in august 2015 as the central mechanism to coordinate r&d efforts across the department , in accordance with recommendations we made in 2012 .

the ipt process works to identify dhs technological capability gaps and coordinate r&d to close the gaps across dhs mission areas .

the ipts consist of senior representatives from operational components .

as of october 2018 , ipts are organized according to the department's identified missions and include the following sub - ipts , as shown in table 2 .

each ipt has an establishing charter document , which formally identifies the ipt component members and responsibilities and lists the corresponding sub - ipts .

ipts and sub - ipts are to meet multiple times throughout the year to support the process of identifying and prioritizing r&d capability gaps and r&d efforts .

for example , the charter for the “secure borders” ipt states that they anticipate meeting at least 2 or 3 times per year , or more frequently to support the annual program planning and budgeting process .

overall , components reported that the ipt process enhanced collaboration and improved visibility into r&d efforts across dhs .

officials from all 10 of the dhs components we interviewed reported the ipt process has been helpful in various ways , including identifying capability gaps , prioritizing and closing the gaps , and providing transparency and insight into other components' r&d efforts .

for example , cbp officials reported that , through the ipt process , they were able to identify r&d projects that the coast guard had been pursuing related to maritime security .

the r&d projects that coast guard was pursuing were also of interest to cbp , and therefore cbp worked through the ipt process to prevent duplicative work and combine some of those efforts .

in another example , tsa officials reported that they collaborated with the secret service to test explosive screening technologies , and that the ipt process facilitated their ability to collaborate and share information about the screening technologies .

in addition to enhancing collaboration , component officials provided their perspectives on how the ipt process prioritizes technology capability gaps that components have identified .

for example , tsa officials reported that the gap identification and prioritization process works well , but that funding r&d activities to close the gaps is more challenging because it is influenced heavily by competing budget priorities , emerging threats , and other dhs senior leadership priorities .

tsa officials further reported that departmental resource constraints limit the number of identified capability gaps that can be addressed .

however , officials from cbp reported that several r&d projects were successfully implemented after cbp had worked with s&t to identify a capability gap and transition a solution to close the gap , such as certain upgrades needed on cbp trucks .

s&t officials stated that they have also taken steps to integrate with the department's joint requirements council and utilize component requirement executives who work with component agencies to provide a basis for requirements and aid the components with the means to track the progress and disposition of each capability gap on a regular basis .

in 2012 , we found that , among other things , dhs had not developed a policy defining who was responsible for coordinating r&d within the department and what processes should be used to coordinate it .

as a result , components did not consistently coordinate with s&t on what r&d was planned or underway , leading to increased risk of unnecessary duplication of r&d efforts .

we recommended that dhs develop and implement policies and guidance for overseeing r&d that included , among other things , a description of the department's process and roles and responsibilities for overseeing and coordinating r&d investments .

dhs concurred with our recommendation , and , in response , the secretary for homeland security delegated the authority to coordinate and integrate the department's r&d , testing , evaluation efforts to the under secretary for science and technology in 2014 .

in 2015 and 2016 , dhs issued two guidance documents regarding the establishment and progress of the ipt process .

these documents specified how dhs , through the ipt process , is to implement processes and mechanisms to coordinate department - wide r&d efforts .

additionally , in january 2017 , dhs issued an r&d directive and associated instruction to formalize r&d reporting and coordination among components , as shown in figure 7 .

the 2017 directive and associated instruction identify the roles and responsibilities , including ipt participation requirements , for key entities involved in r&d across dhs .

however , the directive and instruction do not specifically address steps to be taken if components do not adhere to the requirements .

for example , the january 2017 dhs instruction states that “to effectively coordinate dhs r&d activities , dhs components are required to follow the dhs ipt process.” however , officials from cwmd stated that they do not participate in the s&t - led ipt sessions because they have their own internal process for identifying and prioritizing capability gaps .

s&t officials stated that cwmd's predecessor organization , the domestic nuclear detection office , participated in the ipt process until dhs initiated a reorganization of its weapons of mass destruction programs ( resulting in the current cwmd ) .

current non - participation by cwmd , which has the second - largest r&d budget within dhs and obligated approximately 17 percent of dhs r&d funds , or $176 million in fiscal year 2017 , poses risk of r&d project information not being shared among components .

in august 2018 , we reported that dhs's chemical defense programs and activities were fragmented and not well coordinated across the department , including r&d activities .

we recommended that cwmd develop a strategy and implementation plan to help dhs integrate and coordinate its chemical defense programs and activities , among other things .

additionally , in its 2014-2018 strategic plan , dhs states that , to anticipate key threats , dhs should , among other things , prioritize r&d activities related to chemical , biological , radiological , and nuclear terrorism .

given these factors , cwmd's participation in the ipt process is important to ensure that all r&d efforts are fully coordinated thereby mitigating the risk of potential duplication of other dhs r&d efforts .

s&t officials recognize that some components might not be complying fully with the departmental directives and associated guidance documents which require participating in the ipt process – the key r&d coordination mechanism within dhs .

s&t officials stated that , despite these challenges , they have strong collaborative relationships with the components , and the existing collaboration mechanisms , such as the ipt process , continue to mature and facilitate r&d - related information sharing .

however , dhs guidance documents require that components participate in the ipt process .

by ensuring that all required components participate in the ipt process , dhs can help s&t maintain visibility of r&d projects in order to fulfill its statutory role of coordinating r&d .

since 2012 , s&t has taken steps to identify and track information related to ongoing r&d projects across dhs , and in 2017 , dhs developed a common appropriations structure that standardized r&d budgeting processes across the department .

however , s&t's efforts to identify and track r&d project information have limitations and can result in information that is not comprehensive .

we also identified challenges in collecting information related to the achievement of r&d milestones .

in 2017 , dhs developed a common appropriations structure that allowed it to calculate and monitor its expenses , including r&d expenses , across the department .

officials from dhs's ocfo reported that , prior to the new structure , some components categorized their r&d expenses as other types of expenses , such as “salaries and expenses.” these categorizations made it difficult to account for r&d expenses outside of an individual component's budget management division .

furthermore , ocfo officials reported that components previously utilized inconsistent r&d definitions , which often led to discrepancies in how components would report r&d activities .

in our april 2018 report , we found that dhs had operated for over a decade with significant budget disparities and inconsistencies across its components .

we found that the lack of uniformity hindered visibility , inhibited comparisons between programs , and complicated spending decisions .

according to dhs ocfo officials , the introduction of the common appropriations structure , among other things , has helped improve transparency within dhs and among the components so that r&d can be more readily identified and tracked .

dhs is also able to compare r&d funding amounts throughout dhs more easily than in previous years .

in addition , of the seven components that have their own r&d funding to report , five indicated that the new structure has improved the department's ability to identify and report r&d activities .

we identified multiple sources of component r&d project information , each posing its own challenges or limitations .

as described below , these challenges and limitations include difficulty in collecting and integrating r&d project information , and reporting that is not comprehensive .

dhs's response to the national defense authorization act of 2017: the ndaa , passed in december 2016 , required dhs to provide a list of ongoing r&d projects and accompanying milestone information by january 2017 , and annually thereafter , to specified congressional committees .

in december 2017 , dhs officials reported that they had not yet submitted the report , and anticipated that the response to the ndaa requirement would be completed by january 2018 .

in august 2018 , dhs submitted its response to the committee , then 19 months late .

s&t officials stated that the reporting delays were due to challenges in collecting and integrating the data .

s&t officials also reported that it used the components' congressional budget justification documents as a starting point to identify r&d projects to include in its report in response to the ndaa requirement .

however , additional details about the r&d projects had to be collected via a “data call” process from the components .

s&t officials told us that it was a challenge to have components report information about their r&d projects consistently and systematically .

furthermore , s&t officials identified terminology - related challenges in their r&d data call efforts , including making distinctions between r&d projects , efforts , and activities .

s&t officials also reported that , in its current format , they would not be able to easily identify how many projects were added to the ndaa list across years , or if a given r&d project experienced a large increase or decrease in funding .

annual reports of coordinated r&d: in response to a 2015 request from the secretary of homeland security that the ipts identify r&d work being performed across dhs , s&t issued a “report of coordinated r&d” in 2016 and 2017 .

the content for the reports was developed through a “data call” process , and the reports identified r&d activities and projects across dhs .

the reports – for 2016 and 2017 – contain tables of r&d project names and the component leading the project , among other things .

however , during the course of our review , s&t officials reported that these annual reports should not be considered authoritative lists of r&d projects due to inconsistencies in the project information that components reported which led to the reports not being comprehensive .

for example , when we asked about some significant variations in the number of projects between 2016 and 2017 , s&t officials told us that one dhs component responded to the data call with a list of r&d activities that included a “wish list” of r&d for their component , and not actual ongoing r&d activities .

dhs officials acknowledged that they do not have a mechanism to ensure the comprehensiveness of information reported by the components through the data call process .

in addition , two components did not respond to s&t's request for r&d project information for the 2017 annual report of coordinated r&d .

congressional budget justifications: in may 2018 , in the absence of a single , comprehensive list of r&d projects across dhs prior to the issuance of its report in response to the ndaa , s&t officials referred us to the r&d projects listed within the seven individual congressional budget justifications for the components that currently have budget authority to conduct r&d .

furthermore , as discussed earlier , s&t officials used the congressional budget justifications as their starting point in developing their response to the ndaa .

however , s&t officials stated that there may be differences between the projects listed in the ndaa response and the projects listed in the congressional budget justifications .

for example , s&t stated that the report in response to the ndaa includes all “ongoing” projects , regardless of the fiscal year in which they received funds ; while the congressional budget justifications include r&d projects for which funding was requested for the given fiscal year .

in other words , s&t officials clarified , they included all r&d projects in their response to the ndaa that had project activity , regardless of whether funding was requested in a particular congressional budget justification .

s&t's project tracker database and the s&t analytical tracking system: a 2014 house appropriations committee report noted that the committee had repeatedly raised questions about s&t's prioritization of r&d projects and that , without the ability to easily review and compare detailed information on all s&t projects and activities , the under secretary for s&t could not effectively carry out s&t's responsibilities .

accordingly , the committee directed s&t to develop a method or system for tracking all s&t - funded r&d projects .

a november 2016 dhs directive reiterates this requirement , specifying that the list of projects should be updated on at least a quarterly basis throughout the duration of an r&d project .

s&t officials told us that , in response to the committee report , they developed the project tracker database , which was in use at the time of our review , but was transitioned to a new system , the s&t analytical tracking system , in september 2018 .

neither the s&t analytical tracking system nor its predecessor system , the project tracker database , is intended to comprehensively collect information on r&d projects across the department , only for r&d projects managed within s&t .

given the recent implementation of the s&t analytical tracking system , it is too soon to tell whether it will improve and streamline s&t's efforts to collect and analyze r&d - related information within the directorate .

in addition , s&t officials stated that none of the above r&d information sources are suited to long - term trend analysis or data aggregation of department - wide r&d project information , and that these sources are disparate across dhs .

s&t officials also acknowledged that better aligning r&d project information sources is an important aspect of improving how the department collects information dhs - wide .

standards for internal control in the federal government call for agencies to maintain quality information that is , among other things , current , accurate , accessible , and provided on a timely basis .

furthermore , the standards call for an agency's management team to process relevant data from reliable sources and utilize it to make informed decisions .

the disparate r&d project information sources that s&t maintains , such as dhs's response to the national defense authorization act of 2017 and the annual reports of coordinated r&d discussed above , and the manual data - call process it takes to update the sources limits departmental access to current and reliable r&d project information .

for example , an internal dhs web - based portal with pre - defined fields could provide component officials with a means for reporting information more consistently and comprehensively .

without complete and readily accessible r&d information , dhs may not have the information it needs to make informed decisions about r&d investments , such as which projects are to be prioritized .

by developing a mechanism to address challenges and limitations related to the collection , integration , and comprehensiveness of r&d data across the department , s&t can improve its visibility on r&d efforts across dhs in accordance with its role as dhs's coordinator of r&d efforts .

dhs components have processes in place to collect certain indicators of r&d performance , but we found that these processes have limitations .

the methods used to assess and report performance and progress of dhs r&d efforts we identified include: milestone information – used to assess and communicate progress to congress and agency decision makers on individual r&d projects strategic and management performance goals – milestone and other information is aggregated to provide summary information on r&d performance by mission area customer feedback – information gathered by component officials on r&d customer perspectives on the utility of ongoing or completed projects below is our analysis of the three methods .

milestones are often used as the basis of an alternative form of performance goal .

performance goals specified in alternative form must be described in a way that makes it possible to discern if progress is being made toward the goal .

milestones related to dhs r&d efforts are reported to congress and publicly available through the dhs congressional budget justification .

a milestone is a scheduled event signifying the completion of a major deliverable or a phase of work , and can be described in a way that makes it possible to discern if progress is being made toward a goal .

milestones can also help agencies demonstrate that they have clear and fully developed strategies and are tracking progress to accomplish their goals .

in our analysis of 14 milestones for seven s&t high - priority r&d projects identified in fiscal year 2018 dhs budget justification documents , we found that 3 of the 14 milestones fully adhered to dhs guidance for milestone descriptions .

dhs budget development guidance suggests dhs components , which develop milestones for inclusion in congressional budget justification documents , utilize leading practices provided in the guidance .

the leading practices state that successful milestones contain the following characteristics: 1 .

specific - provide a clear understanding of expected results ; 2 .

measurable - the result can be reported in quantitative or qualitative 3 .

results - oriented / relevant - milestone clearly links to results - oriented activities such as strategy , budget , and / or program / project plans ; 4 .

time - bound - milestone specifies a beginning and end date for as shown in table 3 , we identified that more than half of the milestones ( 8 of 14 ) were not specific and 10 of 14 were not results - oriented .

eleven of 14 milestones we analyzed were measurable and time - bound .

while our analysis is not generalizable to all fiscal year 2018 r&d milestones , it illustrates areas where the selected milestones do not fully incorporate the dhs guidance .

below is more detail on our assessment of the specific and results - oriented guidance .

specific .

of the 14 milestones we reviewed , eight did not contain specific information that would allow reviewers to have a clear understanding of the result expected in connection with the milestone .

for example , one milestone for a cyber - related r&d project states that “testbeds and pilots would be conducted with at least one department or agency.” however , the milestone is not specific enough to ascertain what types of testbeds or pilots are being assessed and how the testbed effort would link to a possible end result .

results - oriented and relevant .

ten of the 14 milestones that we reviewed did not clearly link the milestone back to results - oriented activities , such as strategy , budget , or project / program plans .

for example , one milestone for a first responder program stated the following: “transition , commercialize , or make available through open source platforms at least three technologies ( eg , analyses , models , technology prototypes and / or knowledge prototypes ) .” it is unclear which technologies would be transitioned or how these technologies would be transitioned and made available .

according to dhs ocfo officials , dhs congressional budget justifications , which include milestones , serve to provide explanation and detail for why dhs believes congress should support the department's r&d projects .

dhs components are instructed by dhs's budget office to routinely submit their congressional budget justifications for internal dhs review , which is a process and mechanism that results in the supporting justifications for r&d funding requests .

dhs ocfo officials also stated that they are not aware of a singular reason for why milestones do not consistently incorporate dhs's guidance and stated that they have also identified instances in which milestones do not align with the guidance .

as our analysis indicates , s&t's milestones could better incorporate milestone criteria included in dhs's budget preparation guidance .

without milestone information that more closely aligns with dhs guidance , congress and dhs decision - makers may not be able to fully assess whether r&d projects are meeting specific goals within assigned time frames or identify what adjustments , if any , may be needed to facilitate the achievement of project goals and the r&d mission overall .

dhs has developed 12 performance goals to assess and report on its r&d efforts , dhs is required to identify department - wide goals in its strategic plan and annual performance report .

for fiscal years 2016 through 2018 , dhs's annual performance report included two strategic performance goals related to s&t's r&d efforts .

dhs's congressional budget justification includes the two strategic performance goals as well as 10 related management performance goals .

for a detailed listing of the 12 performance goals , see table 4 .

seven of the 10 management performance goals were for s&t r&d efforts and the remaining three were for domestic nuclear detection office's r&d efforts , which cover the components that account for 96 percent of dhs' fiscal year 2017 r&d obligations .

dhs has performance goals for mission programs that produce operational results that link directly to the dhs strategic plan , according to officials from the ocfo's program analysis and evaluation division .

dhs also uses milestones to track the progress of the other components' r&d efforts .

dhs components that conduct r&d use various methods to collect and analyze customer feedback to assess their r&d efforts , as shown in table 5 .

however , dhs is not well positioned to integrate the results because limited customer feedback information is collected and analyzed .

six dhs components that have r&d - related responsibilities evaluate customers' needs and improve customer satisfaction by listening to customers' feedback about the quality of deliverables they receive — both good and bad — and making changes necessary to enhance that deliverable .

specifically , officials from s&t , the coast guard , cwmd , tsa , the cybersecurity and infrastructure security agency , and the secret service stated they have varying methods in place for gathering customer feedback regarding the progress and the results of r&d activities and deliverables .

below is a summary of these components' efforts to consider customer feedback .

s&t .

s&t's project management guide outlines a process for ensuring customer requirements are being adequately met using a customer survey that can be modified and provided to the customer to complete at each major milestone .

in addition , proceedings ( eg , minutes ) from regularly scheduled meetings with customer and end user groups may be used to gather information regarding value and operational impact in lieu of a survey .

the s&t survey asks customers to rate their overall satisfaction with s&t products and services , along with specific aspects of support , such as providing products in time to meet needs and effectively keeping customers informed .

however , out of the 97 r&d activities that s&t reported in fiscal year 2017 and the 110 activities in fiscal year 2016 , s&t collected one customer survey form .

coast guard .

the coast guard also has a process in place for surveying and interviewing its customers following the completion of an r&d project and officials reported using this information for future r&d planning .

the coast guard's survey instrument seeks feedback on: customer satisfaction , timeliness , utility , and communications , among other things .

the customer service survey is distributed for feedback on deliverables .

at least 6 months after an r&d project is completed , coast guard also conducts an in - person interview with project sponsors to collect project transition performance success and feedback information .

the surveys that coast guard uses to obtain feedback elicit a relatively low number of responses from customers , significantly limiting their usefulness in soliciting feedback data .

specifically , the response rates for fiscal years 2013-2017 were 16% , 17% , 27% , 13% , and 17% , respectively .

experts on customer satisfaction measurement have stated that although survey response rates are never 100 percent , an organization should strive to get its rate as close as possible to that number .

they suggest that ideally , organizations can obtain response rates of over 70 percent .

cwmd .

cwmd does not have a formal mechanism , such as standard processes and procedures , for collecting and analyzing customer feedback .

however , cwmd officials stated that certain informal mechanisms are used to collect customer feedback .

for example , cwmd officials reported that the cwmd office of policy , plans , analysis , and requirements directorate communicate with customers and gather customer needs and requirements .

in addition , as part of these informal mechanisms , internal and external reviews feedback may be obtained from eventual end users of the r&d technology such as operators from cbp , the u.s. coast guard , and the tsa , according to cwmd officials .

cybersecurity and infrastructure security agency .

the directorate does not have a formal mechanism for collecting and analyzing customer feedback .

however , periodic control gates are used to gather customer feedback , according to directorate officials .

the input received during these reviews is used to make corrective actions and manage r&d efforts as necessary .

for example , according to directorate officials , they conduct a comprehensive review of r&d coordination efforts annually to determine what was effective and what can be improved .

tsa .

tsa does not have a formal mechanism for collecting and analyzing customer feedback .

however , according to tsa officials , informal feedback may be obtained through review of the weekly reports and meetings regarding recent developments and project milestones .

in addition , feedback may be obtained during quarterly program management reviews , third party project development , and certification testing .

secret service .

the secret service does not have a formal mechanism for collecting and analyzing customer feedback .

however , according to secret service officials , informal feedback may be obtained in conjunction with other related internal review activities , including program management reviews .

to formalize and improve customer feedback processes for r&d efforts , the national academy of sciences has stated that feedback from both r&d failures and successes may be communicated to stakeholders and used to modify future investments .

research on leading practices in the area of customer satisfaction suggests that multiple approaches are needed to effectively listen to customers about their perceptions of quality service and needs .

the research also points to a need for centrally integrating all customer feedback so that managers can achieve a better understanding of customers' perceptions and needs .

also , we have previously reported that leading organizations combine quantitative and qualitative listening tools to obtain customer feedback and then centrally integrate the data in one location .

such approaches include the following: customer satisfaction surveys .

we previously reported that most major organizations use tools such as surveys to periodically capture customers' overall perceptions about their organization and to measure satisfaction with specific transactions soon after they occur .

these surveys can be administered through the mail , by telephone , in person , or electronically .

benchmark surveys .

benchmark surveys gather perceptions of performance from the entire market .

these surveys usually gather customer perceptions of performance about top competitors in an industry .

this allows the company to examine its customer - perceived strengths and weaknesses in the overall marketplace .

while continuous improvement may be a result of this listening tool , the real value , according to the research in this area , comes from breakthrough thinking to gain a sustainable advantage .

focus groups .

organizations use focus groups to get better information from customers than survey results provide .

in these groups , customers are probed about why they answered survey questions the way they did .

customer interviews .

conducting interviews with customers can provide a way to get very detailed information about their specific needs and problems .

like focus groups , this tool is used by leading customer service organizations to probe survey respondents as to why they answered survey questions a certain way .

the national academy of sciences have stated that evaluating the relevance and impact of r&d is a key stage of the r&d process and that measuring the impact of r&d activities requires looking to the end users and stakeholders for an evaluation of the impact of a research program , such as through polling or systematic outreach .

in addition , standards for internal control in the federal government calls for entities to determine an oversight structure to fulfill responsibilities that are set forth by feedback from key stakeholders , among other things .

as a result of the limited customer feedback information that is collected and analyzed , dhs is unable to more fully understand its customers' perceptions and experience to allow it to assess the benefits and performance of its r&d efforts .

moving forward , standard processes and procedures for collecting and analyzing r&d customer feedback would help in assessing r&d efforts .

since 2010 , dhs has obligated more than $10 billion dollars on r&d to develop technologies to support dhs's efforts to prevent , mitigate , and recover from terrorist and natural threats .

s&t officials indicated that they have strong collaborative relationships with components ; however , it is important that required components fully participate in the ipt process in order for s&t to maintain visibility of r&d projects and successfully fulfill its statutory role of coordinating r&d and to help reduce the risk of potential duplication of r&d efforts across the department .

furthermore , s&t faces challenges and limitations related to the collection , integration , and comprehensiveness of information on r&d projects .

without a mechanism that aligns information sources and results in comprehensive and accurate data , among other things , dhs may not have the information it needs to make informed decisions about r&d investments .

s&t also does not fully leverage existing guidance when developing milestones for r&d efforts .

without milestone information that more fully aligns with dhs criteria , congress and dhs decision - makers may not have a full understanding of r&d progress and challenges .

finally , standard processes and procedures for collecting and analyzing r&d customer feedback would help to assess its r&d efforts .

we are making the following four recommendations to the deputy secretary of the department of homeland security: the deputy secretary of the department of homeland security should ensure that all components adhere to ipt participation requirements , in accordance with the dhs directives .

 ( recommendation 1 ) the deputy secretary of the department of homeland security should develop a mechanism that aligns processes and information sources for collecting r&d project data from dhs components to ensure that the information can be collected , integrated and result in a comprehensive accounting of r&d projects dhs - wide .

 ( recommendation 2 ) the deputy secretary of the department of homeland security should direct ocfo program officials to ensure that s&t take steps to more fully incorporate leading practices , such as those included in dhs's budget preparation guidance , into r&d milestones .

 ( recommendation 3 ) the deputy secretary of the department of homeland security should develop standard processes and procedures for collecting and analyzing customer feedback , applicable to components conducting r&d , for improving the usefulness of existing customer feedback mechanisms to assess r&d efforts and for implementing such mechanisms where absent .

 ( recommendation 4 ) .

we provided a draft of this report to dhs for review and comment .

dhs provided written comments which are reproduced in appendix ii .

in its comments , dhs concurred with our recommendations and described actions planned to address them .

s&t , ocfo , cbp , the cybersecurity and infrastructure security agency , and cwmd also provided technical comments , which we incorporated as appropriate .

with regard to our first recommendation , that the deputy secretary of the department of homeland security should ensure that all components adhere to ipt participation requirements , in accordance with dhs directives , dhs stated that s&t's office of science & engineering will revise the relevant dhs directive to require participation in the ipt process by all components .

dhs estimated that this effort would be completed by december 31 , 2019 .

this action , if fully implemented , should address the intent of the recommendation .

with regard to our second recommendation , that the deputy secretary of the department of homeland security should develop a mechanism for collecting r&d project data in order to complete a comprehensive accounting of r&d projects dhs - wide , dhs stated that s&t's office of science & engineering will revise the relevant dhs directive to include requirements for data collection on all r&d projects across dhs to ensure alignment of the appropriate data elements and existing guidance .

dhs estimated that this effort would be completed by december 31 , 2019 .

this action , if fully implemented , should address the intent of the recommendation .

with regard to our third recommendation , that the deputy secretary of the department of homeland security should direct ocfo program officials to ensure that s&t take steps to more fully incorporate leading practices , such as those included in dhs's budget preparation guidance , into r&d milestones , dhs stated that the ocfo will continue to work with s&t to incorporate the leading practices and that the ocfo will validate all s&t annual budget submissions and provide s&t feedback , as appropriate .

dhs estimated that this effort would be completed by april 30 , 2020 .

this action , if fully implemented , should address the intent of the recommendation .

with regard to our fourth recommendation , that the deputy secretary of the department of homeland security should standardize processes for collecting and analyzing customer feedback to aid in assessing r&d efforts , dhs stated that s&t's office of science & engineering will revise the relevant dhs directive to incorporate customer feedback procedures into the ipt process for the recipients of r&d programs .

dhs estimated that this effort would be completed by december 31 , 2019 .

this action , if fully implemented , should address the intent of the recommendation .

we are sending copies of this report to the appropriate congressional committees and the secretary of homeland security .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff members have any questions about this report , please contact william russell at ( 202 ) 512-8777 or russellw@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix iii .

the following appendix provides a general overview of the department of homeland security's ( dhs ) science and technology directorate ( s&t ) research and development ( r&d ) projects and programs that support the following homeland security mission areas: ( 1 ) border security ; ( 2 ) disaster resilience ; ( 3 ) critical incidents , and ( 4 ) cybersecurity .

the examples provided below are illustrative and therefore not intended to provide a comprehensive list of dhs r&d programs or projects .

s&t and the u.s. coast guard conducted drone demonstrations and tests at two sites in mississippi to test unmanned aerial systems before they are deployed to the field .

the technical assessment of counter unmanned aerial systems technologies in cities is designed to help public safety and industry officials identify potential methods for countering nefarious uses of small unmanned aerial systems .

the wall system design support tool independent verification and validation seeks to strengthen the u.s. border patrol's decision analysis model used to identify the areas of the border where a wall would be most beneficial .

the border research in instrumented construction project is designed to identify cameras , sensors and other technology that can be applied on or near a smart wall via ground , surface / air , subsurface and water to enhance border security and agent safety .

the apex border situational awareness program aims to help u.s. customs and border protection access more data sources , develop decision support tools and share information with partner law enforcement agencies to improve situational awareness .

the integrated maritime domain enterprise is a platform that seeks to bridge disparate data systems to make it easier for dhs components to share information and collaborate .

the adaptive sensor analytics project aims to provide automated data analytics to process satellite imagery , identify patterns of nefarious activity and alert dhs officials .

ground - based technologies program seeks to improve the ability to detect illegal activity at the border through stronger situational awareness , automated detection and alerts , target classification and tools to promote agent safety air - based technologies program is designed to identify , test and evaluate unmanned and manned aircraft platforms and sensors for law enforcement , search and rescue , and disaster response in both land and maritime environments .

the expert tracker training program aims to help u.s. border patrol agents improve their ability to track movement in rough terrain along the nation's borders .

port of entry based technology program seeks to improve illicit cargo detection and legitimate cargo throughput by upgrading legacy scanning systems and linking them to new analysis and information sharing tools that may make the most of personnel resources .

the port of entry people screening program aims to identify , evaluate and implement combinations of process and technology improvements that facilitate the movement of people through the nation's air , land and sea ports of entry .

autopsy is an open - source digital forensics platform that seeks to help law enforcement determine how electronic devices were used in a crime and recover evidence .

voice forensics aims to help identify individuals who make hoax rescue calls to the u.s. coast guard , which may make it easier to find and prosecute suspects .

child exploitation image analytics seeks to reduce the amount of time it takes to identify and rescue children from exploitation , as well as identify perpetrators , through automated face recognition algorithms and forensic tools .

the tunnel detection and surveillance program is designed to help border officials detect and locate clandestine tunnels , as well as gather forensic data to support investigation and prosecution of drug smuggling activities .

the port of entry forensics and investigations program aims to help combat transnational crime and investigate child exploitation and human trafficking through open source data and forensic analysis of material collected from suspicious packages and cargo .

dhs s&t seeks to help improve community resilience to natural disasters through technology and tools that support planning , decision making and mitigation efforts .

the canada - u.s .

enhanced resiliency experiment series aims to use real - world exercises to demonstrate that seamless communication is possible between responders on either side of the northern border during a large - scale emergency .

dhs s&t and the central united states earthquake consortium are developing a suite of decision support tools designed to help emergency managers analyze data used when planning , managing , coordinating and communicating during natural disasters the mutual aid resource planner is a prototype application designed to help jurisdictions develop more accurate resource plans by incorporating custom data on geospatial hazards , risk assessments and potential mutual aid partners .

the national mutual aid technology exercise seeks to test existing mutual aid systems to improve users' ability to exchange information between systems in real time and develop technical guidance for future use .

the coastal resilience center of excellence aims to conduct targeted research and education to address key challenges facing coastal communities in the united states , including storm surge modeling , pre - disaster planning , communicating risk and more .

the flood apex program is designed to help identify and develop technology that can reduce flood - related fatalities and property loss , increase community resilience and improve flood preparation , response and recovery .

the internet of things low cost flood inundation sensors project seeks to develop and test sensor technology that can provide real - time updates on rising water levels .

the kentucky dam safety project aims to create technology and processes to better monitor dams and alert communities of potential danger , reducing loss of life and property .

the advanced circulation modeling tool seeks to accurately predict coastal flooding threats to help emergency managers better coordinate evacuation and response .

the hurricane evacuation - extended platform is a decision support tool for emergency managers designed to organize and stage resources for hurricane response .

the simulation - based decision support system for water infrastructural safety lite™ tool is designed to quickly model the effects of potential dam breaks , helping officials develop accurate emergency response plans and anticipate evacuation needs .

the tunnel plug is an inflatable device that aims to seal off subway tunnels to prevent water from flowing into the system , minimizing damage to critical transportation systems .

the linking the oil and gas industry to improve cybersecurity project seeks to facilitate cooperative research , development , testing and evaluation procedures to improve cybersecurity in petroleum industry digital control systems the homeowner flood insurance roundtable aims to help reduce future uninsured flood losses by identifying decision support and research and development needs .

the automated national structures inventory project is seeking to build a comprehensive list of private and commercial property at risk for flood damage , which may help promote proper insurance and more effective flood protection efforts .

the smart cities iot innovation project is designed to help first responders improve their situational awareness through advances in autonomous drone navigation , intelligent building sensors and body - worn interoperability platforms .

the wireless emergency alerts research , development , testing and evaluation program aims to inform changes to the federal communications commission's alerting system , including increased character length and adding urls , pictures , videos and geo - targeting capabilities .

the system assessment and validation for emergency responders program seeks to evaluate available responder technology on affordability , usability , and other criteria to help agencies understand which equipment will best fit their needs .

the urban operational experimentation program is designed to let responders test new technologies in real - world settings , and may help provide developers with direct feedback on how their products can better meet operational needs .

the enhanced dynamic geo - social environment training platform is a free virtual tool that aims to allow responders to practice responding to an active shooter incident , whether within a single agency or with multiple jurisdictions and disciplines .

the surface transportation explosives threat detection program is aiming to develop screening technology that can identify potential threats on people and in their bags without physically interacting with them .

the explosives detection canine program is designed to help detection canine teams identify new explosive compounds through non - hazardous training aids and increase their proficiency through realistic self - assessment and training events across the country .

the datacasting project aims to help responders send encrypted video , data files , and other critical information through existing public broadcast television signals , which helps prevent other communication channels from being overwhelmed .

the next - generation incident command system , a web - based platform , seeks to allow responders to share data and request assistance in real - time , and also allows officials to observe and make critical decisions during evolving situations to better support preparation , response , and recovery .

the android team awareness kit , a free app , is designed to help responders visually track team members and assets in real time during an incident , as well as share encrypted data across jurisdictions , disciplines , and components .

the assistant for understanding data through reasoning , extraction and synthesis platform aims to help responders overcome information overload by providing actionable insight based on up - to - the - minute sensor data .

the first responder electronic jamming exercise seeks to identify mitigation tactics against intentional or accidental communications jamming , which responders were able to practice implementing in realistic scenarios .

the telephony denial of service program is designed to help improve 911 emergency call centers' ability to defend against attacks through cyber security technologies that can analyze incoming calls and may help determine potential threats in real time .

the finding individuals for disaster and emergency response is designed to detect human heartbeats under up to 30 feet of rubble , which may help responders more effectively target rescue efforts .

the rapid dna technology can complete a dna test within 90 minutes or less from the field , which seeks to help officials identify victims and inform family members in a timely manner .

the forensic video exploitation and analysis tool aims to help responders quickly analyze video to identify potential suspects by allowing users to tag a person to a left - behind item and reconstruct that individual's path across multiple camera views .

the cyber risk economics program seeks to fund applied r&d , knowledge products by gathering stakeholders across government , industry and academia to discuss cyber risk economics capability gaps and needs .

through these stakeholder discussions , along with scholarly cybersecurity economics research literature reviews and authoritative u.s. federal government documents , dhs s&t developed the newly released cyber risk economics capability gaps research strategy which aims to consider business , legal , technical and behavior factors impacting cyber risk .

william russell , ( 202 ) 512-8777 or russellw@gao.gov .

in addition to the contact named above , ben atwater ( assistant director ) , melissa hargy ( analyst - in - charge ) , nanette barton and gary m. malavenda made key contributions to this report .

in addition , key support was provided by chris p. currie , dominick dale , michele fejfar , richard hung , benjamin licht , john mingus , janet temko - blinder , and sarah veale .

