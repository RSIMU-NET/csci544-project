the corporation for national and community service ( cncs ) , as the nation's largest federal grant maker for service and volunteering , engages more than five million americans in national volunteer service initiatives to support the american culture of citizenship , service , and responsibility .

its mission is to improve lives , strengthen communities , and foster civic engagement through service and volunteering .

to do so , the agency awards grants and provides technical assistance to nonprofit volunteer programs like americorps and senior corps that , in turn , provide services to address a range of community challenges , such as tutoring children and mentoring individuals with special needs .

in fiscal year 2016 , cncs administered grants totaling about $784 million to support national service , and the agency reported that nearly 325,000 americans participated in its major programs .

however , the cncs office of inspector general ( oig ) reported in march 2014 that the agency was experiencing problems with its grant management processes , noting that the agency did not have a comprehensive risk management strategy .

the oig also reported that the agency's grant monitoring process and the legacy system used to support the process were outdated , inefficient , and ineffective .

in october 2014 , cncs established plans to modernize its information technology ( it ) computing environment that included projects to develop new systems to support its operations .

among other operations , the it modernization plan addressed the need for improved system support for the management of grants , including processes for monitoring the use of funds awarded by its grant programs .

to support the committee in its oversight of cncs's grant management activities , we evaluated the extent to which the agency's it modernization plans address improved technical support of grant monitoring processes .

our specific objectives were to determine ( 1 ) to what extent cncs's planned it modernization projects align with business and management needs for grant monitoring and ( 2 ) what progress cncs has made toward ensuring the successful and timely delivery of new systems to support its grant monitoring process .

to determine the extent to which cncs's modernization projects aligned with business and management needs for grant monitoring , we collected and reviewed documentation that described cncs's plans regarding its it modernization projects , including the it modernization program management plan and software development planning documents related to business needs for grant monitoring system support .

we compared the system functional requirements defined in the documentation to business and user needs described in the modernization plan and identified consistencies and any gaps between them .

we also compared the relevant contents of the modernization and software development plans to the agency's business planning documentation , such as the cncs strategic plan , to determine the extent to which the it plans reflected business and user needs for grant monitoring support .

to determine the progress cncs had made to ensure the successful and timely delivery of systems to support grant monitoring , we collected and assessed documentation that provided evidence of planned and ongoing system development and implementation activities , such as project schedules and test plans .

we compared reported actual dates and milestones for completing the activities to planned dates documented in it modernization project management artifacts , such as reports of project performance and testing results , to determine whether milestones had been met and the extent to which system functionality had been delivered to support grant monitoring .

further , we obtained and assessed documentation describing activities of the agency's system development contractor and agency officials' conduct of project requirements management , testing , scheduling , and oversight .

we compared the actions taken to software development practices defined by the software engineering institute ( sei ) .

the scope of our study did not include a full assessment of cncs's software development practices .

we supplemented the information we obtained from our assessment of cncs documentation with interviews of cncs officials who are knowledgeable of the overall it modernization program , including the practices used to determine requirements and to develop new grant monitoring system capabilities .

these officials included the agency's chief information officer ( cio ) , chief operating officer , and chief risk officer .

to determine the reliability of the data obtained from cncs's information systems used for managing requirements , conducting system testing , and tracking system defects found during testing , we reviewed relevant documentation , such as requirements definitions , test plans and reports of results , and reports from a project tracking tool .

we compared the data collected from the documentation to actual results of activities , reflected in project status reports and schedule updates , to determine the integrity and reliability of the data .

to further confirm data reliability , we interviewed agency officials knowledgeable of the system development projects and the agency's it management processes .

we determined that the data we used from these sources were sufficiently reliable for the purposes of our audit .

a full description of our objectives , scope , and methodology can be found in appendix i .

we conducted this performance audit from january 2016 through august 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

cncs was created in 1993 with the enactment of the national and community service trust act of 1993 .

the agency is led by a chief executive officer and board of directors who are appointed by the president , and with the advice and consent of the senate .

the chief executive officer oversees the agency , which includes about 600 employees operating throughout the united states and its territories .

the agency provides grants to volunteer organizations throughout the united states to strengthen communities and foster civic engagement .

for example , the national and community service trust act of 1993 established the cncs and authorized it to make grants such as through the americorps state and national grant programs .

the act also made the agency responsible for administering volunteers in service to america ( vista ) and national senior volunteer corps .

the serve america act was also enacted in 2009 , which gave cncs responsibility for administering several newly established programs , such as the social innovation funds , which provide community - level grants .

cncs grants are typically awarded to fund programs for a 3-year period , with funds distributed annually .

in fiscal year 2016 , cncs received appropriations totaling more than $787.9 million and used $783.9 million to fund approximately 2,300 grants .

table 1 shows the amounts and number of grants disbursed by each of the programs in fiscal year 2016 .

within cncs , the chief of program operations , chief risk officer , and chief financial officer share responsibility for managing the grants .

program officers under the chief of program operations and grant officers under the chief financial officer manage the administration of the grants , including monitoring the use of grant funds by grantees .

the program officers focus on issues related to grantee performance and compliance with program objectives , while the grant officers focus on grantees' financial issues and performance .

the program and grant officers use it systems to support monitoring and related activities .

these systems are developed and maintained by the office of information technology ( oit ) .

this office is led by the agency's cio , who reports to the chief operating officer .

figure 1 illustrates the position of the grant management entities within the agency as of april 2017 .

to manage its grant program , cncs conducts a four - phase process that covers pre - award grant reviews through actions taken to close out the grants when the period of related projects expires .

according to cncs policy , during the pre - award phase ( before cncs makes a grant award ) , grant officers evaluate the potential grantee's financial management capabilities and other aspects , such as whether the grantee has any open audit findings on any current or prior grants , to determine if the grant should be awarded .

once grants are awarded for the upcoming fiscal year , cncs program and grant officers take steps to assess the grants and plan for monitoring the use of funds provided to the grantees .

during the agency's annual assessment phase , which is conducted between august and october of each year , the officers establish the upcoming year's monitoring plan .

during the monitoring phase , program and grant officers carry out the plans made during the assessment phase .

lastly , when the period of the project supported by a grant expires , the grant is closed .

during closeout and no later than 90 days after the expiration date of the grant , grantees submit required documentation to their grant officer and pay any outstanding obligations .

cncs's program and grant officers verify completion of these actions and reconcile funds , then notify grantees when they have met all programmatic and fiscal requirements of the award .

at that time , the grant is officially closed .

an overview of the four phases of the monitoring process is depicted in figure 2 .

grant monitoring activities are initiated by program and grant officers during the assessment phase , when awarded grants are assessed , rated , and prioritized , and monitoring plans are made .

the assessment phase is made up of four steps .

in the first step of the assessment phase , officers determine which grants are to be monitored in the upcoming year .

the universe of grants being assessed typically includes all grants that are active at the time cncs is ready to begin the assessment phase , usually in mid - august of each year , and that are expected to be active during the fiscal year beginning in october .

at the second step of the process , the officers further assess each of the grants to be monitored to identify potential vulnerabilities based on a set of criteria related to program compliance , financial weakness , or other issues defined by the program and grant officers .

cncs defined 19 criteria that indicate a grant's potential vulnerabilities to be examined during an assessment .

the officers may consider other key concerns or challenges in their assessment on a case - by - case basis .

based on the outcomes of the second step , a third step is taken to determine the priority of each grant for monitoring purposes .

each grant is rated as high , medium , or low priority to determine the types of monitoring activities to be conducted during the year .

the three priority categories are determined based on the presence of any of the pre - determined 19 criteria and an automated scoring process performed by the it system that is used to support the agency's grant monitoring process .

the plan typically is to be prepared by the end of october .

finally , during the fourth step of the annual assessment , program and grant officers plan the monitoring activities for each grant that are to be conducted during the year , based on the priority ratings determined during the third step .

for example , grant monitoring plans may include on - site compliance visits to the grantees' facilities , desk reviews of documentation submitted by the grantees , reviews of grantees' financial activities , and follow - up visits based on the outcomes of compliance visits and other reviews .

the monitoring phase is conducted each year between october and august , when program and grant officers are to complete the activities described in their plans .

during that time , they may add or omit activities , with supervisory approval , for a number of reasons .

for example , program and grant officers may consider adding an activity for a grantee based on newly identified issues , such as findings of the oig that suggest the grantee may have demonstrated poor financial management capabilities in the past .

in such cases , the officers may add additional on - site or follow - up visits to their plans .

the officers produce reports on the progress made by grantees to accomplish the objectives and meet performance measures associated with a particular grant .

for example , the reports could include data that reflect the number of individuals who received assistance in disaster preparedness , mitigation , response , and recovery efforts ; the percentage of economically disadvantaged people who received housing - related support ; or the percentage of students served by a grant program who showed improvements in academic performance .

in addition , the officers review grantees' financial status reports that identify funds expended compared to funds allocated for the grantees' awards through the cncs budget .

the information reported is used by the program and grant officers to help them identify areas that may need more focused attention or targeted monitoring .

in our march 2017 report on cncs's efforts to improve grant monitoring , we noted that the agency's annual assessment process may not result in the riskiest grants receiving a high priority for monitoring because of limitations in its scoring model .

we also noted that cncs has not evaluated its monitoring efforts to identify opportunities to improve its assessment of , and response to , risks related to grant management .

we recommended that cncs , as part of its efforts to establish enterprise - wide risk - based management , develop a risk - based approach to grant monitoring and establish a policy to ensure that all grants expected to be active in a fiscal year are assessed for potential risk .

such an approach would incorporate key practices , such as identifying risks relevant to the use of funds awarded by the grant program , analyzing and responding to the risks , and addressing risks as part of the grant monitoring process .

the agency did not comment on this recommendation and has not yet addressed it .

cncs's legacy it system , egrants , has been used since 1998 to provide functionality needed to support the agency's grant management process .

grant management includes annual assessment and monitoring activities such as planning , documenting related activities , generating correspondence , and reporting financial status and progress of grantees' actions toward meeting performance goals .

cncs officials reported that , in fiscal year 2016 , they spent about $11 million maintaining their legacy it environment , which includes egrants and other systems used to manage functions such as payroll and benefits .

to support the annual assessment process , program and grant officers record in egrants the results of their evaluations of each grantee .

such evaluations are based on the 19 criteria that were defined to determine the priority of the grants to be monitored and the monitoring activities to be conducted .

the officers indicate which of the criteria are present by choosing “yes” or “no” from a drop - down list .

then , based on the criteria , the system sorts and rates the priority of each grant as high , medium , or low .

figure 3 depicts the input screen of the egrants monitoring and oversight assessment module , which is used by the officers to select criteria used to indicate the priority level of grants .

once the assessment has been completed , the program and grant officers record activities that they plan to take during the year , such as conducting a follow - up visit with the grantee based on any audit findings in egrants , along with the proposed time frames for conducting the activities .

the program and grant officers also use egrants to generate notification letters that are sent to grantees to schedule a site visit .

after the visit has been conducted , the grant or program officers enter information regarding the results of the visit into the system , along with the grantee's responses .

after a site visit , the officers may also identify follow - up actions to be taken and use egrants to record those actions .

the program and grant officers also use the system to generate reports on the progress of the grantees toward addressing any deficiencies identified as a result of monitoring activities they conducted .

grant officers also enter information about the results of financial reviews into the system .

however , cncs has encountered challenges in using egrants .

for example , according to cncs's february 2013 it modernization plan , data and information are not standardized and are entered into the grant management and monitoring systems with limited checks and validation , which results in data quality issues .

in addition , according to the plan , technical limitations of egrants make it difficult and time - consuming to integrate data from multiple sources and filter out inaccuracies .

for example , agency officials stated that initiatives such as reporting on state - level grants require significant intervention by technical staff to obtain , integrate , and analyze data due to the disparate nature of the way the data are stored .

in october 2013 , the cncs oig also reported problems with the agency's legacy it system used to support monitoring activities .

the oig reported that egrants was inefficient and ineffective at supporting monitoring officers' efforts to predict and detect improper use of funds awarded by cncs grants .

the oig noted that , although the agency had collected data from its grantees to monitor their use of funds , its outdated systems did not provide the kind of data analytics capabilities needed to monitor early detection of fraud and mismanagement of grant funds .

for example , the oig reported that cncs could not readily compare information across grants awarded or among the grantee population to identify anomalies and outliers that indicate potentially improper use of funds .

the oig further reported that the agency was falling behind in its efforts to increase the use of technology to support improved risk management practices , relying instead on inefficient processes for conducting oversight of the use of grant funds .

recognizing the growing gap between its business needs and its it infrastructure , cncs engaged a contractor to provide guidance on modernizing its infrastructure .

in may 2014 , the contractor reported the results of its independent evaluation of the agency's it strategy , modernization plan , technology adoption , and costs for supporting cncs's strategic goals .

the evaluation highlighted the limited system collaboration and communication capabilities among cncs end users , data inconsistency , system availability issues , and data transparency and reporting issues as areas needing improvement .

in its report , the contractor noted that cncs had been slowly migrating its legacy grant management system to a new , more current technology , but that its efforts had not kept pace with mission - related programmatic demands .

consequently , program staff had developed workaround solutions to manage critical information accessed from multiple disparate sources , such as spreadsheets , e - mail , local and shared files , and local databases .

our march 2017 report on cncs's grant monitoring process identified similar problems associated with egrants .

we reported that , according to cncs officials , egrants does not automatically produce standard historical reports , and , in order to produce a report from the system , significant manual manipulation of the data is required .

we also discussed system users' concerns regarding the usability of egrants and its lack of integration with other tools used to collect monitoring data .

for example , although each program officer has an electronic monitoring tool to use when conducting on - site monitoring , the data collected using these tools are not automatically integrated into and analyzed by egrants .

we further noted cncs officials' concerns that the agency's existing it environment did not provide automated mechanisms , such as trend analyses , that could help them identify patterns of potentially improper use of funds and risk factors to be considered when monitoring grants within a risk - based management approach .

in february 2013 , cncs' cio released its it modernization plan that describes a program intended to result in the development of systems to improve support of the agency's grant management activities .

program documentation describes the implementation of systems that , when executed collectively , are to provide grantees and agency staff using the systems with new tools and capabilities to increase data quality and transparency , staff productivity , and program effectiveness .

the it modernization program has two overall goals .

modernize grant management systems — re - architect systems and standardize databases for greater agility ; improve data quality and provide a better user experience through new data edits and validations , pre - populated forms , optimized navigation , and context - driven screens ; maximize staff productivity by consolidating core staff functions currently in multiple systems into a common system .

enhance mobile web and information sharing — optimize key cncs information for mobile web viewing and develop capabilities to accept grantee system information and share cncs data with the public .

cncs's it modernization program consists of three phases with projects in each phase that are intended to result in improvements to the overall it computing platform , retirement of outdated legacy systems , and replacement of the retired systems .

specific projects are to be conducted as part of an overall initiative intended to result in the retirement of outdated legacy systems and the implementation of a modernized computing environment , referred to as the grants and member management ( gmm ) platform .

phase 1 of the program includes projects to result in the development and delivery of systems to support existing grant management processes , such as planning and applying for grants , reviewing applications , awarding funds , reporting on grantee and project status , monitoring the use of grant funds and grantee activity , and closing out grants and projects .

phase 2 includes projects to develop systems to support services such as member recruitment , training , travel , awards , and enterprise risk management , including grant monitoring and oversight .

this phase includes a project to deliver system capabilities that support the agency's grant monitoring process as part of a future enterprise - wide risk management approach .

the delivery of the systems to be developed during the first two phases is intended to allow the agency to retire outdated legacy systems .

phase 3 , the final phase , is to retire any remaining legacy systems to complete the transition to the new gmm platform .

cncs defined it modernization projects to be completed throughout the three phases of the initiative , such as the development of modernized systems to be used by the agency's staff to manage grants , and the transition of all system functionality from the legacy environment to the platform .

according to the modernization plan , the new systems are to be deployed via a technology platform that allows users to integrate data from external data sources in real time .

specifically , the platform is to be based on cloud computing that , according to cncs's it strategic plan , is expected to lower it costs , improve system access and stability , and enable it staff to focus on supporting the needs of agency stakeholders who are to use the systems .

to implement the gmm cloud - based platform and develop the new systems , cncs acquired the services of a development contractor through a task order that specifies software and services on a time and materials basis .

the task order for the implementation of gmm was issued in september 2014 , and the contractor began work on phase 1 , including the first modernized grant management system development project , in october 2014 .

in january 2017 , agency officials estimated the cost to complete all of the activities associated with the projects during the three phases of the it modernization program to be $43.6 million — $39.3 million for labor and $4.3 million for software and services .

to define system requirements that meet users' business needs , key practices identified by sei call for , among other things , ensuring that the business needs are understood and that supporting system requirements are defined and agreed upon by system stakeholders , including system developers and users .

consistent with these practices , cncs's software management processes identify steps for defining system functional and technical requirements , including the analysis of users' needs , reviews to obtain stakeholders' and management's approval of requirements , and the development and maintenance of documentation that describes the requirements and any changes made throughout the development of the system .

as currently planned , cncs's projects to develop and deliver the modernized grant monitoring system align with the agency's business and management needs for its existing process , but are not yet defined for a future risk - based process .

when originally planning for the it modernization phase 1 projects , cncs included the development of an initial version of the system to be used by program and grant officers to support activities they conduct in accordance with the existing grant monitoring process .

toward this end , initial requirements for the first version of the grant monitoring system were defined to replicate functionality provided by the legacy egrants monitoring system and to provide enhancements needed to help program and grant officers more effectively conduct monitoring activities .

cncs took steps to define requirements for the first version of the system in accordance with its established processes .

specifically , oit officials , the development contractor , and system users held requirements gathering sessions to determine users' needs beginning in july 2015 , as planned .

as a result of the sessions , program and grant officers who were to use the system defined and documented 26 business requirements to be addressed by functionality implemented in the first version .

of these 26 requirements , 6 were defined to replicate the functionality provided by the legacy egrants system .

for example , the new system was to provide an input screen for users to document assessments of grant awards , and another screen for users to enter data for planning monitoring activities — functionality provided by the egrants monitoring system .

the system was also to replicate other functionality of the egrants system , such as allowing users to record completed monitoring activities and to add flags to organizations' records that indicate potential needs for additional monitoring .

the other 20 requirements that the system users defined were enhancements to help improve the outcomes of monitoring activities in support of cncs's goal to modernize grant management processes .

for example , the system was to , among other things , enable the officers to create monitoring plans for awards and associate monitoring activities with plans — functionality that was not provided by egrants .

according to project planning documentation , the system users reached agreement with oit officials and the contractor to deliver system functionality to meet all 26 requirements .

however , as the contractor proceeded with developing the first version of the system , cncs changed its plans for addressing the 26 requirements .

specifically , in a project review held in october 2015 , oit officials , the development contractor , and system users agreed to defer the 20 requirements for improving the outcomes of monitoring activities and to include them in the requirements definitions for the second version of the monitoring system .

consequently , the requirements that were defined to replicate the capabilities of the legacy egrants system were addressed by functionality planned for the first version .

oit officials stated that the additional 20 requirements were deferred because the agency had not defined business needs for a grant monitoring system beyond those relevant to cncs's existing process .

specifically , agency officials responsible for assuring that major it investments achieve business needs decided to minimize the investments to only support existing business needs and operations until a new risk management program is established and ongoing business process reengineering efforts are completed .

thus , the plans for delivering the first version of the system were modified to align with business needs of cncs's existing grant monitoring process .

project plans for the second version of the system call for enhancements to the it capabilities delivered by the first version .

these planning documents also indicate that , in addition to the requirements deferred from the first version , the second version of the system is to provide any additional functionality needed to align with business needs for monitoring grants within a risk - based approach to enterprise - wide management .

however , in march 2017 , we reported that cncs had not evaluated its monitoring efforts to identify opportunities to improve its assessment of , and response to , risks related to grant management .

we recommended that cncs , as part of its efforts to establish enterprise - wide risk - based management , develop a risk - based approach to grant monitoring and establish a policy to ensure that all grants expected to be active in a fiscal year are assessed for potential risk .

in addition , according to cncs's chief risk officer and chief information officer , as of april 2017 , the agency had not defined a risk - based management approach and , therefore , had not defined business needs for monitoring grants based on risks .

because business needs for a risk - based monitoring process have not been determined , oit officials and system stakeholders cannot begin to define requirements for the second version of the system to align with business and management needs for a future process , as intended by cncs's it modernization plans .

although the agency and its development contractor took steps to align the first version of the system with changing business needs , cncs has made limited progress toward developing and delivering the modernized system capabilities to support grant monitoring .

cncs began the development effort for the first version of the system in july 2015 and initially planned for the system to be delivered in april 2016 .

after subsequent delays , officials and the contractor then planned to deliver the system in september 2016 .

however , as of july 2017 , the system still had not been delivered to support the agency's existing monitoring process .

in cncs's and the contractor's efforts to develop the system , incomplete project schedules and testing practices introduced risks to the agency's ability to deliver the system .

in addition , information documented by agency officials in weekly and monthly reports on the status of the project indicate that performance deficiencies on the contractor's part contributed to delays in the completion of testing , development , and system delivery .

oit officials' and the development contractor's initial project schedules reflected plans to begin defining requirements for the first version of the system in may 2015 and to finalize requirements in november 2015 .

the development contractor was to begin testing to identify and correct any problems with the system in february 2016 .

the system users were also to begin participating in initial testing in february 2016 and complete their final testing in march 2016 , at which time any problems detected during the earlier test phases were to be corrected and the system changes re - tested and approved .

the system was to be in use by the end of april 2016 .

as previously mentioned , oit officials , the contractor , and system users began defining requirements for the system in may 2015 , and finalized initial requirements in november 2015 , as planned .

the contractor also developed a test version of the system and , along with system users , completed the initial phases of testing in march 2016 according to plans .

however , technical and functional problems encountered during subsequent phases of system testing caused delays in the completion of later testing phases , in which users were to participate .

specifically , test completion was delayed from april 2016 until october 2016 — 6 months later than initially planned , and 1 month after the revised date ( of september 2016 ) that cncs had said it intended to deliver the system .

according to cncs's cio and project planning documentation , the contractor's testing of the first version of the grant monitoring system is now expected to be completed and available for final users' testing in september 2017 , and the system is expected to be delivered for operations in october 2017 .

oit officials reported that , as of january 2017 , the agency had spent $12.7 million on conducting the phase 1 gmm platform modernization and related system development projects — $11.2 million on labor and $1.5 million on software and services .

further , as part of its modernization program , cncs initially planned to deliver the second version of the system in october 2017 .

however , because of delays in the delivery of the first version and the agency's lack of progress in determining business needs for monitoring grants in a risk - based management environment , oit officials , system users , and the development contractor are not able to define system requirements or to complete plans for developing and delivering the final system to support a future monitoring process .

thus , a new date for delivering the second version of the system has not been determined .

figure 4 provides a timeline of planned and delayed delivery dates for the first and second versions of the grant monitoring system .

in the development of the first version of the system , cncs and the development contractor did not follow all established software development practices .

specifically , oit officials and the contractor did not develop project schedules that could be used to effectively track and monitor the progress of the system development effort , and they did not conduct complete testing of the grant monitoring system .

according to practices defined in gao's schedule assessment guide , an integrated master schedule should be the focal point of program management .

such a schedule constitutes a program - level schedule that includes the effort necessary from all agency and contractor stakeholders to ensure successful execution from start to finish .

according to gao's guide , managers are to identify a baseline , or target , schedule that is to be maintained and updated with actual dates when activities are started and finished .

the baseline is used to measure and monitor the performance of projects and to determine when actual dates differ from baseline dates and may affect future work .

further , it is useful in determining when strategies are needed to allocate resources more efficiently to meet time constraints .

an agency's program management office is ultimately responsible for the development and management of the schedule .

however , cncs and its contractor did not develop schedules for the phase 1 projects of the gmm modernization plan that would have been useful for managing and tracking the progress of development and testing activities to ensure the first version of the grant monitoring system was delivered in a timely manner .

cncs's contractor developed , and oit officials approved , a schedule which they called an integrated master schedule .

however , this schedule was not constructed as an integrated master schedule should be and , thus , did not provide a useful management tool .

specifically , the schedule that cncs approved established baseline start and finish dates for activities , but did not reflect actual dates for managing the gmm phase 1 system development projects , including the first version of the grant monitoring system .

for example , one version of the schedule identified a testing activity for the grant monitoring system to take place from april 2016 through june 2016 , but the schedule did not include dates for when the activity was actually started and completed .

another later version of the schedule included a planned delivery date of october 2017 for the system , but did not include the originally planned date of april 2016 .

thus , the schedule could not be used to track the status of project activities or to monitor and measure the performance of the grant monitoring system development project to help ensure its successful completion .

in discussing this matter , oit officials said they did not develop and maintain a baseline schedule that identified planned and actual start and completion dates because they believed that they would be able to effectively track the status of project - level activities using other tools and techniques inherent in their approach to developing the system .

for example , the officials stated that they used a field included in the schedules for entering notes to identify actions that needed to be taken to complete activities and to track the status of each of the actions .

however , in many cases , oit officials included certain program - level actions and completion dates in the notes , but they did not record the status of the actions .

for example , they did not indicate whether or not development and testing activities took place as planned .

the officials also noted that their current approach requires users interested in referencing baseline changes to consult historic copies of the schedule or go through the tedious process of comparing the notes field with project files .

as such , this approach could not be used as an effective tracking tool to determine the status of the activities or the project as a whole .

regardless of oit officials' approach to tracking the status of project activities , until they construct a complete integrated master schedule that includes both baseline and actual dates for developing the systems , the agency will lack an effective management tool that could be used to help avoid additional delays in delivering the first version of the modernized grant monitoring system to support its existing process and retiring the legacy egrants system .

likewise , unless oit officials and the development contractor develop a schedule that can be used to monitor and measure progress of the development and delivery of the second version of the system against baseline and actual dates , the agency will remain at risk that it will not be able to successfully execute all activities needed to deliver system capabilities that could support a future risk - based monitoring process .

according to sei , testing the functionality of a new it system is essential to validate that the system will satisfy users' requirements .

effective testing facilitates early detection and correction of software and system anomalies , provides an early assessment of software and system performance , and provides information to key stakeholders for determining the business risk of releasing the product in a current state .

sei guidance advises that a test plan be used to ensure that testing is carried out in a systematic manner .

it describes the technical and management approach to be followed for testing a system or a component of a system , such as the projects within the cncs it modernization program .

consistent with sei guidance , cncs and the development contractor made plans to test the first version of the system early on and throughout the development phase .

however , the program experienced halts and re - starts of testing activities , along with delays in system implementation , in part because the agency and its contractor did not conduct all stages of testing for the system .

oit officials describe in the plans for testing all the gmm phase 1 systems , including the grant monitoring system , a sequence of testing events .

for example , during the systems development process , the developer was to conduct initial testing activities to determine whether each of the systems was functioning independently as expected , addressed users' requirements , and met usability and security requirements — referred to as unit testing .

the contractor's testing team also was to conduct another stage of testing to ensure that all aspects of the system affected by any changes made during initial unit testing functioned as they did prior to the modifications and adjustments that were made .

this stage is referred to as regression testing .

according to the plans , once the development contractor had completed unit and regression testing activities , the systems were to go through three more stages of testing in a system integration test environment — the last two involving system stakeholders and users .

these test stages included: alpha testing — testing conducted by the system developer which was to result in a working prototype that users and stakeholders could evaluate to determine whether to keep developing the product as built or to make modifications before completing additional development .

according to test plans , the version of the system delivered after alpha testing was to include 50 percent of the desired functionality .

beta testing — testing conducted by the agency and stakeholders to validate a fully working prototype that the stakeholders could test more thoroughly prior to delivery .

cncs oit and stakeholders were to conduct beta testing for about 8 weeks to validate that the functionality needed to address business needs was implemented .

the beta testing phase was also intended to provide the cncs user community an opportunity to provide feedback on the user interface before the system would be ready for the next phase of testing — user acceptance testing .

the system resulting from the beta testing phase was to include more than 80 percent of the desired functionality required for the system .

user acceptance testing — testing conducted by users to finally accept the system , confirming that all functionality has been built and requirements met .

user acceptance testing was to be conducted for 3 weeks to validate that the system would provide full functionality , as defined by system requirements , when deployed into a live , working environment .

cncs and its contractor completed and approved the results of the unit and regression test stages for the phase 1 gmm systems in september 2015 , as planned .

however , although the agency conducted alpha testing according to plans , it did not include the grant monitoring system in that phase of testing .

for example , according to oit officials , the development contractor and stakeholders tested 50 percent of the functionality of the gmm phase i systems , as planned ; however , this approach did not guarantee that all systems would be tested , and the grant monitoring system was not included in the alpha testing activities .

subsequently , oit officials , the development contractor , and stakeholders began a first round of beta testing of the system on april 18 , 2016 , and tested through april 22 , 2016 .

throughout the beta test period , testers noticed significant problems related to usability and technical deficiencies , such as awkward screen layouts and a lack of data that were to be migrated from the legacy egrants system — problems that should have been detected and corrected during alpha testing .

based on the extent of these problems , oit officials determined that it was not appropriate to proceed with the testing and , on may 9 , 2016 , called off beta testing so that the development contractor could make the system changes needed to correct the problems .

oit officials resumed and completed the first round of beta testing ( which had begun in april 2016 ) in october 2016 .

they subsequently began and completed a second round of testing in december 2016 .

results of these testing activities were approved by oit management and system users , who then planned to begin a final round of testing in april 2017 .

they also planned to conduct user acceptance testing from july through september 2017 .

oit officials stated that the grant monitoring system was not included in the alpha testing because system test plans required that 50 percent of the overall gmm phase 1 system functionality be tested during that phase — but not 50 percent of the functionality to be provided by each project .

the officials stated that , in managing the development of the overall gmm program , they tested more than 50 percent of other phase i systems' functionality and , therefore , did not need to include the grant monitoring system to meet the requirement .

in addition , the officials stated that , when alpha testing began for the other gmm phase 1 systems in march 2016 , they and system stakeholders still had not agreed on final requirements and , therefore , were not ready to test the system .

however , because they did not complete all phases of testing needed to ensure early detection and correction of system problems throughout the development of the first version of the grant monitoring system , the agency was not prepared to conduct the beta and user acceptance phases of testing .

had they started beta testing with a version of the system that had passed alpha testing , cncs could likely have detected and corrected system errors earlier in the testing process and , thus , avoided the problems experienced when conducting beta testing of the grant monitoring system .

further , unless oit officials and the development contractor conduct alpha testing of grant monitoring functionality when managing the development of the second version of the system , they will likely experience similar challenges and risks to plans for delivering a system to support future risk - based monitoring processes .

according to established practices defined by sei , successful completion of it development projects calls for the delivery of quality products by any contracting entities involved in the project and effective oversight on the part of the contracting agency .

as such , cncs's agreement with the it modernization development contractor specified that the contractor was to provide system development , modernization , and enhancement support including , but not limited to , program management and planning .

the contractor was required to support all phases of the agency's system development life cycle process , including requirements analysis , development , testing , documentation , deployment , and post - deployment support ( eg , training ) .

in addition , according to sei , effective project oversight calls for close monitoring of contractor performance , including regular status reporting and progress reviews to management , and reviewing contractor deliverables that document the level of progress toward meeting milestones .

sei emphasizes the importance of project oversight to ensure progress is being made according to plans for system development projects , and calls for appropriate corrective actions to be taken when project performance deviates significantly from plans .

effective project oversight also includes notifying management as soon as the project performance deviates from plans .

cncs and the development contractor finalized initial requirements for the monitoring system in november 2015 , as planned .

however , even with agency officials' initial efforts to oversee the contractor's progress toward delivering the system , the project experienced repeated delays during the development and testing phases .

for example , soon after development of the system began , oit officials required the contractor to develop plans and schedules for resolving multiple technical and software quality issues .

nevertheless , minutes from project management meetings indicated that many of the issues remained unresolved , which called for repeated corrective action plans .

specifically , from november 2015 through july 2016 , oit officials required the contractor to develop and deliver seven corrective action plans to address deficiencies and defects related to the development of the system .

as the agency took steps to monitor the status of the contractor's actions to address system deficiencies , the oit staff responsible for overseeing the contractor's performance and other management officials held weekly and monthly reviews of the contractor's actions .

in the reviews , the officials assessed any progress made toward completing the actions and planned contingencies for mitigating risks associated with any lack of progress noted .

for example , minutes from a december 2015 it management review meeting documented the acceptance of the contractor's first corrective action plan .

the minutes also described plans to hold weekly status meetings to monitor progress and define actions that would be taken if the contractor did not meet milestones for correcting system development deficiencies .

later , following an april 2016 it management meeting , oit officials again noted that the contractor was behind schedule in developing data migration and training materials required by the fourth corrective action plan .

as another example , in may 2016 , when the contractor was addressing the fifth corrective action plan , oit and other agency management officials documented their intention to make a decision on whether to issue a cure notice .

consequently , when the contractor had not resolved all the problems identified in the first five corrective action plans , cncs issued a cure notice in june 2016 , and required the contractor to deliver two additional corrective action plans in july 2016 and december 2016 .

the first of the two additional corrective action plans — the sixth corrective action plan — was to result in the delivery of the first version of the system in october 2016 .

in a management review meeting held in august 2016 , agency officials noted that the development contractor was on track to meet the requirements of the plan .

regardless , oit officials reported that they made a decision to delay delivery of the system because they did not believe that there was enough time for users to adequately test and receive training on the new system .

the officials then required the contractor to develop a seventh corrective action plan for delivering , by december 2016 , a version of the system that had passed beta testing to allow the additional time needed for users to complete acceptance testing and for the agency to conduct training .

figure 6 depicts the timeline of cncs's corrective action plan requirements and the contractor's delivery of the plans .

according to cncs's cio and documented results of status reviews held with it management officials , since the last corrective action plan was delivered by the contractor in december 2016 , performance has improved and the project is on track to deliver the first version of the grant monitoring system in october 2017 .

for example , the contractor delivered a version of the system and beta testing began in december 2016 , along with plans to continue beta testing from april 2017 through september 2017 .

weekly reports to management on the status of the project indicated that , as of june 2017 , all requirements defined for the first version of the system had been implemented .

the reports also indicated that the development contractor was taking steps to prepare for the user acceptance test phase , which was to be conducted from july through september 2017 .

the reports note that the contractor was continuing to resolve migration and integration issues identified in the april 2017 beta test phase , prepare training materials for system users , and obtain stakeholder input on deployment plans .

in addition , oit officials noted in a june 2017 report to it management officials that there were no outstanding risks to the planned delivery of the system .

cncs's it modernization plans included projects that were to result in the delivery of system functionality to align with business and management needs of the agency's grant monitoring processes — its existing process and a future process to be conducted as part of an enterprise - wide risk - based management approach .

when developing the first version of the modernized grant monitoring system , cncs officials managed requirements to align with changing business needs of the agency .

however , agency officials do not have the information needed to define requirements and plan for the delivery of a second version of the system to align with grant monitoring processes within a future risk - based management approach .

specifically , as we reported in march 2017 , the agency has not defined risk factors to be considered when prioritizing grants and grantees for monitoring activities .

cncs initiated the first project and planned to develop and deliver the first version of the system to support its existing grant monitoring process .

this version of the system was to be delivered in april 2016 , but weaknesses in schedule and testing management practices have introduced risks to the successful delivery of a modernized system .

unless cncs officials make needed improvements in system development practices , successful delivery of system functionality necessary to support grant monitoring will remain at risk .

meanwhile , cncs's grant monitoring officers continue to rely on the agency's outdated legacy system to support an inefficient and ineffective process for monitoring the use of hundreds of millions of dollars in grants awarded each year .

we are making the following three recommendations to cncs: the chief executive officer should direct the chief information officer to take steps needed to ensure that system requirements are defined to align with the business needs of cncs's future risk - based grants monitoring process ( recommendation 1 ) .

the chief executive officer should direct the chief information officer to ensure that the system development project schedule identifies in the baseline both planned and actual dates for completing all project - level activities , and can be used to monitor and measure progress of the grant monitoring system project ( recommendation 2 ) .

the chief executive officer should direct the chief information officer to ensure that test plans are defined and implemented to include the second version of the grant monitoring system in all stages of testing during development , and results of initial stages are approved before conducting subsequent test stages ( recommendation 3 ) .

we received oral comments on a draft of this report during a discussion with cncs's chief information officer ( cio ) , deputy cio , and other agency officials .

in their comments , the officials partially agreed with three of the five recommendations included in the draft report and disagreed with two of the recommendations .

the officials also shared additional information regarding the agency's actions to develop and test the modernized grant monitoring system and subsequently provided documentation to support their views .

after reviewing the documentation , we revised relevant sections of the report and modified the conclusions and recommendations as appropriate .

further , as a result of incorporating the additional information provided by the officials , our final report reflects three , rather than the original five , recommendations .

specifically , the officials partially agreed with our first recommendation that cncs ensure that system requirements are aligned with the business needs of cncs's current and future risk - based grants monitoring processes .

the officials agreed that they needed to take steps to ensure that requirements for the second version of the grant monitoring system will align with business needs of a risk - based monitoring approach and stated that they intend to continue to work with stakeholders to define such requirements .

however , the officials disagreed with our initial conclusion that the first version of the system did not meet business needs of the current grant monitoring process and , consequently , disagreed with the part of the recommendation that they ensure the system's requirements aligned with business need of the current process .

we requested , and the officials provided in june 2017 , additional documentation reflecting alignment of the first version of the system with current grant monitoring business needs .

as a result of our assessment of the supporting documentation , we revised the report to incorporate the additional information and modified the initial conclusion and the related recommendation .

the officials also partially agreed with the second recommendation in the draft report regarding the need to develop a complete integrated master schedule for managing the grant monitoring system development project .

specifically , we recommended that the schedule include actual start and finish dates and detailed system - level schedules that identify specific activities , resource requirements , and interdependencies between activities .

the officials agreed with that part of the recommendation stating a need for baseline schedules that document both planned and actual start and finish dates for project activities .

the officials told us that they intend to include the dates in future planning efforts to allow for easier tracking of progress and more effective project management .

however , the officials disagreed with the part of the recommendation that stressed a need to develop schedules for the development and testing phases of the individual phase 1 systems , rather than the overall gmm phase 1 modernization program .

contrary to statements made by oit officials throughout our review , the officials stated that the agency had , in fact , developed such schedules .

subsequently , in june 2017 , the agency provided us an integrated master schedule for the earlier phases of the project through the requirements definition phase , and that incorporated specific activities , interdependencies , and resources required for the individual system - level projects , as we initially recommended .

the officials added that they used other software development management tools and metrics to track the status of activities conducted during the system development and testing phases , and they provided documented evidence of those activities .

the officials noted that their software development methodology and agreement with the contractor allowed for resource requirements to be identified in other project management artifacts and the contractor's planning documents .

after assessing the additional documentation , we revised the report to incorporate this information and modified the conclusion and recommendation regarding project schedule management practices .

the agency officials also partially agreed with our third recommendation .

this recommendation called for the agency to use an integrated master schedule for managing the system development project that included all the elements identified in the second recommendation .

specifically , the officials agreed with the part of the recommendation addressing the need for cncs to track the progress of the projects by comparing actual start and finish dates to target dates .

however , as noted for the second recommendation , the officials disagreed with the need to use individual schedules to monitor the status of each system .

after considering the additional evidence provided in the agency's response to the second recommendation , we modified the report accordingly .

we also combined the second and third recommendations contained in the draft report into one recommendation , as reflected in this final report .

further , cncs's cio and deputy cio disagreed with a fourth recommendation in the draft report which called for the agency to follow plans for testing the grant monitoring system .

the officials asserted that the agency had followed plans when testing the first version of the system , and provided additional information regarding system testing requirements and processes .

based on our review of this additional information , we acknowledged in the report that the development contractor and system users had followed plans .

nevertheless , we continue to emphasize the need for cncs to , in future project management activities , develop and implement test plans that ensure each system included in the gmm project is adequately tested throughout the early and all subsequent phases of testing .

we modified our recommendation to reflect our position on this matter .

finally , the cio and deputy cio disagreed with the fifth recommendation in the draft report , which pertained to deficient contractor oversight practices conducted by the agency .

the officials stated that the actions taken by the agency to enhance oversight , as described in the draft report , had led to improvements in contractor performance and in the agency's overall ability to get the project on schedule for an october 2017 delivery .

to substantiate their position , in june 2017 the officials provided additional project management artifacts , such as weekly and monthly management reports , that documented the recent status of project activities .

specifically , the reports documented the contractor's actions to correct system defects , plan for system deployment , and develop training materials .

based on our assessment of this documentation , we modified the relevant discussion in the report to incorporate the newly obtained information regarding the outcomes of cncs's actions .

we also removed the recommendation .

beyond the aforementioned oral comments , cncs's chief operating officer also provided technical comments via email , which we incorporated as appropriate .

we are sending copies of this report to the cncs chief executive officer , the director of the office of management and budget , and other interested parties .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

should you or your staff have questions on matters discussed in this report , please contact me at ( 202 ) 512-9286 .

i can also be reached by e - mail at pownerd@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix ii .

the objectives of this study were to determine ( 1 ) to what extent the corporation for national and community service's ( cncs ) planned information technology ( it ) modernization projects align with business and management needs for grant monitoring and ( 2 ) what progress cncs has made toward ensuring the successful and timely delivery of a new system to support its grant monitoring process .

to address the first objective , we collected and reviewed documentation that describes the cncs it modernization projects , including the it modernization program management plan and related system development plans .

we assessed whether the agency's project plans aligned with needs of grant monitoring officials by comparing their contents against documentation that described the agency's grant monitoring process and requirements for providing it support of the current monitoring process .

we identified enhancements needed to assist program and grant officers , by examining planning documentation , such as cncs's strategic plan , system requirements definitions , and presentations and minutes from business stakeholder requirements gathering sessions .

we also reviewed documentation that noted changes to requirements and interviewed agency officials , such as the chief information officer , to determine the rationale for the changes .

we compared the final requirements definition to the needs initially defined by grant monitoring officials to determine the impact that changes had on the agency's plans to align its it modernization projects with business needs for grant monitoring .

to address the second objective , we first determined the progress cncs had made toward delivering a modernized system to support its existing grant monitoring process .

to do so , we collected and evaluated documentation that provided evidence of ongoing system development and implementation activities , including project schedules and status tracking reports .

we compared planned dates and milestones documented in the schedules to actual dates obtained from project artifacts , such as monthly program performance reports , to determine whether milestones had been met and , when they had not , identified the tasks that were not conducted or completed as planned and that caused gaps between intended outcomes and functionality to be provided by the system and delays in the system development and delivery schedule .

we also obtained and examined documentation describing the development contractor's activities , such as minutes and presentations from program reviews , and weekly and monthly reports on the status of system development efforts , to identify any deficiencies in system development practices that may have affected cncs's and the development contractor's ability to deliver the system .

to assess cncs's efforts to develop and manage project schedules , we compared schedules for developing , testing , and delivering the first version of the grant monitoring system , from october 2015 to december 2016 , to criteria defined in gao's schedule assessment guide and held discussions with gao's scheduling experts to determine appropriate criteria for assessing scheduling practices with an agile software development methodology .

we also examined data collected from project planning and management artifacts , such as reports that documented dates of regression and initial beta testing activities and status reports that provided evidence of ongoing and completed system development and implementation activities .

we then compared the planned dates and milestones contained in the schedules to actual dates obtained from project artifacts , to determine whether the project schedules reflected planned and actual dates for the completion of activities , delays in meeting project milestones , and interdependencies and conflicts between activities and resources .

to assess cncs's efforts to test the system , we compared documentation that described agency practices for conducting system testing , such as test plans and reports on testing outcomes , to testing management criteria defined by the software engineering institute ( sei ) and documented in its capability maturity model® integration ( cmmi® ) framework .

to determine whether cncs had taken steps to ensure , through its testing activities , the successful delivery of the grant monitoring system , we assessed documentation of activities that were to occur as part of the alpha , system integration , beta , and user acceptance testing phases .

specifically , we examined test plans and reports of testing outcomes and compared them to criteria for effective system testing identified in sei's framework to determine whether cncs conducted testing as planned and the impact of any deficiencies on the agency's ability to deliver the system as planned .

lastly , we determined the level of contractor oversight conducted by cncs officials by examining documentation such as program schedules , documented requirements and deadlines for the contractor to address system deficiencies identified by the office of information technology officials , corrective action plans delivered by the contractor , and correspondence between the agency and the contractor .

we compared the activities to practices for conducting effective project oversight established by sei .

we supplemented the information we obtained from our assessment of agency documentation by interviewing cncs officials , including the chief information officer , deputy chief information officer , and chief risk officer , who were knowledgeable of efforts to develop systems and oversee the work of contractors to support the grant monitoring process .

to determine the reliability of the data obtained from cncs's information systems used for managing requirements and conducting system testing , we compared information obtained from documentation of requirements definitions and test plans against requirements tracking documents and reports of test results .

we also discussed with knowledgeable agency officials within the office of information technology the status of system development processes , including actions taken to define and manage system requirements and to conduct the various phases of testing .

based on our efforts , we determined that the data we used from these sources were sufficiently reliable for the purposes of our audit .

we conducted this performance audit from january 2016 through august 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact named above , teresa f. tucker ( assistant director ) , freda e. paintsil ( analyst - in - charge ) , melina i. asencio , alexander h. bennett , christopher g. businsky , nancy e. glover , thomas e. murphy , and paige e. teigen made key contributions to this report .

