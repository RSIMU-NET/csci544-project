we are pleased to be here today to discuss the u.s. census bureau's ( bureau ) progress in preparing for the 2020 decennial census .

as you know , one of the most important functions of the bureau is conducting the decennial census of the u.s. population , which is mandated by the constitution and provides vital data for the nation .

the information that the census collects is used to apportion the seats of the house of representatives ; redraw congressional districts ; allocate billions of dollars each year in federal financial assistance ; and provide a social , demographic , and economic profile of the nation's people to guide policy decisions at each level of government .

further , businesses use census data to market new services and products and to tailor existing ones to demographic changes .

for 2020 , a complete count of the nation's population is an enormous undertaking as the bureau seeks to control the cost of the census while it implements several innovations and manages the processes of acquiring and developing new and modified information technology ( it ) systems .

in recent years , we have identified challenges that raise serious concerns about the bureau's ability to conduct a cost - effective count of the nation , including issues with the agency's research , testing , planning , scheduling , cost estimation , systems development , and it security practices .

over the past 4 years , we have made 33 recommendations specific to the 2020 census to help address these issues and others ; however , only 10 of them had been fully implemented as of october 2017 .

we also added the 2020 decennial census to the high - risk list in february 2017 .

the bureau's preparations for 2020 have been further complicated by late changes to the 2018 end - to - end test ( a “dress rehearsal” of the actual enumeration ) and by current vacancies in the positions of bureau director and deputy director .

these vacancies are due to the previous director's retirement on june 30 , 2017 , and the previous deputy director's appointment to be the chief statistician of the united states within the office of management and budget in january 2017 .

although interim leadership has since been named , in our prior work we have noted how turnover in the bureau's top position makes it difficult to ensure accountability and continuity , as well as to develop and sustain efforts that foster change , produce results , mitigate risks , and control costs over the long term .

with the operations for the end - to - end test beginning in august 2017 , and as preparations for 2020 ramp - up , addressing the risks jeopardizing the 2020 census by implementing our recommendations is more critical than ever .

our testimony today focuses on the bureau's progress in three areas: ( 1 ) implementing innovations aimed at controlling costs and enhancing accuracy , ( 2 ) implementing and securing critical it systems , and ( 3 ) ensuring the reliability of the bureau's cost estimate for the 2020 census .

the information in this statement is based primarily on prior work regarding the bureau's planning efforts for 2020 .

for that prior body of work , we reviewed , among other things , relevant bureau documentation , including the 2020 census operational plan , recent decisions on preparations for the 2020 census , and outcomes of key it milestone reviews .

we also interviewed bureau staff .

other details on the scope and methodology for our prior work are provided in each published report on which this testimony is based .

in addition , we included information in this statement from our ongoing work on the 2018 end - to - end test examining the address canvassing operation and the readiness of it systems .

for our ongoing work on the 2018 address canvassing operation , we reviewed plans for and execution of the address canvassing portion of the 2018 end - to - end test at each of the three test sites — in pierce county , washington ; providence county , rhode island ; and bluefield - beckley - oak hill , west virginia .

across the three test sites , we observed 18 census workers conduct address canvassing operations and interviewed local office staff at each location .

these observations are not generalizable .

for our ongoing work on the readiness of the bureau's it systems , we collected and reviewed documentation on the status and plans for system development , testing , and security assessments for the 2018 end - to - end test , including the bureau's integration and implementation plan , solution architecture , and memorandums documenting outcomes of security assessments .

we also interviewed agency officials .

we provided a copy of the new information we are reporting in this testimony to the bureau for comment on september 18 , 2017 .

the bureau provided technical comments , which we addressed as appropriate .

we conducted the work on which this statement is based in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the cost of the census has been escalating over the last several decennials .

the 2010 decennial was the costliest u.s. census in history at about $12.3 billion , and was about 31 percent more costly than the $9.4 billion 2000 census ( in 2020 dollars ) .

the average cost for counting a housing unit increased from about $16 in 1970 to around $92 in 2010 ( in 2020 dollars ) .

according to the bureau , the total cost of the 2020 census is estimated to be approximately $12.5 billion dollars ( in 2020 dollars ) .

as discussed later in this statement , however , the cost of the 2020 census will likely be higher than this current estimate .

meanwhile , the return of census questionnaires by mail ( the primary mode of data collection ) declined over this period from 78 percent in 1970 to 63 percent in 2010 ( see figure 1 ) .

declining mail response rates — a key indicator in determining the cost - effectiveness of the census — are significant and lead to higher costs .

this is because the bureau sends temporary workers to each non - responding household to obtain census data .

as a result , non - response follow - up is the bureau's largest and most costly field operation .

in many ways , the bureau has had to invest substantially more resources each decade to match the results of prior enumerations .

further , achieving a complete and accurate census is becoming an increasingly daunting task , in part , because the nation's population is growing larger , more diverse , and more reluctant to participate .

when the census misses a person who should have been included , it results in an undercount ; conversely , an overcount occurs when an individual is counted more than once .

such errors are particularly problematic because of their impact on various subgroups .

minorities , renters , and children , for example , are more likely to be undercounted by the census .

the bureau faces an additional challenge of locating unconventional and hidden housing units , such as converted basements and attics .

for example , as shown in figure 2 , what appears to be a small , single - family house could contain an apartment , as suggested by its two doorbells .

if an address is not in the bureau's address file , its residents are less likely to be included in the census .

the basic design of the enumeration — mail out and mail back of the census questionnaire with in - person follow - up for non - respondents — has been in use since 1970 .

however , a key lesson learned from the 2010 census and earlier enumerations , is that this “traditional” design is no longer capable of cost - effectively counting the population .

in response to its own assessments , our recommendations , and studies by other organizations , the bureau has fundamentally re - examined its approach for conducting the 2020 census .

specifically , its plan for 2020 includes four broad innovation areas ( re - engineering field operations , using administrative records , verifying addresses in - office , and developing an internet self - response option ) .

the bureau has estimated that these innovations could result in savings of over $5 billion ( in 2020 dollars ) when compared to its estimates of the cost for conducting the census with traditional methods .

however , in june 2016 , we reported that the bureau's life - cycle cost estimate of $12.5 billion , developed in october 2015 , was not reliable and did not adequately account for risk , as discussed later in this statement .

bureau plans to use it to drive innovation to help drive these innovations , the bureau plans to rely on both new and legacy it systems and infrastructure .

for example , the bureau is developing or modifying 11 it systems as part of an enterprise - wide initiative called census enterprise data collection and processing ( cedcap ) , which is managed within the bureau's it directorate .

this initiative is a large and complex modernization program intended to deliver a system - of - systems to support all of the bureau's survey data collection and processing functions , rather than continuing to rely on unique , survey - specific systems with redundant capabilities .

in addition , according to bureau officials , the 2020 census directorate or other bureau divisions are developing or modifying 32 other it systems .

to help inform , validate , and refine the operational design of the 2020 census , and to test several of the it systems , the bureau has held a series of operational tests since 2012 .

among these , in march 2017 , the bureau conducted a nationwide test ( referred to as the 2017 census test ) of households responding to census questions using paper , the internet , or the phone .

this test evaluated key new it components , such as the internet self - response system and the use of a cloud - based infrastructure .

the bureau is currently conducting the 2018 end - to - end test , which began in august 2017 and runs through april 2019 .

it is the bureau's final opportunity to test all key systems and operations to ensure readiness for the 2020 census .

the bureau's plans for this test include , among other things , address canvassing , self - response ( via paper , internet , and phone ) , and nonresponse follow - up .

to support its 2018 end - to - end test , the bureau plans to deploy and use 43 systems incrementally to support nine operations from december 2016 through the end of the test in april 2019 .

these nine operations are: ( 1 ) in - office address canvassing , ( 2 ) recruiting staff for address canvassing , ( 3 ) training for address canvassing , ( 4 ) in - field address canvassing , ( 5 ) recruiting staff for field enumeration , ( 6 ) training for field enumeration , ( 7 ) self - response ( i.e. , internet , phone , or paper ) , ( 8 ) field enumeration , and ( 9 ) tabulation and dissemination .

appendix i includes additional details about the 43 systems , the operation or operations they support , and key deployment dates .

the four innovation areas the bureau plans for 2020 show promise for a more cost - effective head count ( see table 1 ) .

however , the innovations also introduce new risks , in part , because they include new procedures and technology that have not been used extensively in earlier decennials , if at all .

our prior work has shown the importance of the bureau conducting a robust testing program , including the 2018 end - to - end test .

however , because of funding uncertainty the bureau canceled the field components of the 2017 census test including non - response follow - up , a key census operation .

in november 2016 , we reported that the cancelation of the 2017 field tests was a lost opportunity to test , refine , and integrate operations and systems , and that it put more pressure on the 2018 end - to - end test to demonstrate that enumeration activities will function under census - like conditions as needed for 2020 .

in may 2017 , the bureau scaled back the operational scope of the 2018 end - to - end and , of the three planned test sites , only the rhode island site would fully implement the 2018 end - to - end test .

the washington and west virginia state test sites would test address canvassing .

in addition , due to budgetary concerns , the bureau decided to remove three coverage measurement operations ( and the technology that supports them ) from the scope of the test .

without sufficient testing , operational problems can go undiscovered and the opportunity to improve operations will be lost , in part because the 2018 end - to - end test is the last opportunity to demonstrate census technology and procedures across a range of geographic locations , housing types , and demographic groups .

administrative records — information already provided to the government as it administers other programs , such as mail collection by the u.s .

postal service — have been discussed and used for the decennial census since the 1970s , and for 2020 the bureau plans a more significant role for them .

in july 2017 , we reported that the bureau had taken steps to ensure that its use of administrative records would lower the cost and improve the accuracy of the 2020 census .

for example , the bureau set a rule that it would only use administrative records to count a household when a minimum amount of information was present within data sources .

according to the bureau , this would help ensure that administrative records are used only in circumstances where research has shown them to be most accurate .

additionally , before using any administrative records to support census operations , the bureau determined it will subject each source to a quality assurance process that includes , among other things , basic checks for data integrity as well as assessments by subject matter experts of the information's fitness for various uses by the bureau .

 ( see figure 3. ) .

according to the bureau , it links administrative records data sources to complement each other , improving their reliability and completeness .

the bureau also creates an anonymous personal identifier for each individual in the data to reduce the risk of disclosure once the data are linked across sources .

in july 2017 , we reported that the bureau had already tested the uses of administrative records that hold the most potential for reducing census costs , such as counting people who did not respond to census mailings .

the bureau planned to test additional applications of administrative records for the first time during the 2018 end - to - end test .

for example , the bureau planned to use administrative records to support quality control during its non - response field enumeration .

the bureau planned to compare response data collected by enumerators to administrative records and flag significant differences based on predefined rules .

the differences might be in the total count of persons in a household or in specific combinations of personal characteristics , such as age or race .

according to the bureau , flagging such differences could be used to help identify which enumeration cases to reinterview as part of the quality control operation .

however , we reported in october 2015 that the bureau faced other challenges with using administrative records for the 2020 census .

for example , although the bureau has no control over the accuracy of data provided to it by other agencies , it is responsible for ensuring that data it uses for the 2020 census are of sufficient quality for their planned uses .

another challenge we identified in 2015 is the extent to which the public will accept government agencies sharing personal data for the purposes of the census .

the bureau has recognized these challenges within its risk registers .

in - office address canvassing .

the bureau has re - engineered its approach to building its master address list for 2020 .

specifically , by relying on multiple sources of imagery and administrative data , the bureau anticipates constructing its address list with far less door - to - door field canvassing compared to previous censuses .

one major change the bureau has made consists of using in - office address canvassing — a two - phase process that was to systematically review small geographic areas nationwide , known as census blocks , to identify those that will not need to be canvassed in the field , as shown in figure 4 .

the bureau estimated that the two phases of in - office canvassing would have resulted in roughly 25 percent of housing units requiring in - field canvassing , instead of canvassing nearly all housing units in the field as done in prior decennials .

with in - office address canvassing census workers compare current aerial imagery for a given block with imagery for that block dating to the time of the last decennial census in 2010 .

during this first phase , called interactive review , specially trained census workers identify whether a block appears to have experienced change in the number of housing units , flagging each block either as stable — free of population growth , decline , or uncertainty in what is happening in the imagery over time — or “active,” in which case it moves to the next phase .

addresses in stable blocks are not marked for in - field canvassing .

for blocks where change is detected or suspected , the bureau was to use a second phase of in - office canvassing , known as active block resolution , to attempt to resolve the status of each address and housing unit in question within that block .

during this phase , census workers use aerial imagery , street imagery , and data from the u.s .

postal service , as well as from state , local , and tribal partners when reviewing blocks .

if a block can be fully resolved during this phase of in - office canvassing , the changes are recorded in the bureau's master address file .

if a block cannot be fully resolved during the second phase of in - office canvassing , then the entire block , or some portion of the block , is flagged for inclusion in the in - field canvassing operation .

a first pass of the entire country for in - office address canvassing began in september 2015 and was completed in june 2017 .

in - field canvassing for the 2020 census is scheduled to begin in august 2019 .

however , in july 2017 we reported that the bureau altered its design for re - engineered address canvassing because of budget uncertainty by suspending the second phase of in - office address canvassing .

without the second phase of in - office address canvassing , blocks that are not resolved by phase one will have a greater chance of requiring in - field canvassing .

bureau officials told us at that time that they anticipated that canceling the second phase of in - office address canvassing altogether would increase their estimated in - field canvassing workload by 5 percentage points , from 25 percent to 30 percent of housing units — increasing costs .

the bureau did not develop cost and quality information on address canvassing projects , and detailed information on cost tradeoffs was not available when we requested it .

the information the bureau had did not break out the estimated cost of the different phases of in - office address canvassing through 2020 .

however , the total estimated cost for both phases one and two was approximately $22 million .

thus , this suspension might save a portion of the $22 million , but it will potentially increase the cost of the address canvassing operation downstream .

our july 2017 report recommended , and the bureau agreed , that the bureau should use its evaluations before 2020 to determine the implications of in - office address canvassing on the cost and quality of address canvassing , and use this information to justify decisions related to its re - engineered address canvassing approach .

in - field address canvassing for the 2018 end - to - end test .

on august 28 , 2017 , temporary census employees known as address listers began implementing the in - field component of address canvassing for the 2018 end - to - end test .

listers walked the streets of designated census blocks at all three test sites to verify addresses and geographic locations .

the operation ended on september 27 , 2017 .

as part of our ongoing work , we visited all three test sites and observed 18 listers conduct address canvassing .

generally , we found that listers were able to conduct address canvassing as planned .

however , we also noted several challenges .

we shared the following preliminary observations from our site visits with the bureau: internet connectivity was problematic at the west virginia test site .

we spoke to four census field supervisors that described certain areas as dead spots where internet and cell phone service were not available .

we also were told by those same supervisors that only certain cell service providers worked in certain areas .

in order to access the internet or cell service in those areas , census workers sometimes needed to drive several miles .

the allocation of lister assignments was not always optimal .

listers were supposed to be provided assignments close to where they live in order to optimize their local knowledge and to limit the numbers of miles being driven by listers to and from their assignment area .

bureau officials told us this was a challenge at all three test sites .

moreover , at one site the area census manager told us that some listers were being assigned work in another county even though blocks were still unassigned closer to where they resided .

relying on local knowledge and limiting the number of miles can increase both the efficiency and effectiveness of address canvassing .

the assignment of some of the large blocks early in the operations was not occurring as planned .

at all three 2018 end - to - end test sites bureau managers had to manually assign some large blocks ( some blocks had hundreds of housing units ) .

it is important to assign large blocks early on because leaving the large blocks to be canvassed until the end of the operation could jeopardize the timely completion of address canvassing .

the global positioning system - derived location for the lister was not always corresponding to the location on the map .

a bureau official confirmed that at all three test sites , the location icon jumped around or was on the wrong street .

according to a bureau official , listers were told to override the global positioning system - derived location when confirming the geographic location of the residence .

we have discussed these challenges with bureau officials who stated that overall they are satisfied with the implementation of address canvassing but also agreed that resolving challenges discovered during address canvassing , some of which can affect the operation's efficiency and effectiveness , will be important before the 2020 census .

we will continue to monitor address canvassing operation and plan to issue a report in the winter of 2018 .

we have previously reported that the bureau faced challenges in managing and overseeing it programs , systems , and contractors supporting the 2020 census .

specifically , it has been challenged in managing schedules , costs , contracts , and governance and internal coordination for its it systems .

as a result of these challenges , the bureau is at risk of being unable to fully implement key it systems necessary to support the 2020 census .

we have previously recommended that the bureau take action to improve its implementation and management of it in areas such as governance and internal coordination .

we also have ongoing work reviewing each of these areas .

our ongoing work has indicated that the bureau faces significant challenges in managing the schedule for developing and testing systems for the 2018 end - to - end test that began in august 2017 .

in this regard , the bureau still has significant development and testing work that remains to be completed .

as of august 2017 , of the 43 systems in the test , the bureau reported that 4 systems had completed development and integration testing , while the remaining 39 systems had not completed these activities .

of these 39 systems , the bureau reported that it had deployed a portion of the functionality for 21 systems to support address canvassing for the 2018 end - to - end test ; however , it had not yet deployed any functionality for the remaining 18 systems for the test .

figure 5 summarizes the development and testing status for the 43 systems planned for the 2018 end - to - end test , and appendix i includes additional information on the status of development and testing for these systems .

moreover , due to challenges experienced during systems development , the bureau has delayed key it milestone dates ( eg , dates to begin integration testing ) by several months for the systems supporting six of the nine operations in the 2018 end - to - end test .

figure 6 depicts the delays to the deployment dates for the operations in the 2018 end - to - end test , as of august 2017 .

however , our ongoing work also indicates that the bureau is at risk of not meeting the updated milestone dates .

for example , in june 2017 the bureau reported that at least two of the systems expected to be used in the self - response operation ( the internet self - response system and the call center system ) are at risk of not meeting the delayed milestone dates .

in addition , in september 2017 the bureau reported that at least two of the systems expected to be used in the field enumeration operation ( the enumeration system and the operational control system ) are at risk of not meeting their delayed dates .

combined , these delays reduce the time available to conduct the security reviews and approvals for the systems being used in the 2018 end - to - end test .

we previously testified in may 2017 that the bureau faced similar challenges leading up to the 2017 census test , including experiencing delays in system development that led to compressed time frames for security reviews and approvals .

specifically , we noted that the bureau did not have time to thoroughly assess the low - impact components of one system and complete penetration testing for another system prior to the test , but accepted the security risks and uncertainty due to compressed time frames .

we concluded that , for the 2018 end - to - end test , it will be important that these security assessments are completed in a timely manner and that risks are at an acceptable level before the systems are deployed .

the bureau noted that , if it continues to be behind schedule , field operations for the 2018 end - to - end test will not be performed as planned .

bureau officials are evaluating options to decrease the impact of these delays on integration testing and security review activities by , for example , utilizing additional staff .

we have ongoing work reviewing the bureau's development and testing delays and the impacts of these delays on systems readiness for the 2018 end - to - end test .

the bureau faces challenges in reporting and controlling it cost growth .

in april 2017 , the bureau briefed us on its efforts to estimate the costs for the 2020 census , during which it presented it costs of about $2.4 billion from fiscal years 2018 through 2021 .

based on this information and other corroborating it contract information provided by the bureau , we testified in may 2017 that the bureau had identified at least $2 billion in it costs .

however , in june 2017 , bureau officials in the 2020 census directorate told us that the data they provided in april 2017 did not reflect all it costs for the 2020 program .

the officials provided us with an analysis of the bureau's october 2015 cost estimate that identified $3.4 billion in total it costs from fiscal years 2012 through 2023 .

these costs included , among other things , those associated with system engineering , test and evaluation , and infrastructure , as well as a portion of the costs for the cedcap program .

yet , our ongoing work determined that the bureau's $3.4 billion cost estimate does not reflect its current plans for acquiring it to be used during the 2020 census and that the related costs are likely to increase: in august 2016 , the bureau awarded a technical integration contract for about $886 million , a cost that was not reflected in the $3.4 billion expected it costs .

more recently , in may 2017 , we testified that the scope of work for this contract had increased since the contract was awarded ; thus , the corresponding contract costs were likely to rise above $886 million , as well .

in march 2017 , the bureau reported that the contract associated with the call center and it system to support the collection of census data over the phone was projected to overrun its initial estimated cost by at least $40 million .

in may 2017 , the bureau reported that the cedcap program's cost estimate was increasing by about $400 million — from its original estimate of $548 million in 2013 to a revised estimate of $965 million in may 2017 .

in june 2017 , the bureau awarded a contract for mobile devices and associated services for about $283 million , an amount that is about $137 million higher than the cost for these devices and services identified in its october 2015 estimate .

as a result of these factors , the bureau's $3.4 billion estimate of it costs is likely to be at least $1.4 billion higher , thus increasing the total costs to at least $4.8 billion .

figure 7 identifies the bureau estimate of total it costs associated with the 2020 program as of october 2015 , as well as anticipated cost increases as of august 2017 .

it cost information that is accurately reported and clearly communicated is necessary so that congress and the public have confidence that taxpayer funds are being spent in an appropriate manner .

however , changes in the bureau's reporting of these total costs , combined with cost growth since the october 2015 estimate , raise questions as to whether the bureau has a complete understanding of the it costs associated with the 2020 program .

in this regard , we have previously reported on issues with the bureau's cost estimating practices ( which are discussed in more detail later in this statement ) .

to address these issues , in october 2017 , officials stated that the bureau is developing a new cost estimate for the entire 2020 census program , which they expect to release by the end of this fall .

our ongoing work also determined that the bureau faces challenges in managing its significant contractor support .

the bureau is relying on contractor support in many key areas of the 2020 census .

for example , it is relying on contractors to develop a number of key systems and components of the it infrastructure .

these activities include ( 1 ) developing the it platform that is to be used to collect data from a majority of respondents — those using the internet , telephone , and non - response follow - up activities ; ( 2 ) procuring the mobile devices and cellular service to be used for non - response follow - up ; and ( 3 ) developing the infrastructure in the field offices .

according to bureau officials , contractors are also providing support in areas such as fraud detection , cloud computing services , and disaster recovery .

in addition to the development of key technology , the bureau is relying on contractor support for integrating all of the key systems and infrastructure .

the bureau awarded a contract to integrate the 2020 census systems and infrastructure in august 2016 .

the contractor's work was to include evaluating the systems and infrastructure and acquiring the infrastructure ( eg , cloud or data center ) to meet the bureau's scalability and performance needs .

it was also to include integrating all of the systems , supporting technical testing activities , and developing plans for ensuring the continuity of operations .

since the contract was awarded , the bureau has modified the scope to also include assisting with operational testing activities , conducting performance testing for two internet self - response systems , and technical support for the implementation of the paper data capture system .

however , our ongoing work has indicated that the bureau is facing staffing challenges that could impact its ability to manage and oversee the technical integration contractor .

specifically , the bureau is managing the integration contractor through a government program management office , but this office is still filling vacancies .

as of october 2017 , the bureau reported that 35 of the office's 58 federal employee positions were vacant .

as a result , this program management office may not be able to provide adequate oversight of contractor cost , schedule , and performance .

the delays during the 2017 test and preparations for the 2018 end - to - end test raises concerns regarding the bureau's ability to effectively perform contractor management .

as we reported in november 2016 , a greater reliance on contractors for these key components of the 2020 census requires the bureau to focus on sound management and oversight of the key contracts , projects , and systems .

as part of our ongoing work , we plan to monitor the bureau's progress in managing its contractor support .

effective it governance can drive change , provide oversight , and ensure accountability for results .

further , effective it governance was envisioned in the provisions referred to as the federal information technology acquisition reform act ( fitara ) , which strengthened and reinforced the role of the departmental cio .

to ensure executive - level oversight of the key systems and technology , the bureau's cio ( or a representative ) is a member of the governance boards that oversee all of the operations and technology for the 2020 census .

however , in august 2016 we reported on challenges the bureau has had with it governance and internal coordination , including weaknesses in its ability to monitor and control it project costs , schedules , and performance .

we made eight recommendations to the department of commerce to direct the bureau to , among other things , better ensure that risks are adequately identified and schedules are aligned .

the department agreed with our recommendations .

however , as of october 2017 , the bureau had only fully implemented one recommendation and had taken initial steps toward implementing others .

further , given the schedule delays and cost increases previously mentioned , and the vast amount of development , testing , and security assessments left to be completed , we remain concerned about executive - level oversight of systems and security .

moving forward , it will be important that the cio and other agency executives continue to use a collaborative governance approach to effectively manage risks and ensure that the it solutions meet the needs of the agency within cost and schedule .

as part of our ongoing work , we plan to monitor the steps the bureau is taking to effectively oversee and manage the development and acquisition of its it systems .

in november 2016 , we described the significant challenges that the bureau faced in securing systems and data for the 2020 census , and we noted that tight time frames could exacerbate these challenges .

two such challenges were ( 1 ) ensuring that individuals gain only limited and appropriate access to the 2020 census data , including personally identifiable information ( pii ) ( eg , name , address , and date of birth ) , and ( 2 ) making certain that security assessments were completed in a timely manner and that risks were at an acceptable level .

protecting pii , for example , is especially important because a majority of the 43 systems to be used in the 2018 end - to - end test contain pii , as reflected in figure 8 .

to address these and other challenges , federal law and guidance specify requirements for protecting federal information and information systems , such as those to be used in the 2020 census .

specifically , the federal information security management act of 2002 and the federal information security modernization act of 2014 ( fisma ) require executive branch agencies to develop , document , and implement an agency - wide program to provide security for the information and information systems that support operations and assets of the agency .

accordingly , the national institute of standards and technology ( nist ) developed risk management framework guidance for agencies to follow in developing information security programs .

additionally , the office of management and budget's ( omb ) revised circular a - 130 on managing federal information resources required agencies to implement the nist risk management framework to integrate information security and risk management activities into the system development life cycle .

in accordance with fisma , nist guidance , and omb guidance , the office of the cio established a risk management framework .

this framework requires that system developers ensure that each of the systems undergoes a full security assessment , and that system developers remediate critical deficiencies .

in addition , according to the bureau's framework , system developers must ensure that each component of a system has its own system security plan , which documents how the bureau plans to implement security controls .

as a result , system developers for a single system might develop multiple system security plans ( in some cases as many as 34 plans ) , which all have to be approved as part of the system's complete security documentation .

we have ongoing work that is reviewing the extent to which the bureau's framework meets the specific requirements of the nist guidance .

according to the bureau's framework , each of the 43 systems in the 2018 end - to - end test will need to have complete security documentation ( such as system security plans ) and an approved authorization to operate prior to their use in the 2018 end - to - end test .

however , our ongoing work indicates that , while the bureau is completing these steps for the 43 systems to be used in the 2018 end - to - end test , significant work remains .

specifically: none of the 43 systems are fully authorized to operate through the completion of the 2018 end - to - end test .

bureau officials from the cio's office of information security stated that these systems will need to be reauthorized because , among other things , they have additional development work planned that may require the systems to be reauthorized ; are being moved to a different infrastructure environment ( eg , from a data center to a cloud - based environment ) ; or have a current authorization that expires before the completion of the 2018 end - to - end test .

the amount of work remaining is concerning because the test has already begun and the delays experienced in system development and testing mentioned earlier reduce the time available for performing the security assessments needed to fully authorize these systems before the completion of the 2018 end - to - end test .

thirty - seven systems have a current authorization to operate , but the bureau will need to reauthorize these systems before the completion of the 2018 end - to - end test .

this is due to the reasons mentioned previously , such as additional development work planned and changes to the infrastructure environments .

two systems have not yet obtained an authorization to operate .

for the remaining four systems , the bureau has not yet provided us with documentation about the current authorization status .

figure 9 depicts the authorization to operate status for the systems being used in the 2018 end - to - end test , as reported by the bureau .

because many of the systems that will be a part of the 2018 end - to - end test are not yet fully developed , the bureau has not finalized all of the security controls to be implemented ; assessed those controls ; developed plans to remediate control weaknesses ; and determined whether there is time to fully remediate any deficiencies before the systems are needed for the test .

in addition , as discussed earlier , the bureau is facing system development challenges that are delaying the completion of milestones and compressing the time available for security testing activities .

as we previously reported , while the large - scale technological changes ( such as internet self - response ) increase the likelihood of efficiency and effectiveness gains , they also introduce many information security challenges .

the 2018 end - to - end test also involves collecting pii on hundreds of thousands of households across the country , which further increases the need to properly secure these systems .

thus , it will be important that the bureau provides adequate time to perform these security assessments , completes them in a timely manner , and ensures that risks are at an acceptable level before the systems are deployed .

we plan to continue monitoring the bureau's progress in securing its it systems and data as part of our ongoing work .

in june 2016 , we reported that the bureau's october 2015 update of its life - cycle cost estimate for the 2020 census did not conform to the four characteristics that constitute best practices , and , as a result , the estimate was unreliable .

cost estimates that appropriately account for risks facing an agency can help an agency manage large , complex activities like the 2020 census , as well as help congress make funding decisions and provide oversight .

cost estimates are also necessary to inform decisions to fund one program over another , to develop annual budget requests , to determine what resources are needed , and to develop baselines for measuring performance .

in june 2016 , we reported that , although the bureau had taken steps to improve its capacity to carry out an effective cost estimate , such as establishing an independent cost estimation office , its october 2015 version of the estimate for the 2020 census only partially met the characteristics of two best practices ( comprehensive and accurate ) and minimally met the other two ( well - documented and credible ) .

all four characteristics need to be substantially met in order for an estimate to be deemed high - quality: comprehensive .

to be comprehensive an estimate should have enough detail to ensure that cost elements are neither omitted nor double - counted , and all cost - influencing assumptions are detailed in the estimate's documentation , among other things , according to best practices .

in june 2016 , we reported that , while bureau officials were able to provide us with several documents that included projections and assumptions that were used in the cost estimate , we found the estimate to be partially comprehensive because it was unclear if all life - cycle costs were included in the estimate or if the cost estimate completely defined the program .

accurate .

accurate estimates are unbiased and contain few mathematical mistakes .

we reported in june 2016 that the estimate partially met best practices for this characteristic , in part because we could not independently verify the calculations the bureau used within its cost model , which the bureau did not have documented or explained outside its cost model .

well - documented .

cost estimates are considered valid if they are well - documented to the point they can be easily repeated or updated and can be traced to original sources through auditing , according to best practices .

in june 2016 , we reported that , while the bureau provided some documentation of supporting data , it did not describe how the source data were incorporated .

credible .

credible cost estimates must clearly identify limitations due to uncertainty or bias surrounding the data or assumptions , according to best practices .

in june 2016 , we reported that the estimate minimally met best practices for this characteristic in part because the bureau carried out its risk and uncertainty analysis only for about $4.6 billion ( 37 percent ) of the $12.5 billion total estimated life - cycle cost , excluding , for example , consideration of uncertainty over what the decennial census's estimated part will be of the total cost of cedcap .

in june 2016 , we recommended that the bureau take action to ensure its 2020 census cost estimate meets all four characteristic of a reliable cost estimate .

the bureau agreed with our recommendation .

we also reported in june 2016 that risks were not properly accounted for in the cost estimate and recommended that the bureau properly account for risk to ensure there are appropriate levels for budgeted contingencies , and those recommendations have not yet been implemented .

in october 2017 , bureau officials told us they were making progress towards implementing our recommendations and would provide us with that documentation when the cost estimate and supporting documentation are finalized .

moreover , bureau officials also told us that an updated cost estimate would be available by the end of this fall .

however , until the bureau updates its estimate and we have the opportunity to review its reliability , questions will surround the quality of the 2020 census cost estimate and the basis for any 2020 census annual budgetary figures .

while the bureau has not updated its october 2015 cost estimate , several events since then indicate that the cost of the current design will be higher .

for example: as previously mentioned , in august 2016 an $886 million it integration contract was awarded .

according to bureau officials , there was no reference to this contract in the documentation for the planned contract costs supporting the october 2015 life - cycle cost estimate .

in march 2017 , the bureau suspended part of how it is verifying address in - office procedures using on - screen imagery — one of its four key design innovations intended to control the cost of the 2020 census .

according to bureau officials , the suspension of the one part of in - office canvassing will increase the workload of the more expensive in - field ( door - to - door address identification ) by at least five percentage points , from 25 percent to 30 percent of housing units — increasing the cost over what had been assumed as part of the earlier cost estimate .

based on cost assumptions underlying its october 2015 life - cycle cost estimate , we found , as part of our prior work , that the potential addition of five percentage points to the field workload alone could reduce the bureau's cost savings by $26.6 million .

as earlier discussed , in may 2017 , bureau officials reported that the cost of the cedcap program has now increased by over $400 million , from about $548 million to $965 million .

cost estimates are also used by the bureau as a tool to inform the annual budget process .

however , since the bureau did not fully follow best practices for developing and maintaining the life - cycle cost estimate , as previously described , annual budget requests based on that cost estimate may not be fully informed .

a high - quality cost estimate is the foundation of a good budget .

a major purpose of a cost estimate is to support the budget process by providing an estimate of the funding required to efficiently execute a program .

because most programs do not remain static but evolve over time , developing a cost estimate should not be a onetime event but rather a recurrent process .

effective program and cost control requires ongoing revisions to the cost estimate and budget .

using a reliable life - cycle cost estimate to formulate the budget could help the bureau ensure that all costs are fully accounted for so that resources are adequate to support the program .

credible cost estimates could also help the bureau effectively defend budgets to the department of commerce , omb , and congress .

concerns about the soundness of the life cycle cost estimate and the quality of annual budgets related to the 2020 census are particularly important because the bulk of funds will be obligated in fiscal years 2019 through 2020 .

in our june 2016 report on the bureau's life - cycle cost estimate we made several recommendations with which the bureau agreed .

we will continue to monitor the bureau's efforts to address these recommendations .

in conclusion , the bureau has made progress in revamping its approach to the census and testing the new design .

however , it faces considerable challenges and uncertainties in ( 1 ) implementing the cost - saving innovations ; ( 2 ) managing the development and security of key it systems ; and ( 3 ) developing a quality cost estimate for the 2020 census .

for these reasons , the 2020 census is a gao high risk area .

continued management attention is vital for ensuring risks are managed , the bureau's preparations stay on - track , and the bureau is held accountable for implementing the enumeration as planned .

we will continue to assess the bureau's efforts to conduct a cost - effective enumeration and look forward to keeping congress informed of the bureau's progress .

chairman gowdy , ranking member cummings , and members of the committee , this completes our prepared statement .

we would be pleased to respond to any questions that you may have .

if you have any questions about this statement , please contact david a. powner at ( 202 ) 512-9286 or by e - mail at pownerd@gao.gov or robert goldenkoff at ( 202 ) 512-2757 or by e - mail at goldenkoffr@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this statement .

other key contributors to this testimony include lisa pearson ( assistant director ) ; jon ticehurst ( assistant director ) ; kate sharkey ( analyst in charge ) ; mark abraham , dewi djunaidy ; hoyt lacy ; andrea starosciak ; umesh thakkar ; timothy wexler ; and katherine wulff .

staff who made key contributions to the reports cited in this statement are identified in the source products .

as part of its 2018 end - to - end test , the census bureau ( bureau ) plans to deploy 43 systems incrementally to support nine operations from december 2016 through the end of the test in april 2019 .

the nine operations are: ( 1 ) in - office address canvassing , ( 2 ) recruiting for address canvassing , ( 3 ) training for address canvassing , ( 4 ) in - field address canvassing operation , ( 5 ) recruiting for field enumeration , ( 6 ) training for field enumeration , ( 7 ) self - response ( i.e. , internet , phone , or paper ) operation , ( 8 ) field enumeration operation , and ( 9 ) tabulation and dissemination .

according to the bureau , a single system may be deployed multiple times throughout the test ( with additional or new functionality ) if that system is needed for more than one of these operations .

table 1 describes the status as of august 2017 of development and integration testing for each system in the 2018 end - to - end test .

specifically , as of august 2017 , the bureau had completed both development work and integration testing for 4 systems , and was in the process of completing development and testing for 39 systems .

