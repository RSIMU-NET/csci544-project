one of the most complex and vital tasks facing the department of defense ( dod ) is managing its supply chain to effectively and efficiently provide spare parts , food , fuel , and other critical supplies in support of u.s. military forces .

dod's goal and challenge are to deliver the right items in the right quantities to the right place at the right time — and at the right cost .

supply chain management encompasses the processes and systems for accomplishing this goal and includes inventory management , materiel distribution , and asset visibility .

according to dod , to achieve a seamless and effective supply chain , dod needs to have end - to - end visibility of its assets from acquisition to disposal .

dod defines asset visibility as the ability to provide timely and accurate information on the location , quantity , condition , movement , and status of items in its inventory , including assets in transit .

maintaining visibility of these assets is critical to ensure that dod provides support to the warfighter .

because of long - standing weaknesses in dod's supply chain management , in 1990 we designated it as a high - risk area .

in 2005 , we added asset visibility to the supply chain management high - risk area .

in 2011 , we reported that limitations in asset visibility made it difficult for dod to obtain timely and accurate information on the assets that are present in the theater of operations .

in our february 2015 biennial update to the high - risk series , we reported that dod had made progress addressing weaknesses in its supply chain management , which is comprised of three issue areas: inventory management , materiel distribution , and asset visibility .

with respect to asset visibility , we reported that the department had met one of our five criteria — leadership commitment — for the removal of asset visibility from the high risk list , and partially met the other four criteria — capacity , corrective action plan , monitoring , and demonstrated progress .

we reported that dod had made considerable progress from 2013 to 2015 in addressing the four remaining criteria through actions such as developing the department's framework for improving asset visibility , known as its 2014 strategy for improving dod asset visibility ( 2014 strategy ) .

the 2014 strategy outlined initiatives intended to improve dod's asset visibility .

furthermore , we reported that to fully address the remaining four high - risk criteria dod needed to take a number of actions , such as linking the goals and objectives in the 2014 strategy with the initiatives intended to implement the strategy .

we also reported that dod needed to assess and refine , as appropriate , existing performance measures to ensure that these measures assessed the implementation of individual initiatives as well as progress toward achieving the strategy's goals and objectives .

in december 2015 , we reported that dod had updated its 2014 strategy in october 2015 ( 2015 strategy ) , and had taken numerous actions to address weaknesses in its 2014 strategy .

for example , the 2015 strategy addressed steps dod was taking to facilitate collaboration with industry to capture best practices with respect to asset visibility .

like its predecessor , the updated 2015 strategy states that it is intended to create a framework whereby the dod components can work collaboratively to enhance asset visibility in a manner that provides accurate , reliable , and timely data to track assets throughout their life cycles .

according to the 2015 strategy and office of the secretary of defense ( osd ) officials , the asset visibility working group — comprised of representatives from the components and other government agencies , as needed — facilitates collaboration across the components , identifies opportunities for improvement , and monitors the implementation of the initiatives .

we initiated this review under the authority of the comptroller general to address issues of broad interest to congress .

in this report , we address the extent to which dod has ( 1 ) identified performance measures that allow it to monitor the progress of selected asset visibility initiatives identified in its strategies and ( 2 ) addressed our five criteria — leadership commitment , capacity , corrective action plan , monitoring , and demonstrated progress — for removing asset visibility from our high risk list .

to determine the extent to which dod has identified performance measures that allow it to monitor the progress of selected asset visibility initiatives identified in the 2014 and 2015 strategies ( strategies ) , we reviewed documents such as the strategies ; minutes from the asset visibility working group meetings ; and documents showing the status of the implementation , including charts that track the development and closure of the asset visibility initiatives .

thirty initiatives have been included in the strategies , but 3 of these were halted , for a variety of reasons .

to develop a non - generalizable sample from the remaining 27 initiatives , we selected 8 — at least one from each of the components — to review and assess , including analyzing the performance measures associated with each initiative .

the results from this sample cannot be generalized to the other 19 initiatives .

in our selection of initiatives to review , we used several sampling criteria to ensure that we had a range of initiatives — from some just beginning to some that had already been completed .

we surveyed program managers and other cognizant officials ( hereafter referred to as component officials ) responsible for the asset visibility initiatives we selected .

we included questions in our survey related to the development and closure of the initiatives and took several steps to ensure the validity and reliability of the survey instrument .

we also reviewed the strategies to identify performance measures necessary to monitor progress of the 8 initiatives we selected .

we assessed whether ( 1 ) dod had followed the guidance set forth in the strategies and ( 2 ) the measures for the initiatives included selected key attributes of successful performance measures ( for example , are the measures clear , quantifiable ( i.e. , have measurable targets and baseline and trend data ) , objective , and reliable ) .

additionally , we reviewed the after - action reports for all of the initiatives that had been closed — 20 of 27 initiatives , which included 5 of the 8 initiatives we reviewed in detail — by the asset visibility working group as of october 31 , 2016 .

we assessed these after - action reports to determine whether they were completed for the initiative , documented whether measures were obtained , and identified challenges and lessons learned .

furthermore , we interviewed component officials and officials at the office of the deputy assistant secretary of defense for supply chain integration ( hereafter referred to as osd ) to clarify survey responses and to discuss plans to develop the initiatives , including any efforts to monitor progress and demonstrate results .

to determine whether dod had addressed the five criteria — leadership commitment , capacity , corrective action plan , monitoring , and demonstrated progress — that would have to be met for us to remove asset visibility from the high risk list , we reviewed documents such as the 2014 and 2015 strategies and charts that track the implementation and closure of asset visibility initiatives .

we included questions in our survey to collect additional information from officials on their efforts to address the high - risk criteria .

for example , we asked how the component monitored the implementation of the initiative and whether there had been any demonstrated progress in addressing the opportunity , deficiency , or gap in asset visibility capability that the initiative was designed to address .

we evaluated dod's actions to improve asset visibility against each of our five high - risk criteria for removing this dimension from the high - risk list .

additionally , we interviewed component officials and osd officials to clarify their survey responses and to discuss their plans to continue to make progress in improving asset visibility .

we provide additional information about our scope and methodology in appendix i .

we conducted this performance audit from february 2016 to march 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

dod's supply chain is a global network that provides materiel , services , and equipment to the joint force .

in february 2015 , we reported that dod had been experiencing weaknesses in the management of its supply chain , particularly in the following areas: inventory management , materiel distribution , and asset visibility .

regarding asset visibility , dod has had weaknesses in maintaining visibility of supplies , such as problems with inadequate radio - frequency identification information to track all cargo movements .

additionally , in february 2015 , we reported on progress dod had made in addressing weaknesses in its asset visibility , including developing its 2014 strategy .

dod has focused on improving asset visibility since the 1990s , and its efforts have evolved over time , as shown in figure 1 .

the 2015 strategy states that the department introduced automatic identification technology capabilities to improve its ability to track assets .

since we added asset visibility to the high risk list in 2005 , we have reported that dod has made a great deal of progress in improving asset visibility .

the 2014 strategy notes that for more than 25 years , the department has been using technologies , starting with linear bar codes and progressing to a variety of more advanced technologies , with the goal of improving asset visibility .

specifically , the strategies state that , based on lessons learned from years of war in iraq and afghanistan , the department introduced technology capabilities to improve its ability to track assets as they progress from posts , camps , and stations .

additionally , the 2015 strategy states that dod has made significant progress toward improving asset visibility , but opportunities for greater dod - wide integration still exist .

dod has issued two strategies to guide its efforts in improving asset visibility: 2014 strategy: in january 2014 , the department issued its strategy for improving dod asset visibility .

the 2014 strategy creates a framework whereby the components work collaboratively to identify improvement opportunities and capability gaps and to leverage technology capabilities , such as radio frequency identification .

these capabilities aid in providing timely , accurate , and actionable information about the location , quantity , and status of assets .

the 2014 strategy identified 22 initiatives developed by the components that were intended to improve asset visibility .

osd officials stated that an initiative is conducted in accordance with component - level policy and procedures and can either be for a single component or for potential improvement throughout dod .

according to osd officials , dod components develop asset visibility initiatives , and these initiatives may be identified by the asset visibility working group or by components for inclusion in the strategies .

2015 strategy: in october 2015 , dod issued its update to the 2014 strategy .

the 2015 strategy outlined an additional 8 initiatives developed by the components to improve asset visibility .

according to osd officials , they plan to issue an update to the 2015 strategy , but the release date for this update has not been determined .

these officials stated that the update to the 2015 strategy will outline about 10 new initiatives .

as we reported in january 2015 , dod has taken steps to monitor the asset visibility initiatives .

specifically , dod has established a structure for overseeing and coordinating efforts to improve asset visibility .

this structure includes the asset visibility working group , which according to the strategies is responsible for monitoring the execution of the initiatives .

additionally , the components are designated as the offices of primary responsibility to ensure the successful execution of their initiatives , including developing cost estimates and collecting performance data .

working group members include representatives from osd and the components — joint staff , the defense logistics agency , u.s. transportation command , and each of the military services .

the components submit quarterly status reports to the working group about their initiatives — including progress made on implementation milestones , return on investment , and resources and funding .

additionally , as documented in the minutes from its may 2016 asset visibility working group meeting , dod uses an electronic repository that includes information about the initiatives .

the 2015 strategy describes a process in which the asset visibility working group , among other things , reviews and concurs that an initiative has met its performance objectives .

the asset visibility working group files an after - action report , which is added to the status report , for completed initiatives ; this after - action report is to include performance measures used to assess the success of the initiative , challenges associated with implementing the initiative , and any lessons learned from the initiative .

for example , an after - action report for the u.s. transportation command ( u.s. transcom ) active radio frequency identification ( rfid ) migration initiative stated that u.s. transcom had successfully tracked the use of old and new active rfid tags on military assets and updated an active rfid infrastructure to accommodate the new tags .

dod components have identified performance measures for the 8 initiatives we reviewed , but the measures do not generally include the key attributes of successful performance measures ( i.e. , the measures were not generally clear , quantifiable , objective , and reliable ) .

we also found that after - action reports for some initiatives did not always include information on the performance measures and therefore prevent dod from effectively evaluating the success of the initiatives in achieving the goals and objectives described in the strategies .

dod components have identified at least one performance measure for each of the 8 initiatives we examined .

these initiatives are described in table 1 .

 ( for more details on each of the 8 initiatives , see appendix ii. ) .

dod's strategies direct that expected outcomes or key performance indicators ( which we refer to as performance measures ) be identified for assessing the implementation of each initiative .

the 2015 strategy notes that these performance measures enable groups , such as the asset visibility working group and the supply chain executive steering committee — senior - level officials responsible for overseeing asset visibility improvement efforts — to monitor progress toward the implementation of an initiative and to monitor the extent to which the initiative has improved asset visibility in support of the strategy's goals and objectives .

for example , one of the performance measures for a u.s. transcom initiative on the migration to a new active radio frequency identification ( rfid ) tag is to track the use of old and new active rfid tags on military assets .

additionally , one of the performance measures for the defense logistics agency's ( dla ) initiative on passive rfid technology for clothing and textiles is to track the time it takes to issue new uniforms to military personnel .

the 2015 strategy also notes that the performance measures are reviewed before an initiative is closed by the asset visibility working group .

our prior work on performance measurement has identified several important attributes that performance measures should include if they are to be effective in monitoring progress and determining how well programs are achieving their goals .

 ( see table 2 for a list of selected key attributes. ) .

additionally , standards for internal control in the federal government emphasizes using performance measures to assess performance over time .

we have previously reported that by tracking and developing a performance baseline for all performance measures , agencies can better evaluate whether they are making progress and their goals are being achieved .

based on an analysis of the 8 initiatives we reviewed , we found that these performance measures did not generally include the key attributes of successful performance measures .

moreover , dod's strategies lack sufficient direction on how components are to develop measures for these initiatives that would ensure that the performance measures developed include the key attributes for successful measures .

this hinders dod's ability to ensure that effective measures are developed which will allow it to monitor the performance of the individual initiatives and whether the initiatives are likely to achieve the goals and objectives of the strategies .

we found that some of the performance measures for the 8 initiatives we reviewed included the key attributes of successful performance measures , such as linkage to goals and objectives in the strategies .

however , the measures for most of the initiatives did not have many of the key attributes of successful performance measures .

as shown in table 3 , for three initiatives there were no clearly identified performance measures ; for five there were no measurable targets to allow for easier comparison with the initiatives' actual performance ; for five the measures were not objective ; for five the measures were not reliable ; for six there were no baseline and trend data associated with the measures ; and for three the performance measures were not linked to the goals and objectives of the strategies .

a detailed discussion of our assessment of the performance measures for each key attribute follows: measures for 5 of the 8 initiatives partially included the key attribute of “clarity.” for example , a performance measure for a defense logistics agency initiative was to reduce the time required to issue uniforms by improving cycle times and reducing customer wait time .

we identified “to reduce the time required to issue uniforms” as the name of the measure .

however , the definition we identified for this measure , which is to improve cycle times and reduce customer wait time , did not include the methodology for computing the measure .

therefore , for the clarity attribute , we could not determine if the definition of this measure was consistent with the methodology used to calculate it .

we reported in september 2015 that if the name and definition of the performance measure are not consistent with the methodology used to calculate it , data may be confusing and misleading to the component .

for 3 of the 8 initiatives the performance measures were not clearly stated .

for example , a performance measure for an army initiative was to expand current capabilities by accessing data through a defense casualty system and integrate reporting and tracking into one application .

we found that there was an overall description of the initiative , but it did not include a name or definition for the measure or a methodology for calculating it .

2 .

measurable target: measures for 3 of the 8 initiatives fully included the key attribute of measurable targets .

for example , a performance measure for a joint staff initiative is to have 100 percent visibility of condition codes for non - munitions inventory .

measures for 5 of the 8 initiatives did not identify a measurable target .

for example , a performance measure for a marine corps initiative is to increase non - nodal visibility and the delivery status of materiel in transit within an area of responsibility , but the component did not provide a quantifiable goal or other measure that permits expected performance to be compared with actual results so that actual progress can be assessed .

measures for 3 of the 8 initiatives partially included the key attribute of objectivity .

for example , the performance measures for a navy initiative indicated what is to be observed ( timeliness , accuracy , and completeness ) , but the measures did not specify what population and time frames were to be observed .

measures for 5 of the 8 initiatives did not include the key attribute of objectivity .

for example , the performance measures for an army initiative did not indicate what is to be observed , in which population , and in what time frame .

measures for 3 of the 8 initiatives partially included the key attribute of reliability .

for example , some of the performance measures for a navy initiative included data quality control processes to verify or validate information such as automated or manual reviews and the frequency of reviews .

however , the navy did not specify how often it would perform these reviews .

measures for 5 of 8 initiatives did not include the key attribute of reliability .

for example , the performance measures for an army initiative did not include a name for the measures , definitions for these measures , or methodologies for calculating them .

therefore , we could not determine whether the measures would produce the same results under similar conditions .

5 .

baseline and trend data: measures for 2 of 8 initiatives partially included the key attribute of baseline and trend data .

for example , a joint staff initiative included a baseline ( eg , improve the visibility of condition codes of non - munitions assets in the global combat support system – joint ( gcss - j ) from 48 percent to 100 percent ) , but it did not include trend data .

measures for 6 of 8 initiatives did not include the key attribute of baseline and trend data .

for example , the performance measures for a u.s. transcom initiative for implementing transportation tracking numbers did not include baseline and trend data to identify , monitor , and report changes in performance .

measures for 5 of 8 initiatives fully included the key attribute of linkage .

for example , the performance measures for the joint staff initiative , intended to maximize the visibility of the condition codes of non - munitions assets in gcss - j to support joint logistics planning , are linked to the 2015 strategy's goals of: improving visibility into customer materiel requirements and available resources ; o enhancing visibility of assets in transit , in storage , in process , and in theater ; and o enabling an integrated accessible authoritative data set .

measures for 3 of the 8 initiatives did not include the key attribute of linkage because they were not aligned with agency - wide goals and mission and were not clearly communicated throughout the organization .

these initiatives were identified in the 2014 strategy and the descriptions of the initiatives did not specify which of the goals and objectives they were intended to support .

we reported in january 2015 that the 2014 strategy did not direct that the performance measures developed for the initiatives link to the goals or objectives in the 2014 strategy , and we found that it was not clear whether the measures linked to the strategy's goals and objectives .

therefore , we recommended that dod ensure that the linkage between the performance measures for the individual initiatives and the goals and objectives outlined in the 2014 strategy be clear .

dod concurred with our recommendation and in its 2015 strategy linked each initiative to the goals and objectives .

the deficiencies that we identified in the performance measures can be linked to the fact that the strategies have not included complete direction on the key attributes of successful performance measures .

the 2014 strategy provided direction on the types of expected outcomes and key performance indicators .

for example , an expected outcome is to increase supply chain performance and the key performance indicator is to improve customer wait time .

however , when osd updated the 2014 strategy it did not include in the 2015 strategy an example of the types of expected outcomes and key performance indicators for components to use when developing performance measures .

the lack of direction on successful performance measures may have resulted in measures that lacked key attributes , such as clarity , measurable target , objectivity , reliability , baseline and trend data , and linkage , as we previously discussed .

while osd officials stated that they believed the performance measures for the selected initiatives were sufficient to report on the status of the initiatives , our review of these measures determined that they could not be used to effectively assess the performance of the initiatives to improve asset visibility .

without sufficient direction in subsequent updates to the strategy on developing successful performance measures , dod has limited assurance that the components are developing measures that can be used to determine how the department is progressing toward achieving its goals and objectives related to improving asset visibility .

as described in the 2015 strategy , the asset visibility working group and the component review the performance of the initiatives during implementation .

as we reported in january 2015 , the components report quarterly to the asset visibility working group on the status of their initiatives — including progress made on implementation milestones , return on investment , and resources and funding .

we found that dod components had included performance measures in their quarterly status reports for the 8 initiatives we reviewed .

however , dod components have not always included performance measures to assess the success of their initiatives in after - action reports , which are added to the status report for completed initiatives .

to close an initiative , the components responsible for the initiative request closure and the asset visibility working group files an after - action report , which serves as a closure document and permanent record of an initiative's accomplishments .

according to the 2015 strategy , the after - action report should include information on the objectives met , problems or gaps resolved , challenges associated with implementing the initiative , any lessons learned from the initiative , and measures of success obtained .

the asset visibility working group approves the closure of initiatives when the components have completed or canceled the initiatives and updated the status report section called the after - action report .

once an initiative is closed , according to dod officials , the working group no longer monitors the initiative , but the components may continue to monitor it .

according to these dod officials , dod components may update information provided to the asset visibility working group or the working group may request additional information after the initiative is closed , especially when implementation affects multiple components .

we found that the after - action reports did not always include all of the information necessary .

according to our review of after - action reports , as of october 2016 , the asset visibility working group had closed 5 of the 8 asset visibility initiatives that we examined .

our review of the after - action reports for the 5 closed initiatives found the following: two reports included information on whether the performance measures — also referred to as measures of success — for the initiative had been achieved .

three reports did not follow the format identified in the 2015 strategy , and we could not determine whether the intent and outcomes based on performance measures for the initiative had been achieved .

we also reviewed after - action reports for the remaining 15 initiatives that were closed and found the following: seven reports included information on whether the performance measures for the initiative had been achieved .

five reports did not include information on performance measures , because these measures were not a factor in measuring the success of the initiative .

one report was not completed by the component .

two reports did not follow the format identified in the 2015 strategy , and we could not determine whether the intent and outcomes based on performance measures for the initiative had been achieved .

based on our analysis , it appears that while the asset visibility working group closed 20 initiatives , it generally did not have information related to performance measures to assess the progress of these initiatives when evaluating and closing them .

specifically , the after - action reports for 11 of 20 initiatives did not include performance measures that showed whether the initiative had met its intended outcomes in support of the department's strategies .

officials from the asset visibility working group stated that they generally relied on the opinion of the component's subject matter experts , who are familiar with each initiative's day - to - day performance , to assess the progress of these initiatives .

while including the input of the component's subject matter experts for the initiative in the decision to close the initiative is important , without incorporating after - action reports information relating to performance measures into the information considered by the asset visibility working group , dod does not have assurance that closed initiatives have been fully assessed and whether they have resulted in achieving the goals and objectives of the strategies .

dod has fully met three of our criteria for removal from the high risk list by improving leadership commitment , capacity , and its corrective action plan , and it has partially met the criteria to monitor the implementation of the initiatives and demonstrate progress in improving asset visibility .

table 4 includes a description of the criteria and our assessment of dod's progress in addressing each of them .

dod continues to fully meet our high - risk criterion for leadership commitment our high - risk criterion for leadership commitment calls for leadership oversight and involvement .

dod has taken steps to address asset visibility challenges , and we found — as we had in our february 2015 high - risk report — that dod has fully met this criterion .

senior leaders at the department have continued to demonstrate commitment to addressing the department's asset visibility challenges , as evidenced by the issuance of dod's 2014 and 2015 strategies .

the office of the deputy assistant secretary of defense for supply chain integration provides department - wide oversight for development , coordination , approval , and implementation of the strategies and reviews the implementation of the initiatives .

also , senior leadership commitment is evident in its involvement in asset visibility improvement efforts , including groups such as the supply chain executive steering committee — a group of senior - level officials responsible for overseeing asset visibility improvement efforts — and the asset visibility working group — a group of officials that includes representatives from the components and other government agencies , as needed .

the asset visibility working group identifies opportunities for improvement and monitors the implementation of initiatives .

sustained leadership commitment will be critical moving forward , as the department continues to implement its strategies to improve asset visibility and associated asset visibility initiatives .

dod has fully met our high - risk criterion for capacity our high - risk criterion for capacity calls for agencies to demonstrate that they have the people and other resources needed to resolve risks in the high - risk area .

in our october 2014 management letter to a senior osd official and our january 2015 and february 2015 reports , we noted that resources and investments should be discussed in a comprehensive strategic plan , to include the costs to execute the plan and the sources and types of resources and investments — including skills , human capital , technology , information and other resources — required to meet established goals and objectives .

dod has demonstrated that it has the capacity — personnel and resources — to improve asset visibility .

for example , as we previously noted , the department had established the asset visibility working group that is responsible for identifying opportunities for improvement and monitoring the implementation of initiatives .

the working group includes representatives from osd and the components — joint staff , the defense logistics agency , u.s. transportation command , and each of the military services .

furthermore , dod's 2015 strategy called for the components to consider items such as manpower , materiel , and sustainment costs when documenting cost estimates for the initiatives in the strategy , as we recommended in our january 2015 and february 2015 reports .

for example , dod identified and broke down estimated costs of $10 million for implementing an initiative to track air force aircraft and other assets from fiscal years 2015 through 2018 by specifying that $1.2 million was for manpower , $7.4 million for sustainment , and $1.4 million for one - time costs associated with the consolidation of a server for the initiative .

additionally , dod broke down estimated costs of $465,000 for implementing an initiative to track marine corps assets from fiscal years 2013 through 2015 by specifying $400,000 for manpower and $65,000 for materials .

however , in december 2015 we found that the 2015 strategy included three initiatives that did not include cost estimates .

to address this issue , in december 2016 , a dod official provided an abstract from the draft update to the 2015 strategy that provides additional direction on how to explain and document cases where the funding for the initiatives is embedded within overall program funding .

the draft update notes that there may be instances where asset visibility improvements are embedded within a larger program , making it impossible or cost prohibitive to isolate the cost associated with specific asset visibility improvements .

in these cases , the document outlining the initiatives will indicate that cost information is not available and why .

however , if at some point during implementation some or all costs are identified , information about the initiative will be updated .

according to osd officials , dod plans to issue the update to the 2015 strategy , but a release date has not been determined .

dod has fully met our high - risk criterion for a corrective action plan our high - risk criterion for a corrective action plan calls for agencies to define the root causes of problems and related solutions and to include steps necessary to implement the solutions .

the fiscal year 2014 national defense authorization act ( ndaa ) required dod to submit to congress a comprehensive strategy and implementation plans for improving asset tracking and in - transit visibility .

the fiscal year 2014 ndaa , among other things , called for dod to include in its strategy and plans elements such as goals and objectives for implementing the strategy .

the fiscal year ndaa also included a provision that we assess the extent to which dod's strategy and accompanying implementation plans include the statutory elements .

in january 2014 , dod issued its strategy for improving dod asset visibility and accompanying implementation plans that outline initiatives intended to improve asset visibility .

dod updated its 2014 strategy and plans in october 2015 .

the 2014 and 2015 strategies define the root causes of problems associated with asset visibility and related solutions ( i.e. , the initiatives ) .

in our october 2014 management letter to a senior osd official and our january and february 2015 reports , we found that while the 2014 strategy and accompanying plans serve as a corrective action plan , there was not a clear link between the initiatives and the strategy's goals and objectives .

we recommended that dod clearly specify the linkage between the goals and objectives in the strategy and the initiatives intended to implement the strategy .

dod implemented our recommendation in its 2015 strategy , which includes matrixes that link each of dod's ongoing initiatives intended to implement the strategy to the strategy's overarching goals and objectives .

dod also added 8 initiatives to its 2015 strategy and linked each of them to the strategy's overarching goals and objectives .

dod has taken steps to monitor the status of initiatives , but its performance measures could not always be used to track progress our high - risk criterion on monitoring calls for agencies to institute a program to monitor and independently validate the effectiveness and sustainability of corrective measures , for example , through performance measures .

dod has taken steps to monitor the status of asset visibility initiatives , but we found that it has only partially met our high - risk criterion for monitoring .

in our february 2015 high - risk update , we referred to a 2013 report in which we had found that dod lacked a formal , central mechanism to monitor the status of improvements or fully track the resources allocated to them .

we also reported that while dod's draft 2014 strategy included overarching goals and objectives that addressed the overall results desired from implementation of the strategy , it only partially included performance measures , which are necessary to enable monitoring of progress .

since february 2015 , dod has taken some steps to improve its monitoring of its improvement efforts .

as noted in the 2015 strategy , dod has described and implemented a process that tasks the asset visibility working group to review the performance of the component's initiatives during implementation on a quarterly basis , among other things .

the working group uses status reports from the dod components that include information on resources , funding , and progress made toward implementation milestones .

dod also identified performance measures for its asset visibility initiatives .

however , as previously discussed , the measures for the 8 initiatives we reviewed were not generally clear , quantifiable ( i.e. , lacked measurable targets and baseline and trend data ) , objective , and reliable .

measures that are clear , quantifiable , objective , and reliable can help managers better monitor progress , including determining how well they are achieving their goals and identifying areas for improvement , if needed .

in december 2016 , a dod official provided an abstract from the draft update to the 2015 strategy that noted that detailed metrics data will be collected and reviewed at the level appropriate for the initiative .

high - level summary metrics information will be provided to the working group in updates to the plan outlining the initiatives .

the extent to which this planned change will affect the development of clear , quantifiable , objective , and reliable performance measures remains to be determined .

additionally , as discussed previously , while the asset visibility working group has closed 20 initiatives , it generally did not have information related to performance measures to assess the progress of these initiatives .

specifically , after - action reports from 11 of 20 initiatives — which are added to the status reports for completed initiatives — did not include performance measures that showed whether the initiative had met its intended outcomes in support of the department's strategies .

without improved performance measures and information to support that progress has been made , dod may not be able to monitor asset visibility initiatives .

dod has demonstrated some progress but cannot demonstrate that its initiatives have resulted in measurable outcomes and improvements for asset visibility our high - risk criterion for demonstrated progress calls for agencies to demonstrate progress in implementing corrective measures and resolving the high - risk area .

dod has made progress by developing and implementing its strategies for improving asset visibility .

in our october 2014 management letter to a senior osd official and our january and february 2015 reports , we noted that in order to demonstrate progress in having implemented corrective measures , dod should continue the implementation of the initiatives identified in the strategy , refining them over time as appropriate .

dod reports that it has closed or will no longer monitor the status of 20 of the 27 initiatives and continues to monitor the remaining 7 initiatives .

additionally , in october 2016 , dod officials stated that they plan to add about 10 new initiatives in the update to the 2015 strategy .

for example , the u.s. transportation command's new initiative , military service air manifesting capability , is expected to promote timely , accurate , and complete in - transit visibility and effective knowledge sharing to enhance understanding of the operational environment .

osd officials have not yet determined a date for the release of the update to the 2015 strategy .

as discussed previously , we found that dod cannot use the performance measures associated with the initiatives to demonstrate progress , because the measures are not generally clear , quantifiable ( i.e. , lack measurable targets and baseline and trend data ) , objective , and reliable .

additionally , we found that dod has not taken steps to consistently incorporate information on an initiative's performance measures in closure reports , such as after - action reports , in order to demonstrate the extent to which progress has been made toward achieving the intended outcomes of the individual initiatives and the overall goals and objectives of the strategies .

without clear , quantifiable , objective , and reliable performance measures and information to support that progress has been made , dod may not be able to demonstrate that implementation of these initiatives has resulted in measurable outcomes and progress toward achieving the goals and objectives in the strategies .

also , dod will be limited in its ability to demonstrate sustained progress in implementing corrective actions and resolving the high - risk area .

dod has taken some positive steps to address weaknesses in asset visibility .

long - standing management weaknesses related to dod's asset visibility functions hinder the department's ability to provide spare parts , food , fuel , and other critical supplies in support of u.s. military forces .

we previously reported on several actions that we believe dod should take in order to mitigate or resolve long - standing weaknesses in asset visibility and meet the criteria for removing asset visibility from the high risk list .

we believe that dod has taken the actions necessary to meet the capacity and action plan criteria by providing additional direction to the components on formulating cost estimates for the asset visibility initiatives .

additionally , dod linked the 2015 strategy's goals and objectives with the specific initiatives intended to implement the strategy .

however , dod's efforts to monitor initiatives show that the performance measures dod components currently use to assess these initiatives lack some of the key attributes of successful performance measures that we have identified .

to the extent that these measures lack the key attributes of successful performance measures , they limit dod's ability to effectively monitor the implementation of the initiatives and assess the effect of the initiatives on the overall objectives and goals of the strategies .

developing clear , quantifiable , objective , and reliable performance measures can help dod better assess department - wide progress against the strategies' goals and clarify what additional steps need to be taken to enable decision makers to exercise effective oversight .

an important step in determining what effect , if any , the asset visibility initiatives are having on the achievement of the strategies' goals and objectives will be to develop sound performance measures and incorporate information about these measures into the after - action reports when evaluating and closing initiatives .

until dod components demonstrate that implementation of the initiatives will result in measurable outcomes and progress toward achieving the goals and objectives of the strategies , dod may be limited in its ability to demonstrate progress in implementing corrective actions and resolving the high - risk area .

once these actions are taken , dod will be better positioned to demonstrate the sustainable progress needed in its approach to meeting the criteria for removing asset visibility from our high risk list .

we are making two recommendations to help improve dod's asset visibility .

we recommend that the secretary of defense direct the assistant secretary of defense for logistics and materiel readiness , in collaboration with the director , defense logistics agency ; the secretaries of the army , navy , and air force ; the commandant of the marine corps ; the commander of the united states transportation command ; and the chairman of the joint chiefs of staff , to: use the key attributes of successful performance measures — including clarity , measurable target , objectivity , reliability , baseline and trend data , and linkage — in refining the performance measures in subsequent updates to the strategy to improve dod's efforts to monitor asset visibility initiatives ; and incorporate into after - action reports information relating to performance measures for the asset visibility initiatives when evaluating and closing these initiatives to ensure that implemented initiatives will achieve the goals and objectives in the strategies .

in its written comments on a draft of this report , dod partially concurred with our two recommendations .

dod's comments are summarized below and reprinted in appendix iv .

dod partially concurred with our first recommendation that it use the key attributes of successful performance measures — including clarity , measurable target , objectivity , reliability , baseline and trend data , and linkage — in refining the performance measures in subsequent updates to the strategy to improve dod's efforts to monitor asset visibility initiatives .

dod stated that it recognizes the need for performance measures to ensure the success of an asset visibility improvement effort but noted that the level of complexity and granularity of the metrics we suggest may not be suitable for all initiatives .

dod also stated that the purpose of the strategy is to create a framework whereby the components can work collaboratively to coordinate and integrate department - wide efforts to improve asset visibility , not to provide complete direction on how to define , implement , and oversee these initiatives .

additionally , dod stated that the next edition of the strategy will encourage the adoption of our six key attributes for asset visibility initiatives to the extent appropriate , but will not mandate their use .

as discussed in our report , use of the key attributes in measuring the performance of asset visibility initiatives would help dod to better assess department - wide progress against the goals in its strategy and clarify what additional steps need to be taken to enable decision makers to exercise effective oversight .

encouraging adoption of the key attributes , as dod plans to do , is a positive step , but we continue to believe that dod needs to use these key attributes to refine its performance measures to monitor the initiatives in the future .

dod partially concurred with our second recommendation that it incorporate into after - action reports information relating to performance measures for the asset visibility initiatives when evaluating and closing these initiatives to ensure that implemented initiatives will achieve the goals and objectives in the strategies .

dod stated that it is important to capture and review performance data prior to a component closing an asset visibility initiative , but that the strategy after - action report is not intended to be used to evaluate the success of an asset visibility initiative or to determine if an initiative has met its intended objectives .

according to dod , documentation and information to support the evaluation of initiatives is defined by and executed in accordance with component - level policy and procedures .

dod agreed to update its strategy to clarify the purpose and use of the after - action reports and to ensure that the strategy specifies roles and responsibilities for evaluating and closing initiatives .

dod's response , however , did not state whether and how these updates to the strategy would result in more consistent incorporation of information relating to performance measures when closing initiatives in the future .

as we noted previously in this report , according to the 2015 strategy , the after - action report for closed initiatives should include information on the objectives met , problems or gaps resolved , and measures of success obtained .

we believe our recommendation is consistent with this guidance .

without incorporating this information , dod does not have assurance that closed initiatives have been fully assessed and have resulted in achieving the goals and objectives of the strategies .

therefore , we continue to believe that full implementation of our recommendation is needed .

we are sending copies of this report to appropriate congressional committees ; the secretary of defense ; the secretaries of the army , navy , and air force , and the commandant of the marine corps ; the director of defense logistics agency ; the chairman of the joint chiefs of staff ; the commander of the united states transportation command ; and other interested parties .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-5257 or merrittz@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made contributions to this report are listed in appendix v .

to determine the extent to which dod identified performance measures that allow it to monitor the progress of selected asset visibility initiatives identified in dod's 2014 and 2015 strategy for improving dod asset visibility ( strategies ) , we reviewed documents such as the 2014 strategy and its subsequent update in october 2015 ( 2015 strategy ) ; minutes from the asset visibility working group meetings ; and documents showing the status of the implementation , including charts that track the development and closure of the asset visibility initiatives .

thirty initiatives have been included in the 2014 and 2015 strategies , but 3 of these were halted , for a variety of reasons .

from the remaining 27 initiatives , we selected a non - generalizable sample of 8 initiatives .

we selected at least one from each of the components to review and assess , including analyzing the performance measures associated with each initiative .

in our selection of 8 initiatives to review , we also considered the stage of implementation of the initiative , to ensure that our review encompassed initiatives at different stages , from some that were just beginning to some that had already been completed .

specifically , we made selections based on the status of the initiatives as of december 2015 to include the earliest completion dates by component .

in order to cover a range of initiatives — from some just beginning to some already completed — we selected for review 3 initiatives from the 2014 strategy that had been closed , 2 ongoing initiatives that had been included in both strategies , and 3 new initiatives that were included for the first time in the 2015 strategy .

the results from this sample cannot be generalized to the other 19 initiatives .

we did not assess the initiatives to determine if they ( 1 ) met milestones , ( 2 ) lacked resources , or ( 3 ) had performance issues .

instead we assessed the initiatives to determine what progress dod had made toward meeting the criteria for removing an area from our high risk list .

we surveyed program managers and other cognizant officials ( hereafter referred to as component officials ) responsible for the respective asset visibility initiatives we selected .

we included questions in our survey related to the development and closure of the initiatives and took several steps to ensure the validity and reliability of the survey instrument .

we also reviewed the strategies to identify performance measures necessary to monitor the progress of the 8 initiatives we had selected .

two analysts independently assessed whether ( 1 ) dod had followed the guidance set forth in the strategies and ( 2 ) the measures for the initiatives included selected key attributes of successful performance measures ( for example , are the measures clear , quantifiable — i.e. , have measurable targets and baseline and trend data — objective , and reliable ) ; any initial disagreements in assessments were resolved through discussion .

we assessed these measures against 6 of 10 selected key attributes for successful performance measures — clarity , measurable target , objectivity , reliability , baseline and trend data , and linkage — identified in our prior work that we identified as relevant to the sample of initiatives we were examining .

the remaining 4 attributes — government - wide priorities , core program activities , limited overlap , and balance — are used to assess agency - wide performance and are not applicable to our analysis , because we did not assess agency - wide initiatives .

because we had selected a subset of the component - level initiatives to review , these attributes did not apply .

if all of the performance measures for an initiative met the definition of the relevant key attribute , we rated the initiative as having “fully included” the attribute .

on the other hand , if none of the measures met the definition of the relevant key attribute , we rated the initiative as having “not included” the attribute .

if some , but not all , of the measure met the definition of the relevant key attribute , then we rated the initiative as having “partially included” the attribute .

we also selected sites to observe demonstrations of initiatives that were intended to show how they have achieved progress in improving asset visibility .

we selected these demonstrations based on the location of the initiative , the responsible component , and the scope of the initiative .

additionally , we reviewed the after - action reports for all of the initiatives that had been closed — 20 of 27 initiatives , including 5 of the 8 initiatives we reviewed in detail — by the asset visibility working group , as of october 31 , 2016 .

we performed a content analysis in which we reviewed each of these after - action reports to determine whether it was completed for the initiative , documented whether measures were obtained , and identified challenges and lessons learned .

one analyst conducted this analysis , coding the information and entering it into a spreadsheet ; a second analyst checked the first analyst's analysis for accuracy .

any initial disagreements in the coding were discussed and reconciled by the analysts .

the analysts then tallied the responses to determine the extent to which the information was identified in the after - action reports .

we also interviewed component officials and officials at the office of the deputy assistant secretary of defense for supply chain integration ( hereafter referred to as osd ) to clarify survey responses and to discuss plans to develop the initiatives , including any efforts to monitor progress and demonstrate results .

to determine whether dod had addressed the five criteria — leadership commitment , capacity , corrective action plan , monitoring , and demonstrated progress — that would have to be met for us to remove asset visibility from our high risk list , we reviewed documents such as dod's 2014 and 2015 strategies and charts that track the implementation and closure of asset visibility initiatives .

we included questions in our survey to collect additional information from officials on their efforts to address the high - risk criteria .

for example , we asked how the component monitors the implementation of the initiative and whether there has been any demonstrated progress in addressing the opportunity , deficiency , or gap in asset visibility capability that the initiative was designed to address .

one analyst evaluated dod's actions to improve asset visibility against each of our five criteria for removing an area from the high risk list .

a different analyst checked the first analyst's analysis for accuracy .

any initial disagreements were discussed and reconciled by the analysts .

we assessed dod's effort to meet each of the high - risk criteria as “not met” ( i.e. , none of the aspects of the criterion were addressed ) , “partially met” ( i.e. , some , but not all , aspects of the criterion were addressed ) , or “fully met” ( i.e. , all parts of the criterion were fully addressed ) .

we shared with dod officials our preliminary assessment of asset visibility relative to each of the criteria .

to help ensure that our evaluation of improvements made relative to the high - risk criteria were consistent with our prior evaluations of supply chain management and other issue areas , we reviewed our prior high risk reports to gain insight into what actions agencies had taken to address the issues identified in these past reports .

additionally , we interviewed component officials and osd officials to clarify their survey responses and to discuss plans to continue to make progress in improving asset visibility .

we met with officials from the following dod components during our review: office of the secretary of defense department of the army united states marine corps department of the air force we surveyed component officials responsible for the asset visibility initiatives we reviewed .

we included questions in our survey related to our high - risk criteria .

as part of the survey development , we conducted an expert review and pre - tested the draft survey .

we submitted the questionnaire for review by an independent gao survey specialist and an asset visibility subject matter expert from osd .

the expert review phase was intended to ensure that content necessary to understand the questions was included and that technical information included in the survey was correct .

to minimize errors that might occur from respondents interpreting our questions differently than we intended , we pre - tested our questionnaire with component officials and other cognizant officials for 4 of the initiatives .

during the pre - tests , conducted by telephone , we asked the dod officials to read the instructions and each question aloud and to tell us how they interpreted the question .

we then discussed the instructions and questions with them to identify any problems and potential solutions by determining whether ( 1 ) the instructions and questions were clear and unambiguous , ( 2 ) the terms we used were accurate , ( 3 ) the questionnaire was unbiased , and ( 4 ) the questionnaire did not place an undue burden on the officials completing it .

we noted any potential problems and modified the questionnaire based on feedback from the expert reviewers and the pre - tests , as appropriate .

we sent an email to each selected program office beginning on june 16 , 2016 , notifying them of the topics of our survey and when we expected to send the survey .

we then sent the self - administered questionnaire and a cover email to the asset visibility program officials on june 20 , 2016 , and asked them to fill in the questionnaire and email it back to us by july 6 , 2016 .

we received 8 completed questionnaires , for an overall response rate of 100 percent .

we also collected data — such as the number of rfid tags and number of inventory amounts for clothing and textiles — from a sample of initiatives .

the practical difficulties of conducting any survey may introduce errors , commonly referred to as non - sampling errors .

for example , differences in how a particular question is interpreted , the sources of information available to respondents , how the responses are processed and analyzed , or the types of people who do not respond can influence the accuracy of the survey results .

we took steps , as described above , in the development of the survey , the data collection , and the data analysis to minimize these non - sampling errors and help ensure the accuracy of the answers that we obtained .

data were electronically extracted from the questionnaires into a comma - delimited file that was then imported into a statistical program for analysis .

we examined the survey results and performed computer analyses to identify inconsistencies and other indications of error , and we addressed such issues as necessary .

our survey specialist conducted quantitative data analyses using statistical software , and our staff conducted a review of open - ended responses with subject matter expertise .

a data analyst conducted an independent check of the statistical computer programs for accuracy .

we conducted this performance audit from february 2016 to march 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

this appendix provides an overview of the non - generalizable sample of initiatives that we reviewed .

these initiatives are intended to improve asset visibility as part of the department of defense's ( dod ) 2014 strategy for improving dod asset visibility ( 2014 strategy ) and its subsequent update in october 2015 ( 2015 strategy ) .

the process by which we selected these initiatives for this review is described in appendix i .

the initiatives are shown in table 5 .

in 1990 , we began a program to report on government operations that we identified as “high risk,” and we added the department of defense's ( dod ) supply chain management area to our high risk list .

our high - risk program has served to identify and help resolve serious weaknesses in areas that involve substantial resources and provide critical services to the public .

our experience with the high - risk series over the past two decades has shown that the key elements needed to make progress in high - risk areas are congressional action , high - level administrative initiatives , and agencies' efforts grounded in the five criteria we established for removing an area from the high - risk list .

these five criteria form a road map for efforts to improve and ultimately address high - risk issues .

addressing some of the criteria leads to progress , while satisfying all of the criteria is central to removing an area from the list .

these criteria call for agencies to show the following: 1 .

leadership commitment — a strong commitment and top leadership support .

2 .

capacity — the capacity ( i.e. , the people and other resources ) to resolve the risk ( s ) .

3 .

corrective action plan — a plan that defines the root causes and solutions and provides for substantially completing corrective measures , including steps necessary to implement the solutions we recommended .

4 .

monitoring — a program instituted to monitor and independently validate the effectiveness and sustainability of corrective measures .

5 .

demonstrated progress — the ability to demonstrate progress in implementing corrective measures and resolving the high - risk area .

we have reported on various aspects of dod's supply chain , including asset visibility , and noted that dod has taken several actions to improve asset visibility .

we also noted a number of recommendations , actions , and outcomes needed to improve asset visibility , as shown in table 6 .

specifically , in an october 2014 management letter to a senior office of the secretary of defense ( osd ) official , we reported on 7 actions and outcomes across the 5 criteria that we believed dod should take to address long - standing weaknesses in asset visibility .

most recently , in our january 2015 report and february 2015 high risk update , we reported on progress that dod has made in addressing weaknesses in its asset visibility , including developing its 2014 strategy for improving dod asset visibility , and we made a number of recommendations .

in addition to the contact named above , carleen c. bennett , assistant director ; mary jo lacasse ; joanne landesman ; amie lesser ; felicia lopez ; mike silver ; john e. trubey ; angela watson ; and john yee made key contributions to this report .

high - risk series: progress on many high - risk areas , while substantial efforts needed on others .

gao - 17-317 .

washington , d.c.: february 15 , 2017 .

high - risk series: key actions to make progress addressing high - risk issues .

gao - 16-480r .

washington , d.c.: april 25 , 2016 .

defense logistics: dod has addressed most reporting requirements and continues to refine its asset visibility strategy .

gao - 16-88 .

washington , d.c.: december 22 , 2015 .

high - risk series: an update .

gao - 15-290 .

washington , d.c.: february 11 , 2015 .

defense logistics: dod has a strategy and has taken steps to improve its asset visibility , but further actions are needed .

gao - 15-148 .

washington , d.c.: january , 27 , 2015 .

defense logistics: a completed comprehensive strategy is needed to guide dod's in - transit visibility efforts .

gao - 13-201 .

washington , d.c.: february 28 , 2013 .

high - risk series: an update: gao - 13-283 .

washington , d.c.: february 14 , 2013 .

defense logistics: improvements needed to enhance dod's management approach and implementation of item unique identification technology .

gao - 12-482 .

washington , d.c.: may 3 , 2012 .

defense logistics: dod needs to take additional actions to address challenges in supply chain management .

gao - 11-569 .

washington , d.c.: july 28 , 2011 .

high - risk series: an update .

gao - 11-278 .

washington , d.c.: february 16 , 2011 .

dod's high - risk areas: observations on dod's progress and challenges in strategic planning for supply chain management .

gao - 10-929t .

washington , d.c.: july 27 , 2010 .

