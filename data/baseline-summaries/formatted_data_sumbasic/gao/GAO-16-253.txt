since the department of homeland security ( dhs ) was created in 2002 and merged 22 agencies into one department with eight components , its human resources environment has included fragmented systems , duplicative and paper - based processes , and little uniformity of data management practices .

according to dhs , these issues are compromising the department's ability to effectively and efficiently carry out its mission to , among other things , enhance security and respond to disasters .

for example , according to dhs , while it is imperative that it respond quickly to emergencies , catastrophic events , and threats , and deploy appropriately trained , certified , and skilled personnel during these events , the department's inefficient and disjointed hiring process has limited the department's hiring abilities .

to address these issues , dhs initiated the human resources information technology ( hrit ) investment in 2003 to consolidate , integrate , and modernize the department's it infrastructure that supports human resources .

one of the types of human resources programs to be addressed through the hrit umbrella was management of department - wide employee performance and learning — referred to as the performance and learning management system ( palms ) .

this program is designed to implement an enterprise - wide employee performance management and appraisal solution that is to automate the department's primarily paper - based performance management processes .

in addition , palms is to provide a system that will consolidate nine existing learning management systems into one system and enable comprehensive training reporting and analysis across the department .

in light of hrit's expected role in transforming the department's human resources processes and system environment , you asked us to review dhs's efforts to implement the investment .

our objectives were to ( 1 ) evaluate the progress dhs has made in implementing the hrit investment and how effectively dhs managed the investment since completing the human capital segment architecture in august 2011 , ( 2 ) describe whether dhs has justified its investment in the palms program , ( 3 ) determine whether palms is being implemented enterprise - wide , and ( 4 ) evaluate the extent to which palms is implementing selected it acquisition best practices .

to address the first part of our first objective — to evaluate the progress dhs had made in implementing the hrit investment — we compared hrit's goals , scope , and implementation time frames to the investment's actual accomplishments .

we also compared dhs's planned schedule for implementing the improvement opportunities and projects , as of august 2011 , against dhs's current planned schedule for implementing them .

for the second part of our first objective — to evaluate how effectively dhs has managed the investment — we analyzed documentation , such as the investment's schedule , program management briefings , dhs's human capital segment architecture blueprint , cost estimates , and budget documentation , and compared them against relevant cost and schedule best practices identified by gao , the software engineering institute at carnegie mellon university , and the project management institute , inc. to determine the amount spent to date on hrit , we asked officials from dhs headquarters and the components to provide expenditure information on hrit since the investment began in 2003 ; officials were unable to provide complete information .

as such , we were unable to identify the total amount spent on the investment and discuss this limitation further in the report .

in addressing our second objective , we analyzed documentation , such as the program's business case and the documented analysis of alternatives that was conducted to identify recommended approaches for pursuing a commercial off - the - shelf learning management system .

we used this information to determine the various alternative solutions that dhs assessed for delivering enterprise - wide performance and learning management capabilities and justifying its investment in palms .

additionally , we reviewed program management briefings provided to the hrit executive steering committee that outlined , for example , the proposed solution and rationale for such a solution .

to address our third objective , we analyzed the program's acquisition plan and original schedule for implementing the system department - wide , and compared it against program status documentation and the program's current implementation schedule , as of november 2015 .

lastly , for our fourth objective , we analyzed the program's it acquisition documentation ( eg , acquisition plan and risk logs ) and compared it to relevant project planning , project monitoring , and risk management best practices as identified by cmmi - acq , the pmbok® guide , and gao .

additionally , we interviewed officials from hrit , palms , the office of the chief information officer ( ocio ) , the office of the chief human capital officer ( ochco ) , and dhs's eight components to obtain additional information on the program's it acquisition processes in these areas .

we conducted this performance audit from march 2015 to february 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

see appendix i for a more detailed discussion of our objectives , scope , and methodology .

dhs's mission is to lead the unified national effort to secure america by preventing and deterring terrorist attacks and protecting against and responding to threats and hazards to the nation , among other things .

created in 2002 , dhs merged 22 agencies and offices that specialized in one or more aspects of homeland security .

the intent behind the merger that created dhs was to improve coordination , communication , and information sharing among these multiple federal agencies .

each of these agencies is responsible for specific homeland security missions and for coordinating related efforts with its sibling components , as well as external entities .

figure 1 shows a simplified and partial dhs organizational structure .

within the department's management directorate , headed by the under secretary for management ( usm ) , are the ochco and ocio .

the ochco is responsible for department - wide human capital policy and development , planning , and implementation of human capital initiatives .

the ocio is responsible for departmental it policies , processes , and standards , and ensuring that it acquisitions comply with dhs it management processes , among other things .

dhs acquires it and other capabilities that are intended to improve its ability to execute its mission .

dhs classifies these acquisition programs into three levels that determine the extent and scope of required project and program management , the level of reporting requirements , and the acquisition decision authority .

specifically , dhs policy defines acquisition programs as follows: level 1 major acquisition programs are expected to cost $1 billion or more over their life cycles .

level 2 major acquisition programs are expected to cost at least $300 million over their life cycles .

special interest programs , without regard to the established dollar thresholds , are designated as level 1 or level 2 programs .

for example , a program may be raised to a higher acquisition level if its importance to dhs's strategic and performance plans is disproportionate to its size or it has high executive visibility .

level 3 programs are those with life - cycle cost estimates less than $300 million and are considered non - major .

as outlined in dhs's acquisition management directive 102-01 , dhs's chief acquisition officer — the usm — is responsible for the management and oversight of the department's acquisition policies and procedures .

the deputy secretary , usm , and component acquisition executives are the acquisition decision authorities for dhs's acquisition programs .

for level 1 programs , the acquisition decision authority may be either the deputy secretary or usm ; for level 2 programs , the acquisition decision authority may be either the usm or a component acquisition executive ; and for level 3 programs , a component acquisition executive is the acquisition decision authority .

as of march 2015 , the department had 72 major acquisition programs and 42 non - major acquisition programs .

in 2003 , we designated the transformation of dhs as high risk because it had to transform 22 agencies — several with major management challenges — into one department .

we emphasized that failure to effectively address dhs's management and mission risks could have serious consequences for u.s. national and economic security .

in 2007 and 2009 , in reporting on dhs's progress in addressing the high - risk area since its creation , we found that dhs had made more progress in implementing its range of missions than its management functions — such as in the areas of it and human capital — and that continued work was needed to address an array of programmatic and management challenges .

since then , dhs had continued to make important progress in strengthening and integrating its management functions ; however , significant work remained for dhs to improve in these areas .

for example , as of september 2015 , dhs had taken steps to identify current and future human capital needs , including the size of the workforce , its deployment across the department and components , and the knowledge , skills , abilities , and diversity needed ; however , dhs had yet to fully implement its workforce planning model that was intended to allow the department to plan for its current and future organizational and workforce needs .

in february 2015 , we reported that while dhs established a human capital strategic plan in 2011 and made progress in implementing it , the department had considerable work ahead to improve employee morale , which has decreased each year since 2011 .

for example , the office of personnel management's 2014 federal employee viewpoint survey data showed that dhs's scores continued to decrease in all four dimensions of the survey's index for human capital accountability and assessment .

while the department had made progress in implementing its it strategic human capital plan for fiscal years 2010 through 2012 , in january 2015 dhs shifted its it paradigm from acquiring assets to acquiring services , and acting as a service broker ( eg , an intermediary between the purchaser of a service and the seller of that service ) .

according to dhs officials in may 2015 , this paradigm change will require a major transition in the skill sets of dhs's it workforce , as well as the hiring , training , and managing of those new skill sets ; as such , this effort will need to be closely managed in order to succeed .

moreover , as of september 2014 , dhs faced challenges in integrating employee training management across all the components , including centralizing training and consolidating training data into one system .

according to dhs officials , the department planned to address these limitations through the development and deployment of hrit's palms program .

since dhs was created , the department's human resources environment has included fragmented systems , duplicative and paper - based processes , and little uniformity of data management practices .

according to dhs , these limitations in its human resources environment are compromising the department's ability to effectively and efficiently carry out its mission .

for example , while it is imperative that dhs responds quickly to emergencies , catastrophic events , and threats , and deploys appropriately trained , certified , and skilled personnel during these events , according to dhs , the department's hiring process involves numerous systems and multiple hand - offs which result in extra work and prolonged hiring .

this inefficient process is one factor that could have contributed to the skill and workforce gaps that we have previously identified .

for example , in april 2015 , we reported that 21 of the 22 major acquisition programs we reviewed faced shortfalls in their program office workforce in fiscal year 2014 .

according to dhs , the department does not have information on all of its employees , which reduces its abilities to strategically manage its workforce and best deploy people in support of homeland security missions .

according to dhs , reporting and analyzing enterprise human capital data are currently time - consuming , labor - intensive , and challenging because the department's data management largely consists of disconnected , standalone systems , with multiple data sources for the same content .

as one example , we reported in 2014 that dhs could not provide complete information on how much it had spent on administratively uncontrollable overtime to its personnel from fiscal years 2008 through 2014 .

specifically , certain components could not provide information such as duty location or payments for certain years .

to address these issues , in 2003 , dhs initiated the hrit investment , which is intended to consolidate , integrate , and modernize the department's and its components' human resources it infrastructure .

these components include u.s. customs and border protection ( cbp ) , the federal emergency management agency ( fema ) , the federal law enforcement training center ( fletc ) , u.s. immigration and customs enforcement ( ice ) , the transportation security administration ( tsa ) , u.s .

citizenship and immigration services ( uscis ) , the u.s. coast guard ( uscg ) , and the u.s. secret service .

hrit is managed by dhs's human capital business systems unit , which is within ochco and has overall responsibility for hrit .

additionally , ocio plays a key supporting role in the implementation of hrit by reviewing headquarters' and components' human resources investments , identifying redundancies and efficiencies , and delivering and maintaining enterprise it systems .

from 2003 to 2010 , dhs made limited progress on the hrit investment , as reported by dhs's inspector general .

this was due to , among other things , limited coordination with and commitment from dhs's components .

to address this problem , in 2010 the dhs deputy secretary issued a memorandum emphasizing that dhs's wide variety of human resources processes and it systems inhibited the ability to unify dhs and negatively impacted operating costs .

the memorandum stated that , without an enterprise operating model , support for dhs's core mission was at risk and valuable workforce management information remained difficult to acquire across the department .

accordingly , the deputy secretary stated that dhs could no longer sustain a component - centric approach when acquiring or enhancing human resources systems , and prohibited component spending on enhancements to existing human resources systems or acquisitions of new solutions , unless those expenditures were approved by ochco or ocio .

the memorandum also directed these offices to develop a department - wide human resources architecture .

in 2011 , in response to the deputy secretary's direction , dhs completed an effort called the human capital segment architecture , which , according to dhs , defined the department's current ( or as - is ) state of human capital management processes , technology , data , and relevant personnel .

further , from this current state , the department developed a comprehensive future state ( or target state ) and a document referred to as the human capital segment architecture blueprint that redefined the hrit investment's scope and implementation time frames .

as part of this effort , dhs conducted a system inventory and determined that it had 422 human resources systems and applications , many of which were single - use solutions developed to respond to a small need or links to enable disparate systems to work together .

dhs reported that these numerous , antiquated , and fragmented systems inhibited its ability to perform basic workforce management functions necessary to support mission critical programs .

to address this issue , the blueprint articulated that hrit would be comprised of 15 strategic improvement opportunity areas ( eg , enabling seamless , efficient , and transparent end - to - end hiring ) and outlined 77 associated projects ( eg , deploying a department - wide hiring system , establishing an integrated data repository and reporting mechanism , and developing a centralized learning center for all personnel action processing information ) to implement these 15 opportunities .

each opportunity area includes from 1 to 10 associated projects .

table 1 summarizes the scope of the 15 strategic improvement opportunities — listed in the order of dhs's assigned priority — and identifies their original planned completion dates , as of august 2011 when the blueprint was issued .

hrit's only ongoing program is called palms and is intended to fully address the performance management strategic improvement opportunity area and its three associated projects .

palms is attempting to implement a commercial off - the - shelf software product that is to be provided as a service in order to enable , among other things , comprehensive enterprise - wide tracking , reporting , and analysis of employee learning and performance for dhs headquarters and its eight components .

specifically , palms is expected to deliver the following capabilities: learning management .

the learning management capabilities are intended to manage the life cycle of learning activities for all dhs employees and contractors .

palms is intended to , among other things , act as a gateway for accessing training at dhs and record training information when a user has completed a course .

additionally , it is expected to replace nine disparate learning management systems with one unified system .

performance management .

the performance management capabilities are intended to move dhs's existing primarily paper - based performance management processes into an electronic environment and capture performance - related information throughout the performance cycle ( eg , recording performance expectations discussed at the beginning of the rating period and performance ratings at the end of it ) .

each component is responsible for its own palms implementation project , and is expected to issue a task order using a blanket purchase agreement that was established in may 2013 with an estimated value of $95 million .

before implementing palms , each component is completing a fit - gap assessment to , among other things , identify any requirements and critical processes that cannot be met by the preconfigured , commercial off - the - shelf system .

if such component - specific requirements are identified , the component must then decide whether to have the vendor customize the system .

the headquarters palms program management office ( pmo ) is responsible for overseeing the implementation projects across the department .

additionally , ocio is the component acquisition executive responsible for overseeing palms .

in addition to implementing projects intended to address the strategic improvement opportunities in the blueprint , the hrit investment also carried out the following two projects that were not included in the blueprint: balanced workforce assessment tool: this project provided an enterprise - wide tool to automate the formerly paper - based balanced workforce strategy process to determine the appropriate mix of federal employees and contractor employees required to fulfill a specific work function in the government .

dhs deployed this tool beginning in september 2013 .

workers compensation – medical case management services: this project provided an enterprise - wide contract to enable nurses to execute case management processes and facilitate the case management activities to be performed by dhs human resources staff .

as part of this , the project provided access to a web application where dhs workers' compensation coordinators could work on cases with nurses .

as of march 2015 , the tool had been implemented at six components .

entities such as the project management institute , the software engineering institute at carnegie mellon university , and gao have developed and identified best practices to help guide organizations to effectively plan and manage their acquisitions of major it systems .

our prior reviews have shown that proper implementation of such practices can significantly increase the likelihood of delivering promised system capabilities on time and within budget .

these practices include , but are not limited to: project planning: establishes project objectives and outlines the course of action required to attain those objectives .

it also provides a means to track , review , and report progress and performance of the project by defining project activities and developing cost and schedule estimates , among other things .

project monitoring and control: provides an understanding of the project's progress , so that appropriate corrective actions can be taken if performance deviates from plans .

effective practices in this area include , among other things , determining progress against the program plan and conducting program management reviews .

risk management: establishes a process for anticipating problems and taking appropriate steps to mitigate risks and minimize their impact on program commitments .

it involves identifying and documenting risks , categorizing them based on their estimated impact , prioritizing them , developing risk mitigation strategies , and tracking progress in executing the strategies .

dhs has made very little progress in delivering planned hrit capabilities , such as end - to - end hiring and payroll action processing .

while the vast majority of hrit capabilities ( called strategic improvement opportunities ) were to be delivered by june 2015 , only 1 has been fully implemented , and the completion dates for the other 14 are currently unknown .

these delays are largely due to unplanned resource changes and the lack of involvement from the executive oversight committee .

in addition , the department did not effectively manage the investment .

for example , dhs did not update or maintain the hrit schedule , have a life - cycle cost estimate , or track all associated costs .

moreover , the strategic planning document — referred to as the human capital segment architecture blueprint — has not been updated in approximately 4.5 years and , as a result , the department does not know whether it is reflective of current priorities and goals .

as a result of dhs's ineffective management and limited progress in implementing this investment , the department is unaware of when critical weaknesses in the department's human capital environment will be addressed , which is , among other things , impacting dhs's ability to reduce duplication and carry out its mission .

dhs has made very limited progress in addressing the 15 strategic improvement opportunities and the 77 associated projects included in hrit .

according to the human capital segment architecture blueprint , dhs planned to implement 14 of the 15 strategic improvement opportunities and 68 of the 77 associated projects by june 2015 ; and the remaining improvement opportunity and 9 associated projects by december 2016 .

however , as of november 2015 , dhs had fully implemented only 1 of the strategic improvement opportunities , which included 2 associated projects .

this improvement opportunity established an enterprise - wide governance process for evaluating hrit projects and proposals prior to funding them .

this process is referred to as the investment intake process and is intended to help encourage the use of enterprise - level investments , rather than component - specific investments , by preventing components from investing in duplicative systems when an existing dhs capability can meet a particular business need .

table 2 summarizes the implementation status and planned completion dates of the strategic improvement opportunities — listed in the order of dhs's assigned priority — as of november 2015 .

dhs has partially implemented five of the other strategic improvement opportunities , but it is unknown when they will be fully addressed .

for example , dhs's palms program is intended to fully address the blueprint's strategic improvement opportunity for performance management ; however , while progress to implement palms has been made , many actions remain before it can be fully implemented and it is unknown when those actions will be taken ( discussed in more detail later ) .

further , hrit officials stated that dhs has not yet started to work on the remaining nine improvement opportunities , and the officials did not know when they would be addressed .

additionally , dhs developed an hrit strategic plan for fiscal years 2012 through 2016 that outlined the investment's key goals and objectives , including reducing duplication and improving efficiencies in the department's human resources processes and systems .

the strategic plan identified , among other things , two performance metrics and associated targets for delivering human resources it services across dhs .

these performance metrics were focused on reductions in the number of component - specific human resources it services provided and increases in the number of department - wide hrit services provided by the end of fiscal year 2016 .

however , dhs has also made limited progress in achieving these two performance targets .

figure 2 provides a summary of hrit's progress towards achieving its service delivery performance targets .

dhs's goal is to reduce its component - specific hrit services by 46 percent — from 81 percent to 35 percent — however , it had reduced these services by 8 percent as of november 2015 , according to ochco officials .

additionally , while dhs is aiming to increase its dhs - wide hrit services by 38 percent — from 2 percent to 40 percent — as of november 2015 , ochco officials stated that the department had increased these services by 8 percent .

key causes for dhs's lack of progress in implementing hrit and its associated strategic improvement opportunities include unplanned resource changes and the lack of involvement of the hrit executive steering committee .

these causes are discussed in detail below: unplanned resource changes .

dhs elected to dedicate the vast majority of hrit's resources to implementing palms and addressing its problems , rather than initiating additional hrit strategic improvement opportunities .

specifically , palms — which began in july 2012 — experienced programmatic and technical challenges that led to years - long schedule delays .

for example , while the palms system for headquarters was originally planned to be delivered by a vendor in december 2013 , as of november 2015 , the expected delivery date was delayed until the end of february 2016 — an over 2-year delay .

hrit officials explained the decision to focus primarily on palms was due , in part , to the investment's declining funding stream .

however , in doing so , attention was concentrated on the immediate issues affecting palms and diverted from the longer - term hrit mission .

lack of involvement of the hrit executive steering committee .

the hrit executive steering committee — which is chaired by the department's under secretary for management and co - chaired by the chief information officer and chief human capital officer — is intended to be the core oversight and advisory body for all dhs - wide matters related to human capital it investments , expenditures , projects , and initiatives .

in addition , according to the committee's charter , the committee is to approve and provide guidance on the department's mission , vision , and strategies for the hrit program .

however , the executive steering committee only met once from september 2013 through june 2015 — in july 2014 — and was minimally involved with hrit for that almost 2 year period .

it is important to note that dhs replaced its chief information officer ( the executive steering committee's co - chair ) in december 2013 — during this gap in oversight .

also during this time period hrit's only ongoing program — palms — was experiencing significant problems , including schedule slippages and frequent turnover in its program manager position ( i.e. , palms had five different program managers during the time that the hrit executive steering committee was minimally involved ) .

as a result of the executive steering committee not meeting , key governance activities were not completed on hrit .

for example , the committee did not approve hrit's notional operational plan for fiscal years 2014 through 2019 .

ochco and ocio officials attributed the lack of hrit executive steering committee meetings and committee involvement in hrit to the investment's focus being only on the palms program to address its issues , as discussed earlier .

however , by not regularly meeting and providing oversight during a time when a new co - chair for the executive steering committee assumed responsibility and palms was experiencing such problems , the committee's guidance to the troubled program was limited .

more recently , the hrit executive steering committee met in june and october 2015 , and ocio and ochco officials stated that the committee planned to meet quarterly going forward .

however , while the committee's charter specified that it meet on at least a monthly basis for the first year , the charter does not specify the frequency of meetings following that year .

furthermore , the committee's charter has not been updated to reflect the increased frequency of these meetings .

as a result of the limited progress in implementing hrit , dhs is unaware of when critical weaknesses in the department's human capital environment will be addressed , which is , among other things , impacting dhs's ability to carry out its mission .

for example , the end - to - end hiring strategic improvement opportunity ( which has an unknown implementation date ) was intended to streamline numerous systems and multiple hand - offs in order to more efficiently and effectively hire appropriately skilled personnel , thus enabling a quicker response to emergencies , catastrophic events , and threats .

as another example , the data management and sharing strategic improvement opportunity ( which also has an unknown implementation date ) was intended to enable the department to have visibility of all its employees , to improve its ability to strategically manage its workforce , and best deploy people in support of dhs missions .

therefore , until hrit's executive steering committee effectively carries out its oversight responsibility , dhs will be limited in its ability to improve hrit investment results and accountability .

according to the gao schedule assessment guide , a key activity in effectively managing a program and ensuring progress is establishing and maintaining a schedule estimate .

specifically , a well maintained schedule enables programs to gauge progress , identify and resolve potential problems , and forecast dates for program activities and completion of the program .

in august 2011 , dhs established initiation and completion dates for each of the 15 strategic improvement opportunities within the human capital segment architecture blueprint .

additionally , hrit developed a slightly more detailed schedule for fiscal years 2014 through 2021 that updated planned completion dates for aspects of some strategic improvement opportunities , but not all .

however , dhs did not update and maintain either schedule after they were developed .

specifically , neither schedule was updated to reflect that dhs did not implement 13 of the 15 improvement opportunities by their planned completion dates — several of which should have been implemented over 3 years ago .

hrit officials attributed the lack of schedule updates to the investment's focus shifting to the palms program when it started experiencing significant schedule delays .

without developing and maintaining a current schedule showing when dhs plans to implement the strategic improvement opportunities , dhs and congress will be limited in their ability to oversee and ensure dhs's progress in implementing hrit .

omb requires that agencies prepare total estimated life - cycle costs for information technology investments .

program management best practices also stress that key activities in planning and managing a program include establishing a life - cycle cost estimate and tracking costs expended .

a life - cycle cost estimate supports budgetary decisions and key decision points , and should include all costs for planning , procurement , and operations and maintenance of a program .

ochco officials stated that a draft life - cycle cost estimate for hrit was developed , but that it was not completed or finalized because detailed projects plans for the associated projects had not been developed or approved .

according to the hrit blueprint , ochco roughly estimated that implementing all of the projects could cost up to $120 million .

however , the blueprint specifies that this figure did not represent the life - cycle cost estimate ; rather it was intended to be a preliminary estimate to initiate projects .

without a life - cycle cost estimate , dhs has limited information about how much it will cost to implement hrit , which hinders the department's ability to , among other things , make budgetary decisions and informed milestone review decisions .

according to cmmi - acq and the pmbok® guide , programs should track program costs in order to effectively manage the program and make resource adjustments accordingly .

in particular , tracking and monitoring costs enables a program to recognize variances from the plan in order to take corrective action and minimize risk .

however , dhs has not tracked the total actual costs incurred on implementing hrit across the enterprise to date .

specifically , while the investment received line item appropriations for fiscal years 2005 through 2015 which totaled at least $180 million , dhs was unable to provide all cost information on hrit activities since it began in 2003 , including all government - related activities and component costs that were financed through the working capital fund , which , according to dhs officials from multiple offices , were provided separately from the at least $180 million appropriated specifically to hrit .

ochco officials attributed the lack of cost tracking to , among other things , the investment's early reliance on contractors to track costs , and said that the costs were not well maintained nor centrally tracked , and included incomplete component - provided cost information .

the components were also unable to provide us with complete information .

for example , fema officials stated that it would require a significant administrative effort to identify how much it has spent on hrit since inception in 2003 because of the way their financial system obligates and expends funds for working capital fund activities .

uscg officials also said that compiling its expenditure information for fiscal years 2003-2009 would require a substantial administrative effort , including reviewing a significant number of paper files .

uscis was unable to identify its hrit - related expenditures for fiscal years 2003-2010 .

without tracking all costs associated with hrit , including components' costs , stakeholders are limited in making informed resource decisions , and dhs cannot provide complete and accurate information to assist congressional oversight .

according to the hrit executive steering committee's charter , the under secretary for management ( as the chair of the committee ) is to ensure that the department's human resources it business needs are met , as outlined in the blueprint .

additionally , according to the gpra ( government performance and results act ) modernization act of 2010 , agency strategic plans should be updated at least every 4 years .

while this is a legal requirement for agency strategic plans ( the human capital segment architecture blueprint does not fall under the category of an “agency strategic plan” ) , it is considered a best practice for other strategic planning documents , such as the blueprint .

however , the department issued the blueprint in august 2011 ( approximately 4.5 years ago ) and has not updated it since .

as a result , the department does not know whether the remaining 14 strategic improvement opportunities and associated projects that it has not fully implemented are still valid and reflective of dhs's current priorities , and are appropriately prioritized based on current mission and business needs .

additionally , dhs does not know whether new or emerging opportunities or business needs need to be addressed .

officials stated that the department is still committed to implementing the blueprint , but agreed that it should be re - evaluated .

to this end , following a meeting we had with dhs's under secretary for management in october 2015 , in which we expressed concern about hrit's lack of progress , ochco and ocio officials stated that hrit was recently asked by the deputy under secretary of management in late october 2015 to re - evaluate the blueprint's strategic improvement opportunities and to determine the way forward for those improvement opportunities and the hrit investment .

however , officials did not know when this re - evaluation and a determination for how to move forward with hrit would occur , or be completed .

further , according to ocio officials , dhs has not updated its complete systems inventory since it was originally developed as part of the blueprint effort , in response to a 2010 office of inspector general report that stated that dhs had not identified all human resource systems at the components .

this report also emphasized that without an accurate inventory of human resource systems , dhs cannot determine whether components are using redundant systems .

moreover , ocio officials were unable to identify whether and how its inventory of human resources systems had changed .

until dhs establishes time frames for re - evaluating the blueprint to reflect dhs's hrit current priorities and updates its human resources system inventory , the department will be limited in addressing the inefficient human resources environment that has plagued the department since it was first created .

dhs took several steps to justify its investment in the palms program for both of the program's two main purposes ( the learning management capabilities and the performance management capabilities ) through multiple mechanisms .

specifically , although existing dhs guidance did not require an analysis of alternatives for palms because it is a level 3 acquisition program , the department initiated such an analysis in 2010 to identify recommended approaches for pursuing a commercial off - the - shelf learning management system to replace the components' nine existing learning systems .

according to the analysis of alternatives , the nine systems at the department were disconnected from each other and did not exchange information .

the components had independently purchased these learning management systems and , in some cases , had done so before dhs was established in 2002 .

however , dhs determined that a unified strategy for learning management systems at the department was needed , rather than disparate , component - centric efforts .

in particular , dhs determined that such a strategy was necessary to provide , among other things , improved reporting , greater automation , less duplication and redundancy of training courses , better governance , and streamlined it infrastructure .

the analysis of alternatives , which was performed by the homeland security studies and analysis institute , included , among other things , an assessment of six alternative approaches , including status quo , implementation of two systems from separate vendors ( allowing components to choose which system to use ) , and implementation of a single system ( either centrally managed by dhs or individually managed by each component ) .

as part of the analysis , the institute assessed the alternative approaches based on five evaluative categories , including cost , benefits , and risks .

based on the analysis of alternatives process , the institute recommended that dhs adopt a single enterprise - wide , centrally managed learning management system as the most cost - effective approach to providing such a capability to the department .

regarding the second purpose of palms — enabling performance management capabilities — the august 2011 human capital segment architecture blueprint called on dhs to conduct an analysis of alternatives to identify the preferred approach for such a solution .

officials stated that dhs leadership ultimately determined that such an analysis for a performance management solution was unnecessary because the requirement for dhs to automate performance management functions across the department was the same as it was during dhs's prior attempt to pursue an automated performance management system for instituting pay - for - performance — an effort that was ultimately abandoned .

therefore , instead of conducting an analysis of alternatives on performance management system approaches for dhs enterprise - wide adoption , in january 2012 , departmental leadership made an executive decision on the approach based on the findings of a december 2011 request for information from industry .

in particular , the accumulated industry information highlighted that vendors for an enterprise - wide learning management solution could in most cases also provide a system that integrated performance management capabilities .

this industry information validated dhs officials' understanding that a combined solution for learning and performance management at the department was consistent with prevailing industry offerings .

according to ochco officials , the department's request for information from industry to help justify its preferred approach allowed for competition within industry for supplying a solution to the department .

as part of the department's considerations , officials had determined that this competition could better help to reduce overall implementation costs for a consolidated learning and performance management system , versus adopting , without competition , one of the components' existing learning or performance management systems for dhs enterprise - wide deployment .

additionally , ochco officials stated that they contacted other federal departments to determine whether existing shared services could be used by dhs to establish an integrated system for learning and performance management , but dhs determined that other departments' contracts with service providers could not be modified to allow dhs to use the same services .

based on the collective results of the learning management system analysis of alternatives and the request for information from industry on performance management systems , the hrit executive steering committee exercised its executive decision - making authority and decided that an integrated , enterprise - wide learning and performance management system should be pursued for adoption at the department .

dhs's integrated solution is now being implemented by the palms program .

by providing the executive steering committee with enough information for determining this preferred approach for the department , dhs justified its investment in the palms program .

as previously mentioned , palms is intended to provide an enterprise - wide system that offers performance management capabilities , as well as learning management capabilities to headquarters and each of its components .

as such , dhs headquarters pmo and the components estimate that , if fully implemented across dhs , palms's learning management capabilities would be used by approximately 309,360 users , and its performance management capabilities would be used by at least 217,758 users .

table 3 identifies the total estimated number of planned users for both palms's learning management capabilities and performance management capabilities if palms is fully implemented department - wide .

however , there is uncertainty about whether the palms system will be used enterprise - wide to accomplish these goals .

specifically , as of november 2015 , of the eight components and headquarters , five are planning to implement both palms's learning and performance management capabilities ( three of which have already implemented the learning management capabilities — discussed later ) , two are planning to implement only the learning management capabilities , and two components are not currently planning to implement either of these palms capabilities , as illustrated in figure 3 .

officials from fema , tsa , ice , and the uscg cited various reasons for why they were not currently planning to fully implement palms , which include: fema and ice officials stated that they were not currently planning to implement the performance management capabilities because the program had experienced critical deficiencies in meeting the performance management - related requirements .

fema officials stated that they do not plan to make a decision on whether they will or will not implement these performance management capabilities until the vendor can demonstrate that the system meets fema's needs ; as such , fema officials were unable to specify a date for when they plan to make that decision .

ice officials also stated that they do not plan to implement the performance management capabilities of palms until the vendor can demonstrate that all requirements have been met .

palms headquarters pmo officials expected all requirements to be met by the vendor by the end of february 2016 .

tsa officials stated that they were waiting on the results of their fit - gap assessment of palms before determining whether , from a cost and technical perspective , tsa could commit to implementing the learning and / or performance management capabilities of palms .

tsa officials expected the fit - gap assessment to be completed by the end of march 2016 .

uscg officials stated that , based on the palms schedule delays experienced to date , they have little confidence that the palms vendor could meet the component's unique business requirements prior to the 2018 expiration of the vendor's blanket purchase agreement .

additionally , these officials stated that the system would not meet all of its learning management requirements for about 31,000 auxiliary volunteer members and certain other employee groups .

further , although the fit gap assessment for implementing palms at uscg had not been fully completed , the component's officials stated that the system would likely not fully meet the performance management requirements for all of uscg's military components .

due to the component's uncertainty , the officials were unable to specify when they plan to ultimately decide on whether they will implement one or both aspects of palms .

as a result , it is unlikely that the department will reach its expected user estimates as presented in table 3 , and meet its goal of being an enterprise - wide system .

specifically , as of november 2015 , the components estimate 179,360 users will use the learning management capabilities of palms ( not the 309,360 expected , if fully implemented ) .

figure 4 shows the percentage of expected users from components currently planning to implement palms's learning management capabilities in comparison to the total expected users if palms was fully implemented , as of november 2015 .

additionally , as of november 2015 , the components estimate 123,200 users will use the performance management capabilities of palms ( not the 217,758 expected , if fully implemented ) .

figure 5 shows the percentage of expected users from components planning to implement palms's performance management capabilities in comparison to the total expected user estimate if fully implemented as intended .

of the seven components and headquarters that are currently planning to implement the learning and / or performance management aspects of palms , three have completed their implementation efforts of the learning management capabilities and deployed these capabilities to users ( deployed to cbp in july 2015 , headquarters in october 2015 , and fletc in december 2015 ) ; two have initiated their implementation efforts on one or both aspects , but not completed them ; and two have not yet initiated any implementation efforts , as of november 2015 .

as a result , palms's current trajectory is putting the department at risk of not meeting its goals to perform efficient , accurate , and comprehensive tracking and reporting of training and performance management data across the enterprise ; and consolidating its nine learning management systems down to one .

accordingly , until fema decides whether it will implement the performance management capabilities of palms and uscg decides whether it will implement the learning and / or performance management capabilities of palms , the department is at risk of implementing a solution that does not fully address its problems .

moreover , until dhs determines an alternative approach if one or both aspects of palms is deemed not feasible for ice , tsa , fema or the uscg , the department is at risk of not meeting its goal to enable enterprise - wide tracking and reporting of employee learning and performance management .

hrit's palms program varied in its implementation of it acquisition best practices for project planning , project monitoring , and risk management .

specifically , the program management office had implemented selected it acquisition best practices in each of these areas ; however , the program had not developed complete life - cycle cost and schedule estimates .

additionally , the palms pmo did not monitor total costs spent on the program or consistently document the results from progress and milestone reviews .

further , the program management office had not fully implemented selected risk management practices .

without fully implementing effective acquisition management practices , dhs is limited in monitoring and overseeing the implementation of palms , ensuring that the department obtains a system that improves its performance management and learning management weaknesses , reduces duplication , and delivers within cost and schedule commitments .

according to gao's cost estimating and assessment guide , having a complete life - cycle cost estimate is a critical element in the budgeting process that helps decision makers to evaluate resource requirements at milestones and other important decision points .

additionally , a comprehensive cost estimate should include both government and contractor costs of the program over its full life cycle , from inception of the program through design , development , deployment , and operation and maintenance to retirement of the program .

however , according to palms pmo officials , they did not develop a life - cycle cost estimate for palms .

in 2012 dhs developed an independent government cost estimate to determine the contractor - related costs to implement the palms system across the department ( estimated to be approximately $95 million ) ; however , this estimate was not comprehensive because it did not include government - related costs .

as a result , dhs was not able to determine the impact on cost when the palms program experienced problems ( discussed in more detail later ) , since the baseline cost estimate was incomplete .

palms pmo officials stated that palms did not develop a life - cycle cost estimate because the program is a level 3 acquisition program and dhs does not require such an estimate for a level 3 program .

however , while dhs acquisition policy does not require a life - cycle cost estimate for a program of this size , we maintain that such an estimate should be prepared because of the program's risk and troubled history .

without developing a comprehensive life - cycle cost estimate , dhs is limited in making future budget decisions related to palms .

as described in gao's schedule assessment guide , a program's integrated master schedule is a comprehensive plan of all government and contractor work that must be performed to successfully complete the program .

additionally , such a schedule helps manage program schedule dependencies .

best practices for developing and maintaining this schedule include , among other things , capturing all activities needed to do the work and reviewing the schedule after each update to ensure the schedule is complete and accurate .

while dhs had developed an integrated master schedule with the palms vendor , it did not appropriately maintain this schedule .

specifically , the program's schedule was incomplete and inaccurate .

while dhs's original august 2012 schedule planned to fully deploy both the learning and performance management capabilities in one release at each component by march 2015 , the program's september 2015 schedule did not reflect the significant change in palms's deployment strategy and time frames .

specifically , the program now plans to deploy the learning management capabilities first and the performance management capabilities separately and incrementally to headquarters and the components .

however , the september 2015 schedule reflected the deployment - related milestones ( per component ) for only the learning management capabilities and did not include the deployment - related milestones for the performance management capabilities .

in september 2015 , palms officials stated that the deployments related to performance management were not reflected in the program's schedule because the components had not yet determined when they would deploy these capabilities .

since then , two components have determined their planned dates for deploying these capabilities , but seven ( including headquarters ) remain unknown .

as a result , the program does not know when palms will be fully implemented at all components with all capabilities .

table 4 provides a comparison of the program's initial delivery schedule , as of august 2012 , to the program's latest schedule , as of november 2015 .

moreover , the schedule did not include all government - specific activities , including tasks related to employee union activities ( such as notifying employee unions and bargaining with them , where necessary ) related to the proposed implementation of the performance management capabilities .

for example , time frames for when dhs planned to notify employee unions at dhs headquarters , fletc , and uscis were not identified in the schedule .

in september 2015 , palms program officials stated that certain government - specific tasks were not included in the schedule because the integrated master schedule was too big and difficult to manage , so the program decided to track certain government activities , such as union negotiation activities , separately .

however , without an integrated master schedule that includes all government and contractor work that must be performed , the program is at risk of failing to ensure schedule dependencies are appropriately managed and that all essential activities are completed .

additionally , the august 2015 schedule had incorrect completion dates listed for key activities .

for example , dhs reported in the schedule that the actual finish date for deploying the learning management capabilities of the palms system at cbp was february 17 , 2015 ; however , according to cbp officials , they did not deploy these capabilities until july 2015 .

in september 2015 , program officials acknowledged our concerns and attributed the inaccurate dates to a lack of oversight ; subsequently , the program took actions to update the dates .

without developing and maintaining a single comprehensive schedule that fully integrates all government and contractor activities , and includes all planned deployment milestones related to performance management , dhs is limited in monitoring and overseeing the implementation of palms , and managing the dependencies between program tasks and milestones to ensure that it delivers capabilities when expected .

according to cmmi - acq and the pmbok® guide , a key activity for tracking a program's performance is monitoring the project's costs by comparing actual costs to the cost estimate .

the palms pmo — which is responsible for overseeing the palms implementation projects across dhs , including all of its components — monitored task order expenditures on a monthly basis .

as of december 2015 , dhs officials reported that they had awarded approximately $18 million in task orders to the vendor .

however , the program management office officials stated that they were not monitoring the government - related costs associated with each of the palms implementations .

the officials stated that they were not tracking government - related implementation costs at headquarters because many of the headquarters program officials concurrently work on other acquisition projects and these officials are not required to track the amount of time spent working specifically on palms .

the officials also said that they were not monitoring the government - related costs for each of the component palms implementation projects because it would be difficult to obtain and verify the cost data provided by the components .

we acknowledge the department's difficulties associated with obtaining and verifying component cost data ; however , monitoring the program's costs is essential to keeping costs on track and alerting management of potential cost overruns .

additionally , because dhs did not develop a comprehensive life - cycle cost estimate for palms that included government - related costs , the program management office was unable to determine cost increases to the program because it could not compare actual cost values against a baseline cost estimate .

for example , program officials were unable to identify how much the program's cost estimate had increased when the implementation at headquarters experienced schedule delays to address deficiencies identified during testing .

without tracking and monitoring all costs associated with palms , the department will be unable to compare actual costs against planned estimates and thus , will be limited in its ability to fully monitor the program , which is essential for alerting the program to possible cost overruns and prompting corrective actions .

according to cmmi - acq and the pmbok® guide , key activities in tracking a program's performance include conducting and documenting the results from progress and milestone reviews to determine whether there are significant issues or performance shortfalls that need to be addressed .

although the palms pmo conducted reviews to monitor the program's performance , it did not consistently document the results of its progress and milestone reviews .

for example , the palms pmo did not document the results of the status updates that the pmo provided to dhs executives during its bi - weekly integrated project team meetings , so it is unclear whether the program was appropriately monitoring the progress of all government - specific activities .

according to palms pmo officials , palms achieved initial operating capability — which was specified in the contract to be the point when the contractor would deliver an initial set of requirements to the government — in january 2015 ; however , the review for this major milestone was not documented .

in september 2015 , program officials stated that the results were not documented because this milestone did not align with the typical initial operating capability milestone that is defined in dhs acquisition guidance .

specifically , dhs's guidance defines it as when capabilities are first deployed to end users ( palms capabilities were not deployed to any users until july 2015 ) .

nevertheless , palms's achieving initial operating capability in january 2015 was still considered a major milestone that prompted a review .

however , without documenting the results of the milestone review , it is unclear whether any action items were identified during this review and , if so , whether they have all been appropriately managed to closure .

although cbp officials stated that the results of their progress reviews with the vendor were typically documented , cbp was unable to provide the results of the milestone review conducted prior to deploying the palms learning management capabilities in july 2015 .

as such , it is unclear whether any action items were identified during this review and , if so , whether cbp had appropriately managed them to closure .

in the absence of documenting palms's progress and milestone reviews , including all issues and corrective actions discussed , the program cannot demonstrate that these issues and corrective actions are appropriately managed .

according to cmmi - acq and the pmbok® guide , key risk management practices include identifying risks , developing mitigation plans , and regularly tracking the status of risks and mitigation efforts .

in particular , identifying risks and periodically reviewing them is the basis for sound and successful risk management .

additionally , risk mitigation plans should be developed and implemented when appropriate to proactively reduce the potential impact if a risk were to occur .

while palms officials had identified program risks , developed associated mitigation plans , and documented them in the hrit investment - level risk log ( which is intended to be the centralized log containing all palms risks and mitigation plans , including both government - and vendor - identified risks ) , the program did not consistently maintain this log .

specifically , the palms risks in this log were out of date , the log did not accurately capture the status of all of the risks identified by the program , and it was unclear which risks and associated mitigation plans were being assessed on a monthly basis .

for example , in the may 2015 risk log , 16 of the 17 active palms risks stated that the last time any action was taken to mitigate or close any of these risks was in 2014 .

however , the mitigation strategy details for 5 of these active risks included information related to decisions made in 2015 .

as such , it was unclear which risks and mitigation plans were regularly assessed and updated in the risk log , and when actions were last taken on each of the risks .

one of the high - impact and high - probability risks from the may 2015 risk log stated that dhs needed to determine an interim solution for consolidating human resources - related data from dhs's components by december 2014 ; however , the status of this risk had not been updated since august 2014 and it was unclear whether this was still a risk or had been realized as an issue .

additionally , while the hrit investment - level risk management plan identified that the palms program was to , among other things , generate weekly status reports to document the status of decisions made during risk review meetings and identify planned completion dates for each step of the risk mitigation plans , the program was not always complying with these processes .

for example , the program was not developing the required weekly risk status reports or identifying planned completion dates for its risk mitigation plan steps .

program officials acknowledged that the palms risks in the hrit risk log were out of date and inaccurate , and the program was not complying with all of the documented processes in the hrit risk management plan .

program officials attributed this to , among other things , the pmo's focus being on meeting upcoming deadlines ; as such , implementing certain processes identified in the hrit risk management plan were not a priority .

however , by not carrying out these key risk management functions , program officials introduced additional risk to the program .

in october 2015 and in response to us identifying these issues , palms officials stated that they were in the process of validating and updating the risks and mitigation plans in the hrit risk log to address these issues , as well as were updating their risk management processes to align with the documented processes in the hrit risk management plan .

the program completed this validation update process in october 2015 ; however , the updated log continued to have these issues .

for example , the palms pmo had not yet identified the planned completion dates for each mitigation step ( where appropriate ) .

further , this updated log — which is intended to be the program's centralized log of all government - and vendor - identified palms risks — did not contain all of the vendor - identified risks .

for example , two component - specific risks that were identified in the vendor - maintained risk log were not included in the program's centralized risk log .

as such , it is unclear whether the program is appropriately managing these risks .

until a comprehensive risk log is established that accurately captures the status of all risks ( including both government - and vendor - identified risks ) and mitigation plans , and includes planned completion dates for each mitigation step ( where appropriate ) , the program is limited in effectively managing all of its risks .

according to cmmi - acq and pmbok® guide risk management best practices , effective risk management includes evaluating and categorizing risks using defined risk categories and parameters , such as probability and impact , and determining each risk's relative priority .

risk prioritization helps to determine where resources for risk mitigation can be applied to provide the greatest positive impact on the program .

the parameters for evaluating , categorizing , and prioritizing risks should include defined thresholds ( eg , for cost , schedule , performance ) that , when exceeded , trigger management attention and mitigation activities .

these risk parameters should be documented so that they are available for reference throughout the life of the project and are used to provide common and consistent criteria for prompting management attention .

while the palms program had categorized its risks and assigned parameters to them , including probability and impact , the program did not prioritize its risks or document criteria for elevating them to management .

specifically , the palms pmo did not use the assigned parameters to determine each risk's relative priority and overall risk level ( i.e. , high , medium , and low ) .

palms officials acknowledged in june 2015 that the risks were not prioritized in the logs , but said , based on the experience of the palms pmo staff , officials are able to determine each risk's priority by reviewing the assigned probability and impact parameters .

however , this is an inadequate method for managing risks .

specifically , it introduces unnecessary subjectivity by relying heavily on officials to make prioritization decisions , rather than using the assigned parameters to determine and document each risk's relative priority .

additionally , the program had not documented criteria for elevating component risks to the program management office .

as mentioned earlier , each component is responsible for overseeing its own palms implementation project , while the program management office at headquarters is responsible for overseeing the implementation projects across the department .

according to program officials , as part of this effort , each component is to follow the risk management processes documented in palms's vendor - developed risk management plan ( which is a separate plan from the hrit - level risk management plan used by the program management office , as discussed earlier ) .

while the palms vendor - developed risk management plan directed each component to track risks in a component - specific risk register , the plan did not establish criteria for when component - level risks need to be elevated to the palms pmo at headquarters .

in september 2015 , the palms program manager stated that all component - level risks that are rated red ( i.e. , high - probability and high - impact risks ) are reported to headquarters .

however , this guidance was not documented and , as such , the palms pmo did not have reasonable assurance that the components were knowledgeable about which risks to elevate , and whether the components were appropriately elevating such risks .

program officials were unable to explain why this criterion was not documented , but in response to our concern , the program officials directed the vendor to update the palms risk management plan to document this criterion ; the vendor completed this update in october 2015 .

in particular , the plan now specifies that all component - level risks that could impact when the palms system is to be deployed at each of the components should be elevated to the palms pmo and given a priority of high .

documenting the criteria for when risks need to be elevated to the palms pmo should help ensure that all appropriate risks are being elevated for review .

however , until the program prioritizes its risks by determining each risk's relative priority and overall risk level , dhs is hampered in its ability to ensure that the program's attention and resources for risk mitigation are used in the most effective manner .

although the hrit investment was initiated about 12 years ago with the intent to consolidate , integrate , and modernize the department's human resources it infrastructure , dhs has made very limited progress in achieving these goals .

hrit's minimally involved executive steering committee during a time when significant problems were occurring was a key factor in the lack of progress .

this is particularly problematic given that the department's ability to efficiently and effectively carry out its mission is significantly hampered by its fragmented human resources system environment and duplicative and paper - based processes .

moreover , dhs's ineffective management of hrit , such as the lack of an updated schedule and a life - cycle cost estimate , also contributed to the neglect this investment has experienced .

until dhs , among other things , maintains a schedule , develops a life - cycle cost estimate , tracks costs , and re - evaluates and updates the human capital segment architecture blueprint , the department will continue to be plagued by duplicative systems and an inefficient and ineffective human resources environment impacting in its ability to perform its mission .

additionally , until the palms program effectively addresses identified weaknesses in its project planning , project monitoring , and risk management practices and implements palms department - wide , dhs's performance management processes will continue to be cumbersome , time - consuming , and primarily paper - based .

further , dhs will be limited in efficiently tracking and reporting accurate , comprehensive performance and learning management data across the organization , and could risk further implementation delays .

to ensure that the hrit investment receives necessary oversight and attention , we are recommending that the secretary of homeland security direct the under secretary of management take the following two actions: update the hrit executive steering committee charter to establish the frequency with which hrit executive steering committee meetings are to be held .

ensure that the hrit executive steering committee is consistently involved in overseeing and advising hrit , including approving key program management documents , such as hrit's operational plan , schedule , and planned cost estimate .

to address hrit's poor progress and ineffective management , we are recommending that the secretary of homeland security direct the under secretary of management to direct the chief human capital officer to direct the hrit investment take the following six actions: update and maintain a schedule estimate for when dhs plans to implement each of the strategic improvement opportunities .

develop a complete life - cycle cost estimate for the implementation of hrit .

document and track all costs , including components' costs , associated with hrit .

establish time frames for re - evaluating the strategic improvement opportunities and associated projects in the human capital segment architecture blueprint and determining how to move forward with hrit .

evaluate the strategic improvement opportunities and projects within the human capital segment architecture blueprint to determine whether they and the goals of the blueprint are still valid and reflect dhs's hrit priorities going forward , and update the blueprint accordingly .

update and maintain the department's human resources system inventory .

to improve the palms program's implementation of it acquisition best practices , we are recommending that the secretary of homeland security direct the under secretary of management to direct the chief information officer to direct the palms program office to take the following six actions: establish a time frame for deciding whether palms will be fully deployed at fema and uscg , and determine an alternative approach if the learning and / or performance management capabilities of palms are deemed not feasible for ice , fema , tsa , or uscg .

develop a comprehensive life - cycle cost estimate , including all government and contractor costs , for the palms program .

develop and maintain a single comprehensive schedule that includes all government and contractor activities , and includes all planned deployment milestones related to performance management .

track and monitor all costs associated with the palms program .

document palms's progress and milestone reviews , including all issues and corrective actions discussed .

establish a comprehensive risk log that maintains an aggregation of all up - to - date risks ( including both government - and vendor - identified ) and associated mitigation plans .

additionally , within the comprehensive risk log , identify and document planned completion dates for each risk mitigation step ( where appropriate ) , and prioritize the risks by determining each risk's relative priority and overall risk level .

we received written comments on a draft of this report from the director of dhs's departmental gao - oig liaison office .

the comments are reprinted in appendix ii .

in its comments , the department concurred with our 14 recommendations and provided estimated completion dates for implementing each of them .

for example , by april 30 , 2016 , the under secretary of management plans to ensure that the hrit executive steering committee is consistently involved in overseeing and advising hrit and the committee is expected to be reviewed quarterly by the acquisition review board .

these planned actions , if implemented effectively , should help dhs address the intent of our recommendations .

we also received technical comments from dhs headquarters and component officials , which we have incorporated , as appropriate .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the secretary of homeland security and other interested parties .

in addition , this report is available at no charge on the gao website at http: / / www.gao.gov .

should you or your staffs have any questions on information discussed in this report , please contact carol cha at ( 202 ) 512-4456 , chac@gao.gov or rebecca gambler at ( 202 ) 512-6912 , gamblerr@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iii .

our objectives were to ( 1 ) evaluate the progress the department of homeland security ( dhs ) has made in implementing the human resources information technology ( hrit ) investment and how effectively dhs has managed the investment since completing the human capital segment architecture in august 2011 , ( 2 ) describe whether dhs has justified its investment in the performance and learning management system ( palms ) program , ( 3 ) determine whether palms is being implemented enterprise - wide , and ( 4 ) evaluate the extent to which palms is implementing selected information technology ( it ) acquisition best practices .

to address the first part of our first objective — to evaluate the progress dhs had made in implementing the hrit investment — we compared hrit's goals , scope , and implementation time frames ( as defined in the human capital segment architecture blueprint , which was completed in august 2011 ) to the investment's actual accomplishments .

specifically , we compared the completed and in - progress hrit projects against the strategic improvement opportunities and projects that were outlined in the blueprint to determine which of the improvement opportunities and projects had been fully implemented or were in - progress .

we also compared dhs's planned schedule for implementing the improvement opportunities and projects against dhs's current planned schedule for implementing them as of november 2015 .

additionally , we interviewed dhs officials from the hrit investment , office of the chief information officer ( ocio ) , office of the chief human capital officer ( ochco ) , and dhs's components to discuss the steps taken to implement hrit , address the strategic improvement opportunities and projects in the blueprint , and meet the goals of the investment .

in addressing the second part of our first objective — to evaluate how effectively dhs managed the investment — we analyzed documentation , such as the investment's planned and updated completion dates , program management briefings , the blueprint , cost estimates , and budget documentation , and compared it against relevant cost and schedule best practices identified by gao , cmmi - acq , and the pmbok® guide .

these best practices included developing and maintaining a schedule estimate ; developing a life - cycle cost estimate ; and tracking program expenditures .

to determine the amount spent to date on hrit , we asked officials from dhs headquarters and each of the eight components to provide expenditure information on hrit since the investment began in 2003 ; officials were unable to provide complete information .

as such , we were unable to identify the total amount spent on the investment and discuss this limitation earlier in the report .

we also analyzed dhs's human capital investment guidance , including the 2010 deputy secretary memorandum that prohibited component spending on enhancements to existing human resources systems or acquisitions of new human resources solutions , unless those expenditures have been approved by ochco or ocio , and compared it to the components' current investments in human resources systems , such as those listed in dhs's fiscal year 2016 human capital portfolio .

additionally , we interviewed officials from the ocio , ochco , and dhs's eight components to obtain additional information on how hrit reduced or will reduce duplicative human resources systems .

to describe whether dhs justified its investment in the palms program , we analyzed documentation , such as the program's business case and the documented analysis of alternatives that was conducted to identify recommended approaches for pursuing a commercial off - the - shelf learning management system .

we used this information to determine the various alternative solutions that dhs assessed for delivering enterprise - wide performance and learning management capabilities .

additionally , we reviewed program management briefings provided to the hrit executive steering committee that outlined , for example , the proposed solution and rationale for such a solution .

we also interviewed appropriate dhs and palms officials for further information regarding the process dhs used to conduct the analysis of alternatives and other steps the department took to determine its preferred solution , including determining whether dhs could use existing shared services that were being used by other federal agencies .

to determine whether palms is being implemented department - wide , we analyzed the program's acquisition plan and original schedule for implementing the system department - wide , and compared it against actual program status documentation and the program's current implementation schedule .

we also obtained and analyzed information from dhs officials , the palms headquarters program management office and dhs's components on each component's implementation of palms , including identifying which palms capabilities each component planned to implement , the number of planned palms users , and their reported causes for why certain components were not currently planning to implement palms .

to evaluate the extent to which palms implemented selected it acquisition best practices , we analyzed the program's it acquisition documentation and compared it to relevant project planning , project monitoring , and risk management best practices — including cmmi - acq and pmbok® guide practices , and best practices identified by gao .

specifically , we analyzed program documentation , including the acquisition plan , requirements management plan , risk management plan , cost and schedule estimates , program management review briefings , meeting minutes , risk logs , and risk mitigation plans to determine the extent to which the program's acquisition processes were consistent with the best practices .

additionally , we interviewed officials from hrit , palms , ocio , ochco , and dhs's eight components to obtain additional information on the program's risk management , project planning , and project monitoring processes .

to assess the reliability of the data that we used to support the findings in this report , we reviewed relevant program documentation to substantiate evidence obtained through interviews with agency officials .

we determined that the data used in this report were sufficiently reliable , with the exception of expenditure information provided by the hrit investment and selected risk data provided by the palms program .

we discuss limitations with these data in the report .

we have also made appropriate attribution indicating the sources of the data .

we conducted this performance audit from march 2015 to february 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contacts named above , the following staff also made key contributions to this report: shannin o'neill , assistant director ; christopher businsky ; rebecca eyler ; javier irizarry ; emily kuhn ; and david lysy .

