over 40,000 servicemembers have been wounded in the wars in iraq and afghanistan , as of october 2010 .

after receiving medical treatment , many wounded servicemembers must navigate a complex disability evaluation system that begins with the department of defense ( dod ) determining whether they are medically fit to continue their military service .

if they are found unfit , servicemembers continue through the system to obtain a determination of their eligibility for military disability benefits .

once servicemembers are discharged from the military , they may also be eligible to receive disability benefits from the department of veterans affairs ( va ) , but they must first undergo an entirely separate va disability evaluation process .

a series of articles in 2007 by the washington post concerning conditions at walter reed army medical center , and subsequent reports from numerous high - level commissions and review groups , highlighted problems with the dod and va disability evaluations systems .

these included long delays , duplication in dod and va processes , confusion among servicemembers , and distrust of systems regarded as adversarial by servicemembers and veterans .

in response to these concerns , dod and va jointly designed a new disability evaluation system that integrates dod and va processes , with the goal of expediting the delivery of benefits to servicemembers .

dod and va began pilot testing the integrated disability evaluation system ( ides ) in november 2007 at three washington , d.c. , area military treatment facilities and , by march 2010 , added 24 more facilities to the pilot .

dod and va are now planning to expand the piloted system to 28 additional facilities , as a first step toward replacing the military's existing — or “legacy” — disability evaluation system with the ides worldwide .

in january 2008 , congress enacted the national defense authorization act for fiscal year 2008 ( ndaa 2008 ) requiring dod and va , to the extent feasible , to jointly develop and implement a comprehensive policy on improvements to the care , management , and transition of recovering servicemembers , including improvements to the agencies' disability evaluation systems .

the ndaa 2008 also required gao to report on the progress dod and va have made in developing and implementing the comprehensive policy .

in agreement with cognizant congressional staff , we reviewed dod and va's progress in implementing policies related to their disability evaluation systems , focusing on the agencies' joint pilot of the ides .

specifically , we examined: ( 1 ) the results of dod and va's evaluation of the pilot , ( 2 ) challenges in implementing the piloted system to date , and ( 3 ) dod and va plans to expand the piloted system and whether those plans adequately address potential challenges .

to examine dod and va's evaluation of the ides pilot , we identified the goals that dod and va expected the pilot to achieve and reviewed their assessment of whether those goals were met .

as part of this work , we assessed the reliability of two types of data that dod and va planned to use as the basis of their pilot evaluation — case data from both pilot and legacy disability evaluation systems , as well as data from surveys dod conducted to gauge servicemember satisfaction .

we obtained the case data and survey data as of early 2010 , the same cutoff dates that dod and va used for their pilot evaluation .

to identify challenges in implementing the piloted system to date , we visited 10 of the 27 military treatment facilities participating in the pilot .

we selected these 10 facilities to obtain perspectives from sites in different military services and geographical regions and with varying caseloads and organizational structures .

for all of the research objectives , we conducted interviews with key officials involved in the pilot at dod , va , and each of the military services .

furthermore , we analyzed pilot case data and reviewed reports , guidance , plans , and other documents .

we also reviewed relevant federal laws and regulations .

we conducted this performance audit from november 2009 to december 2010 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the ndaa 2008 also requires us to certify whether we had timely access to sufficient information to make informed judgments on the matters covered by our report .

we were provided sufficient information in a timely manner to make informed judgments on the audit objectives covered in this report .

the military's legacy disability evaluation process begins at a military treatment facility when a physician identifies a condition that may interfere with a servicemember's ability to perform his or her duties .

on the basis of medical examinations and the servicemember's medical records , a medical evaluation board ( meb ) identifies and documents any conditions that may limit a servicemember's ability to serve in the military .

the servicemember's case is then evaluated by a physical evaluation board ( peb ) to make a determination of fitness or unfitness for duty .

each of the services conducts this process for its servicemembers .

the army has three pebs , which are located at fort sam houston , texas ; walter reed army medical center in washington , d.c. ; and fort lewis , washington .

the navy and air force each have one peb: the navy's is located at the washington navy yard in washington , d.c. , and the air force's is located in san antonio , texas .

the peb process begins with an “informal” peb — an administrative review of the case file by peb adjudicators without the presence of the servicemember .

if the servicemember is found to be unfit due to medical conditions incurred in the line of duty , the informal peb assigns the servicemember a combined percentage rating for those unfit conditions , and the servicemember is discharged from duty .

disability ratings range from 0 ( least severe ) to 100 percent ( most severe ) in increments of 10 percent .

depending on the overall disability rating and number of years of active duty or equivalent service , the servicemember found unfit with compensable conditions is entitled to either monthly disability retirement benefits or lump sum disability severance pay .

servicemembers have opportunities to appeal the results of their disability evaluations .

if servicemembers are dissatisfied with the informal peb's decisions , they may request a hearing with a “formal” peb .

if they then disagree with the formal peb's findings , they can , under certain conditions , appeal to the reviewing authority of the peb .

as servicemembers navigate dod's disability evaluation system , they interface with staff who play key roles in supporting them through the process .

military physicians involved in the meb process play a fundamental role because they are responsible for documenting in the disability evaluation case file the medical conditions that may limit a servicemember's ability to serve in the military .

to prepare this documentation , military physicians may require that servicemembers obtain additional medical evidence from specialty physicians , such as a psychiatrist .

throughout the meb and peb processes , board liaisons serve a key role by explaining the process to servicemembers and constructing the case files .

the liaisons inform servicemembers of board results and of deadlines at key decision points in the process .

the military also provides legal counsel to advise and represent servicemembers going through the disability evaluation process , although servicemembers may retain their own representative at their own expense .

in addition to receiving disability benefits from dod , veterans with service - connected disabilities may receive compensation from va for lost earnings capacity .

in contrast to dod's disability evaluation system , which evaluates only medical conditions affecting servicemembers' fitness for duty , va evaluates all medical conditions claimed by the veteran , whether or not they were previously evaluated by the military services' medical evaluation process .

although a servicemember may file a va claim while still in the military , he or she can only obtain disability compensation from va as a veteran .

va's disability compensation claims process starts when a veteran submits a claim to va's veterans benefits administration ( vba ) .

the claim lists the medical conditions that the veteran believes are service - connected .

for each claimed condition , va must determine if credible evidence is available to support the veteran's contention of service connection .

a service representative assists the veteran in gathering the relevant evidence to evaluate the claim , which may include the veteran's military service records and treatment records from va medical facilities and private medical service providers .

also , if necessary for reaching a decision on a claim , vba arranges for the veteran to receive a medical examination conducted by clinicians ( including physicians , nurse practitioners , or physician assistants ) certified to perform the exams under va's compensation and pension program .

once a claim has all of the necessary evidence , a va rating specialist evaluates the claim and determines whether the claimant is eligible for benefits .

if so , the rating specialist assigns a percentage rating .

if va finds that a veteran has one or more service - connected disabilities with a combined rating of at least 10 percent , the agency will pay monthly compensation .

the veteran can claim additional benefits over time , for example , if a service - connected disability worsens or surfaces at a later point in time .

in november 2007 , dod and va began piloting the ides , a joint disability evaluation system to eliminate duplication in their separate systems and to expedite receipt of va benefits for wounded , ill , and injured servicemembers .

the ides merges dod and va processes , so that servicemembers begin their va disability claim while they undergo their dod disability evaluation , rather than sequentially , making it possible for them to receive va disability benefits shortly after leaving military service .

specifically , the ides merges dod and va's separate exam processes into a single exam process conducted to va standards .

this single exam — which may involve more than one medical examination ( for example , by different specialists ) — in conjunction with the servicemembers' medical records , is used by military service pebs to make a determination of servicemembers' fitness for continued military service , and by va as evidence of service - connected disabilities .

the single exam may be performed by medical staff working for either va , dod , or a private provider contracted with either agency .

consolidates dod and va's separate rating phases into one va rating phase .

if the informal peb has determined that a servicemember is unfit for duty , va rating specialists prepare two ratings — one for the conditions that dod determined made a servicemember unfit for duty , which dod uses to provide military disability benefits , and the other for all service - connected disabilities , which va uses to determine va disability benefits .

ratings for the ides are prepared by rating specialists at va's baltimore and seattle regional offices .

provides va case managers to perform outreach and nonclinical case management and explain va results and processes to servicemembers .

by consolidating dod and va's separate medical exams and ratings , the ides eliminates several steps from the existing “legacy” systems ( see fig .

1 ) .

in designing the ides , dod and va established goals to provide va benefits to active duty servicemembers within 295 days of being referred into the system , and to reserve component members within 305 days .

in establishing the 295- and 305-day goals , they also established timeliness goals for the specific steps of the ides process ( see fig .

2 ) .

dod and va first piloted the ides at 3 washington , d.c. , area military treatment facilities , beginning in november 2007 ( see table 1 ) .

they added 18 military facilities to the pilot in fiscal year 2009 and 6 in fiscal year 2010 .

dod and va stated that expansion to additional sites was intended to assess the ides system in a variety of geographic areas and to test the agencies' capacity to handle additional caseload .

according to dod , the 27 pilot sites represented almost half of the servicemembers in the military services' disability evaluation systems .

in their planning documents for the ides pilot , dod and va stated that they were basing their evaluation of the effectiveness of the ides pilot on whether it has achieved three key goals relative to the legacy process: increased servicemember satisfaction , improved case - processing time , and a reduction in servicemember appeal rates .

in addition , they also examined ides program costs .

to determine whether they have achieved their goals , the agencies surveyed servicemembers in the ides pilot and legacy systems and are using a data system — called the veterans tracking application ( vta ) — that enables them to track case processing time and appeals .

they have been monitoring their progress on these goals through weekly reports .

in august 2010 , dod and va officials issued an interim report to congress summarizing their evaluation results to date .

in this report , the agencies concluded that servicemembers who went through the ides pilot were more satisfied than those who went through the legacy system , and that the ides process met the agencies' goals of delivering va benefits to active duty servicemembers within 295 days and to reserve component servicemembers within 305 days .

specifically , they reported that , as of february 2010 , the ides process took an average of 274 days to complete for active duty servicemembers and 281 days for reserve component members who , according to the interim report , comprise 15 percent of ides participants .

furthermore , they concluded that the ides pilot has achieved a faster processing time than the legacy system , which they estimated to be 540 days .

while overall results were promising , data presented in the report had some limitations , and the report itself did not include certain analyses .

for example , dod officials told us that the 540-day estimate for the legacy process was based upon a review of a small and nonrepresentative sample of legacy cases during the agencies' “table top” planning exercise in august 2007 .

in addition , although dod officials told us that they planned to compare average processing times of pilot cases with a broader sample of legacy cases , and to determine whether fewer servicemembers are appealing the findings of informal pebs and formal pebs in the pilot compared with the legacy , the interim report did not include these comparisons .

in addition , in their planning documents for the ides pilot , dod and va indicated that they were establishing a goal to deliver va benefits to 80 percent of members in the ides pilot within the 295- and 305-day time frames .

however , their interim report did not discuss whether this goal was met .

our review of dod and va's data and weekly reports generally confirm dod and va's findings , as of early 2010 .

however , while the agencies have largely met their overall goal to increase servicemember satisfaction and met their timeliness goal as of february 2010 , since that time , case processing times have been steadily increasing as the caseload has increased .

in addition , not all of the service branches are achieving the same results .

servicemember satisfaction: our review of the survey data that dod used for the interim report ( as of february 2010 ) , as well as a recent weekly report , indicate that , on average , servicemembers in the ides process have had higher satisfaction levels than those who went through the legacy process .

in addition , a higher percentage of servicemembers who went through the ides process felt that the process was fair compared with those who went through the legacy system .

however , servicemembers in the air force who went through the ides pilot indicated less satisfaction with the process than those who went through the legacy system , though air force members represented a small proportion of pilot cases — about 7 percent of those enrolled in the pilot .

we reviewed the agencies' survey methodology and generally found their survey design and conclusions to be sound ( see app .

i for further information on our review ) .

average case processing times: the agencies have been meeting their 295- day and 305-day timeliness goals for much of the past 2 years , but more recent weekly reports indicate case processing time has been increasing and that they are now missing their goal for active duty members .

as of august 29 , 2010 , the agencies missed the goal for active duty servicemembers by 1 day , while still meeting the 305-day goal for reserve component members by 7 days .

processing times have increased as caseload has increased , from about 5,750 active cases in february to about 9,650 cases in august 2010 .

we reviewed the reliability of the vta data upon which the agencies based their analyses and generally found these data to be sufficiently reliable for purposes of these analyses .

the increases in overall case processing time and caseloads mirror the trends at individual sites .

for each pilot site , case processing times have generally increased as workloads have increased .

for example , figure 3 shows the case processing times 1 year or more after implementation and in august 2010 for the first seven pilot sites .

of the four military services , only the army and navy were achieving the 295- and 305-day goals on average , as of february 2010 , and only the army was achieving these goals as of august 2010 .

because the army comprises a large proportion of cases ( approximately 60 percent of ides pilot cases that have completed the whole process ) , it has lowered the overall average processing time to near or below the established goals .

figure 4 shows the average case processing times for active duty , by service , as of august 2010 .

 ( see app .

ii for reserve component. ) .

as of february 2010 , the agencies also had not met the goal of processing 80 percent of all pilot cases within targeted time frames .

specifically , about 60 percent of active duty pilot cases have been completed within 295 days , according to our analysis of the agencies' case data intended for their interim report .

further , none of the four military services have achieved this goal , although the army has had the highest rate of cases ( 66 percent ) meeting the goal , while only 42 percent of air force cases were processed within the time frame ( see fig .

5 for active duty and app .

ii for reserve component ) .

dod and va planned to compare the case processing times of servicemembers in the ides pilot and servicemembers who , between fiscal years 2005 and 2009 , were enrolled in the legacy system at pilot sites prior to pilot implementation , but significant gaps in the legacy case data preclude reliable comparisons .

dod compiled the legacy case data from each of the military services and the va , but the military services each had slightly different disability evaluation processes , used different data systems , and did not track the same information .

as a result , information needed to conduct a comparison is not available for all services .

for example , the navy , marine corps , and air force legacy data do not have information on when the servicemember was referred into the disability evaluation system and , as a result , case - processing time for the legacy system dod - wide cannot be known .

dod officials said they planned to estimate legacy case processing time by approximating the dates that servicemembers in the navy , marine corps , and air force were referred into the disability evaluation process , but their methodology was based on a limited number of army cases ( see app .

i for further information ) .

in addition , for legacy cases across all military services , va was not able to provide data on the date va benefits were delivered , so total case processing time from referral to delivery of va benefits cannot be measured .

however , while legacy case data are not sufficiently reliable for comparison with the ides overall , the army's legacy data appear to be reliable on some key processing dates , making some limited comparisons possible .

our analysis of army legacy data suggests that , under the legacy process , active duty army cases took 369 days to complete the dod legacy process and reach the va rating phase — though this figure does not include time to complete the va rating and provide the benefits to servicemembers — compared with 266 days to deliver va benefits to servicemembers under the pilot , according to the agencies' august weekly report .

however , army comparisons cannot be generalized to the other services .

the agencies also planned to compare servicemembers' appeal rates in the pilot and legacy systems , but similar gaps in the legacy data preclude a comparison dod - wide .

for example , the legacy data that dod compiled did not contain data on appeals of informal peb decisions to the formal peb in the navy and marines , and consequently the rate of appeals across the military in the legacy system is unknown .

while the army's appeals data appear to be more reliable , potentially making some limited comparisons possible , the agencies' method for comparing pilot appeals with legacy has limitations .

dod officials told us they are planning to compare the proportion of informal peb decisions that were appealed to a formal peb hearing in the pilot and legacy systems .

however , this will not take into account that , under the legacy system , a servicemember could appeal the informal peb's decision for two reasons — because they were dissatisfied with the fitness decision or the disability rating the peb assigned , while in the ides , they can only appeal the informal peb decision to a formal peb if they are dissatisfied with the fitness decision .

under the ides , servicemembers who disagree with the disability rating can appeal to va for a rating reconsideration .

by not including appeals to va for rating reconsiderations , the agencies may overestimate the decrease in appeals in the ides pilot .

for example , our analysis of data as of early 2010 for the army indicates that army members in the pilot appealed 7.5 percent of informal peb decisions .

however , when appeals to va are factored in , 13 percent of army members in the pilot filed an appeal , which is the same proportion as in the legacy system ( see fig .

6 ) .

in addition to evaluating the three goals , dod and va initially planned a cost - benefit analysis of the ides program but have only completed an analysis of costs .

according to data provided to us in august 2010 , dod projects that costs directly associated with implementing the ides will be $63 million greater per year when compared with the legacy system , after full expansion of the ides .

in october 2010 , va reported to us total ides cost estimates of approximately $50 million for fiscal year 2011 — about $33 million for vba , which provides va case managers and rating staff to the ides , and $17 million for the veterans health administration ( vha ) , which provides medical staff to perform the single exams .

these analyses did not quantify the value of potential benefits created by the pilot , for example time savings from dod physicians no longer needing to perform disability examinations , which allows them to perform other duties .

as dod and va tested the ides at different facilities and added caselo to the pilot , they encountered several challenges that led to delays in certain phases of the process .

among these were insufficient staffing , challenges in conducting the single exams , logistical challenges related integrating va staff , as well as housing and managing servicemembers going through the ides .

dod and va were able to address some , but not all , of these challenges as they arose .

dod and va have not provided sufficient numbers of staff in many of th ides locations , affecting their ability to complete certain phases of the ides process within the goals they established .

officials at most of the 1 pilot sites we visited said they have experienced staffing shortages to a t least some extent , with a few sites — fort ca particular — experiencing severe shortages .

rson and fort stewart , in va or contract examiners: at three pilot sites we visited — fort carson , fort polk , and fort stewart — local officials said that a lack of va or va contractor staff who could perform the required single medical exams led to bottlenecks in the process .

for example , as of august 2010 , exams at fort carson have taken an average of 140 days to complete for active duty servicemembers , according to the agencies' data , far from achieving their goal to complete single medical exams within 45 days ( see fig .

7 ; s ee also app .

ii for processing times for reserve component members ) .

across all pilot sites , exams have taken 68 days to complete for active duty servicemembers , on average , with 8 of the 27 pilot sites meeting the 45 goal .

examiners .

for instance , fort carson's ides process was particularly hampered by a lack of mental health specialists ; in contrast , va officials serving the fort polk pilot site said perform specialty medical exams but did not have enough examiners to complete general medical exams .

the 8 pilot sites that met the 45-day goal for completing single exams include 2 air force sites , 5 army sites , and 1 navy site that met the 45-day goal for servicemembers in both the navy and marine corps .

one additional site ( camp pendleton ) met the 45-day goal for navy members but did not meet it for marine corps members .

the navy peb determines fitness decisions for servicemembers in the marine corps .

va rating staff: officials at the baltimore rating office — one of the two va offices that conduct disability ratings for the ides pilot — expressed significant concerns that they were understaffed , in part due to staff turnover .

dod and va data show that , overall , the va rating offices are not meeting the agencies' goal to complete ratings within 15 days , taking 39 days on average for active duty servicemembers and 42 days for reserve component members .

we could not determine case processing times at each individual va rating office , since dod and va's weekly monitoring reports do not provide processing times for the rating phase by office .

the weekly reports also do not provide data on caseloads at each office .

although the baltimore office currently has fewer rating staff than seattle , va officials said that it has prepared ratings for the majority of ides pilot cases , based on the way in which va has allocated cases between the two offices .

the baltimore office handles cases for the air force , navy , marines , and 5 of the 15 army pilot sites , while the seattle office conducts ratings for the remaining 10 army pilot sites .

va officials said that to address staffing shortages in baltimore , they have assigned staff from other va offices to assist the baltimore office .

va case managers: dod and va have set a target for each va case manager to handle no more than 30 cases at a time , but two sites we visited — fort carson and fort stewart — appeared to be far from these targets .

at fort carson , three va case managers told us they were handling about 900 cases when we visited in april 2010 , for a caseload ratio of roughly 1:300 .

at the time of our visit in june 2010 , fort stewart had over 750 active cases with two va case managers , for a caseload ratio of approximately 1:375 .

although local officials we spoke with at both sites told us that the numbers of va case managers were insufficient , an official at va's central office told us that va bases staffing of case managers on the number of new ( not pending ) cases each month , and the agencies' data indicates the average number of new cases per va case manager has been about 25 at each site .

the va official said that the reason local case managers felt understaffed was likely due to other process inefficiencies .

in addition , the official told us va can reassign staff from other va programs to assist case managers at ides pilot sites as needed .

at some of the other pilot sites we visited , local officials also told us they had concerns at times about the numbers of va case managers available to handle the site's caseload , but va was able to add staff .

va case managers at two air force sites we visited — travis and vance air force bases — indicated that their caseloads were manageable .

we were unable to independently determine the extent to which va is meeting its caseload target because va does not collect national data on actual caseloads per case manager .

dod board liaisons: at most of the sites we visited , local officials expressed concerns about insufficient numbers of dod board liaisons , who serve as servicemembers' dod case managers .

dod guidance has been inconsistent on the caseload target for dod board liaisons .

while dod's operations manual for the ides pilot sets a caseload target of at most 30 cases per board liaison , guidance on the general disability evaluation system sets the target at a maximum of 20 cases per liaison .

dod and va's documents related to planning for ides expansion indicate that dod is striving for a 1:20 caseload target in the ides .

however , 19 of the 27 pilot sites did not meet the 1:30 caseload target , and 23 did not meet the 1:20 target ( see fig .

10 ) .

local dod and va officials attributed staffing shortages to higher than anticipated caseloads and difficulty finding qualified staff in rural areas .

at several of the pilot sites we visited , officials said that caseloads were higher than the initial estimates that they had based staffing levels upon .

dod officials said that they had based caseload estimates on a 1-year history of caseload at each site .

while some sites have added staff as caseloads increased , others , such as fort polk , located in central louisiana , have had difficulty finding qualified staff , particularly physicians , in this rural area .

two of the pilot sites we visited — fort carson and fort stewart — were particularly challenged to provide staff in response to surges in caseload , which occurred when army units were preparing to deploy to combat zones .

through the army's predeployment medical assessment process , large numbers of servicemembers were determined to be unable to deploy due to a medical condition and were referred to the ides within a short period of time , overwhelming the staff .

these two sites were unable to quickly increase staffing levels , particularly clinicians performing the single exam .

the va medical center conducting the single medical exams for fort carson experienced turnover among its examiners at the same time that the caseload surged , while at fort stewart , the contractor performing the single medical exams had difficulties finding qualified physicians in a rural area of georgia .

to address caseload surges , examiners were reassigned from other locations to the pilot sites .

for example , va officials told us they assigned examiners from other va medical centers to the fort carson ides and established a contract with a private - sector provider to complete the exams that va examiners would normally have performed for veterans in the area claiming va disability compensation .

at fort stewart , the contractor told us that they had reassigned examiners from their atlanta clinic to fort stewart .

issues related to the completeness and clarity of single exam summaries were an additional cause of delays in the va rating phase of the ides process .

officials from va rating offices said that some exam summaries did not contain information necessary to make a rating or fitness decision , or were unclear as to the examiners' diagnoses and conclusions .

as a result , va rating office staff must ask the examiner to clarify the summary or add information and , in some cases , redo the exam , adding time to the process .

in addition , va rating staff told us that it is sometimes unclear who they should contact if they identify insufficiencies in an exam summary and finding the appropriate person also adds time .

however , the extent to which insufficient exam summaries caused delays in the ides process is unknown because dod and va's vta system does not track whether an exam summary had to be returned to the examiner or whether it was resolved .

due to these limitations , va officials told us that va rating staff have created logs of outstanding insufficient exams and sent them to va examiners to correct .

va officials attributed the problems with exam summaries to several factors , including the difficulty of conducting exams for ides pilot cases , which may entail evaluating many complex medical conditions and may involve several physicians and specialists .

in addition , va officials indicated that , at sites with exam backlogs , such as at fort carson , it may be difficult for examiners to ensure quality when are trying to complete exams quickly .

furthermore , va staff noted that some errors were common , such as missing information for musculoskeletal conditions and traumatic brain injury , suggesting that some examiners may not be aware of the information required for certain types of medical conditions .

finally , while examiners are supposed to receive the servicemember's complete medical records prior to the date of the exam , some va examiners also told us that they did not receive the records in time for the exam in some cases , or the records were not well - organized .

as a result , they lacked key information , such as the servicemember's medical history and results of laboratory tests .

according to the agencies' operations manual for the ides pilot , the dod board liaison should compile the complete medical records within 10 days of an active duty servicemember being referred to the ides , but some dod officials we spoke with said that it is sometimes difficult to obtain all of the records , particularly when servicemembers have received treatment from private - sector physicians .

in addition , while the single exam in the ides eliminates duplicative exams performed by dod and va in the legacy system , it raises the potential for there to be disagreements about diagnoses of servicemembers' conditions , with implications for their disability ratings , as well as processing times .

dod officials we spoke with in our interviews and site visits also said that their physicians sometimes disagree with va medical diagnoses , particularly for mental health conditions , and this has extended processing times for some cases .

in addition , since medical diagnoses are a basis for va's disability ratings , dod may subsequently disagree with the ratings va completed for determining dod disability benefits .

the number of cases with disagreements about diagnoses and ratings , and the extent to which they have increased processing time , are unknown because the vta system does not track when a case has had such disagreements .

however , officials at 4 of the 10 pilot sites we visited said that military physicians have disagreed with va diagnoses in at least some cases .

in addition , peb officials in two of the three military services — the army and the navy — said that they have sometimes disagreed with the rating va produced for determining dod disability benefits .

an example can illustrate the implications of differences in diagnoses .

officials at army pilot sites informed us about cases in which a military physician had treated members for a mental condition , such as anxiety or depressive disorder .

however , when the members went to see the va examiners for their single exam , the examiners diagnosed them with posttraumatic stress disorder ( ptsd ) .

when such cases were sent to the peb , it returned them to the meb because it was unclear to the peb which conditions should be the basis of their decision on the servicemembers' fitness for duty .

the cases then languished because the military physicians experienced difficulties resolving the discrepancy with the va diagnosis .

to address such processing delays , the army issued guidance in february 2010 stating that meb physicians should review all of the medical records ( including the results of the single exam ) and determine whether to revise their diagnoses .

if after doing so the meb physician maintains that their original diagnosis is accurate , they should write a memorandum summarizing the basis of their decision , and the peb should accept the meb's diagnosis .

some army officials we spoke with believe that this guidance has been helpful for enabling cases to move forward when there are differences in diagnoses .

the other services do not have written guidance on how to address differences in diagnoses , though navy officials told us that they have provided verbal guidance to their physicians , and air force officials said they have not had cases with significant disagreements about diagnoses .

in some cases , due to the differences in diagnoses , dod has also disagreed with the rating that va prepared for dod disability benefits , particularly in cases involving servicemembers with mental health conditions .

for example , army and navy officials told us about cases in which the peb found the servicemember unfit due to a mental condition , such as major depression , and asked va to complete a rating for this condition .

however , va returned a rating for occupational and social impairment caused by ptsd , since the examiner had diagnosed the member with ptsd .

dod requires a rating for only the conditions for which the member was found unfit for duty because it can only provide disability benefits for those conditions .

however , according to va regulations for rating mental disorders , va does not rate each mental health condition individually ; rather , va bases its rating on the degree to which the combination of symptoms of mental disorders cause occupational and social impairment .

as such , when rating mental health conditions for ides cases , va officials said that rating specialists would consider both the symptoms of mental conditions diagnosed by dod physicians and those identified by the va examiner .

both army and navy peb officials said that they generally accept va ratings in these cases , even though the rating is not for the unfitting conditions alone .

however , they noted that , if they feel the va rating is in error , there is no guidance on how disagreements about servicemembers' ratings should be resolved .

army and navy officials said that they may return the case to va and informally requ est that they reconsider the case , though navy peb officials said that they are hesitant to do so because it may further delay the case .

dod and va officials attributed disagreements about diagnoses to several factors .

they noted that va examiners may not have received or reviewed the servicemembers' medical records prior to the exam , and therefore may not be aware of the medical conditions for which the members had been previously diagnosed and treated .

in addition , dod and va identify conditions for different purposes in the disability evaluation system .

while dod identifies conditions that make a servicemember unable to perform their duties , va identifies all service - connected conditions .

as such , va examiners are likely to identify a broader set of conditions than dod's physicians .

in addition , local officials we spoke with in some of our site visits said that servicemembers may be more willing to disclose all of their medical conditions to va than to dod because va could potentially compensate them for all of the conditions .

furthermore , va officials noted that servicemembers' health conditions may have changed between the time dod physicians identified the conditions and va performed the exam .

finally , dod and va officials said that differences in opinions about diagnoses are common among physicians , particularly in the mental health field .

for example , they noted that it be can be difficult to distinguish ptsd from anxiety , depression , and other mental health conditions .

dod and va officials at several pilot sites said that they experienced some logistical challenges integrating va staff at the military facilities .

at a few sites , it took time for va staff to receive common access cards needed to access the military facilities and to use the facilities' computer systems .

during the time that va staff did not have access cards , they were unable to access va computer systems , such as those for establishing the va claim , requesting exams , and viewing exam results , via dod's network .

in addition , dod and va staff noted several difficulties using the agencies' multiple information technology ( it ) systems to process cases .

while the agencies both use the vta system to manage cases , va also has it systems for completing certain tasks , and the military services also have their own case tracking systems .

this causes dod and va staff to have to enter the same data multiple times into different it systems .

in addition , some va staff working on military bases reported that using the military services' computer systems to access va systems has significantly slowed down computer processing speeds .

finally , dod and va staff cannot directly access each others' systems , making it more cumbersome for case managers to determine the status of servicemembers' cases .

for example , without access to va's system for managing exams , dod board liaisons cannot readily provide servicemembers with information on when or where their exams are scheduled and must contact va case managers to obtain the information .

a few sites we visited were able to address some it issues .

for example , at fort polk , va officials said they were adding a new telecommunications line to provide faster computer processing speeds for their staff .

in addition , va physicians working at military facilities need to be credentialed by dod before they can begin working on base , which involves verification of their education , license , and clinical history .

some va officials said that this process could take 1 month or longer to complete .

although many dod and va officials we interviewed at central offices and pilot sites felt that the ides process expedited the delivery of va benefits to servicemembers , several also indicated that it may increase the amount of time servicemembers are in the military's disability evaluation process .

data on legacy cases are not sufficiently reliable to determine whether this is the case military - wide , but army data appear to be sufficiently reliable to allow for some limited analysis .

our analysis of army pilot and legacy data as of early 2010 shows that compared with legacy cases , active duty cases in the pilot took on average 39 more days to reach the end of the peb phase — the last step of the dod disability evaluation process before servicemembers begin transitioning from military service or , if found fit , back to duty .

for reserve component cases in the army , ides pilot cases took on average 17 more days to reach the end of the peb phase , compared with legacy cases .

it was not possible to conduct this analysis for the other military services because their legacy data lacked information on when servicemembers were referred into the disability evaluation system .

some dod officials noted that the increased time that servicemembers are in the military's disability evaluation process means that they must be cared for and managed for a longer period .

officials in our site visits and interviews said that some pilot sites have had challenges housing servicemembers in the ides , in part due to servicemembers being in the process longer .

for some servicemembers in the disability evaluation system , the military services may move them to temporary medical units or , for those needing longer - term medical care or complex case management , to special medical units such as a warrior transition unit in the army or wounded warrior regiment in the marine corps .

however , these units were full at a few pilot sites we visited , or members in the ides did not meet the criteria for entering the special medical units .

where servicemembers remain with their units while going through the disability evaluation system , the units cannot replace them with able - bodied members .

officials at fort carson said that this created a challenge for combat units .

because most servicemembers in the ides did not meet the criteria for entering warrior transition units , combat units had to find another organizational unit to take charge of members in the ides so they could replace them with soldiers ready and able to deploy to combat areas .

in addition , officials at naval medical center san diego and fort carson said that some members are not gainfully employed by their units and , left idle while waiting to complete their disability evaluation process , are more likely to engage in negative behavior , potentially resulting in their being discharged due to misconduct and a forfeiture of disability benefits .

we were unable to assess the extent or cause of this problem because the vta system that tracks servicemembers in the ides does not capture sufficient detail on reasons for servicemembers dropping out of the ides , or which organizational unit ( s ) the servicemember was assigned to while in the ides .

dod officials also noted that servicemembers benefit from continuing to receive their salaries and benefits while their case undergoes scrutiny by two agencies , though some also acknowledged that these additional salaries and benefits create costs for dod .

dod and va plan to expand the ides to sites worldwide on an ambitious timetable — to 113 sites during fiscal year 2011 , a pace of about 1 site every 3 days .

expansion is scheduled to occur in four stages , beginning with 28 sites in the southeastern and western united states by the end of december 2010 .

dod and va have many efforts under way to prepare for ides expansion .

at each site , local dod and va officials are expected to work together to prepare for implementation .

this includes completing a site assessment matrix — a checklist of information dod and va officials at each site should obtain and preparations they should make .

while most pilot sites had used a site assessment matrix to prepare for ides implementation , the agencies completed a significant revision of the matrix in august 2010 , and they now request additional information and documentation to address areas where prior ides sites had experienced challenges .

in addition , while during the pilot phase local dod and va officials were encouraged to develop written agreements on ides procedures , the matrix now requests that a written agreement be completed prior to implementing the ides .

finally , senior - level local dod and va officials will be expected to sign the site assessment matrix to certify that a site is ready for ides implementation .

this differs from the pilot phase where , according to dod and va officials , some sites implemented the ides without having been fully prepared .

in addition , in september 2010 , the military services and va held preimplementation training conferences for local dod and va staff .

at the time of our review , the first 28 expansion sites were completing their site assessment matrices .

through the new site assessment matrix and other initiatives under way , dod and va are addressing several of the challenges identified in the pilot phase .

these include ensuring sufficient exam and case management staff , being prepared to deal with surges in caseloads , addressing exam sufficiency issues , and making adequate logistical arrangements .

ensuring sufficient exam resources: the matrix asks whether a site can complete single exams within the ides' 45-day time frame and within dod's tricare access standards .

the matrix asks for detailed information , such as who will conduct the exams ( va , va contractor , or military providers ) , where the exams will be conducted , and va's anticipated overall volume of disability compensation and pension exams in the area .

in addition to the matrix , va has several initiatives under way to increase resources and expedite exams .

va plans to award a new contract under which it can acquire examiners for sites that do not have sufficient staff to perform exams , such as sites located where va does not have medical facilities or in rural areas where va has had difficulty hiring staff .

va has also recently changed its exam policy so that exams performed by nurse practitioners or physician assistants certified to perform disability exams no longer have to be cosigned by a physician , which is expected to expedite completion of more exam reports .

ensuring sufficient va rating staff: va officials said that they have hired new staff to replace those that recently left the baltimore rating office and anticipate hiring a small number of additional staff .

based on caseload projections , they expect that , once the additional staff are hired , the baltimore office will be close to having sufficient rating staff .

although va officials said that the baltimore office conducted ratings for a majority of cases during the ides pilot phase , they have projected that the workload will be divided almost evenly between the baltimore and seattle offices once the ides is fully expanded worldwide .

ensuring sufficient dod peb adjudicators: air force officials informed us they added adjudicators for the informal peb and have since eliminated their case backlog .

they are currently adding adjudicators for the formal peb .

navy peb officials also said that they are adding adjudicators through activation of reserve component personnel for special work and expected that they would be in place by november 2010 .

ensuring sufficient case management staffing: the site assessment matrix also asks whether local facilities will have sufficient trained dod board liaison staff to meet a 1:20 caseload ratio and sufficient va case managers to meet a 1:30 caseload ratio .

in addition , according to dod officials , each of the military services is increasing its board liaison staffing levels to achieve 1:20 caseload ratios .

va officials said that they plan to hire an additional 73 case managers .

coping with caseload surges: the matrix asks sites to provide a longer and more detailed caseload history — a 2-year , month - by - month history — as opposed to the 1-year history that dod based its caseload projections on during the pilot phase .

in addition , the matrix asks sites to anticipate any surges in caseloads , such as those due to seasonal trends .

sites are also expected to provide a written contingency plan for dealing with caseload surges .

in addition , the matrix asks sites to develop a system for communicating updates , such as information on expected caseload surges , to stakeholders .

va officials also said that the army has agreed to keep them better informed of deployments that could result in caseload surges .

further , va officials noted that they are developing a plan for addressing the additional need for examiners during surges , through which va offices with lower demand for disability exams would send examiners to an ides site experiencing a surge in exam workloads .

ensuring the sufficiency of single exams: the site assessment matrix asks sites whether all staff who will conduct exams are trained to va standards and certified by va to conduct disability compensation and pension exams .

in addition , va has begun the process of revising its exam templates , to better ensure that examiners include the information needed for a va disability rating decision and enable them to complete their exam reports in less time .

finally , a va official stated that va is examining whether it can add capabilities to the vta system that would enable staff to identify where problems with exams have occurred and track the progress of their resolution .

for sites that choose to have military physicians perform the single exams , va officials said that they have provided materials to dod from their national training program , and dod has made these materials accessible on its web site .

to help improve the ability of dod board liaisons to obtain servicemembers' medical and personnel records prior to the exam , dod officials said that they are revising their policies to require reserve component units to provide the records when a reserve member is referred to the ides .

ensuring adequate logistics at ides sites: the site assessment matrix asks sites whether they have the logistical arrangements needed to implement the ides , including necessary facilities , it , and transportation for servicemembers to exam locations .

for example , the matrix asks whether the military treatment facility will address the needs of va staff for access cards , identification badges , and security clearances , and whether all va medical providers will be credentialed and privileged to practice at the dod facility .

in terms of it , the matrix asks whether dod sites will enable va staff access to va information systems needed to perform their duties .

the matrix also asks sites to identify it contacts from both va and dod so that they may work together to resolve it problems .

furthermore , dod and va are developing a general memorandum of agreement on ides information sharing .

this agreement is intended to enable dod and va staff access to each other's it systems , for example , to allow dod staff to track the status of va exams .

dod officials also said that they are developing two new it solutions .

according to officials , one system currently being tested would help military treatment facilities better manage their cases .

another it solution , still at a preliminary stage of development , would integrate the vta with the services' case tracking systems so as to reduce multiple data entry .

however , in some areas , dod and va's efforts to prepare for ides expansion do not fully address some challenges or are not yet complete .

ensuring sufficient military physician staffing: while dod and va are taking steps to address shortages of examiners , case managers , and adjudicators , they do not yet have strategies or plans to address potential shortages of military physicians for completing meb determinations .

for example , the site assessment matrix does not include a question about the sufficiency of military providers to handle expected numbers of meb cases at the site , or ask sites to identify strategies for ensuring sufficient military physicians if there is a caseload surge or staff turnover .

ensuring sufficient housing and organizational oversight for ides participants: although the site assessment matrix asks sites whether they will have sufficient temporary housing available for servicemembers going through the ides , the matrix requires only a yes or no response and does not ensure that sites will have conducted a thorough review of their housing capacity prior to implementing the ides .

for example , sites are not asked about the capacity of their medical hold units or special units for wounded servicemembers , or to identify other options if their existing units do not have sufficient capacity for their projected ides caseload .

in addition , the site assessment matrix does not address whether sites have plans for ensuring that ides participants are gainfully employed or sufficiently supported by their organizational units .

addressing differences in diagnoses: according to a dod official , as part of its revision of its ides operations manual , dod is currently developing guidance on how staff should address differences in diagnoses between military physicians and va examiners , and between military pebs and va disability rating staff .

dod anticipated issuing the new guidance in september 2010 , but at the time of our review had not yet done so .

in addition , a va official stated that va is developing new procedures for identifying cases with potential for multiple mental health diagnoses and will ask va examiners to review the servicemembers' medical records and reconcile differing diagnoses .

however , since the new guidance and procedures are still being developed , we cannot determine whether they will resolve discrepancies or disagreements .

significantly , dod and va do not have a mechanism for tracking disagreements about diagnoses and ratings , and consequently , may not be able to determine whether the guidance sufficiently addresses the discrepancies or whether it requires further revision .

as dod and va move quickly to implement the ides worldwide , they have some mechanisms in place to monitor challenges that may arise in the ides .

dod officials said that they expect to continue holding postimplementation “hotwash” meetings , in which they review individual sites' implementation .

in addition , dod and va will continue to regularly collect and report data on caseloads , processing times , and servicemember satisfaction .

furthermore , the new site assessment matrix asks sites to develop plans for va and dod local staff to meet weekly for the first 60 to 90 days after implementing the ides , then no less than monthly to address any identified challenges .

va officials also said that they will continue to prepare a report on an annual basis on challenges in the ides .

to prepare this report , they will obtain input and data from local dod and va officials .

however , dod and va do not have a system - wide monitoring mechanism to help ensure that steps they took to address challenges are sufficient and to identify problems in a more timely basis .

for example , they do not collect data centrally on staffing levels relative to caseload .

consequently , despite efforts to acquire additional staff , as local sites experience staffing turnover in the future , dod and va central offices may not become aware that a site is short - staffed until their monitoring reports show lengthy processing times .

as a result , dod and va may be delayed in taking corrective action , since it takes time to assess what types of staff are needed at a site and to hire or reassign staff .

in addition , without information on when or how often other problems occur , such as insufficient exam summaries or disagreements about diagnoses , dod and va managers may not be able to target additional training or guidance where needed .

furthermore , while dod and va report data on processing times by phase of the process , military treatment facility , and military service , their monitoring reports do not show processing times or caseloads for each va rating office and each of the five pebs ( three army and one each for the navy and air force ) , limiting their ability to identify if specific rating or peb offices are experiencing challenges .

dod and va also lack mechanisms or forums for systematically sharing information on challenges as well as best practices .

for example , while the site assessment matrix indicates that sites are expected to hold periodic meetings to identify local challenges , dod and va have not established a process for local sites to systematically report those challenges to dod and va management and for lessons learned to be systematically shared system - wide .

during the pilot phase , va surveyed pilot sites on a monthly basis about challenges they faced in completing single exams .

such a practice has the potential to provide useful feedback if extended to other ides challenges .

by merging two duplicative disability evaluation systems , the ides shows promise for expediting the delivery of va benefits to servicemembers leaving the military due to a disability .

servicemembers who proceed through the process are able to leave the military with greater financial security , since they receive disability benefits from both agencies shortly after discharge .

further , having both dod and va personnel involved in reviewing each disability evaluation may result in a more thorough scrutiny of cases and informed decisions on behalf of servicemembers .

however , piloting of the system at 27 sites has revealed several significant challenges that require careful management attention and oversight before dod and va expand the system military - wide .

dod and va are currently taking steps to address many of these challenges , and the agencies have developed a site implementation process that encourages local dod and va officials to identify and resolve local challenges prior to transitioning to the new system .

however , given the agencies' ambitious implementation schedule — more than 100 sites in a year — it is unclear whether all of these challenges will be fully dealt with before dod and va deploy the integrated system to additional military facilities .

for example , it is unclear whether sites will have sufficient military physicians to complete key steps of the process in a timely manner .

insufficient staffing of any one part of the process is likely to lead to bottlenecks , delaying not only servicemembers' receipt of disability benefits , but also their separation from the military and reentry into civilian life .

in addition , dod's preparations of sites for the ides do not ensure that military facilities have adequate capacity or plans for housing and providing organizational oversight over servicemembers in the ides , who potentially could remain at the locations for extended periods of time .

furthermore , while integrating va medical exams into dod's disability evaluation system eliminates duplicative exams , it raises the potential for there to be disagreements about diagnoses of servicemembers' conditions , with implications for servicemembers' disability ratings and their dod disability compensation .

while dod is developing guidance to address such disagreements , it is important that the agencies have a thorough understanding of how often and why these disagreements occur and continually review whether their new guidance adequately addresses this issue so as to be able to make improvements where needed .

successful implementation of any program requires effective monitoring .

dod and va currently have mechanisms to track numbers of cases processed , timeliness , and servicemember satisfaction , but they do not routinely monitor factors — such as staffing levels relative to caseload , disagreements about diagnoses , and insufficient exam summaries — that can delay the process .

in addition , they do not monitor timeliness and caseloads for some of the key ides offices , namely each va rating office and each peb .

ultimately , the success or failure of the ides will depend on dod and va's ability to sufficiently staff local sites , the va rating offices , and the pebs , and to resolve other challenges not only at the initiation of the transition to ides but also on an ongoing , long - term basis .

by not monitoring staffing and other risk factors , dod and va may not be able to ensure that their efforts to address these factors are sufficient or to identify problems as they emerge and take immediate steps to address them before they become major problems .

to ensure that the ides is sufficiently staffed and that military treatment facilities are prepared to house personnel in the ides , we recommend that the secretary of defense direct the military services to conduct thorough assessments prior to each site's implementation of the ides of the following three issues: the adequacy of staffing of military physicians for completing meb determinations at military treatment facilities ; contingency plans should be developed to address potential staffing shortfalls , for example , due to staff turnover or caseload surges ; the availability of housing for servicemembers in the ides at military facilities ; alternative housing options should be identified if sites do not have adequate capacity ; and the capacity of organizational units to absorb servicemembers undergoing the disability evaluation ; plans should be in place to ensure servicemembers are appropriately and constructively engaged .

to improve their agencies' ability to resolve differences about diagnoses of servicemembers' conditions , and to determine whether their new guidance sufficiently addresses these disagreements , we recommend that the secretaries of defense and veterans affairs take the following two actions: conduct a study to assess the prevalence and causes of such establish a mechanism to continuously monitor disagreements about diagnoses between military physicians and va examiners and between pebs and va rating offices .

to enable their agencies to take early action on problems at ides sites postimplementation , we recommend that the secretaries of defense and veterans affairs develop a system - wide monitoring mechanism to identify challenges as they arise in all dod and va facilities and offices involved in the ides .

this system could include: continuous collection and analysis of data on dod and va staffing levels , sufficiency of exam summaries , and diagnostic disagreements ; monitoring of available data on caseloads and case processing time by individual va rating office and peb ; and a formal mechanism for agency officials at local dod and va facilities to communicate challenges and best practices to dod and va headquarters offices .

we provided a draft of this report to dod and va for review and comment .

the agencies provided written comments , which are reproduced in appendixes iii and iv .

dod and va generally concurred with our recommendations .

each agency also provided technical comments , which we incorporated as appropriate .

dod concurred with our recommendation to ensure that , before the ides is implemented at each new site , a thorough assessment be done of the site's staffing adequacy , the availability of housing for servicemembers in the ides , and the capacity of organizational units to appropriately and constructively engage servicemembers in the ides .

however , dod stated that the ides site assessment matrix addresses plans to ensure that servicemembers are gainfully employed while in the ides .

we changed our report to more clearly indicate that the site assessment matrix does not , in fact , address such plans .

we believe that specifically identifying this in the matrix could help local dod officials , including servicemembers' unit commanders , focus on ensuring gainful employment or other support .

dod concurred , and va concurred in principle , with our recommendation to study and establish mechanisms to monitor diagnostic differences .

va identified a plan to study the prevalence and causes of diagnostic differences and determine by july 1 , 2011 , whether mechanisms are needed .

dod stated that it expects , as diagnostic differences are monitored and studied , that the agencies will address and resolve many of the issues identified in our report .

we agree that the planned study could yield valuable insights on how to resolve diagnostic differences but emphasize that continuous monitoring of such differences over a period of time may be needed to assess the extent and nature of such differences , as well as the success of any actions to address them .

both agencies concurred with our recommendation to develop monitoring mechanisms to help them take early actions on problems that may arise at ides sites postimplementation .

va stated that the vta system currently has data that can be monitored by peb and va rating site , and dod said its weekly monitoring report could be modified to present these data .

also , vha plans to monitor the ides exam workload , including numbers of exam requests compared with forecasts , exam timeliness , and insufficient exams .

implementation is scheduled for december 31 , 2010 .

in terms of identifying site implementation problems for quick resolution , dod stated that the military services bring sites' challenges and best practices to the disability advisory council , a dod body that includes va representatives , which is being re - chartered as part of the benefits executive council , a subgroup of the va - dod joint executive council .

va and dod's plans sound promising and consistent with our recommendations provided that they allow for ongoing monitoring of site staffing levels and create a systematic way for local dod and va staff to communicate their challenges or best practices , enabling the agencies to identify and address problems at an early stage .

we are sending copies of this report to the appropriate congressional committees , the secretary of defense , the secretary of veterans affairs , and other interested parties .

the report is also available at no charge on the gao web site at www.gao.gov .

if you or your staff members have any questions about this report , please contact me at ( 202 ) 512-7215 or at bertonid@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

staff members who made key contributions in this report are listed in appendix v .

in conducting our review of the integrated disability evaluation system ( ides ) piloted by the departments of defense ( dod ) and veterans affairs ( va ) , our objectives were to examine ( 1 ) the results of dod and va's evaluation of the ides pilot , ( 2 ) challenges in implementing the piloted system to date , and ( 3 ) dod and va plans to expand the piloted system and whether those plans adequately address potential challenges .

we conducted this performance audit from november 2009 to december 2010 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

to address objective 1 , we reviewed dod and va policy guidance , reports , and analysis plans to determine how the agencies are evaluating the pilot's effectiveness and to obtain information on their results .

we also reviewed the relevant requirements of the national defense authorization act of 2008 as it pertains to this review .

in addition , we interviewed officials responsible for the evaluation at dod's office of the deputy under secretary of defense for wounded warrior care & transition policy ( wwctp ) , dod's defense manpower data center , and two organizations that dod has contracted with to perform the evaluation — booz allen hamilton and westat .

we then tested the reliability of the data the agencies are using for their evaluation — data from surveys of servicemembers , ides case data from the veterans tracking application ( vta ) system , and legacy case data that dod's wwctp obtained from the military services .

finally , we conducted some analyses of ides and legacy case data for the army to compare the two systems on timeliness and appeal rates , using elements of the data that we found to be reliable , but these comparisons have limitations and are not generalizable to other military services .

the sections below describe our data reliability work and our analysis of army data in further detail .

dod and va have been surveying servicemembers going through the ides pilot , and a comparison group of veterans who went through the standard “legacy” disability evaluation system , to determine whether the ides pilot has improved servicemember satisfaction .

the agencies survey all servicemembers in the ides pilot at three points in time — following their completion of the medical evaluation board ( meb ) of the disability evaluation process , completion of the physical evaluation board ( peb ) , and during the transition phase .

to create a comparison group , the agencies sampled veterans who have been through the legacy system at current pilot sites .

their sampling methods were designed to ensure that the pilot and legacy groups were of comparable size and had similar proportions of servicemembers found unfit for duty .

dod and va are analyzing the differences between the pilot and legacy groups' average responses on four “survey composites,” or general categories composed of several survey questions: overall experience , fairness , dod board liaison officer customer service , and va case manager customer service .

we reviewed the reliability of surveys dod and va are using to obtain information on satisfaction levels by examining their survey design and analysis .

to do so , we interviewed officials at dod's defense manpower data center and westat responsible for implementing the survey , as well as officials at wwctp and booz allen hamilton responsible for designing the survey and analyzing the survey data .

we also reviewed the survey instruments , response rates , data analysis plans , analysis results , and survey data as of february 28 , 2010 .

we found dod's survey methodology — and the data derived using that methodology — to be reliable for purposes of comparing servicemembers' satisfaction levels in the ides and legacy disability evaluation systems .

dod and va are collecting data on ides pilot cases through the vta and are using these data to conduct ongoing monitoring of case processing times and appeal rates , with the results presented in weekly reports .

va manages vta , but evaluation of the data is primarily conducted by staff at dod's wwctp and booz allen hamilton .

for their august 2010 interim report to congress , dod staff created a data set used to compare pilot and legacy processing times and appeal rates .

this data set included ides pilot cases as of february 28 , 2010 , with the earliest case started in november 2007 .

the data set also included data , as of january 31 , 2010 , on legacy cases started between fiscal years 2005 and 2009 at the first 21 sites operating the ides pilot , prior to pilot implementation .

the agencies also matched legacy case data from each of the military services with va data , in order to capture additional processing time it took for servicemembers to navigate the va disability claims process .

because the data set was created from february 2010 pilot data , it only included about one - third of the ides pilot cases that were completed as of august 29 , 2010 .

the february 2010 data set included cases from 17 of the 27 current pilot sites , and 7 of the 17 sites — including some of the pilot sites with the largest caseloads such as fort carson and camp lejeune — had fewer than 20 completed cases each when the data set was created .

to assess whether the data dod and va are using for their monitoring and evaluation are reliable , we obtained the early 2010 data set that the agencies planned to use for their evaluation report to congress .

we restricted our reliability assessments to the specific variables that the agencies used in their analyses .

following steps detailed below , we found that the ides pilot case data were sufficiently reliable for our analyses , but that the legacy case data were incomplete with respect to data elements key to measuring case processing time and appeal rates .

to assess the reliability of the agencies' ides pilot data , we interviewed va database managers responsible for vta , reviewed vta manuals and guidance , conducted electronic tests of the data and , for a small , random sample of cases , checked the data against case files .

through our interviews and document reviews , we concluded that the agencies have sufficient internal controls to give reasonable assurance that the data are complete .

our electronic testing of the data generally found low rates of missing data and errors in completed ides cases .

in these tests , we considered a data element to be sufficiently reliable for purposes of using in our report if 15 percent or less of the data were missing or had errors .

using this standard , we determined that one data element for ides cases — the date that servicemembers separated from the military — was not reliable , because: ( 1 ) it was missing in 19 percent of completed cases and ( 2 ) in cases where the date was present , more than 30 percent appeared to have errors ( for example , the date was before a step of the process that it should have followed ) .

we also conducted a trace - to - file process to determine whether date fields in the vta system were an accurate reflection of the information in the ides case files .

specifically , we compared 12 date fields in the vta against a random sample of paper files for 54 completed cases: 24 from the three army pebs , 10 from the air force peb , and 20 from the navy peb ( 10 navy cases and 10 marine corps ) .

in comparing these dates , we allowed for a 10 percent discrepancy in dates — i.e. , a difference of 2 to 10 days , depending on the date and phase of the process — to allow for the possibility that dates may have been entered into the database after an event took place .

the trace - to - file process resulted in an overall accuracy rate of 84 percent .

for five data elements key to dod and va's evaluation of the ides pilot , we found that vta dates reflected dates in the case files 85 percent of the time or better .

for six key data elements — i.e. , the end dates of the exam and meb phases , the start of the peb phase , the date a va rating request was made , the date of the final disposition , and the date servicemembers received va benefits — the vta dates matched case file dates between 70 to 85 percent of the time .

although we considered these dates sufficiently reliable to include in this report , these dates should be interpreted with more caution .

the separation date was accurate less than 70 percent of the time and did not meet our standards of reliability .

to assess the reliability of the legacy data that the agencies planned to compare the ides pilot against , we tested the data electronically , and found that data for key dates and appeals indicators had significant gaps because the services did not collect the same information for legacy cases that were collected for pilot cases ( see table 2 ) .

for example , only army cases had information on when servicemembers were referred to the meb process .

in addition , the legacy data did not include the date on when servicemembers received va benefits — which is necessary for measuring the full length of the legacy process .

without sufficient data on the beginning ( when servicemembers were referred into the system ) or end of the process ( when they received va benefits ) , we concluded that the full case processing time in the legacy system cannot be known .

we also concluded that comparisons could not be made between the legacy and ides pilot on appeal rates because only army and air force cases had information on whether servicemembers appealed the informal peb decisions .

in addition to reviewing the reliability of the ides pilot and legacy data , we reviewed how dod and va are using the data for their comparisons of the two disability evaluation systems .

through interviews with officials at dod's wwctp and booz allen hamilton and documents they provided us , we understand that dod planned to address gaps in the legacy data by: ( 1 ) approximating the referral dates in air force , marine corps , and navy cases using army data and ( 2 ) using dates when cases were ready to be rated by va to approximate the end of the process .

specifically , to approximate referral dates , they said they would use the average time for army cases between when the servicemember was referred and when the meb documentation identifying the servicemember's potentially unfitting medical conditions ( i.e. , the narrative summary ) was completed , which they calculated to be 60 days .

for navy and marine corps cases , they then subtracted 60 days from the date of the narrative summary to estimate a referral date and , for air force cases , they did so from the date of the meb decision .

however , because only 11 percent of army legacy cases had a narrative summary date , the estimate of 60 days is based on a small number of cases ( see table 3 ) .

to address the lack of data on the date va benefits were delivered , dod planned to use the date that va determined a case was ready to be rated to approximate the end of the process , though this would underestimate the length of time it took to deliver va benefits in the legacy process .

for objective 1 , we presented information on average processing time in the ides , both overall and by military service , using information presented by dod and va in their weekly monitoring reports .

where information was not available in the weekly reports , we conducted our own analysis using the early 2010 data set that dod and va intended to use for their report to congress .

specifically , we used these data to determine the proportion of pilot cases meeting the 295-day goal for active duty servicemembers and the 305-day goal for reserve servicemembers .

in addition , although limitations in the legacy data preclude reliable comparisons between the ides pilot and legacy systems for all the military services , the army legacy data on when servicemembers were referred into the ides were sufficiently complete to make some limited comparisons .

specifically , we analyzed army legacy data to determine how long the legacy process took , on average , between when servicemembers were referred to the process and when va was ready to conduct the disability rating .

we limited our analysis to cases in which a va claim was filed between 2006 and 2009 because data on when va was ready to conduct the rating was missing for a substantial number of cases where the va claim was filed in 2005 and 2010 .

we compared this legacy average with the total pilot case processing time through to delivery of va benefits , but we noted that the legacy average does not account for time for va to complete the rating and deliver the benefits .

we also analyzed army data on appeals in order to illustrate the limitations of dod's plan to compare only appeals to the informal peb in the pilot and legacy systems and not take into account appeals of rating decisions to va. we conducted this analysis using the legacy data and pilot case data as of early 2010 , since dod and va's weekly reports do not contain information on appeals to va .

to identify challenges in implementing the ides during the pilot phase , we visited 10 of the 27 military treatment facilities participating in the pilot .

at the site visits , we interviewed officials involved in implementing the ides from both dod and va , including military facility commanders and administrators , dod board liaisons , military physicians involved in meb determinations , dod legal staff , va case workers , va or contract examiners , and administrators at va medical clinics and va regional offices .

we selected the 10 facilities to obtain perspectives from sites in different military services and geographical regions and that varied in terms of disability evaluation caseloads and how their single exams were conducted ( by dod , va , or a va contractor ) ( see table 4 ) .

we also interviewed various offices at dod and va involved in implementing the ides pilot .

at dod , this included wwctp ; office of the assistant secretary of defense for health affairs ; office of the assistant secretary of defense for reserve affairs ; air force physical disability division ; army physical disability agency ; navy physical evaluation board ; office of the air force surgeon general ; army medical command ; and navy bureau of medicine and surgery .

at va , we interviewed officials in the veterans benefits administration , veterans health administration , and va / dod collaboration service .

furthermore , we reviewed relevant documents , including dod and va policies and guidance and records of “hotwash” meetings , which dod and va held shortly after implementing the ides at pilot sites to identify implementation successes and challenges .

we also reviewed data on processing times for the single exams , meb determinations , informal peb decisions , and va ratings , as reported in the agencies' weekly monitoring reports .

in addition , we reviewed relevant federal laws and regulations .

to determine whether the ides process extended the time that servicemembers remained in military service , we analyzed the legacy and pilot case data from the early 2010 data set , but we identified several limitations with the data .

as noted earlier , the date servicemembers separated from the military was missing for 19 percent of completed ides pilot cases .

further , as shown in table 5 , only air force cases contained data on the separation date in the legacy data .

also noted earlier , only the army legacy data contained information on when servicemembers were referred into the legacy process .

as a result , for army cases , we compared the average length of time it took cases to reach a final peb decision in the legacy and pilot , since this date was sufficiently complete in both the legacy and pilot data .

the peb decision is the last phase of the disability evaluation process before a servicemember either begins to transition from military service , or if they are found fit , returns to their unit .

to identify the agencies' preparations for worldwide expansion of the ides , we reviewed documents on dod and va's expansion strategy , their site assessment matrix , and weekly monitoring reports which , beginning in july 2010 , tracked key implementation time frames , both nationally and at individual military treatment facilities .

our interviews with officials involved in the pilot at dod , va , and each of the military services also provided us with information on the agencies' expansion plans .

we also reviewed relevant federal laws and regulations .

we determined the adequacy of the agencies' planning efforts by assessing whether their plans addressed the challenges we had identified in objective 2 .

we also determined whether the plans incorporated internal controls described in gao's standards for internal control in the federal government and best practices for program implementation identified in academic literature .

the figures below show case processing times in the ides pilot for reserve component servicemembers .

figure 11 shows the average number of days it took to complete the process — i.e. , to deliver va benefits to reserve component servicemembers , as of august 2010 .

figure 12 shows the percentage of cases that met the dod and va goal to deliver va benefits within 305 days , as of february 2010 .

figures 13-15 show the average length of time it took , as of august 2010 , to complete phases of the ides process — i.e. , the single exam , the meb documentation , and the informal peb decision , respectively — each of which have taken longer , on average , than the goals established by dod and va .

michele grgich ( assistant director ) , yunsian tai ( analyst - in - charge ) , jeremy conley , and greg whitney made significant contributions to this report .

walter vance and vanessa taylor provided assistance with research methodology and data analysis .

bonnie anderson , rebecca beale , mark bird , brenda farrell , valerie melvin , patricia owens , and randall williamson provided subject matter expertise .

susan bernstein and kathleen van gelder provided writing assistance .

james bennett provided graphics assistance .

roger thomas provided legal counsel .

