in fiscal year 2019 , the community services block grant ( csbg ) program provided about $700 million to fight poverty in the united states — funding that went to each of the states and supported over 1,000 local antipoverty agencies .

these local agencies , predominantly community action agencies , use csbg funding to aid them in providing a variety of programs and services such as employment , education , financial management , housing , nutrition , and emergency services to help program participants achieve economic self - sufficiency .

they also often use csbg funds to strengthen their institutional frameworks for providing services , including staff and facilities .

the office of community services ( ocs ) within the department of health and human services ( hhs ) is primarily responsible for overseeing states that receive the block grant , and states are responsible for overseeing local agencies that receive the grant funding .

past gao reports and other reviews have identified deficiencies in federal oversight efforts to ensure that ocs is meeting legal requirements for overseeing states and internal controls for the csbg program .

specifically , in a february 2006 letter and june 2006 report , we found that ocs lacked effective policies , procedures , and controls to help ensure that it fully met legal requirements for overseeing states and internal control standards , and recommended actions to address these issues , which ocs took steps to address .

nonetheless , almost a decade later , a 2014 hhs office of inspector general ( oig ) review found that many of the issues we identified had resurfaced .

you asked that we review the efforts that ocs and states have undertaken to oversee the use of csbg funds .

this report examines ( 1 ) the activities that hhs and states conduct to oversee the state and local agencies that receive csbg funds , and ( 2 ) the extent to which hhs assesses the outcomes of the csbg program .

to address both of our objectives , we reviewed relevant federal laws , federal grants management guidance , and agency documents that describe the federal requirements and responsibilities for overseeing states' csbg programs and assessing program outcomes .

we scoped our review of the csbg program to include the 50 states , american samoa , the district of columbia , guam , northern mariana islands , puerto rico and the united states virgin islands , which are defined as states under the csbg act .

for our first objective , we obtained and reviewed available information on ocs's policies and procedures , including the risk assessment criteria ocs uses to select states for onsite compliance evaluations , and interviewed ocs officials about their oversight efforts .

we selected 12 states for an in - depth review of ocs's oversight activities .

these included six states ( indiana , louisiana , michigan , new york , north carolina , and texas ) of the 12 states for which ocs conducted onsite compliance evaluations during fiscal years 2016 and 2017 .

in fiscal year 2016 and 2017 , ocs also conducted onsite reviews of: alabama , arkansas , connecticut , south carolina , florida , and tennessee .

for our review , we selected states that ocs had prioritized as the top three states to visit during each of the two fiscal years .

we used a random number generator to randomly select five of the six of the remaining states ( alaska , colorado , kentucky , mississippi , and rhode island ) where ocs did not conduct onsite compliance evaluations , but conducted a routine review , which it does yearly for all states .

we also selected a sixth state — north dakota — because ocs had not visited the state in several years .

we reviewed ocs's file documentation for both sets of selected states including a review of ocs's comments on each section of state program documents such as state plans and annual reports , actions states took to address ocs comments , state fiscal controls , and financial and program oversight documents .

we compared the results to identify whether there were any notable differences between the two sets .

while our findings are non - generalizable , they provide insight into the different levels of review ocs conducts and examples of ocs oversight actions .

we visited three of the 12 states in our review: two states ( new york and texas ) for which ocs conducted onsite compliance evaluations and one ( north dakota ) for which ocs conducted a routine review .

we selected these three states based on a range of considerations including recommendations from ocs officials and experts about states with promising practices .

to ensure some variation in our sample , we also considered the amount of csbg funding states received , the year of ocs's last onsite compliance evaluation since 2008 , and the number of local agencies receiving csbg funds within the state .

for each of these three states , we obtained and reviewed documentation of oversight activities from the csbg state agency and reviewed organization - wide audits of the state and local agencies conducted during fiscal years 2016 and 2017 .

during our visits , we interviewed officials with csbg state and state audit agencies about oversight issues , including promising practices and challenges .

we also interviewed officials from two local agencies that received csbg funds in each of the three states .

table 1 summarizes ocs and gao reviews of the states selected for review .

to address our second objective , we reviewed the program performance indicators ocs uses to measure program outcomes in relation to the stated goals of the csbg program .

we also reviewed ocs's design and implementation plans for a new performance management approach , including revised performance measures for assessing program outcomes .

we interviewed ocs officials about the goal of , and changes to , the performance management approach and reporting requirements .

additionally , we interviewed state officials on their experience with csbg program performance and reviewed leading practices in grant performance management as identified in federal guidance and gao reports .

for additional information on our scope and methodology , see appendix i .

we conducted this performance audit from to may 2018 to november 2019 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the csbg program is intended to focus on three overall ( national ) goals: reducing poverty , empowering low - income families and individuals to become self - sufficient , and revitalizing low - income communities .

the program is administered by ocs within the administration for children and families ( acf ) at hhs .

csbg was an outgrowth of the war on poverty of the 1960s and 1970s , which established the community action program under which the nationwide network of local community action agencies was developed .

the federal government had direct oversight of local agencies until 1981 , when the csbg program was established and states were designated as the grant recipients .

ocs and states now share responsibility for oversight of csbg grantees .

in fiscal year 2019 , states received approximately $700 million of the total $725 million csbg appropriation .

appendix ii provides the funding amounts for each state .

ocs distributes csbg funding to states and they , in turn , distribute funds to over 1,000 local agencies .

most of these local agencies receive funding from a variety of federal , state , and private sources .

in fiscal year 2017 , the latest data available , local agencies received about $9 billion from all federal sources , including about $700 million from csbg .

other federal programs providing funding include head start , the low income home energy assistance program ( liheap ) , the community development block grant ( cdbg ) , the child care and development block grant , temporary assistance for needy families , and the social services block grant ( see fig .

1 ) .

programs administered by acf contributed about $6.6 billion of the funds provided to local agencies .

csbg funding can be used broadly , allowing state and local agencies flexibility to provide services tailored to organizational and community needs .

csbg funds can be used by local agencies to provide services to participants in their programs and fill gaps in the funding provided by other means .

for example , local agencies may use csbg funds to support a position for a staff member who determines the service needs of potential participants and connects them with the appropriate services — a position that would not be an allowable expense under the funding rules of other federal programs , according to a local agency official we interviewed .

local agencies have also used csbg funding to leverage other public and private resources to support a variety of initiatives , such as head start programs , low - income energy assistance programs , and low - income housing .

ocs monitors all states receiving grant funds to ensure that they are meeting the standards for federal grant programs set by the office of management and budget ( omb ) and the specific expenditure requirements for the program .

the csbg act requires that states submit plans to ocs describing how they intend to use the funds to address the needs of the local community and annual reports detailing the actual use of funds , including information on state performance results and populations served .

ocs is required by the csbg act to conduct compliance evaluations of several states each fiscal year to review the states' use of csbg funds , report to states on the results of these evaluations , and make recommendations for improvements .

however , the csbg act does not specify the number of states subjected to an evaluation each year or the timeframe each state must undergo such evaluations .

following a compliance evaluation , states are required to submit a plan of action in response to any ocs recommendations .

in addition to conducting compliance evaluations to assess states' use of csbg funds , ocs is required to submit an annual report to congress .

this annual report must include a summary of how states and local agencies had planned to use csbg funds ; how funds were actually spent , data on the number and demographics of those served by local agencies , and other information .

the csbg act requires ocs to provide training and technical assistance to states and to assist them in carrying out corrective action activities and monitoring .

ocs must reserve 1.5 percent of annual appropriations ( in fiscal year 2019 , this percentage totaled about $11 million of the total appropriation ) for many activities , including training and technical assistance ; planning , evaluation , and performance management ; assisting states with carrying out corrective action activities ; and oversight including reporting and data collection activities .

the csbg act also requires that states complete several steps before terminating an underperforming entity .

the state agency is required , among other things , to provide training and technical assistance , if appropriate , to help the agency correct identified deficiencies , review the local agency's quality improvement plan , and provide an opportunity for a hearing .

the entity can request a federal review of the state's decision to reduce or terminate funding , which must be completed within 90 days of ocs's receipt .

during this period , the state is required to continue funding the entity until ocs responds to the request .

the csbg act requires each state to designate a lead state agency to administer csbg funds and provide oversight of local agencies that receive funds .

states are required to award at least 90 percent of their federal block grant allotments to eligible local agencies , and to determine how csbg funds are distributed among local agencies .

states may use up to $55,000 or 5 percent of their csbg allotment , whichever is higher , for administrative costs .

states may use remaining funds for the provision of training and technical assistance , and other activities .

in addition , states and local agencies that expend $750,000 or more in total federal awards are required to undergo an audit annually and submit a report to the federal audit clearinghouse .

the csbg act requires states to determine if local agencies meet the performance goals , administrative standards , and financial management requirements for the csbg program .

for each local agency , the csbg act requires the state to conduct: a full onsite review at least once during each 3-year period ; an onsite review of each new local agency following the completion of the first year receiving csbg funds ; followup reviews including prompt return visits to local agencies that fail to meet goals , standards , and requirements established by the state ; and other reviews as appropriate , including reviews of local agencies found to have had other grants terminated for cause .

for states to receive csbg funding , they must submit an application and state plan at least biennially describing , among other things , how they will use csbg funds to accomplish various things such as helping families and individuals to achieve self - sufficiency , find and retain meaningful employment , and obtain adequate housing .

within their state plan , states must attest that ( 1 ) funds will be used to address the needs of youth in low - income communities ; ( 2 ) funds will be used to coordinate with related programs ; and ( 3 ) local agencies will provide emergency food - related services .

states must also complete annual reports that include fiscal , demographic , and performance data .

in their state plans , states must provide an assurance that all local agencies will submit a community action plan that includes a community needs assessment for the community served .

in addition , local agencies must administer the csbg program through a three - part board , consisting of one - third elected public officials and at least one - third representatives of the low - income community , with the balance drawn from officials or members of the private sector , labor , religious , law enforcement , education or other groups in the community served .

the government performance and results act of 1993 ( gpra ) as enhanced by the gpra modernization act of 2010 ( gprama ) focuses federal agencies on performance by , among other things , requiring agencies ( including hhs ) to develop outcome - oriented goals and a balanced set of performance indicators , including output and outcome indicators as appropriate , to assist agencies in measuring or assessing their progress toward goals .

omb provides guidance to federal executive branch agencies on how to prepare their strategic plans in accordance with gpra requirements .

we have reported that strategic planning requirements established under gpra and gprama can also serve as leading practices for strategic planning at lower levels within federal agencies .

federal standards for internal control help to ensure efficient and effective operations , reliable financial reporting , and compliance with federal laws .

internal controls help government program managers achieve desired results through effective stewardship of public resources .

such interrelated controls comprise the plans , methods , and procedures used to meet missions , goals , and objectives .

internal controls support performance - based management and should provide reasonable assurance that an organization achieve its objectives of ( 1 ) effective and efficient operations , ( 2 ) reliable reporting , and ( 3 ) compliance with applicable laws and regulations .

with regard to performance measurement for state and local agencies , the csbg act requires ocs , in collaboration with states and local agencies , to facilitate the development of one or more model performance measurement systems which may be used by states and local agencies to measure their performance in fulfilling csbg requirements .

each state receiving csbg funds is required to participate in and ensure that all local agencies in the state participate in either a performance measurement system whose development was facilitated by ocs or in an alternative system approved by ocs .

ocs developed the results oriented management and accountability ( roma ) performance management approach that states and local agencies follow when overseeing programs and measuring their performance in achieving their csbg goals .

in 2012 , ocs began four initiatives to update how it oversees the performance of the csbg program , and as of april 30 2019 , ocs had implemented all four of the initiatives , which include: an updated roma process for program management , 58 organizational management standards for local agencies , new federal and state accountability measures , and an updated annual report format where oversight and performance information from states is collected in an automated online data system .

in addition , ocs developed the csbg theory of change which illustrates how the core principles of the csbg program , the performance management framework , and services and strategies offered with csbg funds relate .

the three national goals established under the csbg theory of change are similar to the three national goals identified in the csbg act , but are not identical .

the three goals under the csbg theory of change are: 1. individuals and families are stable and achieve economic security , 2. communities where low - income people live are healthy and offer 3. people with low incomes are active in their community .

ocs and states are responsible for conducting oversight activities to ensure that csbg recipients use the funds in accordance with the csbg act , which includes ensuring that the funds are used in line with the grant's three national goals related to addressing the causes and conditions of poverty .

our review of oversight efforts during fiscal years 2016 and 2017 for the select states showed that ocs and states conducted required oversight activities , as well as additional oversight activities , and provided training and technical assistance to help csbg recipients meet csbg program requirements .

our review of file documentation for six selected states where ocs conducted compliance evaluations during fiscal years 2016 and 2017 , and six selected states where ocs conducted routine oversight , showed that ocs identified primarily administrative issues , but in some instances identified non - compliance and other more serious issues that required corrective actions that states took action to resolve .

we largely found similar results in our review of the selected states' onsite and routine oversight activities for local csbg funds recipients for the same time period .

beyond findings of an administrative nature , a fiscal year 2017 ocs compliance evaluation found that one state did not conduct required monitoring of its eligible entities during fiscal year 2015 .

also , one state identified financial mismanagement , which resulted in termination of a local grantee from the csbg program .

additionally , we found that ocs and states provided training and technical assistance to help csbg recipients meet requirements .

ocs officials conducted onsite compliance evaluations , in addition to other oversight activities , for 12 states using a risk assessment and prioritization process during fiscal years 2016 and 2017 .

we reviewed six of these 12 states and found that a majority of errors identified by ocs were administrative .

the csbg act requires ocs to conduct compliance evaluations for several states each year .

since fiscal year 2009 , ocs has conducted onsite compliance evaluations in five to seven selected states each year , in addition to the routine oversight it conducts for all the states .

according to ocs officials , the number of states visited each year depends upon available resources .

ocs primarily bases its selection of states for onsite compliance evaluations on a risk assessment conducted using a scoring tool .

the scoring tool generates a risk score of 1 to 5 for each state using a number of measures , as shown in figure 2 .

the various factors used in developing the total risk score are weighted to ensure the most significant risk indicators and prioritization factors have the most impact on the selection of states for onsite monitoring .

the list of risk factors was developed by ocs in response to a recommendation from our 2006 report in which we found that ocs did not systematically use available information to assess risk to focus its monitoring resources on states with the highest risk .

according to ocs officials , ocs rarely visits states that they identify as low risk or states that have very few local agencies as grantees , and they try to not visit the same state within 3 years of their last visit .

ocs officials told us that monitoring resources limit their ability to reach all of the states for onsite review .

we found that , since fiscal year 2008 , eight states have not received an onsite evaluation and 10 had been visited twice .

according to agency officials , the risk assessment is part of a larger risk assessment and prioritization process designed to direct monitoring resources over multiple years .

after determining risk under the scoring tool , ocs considers several other factors and may place a higher priority on states with lower risk scores when selecting states for onsite compliance evaluations .

agency officials said such factors include: size of the csbg award , findings from single audits , the rate at which the state spends its csbg funds , time since the last ocs visit , and feedback from the ocs program manager using information gathered from the quarterly calls with the states .

for states selected for onsite compliance evaluations , we found that ocs conducts a comprehensive review of each of the state's plan and annual reports and examines the state's supporting documents to determine if that state is meeting the requirements of the csbg program .

although ocs reviews the plans for all 56 states as part of its routine oversight efforts , during the onsite visit the agency also conducts interviews with staff and examines state statutes or regulations and supportive information , such as financial ledgers and oversight procedural manuals .

ocs also reviews the state's grant funding to determine if the state allocated the funds in accordance with the requirements of the csbg program .

additionally , ocs reviews each state's fiscal controls and accounting procedures and associated documents to assess the financial integrity of the state's process for drawing down federal funds , providing funds to local agencies , and reporting financial information .

for example , ocs officials may review the state agency's bookkeeping system and accounting software .

in our review of ocs's file documentation for the six selected states , we found ocs generally identified administrative errors , but in some instances identified issues of non - compliance and other issues that the states took action to resolve .

for example , during its fiscal year 2017 onsite visit to louisiana , ocs found that louisiana did not implement procedures to monitor and track prior year single audit findings for corrective action and issue management decisions as required .

to address this concern , the state assigned a member of its staff to execute these duties and submitted a copy of the single audit process and audit log to ocs .

additionally , ocs found that louisiana did not visit any of its 42 local agencies in fiscal year 2015 because of limited capacity such as staffing shortages , among other non - compliance issues .

ocs determined that louisiana addressed this issue by visiting all of the local agencies before the end of fiscal year 2017 .

also , in a fiscal year 2016 onsite visit to indiana , ocs found that the state agency did not submit a required financial report to account for csbg expenditures within established timeframes in two consecutive fiscal years — 2014 and 2015 — due to the lack of a process to ensure the timely submission of the report .

ocs also found that the financial report for fiscal year 2014 contained incorrect amounts for certain expenditures .

the indiana state agency responded to the issues by developing formal written procedures regarding the preparation and submission of financial reports .

in addition , for the six selected states , we found that ocs had assessed state plans and annual reports to ensure that the states were complying with the programmatic , financial , and administrative requirements of the csbg program , as outlined in the csbg act .

in our review of the selected states , we found that during fiscal years 2016 and 2017 , ocs conducted routine reviews and other oversight activities to assess states' use of csbg funds .

we selected six states ( alaska , colorado , kentucky , mississippi , north dakota , and rhode island ) for our review of file documentation of ocs's routine reviews .

we found that for these six states , the routine reviews consisted of ocs reviewing all state plans and annual reports to determine if the state completed all sections of the plan and provided information about how it would achieve the goals of the program .

in our review of file documentation for the six states , we found that ocs requested states to provide additional details about their plans ; however , like the issues identified in the onsite compliance evaluations , the issues on which ocs commented were primarily administrative .

for example , in fiscal year 2016 , ocs reviewed colorado's 2016 annual plan and requested that the state provide additional details on plans to modify its organizational standards .

also , in its fiscal year 2017 review , ocs requested that alaska provide additional information in its annual plan to explain how the state would prioritize providing services to individuals based on their income .

we found that the states addressed ocs's comments .

ocs officials told us that they used quarterly calls as a part of their routine oversight .

agency officials told us that they generally use quarterly calls to discuss the state plans and the csbg program broadly , and review the annual reports .

ocs officials also told us that ocs uses these calls to update states on issues that have significant impact or importance on the successful operation of the csbg grantees .

in some cases , ocs program specialists may use the quarterly calls to identify areas where the state may be struggling and to discuss ways to address those issues .

in addition , ocs officials stated that ocs program specialists will work with states to assist with developing work plans or reviewing corrective action procedures for high - risk local agencies .

all three states we visited ( new york , north dakota , and texas ) conducted onsite visits to local agencies at least once every 3 years as required by the csbg act , and conducted routine oversight activities .

in response to our june 2006 recommendation , ocs issued guidance clarifying that states must conduct an onsite review of each local agency at least once every 3 years .

besides the triennial onsite reviews , the law requires states to conduct: ( 1 ) follow up reviews including prompt return visits to local agencies that fail to meet state goals , standards , and requirements , ( 2 ) an onsite review of new local agencies following the completion of the first year receiving csbg funds , and ( 3 ) other reviews as appropriate , including reviews of local agencies found to have had other grants terminated for cause .

each of the states we visited had developed oversight policies and procedures that included information on how often csbg programs should be reviewed onsite and what program operations should be covered during onsite visits ; two states provided sample forms or instructions on what forms to use to record findings .

for example , each state's policies and procedures established the frequency of onsite visits: new york and texas conduct the visits at least once every 3 years and north dakota conducts them once every 2 years ( see table 2 ) .

the selected states' policies and procedures also specified that state officials assess local agency financial controls , review financial records and client files , and review local agency governance .

they also described information about actions state officials were required to take when they identified deficiencies in a local agency's operations .

for example , in all three of the states we visited the policies and procedures required state officials to notify local agencies of deficiencies in writing .

our findings from the two local agencies we visited in each of the three states showed that state officials identified a variety of issues during their reviews , but none that required those local agencies to lose their csbg funding ( see table 3 ) .

generally , we found that the issues identified could be characterized as fiscal , governance , or administrative .

fiscal issues included improper use of funds .

for example , state officials in one selected state found that a local agency had improperly used a small amount of csbg funds to purchase a grill for agency activities .

governance - related findings included issues with both the composition and manner of selecting the local agency's csbg board of directors members .

for example , in texas , state officials cited one local agency for not complying with the csbg act's requirement regarding the structure of its board .

also , north dakota cited a local agency for not having the required representation of low - income individuals on its board .

administrative issues included recordkeeping of information on participants .

for example , texas cited a local agency for inaccurately reporting a program participant as having transitioned out of poverty .

the state agency found that the participant's file did not contain all of the required documentation needed to show that the participant had maintained a certain income level for a 90-day period .

the state agency officials we spoke with told us that their reviews sometimes identified more serious issues that resulted in local agencies being terminated from the program .

for example , texas terminated two local agencies' csbg funding due to financial mismanagement that was uncovered during state monitoring of the local agencies .

texas officials noted that the process for terminating local agencies with deficiencies was , for them , a prolonged process , in part because of the steps they took to provide technical assistance and work with agencies in an attempt to resolve issues before terminating them from the program .

they told us they found it difficult to establish sufficient grounds for termination and , for one of the terminations , texas officials continued to work with the agency for two years while also working with ocs .

texas officials told us that they found the guidance on terminations to be unclear .

ocs officials acknowledged that the information memorandum they have developed on terminations provides broad guidance that covers a range of issues states might encounter , and may not have detailed guidance covering each situation .

however , they noted that they work with states on a case by case basis , as they did with texas , to provide guidance that is specific to each situation .

state officials in the selected states told us that local agencies identified as having deficiencies are notified of those deficiencies and provided information on how to correct them .

further , our review of corrective actions required of selected local agencies by the states we visited showed that the local agencies addressed the concerns raised by the states .

for example , texas required a local agency that it found did not comply with csbg board requirements concerning membership to fill the vacancies on the board and to provide the state a timeline for completing the required corrective actions .

in addition to taking corrective actions , local agencies may be required to submit fiscal and programmatic reports more frequently when monitoring uncovers problems .

for example , north dakota's policies and procedures indicate that monthly reports may be required of local agencies that have been found to have financial recordkeeping problems .

we also found that state agency officials in our three selected states conducted onsite reviews more frequently than the once every 3 years requirement , as well as routine offsite reviews .

for example , new york conducted quarterly onsite visits to all local agencies , where each quarterly visit involved a targeted review of a specific aspect of a local agency's csbg program .

for example , during the third quarterly visit of the year , state officials focused on local agency planning efforts for the next funding year , including the community needs assessment , while during the last quarterly visit of the year , state officials focused on grant closeout activities .

new york , like north dakota and texas , also conducted routine offsite reviews of local agencies' activities and finances .

in our three selected states , these reviews included examining fiscal and program reports periodically submitted by local agencies to state officials , periodic meetings and conference calls between state and local agency staff , and reviewing audit reports .

these oversight activities also included fiscal audits conducted by the state auditor or independent auditors when a local agency's funding met the threshold for such review .

our review of single audits and interviews with each state's auditor's office in the three states we visited showed that none of the state audit agencies focused specifically on csbg funding during the period of our review .

texas last conducted an audit focusing on csbg in 2014 and north dakota did so in 2011 ; neither state reported findings as a result of those audits .

officials from the state auditor offices in north dakota and texas said csbg funding levels are below the federally - established threshold for programs that must be audited .

new york state audit officials told us that they had not conducted any audits focused on csbg .

ocs and states provided training and technical assistance through a variety of methods to help csbg recipients meet program requirements .

in fiscal years 2016 and 2017 , ocs designated nearly $14 million over the 2-year period for such efforts .

ocs officials told us that they determine what training is needed through input from ocs program specialists , information obtained through a data task force , and requests from state and local agencies .

ocs officials stated that the ocs's program specialists use the quarterly calls to identify the types of support that states need .

for example , a specialist may notice that the states need additional guidance on using their customer survey results .

in response , the specialist may share a guide on how states can use the survey results to set reasonable performance improvement goals .

in addition , ocs sponsors a csbg data task force to recommend strategies for building network capacity for collecting , analyzing , reporting and using performance data as well as identifying on - going training and technical assistance needs .

ocs officials told us that they also conducted focus groups in 2016 to gather states' perspectives on their training and technical assistance needs .

from these focus groups , ocs issued guidance stating its technical assistance priorities and strategy for meeting identified needs for training and technical assistance in areas including: performance management , governance , effective state oversight , and results - oriented services and strategies .

in 2017 , ocs issued guidance laying out the agency's 3-year training and technical assistance strategy to guide the development and delivery of training and technical assistance for the csbg network .

ocs officials said that once they establish the standards for the training and technical assistance and identify specific training needs , the agency awards cooperative agreements to organizations that focus on developing and providing training to build upon guidance already provided .

during the period of our review , we found that each agreement focused on a specific type of training .

for example , the national association for state community services programs ( nascsp ) has a cooperative agreement with ocs to provide the orientation and oversight training for new state officials overseeing the csbg program , and collects and coordinates the analysis of the data provided in the state plans and annual reports .

ocs has also worked closely with nascsp in the transition to the new performance framework .

ocs officials told us that they are currently reviewing their training and technical assistance portfolio and may issue additional guidance on its strategy and coordination efforts during fiscal year 2020 .

in addition , ocs uses various methods to provide guidance to states to help them meet csbg requirements , but state officials differed in their views on the usefulness of the guidance .

ocs provides guidance to states through informational memorandums , letters , webinars , and communications with program specialists .

some of the state agency officials in two of the states we visited said that the guidance that ocs has provided to help states ensure compliance with program requirements is not always clear and up to date .

for example , officials in north dakota said that they did not understand the information requirements for a form used to gather information from applicants for local programs .

state agency officials in texas said that ocs issued guidance on the new information requirements just weeks before the reporting deadline , and that this did not allow states sufficient time to set up their data systems to meet the new requirements .

ocs officials acknowledged that they were aware of the issues raised by state agency officials and explained that some states have difficulty with the guidance because it is written at a high level so that it can apply to all states .

they also acknowledged the delays in getting new information requirements to states and said that such delays were related to troubleshooting the new smart forms and online database .

they said that they do not anticipate such delays in the future .

as previously discussed , texas state officials also said that they found the guidance for terminating a deficient agency's csbg funding confusing .

however , officials in new york said that they found the guidance to be clear .

they said that the informational memorandum on terminating agencies' csbg funding is more prescriptive than previously issued csbg guidance .

ocs officials stated that the agency is continuously seeking opportunities to work with its technical assistance centers to identify the best means of delivering guidance to states and to eligible entities .

ocs officials also said that they must continue to refresh training efforts when there is turnover among key staff in a state agency and work with new state administrators to transition into their new roles .

state agency officials in all three states we visited told us that they used some of their state's discretionary funding for training and technical assistance to help local agencies meet csbg requirements .

the csbg act allows states to use a maximum of 10 percent of their csbg funds for training and technical assistance and other specified purposes .

in the selected states , officials spent from $65,000 to over $400,000 for training and technical assistance for local agencies ( see table 4 ) .

across the three selected states , we found that the training provided to local agencies addressed what local agencies need to do to meet a wide variety of csbg requirements , from planning community needs assessments to implementing performance management requirements .

in addition , some funds states provided for training were used by local agencies to send their staff to regional or national conferences for training ( see table 5 ) .

state officials in two of the three states we visited said that they determine what training they need to offer based on analysis of feedback and specific requests from local agencies .

for example , texas identified training needs for local agencies through a training and community affairs group that gathered information from local agencies about their training needs .

texas officials said they analyzed assessment results , feedback , and requests from local agencies and other sources to determine the training needs of individual state and local agencies .

state officials said that they then met with the state association to develop the joint state training and technical assistance plan and , ultimately , to provide trainings at the annual state conference , and to identify workshops , webinars , and online resources ( guides , tools , best practices , and links to other training resources ) that need to be added or changed .

similarly , state officials in north dakota reported working closely with the state association of community action agencies to plan and conduct training for local agency staff .

state and local agency officials also said that they have relied on the ocs - funded national resource centers for assistance .

officials in the states we visited all reported being helped by information provided by the national centers on topics such as the new organizational standards and how to submit data in the new annual report .

local agency officials told us that they send staff to the conferences sponsored by the national resource centers to obtain training when funding is available for that purpose .

in addition to training , state officials in the states we visited cited a variety of practices that contribute to effective oversight .

both new york and north dakota officials emphasized the importance of frequent , ongoing communication with local agencies as crucial to successful oversight .

new york also identified frequent visits to local agencies and immediate action in response to problems as additional key factors for effective oversight .

ocs uses outcome data from state agencies that collect and aggregate data from local csbg recipients to provide an indication of csbg's progress in meeting the three national program goals .

as previously discussed , the three national goals of the csbg program as established under the csbg act are to ( 1 ) reduce poverty , ( 2 ) empower low - income families and individuals to become self - sufficient , and ( 3 ) revitalize low - income communities .

state agencies report data from a menu of more than 100 performance measures established by ocs and grouped by service types such as employment , early childhood programs , and education .

ocs sets annual targets for the overall performance of the csbg program and uses the aggregated state data as an indicator of csbg's national effectiveness to inform budget decisions consistent with federal requirements for performance management .

until fiscal year 2018 , ocs used one performance measure — the number of barriers to economic security that the local agencies receiving csbg funds eliminated for individuals , families , and communities — to provide an indication of csbg's national effectiveness .

to do this , ocs combined the outcome data from 10 of the more than 100 performance measures from the state annual reports to derive a cumulative total number of barriers overcome .

ocs selected the 10 measures as a way to track outcomes from services that range from emergency services to more comprehensive and coordinated services .

the 10 measures included outcomes such as the number of participants who obtained a job , maintained employment , maintained an independent living situation , reached the goals of enrichment programs , or obtained emergency assistance .

while this one performance measure of barriers eliminated was intended to provide ocs with an indication of how the program was meeting csbg national goals , several weaknesses with this measure limited ocs's ability to do so .

first , the measure included duplicative counts .

for example , an individual may overcome a number of different barriers to reach the outcome of obtaining a job .

as a result , by tracking the number of barriers , an outcome may be counted multiple times when combining data from multiple measures .

second , it is also difficult to know which csbg funded program or service caused the positive outcome or if one service helped achieve multiple outcomes .

third , ocs officials clarified that when calculating this and other outcome measures , the removal of barriers to economic security is not solely the result of csbg funds , but of all funding administered to local agencies that received csbg funds .

as such , they said that it is difficult to isolate the effects of csbg funding .

in its agency wide budget justification for fiscal year 2020 , hhs reported that in fiscal year 2017 local agencies eliminated 32.2 million barriers to economic security , well above the 27.6 million it set as its goal for the year .

in the same year , 16.2 million individuals received support through local agencies receiving csbg funds .

while the performance measure aided ocs in providing some indication of how the csbg program contributes to the goal of improving self - sufficiency , it still did not provide information on the program's progress in meeting the other two national program goals .

leading practices in performance management stress that performance measures should be tied to the specific goals of the program .

however , no such linkage existed between the performance measure ocs used to report on the progress of the csbg program and the program's three national goals .

required to annually report , among other things , a summary of certain information the states provide and its findings on state compliance to congress .

while ocs does submit such reports , we found that there has historically been a multi - year lag in ocs providing these reports to congress .

in may of 2019 , ocs released its fiscal year 2015 csbg report to congress ( see sidebar on data reported in the csbg fiscal year 2015 report to congress ) .

over the last decade , this type of reporting lag has been common and ocs has taken an average of more than 3 years from the end of the federal fiscal year until the time the congress received the final report .

ocs officials told us that they submitted the draft annual report for fiscal year 2016 for internal review by hhs in october 2018 , but said that they could not project when the final report would be issued to congress .

they said they are currently drafting the fiscal year 2017 report .

ocs has taken steps to redesign its performance management approach , but several elements of the new approach do not align with federal performance management and internal control standards .

ocs has been redesigning how it oversees and manages the performance of the csbg program to better align with gprama , according to ocs officials .

since fiscal year 2016 , ocs has been implementing new performance management tools for the csbg program , including updating what data it collects and how it collects it on the services and outcomes , or performance measures , of the csbg program .

ocs officials stated that the changes are necessary to be able to provide more information and analysis on csbg funded programs and their outcomes .

they also noted the importance of these updates given a tightening federal budget .

as part of these changes , ocs updated its more than 100 performance measures by revising the language of some and adding new measures that state and local agencies can report on , including measures more focused on outcomes in the communities they serve .

state and local agency officials told us that the increased emphasis on outcomes in the new measures was an improvement and increased their own focus on connecting csbg funds to traceable results .

in addition , ocs transitioned to an online data reporting system that allows state agencies to directly report and access csbg program data .

however , ocs is still revising how it will use the data provided by state and local agencies to reflect nationwide results .

ocs is using the data collected in state annual reports to develop a new national measure intended to provide a national total count of individuals who achieve at least one positive outcome through programs and services offered by local agencies that receive csbg funds .

unlike the prior measure on the number of barriers to economic security eliminated by local csbg recipients that could include duplicative counts , the new measure will be a count of individuals .

ocs stopped using the prior measure after fiscal year 2017 .

until ocs finalizes the new measure , it does not have a performance measure in place with targets and results that it can report to congress .

as such , it is unclear if ocs will report national performance outcomes for fiscal year 2018 or how useful the new measure will be while it is still in development through fiscal year 2022 .

while ocs has taken steps to redesign its performance management approach , several elements of the new approach do not align with federal performance management and internal control standards .

specifically , ocs has not established ( 1 ) how the new national measure will be used to assess csbg goals , ( 2 ) the relationship between state and local measures and program goals , and ( 3 ) how ocs will monitor the reliability of state and local agencies' program data .

how the newly developed national measure will assess csbg program goals .

as discussed , ocs is developing a new national measure intended to provide a total number of individuals who achieved at least one positive outcome from csbg funded program or services .

however , it is unclear which of the three program goals — reducing poverty , empowering low - income families and individuals to become self - sufficient , or revitalizing low - income communities — the new national measure is being used to assess .

as noted previously , ocs officials have stated that they are working to establish ways to provide more information and analysis on programs and their outcomes .

ocs officials also told us that they are using gprama as a guide for these changes and in our prior work we have reported that these requirements can serve as leading practices for strategic planning at lower levels within federal agencies .

gprama requires agencies to establish performance goals and a balanced set of performance indicators , including output and outcome indicators as appropriate , in measuring or assessing progress toward those goals .

additional leading performance management practices state that performance measures should be tied to the specific goals of the program .

however , ocs's new measure which is intended to provide a count of the number of individuals that achieve one or more positive outcomes does not specify which of the three national program goals the new measure will address , nor how the other two national program goals will be addressed .

ocs officials told us that the new measure is related to two of the three goals because it is aggregated data from some of the outcome measures focused on individual and family outcomes .

however , officials acknowledged that the agency has not yet developed a national measure for revitalizing low - income communities .

officials stated they plan to report on progress toward developing these measures and that it will provide examples of community - level outcomes in upcoming reports to congress .

without clearly linking the measure to the goals , there is no way to tell if , and to what degree , the services local agencies are providing through csbg grant funds are having the desired effect on their communities , even if examples are included in the shared results .

how state and local performance measures are related to the three program goals .

it is unclear how the large number of updated state and local performance measures under ocs's redesigned approach aligns with csbg's three national program goals .

ocs still collects data on more than 100 measures but it is unclear which of these measures will be analyzed at a national level .

according to ocs officials , these data are most useful to state and local agencies for assessing outcomes against their unique goals and numerous measures are necessary to capture the variety of services and outcomes across the 1,000 local agencies .

in our prior work on ways that agencies could improve performance management , we have stated that using a minimal number of critical measures is a leading practice .

we have found that organizations that seek to manage an excessive number of performance measures may risk creating confusing , excess data that will obscure rather than clarify performance issues .

the large number of measures can also further complicate ocs's efforts to align the measures with csbg's three national program goals .

how ocs will assess data reliability long - term .

although ocs is taking steps to assess data collected from state and local agencies for its new national measure , it does not have a written plan for how it will assess the data's reliability for future years .

as previously discussed , ocs is using a new data reporting system to collect the data it will subsequently use for its new national measure and this data will now be received directly by ocs instead of a third party .

however , ocs does not have written plans in place for how the agency will determine if the new data collected will be a valid measure of the national program's effectiveness or if the data will be reported reliably by the states into ocs's online data system .

ocs received its first round of performance data for the new measure for fiscal year 2018 on april 30 , 2019 , and is working with its cooperative agreement grantees and contactors to compile results and conduct quality assurance tests for the new performance data using a multi - step process that involves: ocs staff comparing data provided in the annual report to information previously provided in the state plans ; ocs conducting quality assurance reviews , with assistance from the organizations the office has cooperative agreements with , that include checks for discrepancies and identifying items requiring clarification , and conducting follow - up with the states ; and , ocs soliciting feedback from state officials and consulting with performance management experts within hhs about refinements to assist ocs in establishing a baseline that will be used in setting future targets .

ocs officials also told us that the next steps will be to make any necessary modifications to the measure , such as adjusting how states calculate positive outcomes , and establishing a baseline to set future targets .

on october 2 , 2019 , ocs announced via a federal register notice that it was requesting a three year extension with minor changes of the csbg annual report .

ocs plans to make only minor changes to the current data collection tool for 2 years to allow state and local agencies time to assess current information and intends to begin a longer term planning process starting in fiscal year 2020 .

ocs officials told us that they plan to implement and maintain a quality assurance process to ensure the accuracy of the data based on data from previous years .

while the process ocs has put in place to ensure data reliability for the first round of data collected for the new measure is a step in the right direction , ocs does not have a plan for assessing future years' data .

ocs officials told us that they will use selected cooperative agreements and contracts to develop a written plan for how the agency will monitor state and local agency data reliability going forward , but did not provide a timeframe for when this would be completed .

leading practices established by federal internal control standards state that agencies should use quality information that is appropriate , current , complete , and accurate to make informed decisions and evaluate the entity's performance in achieving key objectives .

ocs officials reported that they and contractors are working with the states to adjust and finalize data for fiscal year 2018 by november 2019 .

by not aligning its redesigned performance management approach with federal performance management leading practices related to program goals , performance measures , and data reliability , ocs cannot properly assess its progress in meeting csbg's three national goals .

poverty erodes the well - being of individuals , families , and communities .

the csbg program is intended to reduce poverty , empower low - income individuals and families to become self - sufficient , and revitalize low - income communities .

the csbg program allows local agencies to use funds in a wide variety of ways to reduce the causes of poverty in the communities they serve .

however , the inherent flexibility of the program also makes it difficult to assess the program's performance .

ocs recently redesigned its performance management approach to better understand how well the csbg program is progressing toward meeting national goals .

however , several elements of the redesigned approach do not align with leading practices in federal performance management .

inconsistencies with these practices , such as having an excessive number of performance measures and lacking a plan for assessing the reliability of state and local performance outcome data , limit ocs's ability to demonstrate the national effectiveness of the csbg program .

as such , ocs cannot assure the congress and the american public that the funding is meeting its intended purpose to reduce the causes of poverty .

the director of ocs , in developing the new performance management approach for the csbg program , should ensure that its performance framework includes information on ( 1 ) details for how the national measure is linked to and used to assess the three national program goals , ( 2 ) descriptions of how the updated state and local performance outcome measures align with national program goals , and ( 3 ) a written plan for how ocs will assess the reliability of state performance outcome data .

 ( recommendation 1 ) .

we provided a draft of this report to hhs for review and comment .

we received written comments from hhs , which are reprinted in appendix iii .

hhs concurred with our recommendation , and stated that it plans to take actions to better align its performance measures with the three national performance goals outlined in the new csbg theory of change .

while we commend hhs for its plans to address our recommendation , we urge hhs to focus on aligning its performance outcomes with the three national goals of the csbg program as established by the cbbg act , which are similar but not identical to the three goals outlined in the new csbg theory of change .

hhs also stated that it would implement additional actions to assess the reliability of state performance outcome data .

in addition , hhs provided technical comments which we incorporated as appropriate .

as agreed with your office , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the appropriate congressional committees and the secretary of hhs .

in addition , the report is available at no charge on the gao website at https: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-7215 or larink@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff that made key contributions to this report is listed in appendix iv .

this appendix discusses in detail our methodology for addressing our two research objectives examining ( 1 ) the activities that the department of health and human services ( hhs ) and states conduct to oversee the state and local agencies that receive community services block grant ( csbg ) funds and ( 2 ) the extent to which hhs assesses the outcomes of the csbg program .

we scoped our review of the csbg program to include the 50 states , american samoa , the district of columbia , guam , northern mariana islands , puerto rico , and the united states virgin islands , which are defined as states under the csbg act .

in addition to the methods we discuss below , to address both our research objectives , we reviewed relevant federal laws , federal grants management guidance , and agency documents that describe the federal requirements and responsibilities for overseeing states' csbg programs and assessing program outcomes .

we interviewed hhs , office of community services ( ocs ) officials ; and reviewed relevant research from ocs and the hhs office of inspector general , as well as our prior work on the csbg and other federal grant programs .

further , we interviewed representatives of the national association for state community service programs ( nascsp ) ; state officials from state agencies that oversee the csbg program in new york , north dakota , and texas ; and six local agencies that receive csbg funds .

we also analyzed csbg annual reports to congress and nascsp data on local agency allocations .

to address the federal oversight aspect of our first objective , we reviewed available information on ocs's policies and procedures , including the risk assessment criteria ocs uses to select states for onsite compliance evaluations and interviewed ocs officials about their oversight efforts .

we also selected 12 states for an in - depth review of ocs's oversight activities .

these included six states ( indiana , louisiana , michigan , new york , north carolina , and texas ) for which ocs conducted onsite compliance evaluations during fiscal years 2016 and 2017 .

we selected the six states where ocs had conducted onsite compliance evaluations based on which of the visited states ocs had prioritized as those in highest need of onsite reviews for fiscal years 2016 and 2017 .

we also randomly selected five states ( alaska , colorado , kentucky , mississippi , and rhode island ) where ocs did not conduct such evaluations , but conducted routine reviews .

we also selected a sixth state — north dakota — because ocs had not visited the state in several years .

we compared the results to see if there were any notable differences between the two sets .

while our findings are non - generalizable , they provide insight into the different levels of review ocs conducts and examples of ocs oversight actions .

our file documentation reviews included a review of: ocs's comments on each section of the states' program documents , including the state plan and annual reports ; actions the states took to address ocs's comments ; and state's fiscal controls , financial and program oversight documents .

table 6 provides a summary of the characteristics of the 12 states we selected for review .

to address the state and local oversight aspect of objective one , for a more in - depth look at state oversight practices , including promising practices and challenges , we visited three states: two states ( new york and texas ) for which ocs conducted onsite compliance evaluations and one ( north dakota ) for which ocs conducted a routine review .

we selected these states using several criteria , including state grant amounts , number of local agencies , whether the hhs office of inspector general findings had reviewed the state's use of csbg funds , the time since the state was last visited by ocs for a compliance evaluation visit , and recommendations from experts at nascsp and at ocs , who based their recommendations , in part , on states that had promising practices for overseeing local agencies ( see table 7 ) .

our final state selections comprise a diverse sample based on these criteria .

for example , our selected states include a state with a low number of local agencies , one with a large number of local agencies , states with high and medium amounts of funding , and a state with a low amount of funding .

during our state site visits , we interviewed and collected information from state and local agency officials about state oversight efforts from fiscal years 2016 through 2017 .

for each of the three states , we interviewed state program officials and reviewed related documentation including state policies and procedures , state single audits , onsite oversight guides and reports , and reporting forms for local agencies .

we also visited two local agencies in each state and interviewed staff to learn more about state oversight efforts , including fiscal and performance reporting , onsite visits , training and technical assistance , and promising practices and challenges to such oversight .

we conducted these visits in november and december 2018 .

in each state we visited , we reviewed program files for the two local agencies we visited , including oversight , financial , and performance reports ; and follow up correspondence concerning the findings from state agency visits to those local agencies .

information collected from state and local agency officials during our site visits are not generalizable to all state csbg programs .

in addition , we obtained information on state audit findings related to csbg and met with state auditors during site visits to learn more about additional state oversight of csbg and local agencies to learn whether any coordination occurred between the different federally funded programs offered by the local agencies to support state oversight efforts .

we reviewed the single state audit findings for fiscal years 2016 through 2017 for each of three states and six local agencies we visited .

we reviewed these audit reports to determine if there were findings pertaining to csbg and if so , the nature of those findings .

to address our second objective , we reviewed the program performance indicators ocs uses to measure program outcomes in relation to the stated goals of the csbg program .

we also reviewed ocs's design and implementation plans for a new performance management approach , including revised performance measures for assessing program outcomes .

we compared ocs's previous performance management approach to its new one , including the types of data it collected and its methods of collecting data from state and local agencies .

in conducting our work , we also interviewed ocs officials about the goal of , and changes to , the performance management approach and reporting requirements .

additionally , we interviewed state officials on their experience with csbg program performance .

we reviewed leading practices in grant performance management identified in federal guidance and in gao reports and assessed ocs's approach against federal performance and internal control standards .

we conducted this performance audit from to may 2018 to november 2019 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

this table includes all states as defined by the csbg act , which was the focus of our review .

in addition to the contact named above , mary crenshaw ( assistant director ) , melissa jaynes ( analyst - in - charge ) , sandra baxter and stacy spence made key contributions to this report .

also contributing to this report were james bennett , grace cho , alex galuten , danielle giese , corinna nicolaou , monica savoy , and almeta spencer .

