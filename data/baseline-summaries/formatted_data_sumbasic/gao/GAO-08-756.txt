in fiscal year 2008 , the federal aviation administration ( faa ) plans to spend approximately $2 billion on information technology ( it ) investments , many of which involve systems and technologies to modernize the air traffic control ( atc ) system or to transition to a next generation air transportation system ( nextgen ) .

over the past 13 years , we have identified faa's atc modernization as a high - risk initiative due to the cost , size , and complexity of this program as well as the cost overruns , schedule delays , and performance shortfalls that have plagued the system acquisitions that make up this effort .

to more effectively manage such investments , in 2005 the office of management and budget ( omb ) required agencies to implement earned value management ( evm ) .

evm is a project management approach that , if implemented appropriately , provides objective reports of project status , produces early warning signs of impending schedule delays and cost overruns , and provides unbiased estimates of anticipated costs at completion .

this report responds to your request that we review faa's use of evm .

specifically , our objectives were to ( 1 ) assess faa's policies for implementing evm on its it investments , ( 2 ) evaluate whether the agency is adequately using these techniques to manage key it acquisitions , ( 3 ) assess the agency's efforts to oversee compliance with its evm policies , and ( 4 ) evaluate whether the agency is using earned value data as part of its investment management process .

to address our objectives , we reviewed agency documentation , including faa - wide policies and plans governing the use of evm on it acquisitions , selected programs' documented evm practices and performance reports , internal evm assessment criteria and reports , and executive management briefings .

we conducted case studies of four programs that we selected for their large development and life - cycle costs , representation of faa's major modernization initiatives , and different stages of life - cycle maturity .

we compared the agency's policies and practices with federal standards and best practices of leading organizations to determine the effectiveness of faa's use of earned value data in managing its it investments .

we also interviewed relevant agency officials , including key personnel on programs selected for case study and the official responsible for implementing evm , and we observed working group meetings on evm .

this report builds on a body of work we have performed on faa's atc modernization efforts .

we conducted this performance audit from november 2007 to july 2008 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

further details on our objectives , scope , and methodology are provided in appendix i .

the mission of faa , an agency within the department of transportation , is to promote the safe , orderly , and expeditious flow of air traffic in the u.s. airspace system , commonly referred to as the national airspace system .

to maintain its ability to effectively carry out this mission , address an aging infrastructure , and meet an increasing demand for air transportation , in 1981 , faa embarked on a multibillion - dollar effort to modernize its aging atc system .

under this modernization program , faa has acquired and deployed new technologies and systems — and continues to do so today .

looking to the future , faa is now beginning to fund components of nextgen , a transformation to a new system that is expected to use satellite - based technologies and state - of - the - art procedures to handle increasing air traffic volume through 2025 , while further improving safety and security .

faa relies extensively on it to carry out its mission — both in terms of its operational air traffic responsibilities and its administrative activities .

the agency depends on the adequacy and reliability of the nation's atc system , which includes a vast network of radars , navigation and communications equipment , and information processing systems located at air traffic facilities across the country .

through its atc system , faa provides services such as controlling takeoffs and landings , and managing the flow of traffic between airports .

for example , the integrated terminal weather system integrates local weather data to allow the maximum use of airport runways .

the wide area augmentation system is used to provide vertically guided system approaches via global positioning system satellites and its own satellites to aircraft at thousands of airports and airstrips where there is currently no vertically guided landing capability , thereby improving safety and reducing pilot workload .

faa also relies on it to carry out its mission - support and administrative operations .

for example , faa uses it to support accident and incident investigations , security inspections , and personnel and payroll functions .

with an it budget of $2.1 billion for fiscal year 2008 , faa accounts for about 83 percent of the department of transportation's it budget .

for fiscal years 2007 through 2011 , faa plans to acquire more than $14 billion in new systems to continue operating the nation's current atc system , while simultaneously transitioning to nextgen .

this transition involves acquiring numerous systems to support precision satellite navigation ; digital , networked communications ; integrated weather information ; layered , adaptive security ; and more .

a cost - effective and timely transition to nextgen depends in large part on faa's ability to keep these acquisitions within budget and on schedule .

historically , however , faa has had chronic difficulties in meeting budget , schedule , and performance targets for acquisitions aimed at modernizing the national airspace system .

for example , in june 2005 , we reported that 13 of 16 selected major atc system acquisitions experienced cost , schedule , or performance shortfalls when assessed against their original milestones .

these 13 system acquisitions experienced cost increases ranging from $1.1 million to about $1.5 billion ; schedule extensions ranging from 1 to 13 years ; and performance shortfalls , including safety problems .

in 1995 , we designated faa's modernization of its atc system as a high - risk initiative because of the size , cost , and complexity of the program as well as difficulties in meeting cost , schedule , and performance goals on the individual projects that make up the modernization .

since then , in our high - risk series updates , we have reported on faa's efforts to address the underlying weaknesses that put it on the high - risk list .

these include faa's efforts to institutionalize key processes for acquiring and developing software systems , develop and enforce its enterprise architecture , improve its cost accounting and estimating practices , improve its ability to effectively manage it investments , and develop an organizational culture that supports sound acquisitions .

to the agency's credit , faa has taken a number of steps over the years to better manage its atc modernization program .

because of faa's contention that its modernization efforts were hindered by federal acquisition regulations , in november 1995 congress enacted legislation that exempted the agency from most federal acquisition laws and regulations .

the legislation directed faa to develop and implement a new acquisition management system that would address the unique needs of the agency .

in april 1996 , faa implemented an acquisition management system that provided acquisition policy and guidance for selecting and controlling faa's investments through all phases of the acquisition life cycle .

this guidance was intended to reduce the time and cost needed for fielding new products and services by introducing ( 1 ) a new investment management system that spans the entire life cycle of an acquisition , ( 2 ) a new procurement system that provides flexibility in selecting and managing contractors , and ( 3 ) organizational and human capital reforms that support the new investment and procurement systems .

more recently , in february 2004 , faa created the performance - based air traffic organization to control and improve faa's investments and operations and to better provide safe , secure , and cost - effective air traffic services now and into the future .

this change combined the groups responsible for developing and acquiring systems with those that operate them into a single organization .

the air traffic organization is led by faa's chief operating officer .

pulling together essential cost , schedule , and technical information in a meaningful , coherent fashion is a challenge for most programs .

without meaningful and coherent cost and schedule information , program managers can have a distorted view of a program's status and risks .

to address this issue , in the 1960s , the department of defense developed the evm technique , which goes beyond simply comparing budgeted costs with actual costs .

this technique measures the value of work accomplished in a given period and compares it with the planned value of work scheduled for that period and with the actual cost of work accomplished .

differences in these values are measured in both cost and schedule variances .

cost variances compare the earned value of the completed work with the actual cost of the work performed .

for example , if a contractor completed $5 million worth of work and the work actually cost $6.7 million , there would be a - $1.7 million cost variance .

schedule variances are also measured in dollars , but they compare the earned value of the work completed with the value of work that was expected to be completed .

for example , if a contractor completed $5 million worth of work at the end of the month but was budgeted to complete $10 million worth of work , there would be a - $5 million schedule variance .

positive variances indicate that activities are costing less or are completed ahead of schedule .

negative variances indicate activities are costing more or are falling behind schedule .

these cost and schedule variances can then be used in estimating the cost and time needed to complete the program .

without knowing the planned cost of completed work and work in progress ( i.e. , the earned value ) , it is difficult to determine a program's true status .

earned value provides information that is necessary for understanding the health of a program ; it provides an objective view of program status .

as a result , evm can alert program managers to potential problems sooner than expenditures alone can , thereby reducing the chance and magnitude of cost overruns and schedule delays .

moreover , evm directly supports the institutionalization of key processes for acquiring and developing systems and the ability to effectively manage investments — areas that are often found to be inadequate on the basis of our assessments of major it investments .

because of the importance of ensuring quality earned value data , in may 1998 , the american national standards institute ( ansi ) and the electronic industries alliance ( eia ) jointly established a national standard for evm systems .

this standard , commonly called the ansi standard , consists of 32 guidelines to instruct programs on how to establish a sound evm system , ensure that the data coming from the system are reliable , and use the earned value data to manage the program .

see appendix ii for an overview of this standard .

in august 2005 , omb issued guidance outlining steps that agencies must take for all major and high - risk development projects to better ensure improved execution and performance and to promote more effective oversight through the implementation of evm .

specifically , this guidance directs agencies to ( 1 ) develop comprehensive policies to ensure that agencies are using evm to plan and manage development activities for major it investments ; ( 2 ) include a provision and clause in major acquisition contracts or agency in - house project charters directing the use of an evm system compliant with the ansi standard ; ( 3 ) provide documentation demonstrating that the contractor's or agency's in - house evm system complies with the national standard ; ( 4 ) conduct periodic surveillance reviews ; and ( 5 ) conduct integrated baseline reviews on individual programs to finalize the cost , schedule , and performance goals .

building on omb's requirements , in july 2007 , we issued a draft guide on best practices for estimating and managing program costs .

this guide highlights the policies and practices adopted by leading organizations to implement an effective evm program .

specifically , in the guide , we identify the need for organizational policies that establish clear criteria for which programs are required to use evm , compliance with the ansi standard , a standard product - oriented structure for defining work products , integrated baseline reviews , specialized training , criteria and conditions for rebaselining programs , and an ongoing surveillance function .

in addition , we identify key practices that individual programs can use to ensure that they establish a sound evm system , that the earned value data are reliable , and that the data are used to support decision making .

omb refers to this guide as a key reference manual for agencies in its 2006 capital programming guide .

two faa executives — the acquisition executive and the chief information officer — are jointly responsible for implementing evm and ensuring its consistent application across the agency's it acquisitions .

the acquisition executive's responsibilities include developing evm policy and guidance , certifying contractors' conformance with the ansi standard , advising and assisting programs with integrated baseline reviews , approving programs' plans for continued surveillance of contractors' evm systems , and managing the evm training program and curriculum .

the acquisition executive established the position of evm focal point to lead these efforts .

the chief information officer's responsibilities include assisting in the development of evm policy and guidance , certifying programwide conformance with the ansi standard , performing ongoing programwide evm system surveillance , and managing the preparation of information reported on programs' annual business cases — which includes verifying the accuracy of the program baseline , schedule and cost performance , and corrective action plans .

the chief information officer established a value management office to perform these functions .

in 2005 , faa established a policy requiring the use of evm on its major it investments ; however , key components of this policy are not fully consistent with best practices .

we recently reported that leading organizations establish evm policies that establish clear criteria for which programs are to use evm ; require programs to comply with the ansi standard ; require programs to use a product - oriented structure for defining work products ; require programs to conduct detailed reviews of expected costs , schedules , and deliverables ( called an integrated baseline review ) ; require and enforce evm training ; define when programs may revise cost and schedule baselines ( called require system surveillance — routine validation checks to ensure that major acquisitions are continuing to comply with agency policies and standards .

table 1 describes the key components of an effective evm policy .

faa began developing evm - related policies for its it acquisition programs in 2005 .

the agency currently has a policy in place that fully addresses four of the seven areas and partially addresses the remaining three areas ( see table 2 ) .

specifically , faa has policies and guidance in its acquisition management system that fully address evm implementation on all major it investments , compliance with the ansi standard , integrated baseline reviews , and system surveillance .

these policies are discussed below .

criteria for implementing evm on all it major investments: faa requires all of its major development , modernization , and enhancement programs to use evm .

specifically , these are all programs with a requirement to provide a business case to omb .

in addition , faa requires that all contracts and subcontracts that are expected to exceed a cost of $10 million for development , modernization , and enhancement work must be managed using an evm system .

projects lasting less than 1 year are not required to use evm .

compliance with the ansi standard: faa requires that all work activities performed on major programs by government personnel , major contractors , and support contractors be managed using an evm system that complies with industry standards .

faa's evm focal point is responsible for certifying that contractors with contracts over $10 million conform with the standard .

faa's value management office is responsible for certifying that each program conforms with the standard .

integrated baseline reviews: faa requires each program manager to conduct a comprehensive review of a program baseline for major programs and contracts within 90 to 180 days of contract award or program baseline establishment .

furthermore , an updated integrated baseline review must be performed after a program exercises significant contract options or executes modifications .

the agency's guidance calls for the involvement of program management teams , prime contractor management , and independent subject matter experts who validate the program baselines and performance measurement processes .

system surveillance: faa requires ongoing surveillance of all programs and contracts that are required to use evm systems to ensure their continued compliance with industry standards .

the value management office is responsible for providing surveillance at the program level through annual assessments of each major program .

individual program managers and contracting officers are responsible for conducting surveillance on their contractors' evm in accordance with a surveillance plan approved by the evm focal point .

however , faa's policy and guidance are not consistent with best practices in three areas: defining a product - oriented structure for defining work products , requiring evm training , and establishing rebaselining criteria .

these areas are discussed below .

standard structure for defining work products: faa requires its programs to establish a standard work breakdown structure .

however , faa calls for a function - oriented structure , rather than a product - oriented one .

this means that work is delineated based on functional activities , such as design engineering , requirements analysis , and quality control .

in contrast , a product - oriented work breakdown structure reflects cost , schedule , and technical performance on specific deliverables .

without the level of detail provided by a product - oriented approach , program managers may not have the information they need to make decisions on specific program components .

for example , cost overruns associated with a specific radar component could be quickly identified and addressed using a product - oriented structure .

if a function - oriented structure were used , these costs could be spread out over design , engineering , and quality control .

faa program managers can choose to use a product - oriented work breakdown structure to manage their programs and contracts , but then they need to transfer their data to faa's required function - oriented work breakdown structure when reporting to management .

evm experts agree that such mapping efforts are time - consuming and subject to error .

furthermore , programs do not always map items in the same way , and , as a result , costs may not be captured consistently across programs .

faa officials stated that they use the functional format because it is aligned with the agency's cost accounting system .

while this presents a challenge , it is not insurmountable .

for example , in the near - term , the agency could develop a standard mapping function to translate product - oriented program data into the function - oriented cost accounting system .

while this approach would not resolve the time - consuming nature of mapping ( since programs would still be expected to complete this activity ) , it does at least allow costs to be captured consistently across programs .

as a longer - term solution , we have repeatedly urged government agencies to adopt cost accounting systems that provide meaningful links among budget , accounting , and performance .

such systems are consistent with product - oriented work breakdown structures .

until faa establishes a standard product - oriented work breakdown structure , program officials who use the function - oriented approach to manage their contracts may not be obtaining the information they need .

furthermore , program officials who choose to manage using a product - oriented structure will continue to spend valuable time and effort mapping their product - oriented structures to the faa standard , and the agency will continue to risk that data are captured inaccurately or inconsistently during this mapping exercise .

evm training requirements: faa has developed evm training and requires program managers to complete a minimum of 24 hours of evm and cost estimating training .

however , the agency does not specify evm training requirements for program team members or senior executives with program oversight responsibilities .

in addition , the agency does not enforce evm training to ensure that all relevant staff have completed the required training .

instead , individual program offices are responsible for ensuring that their teams obtain sufficient evm training .

some programs ensure that all key program staff have completed the appropriate level of training they need to understand their roles and responsibilities , while other programs do not .

until faa establishes evm training requirements for all relevant personnel ( including executives with oversight responsibilities and program staff responsible for contract management ) and verifies the completion of this training , it cannot effectively ensure that its program staff have the appropriate skills to validate and interpret evm data , and that its executives fully understand the data they are given in order to ask the right questions and make informed decisions .

rebaselining criteria: faa requires that programs seeking a new cost and schedule baseline gain approval from a board of executives , called the joint resources council , which is responsible for investment decisions .

however , the agency does not define acceptable reasons for rebaselining or require programs to identify and address the reasons for the need to rebaseline .

until faa addresses these elements , it will face an increased risk that its executive managers will make decisions about programs with incomplete information , and that these programs will continue to overrun costs and schedules because their underlying problems have not been identified or addressed .

faa is using evm to manage system acquisition programs , but the extent of implementation varies among programs .

case studies of four programs demonstrated that all are using or planning to use evm .

however , the four programs are not consistently performing evm on the full scope of the program ( as opposed to the scope of the contract ) and ensuring that the earned value data are reliable .

until these areas are fully addressed , faa faces an increased risk that program managers are not adequately using earned value to manage their programs .

our work on best practices in evm identified 11 key practices that are implemented on acquisition programs of leading organizations .

these practices can be organized into three management areas: establishing a sound evm system , ensuring reliable data , and using earned value data to manage .

table 3 lists these 11 key practices .

we performed case studies of four faa system acquisitions: the airport surveillance radar ( asr - 11 ) , en route automation modernization ( eram ) , surveillance and broadcast services ( sbs ) , and system wide information management ( swim ) .

all of the four key faa system programs demonstrated at least a partial level of evm implementation .

figure 1 summarizes our results on these selected programs .

following the figure , we provide a summary of each key area of program management responsibility in evm .

in addition , more details on the four case studies are provided in appendix iii .

the four programs did not consistently establish comprehensive evm systems , but were able to justify these shortfalls .

of the four programs , only sbs demonstrated that it had fully implemented the six practices in this area .

for example , the program established an integrated performance baseline that captures the full scope of work on the program and links directly to the integrated master schedule .

two programs — asr - 11 and eram — demonstrated that they partially implemented each of the six key practices in this area .

both had a reasonable justification for their partial evm implementation: the systems were initiated before faa required projects to obtain evm data and have implemented work - arounds to allow them to meet faa's current earned value reporting requirements .

specifically , the asr - 11 team does not receive any evm data , so the team established a performance measurement baseline to estimate the work remaining on both the contractor and government portions of the program .

alternatively , eram has implemented evm to govern the contract deliverables , but not the government's portion of the program .

instead , the program estimates government costs .

the fourth program , swim , has initiated evm practices , but these efforts are still under way because the system is in an early stage in its acquisition life cycle .

at the time of our review , swim had fully met two of the six key practices .

for example , swim has a work breakdown structure and has identified who will perform the work .

in addition , the program is currently developing its integrated master schedule and plans to complete all key evm process steps prior to beginning development work ( which is expected to begin in fiscal year 2009 ) .

swim is not currently collecting evm data .

the three programs that currently collect or estimate monthly evm data ( asr - 11 , eram , and sbs ) did not consistently ensure that their evm data were reliable .

of the three programs , one fully implemented the practices for ensuring the reliability of the prime contractor and government performance data , one partially implemented the practices but had justification for its shortfalls , and one partially implemented the practices .

sbs demonstrated that it fully implemented the three practices .

the program requires its technical managers to validate the earned value data they are responsible for collecting on a monthly basis .

it also established mechanisms to alert the team if the contractor's deliverables may not meet system requirements .

in addition , program evm analysts are expected to analyze and report cost and schedule performance trends and cost estimates to complete the remaining work to the program manager and an internal management review board .

asr - 11 partially implemented each of the three practices for ensuring that earned value data are reliable , but had a justification for this shortfall .

as we have previously noted , asr - 11 measures government and contractor effort ; however , it is constrained in its oversight capabilities since the prime contractor is not required to report earned value information or cost data to faa .

as a result , the program is unable to collect or validate actual costs expended on the contractor's scope of work .

instead , asr - 11 relies on schedule status to determine when planned work on a contract deliverable has been authorized to begin — such as work to dismantle a legacy facility site — and completed .

the program depends on the receipt of air force invoices to determine the actual costs for that planned effort , and relies on its faa teams that are on - site to get qualitative assessments of the cost and schedule drivers impacting performance .

despite the external constraints , asr - 11 has a skilled team in place to assess the evm data , perform the appropriate analyses of performance trends , and make projections of estimated costs at program completion .

eram also partially implemented each of the three practices for ensuring that earned value data are reliable .

the eram program team analyzes the prime contractor's monthly evm data and variance reports and then uses that information to make projections of estimated costs at program completion .

however , we identified several anomalies in the contractor's reports over an 11-month period that suggest the contractor may not be reliably reporting its work activities .

for example: there were multiple cases in which the contractor reported that no work was planned or accomplished , yet funds were spent ; in other cases , the contractor reported that work was planned and accomplished , but funds were credited to the government .

there were also cases in which the contractor reported that work was planned and dollars spent , but a negative amount of work was performed ( i.e. , work that was previously reported as completed was now reported as not completed ) .

the contractor did not provide an explanation for these issues in its reports to the eram program office .

in september 2007 , the contractor planned to complete $102 million worth of work — a significant spike in planned work , given that the average amount of work planned and accomplished in a single month is about $25 million .

furthermore , the contractor reported that it accomplished $100 million worth of that work and spent only $31 million to complete it .

the contractor did not provide a justification for this steep spike in work planned and accomplished , or for the sizable gap between the work accomplished and the cost of this work .

the eram program office was also unable to explain why this occurred .

these reporting anomalies raise questions about the reliability of the contractor data and the quality of the program's efforts to verify and validate these data .

program officials were unable to explain these anomalies .

until eram improves its ability to assess contract data and resolve anomalies , it risks using inaccurate data to manage the contractor , potentially resulting in cost overruns , schedule delays , and performance shortfalls .

all three programs that currently collect monthly evm data were able to demonstrate that they use these data to manage their programs .

the sbs program manager conducts rigorous reviews with its internal performance management review board to discuss the program's earned value performance against planned cost and schedule targets and take appropriate actions to reverse negative trends .

the asr - 11 program manager is using the current cost and schedule variances being accrued on site construction work to make projections on the overall cost to complete this work and to create risk mitigation plans to address the cost and schedule drivers .

the eram program manager uses the earned value data to identify areas of concern and make recommendations to the contractor on items that should be watched , mitigated , and tracked to closure .

currently , the program manager is monitoring the contractor's use of management reserve as well as fluctuating cost variances associated with the design and engineering supporting eram's initial capability .

faa has taken important steps to oversee compliance with evm policies by establishing an oversight office , assessing major systems using defined evaluation criteria , and demonstrating improved capabilities on most programs .

however , the oversight office's assessments are not thorough enough to identify anomalies in contractor data , and its agencywide progress reports can be misleading , in that the agency's evaluation process does not distinguish between systems that collect comprehensive data and those that do not .

as a result , faa executives do not always receive an accurate view of the quality of a program's evm data when making investment decisions on that program .

according to best practices in program oversight , an organization should assign responsibility for providing oversight , establish and implement a plan for conducting oversight that is sufficiently detailed to identify problems , and report on its progress over time .

faa established an oversight program to ensure evm compliance assessments on its major programs .

in august 2005 , faa established the value management office , an organization responsible for assessing the evm compliance of all major it acquisition programs .

this office developed an evm system assessment plan to evaluate each major system program .

this plan defines the evidence needed to obtain a weak , moderate , or strong score for each of the 32 guidelines in the ansi standard .

the group assesses each major program's earned value capabilities on an annual basis .

in addition , this office provides its senior executives and omb with a summary of the evm compliance status of all major programs .

faa reports that its it systems have made major improvements in their earned value capabilities over the last few years .

for example , in august 2005 , faa reported that 6 of its 19 major it acquisition programs ( or 32 percent ) had fully complied with the standard .

as of february 2008 , faa reported that 17 of its 23 major it programs ( or 74 percent ) had achieved full compliance with the ansi standard .

while faa's oversight has accomplished much since it was established , the process used to assess and report on programs lacks the rigor needed to be a reliable gauge of agency progress .

best practices call for program evm oversight to include an assessment of both government and contractor performance data to identify issues that may undermine the validity of these data .

in addition , to be transparent and reliable , reports on the status of programs' evm implementation should clearly identify situations in which programs are unable to fully comply with faa policies .

in assessing programs' evm compliance , faa's oversight office obtains and reviews earned value data for the program as a whole .

it does not analyze the contractor's performance data .

for example , faa's oversight office did not review eram's contractor data and , therefore , did not identify anomalies in which funds were spent on no work and other work was performed for no funds .

as a result , it rated the program highly on factors associated with data reliability .

in addition , in reporting agencywide progress in implementing evm , the agency's oversight process does not distinguish between programs that collect earned value data only on the contract level , and those that collect integrated data on the program as a whole .

for example , both eram and asr - 11 use approximations to reflect their earned value data .

as we have previously noted , asr - 11 uses approximations for the entire program because another agency administers the contract .

eram uses approximations only for the government portions of the program .

nonetheless , faa gave both of these programs their highest ratings .

this is misleading in that it portrays the performance data on these programs as having the same level of precision as programs that have an integrated approach to evm .

since these programs were initiated before the evm requirement , it is likely that other older acquisition programs have also implemented work - arounds .

of the 23 major programs assessed by faa , 16 were initiated before the evm policy was established .

until these issues are resolved , faa will be unable to effectively ensure that evm implementation is consistent across the agency , and that faa executives obtain an inaccurate view of the quality of an individual program's evm data when making investment decisions .

to obtain better insight into the progress made on its system acquisition programs , faa incorporated evm performance data into its process for reviewing it investments .

our work in it investment management highlights the importance of executive decision makers having sufficient insight into program status so that they can identify and mitigate risks , and ensure that programs are on track against established cost and schedule expectations .

the performance data from program evm systems are critical for helping managers achieve sufficient insight on program status .

faa executives are reviewing evm data as part of their investment review process .

the level of detail in evm data reporting is dependent on the level of executive review .

for example , executives responsible for a portfolio of projects conduct project reviews on a quarterly basis .

they obtain project data that include cumulative cost and schedule variance reporting over an extended period .

for example , asr - 11 has reported cumulative trends over an 11-month period .

other key reported performance metrics include estimated costs at program completion , cost and schedule efficiency indexes ( which describe the dollar value of work being accomplished for every dollar spent ) , and management reserve .

at a more senior level , faa's joint resource council receives project data on a monthly basis , is briefed on projects that are breaching cost and schedule variances by more than 10 percent on a quarterly basis , and obtains detailed briefings on projects twice a year .

at this time , these briefings contain a program dashboard matrix , which shows the earned value cost and schedule efficiency indexes taken over a 6-month period .

faa's value management office also has a joint initiative under way with the joint resource council to refine the dashboard matrix in order to determine the most appropriate data , as well as level of detail , that will enable decision makers to prevent , detect , and respond to issues in a timely manner .

faa has taken a number of important steps to improve the management of its it investments through the implementation of evm .

the agency has established policies that require the use of evm ; system acquisition programs are using earned value data to manage their programs ; an oversight office monitors system acquisition programs' compliance with policy and standards ; and earned value performance data are being used by multiple levels of management as they review and manage it investment .

however , the agency does not fully ensure the accuracy and usefulness of earned value data as a management tool .

specifically , faa policies lack sufficient guidance on the type of work structure needed to most effectively use evm data , training requirements do not extend to all relevant personnel and call for this training to be monitored and enforced , and programs are not required to identify or mitigate the root cause of any cost and schedule overruns when they request a revised cost and schedule baseline .

in addition , faa programs are not consistently ensuring that the data coming from contractors are reliable .

of the three programs we reviewed that currently collect earned value data , one program , eram , had no explanation for anomalies in its contractor data wherein funds were spent but no work was done ; in another situation , work was accomplished but funds were credited to the government .

this is of concern because both program managers and agency executives could be making programmatic and investment decisions on the basis of inaccurate and misleading data .

furthermore , faa's value management office — an internal evm oversight group — does not evaluate the validity of contractor data or distinguish between programs that have comprehensive earned value systems and ones that have implemented work - arounds .

as a result , faa executives are , in selected cases , receiving an inaccurate view of the quality of a program's evm data , which could impede sound investment decisions .

until these issues are resolved , it will be difficult for faa to effectively implement evm or optimize its investment in this critical management tool .

to improve faa's ability to effectively implement evm on its it acquisition programs , we recommend that the secretary of transportation direct the acting faa administrator to take the following seven actions: modify acquisition policies governing evm to require the use of a product - oriented standard work breakdown structure , enforce existing evm training requirements and expand these requirements to include senior executives responsible for investment oversight and program staff responsible for program oversight , and define acceptable reasons for rebaselining and require programs seeking to rebaseline to ( 1 ) perform a root cause analysis to determine why significant cost and schedule variances occurred and ( 2 ) establish mitigation plans to address the root cause .

direct the eram program office to work with faa's value management office to determine the root causes for the anomalies found in the contractor's evm develop a corrective action plan to resolve these problems .

direct the value management office to improve its oversight processes by including an evaluation of contractors' performance data as part of its program assessment criteria , when faa has the authority to do so , and distinguishing between programs that collect earned value data on fully integrated programs and those that do not in its agencywide progress reports to provide transparency to decision makers .

the department of transportation's director of audit relations provided comments on a draft of this report via e - mail .

in those comments , he said that the department generally agreed with the findings and recommendations contained in the draft .

the department also provided technical comments , which we have incorporated in this report as appropriate .

we will be sending copies of this report to interested congressional committees , the secretary of transportation , the acting faa administrator , and other interested parties .

we will also make copies available to others upon request .

in addition , the report will be available at no charge on our web site at http: / / www.gao.gov .

if you or your staffs have any questions on the matters discussed in this report , please contact me at ( 202 ) 512-9286 or by e - mail at pownerd@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iv .

our objectives were to ( 1 ) assess the federal aviation administration's ( faa ) policies for implementing earned value management ( evm ) on its information technology ( it ) investments , ( 2 ) evaluate whether the agency is adequately using evm techniques to manage key system acquisitions , ( 3 ) assess the agency's efforts to oversee compliance with its evm policies , and ( 4 ) evaluate whether the agency is using evm data as part of its it investment management .

to assess whether faa has policies in place to effectively implement evm , we analyzed faa's policies and guidance that support evm implementation agencywide as well as on system acquisition programs .

specifically , we compared these policies and guidance documents with both the office of management and budget's ( omb ) requirements and key best practices recognized within the federal government and industry for the implementation of evm .

these best practices are contained in an exposure draft version of our cost guide .

we also interviewed key agency officials and observed faa evm working group meetings to obtain information on the agency's ongoing and future evm plans .

to determine whether key faa system programs are adequately using evm techniques , we performed case studies on 4 of faa's 23 system acquisition programs currently required to use evm: the airport surveillance radar ( asr - 11 ) , en route automation modernization ( eram ) , surveillance and broadcast services ( sbs ) , and system wide information management ( swim ) .

in consultation with faa officials , we selected programs with high development and life - cycle costs , which represented faa's two major modernization initiatives — the air traffic control modernization and the next generation air transportation system ( nextgen ) — and reflected different stages of life - cycle maturity .

these studies were not intended to be generalizable , but instead to illustrate the status of a variety of programs .

to determine the extent of each program's implementation of sound evm , we compared program documentation with the fundamental evm practices implemented on acquisition programs of leading organizations , as identified in our cost guide .

we determined whether the program implemented , partially implemented , or did not implement each of the 11 practices .

we further analyzed the evm data obtained from the programs to assess the program performance against planned cost and schedule targets .

finally , we interviewed program officials to obtain clarification on how evm practices are implemented and how the data are validated and used for decision - making purposes .

regarding the reliability of cost data , we did not test the adequacy of agency or contractor cost - accounting systems .

our evaluation of these cost data was based on what we were told by the agency and the information they could provide .

to determine whether faa is effectively overseeing compliance with its evm policies , we reviewed the quality and completeness of the agency's surveillance efforts on its system acquisition programs .

specifically , we reviewed the agency's evm assessment reports for programs , faa - developed evm assessment criteria , and other relevant documents .

we further compared the results of faa's evm assessment for each of the selected case study programs with the results of our case evaluation to ascertain the extent to which the results were in agreement .

we also interviewed key agency officials and observed faa evm working group meetings to obtain information on the agency's ongoing surveillance efforts and issues regarding these efforts .

to evaluate whether faa is using evm data as part of its it investment management process , we analyzed senior executive management briefings , omb business cases ( exhibit 300 ) , and other key management reports on program status .

specifically , we analyzed briefings and status reports to determine the types of evm metrics used in describing program status for senior - level decision - making purposes .

we also compared this analysis with the key best practices recognized within the federal government and industry for the implementation of evm , as well as for the execution of sound it investment management .

we also interviewed key agency officials to obtain information on the extent of executive - level evm awareness and clarification on how evm is used in faa's capital planning process .

we conducted this performance audit from november 2007 to july 2008 at faa offices in washington , d.c. , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

organizations must be able to evaluate the quality of an evm system to determine the extent to which the cost , schedule , and technical performance data can be relied on for program management purposes .

in recognition of this , the american national standards institute ( ansi ) and the electronic industries alliance ( eia ) jointly established a national standard for evm systems — ansi / eia - 748-b ( commonly referred to as the ansi standard ) .

this standard consists of 32 guidelines addressing organizational structure ; planning , scheduling , and budgeting ; accounting considerations ; analysis and management reports ; and revisions and data maintenance .

these guidelines comprise three fundamental management functions for effectively using evm: establishing a sound evm system , ensuring that the evm data are reliable , and using earned value data for decision - making purposes .

table 4 lists the management functions and the ansi guidelines .

we conducted case studies of four major system acquisition programs: asr - 11 , eram , sbs , and swim .

for each of these programs , the following sections provide a brief description of the system ; an assessment of the system's implementation of the 11 key evm practices ; and , where applicable , an analysis of the system's recent earned value data and trends .

these data and trends are often described in terms of cost and schedule variances .

cost variances compare the earned value of the completed work with the actual cost of the work performed .

schedule variances are also measured in dollars , but they compare the earned value of the work completed with the value of work that was expected to be completed .

positive variances are good — they indicate that activities are costing less than expected or are completed ahead of schedule .

negative variances are bad — they indicate activities are costing more than expected or are falling behind schedule .

asr - 11 is a joint program sponsored by both faa and the u.s. air force to replace outdated primary radar systems at selected airports with an integrated digital primary and secondary radar system .

this investment is also to replace the deteriorating infrastructure supporting current radar systems with new radar facilities , including advanced grounding and lightning protection systems , digital or fiber - optic telecommunications , emergency backup power supplies , and enhanced physical security .

the contract was awarded in 1996 and is managed by the air force .

the total program cost is currently estimated at $1.15 billion , with $437.2 million remaining to be spent ( see table 5 ) .

asr - 11 is currently being deployed across the country .

as of april 2008 , 44 of the total of 66 systems were operational .

faa plans to complete deployment of these systems by march 2010 .

asr - 11 fully met 2 of the 11 key practices and partially met 9 others ( with justification for not being able to fully meet these ) .

for example , asr - 11 fully met the practices involving using earned value information to mitigate risks and updating baselines as changes occur .

asr - 11 partially met the other practices because , while the program implemented many key components of an effective evm system , asr - 11 is limited in what it can measure and validate .

there are two reasons for these limitations: ( 1 ) the contract was awarded in the mid - 1990s , before faa implemented its evm requirements , and ( 2 ) faa does not have the authority to obtain data on actual costs expended by the contractor or air force because air force is the contracting agency .

to work around these constraints , faa's asr - 11 program management team developed a system that allows them to approximate evm reporting and tracking at the program level on the basis of estimated ( not actual ) costs .

specifically , asr - 11 established a program - level work breakdown structure , developed a work schedule , and identified who will perform the work .

asr - 11 has also implemented evm using estimated data and analyzes its estimated evm results against its performance measurement baseline .

while valuable , this approximation does not fully meet the key practices needed to establish a sound evm system and ensure data reliability .

however , faa is limited in what it can measure and how it can validate the work accomplished and the dollars spent .

table 6 shows the detailed assessment results for asr - 11 .

asr - 11 experienced negative cost variances between january 2007 and december 2007 ( see fig .

2 ) .

in this period , the program exceeded cost targets by $19.2 million — which is 3.3 percent of the program budget for that time .

similarly , the asr - 11 program was unable to complete $20.6 million ( 3.4 percent ) of the work planned in this period .

the main factors contributing to the cost and schedule variances were high construction costs , due mainly to the effects of hurricane katrina , and an unusually long real estate acquisition for the green bay , wisconsin , asr - 11 site .

program officials are currently working on a request to rebaseline the program due to the current high variances .

based on the program performance trends , we estimate that the program will overrun its budget by between $7.6 million and $53.3 million .

our projection of the most likely cost overrun will be about $9.8 million .

in comparison , the asr - 11 program office estimates about a $6.2 million overrun at program completion .

eram is to replace existing software and hardware in the air traffic control automation computer system and its backup system , the direct access radar channel , and other associated interfaces , communications , and support infrastructure at en route centers across the country .

it is a critical effort because it is expected to upgrade hardware and software for facilities that control high altitude air traffic .

the contract was awarded in 2002 .

the eram prime contract requires evm to be accomplished by the contractor in accordance with the ansi standard .

the total program cost is estimated at $2.93 billion , with $1.2 billion still to be spent ( see table 7 ) .

eram consists of two major components .

one component has been fully deployed and is currently in operation at facilities across the country .

the other component is scheduled for deployment through fiscal year 2009 .

eram fully met 2 of the 11 key practices for implementing evm and partially met 9 others ( with justification for 6 of these ) .

eram fully met the practices involving using evm data to mitigate risks and updating performance baselines as changes occur .

eram partially met 6 other practices , with justification , because of limitations in the earned value data for the government portions of the program .

specifically , eram manages its contractor using an evm system that includes a work breakdown structure , master schedule , and performance baseline .

however , eram did not implement a comprehensive evm system that integrates government and contractor data because this was not a requirement when the program was initiated in 2002 .

program officials reported that they implemented a work - around to approximate the government portion of the program .

the eram program partially implemented the 3 remaining practices associated with data reliability .

anomalies in the prime contractor's evm reports affect the program's ability to execute the work plan , analyze variances , and estimate the cost of the program at completion .

table 8 shows the detailed assessment results for eram .

using contractor - provided data , our analysis indicates that the eram program experienced positive cost and schedule performance in 2007 ( see fig .

3 ) .

specifically , from january 2007 to december 2007 , the contractor was able to outperform its planned targets by finishing under budget by $11.3 million ( 1 percent of the work for this period ) and by completing $25.5 million , or 3 percent , worth of work beyond what was planned .

factors that contributed to the positive cost and schedule variances include less labor needed than planned , savings in materials purchased , and higher productivity and efficiency .

for example , the program contractor reported a positive schedule variance in 2007 due to technology refresh activities at the william j. hughes technical center being accomplished earlier than planned .

however , as we have previously noted , our analysis of eram's contractor performance reports uncovered a number of anomalies that raise questions regarding the reliability of these data .

furthermore , the contractor did not provide justification for these anomalies , and the program office was unable to explain the occurrences .

sbs is to provide new surveillance solutions that employ technology using avionics and ground stations for improved accuracy and update rates and provide shared situational awareness ( including visual updates of traffic , weather , and flight notices ) between pilots and air traffic control .

these technologies are considered critical to achieving the faa strategic goals of decreasing the rate of accidents and incursions , improving the efficiency of air traffic , and reducing congestion .

the program is currently estimated at $4.31 billion , with a total of $4.11 billion planned to be spent for the remaining work until completion ( see table 9 ) .

the program reported that the achievement of cost , schedule , and performance goals was expected to be tracked and monitored through faa best practices and established evm processes defined by faa .

monthly program reviews , detailed schedule updates , and evm reporting are expected to be applied in accordance with the faa evm policy .

future contracts are expected to include all evm requirements since established by faa and to be consistent with the industry standards and omb a - 11 guidance .

sbs implemented all 11 of the key practices necessary to ensure that the program was planned in accordance with industry standards , that the resulting evm data were appropriately verified and validated for reliability , and that the sbs management team was using these data for decision - making purposes .

table 10 shows the detailed assessment results for sbs .

from december 2007 to february 2008 , sbs cost performance has been mixed against its planned cost and schedule targets ( see fig .

4 ) .

the program was able to outperform its cost targets by $3.0 million .

however , the sbs program was unable to complete $4.5 million , or 6 percent of the value of planned work .

the program indicated that the positive program cost variances were associated with key activities ( including the preliminary design review ) taking less effort than expected to complete .

the negative schedule variances were primarily due to scheduling errors and system - level testing issues .

in particular , the system - level testing was delayed due to a lack of readiness of the test environment , test documentation , and equipment .

as the key information management and data sharing system for nextgen , swim is expected to provide policies and standards to support data management , along with the core services needed to publish data to the network , retrieve the data , secure the data's integrity , and control access and use of the data .

swim is also expected to reduce the number and types of interfaces and systems , reduce unnecessary redundancy of information , better facilitate information - sharing , improve predictability and operational decision making , and reduce cost of service .

the faa's joint resource council established a baseline for the first 2 years of the first segment of this program on june 20 , 2007 .

the estimated life - cycle cost for the total swim program is $546.1 million , with $501.3 million still to be spent ( see table 11 ) .

swim is in the planning phase of its life cycle , which entails setting up the program's evm system of internal controls and the resulting performance measurement baseline .

evm data will not be available until development work begins in fiscal year 2009 .

our assessment of swim's evm process maturity indicated that the program is on track in its implementation of evm .

specifically , it has fully met two of the six key process steps for ensuring that the program is planned in accordance with industry standards .

swim also has work under way to address the other four steps .

we did not assess swim in the five key process steps related to evm data reliability and use in program decision making because the program has not begun development work at this time .

table 12 shows the detailed assessment results for swim .

in addition to the contact named above , colleen phillips ( assistant director ) , kate agatone , carol cha , neil doherty , nancy glover , and teresa smith made key contributions to this report .

