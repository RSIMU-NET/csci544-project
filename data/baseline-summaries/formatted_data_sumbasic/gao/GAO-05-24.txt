automobile crashes exact an enormous personal and economic toll on this country .

in 2003 , 42,643 people died in automobile crashes in the united states , and nearly 2.9 million more were seriously injured .

in 2000 , the most recent year for which cost estimates are available , the economic cost of fatalities and injuries from crashes totaled almost $231 billion .

reducing this toll requires making informed decisions about safety problems .

traffic safety data , which are compiled from police accident reports completed at the scene of crashes and assembled largely at the state level , are key to making these decisions .

the states and the federal government use data from state - level crash data systems to make many roadway - related spending and policy decisions , ranging from deciding to fix particular roadways to launching major national safety campaigns , such as preventing alcohol - impaired driving or increasing seat belt use .

there is known variability in the quality of information in state traffic data systems , and these differences impact the usefulness of data for these purposes .

when the congress was considering reauthorizing various transit and highway programs earlier this year , both the house and senate proposed bills that would have expanded the section “411 grant program,” which was initially authorized in the transportation equity act for the 21st century ( tea - 21 ) .

the 411 grant program was designed specifically to help states improve their traffic safety data systems and provided states with $36 million over 6 years .

the house and senate proposals would have authorized a similar grant program with a budget authority of up to $270 million over 6 years .

however , an 8-month extension of tea - 21 was passed on september 30 , 2004 , extending current highway and transit programs through may 2005 when both bills may be reintroduced .

the senate appropriations committee report accompanying the department of transportation appropriations bill for fiscal year 2004 ( s. 1589 ) directed us to conduct a survey of state traffic safety data systems .

the committee also asked us to report on the extent to which the 411 grant program has led to improvements in these systems .

the grant program is overseen by the department of transportation's ( dot ) national highway traffic safety administration ( nhtsa ) , which has established six criteria for assessing such systems when states request guidance from nhtsa .

four criteria relate to the information itself ( timeliness , consistency , completeness , and accuracy ) ; two relate to the use of the information ( accessibility to users and links to other related data ) .

accordingly , this report examines ( 1 ) the quality of state crash information ; ( 2 ) the activities states undertook using 411 grant funds to improve their traffic safety data systems , and the progress they made using the grant funds ; and ( 3 ) nhtsa's oversight of the grant program , including what changes in oversight , if any , might help encourage states to improve their traffic data systems and ensure accountability under a reauthorized program .

to provide information on the quality of state crash data and state efforts to improve these data , we conducted site visits , analyzed available traffic safety data , and reviewed grant documentation .

using several criteria , we selected 9 states to visit for detailed reviews and assessed the status of their data systems on the basis of nhtsa's six quality criteria for crash information .

eight of these 9 states had participated in the 411 grant program .

to identify variations in data structure and quality , we also analyzed crash data for 17 states that currently participate in nhtsa's state data system ( sds ) program .

finally , we reviewed the grant documentation submitted by the 48 states that participated in the 411 grant program , including grant applications , traffic records assessments , strategic plans , progress reports , and highway safety plan annual evaluation reports .

to provide information about nhtsa's oversight of the program , we interviewed nhtsa officials responsible for oversight and administration and reviewed nhtsa guidance and policy .

we conducted our review from january 2004 through october 2004 in accordance with generally accepted government auditing standards .

see appendix i for more details regarding our objectives , scope , and methodology .

because an examination of data quality was one of the objectives of this report , we also conducted an assessment of data reliability .

a more complete discussion of data reliability can be found in appendix ii .

traffic safety data are the primary source of knowledge about crashes and how they are related to the traffic safety environment , human behavior , and vehicle performance .

most states have developed traffic safety data systems and manage these data through the initial reporting of crashes by law enforcement officers through data entry and analysis .

figure 1 , which is based on nhtsa's traffic records highway safety program advisorydepicts a model state traffic safety data system , including the collection and submission of data , the processing of these data into state safety data systems , and the potential uses for quality crash information .

these data are often not housed in a single file or on just one computer system ; however , users should have access to crash information in a useful form and of sufficient quality to support the intended use .

at the state level , state agencies use traffic safety data to make highway safety planning decisions and to evaluate the effectiveness of programs , among other uses .

in those states where quality crash data on a range of crashes are not available , officials use federal data such as that from nhtsa's fatality analysis reporting system ( fars ) to make programming decisions .

fars data , while useful for some purposes , are limited because they only include information about fatal crashes , thus preventing decision making based on a range of crash severity or the entirety of a state's crash situation .

at the federal level , nhtsa provides guidelines , recommendations , and technical assistance to help states improve their crash data systems and is responsible for overseeing state highway safety programs .

under tea - 21 , nhtsa awarded $935.6 million in highway safety incentive grants to improve safety .

in 2003 , nhtsa made improving traffic safety data one of the agency's highest priorities .

since the early 1980s , nhtsa has been obtaining crash data files from states , which in turn have been deriving the data from police crash reports .

these statewide crash data files are referred to as the sds program .

participation by states is voluntary , with 27 states currently participating .

these data include some of the basic information for the analyses and data collection programs that support the nhtsa mission of identifying and monitoring traffic safety problems .

one of nhtsa's grant programs was specifically aimed at improving traffic safety data .

administered through its 10 regional offices around the country , the program provided about $36 million to states for improving their crash data systems .

this grant program was authorized under tea - 21 and was known as the “411 grant program” after the relevant section of the u.s. code .

nhtsa administers a number of other grant programs besides the 411 grant program ; however , it was the only incentive grant program that was specifically directed at improving state traffic safety data systems .

the grant program required states to establish a foundation for improving their traffic safety data systems by first completing three activities: establish a coordinating committee of stakeholders to help guide and make decisions about traffic safety data: the committee would ideally include stakeholders from agencies that manage the various data files ( eg , representatives from the state department of transportation responsible for roadway information , and from the state department of motor vehicles responsible for the management of vehicle licensing information ) .

conduct an assessment of the current system: the assessment would evaluate a state's system by identifying strengths and weaknesses and providing a baseline from which the state could develop its strategic plan to address data system needs .

develop a strategic plan that prioritizes traffic safety data system needs and identifies goals: the strategic plan is to provide the “map” specifying which activities should be implemented in order to achieve these goals .

as with the assessment , the focal point for developing the strategic plan , if a state did not already have one , would be the coordinating committee .

the level of funding available to a state was dependent on whether states had already put these requirements in place .

additionally , states were required to contribute matching funds of between 25 and 75 percent , depending on the year of the grant .

three types of grants were awarded: a state received a start - up grant if it had none of the three requirements in place .

this was a one - time grant of $25,000 .

a state received an initiation grant if it had established a coordinating committee , had completed or updated an assessment within the previous 5 years , and had begun to develop a strategic plan .

this grant was a one - time grant of $125,000 , if funds were available .

a state received an implementation grant if it had all three requirements in place and was positioned to make specific improvements as indicated in its strategic plan .

this grant was at least $250,000 in the first year and $225,000 in subsequent years , if funds were available .

the congress has extended tea - 21 until may 2005 , and new house and senate bills will likely be introduced during the next congressional session .

the most recent house and senate bills under consideration , which were not passed in the 2004 session , included proposals to reauthorize the 411 grant program in a similar , but not identical , form to the original program .

the proposals included funding up to $270 million , which is over six times the original funding amount .

they also included ( 1 ) additional requirements for documentation from states describing how grant funds would be used to address needs and goals in state strategic plans and ( 2 ) a requirement that states demonstrate measurable progress toward achieving their goals .

the proposals , however , did not include one of the original program requirements — that states have an assessment of their traffic safety data systems that is no more than 5 years old when they applied for the grant .

the 9 states we examined in detail varied considerably in the extent to which their traffic safety data systems met nhtsa's recommended criteria for the quality of crash information .

nhtsa's six criteria ( shown in table 1 below , along with an explanation of each criterion's significance ) appear in the agency's traffic records highway safety program advisory , the guide used by nhtsa when it carries out traffic records assessments at the request of state officials .

these assessments are a technical assistance tool offered to state officials to document state traffic safety data activities , note strengths and accomplishments , and offer suggestions for improvement .

in addition , nhtsa released the report initiatives to address improvement of traffic safety data in july 2004 , which emphasized these data quality criteria and provided recommendations to states .

we examined all six criteria for the 9 case - study states , and our review of 17 states that participated in nhtsa's sds program provided additional information for three of these six criteria .

none of the 9 states in our case - study review met all six criteria , and most had opportunities for improvement in many of the criteria .

the sections below discuss each criterion .

data available .

data processing times for the 9 states ranged from less than 1 month in 2 states to 18 months or more in 2 others .

for example , to develop their 2005 highway safety plans during 2004 , 4 of the 9 states used data from 2000 , 2001 , or 2002 , and the remaining 5 states used 2003 data .

 ( see fig .

2. ) .

for 6 of the 9 states , three factors accounted for their not meeting the timeliness criterion: slow data entry , data integration delays , and lengthy data edits .

as a result , the state safety plans are unable to take recent crash trends into account in these states .

generally , those states submitting data electronically from local law enforcement agencies to the state traffic safety data system had much faster entry of crash information into centralized databases .

in contrast , states that processed reports manually by keying in information from paper forms at the state level had longer data entry time frames .

the availability of data was also sometimes delayed by inefficient data completion processes .

in states where this is not done automatically , crash data and location information are often manually entered into the traffic safety data system .

in addition , checks for accuracy also delayed data availability .

for example , 1 of the states that had to use data from 2000 to develop its highway safety plan , had used electronic methods to enter more recent data , but detailed edit checks delayed the data's release considerably .

seven of the 9 states we visited had crash forms that could be used to collect data across all jurisdictions within the state , helping to ensure that data collected within the state are consistent .

however , no state had forms that met all of the consistency criteria recommended in the model minimum uniform crash criteria ( mmucc ) guidelines that were developed collaboratively by state and federal authorities .

these guidelines provide a recommended minimum set of data elements to be collected for each crash , including a definition , attributes , and the rationale for collecting each element .

while variation in the crash data collected by states can be attributed to varying information needs , guidelines help to improve the reliability of information collected and also assist in state - to­ state comparisons and national analyses .

the variation between states can be seen among the 17 states we analyzed that contribute to nhtsa's sds program .

for example , the mmucc guidelines recommend reporting on whether alcohol was a factor in the crash by indicating the presence or absence of an alcohol test , the type of test administered , and the test results .

however , several of the states collected information on impaired driving without specifying the presence of an alcohol test , the test type , or the test result ; thereby making it difficult to determine whether alcohol - use contributed to the crash .

in addition , the states were not uniform in collecting and reporting the vin , another element recommended in the mmucc .

a vin is a unique alphanumeric identifier that is applied to each vehicle by the manufacturer .

the vin allows for an effective evaluation of vehicle design characteristics such as occupant protection systems .

as figure 3 shows , data about vins were not available for all 17 states in crashes for any year between 1998 and 2002 .

for example , although every state had submitted crash data for 1998 and 1999 , crash data for 6 of the 17 states did not include vins .

the lack of consistency limits the use of state crash data for most nationwide analyses .

for example , in a recent national center for statistics and analysis ( ncsa ) research note on child safety campaigns , only 3 states met the criteria to be included in the analysis , not nearly enough data to statistically represent the nation .

the criteria necessary for inclusion in the report included collecting data on all vehicle occupants , including uninjured occupants , and vins for the relevant years ( 1995-2001 ) .

if state systems matched the mmucc , they would include this information .

similarly , only 5 states qualified for use in a ncsa analysis of braking performance as part of the new car assessment program because only these states collected vins and had the necessary variables for the years involved in the study .

there is evidence that as states redesign their crash forms , they are following the mmucc guidelines more closely .

remaining differences from the suggested guidelines often reflect the needs of individual states .

among the 9 states we visited , 5 had redesigned their crash forms since 1997 .

all 5 used the guidelines as a baseline , although each of them tailored the form to a degree .

one state , for example , collected no data about the use of seat belts for uninjured passengers , while another chose to collect additional state - specific attributes , such as describing snow conditions ( eg , blowing or drifting ) .

among the remaining 4 states we visited , 2 states are currently using the mmucc guidelines to redesign their forms .

one factor affecting the degree of completeness is state reporting thresholds — that is , standards that local jurisdictions use to determine whether crash data should be reported for a particular crash .

these thresholds include such things as the presence of fatalities or injuries or the extent of property damage .

although all 9 of the states we visited had reporting thresholds that included fatalities and injuries , the thresholds for property damage varied widely .

for example , some states set the property damage threshold at $1,000 , while 1 state did not require reporting of property - damage - only crashes .

in addition , it was not possible to determine the extent that all reportable crashes had been included in the traffic safety data system .

officer discretion may play a role .

for example , capturing complete documentation of a crash event is often a low priority when traffic safety data are not perceived as relevant to the work of the law enforcement officer or other public safety provider .

in 1 state , for example , the police department of a major metropolitan area only reported crashes involving severe injuries or fatalities , although the state's reporting threshold included damage of $1,000 or more .

variation in thresholds among states is not the only factor that affects the completeness of crash data .

for the crash information that does make it into the state database , there are often gaps in the data , as we learned from evaluating the records of 17 states participating in nhtsa's sds program .

for 5 of these states , we analyzed data coded “unknown” and “missing” for 24 data elements .

the percentage of data coded as unknown or missing was frequent for several key data elements , such as the vin ; the results of alcohol or drug testing ; and the use of seat belts , child car seats , and other restraint devices .

for example , the percentage of data coded as unknown or missing for the use of seat belts and other restraints ranged between 1.5 and 54.8 percent for 4 of the 5 states .

such data can be inherently difficult to collect.for example , when officers arrive at the scene of a crash , drivers and passengers may already be outside their vehicles , making it impossible to know if they were wearing seat belts .

asked if they were wearing a seat belt , those involved in the crash may not tell the truth , especially if the state has a law mandating seat belt use .

six of the 9 states we visited made use of quality control methods to help ensure that individual reports were accurate when they were submitted to the traffic safety data system .

of these 6 states , for example , 4 linked crash reports to other traffic safety data , including driver or vehicle files , to verify or populate information on crash reporting forms .

table 2 contains examples of other tools and checks that the states used to help ensure accuracy .

four of the 9 states did quality checks at the aggregate level — that is , when crash reports are analyzed in batches to identify abnormalities in reporting that may not be apparent looking at individual reports .

of these 4 states , for example , 1 had staff analyze the reports to identify invalid entries and data miscodings , while another conducted edit checks each year to check for invalid vehicle types or other problems .

such aggregate - level analysis can be useful to identify systematic problems in data collection that may lead to erroneous investigation or false conclusions , such as when officers report one type of collision as another .

for instance , officers in 1 state were found to be characterizing some car - into - tree crashes as head - on collisions .

once identified , such data collection problems can often be resolved through officer training .

to test data accuracy , we analyzed crash data submitted by the 17 states to nhtsa and found relatively few instances of data that had been coded as “invalid” — generally 3 percent or less .

data classified as invalid were most often for elements more likely to be transposed or miscopied , such as vins .

however , because we could not observe crash - scene reporting and did not examine or verify information on source documents ( such as police accident reports ) , we cannot assume that the other 97 percent of data were accurately reported and entered correctly .

invalid data entries are a good starting point for measuring the accuracy of a data system , but they are only one indication of the accuracy of state traffic safety data .

all 9 states produced crash information summaries , although some were based on data that were several years old — a factor that limited their usefulness .

in addition , 8 states provided law enforcement agencies or other authorized users with access to crash information within 6 months of crashes .

such access was often via the internet , and data analysis tools were typically limited to a certain number of preestablished data reports .

thus , any in - depth analysis was limited to the tools available online .

three states had analysts available to provide information or complete data queries upon request .

in another state , which had the capability to conduct data collection electronically , local law enforcement agencies had access to analysis tools to use with their own data .

if users wanted direct access to completed data for more detailed analysis , they often had to wait somewhat longer , given the need for additional data entry or the completion of accuracy checks .

in 1 state , for example , there was a 2- to 3-month delay due to the transfer of preliminary crash data from the state police database to the state department of transportation where location information was added to complete the data .

only 1 of the 9 states integrated the full array of potential databases — that is , linked the crash file with all five of the files typically or potentially available in various state agencies: driver , vehicle , roadway , citation / conviction , and medical outcome .

all 9 of the states we visited integrated crash information with roadway files to some degree , but only a few integrated these data with driver or vehicle licensing files , or with the conviction files housed in state court systems .

 ( see table 3. ) .

in addition , 7 of the 9 states participated in nhtsa's crash outcome data evaluation system ( codes ) program , which links crash data with medical information such as emergency and hospital discharge data , trauma registries , and death certificates .

technological challenges and the lack of coordination among state agencies often posed hurdles to the integration of state data .

in 1 state , for example , crash files were sent from the central traffic records database kept by the state department of safety to the state department of transportation for manual entry of location information from the roadway file .

once the state department of transportation completed these records , however , there was no mechanism to export that information back into the central database .

also , in some states data integration was limited because data were not processed with integration in mind .

in 1 state , for example , state department of transportation officials noted that the new crash system had been developed for state police use , and that efforts were still under way to develop an interface to bring crash data into the department's system .

in contrast , a state official in another state noted that the housing of several agencies involved in the traffic safety data system — including those responsible for the driver , vehicle , and roadway files — in the state department of transportation had facilitated the direct sharing of information and the full integration of data .

in support of these quality criteria and improved traffic safety data systems , nhtsa released a report in july 2004 detailing steps that could be taken by federal and state stakeholders to improve traffic safety data .

the report , initiatives to address improvement of traffic safety data , was issued by nhtsa and drafted by an integrated project team that included representatives from nhtsa , the bureau of transportation statistics , the federal highway administration , and the federal motor carrier safety administration .

the report articulates the direction and steps needed for traffic safety data to be improved and made more useful to data users .

it makes a number of recommendations under five areas , including improving coordination and leadership , improving data quality and availability , encouraging states to move to electronic data capture and processing , creating greater uniformity in data elements , and facilitating data use and access .

along with these recommendations , the report also outlines initiatives that nhtsa and other stakeholders should implement .

for example , under the area of data quality and availability , the report indicates that states — under the guidance of their coordinating committees — should encourage compliance by law enforcement with state regulations for obtaining blood - alcohol concentration and drug use information and should also strive to capture exact crash locations ( using latitude and longitude measures ) in their traffic safety data systems .

states reported carrying out a range of activities with funding made available under the 411 grant program .

however , relatively little is known about the extent to which they made progress in improving their traffic safety data systems for the years of the grant .

when applying for follow - on grants , states were required to report to nhtsa's regional offices on the progress they were making in improving their traffic safety data systems during the prior year .

however , the required documents filed with nhtsa yielded little or no information on what states had achieved .

we were able to discern from the 8 states we reviewed in detail that those states had indeed used their grants for a variety of projects and showed varying degrees of progress .

regardless of whether states concentrated their grant funds on one project or funded a number of activities , the level of progress was influenced by the effectiveness of state coordinating committees .

forty - eight states applied for and received grant awards under the 411 grant program .

as table 4 shows , most states ( 29 ) began their participation at the implementation grant level — that is , most of them already had the three basic requirements in place , including a coordinating committee , an assessment of their data system , and a strategic plan for improvement .

those states receiving start - up or initiation grants were expected to put the three requirements in place before beginning specific data - related improvement projects .

by the 4th year of the grant , 44 states were still participating , and all but 1 was at the implementation grant level .

the 4 states that were no longer participating by the 4th year reported that they discontinued participation mainly because they could not meet grant requirements .

all three basic program requirements were useful to states to initiate or develop improvements in their traffic safety data systems .

by meeting these grant requirements , states were able to “jump start” their efforts and raise the importance of improving state traffic safety data systems .

the assessments , which were required to be conducted within 5 years of the initial grant application , provided benchmarks and status reports to nhtsa and state officials and included information on how well state systems fared in regard to nhtsa's six recommended quality criteria .

officials with whom we spoke generally agreed that these assessments were excellent tools for systematically identifying needed state improvements .

similarly , strategic plans generally appeared to be based on the state assessment findings and helped states identify and prioritize their future efforts .

the establishment of the traffic records coordinating committees to guide these efforts was also key to initiating improvements , since traffic safety data systems involve many departments and their cooperation is essential in developing and implementing improvements to a state traffic safety data system .

documentation of state progress was limited and of little use in assessing the effect of traffic safety data improvement efforts .

to qualify for grants beyond the first year , each state had to ( 1 ) certify that it had an active coordinating committee and ( 2 ) provide documentation of its efforts through updated strategic plans , separate progress reports , or highway safety annual evaluation reports .

we reviewed these documents when available and found that they contained a variety of activities , ranging from completing the basic requirements ( such as conducting assessments and developing strategic plans ) to identifying specific projects ( such as outsourcing data entry services and redesigning crash forms ) .

figure 4 lists examples of these types of reported activities .

the grant documentation nhtsa received provided few details on the quality of the state efforts .

for example , although states certified the existence of a coordinating committee , they were not required to report on what the committee did or how well it functioned .

also , while states for the most part identified efforts to improve their data systems , we found it difficult to assess their progress because the reports lacked sufficient detail .

for example: one state reported using grant funds on alcohol testing devices to collect more alcohol impairment data on drivers .

however , the progress reports did not indicate who received these devices and how data collection was improved .

one state used funds to hire data entry staff to reduce the backlog of old crash reports .

however , the state provided no indication of whether the increase in staff had reduced the backlog and how any reduction in the backlog could be sustained in the longer term .

one state reported using funds on multimillion dollar information technology projects , but it is unclear how the grant funds were used in these projects .

our visits to 8 of the states that participated in the 411 grant program yielded additional information and documentation about their grant activities , the nature of their efforts , and the extent of progress made .

these states expended funds on a variety of activities , ranging from completing the basic requirements of assessments and strategic plans to implementing specific projects .

as figure 5 shows , in the aggregate , these activities translated into two main types of expenditures — equipment , such as computer hardware and software , and consultant services , such as technical assistance in designing new data systems .

the 8 states either concentrated funding on one large project or used funding on a variety of activities , including data entry , salaries , training , and travel .

four of the 8 states focused on a single project related to improving their data systems mainly by enhancing electronic reporting .

one state reengineered its files to better integrate them with other data systems ; 1 piloted an electronic crash data collection tool ; and the remaining 2 created new electronic data systems , which were upgrades from their previous manual systems .

these states also improved the tools used by law enforcement officers to input data into their crash systems , such as software for mapping and graphing traffic crashes or laptop computers for patrol cars so that law enforcement officers could collect and transmit crash data electronically to statewide repositories .

the remaining 4 states used funding on multiple activities , such as obtaining technical support , adding capability for more data entry , or attending conferences .

some also conducted pilot projects .

for example , 1 state created a project that enabled electronic uploads of traffic citation data from local agencies to the state department of motor vehicles .

according to state officials , this project helped considerably with both timeliness and completeness in the uploading of conviction information to driver files .

in another example , the state used funding to pilot a project to capture data about crashes electronically .

states made improvements under both the single - and multiple - project approaches .

one state that focused on a single project , for example , developed a new statewide electronic crash system that officials said had improved data timeliness and completeness .

similarly , of the states that spread funding among multiple activities , 1 state used funding for a data project on driver convictions — paying for traffic records staff's salaries and hiring consultants to map crashes to identify roadway issues .

as a result , the quality and completeness of crash data improved overall , according to a state official .

one factor that affected state progress was the relative effectiveness of the state's coordinating committee .

in those states , where the state coordinating committee did not actively engage all stakeholders or where its level of authority was limited , projects did not fully address system needs .

for example , 1 state established a coordinating committee that included few stakeholders outside the state police , and this committee decided to concentrate funding on a new electronic crash data system .

the new system , acknowledged by many stakeholders as improving the timeliness and completeness of crash data , resulted in a useful resource allocation and crash - reporting tool for the state police to allocate resources and report on crashes .

according to officials at the state department of transportation , however , improvements in the crash information did not effectively serve to facilitate the state's use of crash data to identify unsafe roadways because the state department of transportation was not fully engaged in the coordinating committee's process .

similarly , in another state , the coordinating committee lacked the authority needed to fully implement its efforts .

the coordinating committee created two subcommittees — a technical committee and an executive committee .

while the executive committee was made up of higher level managers from various agencies , the coordinating committee did not have the legislative authority to compel agencies to participate in the process or to even use the newly created statewide crash data system .

to date , the state does not have all key stakeholders participating in the process and is continuing to have difficulty persuading the largest municipality in the state to use the newly developed statewide electronic reporting system .

as a result , the municipality continues to lag behind other communities in having its crash information entered into the state crash system .

in contrast , another state's coordinating committee had the authority to approve or reject proposals for data system improvements as well as funding .

this state was able to complete several agreed - upon projects , including implementing an electronic driver citation program , which improved the completeness and timeliness of the state crash data .

nhtsa did not adopt adequate regulations or guidelines to ensure states receiving 411 grants submitted accurate and complete information on progress they were making to improve their traffic safety data systems .

in addition , the agency did not have an effective process for monitoring progress and ensuring that grant monies were being spent as intended .

we found some examples where states did not report their progress accurately .

nhtsa , while beginning to take some actions to strengthen program oversight , must be more proactive in developing an effective means of holding states accountable under this program .

in our previous discussion about activities being carried out under the grant program , we described how state documentation of progress often contained too little detail to determine anything about the progress being made as a result of activities being funded with program grants .

reasons for this lack of information , in our view , were nhtsa's limited regulatory requirements and inconsistent guidance about what information states should submit .

regulations for the 411 grant program required states to submit an updated strategic plan or a progress report , but did not specify how progress should be reported .

further , nhtsa's regulations required states to report on progress as part of their 411 grant application , which in effect meant that states did not have to report specifically on 411 activities after fiscal year 2001 .

according to nhtsa regulations , states were to include information on progress through their highway safety plans and annual evaluation reports after fiscal year 2001 , which are part of the reporting for all of nhtsa's highway safety grants .

however , our analysis of these documents found that they lacked the detail needed to adequately assess state activities undertaken with 411 funds .

further , while nhtsa officials told us they also informally obtained information about progress after fiscal year 2001 , the available information about what the activities actually accomplished was limited .

limitations in the information regarding states activities were particularly significant given that states spent most of their grant funds after fiscal year 2001 .

nhtsa regional offices supplemented the regulatory requirements with their own guidance to states , but the guidance varied greatly from region to region .

some of the regional offices said that their contact with states about these requirements was informal , and that their primary contact with states ( 1 ) was over the telephone or by e - mail and ( 2 ) was generally in regards to technical assistance , such as training or referring states to existing guidelines .

other regional office staff said they had additional contact with states through participation in meetings of state coordinating committees , where they were able to provide additional assistance .

however , we found this participation occurred most often for states in proximity to nhtsa regional offices .

few regional offices provided written guidance to states with specific direction on what to include in their progress reports .

for the regions that did so , the requested information included documentation indicating how states intended to use the current year grant funds , a list of projects implemented in the past fiscal year , a brief description of activities completed , an account of problems encountered , and the status of allocated funds .

without consistent and clear requirements and guidance on the content of progress reports , states were left to their own devices .

we found that even in regions where nhtsa officials outlined the information that should be included in the progress reports , states did not necessarily provide the level of information needed for nhtsa to adequately track state progress .

for example , in 1 region , states were to provide nhtsa with documentation that included a list of projects and a description of progress made .

however , 1 state in that region did not provide the list of completed projects ; it only provided a brief description of projects completed during 1 of the 4 years of the grant .

we also found a wide variation in how states reported their activities .

for example: some states provided brief descriptions of the activities completed or under way , while others did not .

states that provided brief descriptions of their activities did not always include the same information .

for example , some states indicated how they were intending to use the current grant funds but did not list projects implemented in the past year .

some states did not indicate the status of their allocated funds for ongoing activities .

none of the states in our review indicated problems that were encountered in implementing projects or activities .

under the 411 grant program , nhtsa's oversight process for monitoring state progress and ensuring that funds were spent in line with program intent was limited .

in fact , nhtsa was unable to provide copies of many of the documents that states were required to submit to qualify for the 411 grant program .

we requested these documents beginning in february 2004 , and nhtsa was only able to provide us with complete documentation for half of the states participating in the program .

when we visited 8 states that participated in the program , we were able to compare expenditure reports obtained from the states with activities that were reported to nhtsa .

we found instances in which documentation of state reported activities provided by nhtsa did not match information provided directly to us by the states .

in documentation submitted to nhtsa , 1 state reported using grant funds on alcohol breath test devices .

however , documents available at the state level indicate that nearly all of the funds were expended on a single project to redevelop a crash data system .

officials we spoke with also indicated that the money had gone for redeveloping the data system .

in a report to nhtsa , 1 state we visited had reported undertaking four projects , but we found that two of them were actually funded by a different federal grant .

the degree to which nhtsa monitored state 411-funded activities was difficult to determine .

nhtsa officials told us that they were not required to review state 411-funded activities in detail .

a few regional office officials told us that they verified state reported activities by linking them to objectives identified in state strategic plans ; however , no documentation of these reviews was provided .

nhtsa has taken several steps to improve its oversight and assist states in improving their traffic safety data systems ; however , more efforts are needed .

as we were completing our work , nhtsa released a report , initiatives to address improvement of traffic safety data , that provides the status of data systems in five areas , including coordination and leadership , improving data quality and availability , encouraging states to move to electronic capture and processing , creating greater uniformity in data elements , and facilitating data use and access .

it also provides recommendations and initiatives in support of nhtsa's efforts to improve state traffic safety data systems .

although the report outlines ( 1 ) steps to be taken , ( 2 ) stakeholder responsibilities for each recommendation , and ( 3 ) the general outcomes expected , the extent to which actions will occur as a result of the report is unclear .

the report is limited to a description of conditions and needs for traffic safety data improvements and does not include an implementation plan with milestones or timelines .

the report acknowledges that due to limited funding , nhtsa will focus primarily on recommendations that are feasible given current resources .

according to nhtsa , the report was issued as a fact - finding status report and , therefore , no timelines or milestones were included .

however , beginning october 2004 , a newly created national traffic records coordinating committee is developing an implementation plan for the goals identified in the report .

nhtsa also recently enhanced its oversight tools for all safety grants .

it has mandated management reviews every 3 years and also expanded its existing regional planning documents for the areas of occupant protection and impaired driving , with three additional areas , including traffic safety data.the first of these regional action plans aimed at data improvements are being initiated fiscal year 2005 and include goals , objectives , and milestones .

mandating management reviews that encompass the broad array of grant programs every 3 years is an improvement over the inconsistent application of these reviews in the past .

also , by establishing traffic safety data improvements as part of the regional action plans , nhtsa will have more uniform tracking of state data improvements and also better information on state progress .

while these newly initiated efforts are positive steps to improving oversight , it is too soon to tell how effective they will be for monitoring and ensuring accountability under the 411 grant program , should the congress chose to reauthorize it .

nhtsa's oversight of the 411 grant program may be strengthened under reauthorized legislation .

proposed reauthorization bills that were considered by the congress in 2004 included additional requirements that states ( 1 ) demonstrate measurable progress toward achieving goals in their strategic plans and ( 2 ) specify how they will use grant funds .

these additional provisions would be important steps in addressing the too - vague reporting requirements of the current program and would be helpful in addressing congressional and other inquiries about what the program is accomplishing .

as the previous proposed bills were drafted , however , they omitted one requirement that will be important in tracking state progress — the requirement for a state to have an assessment of its traffic safety data system no more than 5 years prior to participating in the 411 grant program .

assessments are used mainly to establish the status of state efforts , but state and nhtsa officials suggest that updated assessments could also help in tracking state progress .

during our review , we found some assessments submitted by states that were nearly 10 years old .

we also found that assessments based on recent information reflected the dynamic and often - changing reality of state systems .

for example , 1 of our case­ study states had recently conducted an assessment in 2002 .

when we compared the information we had collected during our site visit , we found much of the information from our visit reflected in the assessment .

updating these assessments at least every 5 years would allow nhtsa to track state progress .

according to nhtsa officials , these assessments were valuable starting points in helping states take stock of the strengths and weaknesses of their entire systems .

updated assessments would take into account changes made as a result of the new 411 grant program and other efforts to improve the system since previous assessments were conducted .

the states and the federal government base significant roadway - related spending and policy decisions on traffic safety data , ranging from deciding to repair particular roadways to launching major safety campaigns .

the quality of such decisions is tied to the quality of these data .

our review indicates that there were opportunities for states to improve crash data .

however , because nhtsa exercised limited oversight over the 411 grant program , it is difficult to say what the program as a whole specifically accomplished or whether there was a general improvement in the quality of these data over the program's duration .

nevertheless , information we obtained from the 8 states we visited suggests the premise that the 411 program did help states improve their traffic safety data systems .

based on our work in these 8 states , we believe that states undertook important improvements in their data systems with the federal grant funds .

the potential reauthorization of the grant program and nhtsa's recent study of state safety data provide an opportunity to include assurances that states use these grants on effective and worthy projects .

furthermore , the reauthorization may provide greater funding and , therefore , greater opportunity for states to improve their traffic safety data systems .

however , a larger program would come with a greater expectation regarding what states will accomplish as well as with a need to effectively track the progress states are making .

nhtsa's inability to provide key grant documentation and its deficiencies in monitoring state progress with 411 grant funds could be minimized if nhtsa ( 1 ) better managed grant documents , ( 2 ) had clearer requirements and guidance for the grant program , and ( 3 ) had an effective oversight process in place to monitor activities and progress .

requiring more specific information on the improvements states are making in their data systems would begin to address the problems we identified with regard to inadequate reporting on the program .

if the program is reauthorized , nhtsa should develop an oversight process that does a better job of ( 1 ) tracking state activities to their strategic plans and assessments , ( 2 ) providing information about progress made in improving safety data , and ( 3 ) ensuring that nhtsa can adequately manage the documentation it is requiring .

in addition , if nhtsa develops a plan to implement the recommendations in its recent integrated project team report on traffic safety data systems , it could incorporate these recommendations through improved oversight efforts .

finally , one requirement present in the earlier program — up - to - date assessments of state traffic safety data systems — was not included in recent proposals to reauthorize the 411 grant program .

these assessments proved a valuable tool to states in developing and updating their strategic plans and activities for the 411 grant program .

they also provide nhtsa with valuable information , including the current status of state traffic safety data systems organized by nhtsa's own recommended quality criteria .

in considering the reauthorization of the traffic safety incentive grant program , the congress should consider including the requirement that states have their traffic safety data system assessed or an update of the assessment conducted at least every 5 years .

if the congress reauthorizes the traffic safety data incentive grant during the next session , we recommend that the secretary of transportation direct the administrator , national highway traffic safety administration , to do the following: ensure better accountability and better reporting for the grant program by outlining a process for regional offices to manage and archive grant documents .

establish a formal process for monitoring and overseeing 411-funded state activities .

specifically , the process should provide guidance for submitting consistent and complete annual reporting on progress for as long as funds are being expended .

these progress reports should , at a minimum , include the status of allocated funds , documentation indicating how states intend to use the current year grant funds , a list of projects implemented in the past fiscal year , brief descriptions of activities completed , and any problems encountered .

establish a formal process for ensuring that assessments , strategic plans , and progress reports contain the level of detail needed to adequately assess progress and are appropriately linked to each other .

agency comments and 	 we provided a draft of this report to the department of transportation for our evaluation	 its review and comment .

generally , the department agreed with the recommendations in this report .

department officials provided a number of technical comments and clarifications , which we incorporated as appropriate to ensure the accuracy of our report .

these officials raised two additional points that bear further comment .

first , officials voiced concern regarding the use of data quality criteria from nhtsa's traffic records highway safety program advisory to review the quality of data or the performance of states .

the department emphasized that these criteria are voluntary and states are not required to meet them ; therefore , states should not be judged against them .

we acknowledge that these criteria are voluntary and clarified the report to emphasize this point more fully .

however , we used the criteria as a framework for providing information on the status of state systems and view this analysis as appropriate since these criteria are used by nhtsa in conducting assessments of state traffic safety data systems .

second , department officials noted that their oversight of the 411 grant program was in accordance with the statutory requirements .

although we recognize that there were minimal requirements for the 411 grant program specifically , we believe the department should carry out more extensive oversight activities so that nhtsa can monitor the progress states are making to improve their traffic safety data systems and better ensure that states are spending the grant monies as intended .

we will send copies of this report to the interested congressional committees , the secretary of transportation , and other interested parties .

we will make copies available to others upon request .

in addition , the report will be available at no charge on gao's web site at http: / / www.gao.gov .

if you or your staff have any questions about this report , please call me at ( 202 ) 512-6570 .

key contributors to this report are listed in appendix iv .

the objectives in this report were to identify ( 1 ) the quality of state crash information ; ( 2 ) the activities states undertook using 411 grant funds to improve their traffic safety data systems , and progress made using the data improvement grants ; and ( 3 ) the national highway traffic safety administration's ( nhtsa ) oversight of the grant program , including what changes in oversight , if any , might help encourage states to improve traffic safety data systems and ensure accountability under a reauthorized program .

to address these objectives , we conducted case - study visits to 9 states , analyzed state crash data , interviewed key experts , reviewed 411 grant program documentation , and interviewed nhtsa officials regarding their oversight and guidance to states in improving their traffic safety data systems .

to provide information on the quality of state crash data and state efforts to improve these data , we conducted site visits to 9 states , including california , iowa , kentucky , louisiana , maine , maryland , tennessee , texas , and utah .

the case - study states were chosen on the basis of a variety of criteria , including population , fatality rates , participation in the 411 grant program , the level of funding received through the program , and participation in the state data system ( sds ) program and the crash outcome data evaluation system ( codes ) .

we adopted a case - study methodology for two reasons .

first , we were unable to determine the status of state systems from our review of 411 documents .

second , while the results of the case studies cannot be projected to the universe of states , the case studies were useful in illustrating the uniqueness and variation of state traffic safety data systems and the challenges states face in improving them .

during our case - study visits , we met and discussed the status of state traffic data systems with a variety of traffic safety data officials .

these discussions included gathering information on nhtsa's criteria , state objectives , and the progress made with 411 grant funds .

in addition to these case - study visits , we analyzed data for 17 states that currently participate in nhtsa's sds program to identify variations in data structure and quality .

we selected a number of elements to assess the quality of data as they related to completeness , consistency , and accuracy for 5 of the 17 states that were part of the sds program and also part of our case - study visits .

we based the analysis on data and computer programs provided by nhtsa .

we reviewed the programs for errors and determined that they were sufficiently accurate for our purposes .

 ( see app .

ii. ) .

finally , we interviewed key experts who use traffic safety data , including consultants , highway safety organizations , and researchers .

in order to describe the activities that states undertook to improve their traffic safety data systems and the progress made under the data improvement grant , we reviewed 411 grant documentation for all 48 participating states , including 8 of our 9 case - study states .

our review included examining required documents states submitted to nhtsa , including their assessments , strategic plans , and grant applications and progress reports .

we obtained these documents from nhtsa regional offices .

for the case - study states , we also obtained additional documentation , including 411 grant expenditure information , in order to ( 1 ) describe state activities and progress made and ( 2 ) compare actual expenditures with the activities states reported to nhtsa .

to review nhtsa's oversight of the 411 grant program , we interviewed nhtsa officials responsible for oversight and administration of the program .

our interviews were conducted with nhtsa program staff at headquarters and in all 10 nhtsa regional offices .

we also discussed program oversight with state officials in 8 of our 9 case - study states .

we reviewed nhtsa guidance and policy , including regulations for the 411 grant program and rules issued by nhtsa for the program .

we also reviewed previous house and senate bills that were introduced reauthorizing the 411 grant program .

finally , in order to understand nhtsa's broader role in oversight , we spoke with nhtsa staff and reviewed nhtsa's response to our recommendations that it improve its oversight .

we conducted our review from january 2004 through october 2004 in accordance with generally accepted government auditing standards .

because an examination of data quality was one of the objectives of this report , we also conducted an assessment of data reliability .

appendix ii contains a more complete discussion of data reliability .

as part of our work , we examined data quality for 17 states that participate in nhtsa's sds program .

the body of our report presents several examples of the kinds of limitations we found ; this appendix contains additional examples .

the examples discussed below relate to two of nhtsa's quality criteria — data consistency and data completeness .

the extent to which a state captures information about various data elements has much to do with the standards or thresholds it sets for what should be reported in crash reports .

nhtsa's model minimum uniform crash criteria ( mmucc ) recommends that every state have reporting thresholds that include all crashes involving death , personal injury , or property damage of $1,000 or more ; that reports be computerized statewide ; and that information be reported for all persons ( injured and uninjured ) involved in the crash .

we found these thresholds differed from state to state .

two thresholds , in particular , create variation in the data: ( 1 ) criteria for whether a crash report must be filed and ( 2 ) criteria for whether to report information about uninjured occupants .

determining which crashes the states varied greatly in their policies on when a police report must be require a crash report	 filed .

fourteen of the 17 states set a property damage threshold , but the threshold varied from less than $500 to as much as $1,000 ( see fig .

6 ) .

among the other 3 states , 1 left the reporting of property - damage - only crashes to the officer's discretion , and 2 stipulated that no report is to be filed unless at least one vehicle has to be towed from the scene .

thus , a crash involving $900 of damage to an untowed vehicle would be reported in some states but not in others .

similarly , some states did not collect information about uninjured passengers involved in crashes .

 ( see fig .

7. ) .

while all 17 states collected information about uninjured drivers ( such as whether he or she was wearing a seat belt ) , 5 did not collect such information about uninjured passengers .

such information could potentially be important , for example , in assessing the degree to which seat belt use helped prevent injuries from occurring .

even for states that collected information about uninjured passengers , the information may be incomplete .

nhtsa officials said they thought that in these states , some officers left seat belt information blank or coded it as “unknown,” either because reporting officers did not know the information or because collecting it was too time - consuming .

alcohol and drug data also showed state - to - state differences , both in consistency and completeness .

alcohol and drug data are important in addressing a major safety issue — impaired driving .

in 2000 , crashes in which drivers had blood - alcohol levels above .08 ( .08 recently became the threshold for being legally impaired in all 50 states ) accounted for an estimated 2 million crashes that killed nearly 14,000 people and injured nearly 470,000 others .

alcohol - related crashes in the united states that year cost an estimated $114.3 billion .

to assess the quality of these data in the sds program , we selected 5 states for detailed review .

the states , chosen because they were also visited as part of our case studies , were california , kentucky , maryland , texas , and utah — although they are not identified by name in the results below .

we looked at the degree to which they conform to guidelines recommended in the mmucc with regard to the consistency and completeness of their data .

information collected about alcohol - and drug - impaired driving varied from state to state and was not consistent with mmucc guidelines .

table 5 provides examples of this variation by comparing crash information submitted by states with the recommended guidelines .

the table shows mmucc's recommended guidelines for four elements — two elements each for alcohol and drugs .

one element relates to whether the officer suspects alcohol or drug use , and the other to an actual test for alcohol or drugs .

all 5 states collected some type of information on suspected alcohol or drug use , but each state differed from the others to some degree .

three states , for example , collected this information as part of a broader element that includes suspected alcohol and drug use as one attribute in a list of causes that might have contributed to the crash .

for alcohol and drug testing , 1 state did not report such testing at all , and the 4 others differed both from each other and from mmucc guidelines .

to determine the completeness of state data files regarding impaired driving , we looked at alcohol test result data that were coded as “missing” or “unknown.” figures 8 and 9 show the results for the first and last years we reviewed .

the percentage of data recorded as missing varied from 0 percent to more than 12 percent , while the percentage of data recorded as unknown varied from 0 percent to more than 6 percent.in addition , the 2 states with the most data in these two categories were almost mirror images of each other: that is , state d showed no data as missing but had the highest percentage of data classified as unknown , while state e showed virtually no data as unknown but had the highest percentage of data classified as missing .

these variations could reflect differences in how states classify and record information .

for example , nhtsa officials said some states may code an alcohol test result that comes back indicating no alcohol in the driver's blood stream as missing or unknown , rather than “negative” or “.00. .

because the alcohol and drug data in sds are subject to so many problems with completeness and consistency , many researchers and state policy makers use alcohol and drug data from the fatality analysis reporting system ( fars ) database instead .

this database , which is also administered by nhtsa , contains information on crashes involving fatalities that occur within 30 days of the crash .

fars is generally seen as a reliable data source , with quality control measures and personnel that do as much follow - up as possible to fill in data gaps by contacting hospitals , medical offices , and coroners' offices to obtain accurate and complete information .

however , fars contains information only on fatal crashes — about 1 percent of all crashes .

thus , while the fars data may be more complete and consistent for those crashes that are included , the vast majority of alcohol - and drug - related crashes are not included .

further , nhtsa imputes some of the alcohol information because even with follow - up there are often gaps in data .

federal motor carrier safety administration ( fmcsa ) the commercial vehicle analysis and reporting systems is a cooperative effort between nhtsa and fmcsa to improve collection of bus and truck data .

its aim is to improve the national data system for all crashes involving commercial motor vehicles and to develop a national analytical data system similar to the fatality analysis reporting system for commercial vehicles .

federal highway administration ( fhwa ) the highway safety information system ( hsis ) is a 9-state database that contains crash , roadway inventory , and traffic volume data .

under contract with fhwa , the university of north carolina highway safety research center and lendis corporation operate the system .

the hsis uses state highway data for the study of highway safety .

the system is able to analyze a large number of safety problems , ranging from more basic "problem identification" issues to identify the size and extent of a safety problem to modeling efforts that attempt to predict future accidents from roadway characteristics and traffic factors .

american association of state highway and transportation officials ( aashto ) the transportation safety information management system ( tsims ) is a joint application development project sponsored by aashto to enable states to link crash data with associated driver , vehicle , injury , commercial carrier , and roadway characteristics .

tsims is an enterprise safety data warehouse that will extend and enhance the safety analysis capabilities of current state crash records information systems by integrating crash data with other safety - related information currently maintained by each state .

association of transportation safety information professionals ( atsip ) atsip aims to improve traffic safety data systems by ( 1 ) providing a forum on these systems for state and local system managers , including the collectors and users of traffic safety data ; ( 2 ) developing , improving , and evaluating these systems ; ( 3 ) encouraging the use of improved techniques and innovative procedures in the collection , storage , and uses of traffic safety data ; and ( 4 ) serving as a forum for the discussion of traffic safety data programs .

in addition to those individuals named above , nora grip , brandon haller , molly laster , dominic nadarski , beverly ross , sharon silas , stan stenersen , and stacey thompson made key contributions to this report .

