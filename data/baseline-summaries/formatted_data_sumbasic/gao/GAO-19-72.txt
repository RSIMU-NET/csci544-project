the increasing availability of open government data — that is , government - produced information that can be freely used , modified , and shared by anyone for any purpose — holds great potential to promote government transparency and private sector innovation .

in recent years , governments around the world have increased the availability of open data by providing information on a wide range of topics such as health , education , transportation networks , budgets , and performance .

such data can foster accountability and public trust by providing citizens with information on government activities and their outcomes .

in addition , according to a 2014 study by the department of commerce , u.s. government data have helped private firms in data - intensive industries generate revenues of at least $24 billion and upwards of $221 billion annually .

however , for open data to achieve their full potential , government websites must ensure that their data are effectively presented to a wide range of users .

to provide more transparency for roughly $4 trillion in federal spending , on march 2 , 2018 , the department of the treasury ( treasury ) released a new version of its usaspending.gov website .

the new usaspending.gov displays data submitted by federal agencies to comply with the federal funding accountability and transparency act of 2006 ( ffata ) , as amended by the digital accountability and transparency act of 2014 ( data act ) , and upon release became the official source of spending data required to be published under the data act .

because of federal spending data's broad appeal to users such as congress , grant recipients , journalists , and the general public , it is important that usaspending.gov follow key practices for reporting this information as transparently as possible .

the data act includes a provision for us to review implementation of the act .

over the past 4 years , we have issued 13 reports assessing various aspects of data act implementation .

this report builds on our body of work on the data act and ( 1 ) identifies key practices for transparently reporting government data on a centralized website , and ( 2 ) evaluates the extent to which the new usaspending.gov is consistent with these key practices , as well as existing standards for federal websites .

to identify key practices for transparently reporting open government data on a centralized website , we conducted a literature search and systematically reviewed articles on open government data programs and practices .

we evaluated and synthesized information from the literature review to identify commonly - reported key practices for transparently reporting open government data .

we also interviewed experts on open data and good governance .

we first had open - ended conversations with experts to obtain their views on what key practices exist for transparently reporting open government data .

after developing an initial list of key practices , we then obtained experts' feedback to finalize the list .

we shared a draft of the key practices with treasury , the office of management and budget ( omb ) , and the general services administration ( gsa ) .

to obtain illustrative examples showing how those key practices can be implemented , we selected open data practitioners from six state and local governments: kansas city , missouri ; los angeles , california ; montgomery county , maryland ; new york city , new york ; and ohio .

we selected these practitioners because they have well - regarded open data websites that include a general open data portal as well as budget or spending data visualizations , and because they represent different locations and levels of government , including cities , counties , and states .

we reviewed these practitioners' open data websites and related documentation , and interviewed cognizant state and local government officials .

to assess the extent to which the new usaspending.gov is consistent with key practices and existing standards for federal websites , we compared the website to applicable laws and policies — such as ffata and omb guidance — as well as the key practices in this report .

we also reviewed documentation related to the website , observed treasury's participation in a hackathon , and interviewed treasury officials .

to clarify policies and practices for federal websites , we interviewed gsa officials and omb staff .

to evaluate the extent to which specified federal award data elements on usaspending.gov are searchable , as required by ffata , as amended by the data act , we obtained and tested a nongeneralizable , random sample of award data from usaspending.gov .

specifically , we downloaded contract and financial assistance data from usaspending.gov , generated a random sample of awards , and used the website's search tools to search for the required data elements from 15 contracts and 15 financial assistance awards .

for the purposes of this report , we focused on the presentation of data and related contextual information on usaspending.gov .

our review did not include data quality or data governance .

we reported on the quality of the data submitted under the data act in november 2017 .

in 2019 , we will report an updated assessment of the quality of these data and , separately , report on omb and treasury's efforts to develop a governance process for maintaining the integrity of the data standards established under the data act .

detailed information on our scope and methodology is included in appendix i .

we conducted this performance audit from february 2017 to december 2018 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

recognizing the federal government's role as a major supplier of data , the 2018 president's management agenda announced the creation of a federal data strategy .

according to the agenda , this strategy promises to leverage data as a strategic asset to grow the economy , increase the effectiveness of the federal government , facilitate oversight , and promote transparency .

it proposes improving data dissemination by making data available more quickly and in more useful formats , maximizing nonsensitive data shared with the public , and enabling external users to access and use government data for commercial and other public purposes .

the federal data strategy builds on existing policy governing the federal government's websites and data .

in 2016 , omb memorandum m - 17-06 , policies for federal agency public websites and digital services , established policy for the federal government's online information resources , such as the need to ensure that information is searchable and to inform users about information quality issues .

in addition , in 2013 , omb memorandum m - 13-13 , open data policy — managing information as an asset , established an information management framework to promote interoperability and openness at each stage of the information life cycle .

these efforts are consistent with the international open government partnership , which aims to make governments more inclusive , responsive , and accountable .

seventy - five countries have committed to the open government partnership by endorsing the open government declaration .

in doing so , these countries have committed to increasing the availability of information about government activities , supporting public participation in government , and using new technologies for openness and accountability , among other things .

enacted in 2006 , ffata requires agencies to report information on federal awards — such as contracts , grants , and loans .

in 2014 , the data act expanded on ffata by establishing new requirements intended to allow policymakers and the public to more effectively track federal spending , including: reporting additional data .

agencies are required to report additional financial data from different points in the spending life cycle .

setting government - wide standards .

omb and treasury are responsible for establishing government - wide financial data standards for any federal funds made available to or expended by federal agencies .

these standards define and describe the data elements that agencies must report .

reporting consistently .

agencies reporting financial information are required to comply with the standards established by omb and treasury so that information can be compared across the government .

improving data access .

the data must be made available in machine - readable and open formats , to be downloaded in bulk , and — to the extent practicable — for automated processing .

the data act required agencies to begin reporting data in accordance with the data standards issued by treasury and omb within three years of its enactment , and required that those data be displayed on usaspending.gov or a successor system .

usaspending.gov has been the platform to provide federal spending information to the public since 2007 ( see figure 1 ) .

in may 2017 , treasury released a new website , beta.usaspending.gov , where it began to publish information submitted under the data act .

in march 2018 , this new website assumed the usaspending.gov web address and treasury retired the old version of usaspending.gov .

data on usaspending.gov come from a variety of sources , including files that agencies began submitting quarterly for data act reporting in may 2017 .

when agencies submit quarterly data , treasury's data act broker ingests the data and validates certain information before the data are published on the website .

agency senior accountable officials certify that the agency's submission is valid and reliable .

in addition to agencies' quarterly data act reporting files , usaspending.gov includes data from government - wide systems .

government - wide procurement data on the website are updated daily , while government - wide financial assistance data are updated biweekly .

the new usaspending.gov also includes older award data that had been available on the prior version of the website .

in november 2017 , we issued our first report on data quality as required by the data act .

we found issues with the completeness and accuracy of the data that agencies submitted for the second quarter of fiscal year 2017 as well as the use of data elements .

for example: of the 78 agencies that submitted data on time , 13 submitted the data file intended to link budgetary and award information without providing any data in the file .

between 56 and 75 percent of the newly - required budgetary records were fully consistent with agency sources , but only between 0 and 1 percent of award records ( such as grants , contracts , and loans ) were fully consistent .

agencies differed in how they interpreted and applied omb's definitions for two data elements — primary place of performance and award description — raising concerns regarding data consistency and comparability .

these two award data elements are particularly important to achieving the transparency goals envisioned by ffata because they provide the public with information on where the federal government spends money and what it spends it on , respectively .

we also found issues with the presentation of the data on beta.usaspending.gov , including fragmented or incomplete search results and insufficient disclosure of data limitations .

among other things , we recommended that treasury disclose known data quality issues and limitations on the new usaspending.gov website .

we provide an update on actions treasury has taken to address this recommendation later in this report .

we identified five key practices that managers of open government data programs can consider to help ensure the transparent presentation of their data .

we also identified key actions for implementing each key practice .

we identified these key practices and key actions by systematically evaluating and synthesizing information from literature on open data as well as interviews with open data experts and good governance groups .

these key practices and key actions are listed in table 1 .

these key practices and actions are intended to be used in tandem with requirements for federal government websites and open data programs , such as relevant laws and omb guidance .

they are not intended to replace or supersede any applicable requirements .

when considering an individual open government data program , some key practices and actions may be more relevant than others because the purpose and characteristics of open government data programs may vary .

in addition , while this report focuses on the presentation of open government data , open data practitioners should also consider other elements — including data quality and data governance — to ensure that the public has access to high - quality information .

to promote transparency , we found that open data should be freely and equally available to users without restrictions .

as such , we identified two key actions for providing free and unrestricted data ( see figure 2 ) .

make government data open by default , while protecting sensitive or restricted information .

making government data open by default ensures that the data are equally open to all types of users ; in contrast , when government information is available by request , it may favor citizens with greater information about and access to government institutions .

in addition , some open data practitioners we spoke with said that providing open data can minimize the burden of responding to information requests .

for example , according to connecticut officials , before the state's open spending data website was launched , payroll data were the most frequently requested information under the state's freedom of information act ( foia ) .

officials said that providing open payroll data on the website significantly reduced foia requests , which allowed state officials to spend time and resources on other activities .

however , not all government information is appropriate to publish .

some datasets may contain sensitive information such as personally identifiable information , information that is classified or similarly not subject to disclosure , or intellectual property .

other legal restrictions may also prohibit the disclosure of certain information .

in some cases the information in an individual dataset may not pose a risk of identifying sensitive information , but may pose such a risk when combined with other available information .

for that reason , when considering whether or not information may be disclosed , omb m - 13-13 requires agencies to determine whether it may be combined with existing publically available data to identify an individual or otherwise pose a security concern .

in such situations , agencies must conduct a risk - based privacy analysis to determine whether the information can be made publicly available that accounts for the nature of the information , the availability of other information , and the technology in place that could facilitate the process of identification .

as an example of how open data practitioners can balance these types of considerations , montgomery county , maryland , applies safeguards such as a review by internal departments .

additionally , if department officials request a secondary fact - specific review , the office of the county attorney will review the information to further ensure that protected information is not published .

in some cases , sensitive information is removed from a dataset prior to publication .

for example , according to county officials , the names of housing assistance recipients are removed from spending data to protect resident privacy .

users can see nonsensitive aspects of these data , such as the amount spent , with identifying details removed .

do not charge users for access to the data .

providing data for free can help ensure equitable access to users independent of their ability to pay .

lowering barriers , such as cost , increases the value of open data , as more users are able to access it .

open government data only create value to the extent that they are used .

with that in mind , we identified three key actions for engaging with users ( see figure 3 ) .

identify data users and their needs .

by identifying who is using the data and what content or features are important to them , data providers can better prioritize their efforts to present information to data consumers .

open data experts we spoke with emphasized that data providers should engage with users both inside and outside of government , including groups that may typically have less access to government institutions .

for example , to further new york city's open data for all vision to provide open data for people from all walks of life and all five of the city's boroughs , columbia university students conducted user research on behalf of the city to better understand the extent to which community organizations use open data and what barriers they face , according to the capstone report for this project .

by surveying and interviewing these organizations , the students learned that users found the city's data portal interface difficult to use .

in response , the city worked with users to design and test a new , more streamlined portal .

solicit and be responsive to user feedback .

soliciting and being responsive to user feedback — both when the website is being developed and on an ongoing basis — can help ensure that the website meets users' needs .

feedback can also surface issues with the functionality of the website and the quality of the data , thus enabling the data provider to make corrections when needed .

user feedback mechanisms vary and can include online comment forms , forums , and discussion boards , as well as in - person public forums .

open data experts we spoke with said it is particularly helpful to list the contact information for a responsible official on the website in case users have questions about the data .

in addition , timely response to feedback encourages engagement by assuring users that their voices have been heard .

monitoring how the public is using the data can also help practitioners determine which content and features are most useful .

web analytics can show how the data are being used , such as by identifying commonly - used search terms and datasets , and showing trends over time .

web analytics web analytics is the collection , reporting , and analysis of website data , such as the number of users who visit the website .

according to a city official , los angeles uses web analytics to measure how frequently its datasets are accessed .

web analytics data showed that some datasets were often accessed on certain dates or in conjunction with current events , while other datasets were rarely used .

city officials use this information to adjust how data are presented on the website , which has increased overall use of the city's data .

for example , the city created data visualizations and links to data — including its city revenue and city budget expenditures datasets — to accompany the release of its comprehensive annual financial report .

reach out to potential users to encourage data use .

actively engaging potential users can provide an opportunity to educate them on how the data can be appropriately used and encourage innovation .

data trainings can provide potential users with important context and information , which can include teaching users how the data can be used .

resources such as how - to guides can also encourage data use .

for example , as shown on the website , new york city's open data portal includes a “how to” page with a step - by - step guide to help users get started with open data , and directs them toward additional resources such as data dictionaries .

we previously found that open data collaboration and prize competitions or challenges are two strategies that agencies can use to harness the ideas , expertise , and resources of those outside of their organization .

agencies engage in open data collaboration by mobilizing participants to use their open data in innovative ways , such as sharing , exploring , and analyzing publicly - available datasets ; using the data to conduct research ; designing data visualizations ; or creating web and mobile applications and websites that help people access and use the data .

in addition , agencies use prize competitions or challenges for help solving a problem or reaching a specific goal by asking members of the public to submit potential solutions .

the agency then evaluates these proposals and provides a monetary or nonmonetary award to selected winners .

new york city encourages the use of its open data using these strategies by hosting data literacy trainings , hackathons , and contests .

for example , in the spring of 2018 the city hosted a contest to recognize projects that effectively use its open data and showcase the diversity of potential uses , according to city officials and contest documentation .

winning projects were posted to a gallery on the city's open data website .

as shown on the city's open data website , one winner — a project called “plan ( t ) wise” — predicts various tree species' likelihood of survival in locations throughout the city based on tree census data , and recommends which type of tree to plant at a given address .

data are most useful when they are provided in formats that allow them to be analyzed in a variety of ways .

we identified four key actions for providing data in useful formats ( see figure 4 ) .

provide users with detailed and disaggregated data .

data are most useful when they are provided in as much granularity as possible .

for example , ohio's online checkbook allows users to view detailed , disaggregated data in a user - friendly checkbook format , as shown on the website ( see figure 5 ) .

the representation of the expenditure is displayed as a check , and includes the vendor's name and address , the amount paid , payment date , check number , and contact information for the appropriate state office .

provide machine - readable data that can be downloaded in bulk and in selected subsets .

providing data in machine - readable formats makes them easier to process and analyze , which is particularly important for large datasets .

for example , kansas city officials said the city has been working to convert information from the pdf format to machine - readable formats such as csv because pdf documents are challenging for the city to update and for users to navigate .

in one instance , officials said that converting the city's list of vehicles for sale in its tow lot from pdf to csv format allowed the city to update the data more frequently so that users can see what vehicles are for sale at any given time .

making data available to download in bulk allows users who need the full dataset to easily access it rather than retrieving information record - by - record .

if the full dataset is large , allowing users to download selected subsets can make it easier for them to work with only the data they need .

data can also be provided to users through an application programming interface ( api ) , which allows users to connect directly with the dataset by enabling machine - to - machine communication .

apis can be particularly useful for large , frequently updated , or highly complex datasets because they offer users flexibility to obtain the data they need .

in addition , developers can use apis to build applications based on the data .

non - proprietary file formats file formats describe what type of information a file contains , as well as how that information is stored and structured .

some file formats are proprietary , meaning that they can only be opened by specific commercial software applications .

in contrast , non - proprietary formats are publicly available and can be used by all software developers .

examples of non - proprietary file formats include: csv , which stores tabular data ; rdf , which stores metadata ; txt , which stores unformatted text ; and xml , which stores both the format and content of data .

provide data downloads in a non - proprietary format .

to ensure broad and equitable access , data downloads should be available in formats that do not require specific commercial software to access , and therefore do not exclude users who do not have access to such software .

non - proprietary data formats include , but are not limited to , csv , rdf , txt , and xml .

for example , kansas city , missouri's , open data portal allows users to export spatial data in an open format that does not require proprietary mapping software , according to city officials and the city's open data portal website .

open data experts we spoke with said that practitioners should consult stakeholders when determining which format is appropriate for a given program , and that the appropriate format may change over time as technology advances .

make the data interoperable with other datasets .

making data interoperable with other datasets can make them more useful because users may want to create new opportunities for analysis by linking datasets together .

this can be done by standardizing the way that the data are reported .

for example , using standard definitions for the specific items included in a set of data — known as data elements — can promote consistency with other datasets .

additionally , documentation such as data dictionaries can help ensure that definitions are clear and avoid misunderstandings .

to promote interoperability between datasets that use geographic information , kansas city uses standard land parcel identification numbers across departments .

this allows different datasets that contain location information to be used in combination .

for example , officials said that the city is linking different datasets that use those identification numbers — including building code violation data , 311 calls , and dangerous buildings data , among others — to build a model to prioritize code enforcement inspections .

providing information about a dataset allows users to determine whether it is suitable for their intended purpose , and make informed decisions about whether and how to use it .

with that in mind , we identified four key actions for fully describing the data ( see figure 6 ) .

disclose known data quality issues and limitations .

disclosing data quality issues and limitations helps users make informed decisions about whether and how to use the data .

disclosure of data quality issues and limitations can include descriptions of the completeness , timeliness , and accuracy of the data , such as an explanation of why certain data may not be disseminated .

for example , we observed that connecticut's “opencheckbook” website includes an “about” page explaining that some information is excluded to protect privacy , or because it is not processed through the state's financial system , such as the state's airport authority , jury duty payments , and unclaimed property .

disclose data sources and timeliness .

disclosing where the data come from and how frequently they are updated provides context that helps users judge their quality and determine whether they can be appropriately used for the intended purpose .

without this information , users may view , download , or use data without full knowledge of the extent to which they are timely , complete , or accurate , and therefore could inadvertently draw inaccurate conclusions from the data .

metadata metadata provide descriptive information about a dataset in a structured , machine - readable format .

they describe aspects of the dataset — such as the source of the data and when it was last updated — in clearly delineated fields .

clearly label data and provide accompanying metadata .

in addition , data should be clearly labeled and accompanied by structured metadata so that users can easily find information about the dataset .

metadata describe the characteristics of data in clearly defined , machine - readable fields , which can include attributes such as the date the data were created or modified , or the license used , among other things .

structuring metadata in clearly defined fields makes it possible for search tools to filter and match content pertaining to those fields .

as shown in figure 7 , kansas city's budget data are accompanied by metadata showing when they were last updated , the source of the data , and the name and contact link for the dataset owner , among other things .

publish data under an open license and communicate licensing information to users .

documentation for a dataset should also specify what license applies to the data because a data license provides users with information about how they may use the data , including whether there are any restrictions , such as copyrights .

an open license indicates that there are few to no restrictions on how the data may be used .

an open license can encourage innovation , for example , by assuring users that they are permitted to use the data to develop commercial applications .

to realize these benefits , licensing information should be clearly communicated to users , ideally in machine - readable and human - readable formats .

as shown in figure 7 , metadata can be used to communicate licensing information in a clear and structured way .

including licensing information in metadata can help ensure that it is machine readable — which makes it easier to process and analyze — as well as help users discover the licensing information and compare it across datasets .

data discovery is facilitated by presenting the data in a way that enables users to easily explore them .

we identified five key actions for facilitating data discovery for all users ( see figure 8 ) .

provide an interface that enables intuitive navigation and ensures that the most important information is made visible .

to facilitate data discovery for all users , practitioners of open government data should ensure that the data are provided on a website that is simple and intuitive so that users can easily navigate it to find the information they need .

obtaining user feedback and conducting usability testing can help practitioners assess whether the website is easy to use , and identify any aspects that do not work well for users .

in addition , websites designed to work on mobile devices , as well as mobile applications such as ohio's “ohiocheckbook” app ( see figure 9 ) , can allow users to access data on a variety of devices , according to the state's website and our observations .

provide users with appropriate interpretations of the data , such as visualizations or summaries .

summaries and visualizations can help users explore data .

for example , our review of montgomery county , maryland's , “spendingmontgomery” website found that the website provides summary data of the top five services , vendors , and expense categories with the greatest amount of spending , as well as a chart of annual spending along with historical averages , as shown in figure 10 .

this summary information provides a starting point for users , who can then navigate through the website to access more granular data .

ensure that the website's content is written in plain language .

the content of an open data website should also be written in a way that is clear and direct , using plain language .

using commonly understood terms rather than technical jargon can help users understand the information provided .

for example , to use well - understood terms when communicating budget information , kansas city officials told us they participated in plain language training and applied that knowledge to the city's open budget data website .

in addition , we found that in cases where it is necessary to use technical language , providing a glossary that defines key terms can help make the information understandable to users .

provide a search function that is optimized for easy and efficient use .

open data websites should also include a search function that is optimized for easy and efficient use so that users can find information that is relevant to them .

for example , connecticut officials said that the search function on the state's open spending data website is designed so that users do not need to be familiar with the state government's structure or terminology to find meaningful results .

when a user enters a search term , the search bar will return a list of items that include this term and a description of what they are .

for example , when we typed “education” into the search bar , the website suggested department of education spending , bilingual education programs , and a vendor called family life education .

in addition , connecticut officials told us that they track the most commonly - used search terms — such as “housing” and “voter turnout” — on the state's open data portal , and test them to verify that the information is discoverable .

similarly , ohio's online checkbook includes a “popular searches” tool that provides presaved searches that allow users to see expenditures for a variety of categories — such as travel , roads and highways , or parks — by clicking a single button .

in addition , officials told us that if a user's search returns a large volume of results , a pop - up appears prompting the user to narrow their search , which could help them focus on more relevant information .

use central data repositories and catalogues to help users easily find the data they are looking for .

central data repositories and catalogues — also known as data portals — are websites that provide a “one - stop shop” for users to access a variety of datasets .

these websites host the data directly , link to other websites where users can access the data , or a combination of the two .

they typically provide descriptions of the datasets , as well as structured metadata , to help users find data suitable for their purpose .

new york city's open data portal also includes a number of tools to help users find datasets , including a search function as well as lists of new datasets , popular datasets , and datasets by category , as shown in figure 11 .

we found that usaspending.gov aligns with the key practices of providing free and unrestricted data and engaging with users .

however , treasury does not fully describe the data and two data elements required by law are not searchable .

in addition , treasury lacks a process to ensure all pages on the website are secure , consistent with federal requirements .

spending data are open by default and sensitive information is protected .

the federal funding accountability and transparency act of 2006 ( ffata ) requires the website displaying the data that agencies must provide to be accessible to the public at no cost .

in response to requirements in ffata , as amended by the digital accountability and transparency act of 2014 ( data act ) , in may 2014 , omb and treasury developed standard definitions for data elements for agencies to report , and treasury displays these open data on usaspending.gov .

agencies should not report classified or protected information , such as personally identifiable information ( pii ) .

however , they are required to aggregate some awards containing pii at the county or state level if they are unable to report spending at the individual level .

all data are available for free .

treasury has made all of the data on usaspending.gov available to users at no cost , as required by the data act and ffata .

during the course of our work , we found that users could only download the complete database after registering for an account with the database host — amazon web services .

further , we also found that users would incur a charge when attempting to download the entire database .

treasury officials said they intended for the data to be available for free and were unaware that users were being charged to access the data .

in response to our inquiries on this issue , in july 2018 , treasury resolved this issue and provided an option for users to download the entire database for free without creating an account .

treasury identifies data users and their needs through user research .

treasury researches users to understand their needs when working with usaspending data .

treasury has developed profiles for eight types of users ranging from data consumers like “citizen” or “journalist” ( see figure 12 ) to budget analysts or chief financial officers .

these profiles are part of treasury's user - centered design process in which officials told us they learn from users , make changes to the website , and test whether those changes make the website more useful and intuitive to users .

treasury obtains and responds to user feedback .

treasury officials told us that they track user feedback , which informs improvements they make to the website .

we previously found that treasury has a variety of user feedback mechanisms , including a community forum , one - on - one interviews , and a “contact us” link that allows users to provide feedback by email .

as of july 2017 , treasury officials said they had interviewed more than 130 users , such as citizens , funding recipients , and federal agency officials , regarding usaspending.gov website features .

they have since conducted 20 additional interviews about the user experience and received feedback from another 130 users about the data lab , a related website that offers visual interpretations of the spending data .

treasury has also conducted “intercept” interviews where interviewers go to a location with large groups of people and request feedback about the website from random individuals .

for example , figure 13 shows a treasury contractor interviewing a visitor about an early version of usaspending.gov at the u.s. capitol visitor center .

treasury officials said they respond to user feedback about usaspending.gov on two websites .

they respond directly to user comments on the usaspending.gov community website , where users can share feedback and find answers to frequently asked questions .

treasury officials told us they also track users' issues as “stories” on an open development platform called jira , which is their primary way of documenting website development decisions and tracking potential improvements to the website .

for example , treasury added new functionality to the application programming interface ( api ) based on user feedback from agencies .

officials said this feature allowed some agencies to more efficiently manage their quarterly data act submissions .

treasury announces updates to the api and other changes to the website via an email newsletter .

treasury reaches out to potential users to encourage data use .

treasury educates the public about the use of the spending data on usaspending.gov and the data lab through how - to guides and outreach activities .

for example , the website offers an “api guide” for users seeking to utilize computer programs to request and receive the data , and the data lab features an “analyst guide” that answers questions about using the data .

treasury officials told us that they have directly engaged with various audiences about usaspending.gov .

for example , they have engaged with the syracuse university maxwell school of government to map the use of federal funds in new york state .

in april 2017 , we observed treasury's participation in a hackathon where participants developed ways to use federal spending data , including using the spending data to evaluate block grant formulas and track the economic impact of stimulus money .

treasury officials said they have held information sessions with congress , federal agencies , and nongovernment organizations .

usaspending.gov provides users with detailed and disaggregated data .

as shown in figure 14 , an award summary page on the website displays information on specific awards , including the awarding agency , recipient , award amount , description , and location .

these pages also include transaction histories so that spending can be tracked over time .

as of october 2018 , we found that usaspending.gov listed more than 53 million pages of prime awards representing more than $33 trillion in obligated funds between fiscal year 2008 and 2018 .

data are machine readable and can be downloaded in bulk and in selected subsets , but treasury lacks a process to fully ensure security .

as shown in figure 15 , usaspending.gov provides six ways for users to download the data , including subsets of the data or the complete database .

an api is also available , which enables machine - to - machine communication that allows real - time updates .

during the course of our review , we found that some of the data download web addresses did not point to a government domain and were unsecured .

omb guidance requires that federal web pages be hosted on a .gov domain and be encrypted by the secure https protocol .

in response to our inquiries on this issue , treasury updated usaspending.gov in october 2018 so that the web pages for the database download and agency submission files use the secure https protocol and are on a government domain .

as a result , the users requesting this information from usaspending.gov now have better assurance of the integrity of the data requested , the privacy of their connection to usaspending.gov , and that the website they are using is a trusted government domain .

treasury officials said they take steps to ensure they meet federal information security requirements , but had not noticed that the web pages were unsecured or on a nongovernment domain .

according to treasury officials , the agency has a process for the team developing a website to vet whether proposed pages are secured and hosted properly , but they acknowledged unintended gaps in how the process was applied in this case , which caused some pages to be omitted .

standards for internal control in the federal government states that management should design control activities to achieve objectives and respond to risks .

control activities are the policies , procedures , techniques , and mechanisms that enforce management's directives to achieve the entity's objectives and address related risks .

until the gaps in treasury's information security process are addressed , the agency does not have assurance that any new pages that may be added to usaspending.gov will conform to federal information security requirements .

in response to our inquiries , treasury provided documentation showing that the agency is in the process of addressing the issue to prevent future unintended gaps .

the agency has taken initial steps to revise its process to ensure that all pages on usaspending.gov are secured and hosted properly .

we will continue to monitor treasury's efforts to develop and implement this new process .

downloads are available in standard , non - proprietary formats .

downloads of search results , agency files , and subsets of the usaspending.gov database are available in file formats that can be opened using common office software , including csv and xml files .

spending data are potentially interoperable with other datasets .

the data in the usaspending.gov database are organized according to a government - wide standard which can potentially support interoperability with related government datasets .

the data act information model schema ( daims ) provides standardized definitions for federal spending information , including 57 data standards that federal agencies are required to report for data act implementation .

these standards come with technical specifications describing the format and structure of each data element , which are intended to facilitate consistent data reporting across the federal government , and allow for interoperability between agencies' data submissions .

according to treasury's daims architecture document , daims could eventually support interoperability between usaspending.gov and related nonfederal datasets such as state , local , and international spending data .

for example , state governments could make their data interoperable with the federal spending data on usaspending.gov by developing their own data standards and definitions aligned with daims as appropriate .

in addition , the daims architecture document specifies that future daims content could include federal receipt and financing balances with accounts and sources , as well as performance measures and outcomes linked to federal grants , awards , or other financial assistance .

website still does not completely disclose data quality issues .

treasury has improved the disclosure of data quality issues and limitations , but other issues have not yet been described to users .

in november 2017 , we found that the website did not sufficiently disclose known limitations affecting data quality .

we recommended that treasury disclose known data quality issues and limitations .

treasury agreed with the recommendation and took the following steps to disclose limitations: by may 2018 , treasury had added a “learn more” box to the website with information about the data , including an explanation that the department of defense reports its data later than other agencies .

in june 2018 , treasury added information on unreported spending to the spending explorer tool that visualizes federal spending , clarifying that information reported on the website does not capture the totality of federal spending .

treasury explains to users that data might not be reported when an agency reports incomplete data , has a submission deadline extension , is not required to submit certain data elements , and for accounts that are not reported to treasury .

while the steps treasury has taken are positive , they do not fully address our recommendation .

this is because one purpose of the data act is to allow users to track federal spending more effectively by linking specific awards to financial budgetary information .

however , we found that award data do not appear in the spending explorer for combinations of certain agencies and program activities .

for example , as figure 16 shows , there are “no associated awards” for the program activity “vaccines for children” within the department of health and human services account for medicaid grants to states .

however , the account page for this program elsewhere on usaspending.gov shows approximately $3.6 billion in obligations and various associated awards for the first three quarters of fiscal year 2018.there is no context for a user to understand whether this information is required for this federal account , missing , or searchable elsewhere on the website .

treasury officials informed us of a number of data limitations that could cause spending data and award data to be disconnected in the spending explorer , but these issues are not disclosed on the website .

according to treasury officials , agencies might not currently report certain data fields as some fields are optional , there are inconsistencies between several agency data systems , and some agencies have not been able to link financial and award data .

as a result , the spending explorer does not consistently provide a clear and complete presentation of federal spending , and because treasury does not disclose these limitations , it could limit the ability of taxpayers and policy makers to fully track federal spending with this tool .

more broadly , we have raised concerns that usaspending.gov does not sufficiently disclose other , broader government - wide data quality issues .

for example , we found in november 2017 that only between 0 to 1 percent of awards were fully consistent with agency records .

while the consistency of individual data elements varied , our prior report found inconsistencies with agency records in at least 41 percent of the data for award description , current total value of award , and primary place of performance address from the second quarter of fiscal year 2017 .

website discloses data sources and timeliness .

the “about” page and “frequently asked questions” describe data sources , data quality , and legal requirements .

there is also a diagram on the “about” page showing how the data go from agencies to the database for usaspending.gov , and the frequency with which the data are updated , which is a useful way to visualize how the types of award data are updated either daily , bi - monthly , or every quarter .

website labels some data , but lacks structured metadata .

treasury labels some of the data on usaspending.gov in tables and data visualizations , and describes it in narrative form .

the website also includes data dictionaries that provide definitions for the data elements .

however , the website lacks structured , machine - readable metadata .

omb guidance requires agencies to use metadata to describe their datasets so that all users can understand and process open data .

agencies must consult with the best practices from project open data , omb's online repository of tools and schema , to help agencies meet the requirements of its open data policy .

according to project open data , metadata are structured information that describe , explain , locate , or otherwise make it easier to retrieve , use , or manage datasets like that displayed on usaspending.gov .

this guidance also indicates that making metadata machine readable greatly increases their utility .

treasury officials said the types of information found in metadata are already available in a number of separate documents on treasury's fiscal service web page .

treasury officials told us that they decided not to provide structured metadata on usaspending.gov because it is more efficient to provide external links to other websites .

further , treasury officials asserted that providing metadata on those websites is sufficient to comply with omb guidance .

however , the information found on these various websites does not align with best practices outlined in project open data , or the key action to clearly label data and provide accompanying metadata , because it is not provided in a single place on usaspending.gov as structured metadata in a machine - readable format .

without easy access to information that fully describes the data , it may be difficult or time consuming for users of usaspending.gov to find the information available on other websites , and determine whether or how to use the data for their purposes .

website lacks complete licensing information .

while the website describes restrictions on the use of proprietary contract data from dun & bradstreet inc.'s data universal numbering system ( duns ) , it does not include general licensing information for the rest of the data .

the website includes a link to a notice specifying the “limitation on permissible use of dun & bradstreet , inc. data.” according to treasury officials , most data on usaspending.gov are in the public domain , but we found that the website does not clearly indicate which data are openly available to use without restrictions .

omb m - 13-13 specifies that federal agencies “must apply open licenses , in consultation with the best practices found in project open data , to information as it is collected or created so that if data are made public there are no restrictions on copying , publishing , distributing , transmitting , adapting , or otherwise using the information for non - commercial or for commercial purposes.” according to omb staff , agencies should include licenses in metadata so that this information is machine readable .

if data access is limited , this should also be prominently featured in the metadata .

in addition , project open data specifies that licensing information should be provided in metadata .

treasury officials said that the agency is evaluating options and approaches for including open data licensing information on the website , consistent with omb m - 13-13 .

in addition , treasury officials said they had only received one question from users about licensing .

however , not displaying licensing information for the majority of data elements on the website is not consistent with the key action to publish data under an open license and communicate licensing information to users .

without licensing information for all of the data , users will likely be unable to determine what license , if any , applies to usaspending.gov , and it will be unclear to the public whether there are any restrictions to reusing data that they can download from the website .

website includes a user interface to assist navigation .

usaspending.gov's top menu gives users various ways to explore , search , download , and understand the most important information .

the menu links to the spending explorer , award search , profiles , download center , and glossary .

there is also “featured content” on the home page guiding users to the data lab , and other new features such as a download option for federal account data and recipient profile pages for any entity that has received federal money in the form of contracts , grants , loans , or other financial assistance .

interactive visualizations enable exploration .

search results can be visualized by prime award or subaward aggregated in a table , in a chart showing awards over time , in a map showing the geographic distribution of awards ( see figure 17 for an example of social security insurance results mapped by congressional district ) , or in a bar chart showing the top 10 awards by category .

the visualizations show how spending has increased over time , the regional concentration of spending , and a list of the top recipients .

we found that the spending explorer provides a simple , graphical interface that allows users to navigate spending data by budget function , agency , and object class .

it gives users the option to drill down from these three high - level categories to specific program activities , federal accounts , recipients , or awards .

it displays the total amount obligated for the selected category , and a breakdown of the amounts in dollars and as a percentage of the total .

the data lab is a separate website linked to usaspending.gov that offers users visual interpretations of the spending data .

treasury officials said the “contract explorer sunburst” is a popular data lab visualization .

as shown in figure 18 , it provides users an interactive overview of about $500 billion in federal contract data organized as a set of concentric circles starting from the funding agency ( inner ring ) to the recipients ( outer ring ) .

treasury officials noted that analyses and visualizations in the data lab are updated with varying frequency because it can be a challenge to continually update some of the visualizations .

the website includes a glossary that provides plain language definitions of terms that describe the spending data .

to help users understand the data on usaspending.gov , the website provides a “glossary” sidebar that is available on every page of the website , and provides users both “plain language” and official definitions of financial terms that are used on the website , as shown in figure 19 .

according to the key practices we identified , using commonly understood terms rather than technical jargon can help users understand the information provided .

a variety of search tools are available , but program source and city are not searchable .

we found that the website features a variety of search tools to help users find and interpret the data .

users can search the data using generic keyword search and advanced search filters .

these features allow users to explore and quickly obtain large volumes of award results .

for example , we found that searching by funding agency returns all spending by that particular federal agency and by award .

however , we tested the search functionality of the website and found that two data elements required to be searchable by ffata , as amended by the data act , were not: ( 1 ) program source ( treasury account symbol ( tas ) ) and ( 2 ) city .

our search testing of a nongeneralizable , random sample of awards for data elements required by ffata successfully found most of the data elements , but we were unable to search for program source ( tas ) or city .

tas and city data can be downloaded and are displayed on award web pages , but we were not able to search for them using either the advanced or keyword search pages .

treasury officials said they did not include functionality to search for these two required data elements on the new website because users searching by these data elements on the beta version of the website had received confusing results .

this is due in part to the fact that agency submissions with these data elements used different standards before and after the data act .

instead , according to our review of the website , users can access tas and city information using the website's navigation features , which officials said meets the spirit of the ffata requirement .

however , simply displaying tas or city information only on award or federal account pages does not meet the ffata requirement that users be able to search for this information .

users currently have to click on a specific award or federal account page , and scroll through the web page to find the relevant section that shows city or tas information .

if federal agencies and congress are not able to search for tas , they cannot easily connect detailed information on financial transactions to federal accounts for management or oversight purposes .

in addition , users looking for geographic information related to recipients or federal programs cannot easily search usaspending.gov by city .

government data catalogues and repositories link to usaspending.gov .

treasury facilitates discovery of the data act data by linking to usaspending.gov from centralized data repositories and catalogues .

information and links to usaspending.gov can be found on data.gov , which is a data catalogue for a variety of u.s. government datasets .

treasury maintains a web page on github , a public online collaboration website , designed to share information about its process in meeting the requirements of the data act , including information and links to usaspending.gov .

associated pages on this github site serve as a data repository for the computer code behind the central data submission platform for the data act , called the data act broker , the api for usaspending.gov , and the usaspending.gov website itself .

usaspending.gov is a major open government data program with the potential to be a model for transparently reporting government data — if treasury takes additional steps to further align it with the five key practices and associated key actions for open data in addition to data act requirements .

usaspending.gov has already followed several key actions such as providing the data on the website for free , engaging the public online and in person , providing detailed and disaggregated data for download , and making interactive tools so users can interpret and visualize the data .

treasury has also made progress in disclosing limitations of the data , although it has not fully addressed our prior recommendation to do more to make users fully aware of issues that affect its quality .

however , treasury has not fully aligned usaspending.gov with some key practices or federal website standards , and has not fully implemented the search functionality required by ffata , as amended by the data act .

as a result , users may not be able to find the information they need , and may not have confidence in the integrity of the data .

treasury updated usaspending.gov in october 2018 so that the web pages for the database download and agency submission files available at that time used the secure https protocol and a government domain .

however , without an effective control process in place , treasury does not have assurance that any new pages that may be added to usaspending.gov will conform to certain federal information security requirements .

furthermore , without easy access to structured metadata , it may be difficult or time consuming for users of usaspending.gov to find the information they need to determine whether or how to use the data .

similarly , the lack of an explicit open license might discourage some users from using the data to develop innovative commercial products .

users are also not able to easily search award information by program source or city , as required by ffata , which could limit their ability to find and use these data to inform future decision making .

we are making a total of five recommendations to treasury .

specifically: the secretary of the treasury should establish a process to ensure all pages on the usaspending.gov website use the secure https protocol , consistent with omb requirements .

 ( recommendation 1 ) the secretary of the treasury should establish a process to ensure all content on usaspending.gov is available from a government domain , consistent with omb requirements .

 ( recommendation 2 ) the secretary of the treasury should fully comply with omb's requirements by providing metadata in a single location that are easy to find on the usaspending.gov website .

 ( recommendation 3 ) the secretary of the treasury should fully comply with omb's requirements by communicating licensing information on usaspending.gov .

 ( recommendation 4 ) the secretary of the treasury should ensure that users can easily search for awards by city and program source ( tas ) , consistent with ffata requirements .

 ( recommendation 5 ) .

we provided a draft of this report to the secretary of the treasury , the director of omb , and the administrator of gsa for review and comment .

treasury provided written responses , which are summarized below and reproduced in appendix ii .

treasury and omb also provided technical comments , which we incorporated as appropriate .

gsa responded that the agency had no comments on the report .

in its written response , treasury highlighted areas where usaspending.gov aligned with the key practices that we identified for transparently reporting government data , such as engaging users and providing the data in useful formats .

treasury agreed with our recommendations .

treasury stated that the agency has already taken steps to address our first two recommendations , to establish processes to ensure that all pages on usaspending.gov use the secure https protocol and to ensure that all content on the website is available from a government domain .

treasury provided us with documentation of a revised process that is intended to address these issues .

we revised the report to acknowledge that treasury has taken these steps .

we will continue to monitor treasury's efforts to develop and implement this new process and update the status of our recommendations accordingly .

we also provided excerpts of the draft report to connecticut ; kansas city , missouri ; los angeles , california ; montgomery county , maryland ; new york city , new york ; and ohio .

los angeles , montgomery county , new york city , and ohio provided technical comments , which we incorporated as appropriate .

connecticut and kansas city officials responded that they had no comments .

we are sending copies of this report to the secretary of the treasury , the director of omb , and the administrator of the general services administration , as well as interested congressional committees and other interested parties .

this report will be available at no charge on our website at https: / / www.gao.gov .

if you or your staff has any questions about this report , please contact triana mcneil 202-512-6806 or mcneilt@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of our report .

key contributors to this report are listed in appendix iii .

the digital accountability and transparency act of 2014 ( data act ) includes a provision for us to review implementation of the act .

over the last 4 years , we have issued 13 reports assessing various aspects of data act implementation .

this report builds on our body of work on the data act and ( 1 ) identifies key practices for transparently reporting government data on a centralized website , and ( 2 ) evaluates the extent to which the new usaspending.gov is consistent with these key practices , as well as existing standards for federal websites .

to identify key practices for transparently reporting open government data on a centralized website , we conducted a literature review and interviewed experts on open data and representatives of good governance groups .

we also identified illustrative examples by interviewing open data practitioners from state and local governments .

literature review .

to conduct the literature review , we first identified relevant publications using a number of bibliographic databases , including proquest , the organisation for economic co - operation and development's ( oecd ) ilibrary , the national technical information service , and the public affairs information service .

we reviewed articles that focused on open data programs and practices in oecd countries , including scholarly peer - reviewed articles , working papers , conference papers , and reports by policy research organizations , nonprofit organizations , and associations .

we conducted our search in march 2017 and subsequently added relevant articles identified during our background research .

to systematically review these articles , one analyst reviewed each article to identify relevant themes .

a second analyst then reviewed the documentation to verify categorization decisions .

then , both analysts met to resolve any discrepancies .

we evaluated and synthesized the categorized information to identify commonly - reported key practices for transparently reporting open government data .

interviews with experts .

we selected open data and good governance experts based on recommendations made by other experts , frequent citations in others' work , and recent contributions to the field .

we also selected experts that represent a variety of sectors and backgrounds ( such as government , academia , and nonprofit organizations ) .

we obtained the views of the following individuals and organizations: andrew stott , former united kingdom director for transparency and center for open data enterprise , code for america , dr. anneke zuiderwijk - van eijk , delft university of technology , general services administration ( gsa ) , global initiative for fiscal transparency , governance laboratory of new york university , ibm center for the business of government , johns hopkins university center for government excellence , project on government oversight , results for america , u.s. public interest research group , what works cities , and world bank .

we first had open - ended conversations with experts to obtain their views on what key practices exist for transparently reporting open government data .

after developing an initial list of key practices , we then conducted a second round of interviews with experts to finalize the list .

we shared a draft of the key practices with the department of the treasury ( treasury ) , the office of management and budget ( omb ) , and gsa .

illustrative examples .

to obtain illustrative examples showing how those key practices can be implemented , we selected open data practitioners from six selected state and local governments: kansas city , missouri ; los angeles , california ; montgomery county , maryland ; new york city , new york ; and ohio .

we selected these practitioners because they were identified in our literature search and by the experts we spoke with as having well - regarded open data websites .

we also selected practitioners that have websites with both a general open data portal and visualizations showing budget or spending data .

we also selected practitioners that represent different locations and levels of government , including cities , counties , and states .

we reviewed these practitioners' open data websites and related documentation , and interviewed cognizant state and local government officials .

to assess the extent to which usaspending.gov is consistent with the key practices and selected standards for federal websites , we reviewed the website , reviewed agency documents , observed treasury's participation in a hackathon , and interviewed omb staff and treasury officials .

specifically , we analyzed the usaspending.gov website to determine how it aligned with the key practices and the extent to which data elements were searchable as required by the federal funding accountability and transparency act of 2006 ( ffata ) .

we also assessed usaspending.gov against criteria for federal websites and open data programs , including omb m - 17-06 , policies for federal agency public websites and digital services , and omb m - 13-13 , open data policy — managing information as an asset .

to evaluate the extent to which the usaspending.gov search functionality complies with ffata requirements , as amended by the data act , we randomly selected a nongeneralizable sample of 30 awards ( consisting of 15 contracts and 15 financial assistance awards ) downloaded from usaspending.gov for fiscal year 2017 .

we identified the required ffata data elements from these awards , searched for these elements on usaspending.gov in july 2018 , recorded whether each search successfully resulted in a matching award , and observed any other issues that occurred during testing .

finally , we interviewed treasury officials to corroborate our observations on search functionality and other aspects of the website , and discussed any planned improvements to the website .

we also interviewed gsa officials and omb staff to clarify policies and procedures for federal websites .

we conducted this performance audit from february 2017 to december 2018 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact named above , thomas j. mccabe , assistant director , and laurel plume , analyst - in - charge , supervised the development of this report .

colenn berracasa , samuel gaffigan , and parke nicholson made major contributions to this report .

also contributing to this report in their areas of expertise were michael bechetti , steven campbell , mark canter , jenny chanley , jacqueline chapin , peter del toro , nancy donovan , kathleen drennan , sarah gilliland , sarah kaczmarek , michael laforge , paula m. rascona , andrew j. stephens , and james sweetman , jr .

data act: reported quality of agencies' spending data reviewed by oigs varied because of government - wide and agency issues .

gao - 18-546 .

washington , d.c.: july 23 , 2018 .

data act: omb , treasury , and agencies need to improve completeness and accuracy of spending data and disclose limitations .

gao - 18-138 .

washington , d.c.: november 8 , 2017 .

open innovation: executive branch developed resources to support implementation , but guidance could better reflect leading practices .

gao - 17-507 .

washington , d.c.: june 8 , 2017 .

data act: as reporting deadline nears , challenges remain that will affect data quality .

gao - 17-496 .

washington , d.c.: april 28 , 2017 .

data act: office of inspector general reports help identify agencies' implementation challenges .

gao - 17-460 .

washington , d.c.: april 26 , 2017 .

data act: implementation progresses but challenges remain .

gao - 17-282t .

washington , d.c.: december 8 , 2016 .

data act: omb and treasury have issued additional guidance and have improved pilot design but implementation challenges remain .

gao - 17-156 .

washington , d.c.: december 8 , 2016 .

open innovation: practices to engage citizens and effectively implement federal initiatives .

gao - 17-14 .

washington , d.c.: october 13 , 2016 .

data act: initial observations on technical implementation .

gao - 16-824r .

washington , d.c.: august 3 , 2016 .

data act: improvements needed in reviewing agency implementation plans and monitoring progress .

gao - 16-698 .

washington , d.c.: july 29 , 2016 .

data act: section 5 pilot design issues need to be addressed to meet goal of reducing recipient reporting burden .

gao - 16-438 .

washington , d.c.: april 19 , 2016 .

data act: progress made but significant challenges must be addressed to ensure full and effective implementation .

gao - 16-556t .

washington , d.c.: april 19 , 2016 .

data act: data standards established , but more complete and timely guidance is needed to ensure effective implementation .

gao - 16-261 .

washington , d.c.: january 29 , 2016 .

data act: progress made in initial implementation but challenges must be addressed as efforts proceed .

gao - 15-752t .

washington , d.c.: july 29 , 2015 .

federal data transparency: effective implementation of the data act would help address government - wide management challenges and improve oversight .

gao - 15-241t .

washington , d.c.: december 3 , 2014 .

government efficiency and effectiveness: inconsistent definitions and information limit the usefulness of federal program inventories .

gao - 15-83 .

washington , d.c.: october 31 , 2014 .

data transparency: oversight needed to address underreporting and inconsistencies on federal award website .

gao - 14-476 .

washington , d.c.: june 30 , 2014 .

federal data transparency: opportunities remain to incorporate lessons learned as availability of spending data increases .

gao - 13-758 .

washington , d.c.: september 12 , 2013 .

government transparency: efforts to improve information on federal spending .

gao - 12-913t .

washington , d.c.: july 18 , 2012 .

electronic government: implementation of the federal funding accountability and transparency act of 2006 .

gao - 10-365 .

washington , d.c.: march 12 , 2010 .

