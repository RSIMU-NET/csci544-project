for decades , the department of defense ( dod ) has been challenged in modernizing its timeworn business systems .

in 1995 , we designated the department's business systems modernization program as high risk , and we continue to designate it as such today .

as our research on public and private sector organizations has shown , two essential ingredients to a successful systems modernization program are an effective institutional approach to managing information technology ( it ) investments and a well - defined enterprise architecture .

for its business systems modernization , dod is developing and using a federated business enterprise architecture , which is a coherent family of parent and subsidiary architectures , to help modernize its nonintegrated and duplicative business operations and the systems that support them .

in may 2001 , we recommended that the secretary of defense establish the means for effectively developing an enterprise architecture and a corporate , architecture - centric approach to investment control and decision making .

yet , between 2001 and 2005 , we reported that the department's business systems modernization program continued to lack both of these approaches , concluding in 2005 that hundreds of millions of dollars had been spent on a business enterprise architecture and investment management structures that had limited value .

accordingly , we made additional , explicit architecture and investment management - related recommendations to address these continuing deficiencies .

to further assist dod in addressing these modernization management challenges , congress included provisions in the ronald w. reagan national defense authorization act ( ndaa ) for fiscal year 2005 that were consistent with our recommendations .

more specifically , section 332 of the act required the department to , among other things , ( 1 ) develop a business enterprise architecture and a transition plan for implementing the architecture , ( 2 ) identify systems information in its annual budget submission , ( 3 ) establish a system investment approval and accountability structure along with an investment review process , and ( 4 ) certify and approve any system modernizations costing in excess of $1 million .

the act further required that the secretary of defense submit an annual report to congressional defense committees on dod's compliance with certain requirements of the act not later than march 15 of each year , from 2005 through 2013 .

additionally , the act directed us to submit to these congressional committees — within 60 days of dod's report submission — an assessment of the department's actions to comply with these requirements .

accordingly , as agreed with your office , the objective of our review was to assess the actions by dod to comply with the above four provisions of section 332 of the act .

to address the provisions of the act related to enterprise architecture and investment management , we focused on the progress the military departments have made relative to developing their respective parts of the federated business enterprise architecture and establishing investment management structures and processes as required by statute , using the results of our prior reports as a baseline .

to address the budgetary disclosure and certification provisions of the act , we reviewed the department's report to congress , which was submitted on may 4 , 2011 , and evaluated the information used to satisfy the budget submission and investment review , certification , and approval aspects of the act .

we conducted this performance audit at dod and military department offices in arlington , virginia , from january to june 2011 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

details on our objective , scope , and methodology are contained in appendix i .

dod is a massive and complex organization entrusted with more taxpayer dollars than any other federal department or agency .

organizationally , the department includes the office of the secretary of defense , the joint chiefs of staff , the military departments , numerous defense agencies and field activities , and various unified combatant commands that are responsible for either specific geographic regions or specific functions .

 ( see fig .

1 for a simplified depiction of dod's organizational structure. ) .

in support of its military operations , dod performs an assortment of interrelated and interdependent business functions , such as logistics management , procurement , health care management , and financial management .

as we have previously reported , the dod systems environment that supports these business functions is overly complex and error prone , and is characterized by ( 1 ) little standardization across the department , ( 2 ) multiple systems performing the same tasks , ( 3 ) the same data stored in multiple systems , and ( 4 ) the need for data to be entered manually into multiple systems .

the department recently requested about $17.3 billion for its business systems environment and it infrastructure investments for fiscal year 2012 .

according to the department's systems inventory , this environment is composed of 2,258 business systems and includes 335 financial management , 709 human resource management , 645 logistics , 243 real property and installation , and 281 weapon acquisition management systems .

dod currently bears responsibility , in whole or in part , for 14 of the 30 programs across the federal government that we have designated as high risk because they are highly susceptible to fraud , waste , abuse , and mismanagement .

seven of these areas are specific to the department , and seven other high - risk areas are shared with other federal agencies .

collectively , these high - risk areas relate to dod's major business operations that are inextricably linked to the department's ability to perform its overall mission and directly affect the readiness and capabilities of u.s. military forces and can affect the success of a mission .

in particular , the department's nonintegrated and duplicative systems impair its ability to combat fraud , waste , and abuse .

as such , dod's business systems modernization is one of the high - risk areas and is an essential enabler in addressing many of the department's other high - risk areas .

for example , modernized business systems are integral to the department's efforts to address its financial , supply chain , and information security management high - risk areas .

effective use of a well - defined enterprise architecture is a hallmark of successful organizations and a basic tenet of organizational transformation and systems modernization .

since the early 1990s , we have promoted federal department and agency enterprise architecture adoption as an essential means to achieving a desired end: having operational and technology environments that maximize institutional mission performance and outcomes .

congress , the office of management and budget ( omb ) , and the federal chief information officers ( cio ) council have also recognized the importance of an architecture - centric approach to modernization .

the clinger - cohen act of 1996 , among other things , requires the cios of federal departments and agencies to develop , maintain , and facilitate architectures as a means of integrating business processes and agency goals with it .

further , the e - government act of 2002 established the omb office of electronic government and assigned it , among other things , responsibility for overseeing the development of enterprise architectures within and across agencies .

in addition , omb , the cio council , and we have issued guidance that emphasizes the need for system investments to be consistent with these architectures .

for example , in april 2003 and in august 2010 , we published a framework that emphasizes the importance of having an enterprise architecture as a critical frame of reference for organizations when they are making it investment decisions .

also , in december 2008 , omb issued guidance that addresses system investment compliance with agency architectures .

a corporate approach to it investment management is another important characteristic of successful public and private organizations .

recognizing this , the clinger - cohen act requires omb to establish processes to analyze , track , and evaluate the risks and results of major capital investments in it systems made by executive agencies .

in response to the clinger - cohen act and other statutes , omb developed policy and issued guidance for planning , budgeting , acquisition , and management of federal capital assets .

we have also issued guidance in this area that defines institutional structures ( such as investment boards ) , processes for developing information on investments ( such as cost / benefit ) , and practices to inform management decisions ( such as whether a given investment is aligned with an enterprise architecture ) .

an enterprise architecture provides a clear and comprehensive picture of an entity , whether it is an organization ( eg , a federal department or agency ) or a functional or mission area that cuts across more than one organization ( eg , financial management ) .

an architecture describes the enterprise in logical terms ( such as interrelated business processes and business rules , information needs and flows , and work locations and users ) as well as in technical terms ( such as hardware , software , data , communications , security attributes , and performance standards ) .

it provides these perspectives both for the enterprise's current environment and for its target environment , and it provides a transition plan for moving from the current to the target environment .

this transition plan provides a temporal road map for moving between the two environments and incorporates considerations such as technology opportunities , marketplace trends , fiscal and budgetary constraints , institutional system development and acquisition capabilities , legacy and new system dependencies and life expectancies , and the projected value of competing investments .

the suite of products adopted for a given entity's enterprise architecture , including its structure and content , is largely governed by the framework used to develop the architecture .

since the 1980s , various architecture frameworks have been developed , such as john a. zachman's “a framework for information systems architecture,” and the dod architecture framework .

the importance of developing , implementing , and maintaining an enterprise architecture is a basic tenet of both organizational transformation and systems modernization .

managed properly , an enterprise architecture can clarify and help optimize the interdependencies and relationships among an organization's business operations and the underlying it infrastructure and applications that support these operations .

moreover , when an enterprise architecture is employed in concert with other important management controls , such as portfolio - based capital planning and investment control practices , the architecture can greatly increase the chances that an organization's operational and it environments will be configured to optimize mission performance .

the alternative , as our work has shown , is the perpetuation of the kinds of operational environments that burden many agencies today , where a lack of integration among business operations and the it resources supporting them leads to systems that are duplicative , poorly integrated , and unnecessarily costly to maintain and interface .

in february 2002 and april 2003 , we issued versions 1.0 and 1.1 of our enterprise architecture management maturity framework ; in august 2010 , we issued a major revision ( version 2.0 ) .

the framework provides a standard yet flexible benchmark against which to determine where the enterprise stands in its progress toward the ultimate goal: having a continuously improving enterprise architecture program that can serve as a featured decision support tool when considering and planning large - scale organizational restructuring or transformation initiatives .

in addition , it also provides a basis for developing architecture management improvement plans , as well as for measuring , reporting , and overseeing progress in implementing these plans .

several approaches to structuring enterprise architecture exist and can be applied to the extent that they are relevant and appropriate for a given enterprise .

in general , these approaches provide for decomposing an enterprise into its logical parts and architecting each of the parts in relation to enterprisewide needs and the inherent relationships and dependencies that exist among the parts .

as such , the approaches are fundamentally aligned and consistent with a number of basic enterprise architecture principles , such as incremental rather than monolithic architecture development and implementation , optimization of the whole rather than optimization of the component parts , and maximization of shared data and services across the component parts rather than duplication .

moreover , these approaches are not mutually exclusive and , in fact , can all be applied to some degree for a given enterprise , depending on the characteristics and circumstances of that enterprise .

the approaches , which are briefly described here , are federated , segmented , and service - oriented .

under a federated approach , the architecture consists of a family of coherent but distinct member architectures that conform to an overarching corporate or parent architecture .

this approach recognizes that each federation member has unique goals and needs as well as common roles and responsibilities with the members above and below it .

as such , member architectures ( eg , component , subordinate , or subsidiary architectures ) are substantially autonomous , but they also inherit certain rules , policies , procedures , and services from the parent architectures .

a federated architecture enables component organization autonomy while ensuring corporate or enterprisewide linkages and alignment where appropriate .

a segmented approach to enterprise architecture development and use , like a federated approach , employs a “divide and conquer” methodology in which architecture segments are identified , prioritized , developed , and implemented .

in general , segments can be viewed as logical aspects , or “slivers,” of the enterprise that can be architected and pursued as separate initiatives under the overall corporate architecture .

as such , the segments serve as a bridge between the corporate frame of reference captured in the enterprise architecture and individual programs within portfolios of system investments .

omb has issued guidance related to segment architectures .

as part of its guidance , agencies are to group segments into three categories: core mission areas ( eg , air transportation ) , business services ( eg , financial management ) , and enterprise services ( eg , records management ) .

a service - oriented approach to enterprise architecture is intended to identify and promote the shared use of common business capabilities across the enterprise .

under this approach , functions and applications are defined and designed as discrete and reusable capabilities or services that may be under the control of different organizational entities .

as such , the capabilities or services need to be , among other things , ( 1 ) self - contained , meaning that they do not depend on any other functions or applications to execute a discrete unit of work ; ( 2 ) published and exposed as self - describing business capabilities that can be accessed and used ; and ( 3 ) subscribed to via well - defined and standardized interfaces .

this approach is intended to reduce redundancy and increase integration , as well as provide the flexibility needed to support a quicker response to changing and evolving business requirements and emerging conditions .

it investment management is a process for linking investment decisions to an organization's strategic objectives and business plans that focuses on selecting , controlling , and evaluating investments in a manner that minimizes risks while maximizing the return of investment .

during the selection phase , the organization ( 1 ) identifies and analyzes each project's risks and returns before committing significant funds to any project and ( 2 ) selects those it projects that will best support its mission needs .

during the control phase , the organization ensures that , as projects develop and investment expenditures continue , the projects meet mission needs at the expected levels of cost and risk .

if the project is not meeting expectations , or if problems arise , steps are quickly taken to address the deficiencies .

during the evaluation phase , actual versus expected results are compared once a project has been fully implemented .

this is done to ( 1 ) assess the project's impact on mission performance , ( 2 ) identify any changes or modifications to the project that may be needed , and ( 3 ) revise the investment management process based on lessons learned .

consistent with this guidance , our it investment management ( itim ) framework consists of five progressive stages of maturity for any given agency relative to selecting , controlling , and evaluating its investment management capabilities .

 ( see fig .

2 for the five itim stages of maturity. ) .

the overriding purpose of the framework is to encourage investment selection and control and to evaluate processes that promote business value and mission performance , reduce risk , and increase accountability and transparency .

we have used the framework in many of our evaluations , and a number of agencies have adopted it .

in our itim framework , with the exception of the first stage , each maturity stage is composed of “critical processes” that must be implemented and institutionalized in order for the organization to achieve that stage .

each itim critical process consists of “key practices” ( organizational structures , policies , and procedures ) that must be executed to implement the critical process .

our research shows that agency efforts to improve investment management capabilities should focus on implementing all lower - stage practices before addressing the higher - stage practices .

stage 2 critical processes lay the foundation by establishing successful , predictable , and repeatable investment control processes at the project level .

stage 3 is where the agency moves from project - centric processes to portfolio - based processes and evaluates potential investments according to how well they support the agency's missions , strategies , and goals .

organizations implementing these stage 2 and 3 practices have in place selection , control , and evaluation processes that are consistent with the clinger - cohen act .

stages 4 and 5 require the use of evaluation techniques to continuously improve both investment processes and portfolios in order to better achieve strategic outcomes .

our research shows that agency efforts to improve investment management capabilities should focus on implementing all lower - stage practices before addressing the higher - stage practices and therefore our reviews tend to focus on stage 2 and stage 3 critical processes .

specifically , within stage 2 , there are five critical processes and nine associated key practices ( known as organizational commitments ) that call for policies and procedures associated with effective project - level management .

these are shown in table 1 .

within stage 3 , there are four critical processes and five associated key practices ( known as organizational commitments ) that call for policies and procedures associated with effective portfolio - based investment management .

these are shown in table 2 .

the ndaa for fiscal year 2008 designated the deputy secretary of defense position as the chief management officer for dod and created a deputy position to assist the chief management officer .

the chief management officer's responsibilities include developing and maintaining a departmentwide strategic plan for business reform and establishing performance goals and measures for improving and evaluating overall economy , efficiency , and effectiveness , and monitoring and measuring the progress of the department .

the deputy chief management officer's responsibilities include recommending to the chief management officer methodologies and measurement criteria to better synchronize , integrate , and coordinate the business operations to ensure alignment in support of the warfighting mission .

the business transformation agency supports the deputy chief management officer in leading and coordinating business transformation efforts across the department .

this includes maintaining and updating the department's enterprise architecture for its business mission area .

the chief management officer and deputy chief management officer are to interact with several entities to guide the direction , oversight , and execution of dod's business transformation efforts , which include business systems modernization .

these entities include the defense business systems management committee , which serves as the highest - ranking investment review and decisionmaking body for business systems modernization activities and is chaired by the deputy secretary of defense ; the principal staff assistants , who serve as the certification authorities for business system modernizations in their respective core business missions ; the investment review boards ( irb ) , which are chaired by the certifying authorities and form the review and decision - making bodies for business system investments in their respective areas of responsibility ; and the business transformation agency , which is responsible for supporting the irbs and for leading and coordinating business transformation efforts across the department .

in august 2010 and in january 2011 , the secretary of defense announced the plans to disestablish the business transformation agency and the office of the assistant secretary of defense for networks and information integration / department of defense cio ( asd ( nii ) / dod cio ) ( who is a member of the defense business systems management committee ) , respectively .

according to dod officials , the mission of the office of the deputy chief management officer duplicates many of the business transformation agency functions .

they added that rather than lead in the development of better business practices , the agency's prime focus has changed to the management of several relatively small business systems and providing direct support to the deputy chief management officer on various policy issues .

as a result , according to these officials , the narrower function does not justify continuing the business transformation agency as a stand - alone defense agency .

the secretary of defense also directed that the remaining functions of the business transformation agency be reviewed and transferred to other organizations in dod , as appropriate and that the disestablishment of the agency should be no later than june 30 , 2011 .

however , as of june 2011 , these implementation decisions had yet to be made and both the business transformation agency and the office of the asd ( nii ) / dod cio organizations were still in operation .

table 3 lists governance entities and provides greater detail on their roles , responsibilities , and composition .

since 2005 , dod has employed a “tiered accountability” approach to business systems modernization .

under this approach , responsibility and accountability for business architectures and systems investment management are assigned to different levels in the organization .

for example , the business transformation agency is responsible for developing the corporate business enterprise architecture ( i.e. , the thin layer of dod - wide policies , capabilities , standards , and rules ) and the associated enterprise transition plan .

each component is responsible for defining a component - level architecture and transition plan associated with its own tiers of responsibility and for doing so in a manner that is aligned with ( i.e. , does not violate ) the corporate business enterprise architecture .

similarly , program managers are responsible for developing program - level architectures and plans and for ensuring alignment with the architectures and transition plans above them .

this concept is to allow for autonomy while also ensuring linkages and alignment from the program level through the component level to the corporate level .

table 4 describes the four investment tiers and identifies the associated reviewing and approving entities .

consistent with the tiered accountability approach , the fiscal year 2008 ndaa required the secretaries of the military departments to designate the department under secretaries as chief management officers with primary responsibility for business operations .

moreover , the fiscal year 2009 duncan hunter ndaa required the military departments to establish business transformation offices to assist their chief management officers in the development of comprehensive business transformation plans .

in response , all of the military departments have designated their respective under secretaries as the chief management officers .

we reported in january 2011 that dod and the military departments had made limited progress in developing business transformation plans that are supported by a strategic planning process and would enable them to align goals and planning efforts and to measure progress .

specifically , we reported that dod had not set up internal mechanisms , such as procedures and milestones , by which it can reach consensus with the military departments and others on priorities , synchronize the development of plans with each other and the budget process , and guide efforts to monitor progress and take corrective action .

therefore , while the military departments were in varying stages of developing business transformation plans , it was unclear to what extent the business transformation priorities for the military departments will be aligned with the priorities identified in dod's strategic management plan or how these business transformation priorities will influence the department's budget requests .

accordingly , we made recommendations to enhance dod's ability to set strategic direction for its business transformation efforts , and better align and institutionalize its efforts to develop and implement plans and measure progress against established goals .

dod partially agreed with the recommendations .

dod has a two - stage process to select investments , which it refers to as certification and is a key step in its it investment process that dod has aimed to model after gao's itim framework .

the first stage involves selection of systems using the joint capabilities integration and development system , the defense acquisition system , and the planning , programming , budgeting , and execution management systems .

at this level , proposals and alternatives are viewed and prioritized for system selection .

the second stage of selection involves ( 1 ) certifying and approving tiers 1 through 3 investments and ( 2 ) elevating certain component investments to an enterprisewide status .

more recently , dod developed business capability lifecycle guidance , dated november 2010 , intended to streamline business system acquisition , and investment management processes to better guide and constrain departmentwide systems modernizations .

for certification , the irbs rely on documentation submitted by appropriate chief management officers for the military departments and precertification authorities for the defense agencies .

this documentation includes but is not limited to , a memorandum asserting that an investment is compliant with the business enterprise architecture ; an economic viability analysis , which addresses the investment's cost and benefits or cost effectiveness ; a business process reengineering determination , which identifies the investment's business process weaknesses , gaps , and opportunities for process improvement ; and a certification dashboard , which includes cost and schedule status information .

dod guidance also gives the boards broad authority in their certification reviews and actions , thus allowing each board to review and consider whatever investment - related information that it deems appropriate .

moreover , business transformation agency and irb officials told us that a board is not limited in the conditions it can place on a program .

after an irb review , the defense business systems management committee will be notified of all certification decisions and may elect to approve or disapprove a certification .

if a certification is approved , the committee will sign an approval memo that warrants the ability to obligate the related funding for the investment .

under dod's approach , there are four types of certification actions: certify: an irb certifies the modernization as fully meeting criteria defined in the act and irb investment review guidance , such as compliance with the business enterprise architecture and the extent to which the investment is consistent with component and department it investment portfolios , which are asserted by the component chief management officer .

certify with conditions: an irb certifies the modernization with the understanding that it will address specific investment review board - imposed conditions .

for example , the army's general fund enterprise business system was certified with a condition to develop a plan for complying with the data standards of dod's item unique identifier registry .

recertify: an irb certifies the obligation of additional modernization funds for a previously - certified modernization investment .

for example , the air force's defense enterprise accounting and management system was recertified in september 2010 for $26.7 million to be spent across fiscal years 2010 and 2011 .

this recertification was in addition to the approximately $22.7 million previously certified in december 2009 .

in addition , a program must request irb recertification if the program plans to redistribute previously approved modernization funds among multiple fiscal years and this redistribution will result in the funding for any given fiscal year exceeding the previously approved amount by 10 percent or more .

decertify: an irb may decertify or reduce the amount of modernization funds available to an investment when ( 1 ) a component reduces funding for a modernization by more than 10 percent of the originally certified amount , ( 2 ) the period of certification for a modernization is shortened , or ( 3 ) the entire amount of funding is not to be obligated as previously certified .

for example , the special operations command's special operations resource business information system had about $4.59 million decertified because funding was reduced by more than 10 percent of the originally certified amount .

an investment review board may also decertify a modernization after development has been terminated .

for example , dod reported that approximately $2.77 million in research , development , test and evaluation funding for the army's wounded warrior accountability system was decertified because it was determined that the system provided a capability that could be better utilized under another system .

congress included provisions in the fiscal year 2005 ndaa that are aimed at ensuring dod's development of a well - defined business enterprise architecture and associated enterprise transition plan , as well as the establishment and implementation of effective investment management structures and processes .

according to the act , dod is required to develop a business enterprise architecture and an enterprise transition plan for implementing the architecture , identify each business system proposed for funding in dod's fiscal year budget submissions , delegate the responsibility for business systems to designated approval authorities within the office of the secretary of defense , require each approval authority to establish investment review structures and processes , and effective october 1 , 2005 , not obligate appropriated funds for a defense business system modernization with a total cost of more than $1 million unless the approval authority certifies that the business system modernization meets several conditions .

the fiscal year 2005 ndaa also requires that the secretary of defense annually submit to the congressional defense committees a report on the department's compliance with the above provisions .

between 2005 and 2008 , we reported that dod had taken steps to comply with key requirements of the fiscal year 2005 ndaa relative to architecture development , transition plan development , budgetary disclosure , and investment review , and to satisfy relevant systems modernization management guidance ; however , each report also concluded that much remained to be accomplished relative to the act's requirements and relevant guidance .

we also reported that dod had fully satisfied the requirement concerning designated approval authorities and continued to certify and approve modernizations costing more than $1 million .

we concluded that the department had made progress in defining and beginning to implement institutional management controls ( i.e. , processes , structures , and tools ) .

we reiterated existing recommendations to address each of the areas .

in may 2008 , we reported that progress in establishing corporate management controls needed to be replicated within the military departments .

for example , we reported that the military departments did not yet have mature enterprise architecture programs .

we also reported that they had yet to fully establish key investment review structures and had yet to define related policies and procedures for effectively performing both project - level and portfolio - based investment management .

because we had previously made recommendations to dod aimed at putting in place the management controls needed to fully comply with the act and related federal guidance , we did not make additional recommendations .

in may 2009 , we reported that the pace of dod's efforts in defining and implementing key institutional modernization management controls had slowed compared with progress made in each of the last four years , leaving much to be accomplished to fully implement the act's requirements and related guidance .

for example: the corporate business enterprise architecture had yet to be extended ( i.e. , federated ) to the entire family of business mission area architectures , including using an independent verification and validation ( iv&v ) agent to assess the components' subsidiary architectures and federation efforts .

the fiscal year 2009 budget submission included some , but omitted other key information about business system investments , in part because of the lack of a reliable , comprehensive inventory of all defense business systems .

the business system information used to support the development of the transition plan and dod's budget requests , as well as certification and annual reviews , was of questionable reliability .

dod and the military departments had yet to fully define key practices ( i.e. , policies and procedures ) related to effectively performing both project - level ( stage 2 ) and portfolio - based ( stage 3 ) investment management as called for in the itim .

for example , of the nine stage 2 key practices and five stage 3 key practices , dod had defined four and one , respectively , while air force had defined three and one , respectively .

subsequent to our reports , army reported that it had ( as of may 2009 ) efforts planned and under way to develop effective investment management processes , but the efforts did not fully satisfy any key practices at the time .

business system investments costing more than $1 million continue to be certified and approved , but these decisions were not always based on complete information .

accordingly , we reiterated existing recommendations to address each of these areas and further recommended that dod , among other things , improve the quality of investment - related information .

dod partially agreed with our recommendations and described actions being planned or under way to address them .

dod is currently in the process of addressing these recommendations .

in may 2010 , we reported that the scope and completeness of key information provided in the report were limited .

specifically , the report omitted information on the number of business system investment certification actions taken during fiscal year 2009 and did not include performance measures , such as measures of progress against program cost , capability , and benefit commitments .

further , we concluded that certification and approval decisions may not be sufficiently justified because investments were certified and approved without conditions even though our prior reports had identified program weaknesses that were unresolved at the time of certification and approval .

accordingly , we recommended that dod ensure that the scope and content of future annual reports to congress on compliance with section 332 of the ndaa for fiscal year 2005 be expanded to include cost , capability , and benefits performance measures for each business system modernization investment and actual performance against these measures as well as all certification actions on its business system modernization investments that were taken in the previous year by the department .

in addition , we recommended that dod guidance be revised to include provisions that require investment review board certification submissions to disclose program weaknesses raised by us and the status of actions to address our recommendations to correct the weaknesses to ensure that investment review board certification actions are better informed and justified .

dod agreed with our recommendations .

dod continues to take steps to comply with the provisions of the fiscal year 2005 ndaa and to satisfy relevant system modernization management guidance .

in particular , dod released its fiscal year 2011 enterprise transition plan in december 2010 , followed by an update to its business enterprise architecture ( version 8.0 ) in march 2011 , and its annual report to congress in may 2011 describing steps that have been taken and are planned relative to the act's requirements .

collectively , these steps address several statutory provisions and best practices concerning the business enterprise architecture , transition plan , budgetary disclosure , and investment review of systems costing in excess of $1 million .

however , challenges that we identified in prior years still need to be addressed in order for the department to be in full compliance with guidance and ndaa requirements .

most notably , the department has yet to extend and evolve its business enterprise architecture to the military departments' architectures and to fully define it investment management policies and procedures at the dod enterprise and component levels .

dod officials agreed that additional steps are needed .

they said that the lack of progress is due in part to the uncertainty and pending decisions surrounding the roles and responsibilities of key organizations and senior leadership positions , such as the business transformation agency and asd ( nii ) / dod cio .

however , until dod fully implements these long - standing institutional modernization management controls required by the act , addressed in gao recommendations , and otherwise embodied in relevant guidance , its business systems modernization will likely remain a high - risk program .

as a result , it is important that the department act quickly to resolve pending decisions about roles and responsibilities .

among other things , the act requires dod to develop a business enterprise architecture to cover all defense business systems and their related functions and activities .

according to the act , the architecture should extend to all defense organizational components .

in 2006 , the department adopted an incremental and federated approach to developing such an architecture .

under this approach , the department releases new architecture versions every year that include a corporate business enterprise architecture that is to be augmented by a coherent family of component architectures .

as we have previously reported , such an approach is consistent with best practices and appropriate given dod's scope and size .

on march 18 , 2011 , dod released its business enterprise architecture version 8.0 , which focuses on improving the department's ability to manage business operations from an end - to - end perspective .

this version continues to represent the thin layer of corporate architectural policies , capabilities , rules , and standards that apply dod - wide ( i.e. , to all dod federation members ) .

this means that version 8.0 appropriately focuses on addressing a limited set of enterprise - level ( dod - wide ) priorities and provides the overarching and common architectural context that the distinct and autonomous member ( i.e. , component ) architectures inherit .

nevertheless , this also means that version 8.0 does not provide the total federated family of dod parent and subsidiary architectures for the business mission area .

having such an architecture is dependent on each military department ( air force , army , and navy ) having the capability to manage its enterprise architecture and develop the necessary content .

to assist dod in its architecture federation efforts , we have previously made a number of recommendations .

specifically , in may 2007 , we recommended that the department include in its annual report , required under the act , the results of its iv&v contractor's assessment of the completeness , consistency , understandability , and usability of the federated family of architectures .

while dod agreed with the recommendation , none of its annual reports since 2007 , including its latest annual report ( issued in may 2011 ) , have included this information .

according to business transformation agency officials , iv&v activities have focused on the corporate business enterprise architecture and not on the entire federated family of architectures .

business transformation agency officials provided us with a report dated march 25 , 2011 , which summarizes selected iv&v contractor observations and recommendations relative to version 8.0's ability to provide a foundation for business enterprise architecture federation .

overall , the summary confirms our findings by stating that , while there has been previous work to develop a business enterprise architecture federation plan , the execution of the federation has yet to be completed .

according to business transformation agency officials , the current requirement under the iv&v contract is to provide analysis of the business enterprise architecture .

there are no plans for reviewing the military departments' enterprise architectures .

the challenges that the department faces in federating its architecture and the importance of disclosing to congressional defense committees the state of its federation efforts are amplified by our prior report on the state of the military departments' enterprise architecture programs .

specifically , we reported in may 2008 that none of the three military departments could demonstrate through verifiable documentation that it had established all of the core foundational commitments and capabilities needed to effectively manage the development , maintenance , and implementation of an architecture , as outlined in our enterprise architecture management maturity framework version 1.1 .

since then , each of the military departments has adopted a federated approach to developing its respective architecture program .

however , the extent to which each of their architecture programs has improved since 2008 varies .

for example , while all three have or are in the process of establishing an executive committee with responsibility and accountability for the department's enterprise architecture , none have fully developed an enterprise architecture methodology or have a well - defined business enterprise architecture and transition plan to guide and constrain business transformation initiatives .

table 5 provides a description of the military departments' progress relative to those elements that we previously reported as not satisfied by one or more of the military departments .

 ( these elements were common to both versions 1.1 and 2.0 of our enterprise architecture maturity management framework. ) .

as described in the table , the military departments have made progress in managing their respective enterprise architecture programs since we last reported in 2008 .

however , each has yet to address key elements , including developing the architecture content , in order to advance to a level that can be considered fully mature .

according to dod officials , the lack of progress in addressing key management elements has been due to the uncertainty and pending decisions surrounding the roles and responsibilities of key organizations and senior leadership positions .

air force officials attributed the state of its enterprise architecture program in part to the lack of resources .

army officials also stated that a major challenge has been the lack of resources ( i.e. , people and funding ) due to the shift of resources to higher priority initiatives .

navy officials stated that there is not one overarching reason for the state of the navy enterprise architecture program but rather a number of reasons , such as limited resources .

navy officials agreed that work remains to be done and stated that they will continue to address the missing elements as they move forward .

although all the military departments reported resources to be a challenge , as noted earlier , dod requested about $17.3 billion for its business systems environment .

given the department's prioritization of about $17 billion , the military department architecture programs have not received resources that they deemed sufficient to meet their needs .

what this means is that dod , as a whole , is not as well positioned as it should be to realize the significant benefits that a well - managed federation of architectures could afford its business systems modernization efforts .

we have ongoing work looking at the status of each of the military departments' enterprise architecture programs relative to all the applicable elements in our enterprise architecture management maturity framework version 2.0 .

the fiscal year 2009 ndaa requires that each military department develop a well - defined enterprisewide business architecture and transition plan encompassing end - to - end business processes and that is capable of providing accurate and timely information in support of business decisions of the military department .

however , while each of the departments has taken steps to develop architecture content , none has a well - defined business enterprise architecture and associated transition plan to guide and constrain its business transformation initiatives .

individual examples of progress made and challenges still facing each department are discussed next .

department of the air force the department of the air force is developing a corporate enterprise architecture and 12 subordinate “sub - enterprise” architectures , each of which is to be supported by subordinate domain architectures ( i.e. , acquisition ) , as appropriate .

according to air force officials , work is still under way to identify the respective domains and determining which domains will support each sub - enterprise .

according to these officials , the air force business enterprise architecture was until now being developed as a separate initiative but work is under way to integrate it with the agile combat support sub - enterprise architecture .

in 2008 , we reported that , as part of its agile combat support sub - enterprise architecture , the department had developed enterprise architecture products that described some , but not all , elements of its current and target environments as well as a transition plan for its business area .

specifically , we reported that the air force had not defined the architecture products that described its logistics enterprise architecture for its current environment and its acquisition enterprise architecture and health services enterprise architectures for its target environments .

we also reported that , while it had developed a sequencing plan of systems , it had not defined a gap analysis describing how the department would transition from the current to the target environment .

since then , the department has developed architectural artifacts that capture some of the missing business - related elements .

for example , the air force has identified acquisition transformation goals , health services operational activities , and logistics systems and services , such as the commodity management service .

in addition , the department has identified and described business transformation initiatives ( eg , streamline civilian hiring process to meet dod's goal of 80 days by 2012 ) .

however , not all important business enterprise architecture contents have been described , including current functional capabilities and data objects necessary for current business operations .

furthermore , although the department has identified some business - related elements , it does not have a well - defined business enterprise architecture and a transition plan to guide and constrain business transformation initiatives .

in particular , it has yet to develop architectural products under its air force business enterprise architecture that would describe its current and target business environments in terms of business , information / data , application / service , technology , performance , and security .

according to the air force , it is focused instead on capturing and using existing architecture artifacts that describe current and target architectures associated with priority areas for improvement .

in addition , although the air force has outlined the business improvement priorities , it has yet to develop an enterprise transition plan for the business environment , including descriptions of gaps in terms of functional capabilities , performance shortfalls of business processes , and potential duplications of system functions .

the department also has yet to determine what , if any , of the business architectural artifacts under the agile combat support sub - enterprise is to be leveraged for the development of the air force business enterprise architecture .

according to air force officials , the air force business enterprise architecture and the agile combat support sub - enterprise will use one common set of artifacts , and the department has identified the business architectural artifacts from the agile combat support sub - enterprise to be merged with the air force business enterprise architecture .

however , we have yet to be provided with a listing of these artifacts .

in addition , according to these officials , discussion is still under way on how the department plans to federate the sub - enterprise architectures , including the agile combat support , to the corporate enterprise architecture .

according to air force officials , in the future , the air force business enterprise architecture will focus on end - to - end processes with defined outputs and it will include an alignment of business systems to these end - to - end business processes .

also , according to the air force , it plans to use an architecture - based approach to align current air force capabilities and systems against specific business processes to identify duplication or gaps in process - based capabilities .

according to the department , an implementation plan will be developed by the end of fiscal year 2011 .

without architectural descriptions of current and target business environments and an associated transition plan , as well as a clear picture of how to leverage prior content in development of the air force business enterprise architecture , the department is not well positioned to realize the significant benefits that a well - defined enterprisewide business architecture and transition plan can provide , including objective decision making regarding capability enhancements across end - to - end business processes and resources allocation across business system investments .

the department of the army has yet to develop or establish plans for developing a corporate enterprise architecture that identifies and describes rules , policies , procedures , and services to be federated across the army .

instead , the department's approach consists of developing three separate and distinct segment architectures ( i.e. , battle command , networks , and generating force ) , each of which is being developed by separate department organizational units and is supported by individual segment and solution architectures .

according to department officials , the department's current approach to developing its business enterprise architecture calls for this content to be developed as part of the generating force enterprise architecture effort .

in 2008 , we reported that army had not defined its current and target business environments and developed a transition plan .

to its credit , the department has since made progress in developing its first version of the army's business enterprise architecture .

specifically , it has defined the scope of this architecture , which comprises traditional business functions such as acquisition , logistics , financial management , human capital management , and installation and environment .

the scope of the army's business enterprise architecture is also extended to include training and sub - segments of the landwarnet / battle command functions .

this provides logical groupings of the key business activities the department performs , and can be used to identify subbordinate architectures that support the department's generating force mission area .

in addition , the architecture includes the 15 end - to - end business processes listed in the dod business enterprise architecture and army plans to use these processes to guide and constrain business process modeling efforts and identify business systems that are to be integrated .

this is consistent with dod's approach of using end - to - end business processes to optimize business processes and the systems that support them .

further , the department has outlined its business transformation initiatives ( eg , civilian hiring reform ) to accelerate business process improvement and cost savings .

however , army does not have a well - defined business enterprise architecture and a transition plan to guide and constrain business transformation initiatives .

in particular , although the first version provides systems mappings to several end - to - end business processes ( eg , procure - to - pay ) , it has yet to provide evidence of mappings of system functions to all the end - to - end business processes , such as service request - to - resolution .

according to officials , the mapping of system functions to process steps will take place when the department performs detailed business process mapping .

further , the first version does not describe how end - to - end business processes will be implemented , including principles and guidance for implementing technologies that would support planned business systems investments .

without this , there is an increased risk of incompatible implementation and / or not being able to leverage the most benefits from the technologies .

the army has also made progress in developing aspects of a business transition plan .

for example , it identifies business transformation initiatives , such as civilian hiring reform , and describes results or changes to business operations to be achieved by the business transformation initiatives .

it also includes diagrams that depict the migration from legacy business systems to commercial off - the - shelf enterprise resource planning solutions .

such diagrams provide a life cycle view of enterprise systems resources , including describing how each system evolves over time .

however , the plan still does not include important content such as gap analyses at the enterprise level and for each business function ( e.g .

acquisition , financial management ) and timelines for addressing the gaps .

a gap analysis is an assessment of the differences between the current and target architectures .

for example , a performance gap analysis identifies performance measures ( eg , effectiveness ) of a business process , highlights which performance measures are not being met in the current environment , and describes performance expectations for these measures in the target environment , thereby describing expected performance improvements of the business process .

this performance gap analysis should also identify the business process activities or steps that need to be changed to achieve the future performance expectations .

as such , these gap analyses are important to help identify changes or adjustments that are necessary at the enterprise level and within each business function to achieve desired business performance results and mission outcomes .

the department of the navy's enterprise architecture is comprised of corporate architecture products , which include applicable laws , regulations , and policies as well as enterprisewide reference models and architecture content and subordinate architectures , which comprise nine segment architectures , with each addressing a distinct functional area such as logistics and command and control .

these subordinate architectures are to be developed by communities of practice groups that have yet to be formally established .

according to navy officials , the current approach calls for the navy business enterprise architecture content to be incorporated into the corporate enterprise architecture and applicable segment architectures ( eg , corporate management and support , force support , and logistics segment architectures ) , as appropriate .

in 2008 , our analysis showed that navy had developed enterprise architecture products that describe some , but not all , elements of its current and target environments as well as a transition plan for its business area .

specifically , we found that the navy had not defined its current core business processes or provided a comprehensive picture of its current business problems that the department needs to address .

we also found that it had yet to develop a well - defined target architecture , including the purpose and scope of all the functional areas ( eg , joint logistics and planning ) .

in addition , we also found that , while the department had developed a transition plan as part of its architecture , the plan was not based on a gap analysis between the current and target environments .

this is important to lay out a road map for optimizing mission performance and transforming business operations by systematically implementing changes to technologies and processes .

since 2008 , navy has identified its business segments such as logistics and force support , representing some of its core business processes .

in addition , according to navy officials , it plans to establish communities of practice to oversee the development of segment reference architectures and a road map for developing these architectures .

it has also added additional business - related architecture content .

for example , the architecture includes the navy's common operational activity list that specifies some business activities related to identifying and resolving accounting records discrepancies .

such operational activities provide a basis from which the department identifies the business activities or functions to be reused ( and optimized ) across the department and those activities or functions that remain unique to each business segment or domain .

nonetheless , navy does not have a well - defined enterprisewide business architecture and transition plan to guide and constrain business transformation initiatives .

in particular , the department has not developed a business enterprise architecture that provides a clear and comprehensive picture of its current and target business environments .

for example , the enterprise architecture does not describe current and target business capabilities , systems that are to be integrated to support dod end - to - end business processes , and information exchange requirements among business activities .

according to navy officials , rather than capturing the department's current and target business environments , the focus of navy's enterprise architecture is to develop artifacts that are “actionable” such as enterprise rules for assessing compliance of business systems .

while such actionable artifacts provide value , they do not provide a comprehensive and systematic approach for transforming business operations .

further , there is no evidence that the department has documented current problems or defined the scope and purpose for all of the business - related segment reference architectures .

documenting current problems will enable the navy to identify opportunities ( eg , new applications , new processes , or new management approaches ) for improvement and to assess whether transformation efforts address these problems .

moreover , although navy has developed an enterprise transition plan , the plan is not well - defined and does not include an enterprise gap analysis that identifies the differences between the current and target business architectures , particularly the critical differences or shortfalls that affect the successful accomplishment of the department's mission .

according to officials , gaps and shortfalls in the current department programs can be identified through enterprise architecture compliance assessments , and enterprise architecture waivers are granted with specific expiration dates and conditions that are to be met to address the gaps and shortfalls .

nevertheless , the focus of these compliance assessments is on gaps and shortfalls of individual programs ( eg , limited system availability ) and not on gaps and shortfalls from the perspective of end - to - end business processes ( eg , process gaps ) that are needed to achieve the target environment .

moreover , a well - defined business enterprise architecture and transition plan is essential for establishing an implementation road map to address key gaps and shortfalls that can significantly impact business operations across the department and for evolving and developing business systems that optimize their mission value .

among other things , the fiscal year 2005 ndaa requires dod's annual it budget submission to include key information on each business system for which funding is being requested , such as the system's designated approval authority and the appropriation type and amount of funds associated with modernization ( i.e. , development ) and current services ( i.e. , operations and maintenance ) .

the department's fiscal year 2012 budget submission includes a range of information for 1,637 business system investments .

of these , 272 involve development and modernization .

for each of the 272 , the information provided includes the system's name , approval authority , and appropriation type .

the submission also identifies the amount of the fiscal year 2012 request that is for development and modernization versus operations and maintenance .

for systems in excess of $1 million in modernization funding , the submission also cites its certification status ( eg , approved , approved with conditions , approved decertification close - out , and withdrawn ) and the defense business systems management committee approval date , where applicable .

however , similar to prior budget submissions , the fiscal year 2012 budget submission still does not reflect all business system investments .

to prepare the submission , dod relied on business system investment information ( eg , funds requested , mission area , and system description ) that is entered by the components into dod's select and native programming data input system — information technology ( snap - it ) .

in accordance with dod guidance and according to asd ( nii ) / dod cio officials , the business systems listed in snap - it should match the systems listed in the defense information technology portfolio repository ( ditpr ) — the department's authoritative business systems inventory .

however , the ditpr data provided by dod in march 2011 included 2,258 business systems .

therefore , snap - it does not reflect about 620 business systems that are identified in ditpr .

we previously reported that the information between snap - it and ditpr were not consistent and accordingly made a recommendation for dod to develop and implement plans for reconciling and validating the completeness and reliability of information in its ditpr and snap - it system data repositories , and to include information on the status of these efforts in the department's fiscal year 2010 report in response to the act .

dod agreed with the need to reconcile information between the two repositories and stated that it had begun to take actions to address this .

however , according to the office of the asd ( nii ) / dod cio , efforts to provide automated snap - it and ditpr integration work were delayed due to increased snap - it requirements in supporting the fiscal year 2012 budget submission and ongoing reorganization efforts within dod .

the department plans to restart the process of integrating the two systems beginning in the third quarter of fiscal year 2011 .

until dod has a reliable , comprehensive inventory of all defense business systems , it will not be able to ensure the completeness and reliability of the department's it budget submissions .

moreover , the lack of current and accurate information increases the risk of oversight decisions that are not prudent and justified .

since our 2009 report , dod has continued to establish investment management processes but has not fully defined all key practices .

further , with regard to certifying and overseeing investments — two key dod it management processes for selecting , managing , and monitoring investments — the department largely followed these processes for four department investments we reviewed , but key steps integral to these processes were not performed .

until dod fully defines these key practices and performs integral key steps , it is unlikely that the department's reported 2,258 business system investments — totaling $17.4 billion in fiscal year 2011 — will be managed in an effective manner that maximizes mission performance while minimizing or eliminating system overlap and duplication .

since we reported in 2009 , dod has continued to make progress in establishing the kind of investment management processes and associated key practices ( i.e. , policies and procedures ) called for in the act and our itim framework as being integral to effective it investment management .

specifically , since 2009 , air force , navy , and army have implemented additional key practices associated with effectively managing investments as individual business system programs ( stage 2 ) and as portfolios of programs ( stage 3 ) , while the dod - level organizations ( herein referred to as dod enterprise ) responsible for dod - level processes have not .

with regard to stage 2 practices , navy and army implemented two key practices , and air force implemented one such practice .

for stage 3 , navy implemented one key practice .

for those key practices that have yet to be fully defined , dod enterprise and the military departments have in large part partially defined these practices .

nonetheless , even with this progress , dod enterprise and the military departments have yet to fully define a majority of the stage 2 and stage 3 practices .

table 6 provides a summary ( by dod enterprise and each military department ) of the key stage 2 practices implemented since 2009 along with those practices we reported in 2009 as having been implemented .

the table also includes those practices yet to be implemented .

as such , table 6 provides an overall snapshot of where dod enterprise and the military departments stand with regard to building their investment management foundation , including the ability to manage investments as individual business system programs .

as shown in the table , since 2009: dod enterprise has not implemented any additional key practices .

air force has implemented one key practice — documenting policies for meeting business needs .

specifically , in its it investment review guide , air force defines a process for ensuring that it business system investments support the department's ongoing and future business needs .

this process includes having an irb — consisting of senior executives from it and functional business units , including the office of the air force cio — to regularly review all business systems , including those in operations and maintenance , to assess their alignment with business needs using factors such as how well investments support the air force's mission and their strategic value and risk .

navy has implemented two additional key practices — ( 1 ) instituting an enterprisewide it investment board and ( 2 ) documenting policies for meeting business needs .

specifically , in march 2011 , navy established an information enterprise governance board — consisting of senior executives from it and functional business units , including the navy cio — to serve as a business systems irb .

among other things , the board is responsible for business system investment governance , including approving and annually reviewing business system investments .

in addition , for meeting business needs , navy's investment review guide dated october 2009 defines a process for conducting annual reviews of ongoing it investments to ensure they support ongoing and future business needs .

the process calls for the annual review of all business systems , including those in operations and maintenance , to demonstrate that they support ongoing and future business needs by , among other things , complying with applicable strategic business guidance such as dod's business enterprise architecture ( bea ) .

army has implemented two key practices associated with capturing investment information .

first , it has established policies and procedures for collecting information about the department's investments .

specifically , army's investment review guide dated march 2010 defines procedures directing army's system owners to submit , update , and maintain it projects and system information in a departmental data repository called the army portfolio management solution .

second , army has assigned responsibility for investment information collection and accuracy .

specifically , army's investment review guide states that system owners are responsible for the accuracy of their data in the repository .

with regard to stage 3 key practices , the following table provides a summary ( by dod enterprise and each military department ) of the key practices implemented since 2009 and those practices that have yet to be implemented .

table 7 provides an overall snapshot of where dod enterprise and the military departments stand in having the capability to build a complete investment portfolio .

as shown in the table , although dod enterprise , air force , and army have not implemented additional key practices , navy has implemented one key practice associated with defining portfolio criteria — assigning responsibility to an individual or group to manage the development and modification of it portfolio selection criteria .

specifically , navy developed guidance that assigns mission area leads and functional area managers with responsibility for portfolio selection criteria .

with regard to the stage 2 and stage 3 key practices that have yet to be fully implemented , it is important to note that dod and the military departments have partially defined these practices .

for example , for selection , dod established a process that calls for investments involving more than $1 million in obligations to be certified and approved before funds are to be expended .

specifically , the process calls for investments to be , among other things , compliant with dod's bea and be economically justified .

however , the process does not fully address all aspects of the selection key practice .

for example , the process does not specify how the irbs are to use the full range of cost , schedule , and benefit data in making selection ( i.e. , certification ) decisions , as called for in our itim framework .

in addition , for oversight , dod has established an oversight process that calls for , among other things , investments to be reviewed annually to assess how each is performing .

as part of the process , the irbs assess program performance relative to cost , schedule , and capability commitments .

however , dod's oversight process does not provide sufficient visibility into the military department's investment management activities , including its reviews of systems in operations and maintenance and smaller investments , commonly referred to as tier 4 investments .

nonetheless , dod enterprise and the military departments have still not fully defined these stage 2 and 3 key practices .

specifically , with regard to the nine stage 2 practices , dod enterprise , air force , and navy , as shown in table 6 , have yet to fully define five key practices ( or 56 percent of the practices ) , and army has yet to do so for seven ( or 78 percent ) of the practices .

with regard to the five stage 3 practices , dod enterprise , air force , and navy , as shown in table 7 , have yet to fully define four key practices ( or 80 percent of the practices ) , and army has yet to do so for any ( 100 percent ) of the practices .

officials from dod enterprise and the military departments attributed the incomplete state of their it investment management processes to the following: dod enterprise officials said the condition of its processes , including the lack of progress since 2009 , was due in part to current ongoing dod efforts to reorganize the business systems governance organizations ( eg , the business transformation agency ) that are responsible for implementing it investment management at the dod enterprise level .

as noted earlier , in august 2010 , the secretary of defense announced the plans to disestablish the business transformation agency and that the functions of the business transformation agency , such as its it investment management function , be reviewed and transferred to other organizations in dod , as appropriate .

the dod officials stated that these implementation plans have yet to be finalized and have resulted in their investment management implementation efforts being delayed .

these officials added that they are aware of the absence of documented project - level and portfolio - level management practices ; they also said they are currently working on developing policies and procedures to address the missing processes and practices but were not able to provide us with milestones and a plan with defined steps for when the policies and procedures were to be completed .

air force and navy officials said their investment management implementation efforts were taking longer than originally planned given their workload and other priorities assigned to them since initiating investment management efforts .

they also acknowledged that their processes were missing certain documented project - level and portfolio - level management policies and procedures and said they were in the process of developing policies and procedures to address these missing processes and practices .

in particular , air force officials stated that they planned to have their policies and procedures approved and finalized by october 2011 .

army officials said the state of their it investment management process is due to the fact that the department focused on first establishing selected institutional capabilities — such as defining roles and responsibilities and establishing a department - level irb — rather than attempting to do everything at once .

the officials added that once its initial steps are completed , army intends to then focus on implementing remaining stage 2 and three key processes and practices .

specifically , these officials said that they are aware that army lacks a military department - level irb and added that until now they have been relying on functional area experts to review investments before they are sent to the dod irbs .

they also acknowledged that army is missing certain documented project - level and portfolio - level management policies and procedures .

they further stated that the department is currently working on guidance to address these missing items with the goal of having it approved and finalized by august 2011 .

as discussed in our itim framework and previous reports on dod's investment management of its business systems , adequately documenting both policies and associated procedures that govern how an organization manages its it projects and investment portfolios is important because doing so provides the basis for rigor , discipline , and repeatability in how investments are selected and controlled across the entire organization .

until dod fully defines missing policies and procedures , it is unlikely that the department's reported 2,258 business systems will be managed in a consistent , repeatable , and effective manner that , among other things , maximizes mission performance while minimizing or eliminating system overlap and duplication .

to this point , there is evidence showing that dod is not managing its systems in this manner .

for example , dod reported that of its 79 major business and other it investments , roughly a third are encountering cost , schedule , and performance shortfalls requiring immediate and sustained management attention .

in addition , we have consistently reported for some time that dod's business system environment has been characterized by ( 1 ) little standardization , ( 2 ) multiple systems performing the same tasks , ( 3 ) the same data stored in multiple systems , and ( 4 ) manual data entry into multiple systems .

because dod spends over $10 billion each year on its business systems and related it infrastructure , the potential for identifying and avoiding the costs associated with duplicative functionality across its business system investments is significant .

as discussed , certification and oversight are key dod processes for selecting , and overseeing it investments .

dod guidance calls for investments to be certified and approved before funds are to be expended on modernization activities .

more specifically , the guidance states that investments involving more than $1 million in obligations are to be certified by designated approval authorities and as part of that certification , authority officials are to attest that each investment is compliant with dod's bea , including all relevant architecture products , such as products that specify the technical standards needed to promote interoperability among related systems or examine overlaps with other business systems ; is economically justified , based on an economic viability analysis developed using disciplined and rigorous cost estimating practices ; and has undergone sufficient business process reengineering analysis , including identifying and developing approaches to streamlining and improving involved processes .

as part of each of these three requirements , we have said it is important for designated approval authorities to validate the results of bea and other assessments to ensure investment decision making is based on accurate and reliable information .

more specifically , we previously reported that dod had not been performing this step and made recommendations that they do so .

dod agreed with our findings and recommendations , and stated that it planned to assign validation responsibilities and issue guidance that describes the methodology for performing validation activities but were not able to provide a date for when this would be completed .

once investments have been certified , dod guidance calls for investments to be effectively overseen .

this includes reviewing annually the progress of investments using predefined criteria and checkpoints , in meeting cost , schedule , risk , and benefit expectations .

consistent with this , dod guidance calls for irbs to annually review certified investments and in doing so , to focus on program performance against cost , schedule , and performance baselines , and progress in meeting the certification conditions discussed .

our itim research and experience with federal agencies also shows that it is important for oversight and other decisionmaking authorities to validate performance information used to make decisions so that investment decision making is based on accurate and reliable information .

dod largely followed the certification process for each of the four investments we reviewed , but did not perform validation and other key aspects of the process .

specifically: bea compliance .

dod enterprise and the military departments took steps to assess bea compliance of their respective systems .

this included following dod guidance ( the appropriate version of dod's bea compliance guidance ) and using an automated tool ( called architecture compliance and requirements traceability ) to determine and report on the extent of each system's architectural compliance .

in addition , in each case , once the bea assessment had been completed , the appropriate dod enterprise and military department precertification authorities asserted ( via memorandum of certification ) that each system was compliant with dod's bea .

for example , on the project management resource tool ( pmrt ) project , air force followed the bea compliance guidance and used the architecture compliance and requirements traceability tool to develop a compliance report that mapped bea activities to pmrt's capabilities .

in august 2010 , air force's director of business transformation and deputy chief management officer stated in a supporting precertification memorandum that this information was used to assert that pmrt was compliant with dod's bea .

in another example , on the defense travel system , dod also assessed bea compliance by using the bea compliance guidance and the architecture compliance and requirements traceability tool to develop a report showing extent of compliance .

in an october 2010 , precertification memo , dod's cio said this information was used to assert that the system was compliant with dod's bea .

although dod took these steps to certify bea compliance , it did not take other key steps .

for example , dod and component designated approval authorities did not validate the assessments and assertions .

specifically , the bea compliance assessments performed on the investments under review were not validated by dod certification and approval entities .

although this was not done , the systems were nevertheless certified as compliant .

we reported on this weakness in 2008 and made recommendations to dod to , among other things , explicitly assign responsibility for validating program bea compliance assessments and issue guidance that describes the methodology for performing such validation activities .

to date , dod has yet to implement these recommendations .

however , dod officials told us the department has actions planned or underway to address these recommendations , although they were not able to provide milestones for when this would be accomplished .

in addition , our 2008 report showed that dod bea assessments did not include all relevant architecture products , such as products that specify the technical standards needed to promote interoperability among related systems or examine overlaps with other business systems .

despite the limited assessments , dod nonetheless certified the investments as bea compliant even though they did not adequately demonstrate such compliance .

accordingly , we have made recommendations to dod to revise its bea compliance guidance , among other things , to address these shortfalls .

to date , dod has yet to implement the recommendations .

however , dod officials said the department has actions planned or underway to address the recommendations but they were not able to provide a date for when this would be completed .

economic viability analysis .

for the investments under review , dod enterprise and the military departments used dod's it investment review process guidance ( dated january 2009 ) that specifies how investment economic viability is to be analyzed and assessed .

they also used a related automated tool designed to support the development of such analyses .

once the analyses had been performed , the precertification authorities for each of the systems asserted that the efforts had been reviewed , and showed the investments were economically justified to proceed with obligating funds .

for example , on the logistics modernization program , army used dod's guidance to conduct its economic viability analysis .

the army also used the economic viability tool to complete the analysis .

in addition , in december 2010 memorandum , the army's chief management officer asserted that the economic viability analysis had been completed , and showed the investment was justified to proceed with obligating funds .

in another example , on the navy enterprise resource planning system , navy used the january 2009 dod guidance to comply with the economic viability analysis requirement and used the economic viability tool to complete the analysis .

further , in a july 2010 memo , the navy's chief management officer asserted that the investment's economic viability analysis had been completed , and showed the investment was justified to obligate funds .

although dod enterprise and the military departments took these steps to justify the investments , they did not perform other key steps .

specifically , dod enterprise and the military departments did not use important cost estimating practices critical to developing such analyses .

for example , in developing its economic justification for its erp system , navy did not implement key aspects of earned value management or develop risk mitigation strategies to address this risk .

we have previously reported on these weaknesses and made recommendations to address them .

although the recommendations are still open , dod enterprise and military department officials have said they have actions planned and under way to address the recommendations .

however , they were not able to provide a timetable for when the actions are to be completed .

business process reengineering assessment .

for the investments under review , dod enterprise and the military departments used dod's business process reengineering guidance ( dated april 2011 ) to assess whether the investments complied with the business process reengineering requirement .

consistent with the guidance , dod enterprise and the military departments completed questionnaires ( contained in the guidance ) that aim to help dod enterprise and the military departments identify and develop approaches to streamlining and improving existing business processes .

once these assessments had been completed , the dod enterprise and military department precertification authorities asserted that business process reengineering assessments had been performed .

for example , on the pmrt project , air force used the dod reengineering guidance to assess whether there were ways to streamline and improve existing business processes to be supported by the system investment .

air force completed the assessment in july 2010 .

air force reported that as part of this assessment , it had representatives from the offices of the cio and the deputy chief management officer review the completed assessment questionnaire and supporting documentation to determine whether the project team had followed the reengineering requirement .

subsequently , in august 2010 , the air force's director of business transformation and the deputy chief management officer used this information to assert that sufficient business process reengineering had been conducted in order for the program to obligate investment funding .

while dod enterprise and military department precertification authorities largely followed dod's guidance , they did not perform the key step of validating the results of these reengineering assessments to ensure they , among other things , accurately assessed process weaknesses and identified opportunities to streamline and improve affected processes .

we have ongoing work on actions the air force and army have taken to comply with statutory requirements regarding business process reengineering .

the reason dod did not follow key aspects of the certification process — primarily not validating assessment results — is attributed in part to unclear roles and responsibilities .

according to military department officials responsible for the investments we reviewed , validation activities did not occur because dod policy and guidance does not explicitly require them to be performed and there is no guidance that specifies how assessments should be validated .

according to dod officials , the oversight and designated approval authorities did not validate the dod enterprise - level assessments and assertions because dod policy and guidance has not yet been revised to require these authorities to do so .

consequently , until the policy and guidance is updated and roles and responsibilities with regard to who is to perform validation functions are clearly defined , there is an increased risk that dod will be making business system investment decisions based on information that is inaccurate and unreliable .

for the investments under review , dod largely followed its oversight process but did not perform an important validation activity .

specifically , dod's oversight process ( as specified in the january 2009 investment review guide ) calls for investments to be reviewed annually to assess how each is performing .

as part of this process , the irbs assess program performance relative to , among other things , cost , schedule , and capability commitments .

the irbs do this using updated information provided by the programs and screened by dod enterprise and military department precertification authorities for completeness .

these oversight reviews are important because an investment board should have visibility into each project's performance and progress toward predefined cost , schedule , and benefit expectations as well as each project's exposure to risk .

without such visibility and validated information , organizations risk making investment decisions that are inconsistent and are not fully grounded in reliable and accurate data .

consistent with this direction , dod conducted ( or is planning to conduct ) annual reviews for the investments we reviewed .

for example , dod conducted annual reviews for the defense travel system in december 2010 and the navy enterprise resource planning system in july 2010 .

in doing these reviews , dod assessed investment performance using the cost , schedule , and performance information provided by the programs and screened by precertification authorities .

although dod largely followed its oversight process , it did not validate the cost , schedule , and performance information used for decision making .

this finding is consistent with our previous report noting that dod's oversight process does not provide for sufficient visibility into the military department's investment management activities , including its reviews of systems in operations and maintenance and smaller investments , commonly referred to as tier 4 investments .

such visibility is important because dod reports that only 100 of approximately 2,258 total business systems are annually reviewed by the irbs .

this means that the vast majority of business systems are overseen only within the military departments .

accordingly , we have made recommendations to address this area .

dod officials said they plan to address the recommendations but were unable to provide a schedule for when this work is to be completed .

in explaining why the information used by the irbs is not validated , dod officials cited the same reasons — outdated policy and guidance and unclear roles and responsibilities — as those provided for the lack of validation in the investment certification process .

consequently , until such roles and responsibilities are clarified , dod faces increased risk that it will not effectively be able to oversee its extensive business systems investments .

among other things , the act requires dod to submit an annual report to congressional committees on dod's compliance with requirements of the act , including a description of specific actions the department has taken on each business system modernization investment submitted for certification .

the act further requires that such investments involving more than $1 million in obligations must be certified by a designated approval authority as meeting specific criteria , such as demonstrating compliance with dod's business enterprise architecture .

further , the act requires the defense business systems management committee to approve each of these certifications .

in may 2010 , we reported that the department's annual report did not discuss certification actions for all systems on which certification actions had been taken , primarily excluding business system recertifications .

we recommended the deputy secretary of defense expand future dod annual reports to congress to include all certification actions that had been taken in the previous year by the department on its business system modernization investments .

dod agreed with our recommendation and stated that it would include recertifications in future reports .

since then , the department has addressed this recommendation by including all types of certification actions in its 2011 annual report , including recertification actions .

as it has since 2005 , dod continues to certify and approve business system modernization investments in excess of $1 million .

dod's annual report identifies irb certification actions associated with 137 business system investments that underwent the irb certification and defense business systems management committee approval process for fiscal year 2010 and cost approximately $1.3 billion .

specifically , the annual report accurately states that during fiscal year 2010 , 52 unique business system modernizations were certified — 35 with and 17 without conditions .

for the 35 systems , 32 conditions were reported .

examples of conditions cited in the report are the need for business enterprise architecture compliance to improve interoperability and integration of cross - functional processes and improved program management functions .

the report also identifies 93 recertifications and 28 decertifications .

for example , the navy's enterprise resource planning system had about $7.6 million recertified in early august and another $96.6 million recertified later in the month .

while dod has made progress by reporting its certification actions , the basis for these certification actions and subsequent approvals is limited as discussed in the previous section .

a well - defined federated architecture and accompanying transition plans for the business mission area , along with well - defined investment management policies and procedures across all levels of the department , are critical to effectively addressing dod's business systems modernization high - risk area .

relatedly , it is important for the department to obtain independent assessments of the completeness , consistency , understandability , and usability of the federated family of business mission area architectures , including associated transition plans .

equally important is for the department to actually implement its architecture and investment management controls in the years ahead on each and every business system investment , and in doing so ensure that it has reliable information on each investment on which to base executive decision making .

dod has continued to take steps in defining and implementing these key institutional modernization management controls , but challenges that we identified in prior years still need to be addressed .

specifically , while dod continues to release updates to its corporate enterprise architecture , the architecture has yet to be federated through development of aligned subordinate architectures for each of the military departments .

in this regard , each of the military departments has made progress in managing its respective architecture program , but there are still limitations in the scope and completeness , as well as the immaturity of the military department architecture programs , including the completeness of their own transition plans .

in addition , while dod continues to establish investment management processes , the dod enterprise and the military departments' approaches to business systems investment management still lacks the defined policies and procedures to be considered effective investment selection , control , and evaluation mechanisms .

finally , information used to support the development of dod's budget requests , as well as to inform certification decisions , is still of questionable reliability .

collectively , these long - standing limitations in the department's institutional modernization management controls continue to put the billions of dollars spent annually on thousands of business system investments at risk .

our previous recommendations to the department have been aimed at accomplishing these and other important activities related to its business systems modernization .

to the department's credit , it has agreed with these recommendations and is committed to implementing them .

however , the state of progress of dod and military department business system modernization efforts is due , in part , to uncertainty and pending decisions surrounding the roles and responsibilities of key organizations and senior leadership positions .

accordingly , it is essential that dod resolve these matters expeditiously , as doing so is on the department's critical path for fully establishing the full range of institutional management controls needed to address its business systems modernization high - risk area .

because we have existing recommendations that address the institutional management control weaknesses discussed in this report , we are making no further recommendations in these areas .

to address the uncertainty and pending decisions surrounding the roles and responsibilities of key organizations , we recommend that the secretary of defense expeditiously complete the implementation of the announced transfer of functions of the business transformation agency and the office of the assistant secretary of defense for networks and information integration / department of defense cio and provide specificity as to when and where these functions will be transferred .

in written comments on a draft of this report , signed by the deputy chief management officer and reprinted in appendix ii , the department agreed with our recommendation and stated that it expects to announce the implementation details concerning the transfer of functions of the business transformation agency and the office of the assistant secretary of defense for networks and information integration / department of defense cio prior to june 30 , 2011 .

we support the department's efforts to address our recommendation and reiterate the importance of following through in implementing the recommendation within the stated time frame .

we are sending copies of this report to interested congressional committees ; the director , office of management and budget ; and the secretary of defense .

this report will also be available at no charge on our web site at http: / / www.gao.gov .

if you or your staffs have any questions on matters discussed in this report , please contact me at ( 202 ) 512-6304 or melvinv@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iii .

as agreed with congressional defense committees , our objective was to assess the actions by the department of defense ( dod ) to comply with provisions of section 332 of the ronald w. reagan national defense authorization act for fiscal year 2005 .

this included ( 1 ) developing a business enterprise architecture and a transition plan for implementing the architecture , ( 2 ) identifying systems information in its annual budget submission , ( 3 ) establishing a system investment approval and accountability structure along with an investment review process , and ( 4 ) certifying and approving any system modernizations costing in excess of $1 million .

 ( see the background section of this report for additional information on the act's requirements. ) .

our methodology relative to each of these four provisions is as follows: to address the architecture and transition plan provision , we focused on the progress the departments of the air force , army , and navy have made in developing their respective parts of the federated dod business enterprise architecture .

in doing so , we compared the baseline enterprise architecture program status information as presented in our 2008 report , with information on the current status of each military department's enterprise architecture program .

in doing so , we focused on those select elements that were either similar or slightly modified across versions 1.1 and 2.0 of our enterprise architecture management maturity framework and that were either partially or not satisfied by one or more of the military departments .

specifically , we reviewed written responses and supporting documentation on steps completed , under way , or planned from each military department to identify examples of progress made in addressing those elements that we had previously identified as being not satisfied or partially satisfied .

we also reviewed business architectural artifacts to determine the progress each department had made in developing their respective business architectural content since we last reported in 2008 .

we interviewed cognizant dod officials to validate the responses and identify any discrepancies .

further , we reviewed the independent verification and validation contractor's statement of work and other work products to determine whether they addressed the department's federated family of corporate and subordinate architectures .

to determine whether dod's fiscal year 2012 it budget submission was prepared in accordance with the criteria set forth in the act , we reviewed and analyzed the report on defense business system modernization fy 2005 national defense authorization act , section 332 , dated march 2011 and compared it to the specific requirements in the act .

we also compared information contained in the department's system that is used to prepare its budget submission ( snap - it ) with information in dod's defense information technology portfolio repository ( ditpr ) system to determine if dod's fiscal year 2012 budget request included all business systems .

we interviewed assistant secretary of defense for networks and information integration / department of defense chief information officer officials to discuss the accuracy and comprehensiveness of information contained in the snap - it system , the discrepancies in the information contained in the ditpr and snap - it systems , and efforts under way or planned to address these discrepancies .

we did not independently validate the reliability of the cost and budget figures provided by dod because the specific amounts were not relevant to our findings .

to assess the establishment of dod enterprise and component investment management structures and processes , we analyzed whether dod and its military departments' information technology investment management processes were compliant with federal guidance and the extent to which dod and the military departments were following their investment management processes , including those at the dod enterprise - level for approving and certifying investments .

to perform the first task , we compared the status of dod enterprise and military department ( air force , army , and navy ) investment management processes — as noted in our may 2009 report and other sources — with the current status of these organization's processes .

as part of this analysis , we focused on the definition of project - level ( stage 2 ) and portfolio - level ( stage 3 ) policies and procedures contained in our information technology investment management ( itim ) framework that were identified in our previous work as not being established .

specifically , we analyzed written department responses and supporting documentation on steps completed , under way , or planned against itim key practices to identify where progress had been made in addressing such previously identified practices .

where there were variances ( i.e. , support did not show the department was meeting a key practice ) , we reviewed relevant documentation and interviewed appropriate dod enterprise and military department officials to identify the causes and impacts .

with regard to our second task , we selected four dod enterprise - level and military department - level investments that met the following criteria: the investment was ( 1 ) either a ( tier 1 or 2 ) major automated information system from key dod functional areas ( i.e. , weapon systems lifecycle management ; materiel supply and services management ; and human resources management ) and ( 2 ) was at a life cycle phase — such as production and deployment and operations and maintenance — where there were extensive opportunities for system investment officials to demonstrate the organization was following itim key practices .

in reviewing these investments , we focused on dod enterprise and military department activities related to certification and oversight , which are a key part of selecting , managing , and overseeing it investments as called for in our itim framework and dod guidance .

for certification , we reviewed dod investment review board guidance to understand the types of actions related to the certification of business system modernizations and , in doing so , focused on three certification requirements ( eg , ensuring that designated approval authorities assert that each investment is compliant with the business enterprise architecture ) .

for each requirement , we reviewed supporting documentation from dod enterprise and the military departments to determine whether there was a documented process for how the requirement was to be certified and to ascertain whether artifacts prepared as part of the process demonstrated that the certification process was being followed .

we did the same for the oversight process .

when there were variances between the criteria and what dod enterprise and the military departments had done , we interviewed cognizant dod enterprise - level and military department - level officials on the causes and impacts .

to determine whether the department was certifying and approving business system investments with annual obligations exceeding $1 million , we reviewed and analyzed all defense business systems management committee certification approval memoranda as well as irb certification memoranda issued prior to the defense business systems management committee's final approval decisions for fiscal year 2010 and compared the results to those certification actions described in the annual report to identify differences .

we also reviewed dod irb guidance to understand the types of actions related to certification of business system modernizations .

we interviewed officials from the business transformation agency and irbs to discuss any discrepancies .

we conducted this performance audit at dod and military department offices in arlington , virginia , from january 2011 to june 2011 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objective .

in addition to the contact named above , key contributors to this report were gerard aflague , mathew bader , carl barden , shaun byrnes , debra conner , elena epps , rebecca eyler , nancy glover , neelaxi lakhmani ( assistant director ) , anh le , lori martinez , gary mountjoy , freda paintsil , david powner ( director ) , christine san , sylvia shanks , donald sebers , teresa smith , jennifer stavros - turner , and adam vodraska .

