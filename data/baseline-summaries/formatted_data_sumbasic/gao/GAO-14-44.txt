computerized matching of data from two or more information systems is one method of data analysis that can assist in detecting and preventing fraud , waste , and abuse in government programs , and it is commonly used to help identify improper payments in federal benefit programs and activities .

however , computer matching may also pose risks to the privacy of individuals whose data are involved .

to ensure that federal agency computer matching programs are effective and protect individuals' privacy rights , from 1988 through 1990 congress enacted amendments to the privacy act of 1974 .

these amendments established conditions for the use of information about individuals for , among other things , establishing or verifying eligibility for federal benefits programs .

they also established protections to ensure procedural uniformity in carrying out computer matches and included due process rights for individuals whose benefits may be affected .

throughout the remainder of this report , we refer to these amendments as the computer matching act .

you asked us to examine agencies' efforts to share data through the computer matching act .

specifically , our objectives were to ( 1 ) determine agencies' responsibilities under the computer matching act , ( 2 ) determine how selected agencies are implementing that act with regard to federal benefits programs , and ( 3 ) describe the views of officials at selected agencies on the process of developing and implementing computer matching agreements ( cma ) .

to describe agencies' responsibilities under the computer matching act , we reviewed the act's provisions , as well as other relevant laws , policies , and guidance that address computer matching for program integrity purposes .

we also interviewed agency officials and examined agency documents , including policies and procedures on computer matching programs and processes .

we selected for review federal agencies with the highest expenditures in benefits and assistance programs , specifically the departments of agriculture ( usda ) , education ( ed ) , health and human services ( hhs ) , homeland security ( dhs ) , and veterans affairs ( va ) , and the social security administration ( ssa ) .

we added the department of labor ( labor ) because it oversees significant employment benefit programs and there were some indications that the labor office of inspector general ( oig ) had faced challenges in using cmas .

labor is also one of the 10 federal agencies with the highest expenditures in benefits and assistance programs .

we also reviewed guidance developed by the office of management and budget ( omb ) .

in addition , we obtained information from the department of the treasury ( treasury ) on the do not pay working system and its relationship to the computer matching act .

to assess agencies' implementation of the act , we compared the requirements of the act with agencies' computer matching agreements relating to benefits programs , including accompanying cost - benefit analyses and agency processes for approving the agreements .

to describe the views of officials at selected agencies on the process of developing and implementing cmas , we interviewed agency officials on how they implemented the act with regard to federal benefits programs .

further , we obtained the views of inspectors general at the agencies we reviewed on the implementation of the act .

we conducted this performance audit from january 2013 to january 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

appendix i contains additional details on the objectives , scope , and methodology of our review .

sharing information is an important tool in improving the efficiency and integrity of government programs .

by sharing data , agencies can often reduce errors , improve program efficiency , evaluate program performance , and reduce information collection burdens on the public .

technological advances have broadened the government's ability to share data for these uses .

likewise , such advances have enhanced the government's ability to use computerized analysis to identify and reduce fraud , waste , and abuse .

one important analytical technique is computer matching , a term commonly used to refer to the computerized comparison of information , generally including personally identifiable information ( pii ) , such as names and social security numbers , in two or more information systems .

agencies use computer matching in a variety of ways to help ensure that federal benefits are distributed appropriately .

for example , the national directory of new hires , established in 1996 under the personal responsibility and work opportunity reconciliation act , is used to match new - hire information from states with information from other states and federal programs to detect and prevent erroneous payments for the temporary assistance for needy families program , supplemental nutrition assistance program , unemployment insurance , medicaid , and other benefit programs .

in another example , according to the chairman of the house committee on ways and means , ssa collects prisoner data from states and local governments to identify incarcerated individuals who should not receive supplemental security income benefits .

the chairman stated that from 1997 to 2009 computer matching had helped ssa identify over 720,000 inmates who were improperly receiving benefits , contributing to billions of dollars in savings to the federal government .

due to the success of this program , prisoner data are now shared with child support enforcement and supplemental nutrition assistance programs as well .

likewise , the chairman also reported that the public assistance reporting information system was being used to match state enrollment data for the temporary assistance for needy families program , supplemental nutrition assistance program , medicaid , and child care programs with data from participating states and a selected group of federal databases to identify potentially inappropriate payments .

according to the subcommittee on human resources of the house committee on ways and means , the state of colorado realized a return on investment of 4000 percent from using the system , and the state of new york annually saves an average of $62 million through its participation in the system .

much computer matching is done for program integrity purposes , but it has other uses as well .

for example , secure flight , a program run by dhs's transportation security administration , matches information about passengers provided by the airlines against government watch lists to detect individuals on the no fly list and prevent them from boarding aircraft and to identify individuals for additional screening .

another example is e - verify , an internet - based system developed by u.s .

citizenship and immigration services that allows businesses to determine the eligibility of potential employees to work in the united states .

while computer matching programs have been successful in identifying fraud , waste , and abuse in federal benefit programs , if proper controls are not in place , they can also adversely affect the privacy and due process rights of individuals whose records are being matched .

the data that are exchanged through matching programs involve personal information such as social security numbers and income and employment data .

without adequate protection , individuals' information could be compromised through inappropriate use , modification , or disclosure .

in addition , without effective due process protections , individuals could unfairly lose government benefits if decisions were made to reduce or terminate those benefits based on inaccurate or misleading computer matches .

for example , according to a senior policy analyst of the center of law and social policy , a computer match authorized under the children's health insurance program reauthorization act of 2009 , which allowed states to verify the citizenship of medicaid and children's health insurance program applicants by matching social security records rather than using clients' birth certificates , produced matches of questionable accuracy .

specifically , according to this analyst , in the first year of using this matching program , the state of alabama incorrectly identified over 1,000 children who would have been denied benefits if the results had not been verified .

the major requirements for computer matching and the protection of personal privacy by federal agencies come from two laws , the privacy act of 1974 and the privacy provisions of the e - government act of 2002 .

the privacy act places limitations on agencies' collection , disclosure , and use of personal information maintained in systems of records .

the act defines a “record” as any item , collection , or grouping of information about an individual that is maintained by an agency and contains his or her name or another individual identifier .

it defines a “system of records” as a group of records under the control of any agency from which information is retrieved by the name of the individual or other individual identifier .

the privacy act requires that when agencies establish or make changes to a system of records , they must notify the public through a system of records notice in the federal register that identifies , among other things , the categories of data collected , the categories of individuals about whom information is collected , the intended “routine” uses of data , and procedures that individuals can use to review and contest its content .

in 2002 , congress enacted the e - government act to , among other things , enhance protection for personal information in government information systems .

toward this end , the act requires agencies to conduct privacy impact assessments before developing or procuring information systems that will collect or process personal information .

these assessments provide a means for agencies to analyze and document the privacy protections they have established for uses of automated data , such as computer matching and other data - sharing activities .

because of concerns about agency use of personal information in computer matching programs , congress passed the computer matching and privacy protection act in 1988 as an amendment to the privacy act .

the provisions were intended to create procedures that would require serious deliberation and prevent data “fishing expeditions” that could reduce or terminate benefits without verifying the information and notifying affected individuals of the matching program .

in 1989 and 1990,congress enacted further amendments to , among other things , require due process procedures for agency computer matching programs , including independent verification of “hits” and a 30-day notice for individuals affected by a matching program .

under these sets of amendments , which we collectively refer to as the computer matching act , computer matching is defined as the computerized comparison of records for the purpose of establishing or verifying eligibility or recouping payments for a federal benefit program or relating to federal personnel management .

to ensure procedural uniformity in carrying out matching programs and to provide due process for potentially affected individuals , the law established a number of requirements for covered agency computer matching programs , including agencies must have computer matching agreements with participating agencies that specify , among other things , the purpose and legal authority of the program and a justification for the program , including a specific estimate of any savings ; data integrity boards ( dib ) must be established to approve and review all agency computer matching programs covered by the computer matching act , including the costs and benefits of such programs ; and omb must prescribe guidance for agencies on conducting computer matching programs as part of implementation of the privacy act .

these requirements do not , however , apply to all federal agency computer matching activities .

for example , the law's definitions exclude matches of federal agency information with commercial data and matches of federal agency payments , grants , or loans to entities other than individuals .

further , the law exempts a number of matching activities .

for example , the initial 1988 amendments included exemptions for matches for statistical or research purposes , law enforcement investigations of specific individuals , and certain tax - related matches .

in 1999 , an exemption was added for social security act - related matches of prisoner data .

in addition , in 2010 , the patient protection and affordable care act exempted matches by hhs relating to potential fraud , waste , and abuse .

most recently , in january 2013 , the improper payments elimination and recovery improvement act ( iperia ) provided , among other things , that data - matching activities conducted by agencies and offices of inspectors general ( oig ) that assist in the detection and prevention of improper payments would be subject to requirements that differ from those of the computer matching act .

these include a 60-day time limit on dib review , approvals extended up to 3 years , and a waiver on the requirement for a specific estimate of savings in a computer matching agreement .

in addition , iperia established in law the do not pay initiative , coordinated by the department of the treasury , to require agencies to reduce improper payments by reviewing a number of databases , including the ssa death master file and the department of housing and urban development credit alert system , before issuing any payments .

iperia also required omb to ensure the establishment of a working system to provide agencies with access to these databases , and to report to congress on the operations of the do not pay initiative .

omb's august 16 , 2013 , guidance also contained instructions for agencies on implementing this initiative , including responsibilities for agency dibs .

for example , the guidance states that dibs should be properly trained and should meet annually to evaluate agency matching programs .

omb is responsible for developing guidelines and providing continuing assistance to agencies on the implementation of the computer matching act , while agencies have a variety of implementation responsibilities .

agency responsibilities can be grouped into three major areas: ( 1 ) developing computer matching agreements containing specific elements for each proposed matching program and notifying congress , omb , and the public of computer matching activities ; ( 2 ) conducting cost - benefit analyses for proposed computer matching programs ; and ( 3 ) establishing dibs to oversee computer matching programs , including reviewing and approving computer matching agreements .

the privacy act gives omb responsibility for developing guidelines and providing continuing assistance to agencies on the implementation of the computer matching act .

omb has periodically published guidance for implementing the act , including documents issued in 1989 , 1991 , 2000 , and 2013 .

in addition , circular no .

a - 130 includes instructions to agencies for reporting on computer matching activities .

the 1989 guidance provided explanations for agencies on interpreting various provisions of the 1988 amendments , including examples of activities that should be treated as computer matching programs covered by the act , types of information that should be in computer matching agreements ( cmas ) , and responsibilities for fulfilling reporting requirements .

the 1989 guidance also addressed required cost - benefit analyses and the responsibilities of dibs .

the 1991 guidance was intended to help implement changes made in the 1990 computer matching amendments to simplify several due process requirements after agencies experienced difficulties implementing the requirements established in 1988 .

omb circular no .

a - 130 , management of federal information resources , includes guidance on implementation of a number of information and information technology laws .

according to omb staff , the circular a - 130 requirements provide guidance to agencies on meeting the reporting requirements for computer matching activities .

the circular's appendix i , “federal agency responsibilities for maintaining records about individuals,” provides specific instructions for agencies on reporting requirements relating to computer matching .

omb's 2000 memorandum reinforced existing privacy act requirements , while its 2013 memorandum on reducing improper payments provided guidance on implementing the requirements in iperia as well as some additional clarifications on computer matching programs .

agencies are required to establish computer matching programs when conducting any computer matches , which are defined as a “computerized comparison of records for the purpose of establishing or verifying eligibility or recouping payments for a federal benefit program or relating to federal personnel management.” agencies first need to determine whether their planned activity falls within the scope of the law under this definition .

if a proposed match is covered by the computer matching act , a cma must be developed and approved by all participating agencies.among other things , the act requires that cmas include the purpose and legal authority for conducting the program ; the justification for the program and the anticipated results , including a specific estimate of any savings ; a description of the records that will be matched , including each data element that will be used , the approximate number of records that will be matched , and the projected starting and completion dates of the matching program ; procedures for providing individual notice at the time of application , and notice periodically thereafter as directed by the dib ( subject to omb guidance ) , to applicants or recipients of federal benefits ; procedures for verifying information produced in the matching program as required to ensure that no benefits action is taken before the information acquired through computer matching is verified and potentially affected individuals are notified and have an opportunity to contest findings ; procedures for the retention and timely destruction of identifiable records created by a recipient agency or nonfederal agency in the matching program ; procedures for ensuring the administrative , technical , and physical security of the records matched and the results of the matching programs ; and information on assessments that have been made on the accuracy of the records that will be used in the program .

after the cma has been approved by all participating agencies , the agency that receives the data and derives benefit from the matching program is responsible for publishing a notice describing the details of the cma in the federal register and must notify congress and omb prior to implementation .

the act requires agencies to annually review each ongoing matching program in which the agency has participated during the year and submit a copy of every cma to the house committee on oversight and government reform and the senate committee on homeland security and governmental affairs .

the computer matching act also requires that agencies conduct cost - benefit analyses in conjunction with the development of cmas .

the act states that agency cmas must include a specific estimate of any savings from the matching program and that dibs shall not approve any cma without a cost - benefit analysis of the proposed program that demonstrates that the program is likely to be cost - effective .

according to omb's 1989 guidance , the intent of this requirement is to ensure that sound management practices are followed when agencies use records from privacy act systems of records in matching programs .

according to omb , cost - effectiveness must be established before a cma is approved and matching can occur , the goal being to ensure that when agencies are conducting matching programs they do not drain agency resources that could be better spent elsewhere .

omb guidance states that the cost - benefit information from cmas helps congress evaluate the effectiveness of statutory matching requirements .

the act does not specify the elements of the required cost - benefit analyses , and omb's guidance provides only a general outline of the costs and benefits that should be considered .

in its 1989 guidance , omb referred agencies to a gao report published in 1986costs and benefits of computer matching programs as one source for conducting a computer matching cost - benefit analysis , and stated that it would issue a checklist providing a step - by - step methodology for such analyses at a later date .

however , according to omb staff , it has not issued such a checklist .

officials at three agencies we reviewed stated that they used our report as a source of guidance on the expected contents of cost - benefit analyses for computer matching .

without more recent guidance , our 1986 report is the only guidance available to on assessing the agencies specifically for developing cost - benefit analyses for computer matching programs .

while different computer matching programs may have unique costs and benefits , our 1986 report identified the following key elements as common types of costs and benefits associated with computer matching: personnel costs , such as salaries and fringe benefits , for personnel involved in the matching process , including staff time dedicated to performing the match .

computer costs related to the processing of computer matching programs , such as the maintenance and use of computers at facilities .

avoidance of future improper payments: the prevention of future overpayments by identifying and correcting an error .

recovery of improper payments and debts: the detection of an overpayment or debt already made and the collection of the money owed to an agency .

the computer matching act also requires that each agency participating in a computer matching program establish a dib to oversee computer matching activities .

the act requires that the dibs be composed of senior officials designated by the head of each agency .

according to the act , duties of the dibs include the following: reviewing , approving , and maintaining all written agreements for receipt or disclosure of agency records under computer matching programs .

determining the agency's compliance with applicable laws , regulations , guidelines , and agency agreements .

assessing the costs and benefits of matching programs and approving only those for which a cost - benefit analysis demonstrates that the program is likely to be cost - effective .

reviewing all recurring matching programs for continued justification .

annually reviewing all matching programs in which the agency participated during the year , either as source or recipient .

compiling an annual report describing the matching activities of the agency , which is to be submitted to the head of the agency and omb and made available to the public .

the annual report should include a description of matching programs , matching agreements disapproved by the dib , waivers of a cost - benefit analysis , and any violations of matching agreements .

in addition , omb's1989 guidance specifies that dibs are to include the inspector general and a senior official responsible for the implementation of the privacy act .

the inspector general may not serve as the chairman of the dib .

omb recommended , but did not require , that the privacy act officer serve as the board secretary .

according to omb's 1989 guidance , reviewing computer matching agreements is the foremost responsibility of the dibs , and they are required to meet often enough to ensure that the agency's matching programs are carried out efficiently , expeditiously , and in conformance with the privacy act .

more generally , omb's 1989 guidance noted that the dibs should serve as an information resource on matching for agencies , be placed at the top of the agency's organization , be staffed with senior personnel , and ensure that their reasons for either approving or denying a matching program are well documented .

among other things , the guidance also explained that the law's requirement for annual dib review of agency matching programs was to ( 1 ) determine whether the matches have been , or are being , conducted in accordance with appropriate authorities and under the terms of the matching agreements and ( 2 ) assess the utility of the programs in terms of their costs and benefits .

the act and omb guidance also state that if a matching agreement is disapproved by the dib , any party to such agreement may appeal the disapproval to the director of omb .

omb circular no .

a - 130 also instructs agencies to submit a biennial report ( rather than an annual report , as required by the act ) to omb summarizing the agency's computer matching activities .

the report is to include the names of the dib members and a list of each matching program , including its purpose , the participating agency , and a brief description of the program .

for each matching program , the report is to state whether a cost - benefit analysis provided a favorable ratio or if the cost - benefit analysis was waived , the reason why .

the agencies we reviewed have taken a number of steps to implement the requirements of the act .

all seven agencies had established processes for creating and approving computer matching agreements , and the agreements they implemented generally included the elements required by the act .

however , implementation among these seven agencies was inconsistent in several ways: agencies differed in their understanding of what circumstances and types of data - sharing the act applied to , such as whether cmas were required for “front - end” data queries .

while these agencies generally developed cost - benefit analyses for their computer matching agreements , they did not consistently address key costs and benefits needed to assess the value of their computer matching programs .

agency dibs , which are required to review and approve computer matching agreements , did not always regularly meet or thoroughly review proposed cmas or cost - benefit analyses .

dibs have also not consistently reported to omb on agencies' computer matching activities , as required by the act , leading to reduced transparency of these programs .

further , omb has provided little assistance to agencies in implementing the act , which may contribute to inconsistent implementation .

for the matching programs that the agencies believe are covered by the act , the seven agencies we reviewed had 82 cmas in place that addressed the act's requirements .

all seven agencies also issued agency - wide policies and guidance that address compliance with the act , and the cmas these agencies had in place met basic requirements , including stating the purpose and legal authority for conducting the match , justification for the program and anticipated results , descriptions of records to be matched , procedures for providing individual notice , procedures for verifying information , procedures for retention and timely destruction of records , procedures for ensuring the physical security of the records , and assessments of the accuracy of the records used .

figure 1 shows the number of active cmas at each of these agencies .

while the seven selected agencies were in compliance with the basic requirements of the act with regard to developing cmas for activities they identified as covered by the act , they differed in how they interpreted the scope and application of the act to their data - sharing activities .

specifically , three agencies interpreted the law to apply only to the matching of an entire system of records against another database , but not to other types of comparisons .

for example: officials from dhs and va stated that they interpret the act to apply only to automated comparisons of two complete systems of records ( eg , a batch comparison of two entire databases identified under the privacy act as “systems of records” ) .

they believe that single - record comparisons , such as checks performed by front - end verification systems or individual queries of information within a system of records , are exempt .

similarly , no cmas were established for certain data - sharing arrangements between ssa and va .

specifically , ssa established information exchange agreements with va by which it provides information via online queries about individuals for program integrity and benefit accuracy purposes .

according to ssa officials , a cma with va was not necessary because va employees directly accessed ssa data using a computer terminal .

an ssa official also commented that they preferred using information exchange agreements because they were quicker to process and approve than cmas .

likewise , dhs offers a web - based service that federal , state , and local benefit - issuing agencies , institutions , and licensing agencies use to verify the immigration status of benefit applicants so that only those entitled to benefits receive them .

according to dhs officials , this service is also not covered by the act because it does not involve comparison of two complete systems of records .

in contrast , officials from usda's food and nutrition service noted that a cma was established between the states and ssa for performing front - end verification of supplemental nutrition assistance program eligibility .

similarly , ed officials stated that they require cmas for front - end queries that establish eligibility for federal student aid .

in addition , hhs officials stated that they believe the computer matching act requires cmas to cover front - end queries .

labor officials indicated that they do not use front - end verification to establish benefits eligibility .

moreover , the do not pay working system , an online portal run by the department of the treasury that can conduct online queries similar to computer matching , is not currently covered by any cmas .

the system is run as part of the do not pay initiative , which was established by law in iperia on january 10 , 2013 .

iperia requires federal agencies to use certain databases , which are to be available through the do not pay working system , for prepayment review of eligibility for payments and awards .

agencies use the portal to perform online queries to verify records related to specific individuals , a process known as front - end verification .

treasury officials stated that the initiative currently has no computer matching agreements in place because the portal operates only as a query system , which they believe does not require cmas .

they stated that in the future , upon establishment of a system of records , they plan to add batch matching for privacy act records , at which time they will secure computer matching agreements .

varying agency interpretations of the scope of the act are partially due to unclear guidance from omb on this subject .

omb's 1989 matching guidance includes examples of front - end verification programs that are covered by the act , but none of omb's guidance documents indicate specifically whether queries are subject to the act .

omb's 2013 iperia guidance addressed the subject indirectly by stating that matches involving “subsets” of systems of records are covered by the act .

however , it did not clarify whether front - end verification queries qualify as subsets of systems of records or are otherwise covered , thus continuing to leave the subject unclear .

according to omb , it is up to agencies to adhere to the act and official guidance .

omb staff stated that the types of data - sharing covered by the act are determined on a case - by - case basis , and omb's iperia guidance states that the act applies to matches involving a “subset” of records from a system of records .

however , omb has not clarified whether the law applies to front - end verification , which generally involves just one record , or only to the matching of larger sets of records against another database .

without clear guidance on the scope of the act , agencies are likely to continue to interpret what the act covers in varying ways , and its privacy protections are likely to continue to be inconsistently applied .

while agency cmas generally included cost - benefit analyses , the completeness of their analyses varied .

of the 82 cmas from the seven agencies we reviewed , 68 included cost - benefit analyses .

eleven cmas from the seven agencies were for statutorily required programs that did for the other 3 cmas , ssa did not not require cost - benefit analyses.conduct cost - benefit analyses because , according to officials , it was the source agency for these matching programs .

according to omb's 1989 guidance , while recipient agencies are suggested to take the lead in developing cost - benefit analyses , such analyses should be provided to source agencies to assist in their decision to approve or deny a cma .

while most agencies submitted a cost - benefit analysis with their cmas , they did not always address all four key elements identified by gao's 1986 report .

more specifically , of the 68 cost - benefit analyses from the seven agencies that we reviewed , 2 included all the key elements , 63 included some but not all key elements , and 3 did not address any of the key elements .

fourteen cost - benefit analyses did not include personnel costs , and 14 did not include computer costs .

additionally , 13 did not include the avoidance of future improper payments , and 33 did not include an estimate of the recovery of improper payments and debts .

the dibs approved all cmas even though most cost - benefit analyses did not include all key information .

table 1 provides more detail on the seven selected agencies' inclusion of key elements in their cost - benefit analyses .

the act requires that agencies conduct cost - benefit analyses in conjunction with the development of cmas .

the act states that agency cmas must include a specific estimate of any savings from the matching program and that dibs shall not approve any cma without a cost - benefit analysis of the proposed program that demonstrates that the program is likely to be cost - effective .

according to omb guidance , the goal is to ensure that sound management practices are followed when agencies conduct matching programs and that they do not drain agency resources that could be better spent elsewhere .

omb's general guidance for conducting cost - benefit analyses for federal programs is contained in circular a - 94 .

however , specific guidance for cost - benefit analyses on computer matching programs , which was promised in omb's1989 guidance , has never been developed .

in the absence of specific omb guidance , three agencies developed their own interim guides for cost - benefit analyses , while the others had no established methodology .

specifically , va , ed , and ssa had policies and procedures on developing cost - benefit analyses: va had guidance that included formulas staff should use to calculate each of the key elements , and ssa used omb circular no .

while ed used the prior gao report ; a - 94 .

the other four agencies — dhs , usda , hhs , and labor — did not develop or document guidance for conducting cost - benefit analyses .

without guidance from omb that specifically addresses the necessary elements of cost - benefit analyses for computer matching , agencies are likely to continue to inconsistently assess the costs and benefits of their proposed matches and may be unable to demonstrate that such matches are a cost - effective use of resources .

while they varied in size and composition , all seven agencies we reviewed established dibs as required by the act .

as required by the act , all of the dibs included senior officials and the inspector general , as shown in table 2 .

all seven agencies also have issued agency - wide policy and guidance that addresses dib membership and responsibilities , in compliance with the act .

according to these agency policies , the dibs' primary purpose is to review and provide final approval of cmas and associated cost - benefit analyses .

each of the 82 cmas from the seven agencies we reviewed showed evidence that they were reviewed and approved by the dibs .

however , as noted previously , dibs approved cost - benefit analyses that did not always include all key data elements .

for example , the dib at usda approved one cost - benefit analysis that did not include any estimate of cost or benefits and provided no estimated value .

in addition , dibs at the seven agencies we selected for review approved 13 cost - benefit analyses that did not identify an estimate of the avoidance of future improper payments , as well as 33 cost - benefit analyses that did not identify an estimate of the recovery of improper payments and debts .

without the dibs ensuring that cost - benefit analyses include key costs and benefits , agencies will have less assurance that their computer matching programs are a cost - effective use of resources .

in addition to reviewing specific proposed cmas and their associated cost - benefit analyses , the computer matching act requires dibs to conduct an annual review of agency matching programs .

these annual reviews are an important element of the act's privacy protections and are intended to ( 1 ) determine whether matches have been or are being conducted in accordance with appropriate authorities and under the terms of the matching agreements and ( 2 ) assess the utility of the programs in terms of their costs and benefits .

appendix i to omb circular no .

a - 130 , on the management of federal information resources , includes guidance for implementing the reporting requirements for computer matching agreements .

however , the dibs have not always followed the review and reporting requirements of the act or omb guidance .

of the seven agencies , only va provided evidence of an annual dib review and report of computer matching activities .

according to officials at hhs and ed , they do not submit such a report because omb guidance only requires the submission of a biennial report .

without annual reviews , agencies and omb have less assurance that matches are being conducted in accordance with the terms of matching agreements and that the programs are justified and viable in terms of cost and benefits .

in addition , the transparency of agency computer matching programs may be limited if annual reviews are not conducted .

omb staff agreed that they have required agencies to submit only biennial reports rather than the annual reports required by the act: omb guidance requires dibs to report on computer matching activity every 2 years .

this guidance is inconsistent with the computer matching act , which requires an annual reporting of computer matching activity .

omb did not revise its guidance to reflect amendments to the act in 1995 and 1998. to conduct annual reviews of all computer matching programs , even if it does not require them to report on those reviews annually as required by the act .

however , omb staff stated that omb guidance still requires dibs while only va submitted annual reports , other agencies submitted the omb - required biennial reports only intermittently: while the dibs at va , ed , and ssa have submitted biennial reports over the last 5 years , hhs did not submit one in 2012 .

appendix i of omb circular no .

130 ( as reflected in 1993 , 1996 , and 2000 revisions ) , states that the act requires dib reporting on computer matching activity every 2 years ; however , this is inconsistent with the computer matching act ( specifically , 5 u.s.c .

§ 552a ( u ) and ( s ) ) , as amended by sec .

1301 of pub .

l. no .

105-362 ( nov. 10 , 1998 ) , and sec .

3003 of pub .

l. no .

104-66 ( dec. 21 , 1995 ) .

labor's dib did not submit biennial reports in 2008 or 2012 .

officials stated they were waiting for instructions from omb to send their latest one .

usda did not submit two of the last three biennial reports .

usda officials stated that they were not able to send past reports due to resource constraints .

dhs's dib has not submitted any biennial reports .

however , it reports summary information on computer matching programs annually in the privacy portion of its federal information security management act ( fisma ) report to omb .

according to dhs officials , this reporting meets the requirements of the act .

table 3 shows submission of biennial reports from 2008 through 2012 by the seven agencies we reviewed .

in addition , while the law does not specifically require agencies to publish reports on their websites , it does require they be made publicly available .

however , existing reports were not always accessible on six agencies' websites .

only one agency , va , had a recent biennial report posted online .

dhs had posted its annual privacy report , which includes information on new cmas , on its website .

ed officials stated they are in the process of upgrading their website and plan to post the reports at a future date .

ssa and usda require that individual requests be submitted to gain access to their biennial reports .

labor does not post any reports , and officials said they are not aware of any public requests for them .

also , we found that the agencies submitting biennial reports ( usda , ed , hhs , labor , va , and ssa ) did not always include all the information required by omb guidance .

for example , va was the only agency included in our review that submitted biennial reports with cost - benefit analysis ratios ; however , for certain programs it was not able to determine cost savings information or whether the program had a favorable cost - benefit ratio .

labor did not include in its biennial report whether the cmas approved or conducted during the 2 years covered by the report had a favorable cost - benefit ratio .

other agencies ( usda , ed , hhs , and ssa ) stated in their biennial reports that all their matching programs had favorable ratios but did not provide specific cost - benefit information for any of the programs .

as stated previously , not all cmas included cost - benefit analyses or savings information ; therefore , statements in agency biennial reports that all their matching programs had favorable cost - benefit ratios could be unjustified .

without consistent dib review and reporting , agencies' computer matching programs are not being regularly evaluated for effectiveness by agencies and are less transparent to omb , congress , and the public .

the computer matching act gave omb responsibility for providing continuing assistance to agencies in their implementation of the act and the other provisions of the privacy act .

however , agency officials stated that they have not received consistent assistance from omb .

according to usda , dhs , labor , va , and ssa officials , omb has not provided assistance to them on conducting cmas or submitting biennial reports .

however , officials at ed stated that omb had briefed them on the cma process , and hhs officials have not received any specific instruction from omb on conducting cmas .

in addition , officials at the hhs oig and ssa stated they had no knowledge of actions taken by omb with regard to cmas , notices , or related reports submitted to omb .

according to omb , it is up to agencies to adhere to the act and omb guidance .

when asked what happens if an agency does not submit a biennial report as required by omb guidance , omb staff said they may reach out and discuss it with the agency .

however , omb staff gave no evidence of knowing the extent to which agencies have not submitted the biennial reports or following up with any of the agencies .

for example , usda did not submit a report between 2000 and 2013 .

further , labor officials stated that one reason for not submitting the 2012 biennial report is that they have been waiting for omb to provide specific reporting instructions .

the labor officials also stated that they do not even know where to send the biennial reports at omb .

when informed of this , omb staff said that is not consistent with the requirement to submit a report biennially to omb .

without taking steps to follow up on reporting requirements or to provide assistance to agencies , omb may be allowing agencies to implement the act inconsistently .

agency officials at six of the seven agencies we reviewed told us that the act's rigorous requirements and the cma review processes within and among agencies were lengthy and resource - intensive and that statutory time frames for conducting matching activities were too short , discouraging implementation of cmas .

similarly , oig officials at four agencies stated that , given the short duration of cmas , the typical length of the cma approval process discouraged them from computer matching , as did the requirement that their proposed agreements be approved by agency dibs .

for example , officials at dhs told us they avoid attempting to implement cmas because the internal review processes are lengthy and resource - intensive and because of the relatively short duration of approved cmas .

officials at ed , hhs , labor , ssa , and va agreed that the cma review process is lengthy and resource - intensive .

they said that the fact that proposed cmas must be reviewed by both the source and recipient agencies created extensive review processes that often took a long time to complete .

in contrast , officials at usda did not think the review process was overly lengthy or resource - intensive .

to implement the requirements of the act , agencies we reviewed typically adhere to the following cma process , which involves an extensive sequence of multiple reviews: development of the computer matching agreement: the agency that wants to run a match on its program records ( the recipient ) develops a proposed cma to receive records from another agency ( the source ) to match against its records .

the proposed cma must include a cost - benefit analysis that adheres to all the act's requirements , which can add to the time and cost of developing a cma .

reaching agreement on the cma frequently involves negotiation between the agencies over what data will be matched and how the data will be transferred .

upon reaching a draft agreement , the proposed cma is reviewed and approved by multiple offices , including separate legal and privacy office reviews , in each agency .

officials said that the negotiation process and legal and privacy reviews often took many months to complete .

data integrity board review: the proposed cma is reviewed and must be approved by dibs at both the source and recipient agencies .

agency head approval: following dib approval , the proposed cma must also be approved by both agency heads , requiring that the draft agreement be vetted through officials at additional offices within each agency .

notice to congress: recipient agencies must allow an additional 40 days to notify the senate committee on homeland security and governmental affairs , the house committee on oversight and government reform , and omb to provide an opportunity for review and comments prior to implementation of the match .

public notice: a notice of the computer matching program must be published in the federal register at least 30 days prior to implementation to provide an opportunity for interested persons to submit comments .

 ( this public notice period can occur at the same time as notice is given to omb and congress. ) .

figure 2 provides an overview of the typical cma approval process .

according to agency officials , following these steps can be a lengthy process , often taking 3 months or longer to complete .

for example: an ed official stated that new cmas usually take 9-10 months and renewals take 6 months to complete .

according to officials from the hhs administration for children and families , cmas with supplemental nutrition assistance program agencies typically take 6 to 9 months , while those with state workforce programs take up to a year .

according to officials from the dhs privacy office , the cma process at dhs can take up to 6 months .

according to officials from va's veterans benefits administration , cmas can take 3 months to 1 year .

according to officials from the ssa privacy office , on average , cmas take about a year to process or to be renewed ; however , the process can take longer .

officials at va and hhs stated that cmas with ssa must be planned a year in advance .

not all agency officials reported that the cma process was lengthy .

for example , usda officials stated that the cma process could take up to 45 days to complete .

in addition , agency officials generally believed that cmas do not last long enough .

given the lengthy internal review processes , agency officials from ed , hhs , dhs , va , and ssa indicated that the statutory requirement that agreements be effective for only 18 months with a possible extension for 12 additional months was too short .

given such constraints , the approval process can last nearly as long as the proposed matching program itself .

these officials said that when they have a continuing need to maintain permanent matching programs they have to restart the approval process nearly as soon as a cma is approved in order to get either a 12-month extension or to reinstate the cma as a new agreement after an existing 12-month extension has expired .

as a result of the lengthy administrative process , agencies could be discouraged from pursuing cmas .

similarly , dhs privacy office officials stated that the review requirements and limited duration of cmas discouraged implementation in the department .

they said that the department's other review processes provided protections that were as good as those afforded by the act .

for example , they stated that privacy protections were examined in privacy impact assessments and were assessed for all data - sharing agreements , including those that fell outside of the act .

in addition , dhs privacy impact assessments are publicly available on the agency's website and thus contribute to the transparency of the programs .

oig officials also had concerns with the approval process for cmas .

specifically , oig officials at ed , dhs , ssa , and labor stated that they were reluctant to make the effort to establish cmas because it could take 6 months to several years to get them approved , which could overly delay their planned audit and investigative work .

oigs that did not have active cmas , including those at usda , ed , dhs , and labor , said they perform computer matches only when they do not need to seek new cmas , such as when they can use data already obtained by other entities within their departments or gathered by the states .

in both such cases , separate cmas are not required .

ed oig officials also added that although the lengthy computer matching approval process may be acceptable for agency programs that may last for multiple years , oig's needs generally are confined to investigations and audits with limited time frames , and cmas are less practical in those circumstances .

an oig official at hhs stated that the hhs oig was exempt by law from having to prepare cmas .

oig officials at ed and representatives from the council of the inspectors general on integrity and efficiency ( cigie ) and recovery accountability and transparency board ( recovery board ) also expressed concerns about their independence in initiating and conducting computer matching programs .

specifically , they said that because agency management officials sit on the data integrity boards that approve cmas , the agency is informed of oig investigations that intend to use computer matching , which could compromise certain investigations .

lastly , an official from the dhs oig expressed the opinion that because the oig's role is advisory in nature and does not involve making official eligibility determinations based on computer matching results , the oig should be exempt from having to establish cmas in order to do computer matching .

not all oig officials agreed that cmas were problematic .

for example , oig officials from labor and usda said they had not experienced independence issues at their agencies .

in addition , an official from the va oig stated that while the computer matching process usually takes 6 to 9 months , she did not feel the requirements posed a problem for investigative projects that were adequately planned in advance .

for example , the va oig official pointed out that the act allowed for pilot data matches ( under its exemption for statistical matching ) that provide an opportunity for investigative methods to be tested in advance of developing a cma .

the official stated that in one case the va oig had conducted pilot matches using a small data subset to determine whether it would be productive to perform a match of the entire dataset .

after the pilot showed the value of conducting the match , the va oig initiated a cma with the source agency , and matching under this cma is currently under way .

in this case , the length of time required to get the cma approved was not problematic because the oig had planned for it in advance .

further , officials from privacy offices in several agencies , such as usda , ed , and ssa , stated that requirements of the computer matching act were valuable to their agencies as privacy protections and did not discourage use .

for example , an official in the usda privacy office stated that usda ensures that mechanisms similar to those in the computer matching act are incorporated in policies and practices relating to all applicable computer matching and data - sharing activities regardless of whether they are statutorily covered by the act .

similarly , officials from ed said they have applied the cma process to data - sharing agreements not covered by the act , including a data - sharing agreement with ssa , to ensure that that program had privacy protections comparable to those provided by the act .

furthermore , officials from ssa stated that the provisions play an important role for members of the public by providing protections for their information .

the seven agencies we reviewed have responded to the computer matching act by developing policies and procedures that comply with its requirements ; however these agencies have also implemented the act inconsistently .

interpretations of the act's scope have varied , cost - benefit analyses have not always addressed key elements , and dibs have not always met requirements .

inconsistent implementation has led to reduced transparency of computer matching programs and raises questions of whether privacy is being protected consistently for these agencies' computer matching activities .

omb has also not taken steps to ensure consistent implementation of the act .

for example , omb guidance does not resolve questions about what types of matching are covered by the act , as well as how to assess costs and benefits , resulting in confusion among the agencies .

without clearer guidance and assistance from omb , the agencies we reviewed are likely to continue implementing the act inconsistently and potentially conducting computer matching programs that are neither cost - effective nor protective of privacy , as provided for by the act .

further , the act contains a number of provisions that pose challenges for agencies , such as the act's definitions and limited time frames for conducting computer matches .

to the extent that agencies avoid performing matches because of the extensive and time - consuming process for establishing cmas , they may be losing opportunities to identify improper payments that could result in savings to the government .

to make government - wide computer matching program planning efforts more consistent , we recommend that the director of omb take the following four actions: revise guidance on computer matching to clarify whether front - end verification queries are covered by the computer matching act , direct agencies to address all key elements when preparing cost - ensure that dibs prepare and submit annual reports of agency - wide computer matching activities , and ensure that agencies receive assistance in implementing computer matching programs as envisioned by the act .

we are also making specific recommendations for the seven agencies in our review to improve the implementation of the act as follows .

we recommend that the secretary of agriculture develop and implement policies and procedures for cost - benefit analyses related to computer matching agreements to include key elements such as personnel and computer costs , as well as avoidance of future improper payments and recovery of improper payments and debts ; ensure the dib reviews cost - benefit analyses to make certain cost savings information for the computer matching program is included before approving cmas ; and ensure the dib performs annual reviews and submits annual reports on the agency's computer matching activities , as required by the act .

we recommend that the secretary of education develop and implement policies and procedures for cost - benefit analyses related to computer matching agreements to include key elements such as personnel and computer costs , as well as avoidance of future improper payments and recovery of improper payments and debts ; ensure the dib reviews cost - benefit analyses to make certain cost savings information for the computer matching program is included before approving cmas ; and ensure the dib performs annual reviews and submits annual reports on agency computer matching activities , as required by the act .

we recommend that the secretary of health and human services develop and implement policies and procedures for cost - benefit analyses related to computer matching agreements to include key elements such as personnel and computer costs , as well as avoidance of future improper payments and recovery of improper payments and debts ; ensure the dib reviews cost - benefit analyses to make certain cost savings information for the computer matching program is included before approving cmas ; and ensure the dib performs annual reviews and submits annual reports on agency computer matching activities , as required by the act .

we recommend that the secretary of homeland security develop and implement policies and procedures for cost - benefit analyses related to computer matching agreements to include key elements such as personnel and computer costs , as well as avoidance of future improper payments and recovery of improper payments and debts ; ensure the dib reviews cost - benefit analyses to make certain cost savings information for the computer matching program is included before approving cmas ; and ensure the dib performs annual reviews and submits annual reports on agency computer matching activities , as required by the act .

we recommend that the secretary of labor develop and implement policies and procedures for cost - benefit analyses related to computer matching agreements to include key elements such as personnel and computer costs , as well as avoidance of future improper payments and recovery of improper payments and debts ; ensure the dib reviews cost - benefit analyses to make certain cost savings information for the computer matching program is included before approving cmas ; and ensure the dib performs annual reviews and submits annual reports on agency computer matching activities , as required by the act .

we recommend that the secretary of veterans affairs develop and implement policies and procedures for cost - benefit analyses related to computer matching agreements to include key elements such as personnel and computer costs , as well as avoidance of future improper payments and recovery of improper payments and debts ; and ensure the dib reviews cost - benefit analyses to make certain cost savings information for the computer matching program is included before approving cmas .

we recommend that the administrator of social security develop and implement policies and procedures for cost - benefit analyses related to computer matching agreements to include key elements such as personnel and computer costs , as well as avoidance of future improper payments and recovery of improper payments and debts ; ensure the dib reviews cost - benefit analyses to make certain cost savings information for the computer matching program is included before approving cmas ; and ensure the dib performs annual reviews and submits annual reports on agency computer matching activities , as required by the act .

we sent draft copies of this report to the seven agencies covered by our review as well as to the department of the treasury and omb .

we received written responses from usda , ed , dhs , labor , va , and ssa .

these comments are reprinted in appendices ii through vii .

all of the agencies to which we made recommendations and received comments concurred with our recommendations , with the exception of ed , which concurred with one of our three recommendations .

the agencies also provided technical comments , which we have incorporated as appropriate into the final report .

the hhs gao intake coordinator indicated via e - mail that hhs agreed with our recommendations and offered no further comments .

the executive director of the bureau of fiscal services at treasury provided technical comments via e - mail , which we have addressed as appropriate .

omb staff provided technical comments via e - mail which we have considered and included as appropriate .

the omb staff did not state whether the agency agreed or disagreed with our recommendations .

usda concurred with all our recommendations and stated that it plans to move forward with implementing them .

usda noted the need for consistent , clear instructions and assistance from omb on implementing the computer matching programs .

ed concurred with one of our recommendations , to ensure the dib performs annual reviews and submits annual reports on agency computer matching activities , as required by the computer matching act .

however , ed did not concur with the other two recommendations .

regarding our recommendation to develop and implement policies and procedures for cost - benefit analyses that include all key elements , ed stated that it agreed that the elements of our recommendation are important but stated that its analyses included appropriate key elements .

specifically , the department argued that not all key elements apply to every computer matching program .

for example , ed did not think it appropriate to address the recovery of improper payments and debts for matching programs to establish eligibility .

however , we believe all key elements should be addressed in cost benefit analyses , even if only to note that certain types of benefits have been considered and determined not to be applicable in the specific circumstances of a given computer matching program .

without a thorough assessment , the dib may not have sufficient information to determine whether a thorough cost analysis has been conducted .

regarding our recommendation to ensure that the dib reviews cost - benefit analyses to make certain cost savings information for cmas are included before approval , ed did not concur and stated that the dib has consistently reviewed cost - benefit analyses before approving cmas and that no change in agency practices was needed .

however , our review of ed's eight cost - benefit analyses showed that two did not address avoidance of future improper payments and five did not address recovery of improper payments and debts .

given that ed's cost - benefit analyses did not mention these costs , which are key elements of cost savings information , the dib would not have been able to make a full review of costs and benefits to ensure that cost savings information was included in cmas before approving them .

we continue to believe it is important that agency dibs perform comprehensive reviews of cost - benefit analyses to ensure that benefits outweigh costs .

dhs stated that it will work to update its guidance concerning cmas and the dib and that it plans to update instructions on implementing policies and procedures for cost - benefit analyses to include the key elements we identified .

in addition , the dhs privacy office plans to update its cma process to clarify the dib's responsibilities in assessing cost - benefit analyses and ensure the dib reviews and reports annually on its computer matching program .

in addition to dhs's written comments , a dhs privacy official provided technical comments in an e - mail , which we have incorporated as appropriate .

labor concurred with our recommendations and provided technical comments .

we have taken labor's comments into consideration and updated the report as appropriate .

labor also stated that it agreed that the computer matching process is both lengthy and resource - intensive , and we have noted this in the report .

va stated that it would revise its current policy to include the key elements of cost - benefit analyses within the next 12 months .

furthermore , va also plans to ensure that the dib reviews cost - benefit analyses to make certain that cost savings information is included in cmas before approval .

ssa stated that it is currently working on an initiative to improve its cost - benefit analysis process and will ensure that all cmas comply with the act's requirements and omb's guidance .

in addition , ssa said it will ensure that the dib receives cost - benefit analyses for proposed computer matching programs that include cost savings information prior to approval .

lastly , ssa stated that it agrees that its dib should conduct an annual review but would defer to omb with regard to complying with the requirement that the dib report annually .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to interested congressional committees , the director of omb , the secretary of treasury and the heads of the seven agencies in our review .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-6244 or wilshuseng@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix viii .

the objectives of our review were to ( 1 ) determine agencies' responsibilities under the computer matching act , ( 2 ) determine how selected agencies are implementing that act with regard to federal benefits programs , and ( 3 ) describe the views of officials at selected agencies on the process of developing and implementing computer matching agreements ( cma ) .

to describe agencies' responsibilities under the computer matching act , we reviewed the law , as well as other relevant laws , policies , and guidance that address computer matching for program integrity purposes .

we also interviewed agency officials and examined agency documents on computer matching programs and processes .

we focused on federal agencies with the highest expenditures in benefits and assistance programs , specifically the departments of agriculture ( usda ) , education ( ed ) , health and human services ( hhs ) , homeland security ( dhs ) , and veterans affairs ( va ) , and the social security administration ( ssa ) .

we added the department of labor ( labor ) because it oversees significant employment benefit programs and there were some indications that the labor office of inspector general ( oig ) had faced challenges in using cmas .

labor is also one of the 10 federal agencies with the highest expenditures in benefits and assistance programs .

we also reviewed guidance developed by the office of management and budget ( omb ) on computer matching .

in addition , we obtained information from the department of the treasury on the do not pay working system and the do not pay initiative , and their relationship to the computer matching provisions of the privacy act .

we analyzed the requirements of the act and omb guidance and confirmed with agency officials the typical process for conducting computer matching programs .

in addition , while the provisions of the act established procedural safeguards for benefit programs and federal personnel management , we mainly focused on requirements for agencies to establish or verify eligibility for federal benefits .

to determine selected agencies' implementation of the act with regard to federal benefits programs , we compared the requirements of the act with agencies' computer matching agreements , including accompanying cost - benefits analyses and documentation of agency processes for reviewing the draft agreements .

specifically , we examined computer matching agreements to determine if the agreements contained information required by the act .

in addition , we reviewed the accompanying cost - benefit analyses to determine if they contained relevant information to conclude that the matching program was beneficial to the agency .

specifically we reviewed the 1986 gao report for criteria on cost - benefit analyses since omb guidance refers agencies to it and because agencies we reviewed used it .

we selected four key elements of costs and benefits ( cost: personnel and computer costs ; benefits: avoidance of future improper payment and recovery of improper payments and debts ) and determined whether the agencies' cost - benefit analyses included these key elements .

we also reviewed the activities and documentation of the data integrity boards ( dib ) to determine if they followed the requirements of the law .

specifically , we examined the structure of the dibs and determined whether they disapproved cmas that included cost - benefit analyses that lacked key elements .

also , we reviewed the reporting requirements of the dibs to determine if they issued computer matching reports as required .

we also reviewed omb's guidance and queried agency officials to determine whether they interpreted the guidance consistently .

to describe the views of officials at selected agencies on the process of developing and implementing cmas , we interviewed agency officials and inspectors general to determine how they implemented the act's computer matching provisions .

furthermore , we solicited these officials' views on the requirements of the act and whether they thought improvements could be made .

we conducted this performance audit from january 2013 to january 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the individuals named above , key contributions to this report were made by john de ferrari ( assistant director ) , wilfred b. holloway , tammi n. kalugdan , lee a. mccracken , mimi nguyen , david f. plocher , and tina m. torabi .

