the mission of the department of transportation's ( dot ) federal motor carrier safety administration ( fmcsa ) is to reduce crashes , injuries , and fatalities involving the more than 500,000 commercial motor carriers ( i.e. , large trucks and buses ) operating in the united states .

information technology ( it ) systems and infrastructure serve as a key enabler for fmcsa to achieve its mission of preventing crashes and saving lives .

the agency reported spending about $46 million for its it investments in fiscal year 2016 .

the fixing america's surface transportation act , which was enacted in december 2015 , included a provision calling for us to review fmcsa's it , data collection , and management systems .

our specific objectives were to ( 1 ) assess the extent to which the agency has plans to modernize its existing systems , ( 2 ) assess the extent to which fmcsa has implemented an it governance structure , and ( 3 ) determine the extent to which fmcsa has ensured selected it systems are effective .

to address the first objective , we obtained and evaluated fmcsa documentation on modernizing its systems , including its it strategic plan and it modernization plans .

we analyzed whether these plans complied with best practices for it strategic planning that we have previously identified .

these practices include developing a strategic plan that defines the agency's vision and provides a road map to help align information resources with business strategies and investment decisions .

we also interviewed agency officials in the office of information technology ; and the enforcement and compliance , information security , and privacy divisions , among others , to discuss the agency's plans to modernize existing systems .

to address the second objective , we evaluated agency documentation , including executive board meeting minutes and briefings , charters , and governance orders , against critical processes found in gao's it investment management framework that provides a method for evaluating and assessing how well an agency is selecting and managing its it resources .

we specifically focused on key processes identified in the framework for instituting an investment board to manage its investments , selecting and reselecting investments that meet business needs , and providing investment oversight .

we also interviewed agency officials in the office of information technology ; and the enforcement and compliance , information security , and privacy divisions to better understand fmcsa's governance structure .

to address the third objective , we selected existing it systems to determine the extent that fmcsa has ensured they are effectively meeting the needs of the agency .

in selecting these systems , we identified the systems in fmcsa's fiscal year 2016 it portfolio summary submitted to the office of management and budget ( omb ) that had planned operations and maintenance ( o&m ) spending funds for fiscal year 2017 .

our criteria focused on selecting at least one major system , as defined by omb ; and at least one mission critical system , as defined by fmcsa .

further , we aimed to select systems that were not included in a recent gao or inspector general review that examined program effectiveness .

based on these criteria , we selected four investments for our review: aspen is a non - major investment that is a desktop application which collects commercial driver / vehicle inspection details and creates and prints a vehicle inspection report .

in fiscal year 2016 , the agency reported that o&m costs for aspen was $138,000 .

motor carrier management information system ( mcmis ) is a non - major information system that captures data from field offices and is the authoritative source for inspection , crash , compliance review , safety audit , and registration data .

in fiscal year 2016 , the agency reported that the o&m cost for mcmis was $221,000 .

safety enforcement tracking and investigation system ( sentri ) is a non - major investment that is currently used to facilitate safety audits conducted by fmcsa and state users .

fmcsa program officials told us that sentri involves two primary components: the new entrant program component that has been operational since may 2010 and the compliance , safety , and accountability component that is currently under development ( also known as sentri 2.0 and sentri 2.1 , respectively ) .

in fiscal year 2016 , fmcsa reported spending about $3.1 million on sentri , of which about $138,000 was spent on o&m for the existing component .

unified registration system ( urs ) is a major system that , when fully deployed , is intended to replace existing registration systems with a single comprehensive , online system and provide fmcsa - regulated entities a more efficient means of submission and manipulation of data pertaining to registration applications .

the system is expected to be delivered in three phases: the first phase was delivered in march 2014 , the second phase was delivered in december 2015 , and the delivery of the final phase is to be determined .

in fiscal year 2016 , fmcsa reported spending about $3.8 million on urs , of which about $332,000 was for o&m of the capabilities already delivered .

we compared fmcsa's it documentation on the performance of the selected systems ( i.e. , business cases and performance management reviews ) to omb criteria on operational analysis that provides guidance to help agencies ensure their existing investments are effective .

we also conducted interviews with selected users to obtain their insight into whether the identified systems were meeting their needs and whether they had faced any challenges in using these systems .

specifically , based on recommendations from agency officials in the office of information technology ; the enforcement and compliance , information security , and privacy divisions ; and industry stakeholder representatives , we selected 22 system users from the following groups: fmcsa users , state agencies , law enforcement officials , and private sector individuals involved in the motor carrier industry .

our selection included at least one representative from each of these user groups .

additional details on our objectives , scope , and methodology are contained in appendix i .

we conducted this performance audit from april 2016 to july 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

fmcsa was established within dot in january 2000 and was tasked with promoting safe commercial motor vehicle operations and preventing large truck and bus crashes , injuries , and fatalities .

the commercial motor carrier industry is a vital part of the u.s. economy and , as of december 2015 , fmcsa estimated that there were 551,150 active carriers and approximately 6 million commercial drivers operating in the united states .

the domestic commercial motor carrier industry covers a range of businesses , including private and for - hire freight transportation , passenger carriers , and specialized transporters of hazardous materials .

these carriers also range from small carriers with only one vehicle that is owned and operated by a single individual , to large corporations that own thousands of vehicles .

in carrying out its mission , fmcsa is responsible for four key safety service areas .

registration services: motor carriers are required to register with fmcsa ; have insurance ; and attest that they are fit , willing , and able to follow safety standards .

vehicles must be properly registered and insured with the state of domicile and are subject to random and scheduled inspections by both state and fmcsa agents .

drivers must have a valid commercial driver's license issued by their state of residence and pass a physical examination as evidenced by a current valid medical card every 2 years .

in calendar year 2015 , there were 57,358 active interstate new entrant carriers that registered with fmcsa .

inspection services: conducting roadside inspections is central to fmcsa's mission .

states and , to a lesser extent , fmcsa staff , perform roadside inspections of vehicles to check for driver and maintenance violations and then provide the data from those inspections to the agency for analysis and determinations about a carrier's safety performance .

fmcsa also obtains data from the reports filed by state and local law enforcement officers when investigating commercial motor vehicle accidents or regulatory violations .

the agency provides grants to states that may be used to offset the costs of conducting roadside inspections and improve the quality of the crash data the states report to it .

in addition , the field offices in each state , known as divisions , have investigators who conduct compliance reviews of carriers identified by state inspection and other data as unsafe or at risk of being unsafe .

fmcsa and its state partners conduct about 3.4 million inspections a year .

compliance services: fmcsa monitors and ensures compliance with regulations governing both safety and commerce .

the compliance review process is performed by safety auditors and investigators who collect safety compliance data by visiting a motor carrier's location to review safety and personnel records .

in the instances of new carriers entering the commercial market , fmcsa audits these carriers within 12 months of service .

in 2015 , fmcsa conducted 14,656 investigations and 30,000 new entrant safety audits , and sent about 21,000 warning letters .

fmcsa uses data collected from motor carriers , federal and state agencies , and other sources to monitor motor carrier compliance with the federal motor carrier safety regulations and hazardous materials regulations .

these data are also used to evaluate the safety performance of motor carriers , drivers , and vehicle fleets .

the agency uses the data to characterize and evaluate the safety experience of motor carrier operations to help federal safety investigators focus their enforcement resources by identifying the highest - risk carriers , drivers , and vehicles .

enforcement services: fmcsa is responsible for bringing legal action against companies that are not in compliance with motor carrier safety policies .

in fiscal year 2015 , fmcsa closed 4,766 enforcement cases .

fmcsa's estimated budget for fiscal year 2017 is approximately $794.2 million .

the agency employs more than 1,000 staff members who are located in its washington , d.c. , headquarters , 4 regional service centers , and 52 division offices .

fmcsa's chief information officer ( cio ) oversees the development , implementation , and maintenance of the it systems and infrastructure that serve as the key enabler in executing fmcsa's mission .

the cio reports directly to the chief safety officer within fmcsa's office of information technology .

this office supports a highly mobile workforce by operating the agency's field it network of regional and state service centers , and ensuring that inspectors have the tools and mobile infrastructure necessary to perform their roadside duties .

in addition , the office supports fmcsa headquarters , regional , and state service centers , which depend on the agency's it infrastructure including servers , laptops , desktops , printers , and mobile devices .

currently , the office of information technology is undergoing a reorganization to establish an office of the cio .

while a revised structure has been proposed , it has not yet been approved .

of its total budget , in fiscal year 2017 , fmcsa's expected it budget is $58 million , of which approximately 60 percent ( $34.4 million ) is to be spent on the o&m of existing systems .

in fiscal year 2013 , the office of information technology led an effort to establish a new it portfolio that was intended to provide fmcsa with the ability to look across the investments in these portfolios and identify the linkages of business processes and strategic improvement opportunities to enhance mission effectiveness .

to do so , the office implemented a product development team to integrate activities within and across the portfolio , interacting with business and program stakeholders .

specifically , it established four key safety process areas — registration , inspection , compliance , and enforcement — and two operations process areas — mission support systems and infrastructure .

the registration portfolio includes systems that process and review applications for operating authority .

the inspection portfolio includes systems that aid inspectors in conducting roadside inspections of large trucks and buses and ensure inspection data are available and useable .

the compliance portfolio includes systems that help investigators to identify and investigate carriers for safe operations and maintain high safety standards to remain in the industry .

the enforcement portfolio includes systems to assist the agency in ensuring that carriers and drivers are operating in compliance with regulations .

the mission support portfolio includes systems and services that crosscut multiple portfolios .

the infrastructure portfolio includes those systems that provide support services , hardware , software , licenses , and tools .

as of august 2016 , fmcsa had identified and categorized 40 investments in its it portfolio , as described in table 1 .

according to the acting cio , by creating the it portfolio , the agency determined that the functionality of these investments was not redundant , but that the aging legacy systems were in need of modernization .

further , the acting cio stated that the agency is planning to consolidate many of the systems that are in o&m , which , as of fiscal year 2016 , had a combined cost of $2.9 million .

fmcsa has acknowledged the need to upgrade its aging systems to improve data processing and data quality , and reduce system maintenance costs .

accordingly , in 2013 , it began a modernization effort that includes both developing new systems and retiring legacy systems for each of its four key safety process areas — registration , inspection , compliance , and enforcement .

to modernize its registration systems , in 2013 , the agency began developing the urs system to streamline and strengthen the registration process .

when fully implemented , urs is intended to replace the current registration systems with a single , online federal system .

program officials stated that the licensing and insurance system , operations authority management system , and the registration function in mcmis are to be retired upon urs's deployment .

the acting cio stated that the agency has not determined when urs will be fully deployed .

to modernize its inspection systems , fmcsa began planning efforts in 2014 to develop integrated inspection management system ( iims ) , which is intended to provide inspectors with a single system to perform checks .

as of may 2017 , the agency was still in the planning stage of this effort , as it was assessing the current state of its inspection processes and data management systems , and planning to issue a report detailing actions the agency needs to take .

according to officials from the office of information technology , subsequent to this report , a detailed analysis will be conducted , including development of acquisition and development plans .

according to agency officials , its six operational inspection systems — query central , safety and fitness electronic records , safetynet , aspen , inspection selection system , and commercial driver's license information system access — are intended to be retired upon deployment of iims .

to modernize its compliance systems , fmcsa began developing sentri 2.1 .

according to the acting cio , the agency's three legacy compliance systems — provu , national registry of certified medical examiners , and compliance analysis and performance review information — are to be retired upon deployment of sentri 2.1 .

as of may 2017 , agency officials from the office of information technology stated they have stopped the development of sentri 2.1 .

to modernize its enforcement systems , fmcsa intends to migrate the functionality of its current enforcement systems into an existing mission support system .

specifically , the functionality of fmcsa's three operational enforcement systems — caserite , electronic management information system , and uniform fine assessment — is to be migrated into its portal system , which is a website that provides users a single sign - on to access applications .

the agency did not provide a date for when this effort is expected to be completed .

a federal agency's ability to effectively and efficiently maintain and modernize its existing it environment depends , in large part , on how well it employs certain it management controls , including strategic planning .

strategic planning is essential for an agency to define what it seeks to accomplish , identify strategies to efficiently achieve the desired results , and effectively guide modernization efforts .

key elements of it strategic planning include establishing a plan with well - defined goals , strategies , measures , and timelines to guide these efforts .

our prior work stressed that an it strategic plan should define the agency's vision and provide a road map to help align information resources with business strategies and investment decisions .

additionally , as we have previously reported , effective modernization planning is essential .

such planning includes defining the scope of the modernization effort , an implementation strategy , and a schedule , as well as establishing results - oriented goals and measures .

however , fmcsa lacks complete plans to guide its systems modernization efforts .

specifically , the agency's it strategic plan lacks key elements .

while the agency has an it strategic plan that describes the technical strategy , vision , mission , and direction for managing its it modernization programs , and defines the strategic goals and objectives to support its mission , the plan lacks timelines to guide its goals and strategies related to integrated project planning and execution , it security , and innovative it business solutions , among others .

for example , there were no identified milestones for achieving efficient , consolidated , and reliable it solutions for it modernization that meet the changing business needs of users and improve safety .

the acting cio acknowledged that the strategic plan is not complete and that a date by which a revised plan will be completed has not been established .

the official further acknowledged that updating the current strategic plan has not been a priority .

however , until the agency establishes a complete strategic plan , it is likely to face challenges in aligning its information resources with its business strategies and investment decisions .

in addition , fmcsa has not yet developed an effective modernization plan that defines the overall scope , implementation strategy , and schedule for its efforts .

according to the acting cio , the agency has recognized the need for such a plan and has recently awarded a contract to develop one by june 2017 .

if fmsca develops an effective modernization plan and uses it to guide its efforts , it should be better positioned to successfully modernize its aging legacy systems .

gao's it investment management framework is comprised of five progressive stages of maturity that mark an agency's level of sophistication with regard to its it investment management capabilities .

such capabilities are essential to the governance of an agency's it investments .

at the stage 2 level of maturity , an agency lays the foundation for sound it investment management to help it attain successful , predictable , and repeatable investment governance processes at the project level .

these processes focus on the agency's ability to select , oversee , and review it projects by defining and developing its it governance board ( s ) and documented processes for directing the governance boards operations .

according to the framework , stage 2 includes the following three processes: instituting the investment board: as part of this process , an agency is to establish an investment review board comprised of senior executives , including the agency's head or a designee , the cio or other senior executive representing the cio's interests , and heads of business units that are responsible for defining and implementing the department's it investment governance process .

the agency's it investment process guidance should lay out the roles of investment review boards , working groups , and individuals involved in the agency's it investment processes .

selecting investments that meet business needs: as part of the process for selecting and reselecting investments , an agency is to establish and implement policies and procedures made by senior executives that meet the agency's needs .

this includes selecting projects by identifying and analyzing projects' risks and returns before committing any significant funds to them and selecting those that will best support the agency's mission needs .

providing investment oversight: this process includes establishing and implementing policies and procedures for overseeing it projects by reviewing the performance of projects against expectations and taking corrective action when these expectations are not being met .

fmcsa has partially addressed the three processes associated with having a sound governance structure to manage its modernization efforts .

table 2 provides a summary of the extent to which the agency's it investment management structure implemented the key processes .

with regard to establishing an it investment review board , fmcsa recently restructured its governance boards .

specifically , in january 2017 , fmcsa finalized its it governance order to have three major governance boards that are to serve as the decision - making structure for how it investment decisions are made and escalated — the executive management team , the technical review board , and the change control board .

at the highest level , the executive management team is to provide strategic direction and decision making for major it investments .

the team , which is to meet at least quarterly , is chaired by the fmcsa deputy administrator .

below this team , the technical review board is to provide oversight for all it investments and is chaired by the director of the office of information technology policy , plans , and oversight .

according to the governance order , this team is to meet monthly .

further , underneath the technical review board is the change control board that has responsibility for reviewing and approving system change requests associated with a new system , a major release or modification to an existing system , a change in contract funding , or a change in contract scope .

this board , which also is to meet monthly , is chaired by the enterprise architect of the office of information technology policy , plans , and oversight .

figure 1 depicts the agency's governance structure .

nevertheless , fmcsa has not yet clearly defined roles and responsibilities of all working groups and individuals involved in the agency's it governance process .

for example , fmcsa's governance order calls for the office of information technology policy , plans , and oversight to adopt specific it performance measures , but does not define the manner in which these measures should be tracked .

moreover , in august 2016 , the agency finalized an order that established 10 integrated functional areas of it management and the development of an office of the cio .

however , fmcsa has not yet finalized a new structure for the office of the cio or clearly defined how this office and the cio will manage , direct , and oversee the implementation of these areas as it relates to the agency's it governance process .

further , fmcsa officials have not identified time frames for doing so .

without clearly defined roles and responsibilities for the agency's working groups and individuals involved in the governance process , fmcsa has less assurance that its modernization investments will be reviewed by those with the appropriate authority and aligned with agency goals .

with regard to selecting and reselecting it investments , fmcsa's january 2017 governance order requires participation and collaboration of the it system owner , business owner , it planning staff , and governance boards during the select phases for all investments .

however , the agency lacks procedures for selecting new modernization investments and for reselecting investments that are already operational ( which makes up the majority of the agency's it portfolio ) for continued funding .

for example , the order calls for the executive management team , comprised of senior executives , to make decisions regarding the funding of the it portfolio , among other things , and for the technical review board to provide recommendations to the team on the prioritization of it investments including the allocation of funds .

however , the order does not specify the procedures for approving the movement of funds within the it and capital planning and investment control portfolio .

according to the acting cio , fmcsa is currently drafting procedures for selecting new investments and reselecting investments that are already operational and intends to finalize the procedures by the end of may 2017 .

upon establishing and implementing such procedures , fmcsa's decision makers should have a common understanding of the process and the cost , benefit , schedule , and risk criteria that will be used to reselect it projects .

with regard to it investment oversight , the agency's order established policies and procedures to ensure that governance bodies review investments and track corrective actions to closure .

however , the policies and procedures for reviewing and tracking actions have not yet been fully implemented by the three governance bodies .

for example , the boards have not met regularly to review the performance of it investments , including those investments that are part of its modernization efforts , against expectations .

in particular , in calendar year 2016 , the executive management team met once and the technical review board met four times .

the change control board was not formally approved until january 2017 and , thus , has held no meetings .

also , while the technical review board met four times in calendar year 2016 , none of the meetings discussed the cost , schedule , performance , and risks for fmcsa's major it modernization investment , systems in development , or existing systems .

for example , in february 2016 , the it director presented to the board members an overview of the statutory provisions commonly referred to as the federal information technology acquisition reform act and their implications for fmcsa .

in april 2016 , the board members were provided with an overview of omb's regulatory guidance for the budget process .

in addition , in august 2016 , the technical review board met to discuss the planned fiscal year 2017 budget for its it investments and , in november 2016 , the director of the office of information technology discussed with board members the status of the planning efforts for the iims project .

the acting cio did not attend any of the four meetings .

further , neither the executive management team nor the technical review board discussed with its members the transition of fmcsa's investments into the cloud environment , to include identifying any key risks .

for example , in november 2016 , over 70 issues regarding the migration effort were identified by the contractor and a fmcsa official , but none were discussed at the technical review board or executive management team board meetings .

as a result , program officials stated that there were delays to program's transition to the cloud environment because additional time was needed to securely migrate data from multiple legacy platforms into a new central database and conduct further testing .

action items have been noted in meeting minutes , but have not been fully addressed or updated to closure .

for example , in august 2016 , the capital planning and investment control coordinator , within the office of information technology , provided an overview of the fiscal year 2017 budget to the technical review board members .

as part of this discussion , the director of the office of information technology stated that , during the next board meeting , additional details would be provided on the planned budget for fiscal year 2018 .

however , the meeting minutes from november 2016 did not include any evidence that this subject was discussed at the next meeting .

these weaknesses were due , in part , to the agency not adhering to its it orders and governance board charters , which establish fmcsa's governance structure , as described above .

as a result , the agency lacks adequate visibility into and oversight of it investment decisions and activities , and cannot ensure that its investments are meeting cost and schedule expectations and that appropriate actions are taken if these expectations are not being met .

according to omb guidance , the o&m phase is often the longest phase of an investment and can consume more than 80 percent of the total lifecycle costs .

thus , it is essential that agencies effectively manage this phase to ensure that the investments continue to meet agency needs .

as such , omb and dot direct agencies to monitor all o&m investments through operational analyses , which should be performed annually .

these analyses should include assessments of four key factors: costs , schedules , investment performance ( i.e. , structured assessments of performance goals ) , and customer and business needs ( i.e. , whether the investment is still meeting customer and business needs , and identifies any areas for innovation in the area of customer satisfaction ) .

fmcsa had not fully ensured that the selected systems — aspen , mcmis , sentri 2.0 , and urs — were effectively meeting the needs of the agency .

specifically , none of the program offices conducted the required operational analyses for the four systems .

the program offices stated that , in lieu of conducting these analyses , they assessed the key factors of costs , schedules , investment performance , and customer and business needs as part of the capital planning and investment control process .

nonetheless , only one program office ( urs ) partially met the four key factors .

table 3 provides a summary of the extent to which the four selected systems implemented the key operational analysis factors .

aspen: the aspen program office had partially implemented one of the required operational analysis factors and had not implemented the three other factors .

specifically , as part of its plans to modernize this system , fmcsa had taken steps to assess customer and business needs .

for example , it reached out to users and found that 33 states use aspen and the remaining states use their own in - house developed programs or third - party vendor - based systems .

however , while the agency collected feedback from users via phone calls and meetings , it had not yet assessed this feedback , including identifying any opportunities for innovation in the areas of customer satisfaction , strategic and business results , and financial performance .

in addition , the program office did not assess current costs against life - cycle costs , perform a structured schedule assessment , or compare current performance against cost baseline and estimates developed when the investment was being planned .

mcmis: the mcmis program office had not implemented any of the required operational analysis factors .

specifically , program officials did not assess current costs against life - cycle costs , perform structured assessments of schedule and performance goals , or identify whether the investment supports business and customer needs and is delivering the services it was designed to , including identifying whether the system overlaps with other systems .

this is particularly concerning given that all seven users we interviewed stated that the system does not interact well with other systems and users have to access other systems to gather information that they cannot obtain in mcmis .

sentri 2.0: sentri's program office partially implemented one of the required operational analysis factors and did not implement the three other factors for the component that has been operational since may 2010 , also known as sentri 2.0 .

specifically , the program had partially implemented assessments of customer and business needs by reviewing sentri 2.0 user needs as it develops the business and user requirements for development of sentri 2.1 .

however , while all five users we interviewed stated that their feedback regarding sentri was provided to fmcsa , they were not sure whether the feedback was being implemented .

moreover , the program office had not identified whether the investment supports customer processes , as designed , and is delivering the goods and services it was intended to deliver .

in addition , the program did not assess current costs against life - cycle costs or perform structured schedule and performance goal assessments .

urs: the urs program office partially implemented four of the required operational analysis factors for functionality of the system that was delivered in december 2015 .

specifically , the program office developed a business case that outlines costs , schedules , investment performance goals , and customer and business needs .

additionally , the program office communicated with stakeholders through meetings , conferences , webinars , and call centers .

for example , it has hosted over 30 webinars to better understand how the system is working for the users .

nevertheless , the program office had not yet conducted an analysis to assess current costs against life - cycle costs , performed a structured assessment of the schedule or performance goals , or ensured the functionality delivered is operating as intended and is meeting user needs .

the need for conducting an analysis is particularly pressing for this program since all four system users we interviewed stated that urs is difficult to use and does not work as intended: they stated that they are unable to complete filings , carrier registration , and request changes to dot numbers .

with regard to the deficiencies we identified , the acting cio stated that the agency does not yet have fmcsa - specific guidance to assist programs to conduct operational analyses on an annual basis .

the acting cio stated that fmcsa has drafted guidance , including templates , to assist programs in conducting these analyses and officials in the office of information technology stated that the agency planned to have the guidance finalized by end of june 2017 .

while finalizing this guidance is a positive step to assist programs in conducting operational analyses , fmcsa does not adequately ensure its systems are effective at meeting user needs .

until fmcsa fully reviews its o&m investments as part of its annual operational analyses , the agency will lack assurance that these systems meet mission needs , and the associated spending could be wasteful .

while fmcsa has recognized the need to develop an effective modernization plan and has awarded a contract to do so , it has not completed an it strategic plan needed for modernizing its existing legacy systems .

in addition , while the agency has established governance boards for overseeing it systems , these boards do not exhibit key processes of a sound governance approach , such as ensuring corrective actions are executed and tracked to closure .

further , fmcsa does not have the processes in place for ensuring that systems currently in use are meeting agency needs or for overseeing its it portfolio .

the four systems we reviewed did not have completed operational analyses that show if a system is , among other things , effective at meeting users' needs .

until the agency addresses shortcomings in strategic planning , it governance , and oversight , its progress in modernizing its systems will likely be limited and the agency will be unable to ensure that the systems are working effectively .

to help improve the modernization of fmcsa's it systems , we are recommending that the secretary of transportation direct the fmcsa administrator to take the following five actions: update fmcsa's it strategic plan to include well - defined goals , strategies , measures , and timelines for modernizing its systems .

ensure that the it investment process guidance lays out the roles and responsibilities of all working groups and individuals involved in the agency's governance process .

finalize the restructure of the office of information technology , including fully defining the roles and responsibilities of the cio .

ensure that appropriate governance bodies review all it investments and track corrective actions to closure .

ensure that required operational analyses are performed for aspen , mcmis , sentri 2.0 , and urs on an annual basis .

we provided a draft of this report to the department of transportation for review and comment .

in its written comments , reproduced in appendix ii , the department concurred with our five recommendations .

the department also described actions that fmcsa has completed or is finalizing to improve its it strategic planning and investment governance processes .

these actions include updating the fmcsa it strategic plan and finalizing investment review board charters to better define all stakeholders roles and responsibilities .

effective implementation of these actions should help fmcsa improve the modernization of its it systems .

in addition to the written comments , the department provided technical comments on the draft report , which we incorporated as appropriate .

we are sending copies of this report to the appropriate congressional committees , the secretary of transportation , the administrator of fmcsa , and other interested parties .

this report also is available at no charge on the gao website at http: / / www.gao.gov .

should you or your staff have any questions on information discussed in this report , please contact me at ( 202 ) 512-4456 or harriscc@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iii .

the fixing america's surface transportation act included a provision for us to conduct a comprehensive analysis of the information technology ( it ) and data collection management systems of the federal motor carrier safety administration ( fmcsa ) by june 4 , 2017 .

our objectives were to ( 1 ) assess the extent to which the agency has plans to modernize its existing systems , ( 2 ) assess the extent to which fmcsa has implemented an it governance structure , and ( 3 ) determine the extent to which fmcsa has ensured selected it systems are effective .

to address the first objective , we obtained and evaluated fmcsa it systems modernization documentation that discuss future changes to ensure user needs are met , including its it strategic plan for fiscal years 2014 to 2016 and systems modernization plans .

we analyzed whether these plans complied with best practices that we have previously identified .

these practices call for developing a strategic plan that includes defining the agency's vision and providing a road map to help align information resources with business strategies and investment decisions .

we also interviewed agency officials including those from the office of information technology ; enforcement and compliance , information security , and privacy divisions to discuss the agency's plans to modernize existing systems , including any actions the agency is taking to identify redundancies among the systems and explore the feasibility of consolidating data collection and processing systems .

to corroborate this information , we reviewed the fmcsa's budgetary data ( i.e. , its fiscal year 2016 it portfolio summary ) submitted to the office of management and budget ( omb ) that identifies all of the agency's it investments to identify whether it included any potentially redundant systems .

specifically , we reviewed the name and narrative description of each investment's purpose to identify any similarities among related investments and discussed any potential redundancies with the acting chief information officer ( cio ) .

for the second objective , we compared agency documentation , including executive board meeting minutes and briefings from fiscal years 2015 and 2016 , fmcsa it governance orders , and charters , against critical processes associated with stage 2 of gao's it investment management framework .

in particular , stage 2 of the framework includes the following key processes for effective governance: instituting the investment board ; selecting and reselecting investments that meet business needs ; and providing investment oversight .

we also interviewed agency officials to better understand fmcsa's governance structure , which included identifying whether the agency is taking appropriate steps with respect to it governance .

to address the third objective , we selected four existing it systems to review .

in selecting these investments , we analyzed fmcsa's fiscal year 2016 it portfolio summary submitted to omb which included the agency's existing it , data collection , processing systems , data correction procedures , and data management systems and programs .

to assess the reliability of the omb budget data , we reviewed related documentation , such as omb guidance on budget preparation and capital planning .

in addition , we corroborated with fmcsa that the data was accurate and reflected the data it had reported to omb .

we determined that the budget data was reliable for our purposes of selecting these systems .

specifically , we used the following criteria to select four systems to review: at least one investment must have been identified as a major it investment , as defined by omb .

fmcsa had only identified one major it investment in fiscal year 2016 .

the remaining non - major systems must have had planned operations and maintenance ( o&m ) spending in fiscal year 2017 .

the system is mission critical .

the program must not have been included in a recent gao or inspector general review that examined the program's effectiveness .

using the above criteria , we selected the following four systems: 1 .

aspen: a non - major desktop application that collects commercial driver / vehicle inspection details , performs some immediate data analysis , creates and prints a vehicle inspection report , and transfers inspection data into the fmcsa information systems .

2 .

motor carrier management information system ( mcmis ) : a non - major information system that captures fmcsa inspection , crash , compliance review , safety audit , and registration data .

it is fmcsa's authoritative source for the safety performance records for all commercial motor carriers and hazardous materials shippers .

3 .

safety enforcement tracking and investigation system ( sentri ) : a non - major application used to facilitate safety audits and interventions by fmcsa and state users .

it is intended to combine roadside inspection , investigative , and enforcement functions into a single interface .

4 .

unified registration system ( urs ) : a major system that is intended to replace the existing registration systems with a single comprehensive , online system and provide fmcsa - regulated entities a more efficient means of submission and management of data pertaining to registration applications .

we then assessed the agency's efforts to determine the effectiveness of these systems in meeting the needs of the agency by reviewing documentation from the four selected systems and compared it to key factors identified in omb's guidance on conducting annual operational analysis , which are a key method for examining the performance of investments with o&m funding .

more specifically , we assessed whether fmcsa had conducted an operational analysis on each of the systems .

for those systems that did not have an analysis performed , we reviewed fmcsa's it documentation on the performance of these systems ( i.e. , business cases and performance management reviews ) to determine whether key factors of an operational analysis were conducted .

for example , we assessed whether the agency assessed cost , schedule , and investment performance , including its interaction with other systems ; and customer and business needs , including adaptability of the system in order to make necessary future changes to ensure user needs are met and areas for innovation in the areas of customer satisfaction .

we also conducted interviews with 22 selected system users to obtain insight into whether the identified systems are meeting their needs and any challenges users face in using these systems , including whether the systems are adaptable to future needs and methods to improve user interface .

we selected these users based on recommendations from fmcsa program officials and industry stakeholder representatives .

based on these recommendations , we then selected users based on the type of users , including fmcsa users , state agencies , law enforcement officials , and private sector individuals involved in the motor carrier industry .

while these user interviews are illustrative , they cannot be used to make generalizable statements about users' experience as a whole .

based on our work to determine selected programs' effectiveness , we made recommendations regarding deficiencies identified in the report .

we did not make recommendations regarding methods to improve user interfaces since two of the selected systems ( aspen and mcmis ) are planned to be modernized and the remaining two systems ( sentri and urs ) have components still under development , as discussed in our report .

we conducted this performance audit from april 2016 to july 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact name above , the following staff also made key contributions to this report: eric winter ( assistant director ) , niti tandon ( analyst in charge ) , rebecca eyler , lisa maine , and tyler mountjoy .

