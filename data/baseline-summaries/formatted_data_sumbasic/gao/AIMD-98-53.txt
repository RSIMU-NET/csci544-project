this report presents the results of our review to date of the army's program for solving its year 2000 computer systems problem .

the problem results from the inability of computer programs at the year 2000 to interpret the correct century from a recorded or calculated date having only two digits to indicate the year .

unless corrected , this problem could cause systems to malfunction or produce incorrect information when the year 2000 is encountered during automated data processing .

the impact of these failures could be widespread , costly , and potentially debilitating to army and other department of defense ( dod ) operations .

we performed this work as part of our review of dod's year 2000 computer systems efforts for the chairman of the senate governmental affairs committee ; the chairman and ranking minority member of the subcommittee on government management , information and technology , house committee on government reform and oversight ; and the honorable thomas m. davis , iii , house of representatives .

our objectives were to assess ( 1 ) the status of the army's efforts to identify and correct its systems and ( 2 ) the appropriateness of the army's strategy and actions to remediate its year 2000 problems .

this letter summarizes our concerns and provides recommendations for addressing them .

in conducting our review , we assessed the army's year 2000 efforts against our year 2000 assessment guide .

this guide addresses common issues affecting most federal agencies and presents a structured approach and a checklist to aid in planning , managing , and evaluating year 2000 programs .

the guidance , which is consistent with the dod year 2000 management plan and the army's own year 2000 guidance , describes five phases — supported by program and project management activities — with each phase representing a major year 2000 program activity or segment .

the guide draws heavily on the work of the cio council subcommittee on year 2000 , and incorporates guidance and practices identified by leading organizations in the information technology industry .

the phases and a description of each phase follows .

awareness — define the year 2000 problem and gain executive - level support and sponsorship .

establish a year 2000 program team and develop an overall strategy .

ensure that everyone in the organization is fully aware of the issue .

assessment — assess the year 2000 impact on the enterprise .

identify core business areas and processes , inventory and analyze systems supporting the core business areas , and prioritize their conversion or replacement .

develop contingency plans to handle data exchange issues , lack of data , and bad data .

identify and secure the necessary resources .

renovation — convert , replace , or eliminate selected platforms , applications , databases , and utilities .

modify interfaces .

validation — test , verify , and validate converted or replaced platforms , applications , databases , and utilities .

test the performance , functionality , and integration of converted or replaced platforms , applications , databases , utilities , and interfaces in an operational environment .

implementation — implement converted or replaced platforms , applications , databases , utilities , and interfaces .

implement data exchange contingency plans , if necessary .

to determine the status of the army's year 2000 program and the appropriateness of its strategy and actions for ensuring successful completion , we evaluated dod's office of the assistant secretary of defense for command , control , communications and intelligence ( oasd / c3i ) efforts to provide year 2000 support to the army .

we also evaluated the efforts of the army's office of the director of information systems , command , control , communications , and computers ( disc4 ) to manage and oversee army components' correction of the year 2000 problem .

the disc4 director also serves as the army cio .

specifically , we obtained and reviewed from these offices pertinent year 2000 guidance , project and funding documentation , and date format requirements .

in addition , we reviewed the u.s. army project change of century action plan to assess the level of guidance , roles , and responsibilities and target milestone dates for the year 2000 effort .

further , we met with army officials and analyzed their efforts to address the year 2000 problem at the army materiel command ( amc ) — one of the army's 17 major commands .

we also obtained a copy of the army's october 1997 year 2000 inventory database to evaluate its accuracy , reliability , and usefulness .

the army relies on this database to monitor year 2000 progress and as the source of army information input to the defense integration support tools .

we also reviewed segments of the year 2000 database that amc uses to manage its year 2000 program .

however , because the results of limited data testing showed that these army databases were incomplete and inaccurate , we could not and did not rely on the data to validate year 2000 costs or the numbers of systems reported as being in each year 2000 phase .

we also obtained a copy of the u.s. army year 2000 database user's manual and discussed the specifics of database use and effectiveness with army officials .

in addition , we met with officials from the logistics systems support center ( lssc ) , an army central design activity with responsibility for maintaining the software for the commodity command standard system ( ccss ) — a large standard automated information system — to determine whether lssc officials were receiving year 2000 guidance and other related requirements issued by the oasd / c3i and the army's disc4 .

we also discussed with lssc officials their progress and challenges they face in solving the year 2000 problem .

further , we compared the information they maintained on their efforts with the information disc4 and amc are maintaining for oversight purposes .

lastly , we obtained and analyzed army and amc data to gain an understanding of the size , complexity , and diversity of the army's year 2000 organizational structure .

to help ensure that we were not duplicating other audit agency work , we met with officials of aaa and the army inspector general to determine the objectives and scope of their reviews of the army's year 2000 problem .

we also discussed preliminary results of work performed on the army's year 2000 inventory database with aaa officials .

we conducted our work primarily at the army's disc4 office in fairfax , virginia ; amc headquarters in alexandria , virginia ; and lssc in st. louis , missouri .

our work was performed from november 1996 through february 1998 in accordance with generally accepted government auditing standards .

this work builds upon information included in a series of dod component - level year 2000 reports that have already been issued , including a related report on the army lssc .

we requested and received written comments on a draft of this report from the chief information officer of the department of the army .

these comments are discussed in the “agency comments and our evaluation” section and are reprinted in appendix ii .

many of the army's automated information systems and embedded weapons systems are vulnerable to the year 2000 problem , which is rooted in the way dates are recorded and computed in automated information systems .

for the past several decades , systems have typically used two digits to represent the year , such as “97” representing 1997 , in order to conserve electronic data storage and reduce operating costs .

however , with this two - digit format , the year 2000 is indistinguishable from 1900 , as is 2001 indistinguishable from 1901 .

as a result of this ambiguity , system or application programs that use dates to perform calculations , comparisons , or sorting may generate incorrect results when working with years after 1999 .

should the army's computer systems fail on the morning of the year 2000 , army operations at all levels could be impacted by the incorrect processing of data , as well as corrupted databases , or even massive system failures .

in turn , this could result in such problems as weapons systems failures , delays in supply shipments , faulty inventory forecasts , unreliable budget estimates , and erroneous personnel - related information .

the problem could also lead to a degradation of the army's ability to maintain a readiness posture by seriously slowing or curtailing its ability to sustain the warfighters' vital supplies and information .

like the other military services , the army has adopted the dod year 2000 management strategy , which calls for centralized oversight with decentralized execution of year 2000 corrective actions .

the strategy also adopts dod's five - phased management approach for addressing the year 2000 problem .

the army has assigned responsibility to disc4 for overseeing the year 2000 effort and has charged it with facilitating the sharing of information and best practices and with monitoring army year 2000 progress .

disc4 is the army's primary information resources manager and its director also serves as the army's cio .

as of october 1997 , the army year 2000 project office had eight staff to oversee the army's year 2000 program .

appendix i shows the army's year 2000 organizational structure and depicts the complexity and diversity of the year 2000 program .

it also provides an example of the magnitude of the year 2000 effort at a major command level .

the army began its year 2000 program in december 1995 by establishing a year 2000 project office .

although an official charter was never formulated , the army year 2000 project office was tasked with broad responsibility for providing centralized oversight and management of the army's year 2000 effort .

in march 1996 , the army approved an initial u.s. army project change of century action plan .

this plan , which was revised in october 1996 , formalized the project office's responsibilities , which include establishing army - wide strategies and guidance for addressing the year overseeing army - wide year 2000 planning and monitoring progress ; representing the army in year 2000 discussions with dod and other developing a strategy for army year 2000 cross - functional resource directing the establishment of year 2000 emergency response teams trained and capable of rapidly responding to and assisting with critical operational systems that fail due to year 2000 problems ; chairing an army year 2000 working group to ( 1 ) investigate year 2000 and cross - functional issues , ( 2 ) avoid duplication of effort , ( 3 ) identify and share lessons learned , and ( 4 ) provide recommendations for army - wide improvement ; and establishing and maintaining army year 2000 home pages ( public and restricted ) that contain the army year 2000 systems database and serve as a clearinghouse for year 2000 information .

at the time of our review , the army year 2000 project office had already met many year 2000 challenges .

for example , the project office had ( 1 ) developed an extensive year 2000 plan that specified tasks , goals , and milestones for each phase of year 2000 corrective actions , ( 2 ) established roles and responsibilities for performing the specified tasks , ( 3 ) provided guidance to components for estimating year 2000 costs , and ( 4 ) published year 2000 certification requirements .

the year 2000 plan was updated in october 1996 and revised in january 1998 .

the project office had conducted six army - wide data calls to accumulate important year 2000 information from its components .

early in the awareness phase , it had also established a baseline system inventory that was used to develop and populate the army's current year 2000 system inventory database .

the project office's establishment of an army year 2000 home page enables army components to access systems inventory information .

throughout the effort , the project office has maintained its year 2000 awareness campaign and has emphasized to army organizations the need to report year 2000 information .

in early 1997 , the army took several actions to minimize the adverse impact of the year 2000 problem .

the army's cio requested that aaa help evaluate component needs and identify areas that could cause year 2000 failures .

at the time of our review , aaa had completed phase i of its eight - phase audit coverage and was finishing detailed site work on phase ii .

during phase i , aaa focused on component oversight and management of year 2000 issues and the accuracy , completeness , and utility of the army's year 2000 inventory database .

in the next phases , aaa will assess component progress in remediating , testing , and implementing systems .

this work will include determining the reasonableness of the army's plans for year 2000 testing and contingency planning .

also , the army inspector general is charged with determining the impact of the year 2000 on personal computers and network hardware , local computer programs and applications , and installation infrastructure at the tactical unit and installation level .

further , the army reports that it has supplemented its year 2000 program with contractor staff that are to concentrate on evaluating the year 2000 compliance of army infrastructure items , such as telephone and network switching equipment .

in february 1998 , the army reported that it had 376 mission - critical automated information and embedded weapons systems and 19,731 nonmission - critical systems .

according to the army , 120 mission - critical systems needed to be repaired ; all of these had completed the assessment phase and most were in the renovation phase .

in addition , 12,120 nonmission - critical systems needed to be corrected ; a small number of these were in the assessment phase and over half were in renovation .

as of february 1998 , the army estimated that it would cost $366 million to address its year 2000 problem .

specific totals reported by the army are shown in table 1 .

as discussed later in this report , we question the reliability of this information .

although the army has taken a number of positive steps toward meeting the challenges of the year 2000 problem , it is not effectively managing its year 2000 project .

first , it lacks complete and accurate information on systems , interfaces , year 2000 costs , and the progress of remediation efforts .

until these data are complete and reliable , the army will not have the necessary foundation for managing the year 2000 program .

second , the army is late in preparing interface agreements .

as a result , there is increased risk that key interfaces will not be corrected prior to the year 2000 .

third , the army is behind in developing contingency plans .

without these plans , it will not be able to minimize the impact of year 2000 problems on operations .

fourth , the army has not assessed how much testing capacity is needed and available .

as a result , it is missing opportunities to help ensure that all mission - critical systems will be tested before the year 2000 deadline .

our year 2000 assessment guide , office of management and budget ( omb ) guidance , and dod's year 2000 management plan recognize that a key part of the assessment phase is conducting an enterprisewide inventory of information systems for each business area .

this inventory should include specific information , such as the business processes the systems support , the potential impact on those business processes if systems are not remediated on time , the schedule for remediation efforts , the identification and descriptions of internal and external system interfaces , and the costs of remediation .

this provides the necessary foundation for year 2000 program planning .

the army lacks the accurate and complete data required to effectively manage the year 2000 effort .

specifically , we found that the departmentwide systems inventory maintained by the army year 2000 project office is unreliable due to ( 1 ) poor design of the army's inventory database and ( 2 ) lack of complete information on interfaces , costs , and certifications of year 2000 compliance .

in addition , we reviewed the inventory maintained by the army materiel command ( amc ) and found that the component lacked data on systems , costs , and funding .

the army's inventory database consists of 139 data fields for each system , including hardware make and model and system software ; mission criticality ; system owners ; the number of executable lines of source code ; cost estimates for repair or replacement ; schedule for repair ; business impact ; status certification ; and core business areas supported by the systems .

of the 139 data fields , 24 are binary ; that is , they have possible values of only “yes” or “no.” if any of these fields are left blank , they default to a “no” answer , which may be incorrect .

for example , if a system has been designated as mission - critical , but the binary field for this information is left blank , the inventory will show that the system is not mission - critical .

this logic flaw could lead to inaccurate information .

although we did not determine the extent to which inaccuracies may have occurred , army year 2000 project office officials and aaa considered this to be a problem and believed that this flaw put the reliability of inventory data into question .

although army components have identified 1,009 system interfaces that will be impacted by the year 2000 , the army lacks most of the detailed interface information it needs to monitor and oversee component efforts to ensure that systems data can be exchanged effectively at the year 2000 .

for example , detailed interface information describing the ( 1 ) transfer media ( eg , satellite link , telephone dialup , or diskette ) , ( 2 ) frequency of data exchange ( eg , real time or scheduled periodically ) , ( 3 ) security classification ( eg , unclassified , confidential , or secret ) , and ( 4 ) whether the interface is planned or currently exists had not been provided to the project office for the vast majority of interfaces identified .

specifically , of the 1,009 interfaces identified , 809 were missing data on transfer media , 915 were missing frequency of data exchange information , 917 were missing security classification information , and 911 did not identify whether the interface is planned or currently exists .

at the time of our review , the army reported that it expected to spend about $429 million to correct its year 2000 problem .

however , this estimate was incomplete because ( 1 ) it did not contain cost data for all noncompliant mission - critical systems and ( 2 ) it was not based on a detailed cost analysis .

of the 143 mission - critical systems requiring repair at the time of the october 1997 quarterly report , 45 percent had costs entered by system managers and 52 percent had no costs entered into the army's inventory database .

the costs of the remaining 3 percent were unknown and were not reported in the $429 million .

however , for the 52 percent of the systems where costs had not been entered into the army's inventory database by system managers , year 2000 project office staff computed the costs using the gartner group formula .

this formula recommends multiplying the number of lines of code to be converted by $1.10 for automated information systems and by $8.00 for weapon systems .

dod recommended that components use this formula early in their year 2000 effort to make a rough estimate of costs .

however , this rough estimate was to be refined by conducting a detailed cost analysis based on more than 30 cost factors as the component progressed through the assessment phase and more was learned about its systems and the resources that would be required to fix them .

these include such factors as the age of systems ; skill and expertise of in - house programmers ; the strategy that the agency is pursuing ( strategies that involve keeping the two - digit code , for example , may be much less expensive than those that involve changing the two - digit code to a four - digit code ) ; the clarity and completeness of documentation on systems ; the availability of source code ; and the programming language used .

the difference between an estimate based on a reliable analysis of data collected during the assessment phase and an estimate based on the gartner formula can be significant .

for example , using the gartner formula , in august 1996 the army lssc initially estimated that it would cost $8.4 million to correct ccss .

when it conducted a detailed cost analysis in april 1997 based on data collected during the assessment phase , it estimated that it would cost about $12.4 million — almost 50 percent more than the august 1996 estimate .

recently , the army year 2000 program manager agreed that components need to provide better cost estimates on year 2000 remediation efforts and indicated that some improvement had been made .

for example , the program manager told us that , in january 1998 , the project office had to calculate cost estimates for only about 30 percent of the components' systems compared to calculating cost estimates for over 50 percent of the components' systems in october 1997 .

however , while progress is being reported , in many cases , the gartner formula is still being used to calculate cost estimates .

to provide assurance that systems are thoroughly tested , properly documented , and determined to be compliant , the army is requiring that components complete a compliance checklist of all mission - critical and major systems at the conclusion of the validation phase .

once checklists are completed , the components are to submit them to the army year 2000 project office .

while the army recommends that checklists also be completed for systems that are not mission - critical or major , components are not required to submit completed checklists for them to the project office .

at the time of our review , the army year 2000 project office had not received compliance checklists for any of the 832 mission - critical and major systems contained in its year 2000 database , including 344 systems that components had identified as year 2000 compliant .

in addition , although checklists are to be submitted to the project office after a system has entered the implementation phase , completed certification checklists had not been received for 30 systems reported to be in the implementation phase .

army officials recently informed us that as of march 31 , 1998 , 15 certification checklists had been received by the year 2000 project office .

we reviewed the systems database maintained by amc — the command responsible for developing , buying , and maintaining equipment and supplies for u.s. soldiers and allies worldwide .

amc data have a significant impact on the army's year 2000 effort because amc and its components own approximately 93 percent of the systems the army reported as not being year 2000 compliant .

we found that the amc database lacked important data .

for example , 328 of the 505 amc systems needing year 2000 remediation did not have repair cost estimates .

one of these was the maneuver control system — a mission - critical system used for planning , coordinating , and managing battlefield tactical operations .

as a result of the missing cost data , amc's $196.7 million cost estimate for its year 2000 remediation program was understated .

we also found that another major system , the munitions transportation management system , which helps ensure that correct supplies of munitions are efficiently and effectively transported from port to port worldwide , was missing from the database altogether .

all of these data problems seriously impair the army's ability to effectively manage year 2000 remediation efforts .

for example , the army cannot monitor the progress of remediation efforts , identify areas requiring greater management attention , or adequately analyze and prioritize systems conversion or replacement .

without complete interface information , the army cannot ensure that year 2000 errors are not propagated from one organization's system to another's .

without good cost information , the army cannot make informed choices about information technology priorities and determine whether other system development efforts should be deferred or cancelled so that resources can be freed to solve the year 2000 problem .

without documentation on certification , the army cannot assess whether systems have been verified as compliant .

because the army year 2000 project office did not have effective mechanisms in place to track whether system managers were providing complete and accurate information and to follow up where they were not , the army is taking action to improve its oversight of year 2000 efforts .

specifically , aaa and the army and dod inspectors general are engaged in efforts to help determine the extent of data problems and validate the accuracy and completeness of components' information .

in addition , in october 1997 , the army hired a contractor to improve the inventory database by creating an internet web - based version of the database on the army year 2000 home page that is intended to be easier for the user to update and download .

further , the army cio and the army chief of staff have been communicating to system managers the need to provide complete and accurate data .

while all actions have not yet been completed , these efforts should help encourage better reporting on the part of components and provide the more comprehensive and continued oversight that is needed to establish a complete and accurate picture of remediation efforts .

however , the army year 2000 project office will still need to continuously validate the data submitted by components to ensure the accuracy , completeness , and currency of information in the army year 2000 database .

for system interfaces to work , both sending and receiving interface partners need to know what to send and what to expect from the other .

for example , one system manager may choose to make a system year 2000 compliant by expanding to a four - digit year date , while another may choose to keep the two - digit format and use procedural code or sliding windows as a strategy .

according to current dod guidance , either fix is acceptable , but both parties need to be aware of the differences and any potential conflicts so that they can install the proper data bridge .

our year 2000 assessment guide and dod's year 2000 management plan recommend that written memorandums of agreement ( moa ) with interface partners be initiated during the assessment phase to allow enough time for conflicts to be resolved .

however , although the army reports that all of its mission - critical and major systems have completed the assessment phase , as of january 1998 , army components reported that , of the 627 instances where they had identified the need for interface agreements , only 366 moas had been completed .

in addition , while aaa is in the process of reviewing the existence and quality of components' moas , these efforts have not yet been completed at all locations .

until all moas have been prepared and the quality assessed by aaa , the army is at risk that key interfaces will not work .

to mitigate the risk that year 2000-related problems will disrupt critical business operations , dod's year 2000 management plan , our year 2000 assessment guide , and recent omb directives recommend that agencies perform risk assessments and develop realistic contingency plans for core business functions during the assessment phase .

contingency plans are important because they identify the manual or other fallback procedures to be employed should systems miss their year 2000 deadline or fail unexpectedly in operations .

contingency plans also define the specific conditions that will cause their activation .

while the army has issued guidance requiring that contingency plans be prepared for all critical systems and activities , it has not yet completed the development of these plans .

as of january 1998 , of its reported 344 noncompliant mission - critical and major systems , the army reported that contingency plans had been completed for 96 systems , no plans had been completed for 82 systems , and the status of the remaining 166 systems was unknown .

army year 2000 project office officials recently informed us that aaa is reviewing contingency plans as part of its year 2000 reviews of individual systems .

while we view aaa efforts as a positive step , if the army does not ensure that contingency plans for all core business areas are promptly completed and reviewed , it may not have enough time to identify alternatives if replacement or repair schedules slip or systems do not operate correctly .

thus , it will increase the risk of being unprepared to carry out operational missions after the year 2000 deadline .

the validation ( testing ) phase of the year 2000 effort is expected to be the most expensive and time - consuming .

for example , the mitre corporation , the gartner group , and other industry experts estimate that testing will account for 40 percent to 60 percent of the cost of the entire effort .

our year 2000 assessment guide cautions that agencies may need over a year to adequately test converted or replaced mission - critical systems for year 2000 compliance .

further , as both dod's year 2000 management plan and our year 2000 assessment guide state , the testing phase will be complex since components must not only test year 2000 compliance of individual applications , but also the complex interactions between scores of converted or replaced computer platforms , operating systems , utilities , networks , databases , and interfaces .

moreover , in some instances , agencies may not be able to shut down their production systems for testing and , thus , may have to operate parallel systems implemented at a year 2000 test facility .

because of the length and complexity of the testing phase and the potential that other test facilities may be needed , our year 2000 assessment guide and dod's year 2000 management plan recommend that agencies begin identifying the need for test facilities during the assessment phase .

army year 2000 project office officials acknowledged that they must know the year 2000 testing requirements of army components ( eg , equipment , facilities , personnel , and schedule ) in order to ensure effective and timely testing of all army systems .

further , over a year ago , in january 1997 , army year 2000 project office staff recognized that there may be competition for testing resources and agreed to evaluate the issue .

however , as of february 1998 , the army year 2000 project office had not yet assessed the situation even though all its mission - critical systems had completed the assessment phase .

without knowing the testing requirements of all army components , the army will not be able to effectively schedule resources , prioritize demand , and acquire the additional resources it may need to meet the demands of year 2000 testing .

the army's year 2000 program is at risk of failure because the data required to effectively manage correction efforts are inaccurate and incomplete , interface agreements and contingency plans have not been completed , and all testing requirements have not been determined .

in view of these problems , the army has supplemented its efforts with aaa , the army inspector general , and contractor services .

however , these initiatives are designed to identify systemic year 2000 issues and assess the progress made toward resolving them based on data provided , and do not preclude the need for the army year 2000 project office to effectively and efficiently determine whether system managers are providing complete and accurate information and to ensure that they do .

also , until the army provides increased oversight of components' efforts to plan for contingencies , prepare interface agreements , and acquire needed testing facilities , it cannot be assured that its mission - critical operations will not be severely degraded or disabled as a result of the year 2000 problem .

we recommend that the secretary of the army direct the army cio to do the following: require by july 30 , 1998 , that all army components ( 1 ) correct their inventory databases , ensuring that they are accurate and complete , ( 2 ) certify all claims of year 2000 compliance and submit completed certification checklists to the army year 2000 project office , ( 3 ) provide reliable year 2000 cost estimates that are based on a comprehensive inventory and completed assessments of all mission - critical and major systems so that priorities can be established and informed resource trade - off decisions can be made , ( 4 ) prepare contingency plans that include specific actions for ensuring the continuity of the army's critical operations at the year 2000 , ( 5 ) prepare memorandums of agreement for all identified interfaces , and ( 6 ) develop test plans and identify the need for additional testing resources .

require by july 30 , 1998 , that the army year 2000 project office ensure that the army year 2000 inventory database contains complete , accurate , and current information on year 2000 status .

to accomplish this , the army year 2000 project office should ( 1 ) correct known problems , including erroneous database default values and ( 2 ) perform quality assurance checks of the data prior to its use .

require that the army year 2000 project office continuously monitor components' progress in ( 1 ) identifying all systems interfaces and defining key details of the data exchange between systems interfaces and ( 2 ) preparing and implementing required memorandums of agreement .

require that the army year 2000 project office negotiate with other entities to secure and schedule additional test facilities if components determine that more test capacity is needed .

in written comments on a draft of this report , the office of the army chief information officer ( cio ) concurred with all of our recommendations and indicated that , based on our review efforts and those of the military audit agencies , actions are already in process to improve the army year 2000 program .

for example , the cio noted that , in a february 1998 policy memorandum , he had directed components to ( 1 ) provide more complete and accurate data on their systems , ( 2 ) ensure that all mission - critical and major systems reported as compliant in the army year 2000 database are certified and copies of the certification are provided to the army year 2000 project office , ( 3 ) ensure that all noncompliant mission - critical and major systems are certified following renovation and testing , ( 4 ) complete contingency plans for all noncompliant mission - critical and major systems and core business areas , and ( 5 ) inventory all system interfaces and coordinate interface agreements with interface partners .

also , the cio indicated that he had directed senior - level component managers to meet with him during the april - may 1998 time frame to review progress in fixing year 2000 issues .

however , as the army states , many of the actions are not yet complete .

until actions to implement all our recommendations are completed , the army cannot ensure that it will transition smoothly into the next millennium .

this report contains recommendations to you .

the head of a federal agency is required by 31 u.s.c .

720 to submit a written statement on actions taken on these recommendations to the senate committee on governmental affairs and the house committee on government reform and oversight not later than 60 days after the date of this report .

a written statement also must be sent to the house and senate committees on appropriations with the agency's first request for appropriations made more than 60 days after the date of this report .

we are sending copies of this letter to the chairmen and ranking minority members of the senate committee on governmental affairs and its subcommittee on oversight of government management , restructuring and the district of columbia ; the subcommittee on defense , senate committee on appropriations ; the senate committee on armed services ; the subcommittee on government management , information and technology , house committee on government reform and oversight ; the subcommittee on national security , house committee on appropriations ; and the house committee on national security .

we are also sending copies to the honorable thomas m. davis , iii , house of representatives ; the secretary of defense ; the deputy secretary of defense ; the under secretary of defense ( acquisition and technology ) ; the under secretary of defense ( comptroller ) ; the acting assistant secretary of defense ( command , control , communications and intelligence ) ; the army's director of information systems for command , control , communications , and computers ; the commander of the army materiel command ; the army inspector general ; the army auditor general ; the director of the office of management and budget ; and other interested parties .

copies will be made available to others upon request .

we appreciate the courtesy and cooperation extended to our audit team by army officials and staff .

if you have any questions on matters discussed in this letter , please call me or ronald b. bageant , assistant director , at ( 202 ) 512-6240 .

major contributors to this report are listed in appendix iii .

as figure i.1 indicates , year 2000 management and oversight efforts will have to be coordinated among 17 major commands ( macom ) — each with a complex and diverse organizational structure of its own — 17 functional proponents , 8 program executive offices , and 8 program management offices .

in addition , 65 project manager offices and 109 product manager offices fall under the macom and program executive office umbrellas .

figure i.2 shows the organizational structure of one major army command — amc — in greater detail .

to understand the complexity involved in carrying out year 2000 efforts at the major command level , consider the following information provided by amc: amc employs more than 65,000 civilian and military employees at 285 locations worldwide .

the command ranks in business volume with the top 10 corporations in the u.s. and is responsible for about 50 percent of every procurement dollar the army spends .

amc manages about 500,000 computer applications , infrastructure devices , and embedded systems .

of these 500,000 , about 476,000 support the business systems infrastructure , such as local area networks and desktop computers and about 1,700 support weapons systems , including the ah - 64a apache and ah - 64d apache longbow attack helicopters , the m1a2 abrams tank system and the m2 / m3a3 bradley fighting vehicle , the patriot missile system , and the guardrail common sensor system used to support the intelligence gathering capabilities of the army's rc - 12 aircraft .

amc's 138 logistics business systems include 1,023 system interfaces and 4,694 data bridges .

amc has given 149 individuals the responsibility to ensure that year 2000 problems are resolved .

tank - automotive research , development and engineering center armament research , development and engineering center armament and chemical acquisition and logistics activity aviation research , development and engineering center missile research , development and engineering center charles melvin price support center communications - electronics command research development and engineering center army war reserve support command ( continued ) .

the following is gao's comment on the department of the army's letter dated may 6 , 1998 .

1 .

the army provided a number of clarifications to the report that we have incorporated as appropriate .

denice m. millett , evaluator - in - charge the first copy of each gao report and testimony is free .

additional copies are $2 each .

orders should be sent to the following address , accompanied by a check or money order made out to the superintendent of documents , when necessary .

visa and mastercard credit cards are accepted , also .

orders for 100 or more copies to be mailed to a single address are discounted 25 percent .

u.s. general accounting office p.o .

box 37050 washington , dc 20013 room 1100 700 4th st. nw ( corner of 4th and g sts .

nw ) u.s. general accounting office washington , dc orders may also be placed by calling ( 202 ) 512-6000 or by using fax number ( 202 ) 512-6061 , or tdd ( 202 ) 512-2537 .

each day , gao issues a list of newly available reports and testimony .

to receive facsimile copies of the daily list or any list from the past 30 days , please call ( 202 ) 512-6000 using a touchtone phone .

a recorded menu will provide information on how to obtain these lists .

