the nation's surface transportation system is under growing strain , and the cost to repair and upgrade the system to meet current and future demands is estimated in the hundreds of billions of dollars .

federal transportation grants provide critical funding to help build and upgrade the freight and highway networks that support safe , efficient , and reliable movement of goods and people .

in december 2015 , the fixing america's surface transportation act ( fast act ) established a nationally significant freight and highway project program and authorized the appropriation of $4.5 billion to the department of transportation ( dot ) to award in discretionary grants for such projects for fiscal years 2016 through 2020 .

in 2016 , dot issued the first round of grants providing approximately $759 million to 18 projects under this new program , called the fostering advancement in shipping and transportation for the long - term achievement of national efficiencies ( fastlane ) program .

we reviewed dot's processes used to evaluate and award fastlane grants and found issues related to consistency and transparency .

specifically , we found that due to inconsistencies in dot's review of applications and limited documentation of decisions regarding awards , we were unable to determine the rationale dot used to award projects .

we have repeatedly found similar issues related to consistency and transparency in our prior reviews of dot's various discretionary grant programs , beginning in 2011 .

in july 2017 , to reflect the priorities of the new administration , dot revised the fastlane program by establishing new criteria for evaluating grant applications and renaming it the infrastructure for rebuilding america ( infra ) program .

dot also announced that up to $1.6 billion would be awarded for fiscal years 2017 and 2018 .

after dot reviewed the 258 applications it received , it awarded roughly $1.54 billion to 26 projects .

you asked us to review the infra award process .

this report: describes dot's process for evaluating infra grant applications , and assesses the consistency and transparency of dot's process for evaluating infra grant applications .

to describe dot's processes for evaluating and awarding infra grant applications submitted in response to dot's july 2017 call for applications for the fiscal - year 2017 – 2018 round of funding , we identified pertinent statutory requirements in the fast act .

we then reviewed dot's july 5 , 2017 , notice of funding opportunity ( nofo ) announcing the availability of infra funds , as well as the program's funding priorities and the corresponding criteria dot would use to evaluate the projects proposed in the grant applications .

we also reviewed dot's infra evaluation plan that described how dot staff should evaluate and score the projects against these requirements and criteria as well as documentation from an internal dot spreadsheet showing the results of the reviews , including project scores and narratives explaining the rationale for the scores .

finally , we reviewed the documents presented to the secretary .

to assess the reliability of dot's infra spreadsheet , we interviewed dot officials and conducted checks of the data , such as identifying blank cells in the spreadsheet and comparing the information from the spreadsheet against the documents presented to the secretary to identify any discrepancies .

while we identified instances in which dot did not record score changes in its spreadsheet , we were able to identify final project scores and found the data were reliable for the purposes of identifying the scores given by dot to projects and understanding how dot evaluated projects .

to assess the consistency and transparency of dot's process for evaluating infra grant applications , we compared dot's processes for evaluating applications submitted in response to the july 2017 nofo to requirements and best practices related to consistency and transparency in the administration of discretionary grant programs .

we identified relevant requirements and guidance from the office of management and budget's ( omb ) uniform administrative requirements , cost principles , and audit requirements for federal awards ( uniform guidance ) , federal internal control standards related to control activities and communication , dot's financial assistance guidance manual , and our prior work in which we identified recommended practices for awarding discretionary grants .

we then conducted document reviews and interviews with dot staff and officials to assess dot's process against these criteria .

for example , we conducted in - depth reviews of the narratives explaining the scores and any reviewer's concerns for all of the awarded projects , and a non - generalizable sample of 10 non - awarded projects , selected to ensure diversity in projects' size , type , urban or rural status , and applicant type .

we followed up with dot regarding concerns raised by reviewers on specific projects , as well as potential inconsistencies between the reviewer's narrative and the project's score .

in addition , we interviewed dot staff with diverse responsibilities , including: ( 1 ) those who conducted technical reviews of infra projects against criteria established by dot , ( 2 ) those responsible for overseeing the process , and ( 3 ) senior officials responsible for deciding which projects should be forwarded to the secretary .

we asked these staff how they conducted reviews and documented their decisions .

for the technical review staff , we selected a sample of staff from six of the seven teams that reviewed projects against criteria .

we selected technical review staff from the federal highway administration ( fhwa ) , federal railroad administration ( fra ) , and united states maritime administration ( marad ) to ensure diversity with respect to area of expertise and modal administration .

for the senior officials , we selected two officials who served on the team that decided which projects should be forwarded to the secretary , including one official dot identified as best able to discuss how the secretary reviewed the projects .

to obtain applicant perspectives on the process , we interviewed 11 applicants and 3 consultants that applicants hired to help them with their infra application .

applicants were selected to ensure diversity in projects' size ; type ( highway , rail , port , multimodal , grade crossing ) ; location ; urban or rural setting ; award status ; as well as types of applicants ( state , city , county government , among others ) .

to identify consultants to interview , we asked dot staff and infra applicants we interviewed to provide the names of consultants that worked on infra project applications .

the results of our interviews provide insight into applicants' experiences with the infra process but are not generalizable to all applicants .

when reporting on applicants' and consultants' responses to our questions , we use the following terms to enumerate responses: several ( 9 to 13 ) ; some ( 5 to 8 ) ; and a few ( less than 5 ) .

we conducted this performance audit from july 2018 to june 2019 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

traditionally , federal surface - transportation funding has been primarily delivered through formula grant programs based on distributions prescribed by statute .

discretionary grant programs , such as infra , represent an alternative approach for directing federal funding toward national priorities .

through a discretionary grant program , congress or federal agencies establish desired goals or outcomes — such as improving the condition of critical infrastructure , enhancing economic competitiveness , or reducing fatalities .

generally , federal agencies review grant applications against published selection criteria and statutory and regulatory requirements before selecting projects to receive awards .

this approach can help assure accountability for federal investment by more clearly linking program funds to desired outcomes and can support projects of national or regional significance that cross state lines .

in prior work , we have recommended that a merit - based competitive approach — like infra — be used to direct a portion of federal funds to transportation projects of national and regional significance .

the fast act authorized over a dozen discretionary transportation - grant programs , and congress may consider additional programs as it considers reauthorizing dot's surface transportation programs in 2020 .

state , local , and tribal governments , as well as multistate or multijurisdictional groups , are among the entities eligible to receive infra funding .

freight or highway projects must meet the statutory requirements outlined in the fast act to receive infra funding .

notable statutory requirements regarding the distribution of awards include: ten percent of available funds are reserved for small projects each fiscal year .

at least 25 percent of available funds are reserved for rural areas each fiscal year unless dot does not receive enough qualified rural project applicants .

no more than $500 million , in aggregate , over fiscal years 2016 through 2020 may be used to fund freight rail , water ( including ports ) , or other freight intermodal projects .

the secretary must consider geographic diversity during the selection process .

large projects have to meet seven additional statutory requirements to be eligible for selection by the secretary .

specifically , the secretary must determine that the project: will generate national or regional economic , mobility , or safety will be cost - effective ; will contribute to one or more of the national goals for the transportation system: improved safety , infrastructure maintenance , congestion reduction , system reliability , freight movement , economic vitality , environmental sustainability , and reduced project delivery delays ; is based on the results of preliminary engineering ; for related non - federal financial commitments , has stable and dependable funding and financing sources to construct , maintain , and operate the project , and contingency amounts to cover unanticipated cost increases ; cannot be easily and efficiently completed without other federal funding or financial assistance ; and is reasonably expected to begin construction no later than 18 months after the date of obligation of funds for the project .

in the july 2017 nofo for the infra program , dot established four new criteria for infra outlining how projects would be evaluated ( see table 1 ) .

dot did not require that projects address every criterion .

dot noted that in addition to these criteria , called merit criteria , it would also evaluate a project's readiness , meaning the likelihood of a project's successful delivery and that the project will meet statutory deadlines for certain milestones .

in december 2018 , dot issued a nofo in which it called for applications for grants of fiscal year 2019 infra funds , and made some changes to the program's criteria .

however , that process is ongoing and is outside the scope of this review .

in reviewing applications submitted in response to the july 2017 nofo , dot evaluated proposed projects against the statutory and merit criteria using a multiphase review process involving technical and senior management teams .

the process had three phases — application intake , technical evaluation , and senior review — each supported by different teams .

the process also included a quality control and oversight team ( qco ) that was involved throughout the process and responsible for ensuring consistent reviews and documentation .

qco consisted of team leads from each of the seven technical evaluation teams as well as liaisons from fhwa , marad , and fra ( see fig .

1 ) .

the application intake phase consisted of two sequential steps performed by two different teams .

first , the intake review team assessed each of the projects to: 1. verify that the applicant type , project type , and cost - sharing met the statutory requirements ; 2. determine the project's size as being either small or large ; 3. identify the highway and non - highway cost components ; 4. determine whether the project is in an urban or rural area ; 5. identify which technical evaluation teams should review the 6. which modal administration should perform the operating administration screen ( described below ) .

dot received 258 applications for projects in november 2017 and determined that 24 projects did not qualify for infra funding .

the remaining 234 projects then moved to the operating administrations' screen .

as part of the operating administrations' screen , staff from the appropriate modal agency provided input on: 1. the applicant's history with delivering projects on time ; 2. whether the applicant had previously received federal funding from 3. whether the applicant contacted the agency about their infra project , the nature of the contact , and the level of technical and financial assistance provided by the agency ; 4. whether the project is on the transportation improvement program or the statewide transportation improvement program ; and , 5. any specific issues with the project that evaluators should be aware of .

the 234 projects then advanced to the technical evaluation phase of the process .

the seven technical evaluation teams , made up of experts from across the agency , assessed and rated projects against the merit criteria .

each team was responsible for rating a different merit criterion ( as noted in figure 1 , the innovation criterion was split into three factors , so there were three innovation teams ) .

since dot did not require projects to address all the criteria , teams only reviewed the projects that related to their criterion .

the teams used the factors outlined in dot's infra evaluation plan to assess and rate the projects and documented their rating and a narrative justification for the assigned rating in dot's tracking spreadsheet .

generally , raters assigned scores of high , medium , or low for each criterion , with some exceptions .

for example , the economic vitality team calculated the project's benefit - cost ratio and net present value , while also noting whether the uncertainty associated with the rating was high , medium , or low .

similarly , the leveraging team assigned a rating score of high , medium , or low , but also calculated the percentage of non - federal funding , and noted whether the project included private - sector funding .

technical teams did not provide an overall rating of projects ( such as not recommended , recommended , or highly recommended ) , an approach that differs from prior dot discretionary grant programs we have reviewed .

for detailed information about the evaluation factors and possible scores for each criterion , see appendix i .

each technical review team was assigned a team lead , who was responsible for ensuring that the projects were evaluated consistently and per the plan that governed that team's criterion .

all 234 projects received technical evaluation ratings for their merit criteria and then advanced for further review .

according to dot's evaluation plan , the quality control and oversight team ( qco ) was responsible for ensuring the consistency of reviews and documentation throughout the infra process .

qco consisted of team leads from each of the seven technical evaluation teams and liaisons from fhwa , marad , and fra .

qco was also responsible for performing a “large project determination,” in which qco assessed whether projects met each of the seven statutory requirements for large projects .

qco used information from the technical evaluations and the information provided in the application to determine whether projects met the statutory requirements .

in cases where qco could not definitively determine whether a large project met a statutory requirement , it would note “additional information is necessary” in dot's tracking spreadsheet .

after qco recorded its assessment , it submitted the projects to the senior review team for review .

the senior review team was responsible for assembling a list of projects for consideration by the secretary , and consisted of senior officials from the office of the secretary , and the administrators of fhwa , fra , fta , and marad .

the senior review team , with qco present to answer questions , met to review the projects and their technical evaluation scores for each criterion .

the evaluation plan stated the senior review team could , at its discretion , request that qco seek additional information from applicants to help qco determine if a large project met the statutory requirements .

the final list of projects for consideration developed by the senior review team contained 165 projects ( all of the small projects and all of the large projects that qco and the senior review team determined met the statutory requirements ) .

at the end of the review process , the secretary received a series of spreadsheets ranking each of the 165 projects according to how well they scored on each merit criteria .

according to a member of the senior review team , the secretary formally met twice with her chief of staff , deputy secretary , and other senior advisors to discuss the projects , first to analyze all of the projects on the list and second to finalize the award decisions .

in june 2018 , dot announced it had awarded approximately $1.54 billion in infra funding to 26 projects ( see fig .

2 ) .

for the 26 awarded projects , 44 percent of funds went to rural projects and 5 percent of funds went to small projects .

in addition as shown in figure 2 , highway projects received the largest percentage of funding ( 85 percent ) , and rail projects received the smallest percentage ( 1 percent ) .

in designing its process for evaluating infra applications submitted in response to the july 2017 nofo , dot took steps to address issues that we found led to inconsistencies in dot's review of fastlane applications .

specifically , we reported that technical teams were divided by modal administrations ( fhwa , marad , and fra ) and lacked clear guidance on how to score applications .

this led to inconsistent scoring practices among the fastlane teams because one team applied a higher standard than the others .

we recommended that dot develop an evaluation plan for infra that clearly defined how all review teams should apply criteria , assess applications , and assign ratings to ensure that all applications are consistently reviewed .

in response , dot developed an infra evaluation plan that provided guidance on how to evaluate and assign a rating for each criterion , and in some cases , provided discrete numeric rating categories , allowing for less interpretation by technical review teams when assigning a score .

in addition , dot organized technical review teams by merit criteria and selected staff with the relevant expertise to serve on each team — for example , economists from the various modal agencies served on the economic vitality team .

dot also took steps to improve the transparency of its process by better communicating with unsuccessful applicants .

specifically , dot formally notified unsuccessful infra applicants of selection decisions via email , addressing a concern we raised regarding the fastlane process .

in our review of fastlane , we recommended that dot notify unsuccessful applicants of dot's decision and that the notification should include a brief explanation of the decision .

for infra , dot emailed unsuccessful applicants notifying them of its decision .

while the email did not include a brief explanation of the decision , it did offer applicants the chance to schedule a debriefing with dot officials .

some of the selected applicants and consultants we spoke to said that the debriefing was helpful .

for example , one applicant told us that during the debriefing , dot shared how the project was rated by criterion .

one applicant we met with said the debriefing was not helpful because the applicant did not receive a substantive answer about why they did not receive an award .

another applicant said he requested a debriefing but did not receive one .

a dot official told us that prior to issuing the fiscal year 2019 infra nofo , dot contacted all previous applicants to notify them of the upcoming round and again offer debriefs .

we found that dot's process for following up with applicants lacked consistency and transparency , due to a lack of guidance and documentation .

specifically , dot followed up with some applicants and not others to request additional information about their projects , and the rationale behind which applicants were selected for follow - up is not clear .

we identified similar issues in our review of fastlane .

as discussed earlier , for large projects to be eligible for an award , dot must determine that the project meets several statutory requirements , such as generating benefits and demonstrating cost - effectiveness , among others .

our review of dot documents revealed that dot staff originally determined that 97 ( of 116 ) applications for large projects did not include sufficient information for dot to assess if the projects met each of the statutory requirements .

at the request of officials on the senior review team , qco requested more information from 42 of those 97 applicants to help dot determine if their projects met the requirements .

of the 42 applicants that dot followed up with , 28 provided information that qco determined was sufficient to ensure that they met the statutory requirements , and 13 of the projects received an award .

similarly , at the request of officials on the senior review team , dot staff reduced the scope of a number of projects .

qco staff split 9 projects into “components,” to scope out pieces of projects that could not meet a statutory requirement ( for example , cost - effectiveness ) .

four of these component projects received an award .

omb guidance states that the intent of a nofo is to make the application review process transparent so applicants can make informed decisions when preparing their applications to maximize fairness of the process .

the guidance also states that federal agencies should make clear whether an applicant's failure to meet an eligibility criterion by the time of an application deadline will result in the awarding agency returning the application without review or , even though an application may be reviewed , will preclude the awarding agency from making an award .

similarly , internal control standards note that federal agencies should communicate with external entities and enable these entities to provide quality information to the agency that will help it achieve its objectives .

dot's nofo states that the applications must include sufficient information for dot to determine whether projects meet the statutory requirements , but also notes that dot may seek additional information from applicants .

the nofo does not provide information on the basis for why dot would follow up with one applicant and not another .

after reviewing dot's documentation , we found that the rationales for following up with specific applicants were insufficient to explain why dot followed up with certain applicants over others .

the documentation , with few exceptions , included generally vague statements that additional information from the applicant could help dot determine whether the project met the statutory requirements .

we asked two officials from the senior review team about several specific projects for which those officials requested additional information .

these officials both stated they could not recall their rationale , given that roughly a year had elapsed and the large number of projects reviewed .

however , they did provide some reasons why they might have requested additional information , such as the need for more clarity on a project , a high score on a criterion of interest to that official , or the desire to ensure that the list provided to the secretary included a diverse array of projects ( in terms of location , urban or rural status , and project type ) .

further , one official noted that there was insufficient time to follow up with every applicant .

we have previously identified recommended practices for evaluating and selecting discretionary grant awards and noted that in order to align with these practices , it is important to document decisions , including decisions regarding which projects should have the opportunity to advance in the process .

when we identified similar issues related to a lack of consistent and transparent follow - up with fastlane applicants , we recommended dot develop an infra evaluation plan that clearly defines how all review teams should apply criteria , assess applications , and assign ratings to ensure that all applications are consistently reviewed .

dot's infra evaluation plan states that if qco has been unable to make an affirmative determination with respect to whether a large project meets a statutory requirement , a senior review team member may direct qco to seek clarifying information from the applicant or provide the necessary clarifying information themselves to support a determination .

however , dot's evaluation plan does not require documentation of the reasons why the senior review team asked qco to follow up with certain projects over others .

without clearly outlining in the nofo and the evaluation plan the situations in which certain applicants may be asked to provide additional information , as well as clear documentation for why follow - up does occur with specific projects over others , the process lacks transparency and the assurance of fairness .

for example , we found examples in which reviewers noted that additional information could help them determine whether a project met the statutory requirements ( such as whether the project was cost - effective ) but less than half of the projects had the chance to provide such information .

of the 26 awarded projects , half of those projects ( 13 large projects ) were afforded the opportunity to provide additional information to demonstrate that their projects met the statutory requirements .

we were unable to determine the rationale for the selection of projects for infra awards ; an issue we also found with the fastlane process .

this is due to: inconsistency in the nofo regarding how merit criteria would be used to select awardees ; a large number of applications forwarded for potential award regardless of merit scoring ; and limited documentation regarding why 26 projects were ultimately selected out of 165 for award .

in the nofo for infra , dot provided inconsistent and unclear messages regarding the extent to which the merit criteria should be addressed to be competitive for an award , which also reduced transparency and caused confusion for some applicants .

omb guidance states that the intent of a nofo is to make the application review process transparent so applicants can make informed decisions when preparing their applications to maximize fairness of the process .

in the nofo , dot stated it would evaluate applications against four merit criteria , but also stated , “the department is neither weighting these criteria nor requiring that each application address every criterion , but the department expects that competitive applications will substantively address all four criteria.” in some cases , this approach led to confusion among applicants , as several of the selected applicants and consultants we interviewed noted that it was difficult to address the innovation merit criterion , with some stating the criterion was confusing or unclear and others stating that they faced difficulties adapting their projects to meet the criterion .

compounding this issue , several applicants and consultants also expressed uncertainty as to how dot determined which projects should receive awards and which factors affected a project's ability to get an award .

for example , representatives for one applicant noted that they spent a considerable amount on a consultant for the benefit - cost analysis ( which was common among most of the applicants we interviewed ) , but it was not clear how the benefit - cost analysis affected dot's decision - making .

despite the language in the nofo , dot did not use the merit scores — which reflect the extent to which projects addressed all four criteria — when it determined which projects should be provided to the secretary for consideration .

while dot reviewers did score applications on all four merit criteria , all of the 165 projects that qco found to be statutorily eligible — 47 large projects and 118 small projects — were sent to the secretary for potential award , regardless of merit criteria scores or whether the applicant substantively addressed all four merit criteria .

dot officials told us that dot sought a “portfolio” approach in which the secretary selected projects that scored highly on at least one criterion .

thus , the secretary received a 25-page spreadsheet showing 14 different lists ( 7 for small projects and 7 for large projects ) sorting all of the projects against the merit criteria , with each list arranged from highest to lowest score for that criterion .

this method of presenting information on projects ( and the volume of information presented ) would make it challenging for any decision maker to compare projects and readily see how 165 projects scored across all criteria and whether all criteria were “substantively addressed.” in addition , projects were provided to the secretary for consideration — and in some cases awarded — despite concerns raised by technical reviewers and regardless of whether projects addressed all of the merit criteria .

for example , we found instances in which awarded projects had: low cost - effectiveness scores .

over 50 percent ( 14 of 26 ) of all awarded projects received a high uncertainty rating related to their benefit - cost ratio and net present value score , meaning that the technical team had a low degree of confidence in the assigned score .

only 38 percent of all projects had this uncertainty rating .

moreover , of the 14 awarded projects with this rating , 11 had benefit - cost ratios of 1.0 to 1.5 , which , when combined with the high uncertainty rating , raises the risk that the project would not be cost - effective .

for example , for one large project , a technical reviewer noted , “… we conclude that the benefits of this project are reasonably likely to exceed its costs , though the case is very marginal and highly uncertain , as even a small change in some of the key assumptions and parameters could result in a negative finding.” uncertainty regarding projects' benefit - cost ratios is particularly important as dot used these scores to assess whether large projects met the fast act requirement to be cost - effective .

while comments from technical reviewers were not included in the spreadsheets provided to the secretary , an official stated that the senior review team reviewed each project in - depth with the secretary , and other dot officials noted that the spreadsheet provided to the secretary included the uncertainty ratings for each project .

low scores on multiple criteria , or did not address all criteria .

two awarded small projects had a benefit - cost ratio of less than one , and one of those projects did not address the innovation criteria at all .

three of the 26 awarded projects ( 11.5 percent ) did not address the innovation criteria at all .

in addition , several of the selected applicants and consultants we interviewed expressed confusion regarding how dot reviewed the applications and moved them forward within dot .

some of the applicants and consultants thought that dot used the project scores to determine which projects should move forward to the secretary ( similarly to previous rounds of other dot grant programs in which projects were sorted into categories such as “highly recommended,” “recommended,” and “not recommended” ) .

one applicant noted that it is important to know how many projects make it to the secretary in order to understand the extent to which decisions are based on technical scores versus other considerations .

dot's guidance states that grant recipients should be selected based on technical merit and those projects most likely to achieve the intended purpose .

in addition , we have identified recommended practices for awarding discretionary grants , one of which includes documenting the rationale for award decisions .

documenting the rationale for award decisions becomes even more important in light of dot's decision to provide every eligible infra application to the secretary , rather than providing the secretary a list of the projects “most likely to achieve the intended purpose.” however , dot's documentation on the final selection of projects states the anticipated benefits of the projects but does not indicate why these projects , according to dot's guidance , “best address program requirements and , therefore , are most worthy of funding.” in our review of the fastlane process , we also noted that due to limited documentation , we could not determine how dot selected which projects should receive awards .

we recommended that dot require program teams to document their decision - making rationale throughout all levels of review in the application selection process .

dot agreed with this recommendation ; however , it has not yet been implemented .

therefore , it remains unclear whether dot is awarding discretionary grants on the basis of merit principles or other considerations .

an absence of documentation can give rise to challenges to the integrity of the evaluation process and thus the decisions made .

since 2011 , we have found similar issues with dot's management of other competitive discretionary grant programs , including a lack of documentation of key award decisions , and have made recommendations aimed at increasing consistency and transparency .

in some cases , dot implemented our recommendations for one program , but we subsequently found similar or recurring problems in other dot programs .

in 2011 , we reviewed dot's transportation investment generating economic recovery ( tiger ) program and fra's high speed intercity passenger rail program — two discretionary grant programs funded through the american recovery and reinvestment act of 2009 .

for both programs , we found , among other things , limitations in the agencies' documentation of the rationale for award decisions .

with respect to tiger , we noted that a lack of documentation could subject dot to criticism that projects were selected for reasons other than merit .

however , we also noted that documenting key decisions could help build confidence in dot's ability to administer competitive discretionary grant programs .

we recommended that dot and fra improve their documentation of key decisions for both programs .

dot implemented these recommendations by updating its tiger and fra guidance to require additional documentation .

despite the steps dot took to address our prior recommendations , in 2014 , we found continued issues in the tiger program and made more targeted recommendations .

specifically , we found that dot did not document key decisions to , among other things , ( 1 ) advance projects with lower technical ratings instead of more highly rated projects , and ( 2 ) change the technical ratings of lower - rated projects that had been selected for an award .

we recommended that the secretary of transportation establish additional accountability measures for management of the tiger program , to include using a decision memorandum or similar mechanism to document a clear rationale for decisions to: change the technical evaluation rating of an application , not advance applications rated as highly recommended , and advance for senior review applications other than those rated as highly recommended .

subsequently , dot revised its guidance for the tiger program to prohibit changes to the technical ratings , require that all highly rated projects be advanced , define the conditions through which lower rated projects may be advanced , and require that all such decisions be fully documented .

dot did not require that these decisions be documented through a decision memorandum or similar mechanism , as we had recommended .

however , taken together , we determined dot's actions were sufficient to address our recommendation for the tiger program .

in december 2016 , we found similar problems during our review of the hurricane sandy transit - resilience grant program administered by the federal transit administration ( fta ) .

for example , we found that fta did not document rationales for changes to project ratings nor did it document how it addressed high - level project concerns raised by reviewers in their evaluation comments .

in addition , we found that dot lacked clear department - wide requirements for what should be documented when evaluating and selecting discretionary grant awards .

we noted that internal control standards state that all transactions and significant events need to be clearly documented , and that a recommended practice for evaluating and selecting discretionary grant awards is documenting the rationale for awards decisions , including reasons individual projects were selected or not selected .

we also found that fta did not develop an evaluation plan prior to calling for applications , despite the fact that this was a requirement in dot's financial assistance guidance manual and that recommended practices for administering discretionary grant programs note the importance of having an evaluation plan that describes a method for overseeing the technical review panels to ensure a consistent review .

finally , we found that fta did not assess projects against the policy priorities it outlined in its notice of funding availability , despite an omb directive to provide sufficient information to help an applicant make an informed decision about whether to submit a proposal .

at this time , we noted a pattern of problems occurring across dot and its modal administrations' discretionary grant programs and determined that a department - wide action was needed to address these issues .

specifically , we recommended that the secretary issue a department - wide directive that should include requirements to: develop a plan for evaluating project proposals in advance of issuing a notice of funding availability that defines the stages of the process , including how the process will be overseen to ensure a consistent review of applications ; document key decisions , including the reason for any rating changes and the officials responsible for those changes , and how high - level concerns raised during the process were addressed ; and align stated program purpose and policy priorities with the evaluation and selection process .

dot concurred with our 2016 recommendation to develop a department - wide directive and initially stated that it would address it by updating its financial assistance guidance manual by september 2018 ( dot recently extended this to december 2019 ) .

in response , we noted that in order to address our recommendation , dot needed to issue a directive that incorporates all of the elements identified in our recommendation .

in addition , it remains unclear whether updating the manual would have the same effect as issuing the department - wide directive that we recommended .

specifically , we have found that dot has not always followed its own guidance despite clear language that certain actions are required .

for example , in our 2017 review of the fastlane program , we noted that the financial assistance guidance manual required finalization of the evaluation plan prior to soliciting applications for grants , but this guidance was not followed .

since 2017 , we have sent letters to the secretary of transportation noting that this is a high - priority recommendation that warrants her attention .

in march 2019 , dot issued a one - page memo to all offices and departments that administer discretionary grants .

this memo directed the offices to update their policies and procedures to implement our 2016 recommendation and to send the updated policies to dot's office of the senior procurement executive by june 30 , 2019 .

dot officials told us that dot believes this action has addressed the recommendation .

due to a number of issues , however , it is unclear how this action will address our recommendation to create clear department - wide requirements aimed at improving transparency and consistency .

specifically , we found that the memo was essentially limited to a repetition of our recommendation .

that is , dot did not take steps to ensure that the various affected offices consistently interpret and implement the recommendation .

for example , dot did not define key terms such as “high level concerns,” or “key decisions.” in addition , dot did not communicate to offices how they should sufficiently document their decisions to ensure that the rationale for those decisions — including the reasons individual projects were selected or not selected — is clear .

dot officials told us they wanted to provide the affected offices flexibility to implement the recommendation and would assess the need for additional guidance based on the completion of the financial assistance guidance manual .

however , the lack of information regarding how offices should implement the memo raises significant questions about whether various offices will interpret and implement the recommendations differently , and enhances the risk that dot will continue to lack a department - wide approach to ensure that discretionary grant programs are consistently and transparently administered .

as dot continues to try to address these long - standing issues with its discretionary grant programs , congress has an opportunity through reauthorization legislation , scheduled for 2020 , to build requirements for enhanced consistency and transparency into these programs .

this is particularly important as dot has two additional rounds of infra funding to award under the fast act , and the president's budget proposal proposed providing an additional $1 billion to infra .

moreover , the fast act also authorized over a dozen discretionary transportation grant programs , and congress may consider additional programs during the reauthorization of dot's surface transportation programs .

through legislation , congress could craft requirements around the administration of dot's discretionary grants to improve the processes for awarding grants .

absent effective action by dot going forward , the recurring and long - standing issues we have identified could continue to affect dot's discretionary grant programs .

while dot has taken some steps to improve its reviews of infra grant applications since we reviewed the fastlane program , issues related to consistency and transparency remain .

specifically , without clear communication from dot regarding ( 1 ) the situations in which dot may provide certain applicants the opportunity to supplement their applications with additional information , and ( 2 ) how merit scoring is used , if at all , to determine whether projects advance to the secretary for selection and which projects are selected , applicants lack the information needed to make informed decisions about whether to apply .

in addition , without documentation outlining why dot decided to request additional information from certain applicants over others , the process lacks transparency .

since the fast act was enacted in 2015 , we have been unable to determine the basis for the resulting awards of about $2.3 billion through the fastlane and infra program .

this lack of clarity is significant and is the product of long - standing issues that we have identified with dot's discretionary grant programs since 2011 .

we have previously noted that competitive discretionary grant programs have promise in better targeting federal transportation spending to areas of national and regional significance ; however , this promise cannot be fulfilled if dot's process and rationale for making awards remains unclear .

in 2019 , dot issued a department - wide memo aimed at addressing our 2016 recommendation , but it is unclear how dot's approach will improve consistency and transparency in its management of grant programs .

we will continue to monitor dot's efforts to address our recommendation .

however , given the long - standing nature of the issues we identified and the potential that they could continue to affect dot's discretionary grant programs , the reauthorization of dot's surface transportation programs scheduled for 2020 provides congress the opportunity to require dot to take additional action to ensure consistency and transparency in the management of its discretionary grant programs .

during the next reauthorization for surface transportation programs , congress should consider including language in the reauthorization bill that would require dot to develop and implement transparency measures for dot's review and selection process for discretionary grants .

such measures should , at a minimum , help to ensure that the evaluation process is clearly communicated , that applications are consistently evaluated , and that the rationale for dot's decisions are clearly documented .

such measures should be developed in line with omb guidance , federal internal control standards , and recommended practices for evaluating and selecting discretionary grant awards ( matter for consideration 1 ) .

we are making the following three recommendations to dot: the secretary of transportation should ensure that dot , in its notice of funding opportunity and evaluation plan for each remaining infra - funding cycle , clarify the circumstances under which dot may select applicants to receive requests for additional information .

 ( recommendation 1 ) the secretary of transportation should develop procedures for each remaining infra - funding cycle to ensure that when additional information is requested from an applicant , the specific rationale behind the request is documented ( for example , to promote geographic diversity among projects ) , as well as to ensure that dot documents the rationale if similar projects were not afforded an opportunity to provide additional information .

 ( recommendation 2 ) the secretary of transportation should ensure that dot provides information to applicants in its notice of funding opportunity for each remaining infra - funding cycle regarding: ( 1 ) how scores on merit criteria are used , if at all , to determine whether projects advance to the secretary for selection , and ( 2 ) how , if at all , dot plans to use merit scores to determine which projects should receive an award .

 ( recommendation 3 ) .

we provided a draft of this report to dot for review and comment .

in comments , reproduced in appendix ii , dot concurred with our recommendations .

dot noted its efforts to improve the infra process for the 2019 round of funding and stated that it looks forward to assisting congress in addressing the matter for congressional consideration in a manner that is feasible within dot's timing and resource constraints .

dot also provided technical comments , which we incorporated as appropriate .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the appropriate congressional committees , the secretary of transportation , and other interested parties .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-2834 or flemings@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix iii .

likely nepa status / type of action required , based on available information ( such as expecting the project to be found to have no significant impact on the environment or that the project would be required to be reevaluated ) the likelihood the project will be able to be delivered by its obligation timeframe high risk = high likelihood that the project will not be obligated on time medium risk = some possibility the project will not be obligated on time low risk = highly likely the project will be obligated on time the special experimental project authorities ( sep 14 / 15 waiver ) is a program that identifies and tests innovative project - delivery methods ( such as non - traditional contracting techniques ) .

susan fleming , ( 202 ) 512-2834 or flemings@gao.gov .

in addition to the contact named above , steve cohen ( assistant director ) ; crystal huggins ( analyst in charge ) ; amy abramowitz ; melissa bodeau ; michelle everett ; geoffrey hamilton ; joshua ormond ; oliver richard ; kelly rubin ; and charles truxillo made key contributions to this report .

