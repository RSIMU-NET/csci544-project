the department of homeland security ( dhs ) invests extensively in acquisition programs to develop new systems that help the department execute its many critical missions .

dhs is acquiring systems to help secure the border , facilitate trade , screen travelers , enhance cyber security , improve disaster response , and execute a wide variety of other operations .

several of dhs's major acquisition programs — the department's most expensive and critical investments — existed prior to the creation of dhs and were managed by one of the 22 separate agencies that merged to form the department .

these acquisition programs are now managed by senior officials at dhs headquarters and 12 component agencies .

in 2011 , dhs reported to congress that it planned to ultimately invest $167 billion in its major acquisition programs .

in fiscal year 2012 , dhs reported it was investing more than $18 billion in the department's acquisition programs .

dhs acquisition management issues have been highlighted in our high - risk list since 2005 .

over the past several years , our work has identified significant shortcomings in the department's ability to manage an expanding portfolio of complex acquisitions .

in 2008 , dhs revised its acquisition review process to include more detailed guidance for key acquisition decision events , documentation requirements , and the roles and responsibilities of dhs decision makers .

in january 2010 , dhs again updated its acquisition policy , but later that year , we found that the department still was not effectively carrying out its acquisition management responsibilities .

we have previously established that a program must have a sound business case that includes firm requirements , a knowledge - based acquisition strategy , and realistic cost estimates in order to reduce program challenges.provide a program a reasonable chance of overcoming challenges yet delivering on time and within budget .

because dhs invests significant resources developing capabilities to support the department's mission , you asked us to assess the extent to which ( 1 ) dhs's major acquisition programs face challenges that increase the risk of poor outcomes ; ( 2 ) dhs has policies and processes in place to effectively manage individual acquisition programs ; ( 3 ) dhs has policies and processes in place to effectively manage its portfolio of acquisition programs as a whole ; and ( 4 ) dhs has taken actions to address the high - risk acquisition management issues we have identified in previous reports .

in addition to this report , we are also issuing a report focused on the performance of dhs's major information technology ( it ) investments .

to determine the extent to which major acquisition programs identified by dhs in 2011 face challenges , we surveyed all 77 major program offices from january to march 2012 , and achieved a 92 percent response rate .

dhs originally identified 82 major acquisition programs in the 2011 major acquisition oversight list , but five of those programs were subsequently cancelled in 2011 .

seventy - one program managers responded to the survey .

see appendix iv .

risks , management challenges , and data limitations — particularly data limitations regarding program performance .

further , we reviewed resource plans and dhs performance reports to establish the extent to which major acquisition programs are achieving their cost , schedule and capability objectives .

to determine the extent to which dhs has policies in place to effectively manage individual acquisition programs , as well as the department's acquisition portfolio as a whole , we compared our key acquisition management practices to dhs acquisition policy , and identified the extent to which dhs has implemented its policy .

we also met with dhs officials to discuss our analysis , identify relevant sections of the policy that we had not yet accounted for , and solicit their thoughts on those key practices that were not reflected in the policy .

to determine the extent to which dhs has taken actions to address the high - risk acquisition management issues we have identified in previous reports , we analyzed the department's recently proposed efforts to address high - risk acquisition management challenges , including the department's progress in implementing new initiatives and any challenges dhs must overcome moving forward .

we conducted this performance audit from august 2011 to september 2012 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

dhs invests in major acquisition programs to develop capabilities intended to improve its ability to execute its mission .

dhs generally defines major programs as those expected to cost at least $300 million over their respective life cycles , and many are expected to cost more than $1 billion .

dhs acquisition management directive 102-01 ( ad 102 ) and dhs instruction manual 102-01-001 ( guidebook ) , which includes 12 appendixes , establish the department's policies and processes for managing these major acquisition programs .

dhs issued the initial version of ad 102 in 2008 in an effort to establish an acquisition management system that effectively provides required capability to operators in support of the department's missions .

ad 102 establishes that dhs's chief acquisition officer — currently the under secretary for management ( usm ) — is responsible for the management and oversight of the department's acquisition policies and procedures .

the usm , deputy secretary , and component acquisition executives ( cae ) are the acquisition decision authorities for dhs's major acquisition programs .

table 1 identifies how dhs categorizes the 77 major acquisition programs it identified in 2011 .

the acquisition decision authority is responsible for reviewing and approving the movement of dhs's major acquisition programs through four phases of the acquisition life cycle at a series of five predetermined acquisition decision events .

these five acquisition decision events provide the acquisition decision authority an opportunity to assess whether a major program is ready to proceed through the life - cycle phases .

the four phases of the acquisition life cycle , as established in ad 102 , are: 1 .

need phase: department officials identify that there is a need , consistent with dhs's strategic plan , justifying an investment in a new capability and the establishment of an acquisition program to produce that capability ; 2 .

analyze / select phase: the acquisition decision authority designates a qualified official to manage the program , and this program manager subsequently reviews alternative approaches to meeting the need , and recommends a best option to the acquisition decision authority ; 3 .

obtain phase: the program manager develops , tests , and evaluates the selected option ; during this phase , programs may proceed through ade 2b , which focuses on the cost , schedule , and performance parameters for each of the program's projects ; and ade 2c , which focuses on low rate initial production issues ; and 4 .

produce / deploy / support phase: dhs delivers the new capability to its operators , and maintains the capability until it is retired ; this phase includes sustainment , which begins when a capability has been fielded for operational use ; sustainment involves the supportability of fielded systems through disposal , including maintenance and the identification of cost reduction opportunities ; this phase tends to account for up to 70 percent of life - cycle costs .

figure 1 depicts the acquisition life cycle .

an important aspect of the acquisition decision events is the review and approval of key acquisition documents critical to establishing the need for a major program , its operational requirements , an acquisition baseline , and testing and support plans .

ad 102 — and the associated dhs instruction manual 102-01-001 and appendixes — provide more detailed guidance for preparing these documents than dhs's predecessor policy .

see table 2 for descriptions of the key acquisition documents requiring department - level approval before a program moves to the next acquisition phase .

level 2 programs' life cycle cost estimates do not require department - level approval .

chief financial officer , chief procurement officer , chief information officer , chief human capital officer , chief administrative services officer , chief security officer , cae responsible for the program being reviewed , and user representatives from component ( s ) sponsoring the capability .

the office of program accountability and risk management ( parm ) is responsible for dhs's overall acquisition governance process , supports the irb , and reports directly to the usm .

parm , which is led by an executive director , develops and updates program management policies and practices , oversees the acquisition workforce , provides support to program managers , and collects program performance data .

in march 2012 , parm issued its first quarterly program accountability report , which provided an independent evaluation of major programs' health and risks .

the department's program management offices are responsible for planning and executing dhs's individual programs within cost , schedule , and performance goals .

the program managers provide the irb key information by preparing required acquisition documents that contain critical knowledge about their respective programs , facilitating the governance process .

nearly all of dhs's program management offices are located within 12 of the department's component agencies , such as the transportation security administration , or u.s. customs and border protection .

within these components , caes are responsible for establishing acquisition processes and overseeing the execution of their respective portfolios .

additionally , under ad 102 , the usm can delegate acquisition decision authority to caes for programs with life - cycle cost estimates between $300 million and $1 billion .

figure 2 depicts the relationship between acquisition managers at the department , component , and program level .

the office of program analysis and evaluation ( pa&e ) , within the office of the chief financial officer ( ocfo ) , is responsible for advising the usm , among others , on resource allocation issues .

pa&e coordinates with dhs's office of policy on the department's long - term strategic planning efforts , analyzing budget submissions , cost estimates , and resource constraints .

pa&e also oversees the development of the future years homeland security program ( fyhsp ) .

dhs is required to submit the fyhsp to congress annually with each budget request .

the fyhsp is dhs's 5-year funding plan for programs approved by the secretary that are to support the dhs strategic plan .

the fyhsp provides a detailed account of time - phased resource requirements for each component , as well as programs' cost estimates , milestones , and performance measures .

nearly all of the program managers we surveyed reported their programs had experienced significant challenges increasing the risk of poor outcomes , particularly cost growth and schedule slips .

sixty - eight of the 71 programs that responded to our survey reported that they experienced funding instability , faced workforce shortfalls , or their planned capabilities changed after initiation .

most program managers reported a combination of these challenges , as illustrated in figure 3 .

we have previously reported that these challenges increase the likelihood acquisition programs will cost more and take longer to deliver capabilities than expected.realistic schedules needed to accurately measure program performance , although dhs lacks the reliable cost estimates and it has submitted some cost information to congress , and parm conducted an internal review of its major acquisition programs in march 2012 .

we used this information and our survey results to identify 42 programs that experienced cost growth , schedule slips , or both .

cost information dhs submitted to congress provides insight into the magnitude of the cost growth for 16 of the 42 programs .

using this information , we found total project costs increased from $19.7 billion in 2008 to $52.2 billion in 2011 , an aggregate increase of 166 percent .

see figure 4 .

we have previously reported that cost growth and schedule slips can lead to reduced capabilities , decreasing the value provided to the operator — as well as the value of the resources invested in the programs .

this poor performance threatens the department's ability to successfully field the capabilities it is pursuing .

prior to entering the obtain phase , programs are to establish the specific capabilities they plan to develop to improve dhs's ability to execute its mission .

forty - three survey respondents reported that their programs changed planned capabilities after the initiation of design and development activities , which occurs between ade 2b and testing .

we have previously found that both increases and decreases in planned capabilities are associated with cost growth and schedule slips .

we have found that increasing planned capabilities can lead to cost growth or schedule slips because programs are more costly to change after they begin development activities .

alternatively , we have stated that programs may choose to decrease their planned capabilities in response to cost growth or schedule slips in an effort to maintain affordability or deliver certain capabilities when needed .

at dhs , we found that more than half of the 43 programs that reported changing their capabilities had experienced cost growth or schedule slips , regardless of whether their planned capabilities increased , decreased , or both .

see figure 5 .

the 43 survey respondents that reported their planned capabilities changed identified five key reasons for the changes .

nineteen of the 43 survey respondents reported more than one reason .

see figure 6 .

survey respondents identified operator input as the most common reason for increasing planned capabilities after the initiation of development efforts , even though officials at the department , component , and program levels all said operator input at the initiation of design and development is very useful .

for example , in 2011 , we reported that the u.s .

citizenship and immigration services's transformation program did not fully define its planned capabilities before it awarded a contract to develop a new system to enhance the adjudication of applications .

after the contract was awarded , the program office worked with those officials most familiar with adjudication operations and discovered that the functions were more complex than expected .

as a result , the program office revised the requirements , and the deployment date for key capabilities slipped from april 2011 to october 2012 .

alternatively , dhs program managers identified funding availability as the most common reason for decreasing planned capabilities after the initiation of development efforts .

in the past , we have stated that agencies may reduce planned capabilities in this manner when their programs experience cost growth .

decreasing planned capabilities in response to affordability concerns may be fiscally responsible , but as a result , operators may not receive the capability originally agreed upon to address existing capability gaps .

dhs is required to establish out - year funding levels for programs annually in the fyhsp .

changes to planned out - year funding levels create funding instability , which we have previously found increases the risk of cost growth , schedule slips , and capability shortfalls .

sixty - one survey respondents reported that their programs have experienced funding instability , and we found that 44 of the 61 programs had also realized cost growth , schedule slips , or capability reductions .

additionally , 29 survey respondents reported that their programs had to resequence the delivery of certain capabilities .

for example , coast guard officials told us they deferred some of the hh - 60 helicopter's capabilities because of funding constraints across their portfolio of programs .

the coast guard delayed delivery of dedicated radar to search the surface of the water in order to replace critical components , such as main rotor blades , as planned .

figure 7 identifies how program managers reported funding instability has affected their programs .

forty - five of the 61 survey respondents that reported their programs experienced funding instability also reported reasons for the funding instability .

twenty - two survey respondents reported more than one reason .

see figure 8 .

eighteen survey respondents reported that their program experienced a funding decrease because of another program's funding needs .

we have previously reported that agencies often change funding levels in this manner when they commit to more programs than they can afford .

a pa&e official told us that dhs's resource requirements exceed the department's funding levels , and that the department has allowed major acquisition programs to advance through the acquisition life cycle without identifying how they will be funded .

furthermore , a pa&e official stated that dhs has not been able to determine the magnitude of its forthcoming funding gap because cost estimates are unreliable .

the director of the department's cost analysis division determined that only 12 major acquisition programs met most of dhs's criteria for reliable cost estimates when it reviewed the components' fiscal year 2013 budget submissions .

in 2010 , we reported that dhs officials had difficulty managing major programs because they lacked accurate cost estimates .

given the fiscal challenges facing the federal government , funding shortfalls may become an increasingly common challenge at dhs , leading to further cost growth that widens the gap between resource requirements and available funding .

dhs acquisition policy establishes that each program office should be staffed with personnel who have appropriate qualifications and experience in key disciplines , such as systems engineering , logistics , and financial management .

fifty - one survey respondents reported that their programs had experienced workforce shortfalls — specifically a lack of government personnel — increasing the likelihood their programs will perform poorly in the future .

we have previously reported that a lack of adequate staff in dhs program offices — both in terms of skill and staffing levels — increased the risk of insufficient program planning and contractor oversight , which is often associated with cost growth and schedule slips.figure 9 below identifies the functional areas where dhs acquisition programs reported workforce shortfalls .

we found that 29 of the 51 dhs programs that identified workforce shortfalls had also experienced cost growth or schedule slips.workforce shortfalls have led to insufficient program planning , hindering the development of key acquisition documents intended to inform senior - level decision making .

for example , caes and program managers said that workforce shortfalls limited program management offices' interaction with stakeholders and operators , and delayed or degraded test plans and cost estimates .

in addition , a parm official explained that dhs has had to rely on contractors to produce cost estimates because of workforce shortfalls , and the quality of these cost estimates has varied .

the the usm has stated that properly staffing programs is one of dhs's biggest challenges , and we have previously reported that the capacity of the federal government's acquisition workforce has not kept pace with increased spending for increasingly complex purchases .

parm officials told us that the irb's program reviews include assessments of the program office workforce , but that the irb considers staffing issues a relatively low priority , and we found the irb has formally documented workforce - related challenges for only 11 programs .

dhs acquisition policy reflects many key program management practices.critical knowledge that would help leaders make better informed investment decisions when managing individual programs .

this knowledge would help dhs mitigate the risks of cost growth and schedule slips resulting from funding instability , workforce shortfalls , and planned - capability changes .

however , as of april 2012 , the department had only verified that four programs documented all of the critical knowledge required to progress through the acquisition life cycle .

in most instances , dhs leadership has allowed programs it has reviewed to proceed with acquisition activities without meeting these requirements .

officials explained that dhs's culture has emphasized the need to rapidly execute missions more than sound acquisition management practices , and we have found that most of the department's major programs are at risk of cost growth and schedule slips as a result .

in addition , they lack the reliable cost estimates , realistic schedules , and agreed - upon baseline objectives that dhs acknowledges are needed to accurately track program performance , limiting dhs leadership's ability to effectively manage those programs and provide information to congress .

dhs recognizes the need to implement its acquisition policy more consistently , but significant work remains .

in 2005 , we reported that dhs established an investment review process that adopted many practices to reduce risk and increase the chances for successful outcomes .

in 2010 , we reported that ad 102 provided more detailed guidance for preparing key acquisition documents than the department's predecessor policy .

in october 2011 , dhs updated the guidebook and its appendixes , and we have found that it establishes a knowledge - based acquisition policy for program management that is largely consistent with key practices .

a knowledge - based approach to capability development allows developers to be reasonably certain , at critical points in the acquisition life cycle , that their products are likely to meet established cost , schedule , and performance objectives .

information needed to make sound investment decisions , and it would help dhs address the significant challenges we identified across its acquisition programs: funding instability , workforce shortfalls , and planned - capability changes .

over the past several years , our work has emphasized the importance of obtaining key knowledge at critical points in major system acquisitions and , based on this work , we have identified eight key practice areas for program management .

these key practice areas are summarized in table 3 , along with our assessment of dhs's acquisition policy .

in our past work examining weapon acquisition issues and best practices for product development , we have found that leading commercial firms pursue an acquisition approach that is anchored in knowledge , whereby high levels of product knowledge are demonstrated by critical points in the acquisition process .

see gao - 11-233sp .

legend:  dhs policy reflects key practices ; ◕ dhs policy substantially reflects key practices ; ◑ dhs policy partially reflects key practices .

we found that dhs's acquisition policy generally reflects key program - management practices , including some intended to help develop knowledge at critical points in the acquisition life cycle .

furthermore , the revised policy the department issued in october 2011 better reflects two key practice areas by bolstering exit criteria and taking steps to establish an adequate acquisition workforce .

specifically , the revised guidebook and its appendixes require that refined cost estimates be reviewed at major milestones after the program baseline has been established , and used to determine whether a program has developed appropriate knowledge to move forward in the acquisition life cycle .

these reviews can help reduce risk and the potential for unexpected cost and schedule growth .

additionally , the revised policy establishes that major program offices should be staffed with personnel with appropriate qualifications and experience in key acquisition disciplines .

we have previously identified that the magnitude and complexity of the dhs acquisition portfolio demands a capable and properly trained workforce and that workforce shortfalls increase the risk of poor acquisition outcomes .

the policy revisions could help mitigate this risk .

however , there are three areas where dhs could further enhance acquisition oversight: the policy requires that dhs test technologies and manufacturing processes , but it does not require that 1 ) programs demonstrate technologies in a realistic environment prior to initiating development activities at the outset of the obtain phase , or 2 ) manufacturing processes be tested prior to production .

these practices decrease the risk that rework will be required , which can lead to additional cost growth and schedule slips .

the policy requires that dhs establish exit criteria for programs moving to the next acquisition phase , and standardizes document requirements across all major programs , but it does not require that 1 ) exit criteria be quantifiable to the extent possible , or 2 ) consistent information be used across programs when approving progress within the obtain phase , specifically at ade 2b and 2c .

these practices decrease the risk that a program will make an avoidable error because management lacks information needed to leverage lessons learned across multiple program reviews .

the policy requires that program managers be certified at an appropriate level , but it does not state that they should remain with their programs until the next major milestone when possible .

this practice decreases the risk that program managers will not be held accountable for their decisions , such as proceeding without reliable cost estimates or realistic schedules .

parm officials generally acknowledged dhs has opportunities to strengthen its program - management guidance .

officials reported that they are currently in the process of updating ad 102 , which they plan to complete by the end of fiscal year 2012 .

they also plan to issue revisions to the associated guidebook and appendixes in phases .

parm officials told us that they plan to structure the revised acquisition policy by function , consolidating guidance for financial management , systems engineering , reporting requirements , and so forth .

parm officials anticipate that this organization will make it easier for users to identify relevant information as well as streamline the internal review process for future updates .

dhs acquisition policy establishes several key program - management practices through document requirements .

ad 102 requires that major acquisition programs provide the irb documents demonstrating the critical knowledge needed to support effective decision making before progressing through the acquisition life cycle .

for example , programs must document that they have assessed alternatives to select the most appropriate solution through a formal analysis of alternatives report , which must be approved by component - level leadership .

figure10 identifies acquisition documents that must be approved at the department level and their corresponding key practice areas .

dhs acquisition policy requires these documents , but the department generally has not implemented its acquisition policy as intended , and in practice the department has not adhered to key program management practices .

dhs's efforts to implement the department's acquisition policy have been complicated by the large number of legacy programs initiated before the department was created , including 11 programs that parm officials told us were in sustainment when ad 102 was signed .

we found that the department has only approved four programs' required documents in accordance with dhs policy: the national cybersecurity and protection system , the next generation network , the offshore patrol cutter , and the passenger screening program .

additionally , we found that 32 programs had none of the required documents approved by the department .

see figure 11 .

since 2008 , dhs leadership — through the irb or its predecessor body the acquisition review board — has formally reviewed 49 of the 71 major programs that responded to our survey .

it permitted 43 of those programs to proceed with acquisition activities without verifying the programs had developed the knowledge required for ad 102's key acquisition documents .

see figure 12 .

officials from half of the cae offices we spoke to reported that dhs's culture has emphasized the need to rapidly execute missions more than sound acquisition management practices .

parm officials agreed , explaining that dhs has permitted programs to advance without department - approved acquisition documents because dhs had an operational need for the promised capabilities , but the department could not approve the documents in a timely manner .

parm officials explained that , in certain instances , programs were not capable of documenting knowledge , while in others , parm lacked the capacity to validate that the documented knowledge was adequate .

in 2008 and 2010 , we reported that several programs were permitted to proceed with acquisition activities on the condition they complete key action items in the future.however , parm officials told us that many of these action items were not addressed in a timely manner .

additionally , program managers reported that there has been miscommunication between dhs headquarters and program offices regarding implementation of the acquisition policy , and we found that dhs headquarters and program managers often had a different understanding of whether their programs were in compliance with ad 102 .

for example , dhs headquarters officials told us that 19 of the 40 programs that reported through our survey they had department - approved acquisition program baselines ( apb ) in fact did not .

because dhs has not generally implemented its acquisition policy , senior leaders lack the critical knowledge needed to accurately track program performance: ( 1 ) department - approved apbs , ( 2 ) reliable cost estimates , and ( 3 ) realistic schedules .

specifically , at the beginning of 2012 , dhs leadership had approved apbs for less than one - third of the 63 programs we reviewed that are required to have one based on their progression through the acquisition life cycle .

additionally , we found that none of the programs with a department - approved apb also met dhs's criteria for both reliable cost estimates and realistic schedules , which are key components of the apb .

this raises questions about the quality of those apbs that have been approved , as well as the value of the dhs review process in practice .

figure 13 identifies how many programs currently have department - approved apbs , reliable cost estimates , and realistic schedules .

the apb is a critical tool for managing an acquisition program .

according to dhs's acquisition guidebook , the program baseline is the agreement between program , component , and department level officials , establishing how systems will perform , when they will be delivered , and what they will cost .

in practice , when the acquisition decision authority approves a program's apb , among other things , it is concurring that the proposed capability is worth the estimated cost .

however , we found that dhs plans to spend more than $105 billion on programs lacking current , department - approved apbs .

specifically , when dhs submitted the fyhsp to congress in 2011 , it reported that 34 of the 43 programs lacking department - approved apbs were expected to cost $108.8 billion over their acquisition life cycles .

dhs did not provide cost estimates for the other 9 programs because the data were unreliable .

in addition to overall cost , schedule , and performance goals , the apb also contains intermediate metrics to measure a program's progress in achieving those goals .

these intermediate metrics allow managers to take corrective actions earlier in the acquisition life cycle .

dhs's lack of apbs , parm officials explained , makes it more difficult to manage program performance .

in march 2012 , parm reported that 32 programs had experienced significant cost growth or schedule slips in its internal quarterly program accountability report .

however , dhs has only formally established that 8 of its programs have fallen short of their cost , schedule , or performance goals , because approximately three - quarters of the programs parm identified lack the current , department - approved apbs needed to authoritatively measure performance .

to accurately assess a program's performance , managers need accurate cost and schedule information .

however , dhs acquisition programs generally do not have reliable cost estimates and realistic schedules , as required by dhs policy .

in june 2012 , the department reported to gao that its senior leaders lacked confidence in the performance data they receive , hindering their efforts to manage risk and allocate resources .

gao - 10-588sp .

approved apbs .

additionally , only 12 program offices reported that they fully adhered to dhs's scheduling guidance , which requires that programs sequence all activities , examine the effects of any delays , update schedules to ensure validity , and so forth .

eight of these programs lacked department - approved apbs .

dhs's lack of reliable performance data not only hinders its internal acquisition management efforts , but also limits congressional oversight .

congress mandated the department submit the comprehensive acquisition status report ( casr ) to the senate and house committees on appropriations as part of the president's fiscal year 2013 budget , which was submitted in february 2012 .

however , dhs told us that it did not do so until august 2012 .

congress mandated dhs produce the casr in order to obtain information necessary for in - depth congressional oversight , including life - cycle cost estimates , schedules , risk ratings , and out - year funding levels for all major programs .

the casr has the potential to greatly enhance oversight efforts by establishing a common understanding of the status of all major programs .

in april 2012 , parm officials told us that dhs had begun to implement its acquisition policy in a more disciplined manner .

they told us that they had adequate capacity to review programs , and would no longer advance programs through the acquisition life cycle until dhs leadership verified the programs had developed critical knowledge .

for example , in february 2012 , the irb denied a request from the biowatch gen 3 program — which is developing a capability to detect airborne biological agents — to solicit proposals from contractors because its draft apb was not valid .

parm officials said they are using a risk - based approach to prioritize the approval of the department's apbs .

specifically , they explained that one of their fiscal year 2011 initiatives was to attain department - level approval of apbs for all level 1 programs in the obtain phase of the acquisition life cycle .

however , we found only 8 of the 19 programs parm said fell into this category had current , department - approved apbs as of september 2012 .

in an effort to improve the consistency of performance data reported by program managers , parm officials stated that they are establishing scorecards to assess cost estimates and standard work breakdown structures for it programs .

the parm officials also explained that cae's performance evaluations now include an assessment of the completeness and accuracy of performance data reported for their respective programs .

however , dhs must overcome significant challenges in order to improve the reliability of performance data and meet key requirements in the department's acquisition policy .

for example , department and component - level officials told us that program managers do not report on their programs in a consistent manner .

additionally , dhs officials told us that they lack cost estimating capacity throughout the department and that they must rely heavily on contractors , which do not consistently provide high - quality deliverables .

in august 2012 , a parm official stated that dhs was currently in the process of hiring eight additional government cost estimators to support programs .

dhs acquisition policy does not fully reflect several key portfolio - management practices , such as allocating resources strategically , and dhs has not yet reestablished an oversight board to manage its investment portfolio across the department .

as a result , dhs has largely made investment decisions on a program - by - program and component - by - component basis .

the widespread risk of poorly understood cost growth , coupled with the fiscal challenges facing the federal government , makes it essential that dhs allocate resources to its major programs in a deliberate manner .

dhs plans to develop stronger portfolio - management policies and processes , but until it does so , dhs programs are more likely to experience additional funding instability in the future , which will increase the risk of further cost growth and schedule slips .

these outcomes , combined with a tighter budget , could prevent dhs from developing needed capabilities .

in our past work , we have found that successful commercial companies use a disciplined and integrated approach to prioritize needs and allocate resources .

as a result , they can avoid pursuing more projects than their resources can support , and better optimize the return on their investment .

this approach , known as portfolio management , requires companies to view each of their investments as contributing to a collective whole , rather than as independent and unrelated .

with this enterprise perspective , companies can effectively ( 1 ) identify and prioritize opportunities , and ( 2 ) allocate available resources to support the highest priority — or most promising — opportunities .

over the past several years , we have examined the practices that private and public sector entities use to achieve a balanced mix of new projects , and based on this work , we have identified four key practice areas for portfolio management , summarized in table 4 , along with our assessment of dhs acquisition policy .

we found that dhs's acquisition policy reflects some key portfolio - management practices .

dhs has not designated individual portfolio managers , but it requires that the department's chief acquisition officer — currently the usm — be supported by the irb , which includes officials representing key functional areas , such as budget , procurement , it , and human capital .

dhs's acquisition policy also establishes that requirements , acquisition , and budget processes should be connected to promote stability .

however , as acknowledged by dhs officials , the policy does not reflect several other key portfolio - management practices: the policy does not empower portfolio managers to decide how best to invest resources .

this practice increases the likelihood resources will be invested effectively , and that portfolio managers will be held accountable for outcomes .

the policy does not establish that investments should be ranked and selected using a disciplined process .

this practice increases the likelihood the portfolio will be balanced with risk spread across products .

the policy does not establish that ( 1 ) resource allocations should align with strategic goals , or ( 2 ) the investment review policy should use long - range planning .

these practices increase the likelihood that the right amount of funds will be delivered to the right projects , maximizing return on investments .

the policy does not require portfolio reviews ( 1 ) annually to consider proposed changes , ( 2 ) as new opportunities are identified , or ( 3 ) whenever a program breaches its objectives .

these practices provide opportunities for leaders to increase the value of investments , determine whether or not the investments are still relevant and affordable , and help keep programs within cost and schedule targets .

parm officials acknowledge that the department does not currently have a policy that addresses these key portfolio - management practices .

further , they told us that there has been less focus on portfolio management than program management to date because the acquisition process is still relatively immature .

as a result , dhs largely makes investment decisions on a program - by - program and component - by - component basis .

in our work at the department of defense , we have found this approach hinders efforts to achieve a balanced mix of programs that are affordable and feasible and that provide the greatest return on investment .

parm officials anticipate that dhs will improve its portfolio - management guidance in the future by formalizing its proposed integrated investment life cycle model ( iilcm ) .

in january 2011 , dhs presented a vision of the iilcm as a means to better integrate investment management functions , including requirements development , resource allocation , and program governance .

dhs explained that the iilcm would ensure mission needs drive investment decisions and establish a common framework for monitoring and assessing the department's investments .

the iilcm would be implemented through the creation of several new department - level councils , as illustrated in figure 14 , which would identify priorities and capability gaps .

in 2003 , dhs established the joint requirements council ( jrc ) to identify crosscutting opportunities and common requirements among dhs components , and help determine how dhs should use its resources .

however , as we have previously reported , the jrc stopped meeting in 2006 .

in 2008 , we recommended that the jrc be reinstated , or that dhs establish another joint requirements oversight board .

at that time , dhs officials recognized that strengthening the jrc was a top priority .

the department has proposed the creation of a capabilities and requirements council ( crc ) to serve in a similar role as the jrc , but the crc is not yet established .

in the absence of a jrc , or the proposed crc , dhs budget officials explained it is difficult to develop a unified strategy to guide trade - offs between programs because of the diversity of the department's missions .

poor program outcomes , coupled with a tighter budget , could prevent dhs from developing needed capabilities .

in our work at the department of defense , we have found that agencies must prioritize investments , or programs will continually compete for funding by promising more capabilities than they can deliver while underestimating costs .

found that success was measured in terms of keeping a program alive rather than efficiently delivering the capabilities needed .

it appears the lack of prioritization is affecting dhs in the same way .

as discussed earlier in our assessment of program challenges , 18 of the department's programs reported dhs decreased their out - year funding levels because of another program's funding needs , and 61 programs reported they experienced some form of funding instability .

until recently , the responsibility for balancing portfolios has fallen on components .

however , dhs policy officials noted that component - level officials have a relatively limited perspective focused on those programs under their authority , making it more difficult to ensure the alignment of mission needs to department - level goals .

additionally , component - level officials can only make trade - offs across the portion of the dhs portfolio that falls under their purview , limiting opportunities to increase the department's return on its investments .

gao - 08-619 .

the usm and parm officials have stated they recognize the value of portfolio management , and they have taken some steps to fill the gap left without a functioning jrc or crc .

a parm official stated that , starting in 2012 , parm is collaborating with the offices of the chief information , financial , and procurement officers , as well as the office of policy , to conduct portfolio reviews from a functional , cross - component perspective .

in the past , parm's portfolio reviews focused on each component individually .

this new functional approach is establishing portfolios based on departmentwide missions , such as domain awareness or screening , and parm officials intend to produce trade - off recommendations for prioritizing funding across different components .

they also intend to use functional portfolio reviews to provide greater insight into the effects of funding instability , and the usm has stated that the portfolio reviews will inform the department's fiscal year 2014 budget .

dhs intends for the proposed crc to make trade - offs across the functional portfolios .

parm's quarterly program accountability report ( qpar ) , issued in march 2012 , also has the potential to inform dhs's portfolio management efforts .

in developing the qpar , parm used a standardized set of five criteria to measure the value of each program: mission alignment , architectural maturity , capability gap , mission criticality , and dhs benefit .

this allowed parm to identify 48 high - value and 13 low - value programs .

however , the qpar does not recommend using the information to prioritize resource allocations , which would address a key portfolio management practice .

further , dhs's widespread lack of department - approved mission need statements ( mns ) undermines efforts to improve portfolio management and prioritize investments .

the mns links capability gaps to the acquisitions that will fill those gaps , making it a critical tool for prioritizing programs .

the mns also provides formal executive - level acknowledgment that there is a mission need justifying the allocation of dhs's limited resources .

however , only about 40 percent of dhs's major acquisition programs have a department - approved mns .

dhs has introduced seven initiatives that could improve acquisition management by addressing longstanding challenges we have identified — such as funding instability and acquisition workforce shortfalls — which dhs survey respondents also identified in 2012 .

implementation plans are still being developed for all of these initiatives , and dhs is still working to address critical issues , particularly capacity questions .

because of this , it is too early to determine whether the dhs initiatives will be effective , as we have previously established that agencies must sustain progress over time to address management challenges .

dhs is also pursuing a tiered - governance structure that it has begun to implement for it acquisitions .

before the department can regularly delegate ade decision authority through this tiered - governance structure , dhs must successfully implement its seven acquisition management initiatives and apply its knowledge - based acquisition policy on a more consistent basis to reduce risks and improve program outcomes .

in 2005 , we identified acquisition management as a high - risk area at dhs .

since then , we have issued multiple reports identifying acquisition management challenges .

in 2008 , we made several recommendations intended to help dhs address those challenges , and in september 2010 , we provided dhs a list of specific acquisition management outcomes the department must achieve to help address the high - risk designation .

this list largely drew from our past recommendations , and stressed that the department must implement its knowledge - based acquisition policy consistently .

dhs has generally concurred with our recommendations , but still faces many of the same challenges we have previously identified .

in 2011 , dhs began to develop initiatives to address these challenges , and dhs has continued to evolve these plans in 2012 .

in january 2011 , dhs produced the initial iteration of its integrated strategy for high risk management in order to measure progress in addressing acquisition management challenges we had identified , as well as financial management , human capital , it , and management integration issues .

the department subsequently produced updates in june 2011 , december 2011 , and june 2012 .

these updates present the department's progress in developing and implementing its initiatives .

additionally , in december 2011 , dhs issued the program management and execution playbook ( playbook ) , which expounded on some of those initiatives , and introduced a vision for a “more mature , agile , and effective process for program governance and execution.” figure 15 identifies seven key dhs initiatives and how they correspond to acquisition management challenges we have identified .

as envisioned , the dhs initiatives would better position the department to implement its knowledge - based acquisition policy on a more consistent basis to reduce risks and ultimately improve individual program outcomes .

the initiatives would also help address challenges identified by survey respondents in 2012 , particularly funding instability and acquisition workforce shortfalls .

additionally , the iilcm would enhance dhs's ability to effectively manage its acquisition portfolio as a whole .

dhs has made progress implementing some of the initiatives intended to address the challenges we have identified .

in june 2012 , dhs reported that all of its components had an approved cae in place and the procurement staffing model had been completed .

in august 2012 , dhs told us that eight centers of excellence had been chartered .

however , from january 2011 to june 2012 , the schedules for four of the seven initiatives slipped by at least 6 months , including the schedule for the iilcm , which slipped by a year .

in march 2012 , an official responsible for the iilcm initiative stated that many acquisition officials throughout the department do not yet understand the intended benefits of the iilcm .

thirty - two survey respondents reported that they were not at all familiar with the initiative , as opposed to nine that reported they were very familiar with the iilcm .

additionally , officials from three cae offices , including two caes , told us that they were not familiar with the iilcm .

previously , we have reported that it is important to involve employees and obtain their ownership when transforming organizations.schedule slips and their causes .

dhs has a diverse , critical , and challenging mission that requires it to respond to an ever - evolving range of threats .

given this mission , it is important that dhs maintain an agile and flexible management approach in its day - to - day operations .

however , dhs must adopt a more disciplined and systematic approach for managing its major investments , which are intended to help meet critical mission needs .

dhs has taken some steps to improve investment management , but most of its major acquisition programs continue to cost more than expected , take longer to deploy than planned , or deliver less capability than promised .

these outcomes are largely the result of dhs's lack of adherence to key knowledge - based program management practices , even though many are reflected in the department's own acquisition policy .

dhs leadership has authorized and continued to invest in major acquisition programs even though the vast majority of those programs lack foundational documents demonstrating the knowledge needed to help manage risks and measure performance .

this limits dhs's ability to proactively identify and address the challenges facing individual programs .

further , although the department's acquisition policy contains many key practices that help reduce risks and increase the chances for successful outcomes , the policy does not include certain program management practices that could further enhance acquisition management .

for example , the policy does not require that programs demonstrate technologies in a realistic environment prior to initiating development activities , or that exit criteria be quantifiable to the extent possible .

cost growth and schedule slips at the individual program level complicate dhs's efforts to manage its investment portfolio as a whole .

when programs encounter setbacks , the department has often redirected funding to troubled programs at the expense of others , which in turn are more likely to struggle .

additionally , dhs acquisition policy does not fully reflect key portfolio - management practices that would help improve investment management across the department .

for example , the policy does not empower portfolio managers to invest resources in a disciplined manner or establish that investments should be ranked and selected using a disciplined process .

dhs acknowledges the importance of having strong portfolio - management practices .

however , dhs does not have a process to systematically prioritize its major investments to ensure that the department's acquisition portfolio is consistent with dhs's anticipated resource constraints , which is particularly important because of the diversity of the department's missions .

since 2008 , we have emphasized the need for dhs to re - establish an oversight board dedicated to addressing portfolio management challenges .

dhs has produced plans to establish such a board , but the concept is still under development .

it is essential that dhs take a more disciplined acquisition management approach moving forward , particularly as the department must adjust to a period of governmentwide funding constraints .

without greater discipline , decisionmakers will continue to lack critical information and the department will likely continue to pay more than expected for less capability than promised , which will ultimately hinder dhs's day - to - day operations and its ability to execute its mission .

further , congress's ability to assess dhs funding requests and conduct oversight will remain limited .

to its credit , dhs has undertaken a variety of initiatives over the past two years designed to address the department's longstanding acquisition management challenges , such as increasing acquisition management capabilities at the component - level .

however , more disciplined program and portfolio management at the department - level is needed before dhs can regularly delegate major milestone decision authority to component - level officials .

widespread challenges — including funding instability and acquisition workforce shortfalls — cost growth , and schedule slips indicate how much further dhs must go to improve acquisition outcomes .

we recommend that the secretary of homeland security direct the under secretary for management to take the following five actions to help mitigate the risk of poor acquisition outcomes and strengthen the department's investment management activities: modify dhs acquisition policy to more fully reflect the following program management practices: require that ( 1 ) programs demonstrate technologies in a realistic environment prior to initiating development activities , and ( 2 ) manufacturing processes be tested prior to production ; require that ( 1 ) exit criteria be quantifiable to the extent possible , and ( 2 ) consistent information be used across programs at ade 2b and 2c ; state that program managers should remain with their programs until the next major milestone when possible ; modify dhs acquisition policy to more fully reflect the following portfolio management practices: empower portfolio managers to decide how best to invest establish that investments should be ranked and selected using a establish that ( 1 ) resource allocations should align with strategic goals , and ( 2 ) the investment review policy should use long - range planning ; and require portfolio reviews ( 1 ) annually to consider proposed changes , ( 2 ) as new opportunities are identified , and ( 3 ) whenever a program breaches its objectives ; ensure all major acquisition programs fully comply with dhs acquisition policy by obtaining department - level approval for key acquisition documents before approving their movement through the acquisition life cycle ; once the department's acquisition programs comply with dhs acquisition policy , prioritize major acquisition programs departmentwide and ensure that the department's acquisition portfolio is consistent with dhs's anticipated resource constraints ; and clearly document that department - level officials should not delegate ade decision authority to component - level officials for programs lacking department approved apbs or not meeting agreed - upon cost , schedule , and performance thresholds .

dhs provided us with written comments on a draft of this report .

in its comments , dhs concurred with all five of our recommendations and noted that two should be closed based on actions taken .

the department's written comments are reprinted in appendix v. dhs also provided technical comments that we incorporated into the report as appropriate .

dhs identified specific actions the department would take to address three of our recommendations .

dhs stated that it was in the process of revising its policy to more fully reflect key program management practices .

additionally , dhs stated that it would continue to mature and solidify the portfolio review process over the next few years , and that it would revise its policy to reflect this process .

dhs anticipates that this effort will also help the department prioritize its major acquisition programs departmentwide , and help ensure that the department's acquisition portfolio is consistent with anticipated resource constraints .

dhs concurred with and requested we close our recommendation that the department ensure all acquisition programs fully comply with dhs acquisition policy by obtaining department - level approval for key acquisition documents before approving their movement through the acquisition life cycle .

dhs stated that , in effect , its executive review board is approving a program's documents when it advances the program , thus satisfying this recommendation .

as we noted in our report , dhs officials told us in april 2012 that the department has begun to implement its acquisition policy in a more disciplined manner and that it will no longer advance programs through the acquisition life cycle until dhs leadership verifies the programs have developed critical knowledge .

however , it would be premature to close this recommendation until dhs demonstrates , over time , the consistent verification of the critical knowledge captured in key documents , especially as we found that nearly all of the department's major acquisition programs lack at least some of these acquisition documents .

dhs also concurred with and requested we close our recommendation that the department clearly document that department - level officials should not delegate ade decision authority to component - level officials for programs lacking department approved apbs or not meeting agreed - upon cost , schedule , and performance thresholds .

dhs stated that it amended ad 102 to clarify that decision authority for any program that breaches an approved apb's cost , schedule or performance parameters will not be delegated to component - level officials , thus satisfying this recommendation .

however , the amendment dhs provided does not include this language or clearly document the department's stated position .

for this reason , it would be premature to close this recommendation at this time .

in addition to commenting on our recommendations , the department made a number of observations on our draft report .

for example , dhs stated that the report references many practices that occurred prior to the time period of the audit , and that the department has made measurable progress on a number of fronts .

while we reviewed investment management activities going back to november 2008 to coincide with the issuance of ad 102 , we also accounted for progress made through august 2012 by assessing ongoing dhs initiatives intended to address investment management challenges in the future .

dhs also noted that our survey of 71 programs captured valuable information , but suggested the survey data cannot be generalized and expressed concern that it would be used as the basis for a recommendation .

to clarify , none of the recommendations in this report are based on the survey data .

in the absence of reliable program data , we surveyed program managers to obtain their perspectives on challenges facing the department's acquisition programs , and we obtained responses from 92 percent of the major acquisition programs dhs identified in 2011 .

dhs noted that programs can experience cost growth and schedule slips without a “breach.” we recognize the validity of this point and our findings are consistent with this position .

dhs incorrectly suggested that our data sources for quantifying cost growth – the future years homeland security programs ( fyhsp ) issued in 2008 and 2011 – did not consistently account for costs beyond the initial five - year period .

however , these two fyhsps aggregated funding levels for each program to produce a total project cost .

to measure total project cost growth for the 16 programs , as depicted in figure 4 , we compared the total project costs reported in the 2008 fyhsp to the total project costs reported in the 2011 fyhsp .

thus , we measured changes in total project costs , not just costs over two different five - year periods .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until september 19 , 2012 .

at that time , we will send copies to the secretary of homeland security .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-4841 or huttonj@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix vi .

the objectives of this review were to assess the department of homeland security's ( dhs ) acquisition management activities .

specifically , we assessed the extent to which: ( 1 ) dhs's major acquisition programs face challenges that increase the risk of poor outcomes ; ( 2 ) dhs has policies and processes in place to effectively manage individual acquisition programs ; ( 3 ) dhs has policies and processes in place to effectively manage its portfolio of acquisition programs as a whole ; and ( 4 ) dhs has taken actions to resolve the high - risk acquisition management issues we have identified in previous reports .

to answer these questions , we reviewed 77 of the 82 programs dhs included in its fiscal year 2011 major acquisition oversight list ( maol ) , which identified each program the department designated a major acquisition in 2011 .

we excluded 5 programs that were canceled in 2011 ; these are identified in appendix iv .

the 77 selected programs were sponsored by 12 different components and departmental offices .

to determine the extent to which major dhs acquisition programs face challenges increasing the risk of poor outcomes , we surveyed the program managers for all 77 programs , and received usable responses from 71 programs ( 92 percent response rate ) .

appendix iii presents the survey questions we asked , and summarizes the responses we received .

the web - based survey was administered from january 12 , 2012 , to march 30 , 2012 .

respondents were sent an e - mail invitation to complete the survey on a gao web server using a unique username and password .

during the data collection period , nonrespondents received a reminder e - mail and phone call .

because this was not a sample survey , it has no sampling errors .

the practical difficulties of conducting any survey may also introduce nonsampling errors , such as difficulties interpreting a particular question , which can introduce unwanted variability into the survey results .

we took steps to minimize nonsampling errors by pretesting the questionnaire in person with program management officials for five different programs , each in a different component .

we conducted pretests to make sure that the questions were clear and unbiased , the data and information were readily obtainable , and that the questionnaire did not place an undue burden on respondents .

additionally , a senior methodologist within gao independently reviewed a draft of the questionnaire prior to its administration .

we made appropriate revisions to the content and format of the questionnaire after the pretests and independent review .

all data analysis programs used to generate survey results were independently verified for accuracy .

to determine the extent to which major dhs acquisition programs face challenges increasing the risk of poor outcomes , we also reviewed the 2008 and 2011 versions of the future years homeland security program ( fyhsp ) , all acquisition decision memoranda documenting dhs executive review board decisions from november 2008 to april 2012 , the office of program accountability and risk management's ( parm ) initial quarterly program assessment report ( qpar ) , issued march 2012 , and other management memos identifying available program - performance data .

the survey results and documentation review allowed us to identify program performance , and the reasons for any poor performance .

we also interviewed individuals at the component and department - level to enhance our understanding of common challenges .

at the component level , we interviewed six of the eight component acquisition executives that had been designated by the usm , and interviewed representatives of the remaining two .

at the department level , we interviewed policy , budget , and acquisition oversight officials , including the deputy assistant secretary for the office of strategic plans , the department's chief information officer , the executive director of parm , and the director of program analysis and evaluation ( pa&e ) .

these officials provided a strategic perspective on program management challenges , and shared valuable insights regarding the limitations of available program performance data .

based on their input , we chose to use fyhsp data to calculate cost growth for individual programs where possible because the document is provided to congress and constitutes dhs's most authoritative , out - year funding plan .

to determine the extent to which dhs policies and processes are in place to effectively manage individual acquisition programs , as well as the department's acquisition portfolio as a whole , we identified key acquisition management practices and assessed the extent to which dhs policies and processes reflected those practices .

we identified the key practices through a review of previous gao reports , which are listed in appendix ii .

we compared dhs acquisition directive 102-01 ( ad 102 ) , an associated guidebook — dhs instruction manual 102-01-001 — and the guidebook's 12 appendixes to those key practices , and identified the extent to which they were reflected in the department's acquisition policy using a basic scoring system .

if the dhs policy reflected a particular key practice , we assigned the policy a score of 5 for that practice .

if the policy did not reflect the key practice , we assigned it a score of 1 .

we then took the average score for all the key practices in a particular area — as identified in appendix ii — to establish an overall score for each key practice area .

we concluded that key practice areas that scored a 5 were reflected in the policy , scored a 4 were substantially reflected , scored a 3 were partially reflected , and scored a 2 were minimally reflected .

we subsequently met with parm officials to discuss our analysis , identify relevant sections of the policy that we had not yet accounted for , and solicit their thoughts on those key practices that were not reflected in the policy .

in order to assess dhs's processes for implementing its policy , we surveyed program managers , and interviewed component and department - level officials .

we also reviewed dhs's plans for the integrated investment life cycle model ( iilcm ) , which is being designed to better integrate the department's investment management functions .

further , we reviewed all acquisition decision memoranda documenting dhs executive review board decisions from november 2008 to april 2012 , the march 2012 qpar , and other management memos identifying available program - performance data , and any limitations of that data .

to determine the extent to which dhs has taken actions to resolve the high - risk acquisition management issues we have identified in previous reports and this audit , we reviewed the first three versions of the dhs integrated strategy for high risk management — issued in january , june , and december 2011 .

we also reviewed the dhs program management and execution playbook , issued in december 2011 .

we identified initiatives intended to improve acquisition management , the department's progress in implementing those initiatives , and enduring challenges confronting the department .

we also surveyed program managers , and interviewed component and department - level officials to obtain their perspectives on the initiatives .

we conducted this performance audit from august 2011 to september 2012 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

to determine the extent to which the department of homeland security ( dhs ) has policies and processes in place to effectively manage individual acquisition programs , and the department's acquisition portfolio as a whole , we identified key acquisition management practices established in our previous reports examining dhs , the department of defense , nasa , and private sector organizations .

the specific program - and portfolio - management practices , as well as the reports where we previously identified the value of those practices , are presented below .

the following list identifies several key practices that can improve outcomes when managing a portfolio of multiple programs .

information technology: critical factors underlying successful major acquisitions .

gao - 12-7 .

washington , d.c.: october 21 , 2011 .

acquisition planning: opportunities to build strong foundations for better services contracts .

gao - 11-672 .

washington , d.c.: august 9 , 2011 .

nasa: assessments of selected large - scale projects .

gao - 11-239sp .

washington , d.c.: march 3 , 2011 .

defense acquisitions: assessments of selected weapon programs .

gao - 11-233sp .

washington , d.c.: march 29 , 2011 .

defense acquisitions: strong leadership is key to planning and executing stable weapon programs .

gao - 10-522 .

washington , d.c.: may 6 , 2010 .

defense acquisitions: assessments of selected weapon programs .

gao - 10-388sp .

washington , d.c.: march 30 , 2010 .

defense acquisitions: many analyses of alternatives have not provided a robust assessment of weapon systems options .

gao - 09-665 .

washington , d.c.: september 24 , 2009 .

department of homeland security: billions invested in major programs lack appropriate oversight .

gao - 09-29 .

washington , d.c.: november 18 , 2008 .

gao cost estimating and assessment guide: best practices for developing and managing capital program costs .

gao - 09-3sp .

washington , d.c.: march 2009 .

defense acquisitions: sound business case needed to implement missile defense agency's targets program .

gao - 08-1113 .

washington , d.c.: september 26 , 2008 .

defense acquisitions: a knowledge - based funding approach could improve major weapon system program outcomes .

gao - 08-619 .

washington , d.c.: july 2 , 2008 .

defense acquisitions: realistic business cases needed to execute navy shipbuilding programs .

gao - 07-943t .

washington , d.c.: july 24 , 2007 .

best practices: an integrated portfolio management approach to weapon system investments could improve dod's acquisition outcomes .

gao - 07-388 .

washington , d.c.: march 30 , 2007 .

best practices: better support of weapon system program managers needed to improve outcomes .

gao - 06-110 .

washington , d.c.: november 30 , 2005 .

nasa's space vision: business case for prometheus 1 needed to ensure requirements match available resources .

gao - 05-242 .

washington , d.c.: february 28 , 2005 .

information technology investment management: a framework for assessing and improving process maturity .

gao - 04-394g .

washington , d.c.: march 2004 .

executive guide: leading practices in capital decision - making .

gao / aimd - 99-32 .

washington , d.c.: december 1998 .

to help determine the extent to which major department of homeland security ( dhs ) acquisition programs face challenges increasing the risk of poor outcomes , we surveyed the program managers for all 77 programs , and received usable responses from 71 programs ( 92 percent response rate ) .

the web - based survey was administered from january 12 , 2012 , to march 30 , 2012 .

we present the survey questions we asked and summarize the responses we received below .

number of respondents 28 3 .

in what phase ( s ) of the dhs acquisition directive ( ad ) 102 acquisition lifecycle is your program currently ? .

 ( select all that apply ) 1 .

need ( prior to acquisition decision event ( ade ) 1 ) 2 .

analyze / select ( between ade 1 and ade 2 ) 4 .

production / deploy / support ( post ade 3 ) .

i do not refer to this source 4 dhs acquisition program management division ( apmd ) / program analysis and risk management ( parm ) number of respondents 26 5 .

which of the following dhs - provided opportunities , if any , has your program management office used to understand dhs acquisition guidance , ad 102 ; and if used , how useful was the opportunity , if at all ? .

1 .

check box at left if your program is not required to follow ad 102 , and then click here to skip to question 13 training session ( s ) on ad 102 hosted by dhs headquarters did your program management office use this opportunity ? .

if used , how useful was the opportunity , if at all ? .

not at all useful 1 manuals and templates for implementing ad 102 provided by dhs headquarters did your program management office use this opportunity ? .

if used , how useful was the opportunity , if at all ? .

number of respondents 50 direct support for your program from dhs acquisition program management division ( apmd ) / program analysis and risk management ( parm ) did your program management office use this opportunity ? .

if used , how useful was the opportunity , if at all ? .

not at all useful 2 did your program management office use this opportunity ? .

if used , how useful was the opportunity , if at all ? .

number of respondents 16 6 .

how clear or unclear is the dhs ad 102 acquisition guidance and framework for managing the following types of acquisitions ? .

neither clear nor unclear 6 unclear very unclear 4 4 7 .

how clear or unclear is dhs ad 102 acquisition guidance , including the guidebook and appendices , regarding each of the following ? .

number of respondents 22 8 .

how clear or unclear is dhs ad 102 acquisition guidance , including the guidebook and appendices , on how to develop each of the following key acquisition documents ? .

operational requirements document ( ord ) test and evaluation master plan ( temp ) number of respondents 64 9 .

how long is the average component and dhs review period for key acquisition documents required by ad 102 ( e.g .

mns , ord , lcce and apb ) ? .

more than 1 year 5 10 .

after an acquisition review board ( arb ) review , how adequately does an acquisition decision memo ( adm ) communicate action items ? .

no opinion not applicable 5 6 11 .

how has the introduction of ad 102 helped or hindered your ability to manage your program's cost and schedule and the overall acquisition program ? .

number of respondents 65 12 .

if you would like to elaborate on any of your previous responses regarding the clarity and / or implementation of dhs acquisition guidance ( ad 102 ) please use the following space .

13 .

does your program have a dhs - approved acquisition program baseline ( apb ) ? .

no ( please explain below ) 31 13a .

if your program does not have a dhs - approved apb , please explain why it does not have one in the box below .

14 .

how does your program's current projected cost compare against its dhs - approved apb ? .

cost exceeds the apb by 8 percent or 15 .

how does your program's current projected schedule compare to its dhs - approved apb ? .

schedule is ahead of the apb 3 16 .

how do your program's current planned system capabilities compare to its dhs - approved apb ? .

number of respondents 39 17 .

how frequently , if at all , does your program management office use each of the following performance metrics to monitor your program's progress ? .

submitted to dhs leadership , not yet approved 6 operational requirements document ( ord ) test and evaluation master plan ( temp ) submitted to dhs leadership , not yet approved 7 submitted to dhs leadership , not yet approved 9 22 .

when setting operational requirements , which of the following processes best describes your program's efforts to consider alternatives at the program level ? .

no aoa or trade - off analysis was been set .

neither clear nor unclear 2 unclear very unclear 1 3 26 .

which of the following are reasons your program's kpps have changed or been redefined since development activities began ( ade 2a ) ? .

associated capabilities were determined unnecessary not a reason do not know 2 14 to demonstrate traceability between mns , ord , and temp not a reason do not know 3 11 not a reason do not know 1 1 27 .

since your program's design and development activities began ( ade 2a ) , how have each of the following factors affected your planned capabilities , if at all ? .

number of respondents 66 29 .

prior to the initiation of low - rate initial production ( ade 2c ) , how many reliability goals were met , if any , by production - representative prototypes demonstrated in the intended environment ? .

not applicable , the program will not use low - rate initial production 21 30 .

has the program used an independent testing authority ? .

no do not know 0 49 32 .

does your program use a five - year funding plan to project resource needs ? .

no do not know 0 3 33 .

did your program's funding levels in each of the following budget documents meet your program's required funding needs as reflected in your apb ? .

1 .

check box at left if your program does not have an apb , and then click here to skip to question 34 number of respondents 71 at program start , component's commitment in a resource allocation plan ( rap ) no , funds in the document were below the apb do not know not applicable 4 6 5 at program start , dhs's commitment in a resource allocation decision ( rad ) number of respondents 17 35 .

if your program has experienced funding instability ( e.g .

a change in planned out - year funding from one five - year funding plan to the next five - year funding plan ) , did it affect your program in each of the following ways ? .

number of respondents 22 36 .

if a gap existed between fy11 enacted funding and fy11 required funding , how effectively were you , as a program manager , able to directly communicate the impact on your program to dhs and component leadership ? .

1 .

check box at left if your program did not experience a gap between fy11 enacted and required funding , and then click here to skip to question 37 component leadership ( component head , cae , etc. ) .

somewhat effectively not effectively 1 dhs leadership ( deputy secretary , usm , parm officials , etc. ) .

somewhat effectively not effectively 1 3 37 .

if you would like to elaborate on how resource allocation ( i.e .

funding ) has affected the program's ability to achieve cost , schedule and performance goals , please use the following space .

38 .

since the program was initially staffed , how many program managers have overseen the program management office ( pmo ) ? .

number of respondents 71 39 .

what is the number of government ftes in your pmo for each of the following functional areas ? .

number of government ftes staffed at initiation of development activities number of government ftes currently staffed number of government ftes currently identified as a need by the program business functions ( includes auditing , business , cost estimating , financial management , property management , and purchasing ) number of respondents 47 engineering and technical ( includes systems planning , research , development and engineering ; life cycle logistics ; test and evaluation ; production , quality and manufacturing ; and facilities engineering ) .

next - generation periodic reporting system ( nprs ) .

establishing the integrated investment life cycle model ( iilcm ) not at all familiar 31 empowering the component acquisition executives ( caes ) not at all familiar 18 establishing functional coordination office ( e.g .

screening coordination office ) number of respondents 67 developing apex , a decision support tool owned by parm to capture and synthesize information from nprs and ims not at all familiar 37 47 .

how helpful , if at all , will the following dhs initiatives be in helping you manage your acquisition program ? .

establishing the integrated investment life cycle model ( iilcm ) not at all helpful 6 empowering the component acquisition executives ( caes ) not at all helpful 7 establishing functional coordination office ( e.g .

screening coordination office ) creating executive steering councils for program governance not at all helpful 8 forming the capabilities and requirements council not at all helpful 8 developing apex , a decision support tool owned by parm to capture and synthesize information from nprs and ims not at all helpful 9 48 .

please use the following space to describe any additional actions that dhs could implement that would help you better manage your acquisition program ( i.e .

improvements for acquisition governance and document development ) .

49 .

please identify any significant challenges affecting your program's ability to achieve program objectives ( i.e .

cost , schedule , and capabilities ) that have not been adequately addressed above .

50 .

if you would like , please identify any practices your program has found significantly helpful in managing your program .

table 6 below identifies the 71 major department of homeland security ( dhs ) acquisition programs that responded to our survey .

it consists of all the programs dhs included in its 2011 major acquisition oversight list , with the exception of the 6 programs that did not respond to our survey ( see table 7 ) , and the 5 programs that were cancelled in 2011 ( see table 8 ) .

table 6 also identifies whether each program's mission need statement ( mns ) , operational requirements document ( ord ) , acquisition program baseline ( apb ) , integrated logistics support plan ( ilsp ) , and test and evaluation master plan ( temp ) have been approved at the department level .

table 7 identifies the programs that were included in dhs's 2011 major acquisition oversight list , but did not respond to our survey .

table 8 identifies the programs that were included in dhs's 2011 major acquisition oversight list , but were cancelled in 2011 .

in addition to the contact named above , katherine trimble ( assistant director ) , nathan tranquilli ( analyst - in - charge ) , john crawford , david garcia , jill lacey , sylvia schatz , rebecca wilson , candice wright , and andrea yohe made key contributions to this report .

immigration benefits: consistent adherence to dhs's acquisition policy could help improve transformation program outcomes .

gao - 12-66 .

washington , d.c.: november 22 , 2011 .

coast guard: action needed as approved deepwater program remains unachievable .

gao - 11-743 .

washington , d.c.: july 28 , 2011 .

opportunities to reduce potential duplication in government programs , save tax dollars , and enhance revenue .

gao - 11-318sp .

washington , d.c.: march 1 , 2011 .

high - risk series: an update .

gao - 11-278 .

washington , d.c.: february 2011 .

defense acquisitions: assessments of selected weapon programs .

gao - 11-233sp .

washington , d.c.: march 29 , 2011 .

secure border initiative: controls over contractor payment for the technology component need improvement .

gao - 11-68 .

washington , d.c.: may 25 , 2011 .

department of homeland security: assessments of selected complex acquisitions .

gao - 10-588sp .

washington , d.c.: june 30 , 2010 .

the office of management and budget's acquisition workforce development strategic plan for civilian agencies .

gao - 10-459r .

washington , d.c.: april 23 , 2010 .

defense acquisitions: measuring the value of dod's weapon programs requires starting with realistic baselines .

gao - 09-543t .

washington , d.c.: april 1 , 2009 .

department of homeland security: billions invested in major programs lack appropriate oversight .

gao - 09-29 .

washington , d.c.: november 18 , 2008 .

homeland security: challenges in creating an effective acquisition organization .

gao - 06-1012t .

washington , d.c.: july 27 , 2006 .

homeland security: successes and challenges in dhs's efforts to create an effective acquisition organization .

gao - 05-179 .

washington , d.c.: march 29 , 2005 .

results - oriented cultures: implementation steps to assist mergers and organizational transformations .

gao - 03-669 .

washington , d.c.: july 2 , 2003 best practices: better matching of needs and resources will lead to better weapon system outcomes .

gao - 01-288 .

washington , d.c.: march 8 , 2001 .

