thank you for the opportunity to discuss federal efforts to increase the transparency of information detailing federal awards and expenditures .

as you know , the federal government makes more than $1 trillion in awards annually in forms that include contracts , grants , loans , and other awards .

since 2006 , several efforts have been initiated to provide the public with more specific information on these awards .

for example , the government currently operates several websites that provide access to detailed information on federal spending , including http: / / www.usaspending.gov ( usaspending.gov ) and http: / / www.recovery.gov ( recovery.gov ) .

however , as you noted in a recent request to us to evaluate spending transparency , while these sites represent important advances in government transparency , challenges have been identified to better ensure the quality of data on these sites .

my testimony today will address two topics: ( 1 ) the status of efforts to improve the quality of publicly available data on government awards and expenditures and ( 2 ) lessons that can be learned from the operation of recovery.gov that can contribute to other spending transparency efforts .

the statement is based on our prior work on usaspending.gov and recovery.gov .

we also reviewed reports by the office of management and budget ( omb ) and federal departments and agencies and discussed spending transparency with officials from omb and the recovery accountability and transparency board .

we conducted our work in accordance with generally accepted government auditing standards or with our quality assurance framework , as appropriate .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the first federal effort to publicly display comprehensive data on federal awards was usaspending.gov .

among other things , the federal funding accountability and transparency act of 2006 ( ffata ) required omb to establish a free , publicly accessible website containing data on federal awards no later than january 1 , 2008 .

in addition , omb was required to include data on subawards by january 1 , 2009 .

the act specified a number of required data fields , including the recipient's name , funding agency , amount of award , and a descriptive title .

the act also authorized omb to issue guidance and instructions to federal agencies for reporting award information and requires agencies to comply with that guidance .

omb launched usaspending.gov to meet the act's requirements , relying primarily on federal sources of information .

in 2010 , we reported on compliance with ffata's requirements .

in that report we presented several key findings , including:  omb had satisfied six of the act's nine requirements we reviewed and partially satisfied another , but did not satisfy two requirements ( see appendix ii for details ) .

for example , omb established the publicly searchable website – usaspending.gov – in december 2007 .

the site included the required data elements and search capabilities , and omb guidance required periodic updates from agencies consistent with the act's requirement for timeliness .

omb partially satisfied the act's requirement to establish a pilot to test the collection of subaward data .

although it started pilots at two agencies , they were initiated after the date provided for in the act .

also , omb had not satisfied the provision requiring the inclusion of subaward data on the website by january 2009 or the provision regarding periodic reporting to congress .

 although usaspending.gov included required grant information from 29 agencies for fiscal year 2008 , it did not include grant information from 15 programs at 9 other agencies .

the unlisted awards were made by large agencies , including the department of the treasury and general services administration , and smaller agencies such as the u.s. election assistance commission and japan - u.s .

friendship commission .

we reported that incomplete reporting by agencies was due in part to omb not implementing a process to identify agencies that did not report required award information and stated that without such a process , it risked continued data gaps that limited the usefulness of the site .

in a sample of 100 awards from usaspending.gov that we reviewed , each had at least one data error in a required field , consisting of either a blank data field , an inconsistency between the usaspending.gov data and agency records , or a lack of sufficient agency information to determine consistency .

in 73 of the sampled awards , 6 or more of the 17 required data fields exhibited an error .

agency officials attributed the lack of sufficient information , in part , to procedures and systems that did not include documenting all of the data required by ffata .

for those awards where we had enough information to judge sufficiency , the data field with the most inconsistencies was the award title , which often lacked necessary specificity .

this weakness was attributed , in part , to the lack of specific guidance from omb and to the lack of tools to identify incomplete reports .

we reported that until omb addressed these issues , the ability of the public to find requested information and of omb to correct errors would be limited .

to address these findings , we made several recommendations to the director of omb .

for example , we recommended that omb revise its guidance to agencies to clarify that award titles should describe the purpose of each award and how agencies should validate and document their submitted data .

we also recommended that omb develop and implement a plan to collect and report subaward data , as well as a procedure to regularly ensure that agencies report required award information .

omb generally agreed with our findings and recommendations .

since we last evaluated ffata compliance , omb has taken steps to improve usaspending.gov and the quality of its data through increased agency - level accountability and government - wide improvements .

first , in omb's 2009 open government directive , agencies were directed to designate a high - level senior official to be accountable for the quality of , and internal controls over , federal spending information disseminated on public websites .

a list of the agency - designated officials appears on usaspending.gov .

subsequently , in an april 2010 memorandum to senior accountable officials , omb required agencies to establish a data quality framework for federal spending information , including a governance structure , risk assessments , control activities , and monitoring program .

agencies were directed to submit plans for addressing these requirements to omb .

to address government - wide weaknesses , omb issued guidance to agencies on improving the quality of data in the federal procurement data system , a contract database that is one of the main sources of usaspending.gov data .

in addition , omb's april 2010 memo established a deadline for the agency collection of subaward data and announced technical improvements to usaspending.gov , including a move to a cloud computing environment , and a control board to coordinate policies and systems that support the collection and presentation of federal spending data .

one result of these efforts is the current availability of subaward data on usaspending.gov .

agencies have also reported taking steps to improve their usaspending.gov data .

for example , automated tools have been developed through interagency electronic government initiatives that are expected to improve the quality of data on grants and cooperative agreements by making it easier for agencies to regularly report their awards .

additionally , individual agencies reported efforts to improve data quality in open government plans released earlier this year .

for example , the department of commerce established a formal process to ensure that all grant offices are reporting awards in a timely manner , and the general services administration developed an "information and data quality handbook" that contains a framework for consistent data management .

agencies also reported ongoing efforts to improve data quality .

for example , the department of homeland security plans to improve the accuracy and timeliness of data posted on usaspending.gov by promulgating best practices , and the department of transportation is working with its components to develop memorandums of understanding to ensure they meet quality assurance reporting guidelines .

while the steps discussed above could contribute to improvements in the quality of spending data , their impact is not yet known because omb's recent reporting on data quality and user feedback has been limited .

specifically:  previously available information on the timeliness and completeness of agency - submitted data is no longer provided on usaspending.gov .

we previously reported that omb maintained a page at usaspending.gov that addressed the completeness of the agency - submitted data by field .

that information is no longer available on the site .

in its april 2010 memo , omb discussed the creation of a dashboard on usaspending.gov to track the timeliness , completeness , and accuracy of agencies' reported data .

after establishing a baseline , these data were to be updated quarterly .

however , the usaspending.gov site does not currently include such a dashboard .

 omb has produced only one of the required annual reports to congress that were to include data on usage of the site and public feedback on its utility .

in july 2010 , omb reported that usaspending.gov had been used extensively by the public , and that it had adopted or planned improvements based on user feedback .

however , omb has not produced any subsequent reports , as required by ffata .

on july 13 , 2012 , officials with omb's office of federal financial management told us that omb no longer plans to rely on a public dashboard to improve data quality .

instead , the officials said , omb is pursuing several other efforts , including ensuring the implementation of the data quality framework established through its prior guidance and identifying best practices for improving data quality .

as we initiate work to address your recent request on spending transparency , we will reassess the quality of data on usaspending.gov , including the extent to which agencies report award data , the accuracy of the data that are reported , and the quality assurance processes used by agencies .

as congress and the administration crafted the american recovery and reinvestment act of 2009 ( recovery act ) , they built into it provisions to increase transparency and accountability over spending .

it required recipients of recovery act funds , including grants , contracts , or loans , to submit quarterly reports with information on each project or activity , including the amount and use of funds and an estimate of the jobs created or retained .

similar to ffata , the recovery act called for the establishment of a website through which the public could gain easy access to this information .

initial establishment of the website was to take place 30 days after the recovery act's enactment .

the recovery.gov site was launched in 2009 to fulfill these requirements , and a second site — http: / / www.federalreporting.gov — was established for recipients to report their data .

recipients first reported in early october 2009 on the period from february through september 2009 , and reporting has continued for each quarter since then .

the transparency envisioned under the recovery act for tracking spending and results was unprecedented for the federal government .

tracking billions of dollars disbursed to thousands of recipients promised to be an enormous effort .

further , the need to get a system developed and operating quickly added to the challenge , as did the fact that the public would be able to access the system and form its own views as to the system's transparency .

the system also needed to be operational quickly for a variety of programs , across which even the basic question of what constituted a project could differ .

given this daunting task , omb and the recovery board implemented an iterative process involving many stakeholders that can provide insight into challenges and solutions for establishing procedures to increase spending transparency .

as part of our oversight of the recovery act and in response to a mandate to comment quarterly on recipient reporting , we issued a number of reports addressing procedures related to recipient reporting and the quality of data on recovery.gov , and we made several recommendations for improvements .

initially , we reported that a range of significant reporting and data quality issues needed to be addressed ; our later reports , however , documented both progress and further refinements needed , and progress in making them .

our recommendations included that omb clarify the definition of full - time equivalent ( fte ) jobs and encourage federal agencies to provide or improve program - specific guidance for recipients .

in general , omb and agencies acted upon our recipient reporting - related recommendations and implemented changes in guidance and procedures .

throughout the development of guidance and the early months of implementing recipients reporting , omb and the recovery board used several opportunities for two - way communication with recipients .

early on , omb and recovery board officials held weekly conference calls with state and local representatives to hear comments and suggestions from them and share decisions made .

state and local governments , with their difficult fiscal situations , were concerned about being able to meet the added reporting requirements , and the tight timeframes made this particularly difficult .

federal officials heard the concerns and made changes to their plans and related guidance in response .

for example , initial guidance in february 2009 began to lay out information that would be reported on recovery.gov and steps needed to meet reporting requirements , such as including recipient reporting requirements in grant awards and contracts .

in response to requests for more clarity , omb , with input from an array of stakeholders , issued more guidance in june 2009 .

the june guidance clarified requirements on reporting jobs , such as which recipients were required to report and how to calculate jobs created and retained .

in december 2009 , responding to concerns regarding the calculation of ftes , including some we expressed , omb issued further changes in guidance resulting in simplified jobs - reporting guidance .

recipients of recovery act funds needed to quickly learn reporting requirements and develop procedures for meeting them .

this was particularly difficult for entities that had not previously received federal funding and were not familiar with federal reporting requirements .

outreach from omb and the recovery board , including conference calls , webinars , and websites , along with guidance were instrumental in bringing recipients up to speed .

in addition , agencies provided information and training on reporting for their specific programs through conference calls and webinars .

states , as the prime recipients in many cases , ensured that their own agencies and departments and their subrecipients were informed as well by using various means of communications , including conference calls , webinars , and websites .

finally , the recovery board also maintained a help desk during the reporting period .

even so , given the uncertainties and ongoing development of the new systems , there were instances of systems going down and data rejections that frustrated recipients .

some extensions were allowed and provisions made for recipients to report and make adjustments to the data , except for ftes , after reporting closed .

after we reported that initially there were significant reporting and quality issues , omb issued guidance to federal agencies that incorporated lessons learned from the first reporting period and addressed recommendations we had made .

specifically , in december 2009 , omb required agencies to identify significant errors , particularly in award amounts , ftes , federal award numbers , and recipient name .

omb also provided guidance in identifying instances where recipients did not report .

as a result , federal agencies that awarded recovery act funds to states generally developed internal policies and procedures for reviewing data quality , as omb required .

at the ground level , agencies addressed recipients' quarterly reporting when performing their oversight of recovery act recipients .

further , agencies also reviewed data centrally and performed tests of reasonableness on recipient data by program .

omb also required agencies to provide lists each quarter of those recipients who did not report .

our discussions with agencies indicated that agencies worked with these recipients to identify reasons they did not report .

lists of those who did not report each quarter continue to be available on recovery.gov .

in our work evaluating recipient reporting under specific programs , we found that agencies put considerable effort into ensuring accuracy and completeness , but while the public transparency of recovery act spending improved , the agencies often did not benefit much from such recipient - reported data .

agency officials told us they already had much of the information ; their own systems provided information on award amounts , funds disbursed , and , to varying degrees , progress being made by grant recipients .

however , officials at one agency , the department of education , noted that the information obtained through recipient reporting did provide them a useful indication of jobs funded for education programs under the recovery act , information they otherwise did not have .

our work also identified some concerns with ensuring that descriptions of awarded projects were adequately detailed in the information that recipients reported .

data collected for recovery.gov included narrative information that provided the public with details such as the overall purpose of the award and expected results .

we found , for example , that an estimated 25 percent of the descriptions of selected infrastructure - related awards met our transparency criteria of having sufficiently clear and complete information on the award's purpose , scope , and nature of activities ; location ; cost ; outcomes ; and status of work .

another 68 percent partially met the criteria ; and an estimated 7 percent provided little or none of this information .

in its september 2010 guidance , omb added a requirement for agencies to review the narrative fields of recipient reports to better ensure transparency .

our analysis of the quality of recipient - reported data showed that recipients made errors in reporting award identification numbers , amount of awards , and other data that agencies already had , and that if those items had been pre - populated for recipients , errors might have been reduced .

the award identification number was a particularly key data element , since it was part of the mechanism to link awards across quarters , yet recipient errors as small as leaving out a hyphen could result in information not being able to be linked .

agencies identified other errors , such as incorrect award amounts , by comparing data recipients reported with data they had .

it was time - consuming both to perform those comparisons and to follow up with recipients to get them to fix the errors .

the recovery board eventually enabled recipients to “copy forward” information reported in previous rounds and modify it as needed , which helped prevent some errors .

however , some agency officials suggested that pre - populating these fields with agency data before recipients began their reporting would have reduced the number of errors .

in addition , our work indicated that recipients sometimes were required to report similar information into both agency reporting systems and federalreporting.gov .

agencies required more data in some cases to manage their programs than was required on recipient reports and made available on recovery.gov .

for example , environmental protection agency officials said that they needed project details that were not available in recovery.gov data for their recovery act water programs .

similarly , the department of transportation preferred using its own data because they were more detailed , and were reported monthly — more frequently than the recovery.gov data .

while the time constraints of implementing recovery act reporting made it difficult to consolidate data collection and prevent collecting similar data from recipients more than once , if more planning time was available to solve this issue , the burden on recipients may have been reduced .

there are initiatives under way in congress and the administration that look to build on these two transparency efforts now in place .

for example , legislation has been passed in the house of representatives and introduced in the senate to improve the accountability and transparency of federal spending .

in addition , in june 2011 the president issued an executive order establishing the government accountability and transparency board to provide strategic direction for , among other things , enhancing the transparency of federal spending .

there are lessons from the implementation of both usaspending.gov and recovery.gov that can be applied to these new initiatives .

foremost , consideration needs to be given to what objectives are to be achieved and in what priority .

as we have seen with both existing systems , success hinges upon ensuring the data's completeness and accuracy .

because it is resource - intensive to ensure all data are reported and correct , it is imperative to limit the data collected to only those essential elements .

clear objectives are helpful in guiding such focus .

in addition , the input of federal agencies , recipients , and subrecipients should be considered early in the development of both the system and its procedures .

also , as the system is implemented , communicating impending changes as soon as possible allows for better planning .

finally , as a system rolls out , recipients will need help to learn how to fulfill their reporting responsibilities .

further related to the issue of involving all stakeholders is the need to recognize the increased reporting and oversight effort required of recipients and federal agencies , and to identify approaches that minimize that effort .

for example , pre - populating data from federal agencies to reduce the need for recipients to input those data could help with accuracy , although agencies likely will need to continue to play a key role in checking data quality .

 - - - - - in conclusion , there have been great strides in increasing the transparency of federal awards since 2006 .

the usaspending.gov and recovery.gov websites offer the public a wealth of information on how federal funds are spent .

however , it is important that ongoing efforts to improve the data provided to the public continue to evolve .

we believe having a strategic vision , ensuring data quality , allowing for input of ideas , helping those who have to report , and minimizing reporting burdens can improve the chances of success .

chairman lieberman , ranking member collins , and members of the committee , this concludes my prepared statement .

i would be pleased to answer any questions that you may have .

for further information regarding this testimony , please contact stanley j. czerwinski at ( 202 ) 512-6808 or czerwinskis@gao.gov or david a. powner at ( 202 ) 512-9286 or pownerd@gao.gov .

in addition , contact points for our offices of congressional relations and public affairs may be found on the last page of this statement .

individuals who made key contributions to this testimony are carol patey and james r. sweetman , jr. , assistant directors , lee mccracken , and kevin walsh .

recovery act: as initial implementation unfolds in states and localities , continued attention to accountability issues is essential .

gao - 09-580 .

washington , d.c.: april 23 , 2009 .

recovery act: states' and localities' current and planned uses of funds while facing fiscal stresses .

gao - 09-829 .

washington , d.c.: july 8 , 2009 .

recovery act: funds continue to provide fiscal relief to states and localities , while accountability and reporting challenges need to be fully addressed .

gao - 09-1016 .

washington , d.c.: september 23 , 2009 .

recovery act: recipient reported jobs data provide some insight into use of recovery act funding , but data quality and reporting issues need attention .

gao - 10-223 .

washington , d.c.: november 19 , 2009 .

recovery act: status of states' and localities' use of funds and efforts to ensure accountability .

gao - 10-231 .

washington , d.c.: december 10 , 2009 .

recovery act: one year later , states' and localities' uses of funds and opportunities to strengthen accountability .

gao - 10-437 .

washington , d.c.: march 3 , 2010 .

recovery act: states' and localities' uses of funds and actions needed to address implementation challenges and bolster accountability .

gao - 10-604 .

washington , d.c.: may 26 , 2010 .

recovery act: increasing the public's understanding of what funds are being spent on and what outcomes are expected .

gao - 10-581 .

washington , d.c.: may 27 , 2010 .

recovery act: states could provide more information on education programs to enhance the public's understanding of fund use .

gao - 10- 807 .

washington , d.c.: july 30 , 2010 .

recovery act: opportunities to improve management and strengthen accountability over states' and localities' uses of funds .

gao - 10-999 .

washington , d.c.: september 20 , 2010 .

participants in sba's microloan program could provide additional information to enhance the public's understanding of recovery act fund uses and expected outcomes .

gao - 10-1032r .

washington , d.c.: september 29 , 2010 .

recovery act: opportunities exist to increase the public's understanding of recipient reporting on hud programs .

gao - 10-966 .

washington , d.c.: september 30 , 2010 .

recovery act: head start grantees expand services , but more consistent communication could improve accountability and decisions about spending .

gao - 11-166 .

washington , d.c.: december 15 , 2010 .

recovery act: energy efficiency and conservation block grant recipients face challenges meeting legislative and program goals and requirements .

gao - 11-379 .

washington , d.c.: april 7 , 2011 .

recovery act: funding used for transportation infrastructure projects , but some requirements proved challenging .

gao - 11-600 .

washington , d.c.: june 29 , 2011 .

recovery act: funds supported many water projects , and federal and state monitoring shows few compliance problems .

gao - 11-608 .

washington , d.c.: june 29 , 2011 .

recovery act education programs: funding retained teachers , but education could more consistently communicate stabilization monitoring issues .

gao - 11-804 .

washington , d.c.: september 22 , 2011 .

recovery act: progress and challenges in spending weatherization funds .

gao - 12-195 .

washington , d.c.: december 16 , 2011 .

recovery act: housing programs met spending milestones , but asset management information needs evaluation .

gao - 12-634 .

washington , d.c.: june18 , 2012 .

gao's assessment of compliance met omb launched usaspending.gov , a free , publicly available website , in december 2007 .

met the site captured information on all required data elements , such as the entity receiving the award and the award amounts .

met the site allowed searches of data by all required data elements and provided totals for awards made as well as downloadable data .

met the site included data for federal awards made in fiscal year 2007 and later , as well as limited data from previous years .

met to facilitate timeliness of data available on the website , omb guidance required agencies to submit award data on the 5th and 20th of each month .

met the site included a contact form for public comments and suggestions .

partially met omb commissioned two pilot programs for collecting subaward data , one at the general services administration that ran from april 2008 to december 2008 , and one at the department of health and human services that ran from october 2008 to november 2008 .

both pilots were begun after the july 2007 date specified in the act .

ffata requirement include subaward data no later than january 1 , 2009 ( an 18-month extension can be granted for subaward recipients that receive federal funds through state , local , or tribal governments if omb determines that compliance would impose an undue burden on the subaward recipient. ) .

gao's assessment of compliance not met subaward data ( eg , subcontracts and subgrants ) were not yet available for searching on usaspending.gov .

ffata allows omb to extend the deadline by 18 months for some subaward recipients .

however , according to omb , there was no official extension in place for reporting subaward data at this time .

in addition , as of november 2009 , omb had not developed a specific plan for collecting and reporting subaward data .

not met omb had not submitted the required annual report to congress containing ( 1 ) data on the usage of and public feedback on the site , ( 2 ) an assessment of the reporting burden on award recipients , and ( 3 ) an explanation of any extension of the subaward deadline .

according to omb officials , it was gathering the necessary information and planned to issue a report in 2010 .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

the published product may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

