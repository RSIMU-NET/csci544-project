federal agencies rely extensively on computerized information systems and electronic data to carry out their missions .

the security of these systems and data is essential to prevent data tampering , disruptions in critical operations , fraud , and the inappropriate disclosure of sensitive information .

concerned with accounts of attacks on systems through the internet and reports of significant weaknesses in federal computer systems that make them vulnerable to attack , congress passed the federal information security management act ( fisma ) in 2002 .

fisma recognizes that the major underlying cause for the majority of information security problems in federal agencies is the lack of an effective information security management program .

therefore , fisma set forth a comprehensive framework for ensuring the effectiveness of information security controls over information resources that support federal operations and assets .

in addition , fisma provides a mechanism for improved oversight of federal agency information security programs .

this mechanism includes mandated annual reporting by the agencies , the office of management and budget ( omb ) , and the national institute of standards and technology ( nist ) .

fisma also includes a requirement for independent annual evaluations by the inspectors general ( ig ) or independent external auditors .

in accordance with the fisma requirement that the comptroller general report periodically to the congress , our objectives were to evaluate ( 1 ) the adequacy and effectiveness of agencies' information security policies and practices and ( 2 ) implementation of the fisma requirements .

to address these objectives , we analyzed ig , agency , and gao reports on information security .

we conducted our evaluation from september 2004 through may 2005 in accordance with generally accepted government auditing standards .

for further information about our objectives , scope , and methodology , refer to appendix i .

federal agencies and our nation's critical infrastructures — such as power distribution , water supply , telecommunications , national defense , and emergency services — rely extensively on computerized information systems and electronic data to carry out their missions .

the security of these systems and data is essential to prevent data tampering , disruptions in critical operations , fraud , and inappropriate disclosure of sensitive information .

protecting federal computer systems and the systems that support critical infrastructures has never been more important due to escalating threats of computer security incidents , the ease of obtaining and using hacking tools , the steady advances in the sophistication and effectiveness of attack technology , and the emergence of new and more destructive attacks .

information security is a critical consideration for any organization that depends on information systems and networks to carry out its mission or business .

it is especially important for federal agencies where maintaining the public trust is essential .

without proper safeguards , there is enormous risk that individuals and groups with malicious intent may intrude into inadequately protected systems and use this access to obtain sensitive information , commit fraud , disrupt operations , or launch attacks against other computer systems and networks .

enacted into law on december 17 , 2002 , as title iii of the e - government act of 2002 , fisma permanently authorized and strengthened information security program , evaluation , and reporting requirements .

it assigns specific responsibilities to agency heads and chief information officers ( cio ) , igs , nist , and omb .

fisma requires each agency , including agencies with national security systems , to develop , document , and implement an agencywide information security program to provide security for the information and information systems that support the operations and assets of the agency , including those provided or managed by another agency , contractor , or other source .

specifically , this program is to include periodic assessments of the risk and magnitude of harm that could result from the unauthorized access , use , disclosure , disruption , modification , or destruction of information or information systems ; risk - based policies and procedures that cost effectively reduce information security risks to an acceptable level and ensure that information security is addressed throughout the life cycle of each information system ; subordinate plans for providing adequate information security for networks , facilities , and systems or groups of information systems ; security awareness training for agency personnel , including contractors and other users of information systems that support the operations and assets of the agency ; periodic testing and evaluation of the effectiveness of information security policies , procedures , and practices , performed with a frequency depending on risk , but no less than annually , and that includes testing of management , operational , and technical controls for every system identified in the agency's required inventory of major information systems ; a process for planning , implementing , evaluating , and documenting remedial action to address any deficiencies in the information security policies , procedures , and practices of the agency , through plans of action and milestones ; procedures for detecting , reporting , and responding to security plans and procedures to ensure continuity of operations for information systems that support the operations and assets of the agency .

fisma also requires each agency to annually report to omb , selected congressional committees , and the comptroller general on the adequacy of information security policies , procedures , and practices and compliance with requirements .

in addition , agency heads are required to annually report the results of their independent evaluations to omb , except to the extent that an evaluation pertains to a national security system ; then only a summary and assessment of that portion of the evaluation is reported to omb .

furthermore , fisma established a requirement that each agency develop , maintain , and annually update an inventory of major information systems ( including major national security systems ) operated by the agency or under its control .

this inventory is to include an identification of the interfaces between each system and all other systems or networks , including those not operated by or under the control of the agency .

responsibilities of the inspectors general under fisma , the ig for each agency must perform an independent annual evaluation of the agency's information security program and practices .

the evaluation should include testing of the effectiveness of information security policies , procedures , and practices of a representative subset of agency systems .

in addition , the evaluation must include an assessment of the compliance with the act and any related information security policies , procedures , standards , and guidelines .

for agencies without an ig , evaluations of nonnational security systems must be performed by an independent external auditor .

evaluations related to national security systems are to be performed by an entity designated by the agency head .

responsibilities of the national institute of standards and technology under fisma , nist is tasked with developing , for systems other than national security systems , ( 1 ) standards to be used by all agencies to categorize all their information and information systems , based on the objectives of providing appropriate levels of information security , according to a range of risk levels ; ( 2 ) guidelines recommending the types of information and information systems to be included in each category ; and ( 3 ) minimum information security requirements for information and information systems in each category .

nist must also develop a definition of and guidelines concerning detection and handling of information security incidents as well as guidelines , developed in conjunction with the department of defense ( dod ) and the national security agency , for identifying an information system as a national security system .

the law also assigns other information security functions to nist , including providing technical assistance to agencies on such elements as compliance with the standards and guidelines and the detection and handling of information security incidents ; evaluating private - sector information security policies and practices and commercially available information technologies to assess potential application by agencies ; evaluating security policies and practices developed for national security systems to assess their potential application by agencies ; and conducting research , as needed , to determine the nature and extent of information security vulnerabilities and techniques for providing cost - effective information security .

nist is also required to prepare an annual public report on activities undertaken in the previous year and planned for the coming year .

responsibilities of the office of management and budget fisma states that the director of omb shall oversee agency information security policies and practices , including developing and overseeing the implementation of policies , principles , standards , and guidelines on information security ; requiring agencies to identify and provide information security protections commensurate with risk and magnitude of the harm resulting from the unauthorized access , use , disclosure , disruption , modification , or destruction of information collected or maintained by or on behalf of an agency , or information systems used or operated by an agency , or by a contractor of an agency , or other organization on behalf of an agency ; coordinating information security policies and procedures with related information resource management policies and procedures ; overseeing agency compliance with fisma to enforce accountability ; reviewing at least annually , and approving or disapproving , agency information security programs .

in addition , the act requires that omb report to congress no later than march 1 of each year on agency compliance with fisma .

the 24 major federal agencies continue to have significant control weaknesses in their computer systems that threaten the integrity , confidentiality , and availability of federal information and systems .

in addition , these weaknesses place financial information at risk of unauthorized modification or destruction , sensitive information at risk of inappropriate disclosure , and critical operations at risk of disruption .

the weaknesses appear in the five major categories of information system controls ( see fig .

1 ) defined in our audit methodology for performing information security evaluations and audits .

these areas are ( 1 ) access controls , which ensure that only authorized individuals can read , alter , or delete data ; ( 2 ) software change controls , which provide assurance that only authorized software programs are implemented ; ( 3 ) segregation of duties , which reduces the risk that one individual can independently perform inappropriate actions without detection ; ( 4 ) continuity of operations planning , which provides for the prevention of significant disruptions of computer - dependent operations , and ( 5 ) an agencywide security program , which provides the framework for ensuring that risks are understood and that effective controls are selected and properly implemented .

most agencies had weaknesses in access controls , software change controls , segregation of duties , continuity of operations , and agencywide security programs , as shown in table 1 .

as a result , federal information , systems , and operations were at risk of fraud , misuse , and disruption .

the significance of these weaknesses has led us to continue to report information security as a material weakness in our audit of the fiscal year 2004 financial statements of the u.s. government and to continue to include it in our high risk list .

in the 24 major agencies' fiscal year 2004 reporting regarding their financial systems , 10 reported information security as a material weakness and 12 reported it as a reportable condition .

our audits also identified similar weaknesses in nonfinancial systems .

in our prior reports , listed in the related gao products section , we have made specific recommendations to the agencies to mitigate identified information security weaknesses .

the igs have also made specific recommendations as part of their information security review work .

a basic management control objective for any organization is to protect data supporting its critical operations from unauthorized access , which could lead to improper modification , disclosure , or deletion of the data .

as detailed in our methodology for performing information security audits , organizations accomplish this by designing and implementing controls that are intended to prevent , limit , and detect access to computing resources ( computers , networks , programs , and data ) , thereby protecting these resources from unauthorized use , modification , loss , and disclosure .

access controls can be both electronic and physical .

electronic access controls include control of user accounts , use of passwords , and assignment of user rights .

physical security controls are important for protecting computer facilities and resources from espionage , sabotage , damage , and theft .

these controls involve restricting physical access to computer resources , usually by limiting access to the buildings and rooms in which they are housed .

physical control measures may include guards , badges , and locks , used alone or in combination .

our analysis of ig , agency , and gao reports has shown that agencies have not always effectively implemented controls to allow only authorized individuals to read , alter , or delete data .

twenty - three of 24 major agencies had access control weaknesses .

we identified weaknesses in controls such as user accounts , passwords , and access rights .

for example , users created passwords that were common words .

using such words as passwords increases the possibility that an attacker could guess the password and gain access to the account .

also , agencies did not always deactivate unused accounts to prevent them from being exploited by malicious users .

in addition , agencies have weaknesses in the controls that prevent unauthorized access to their networks .

for example , at one agency , we found an excessive number of connections to the internet .

each such connection could provide a path for an attacker into the agency's network .

agencies often lacked effective physical barriers to access , including locked doors , visitor screening , and effective use of access cards .

inadequate access controls diminish the reliability of computerized data and increase the risk of unauthorized disclosure , modification , and use .

as a result , critical information held by the federal government is at heightened risk of access by unauthorized persons — individuals who could obtain personal data ( such as taxpayer information ) to perpetrate identity theft and commit financial crimes .

software change controls ensure that only authorized and fully tested software is placed in operation .

these controls , which also limit and monitor access to powerful programs and sensitive files associated with computer operations , are important in providing reasonable assurance that access controls are not compromised and that the system will not be impaired .

these policies , procedures , and techniques help ensure that all programs and program modifications are properly authorized , tested , and approved .

failure to implement these controls increases the risk that unauthorized programs or changes could be , inadvertently or deliberately , placed into operation .

our analysis revealed that 22 of the major agencies had weaknesses in software change controls .

weaknesses in this area included the failure to ensure that software was updated correctly and that changes to computer systems were properly approved .

in addition , approval , testing , and implementation documentation for changes were not always properly maintained .

consequently , there is an increased risk that programming errors or deliberate execution of unauthorized programs could compromise security controls , corrupt data , or disrupt computer operations .

segregation of duties refers to the policies , procedures , and organizational structure that helps ensure that one individual cannot independently control all key aspects of a process or computer - related operation and , thereby , conduct unauthorized actions or gain unauthorized access to assets or records .

proper segregation of duties is achieved by dividing responsibilities among two or more individuals or organizational groups .

dividing duties among individuals or groups diminishes the likelihood that errors and wrongful acts will go undetected because the activities of one individual or group will serve as a check on the activities of the other .

without adequate segregation of duties , there is an increased risk that erroneous or fraudulent transactions can be processed , improper program changes implemented , and computer resources damaged or destroyed .

fourteen agencies had weaknesses regarding segregation of information technology duties .

agencies did not always segregate duties for system administration from duties relating to security administration .

for example , individuals at certain agencies could add fictitious users to a system with elevated access privileges and perform unauthorized activities without detection .

as a result , these agencies may be exposed to an increased risk of fraud and loss .

an organization must take steps to ensure that it is adequately prepared to cope with the loss of operational capabilities due to earthquake , fire , accident , sabotage , or any other disruption .

an essential element in preparing for such catastrophes is an up - to - date , detailed , and fully tested continuity of operations plan .

such a plan should cover all key computer operations and should include planning for business continuity .

this plan is essential for helping to ensure that critical information systems , operations , and data such as financial processing and related records can be properly restored if a disaster occurred .

to ensure that the plan is complete and fully understood by all key staff , it should be tested , including surprise tests , and test plans and results documented to provide a basis for improvement .

if continuity of operations controls are inadequate , even relatively minor interruptions can result in lost or incorrectly processed data , which can cause financial losses , expensive recovery efforts , and inaccurate or incomplete mission - critical information .

most agencies did not have adequate continuity of operations planning .

twenty of the 24 major agencies had weaknesses in this area .

in our april 2005 report on federal continuity of operations plans , we determined that agencies had not developed plans that addressed all the necessary elements .

for example , fewer than half the plans reviewed contained adequate contact information for emergency communications .

few plans documented the location of all vital records for the agencies , or methods of updating those records in an emergency .

further , most of the agencies had not conducted tests , training , or exercises frequently enough to have assurance that the plan would work in an emergency .

losing the capability to process , retrieve , and protect information maintained electronically can significantly affect an agency's ability to accomplish its mission .

the underlying cause for the information security weaknesses identified at federal agencies is that they have not yet fully implemented agencywide information security programs .

an agencywide security program provides a framework and continuing cycle of activity for managing risk , developing security policies , assigning responsibilities , and monitoring the adequacy of the entity's computer - related controls .

without a well - designed program , security controls may be inadequate ; responsibilities may be unclear , misunderstood , and improperly implemented ; and controls may be inconsistently applied .

such conditions may lead to insufficient protection of sensitive or critical resources and disproportionately high expenditures for controls over low - risk resources .

our analysis has shown that none of the 24 major agencies had fully implemented agencywide information security programs .

agencies often did not adequately assess risks , develop sufficient risk - based policies or procedures for information security , ensure that existing policies and procedures were implemented effectively , or monitor operations to ensure compliance and determine the effectiveness of existing controls .

for example , our report on wireless networking at federal agencies revealed that the majority of agencies had not yet identified and responded to the security implications of this emerging technology at their facilities .

agencies had not developed policies and procedures for wireless technology , including configuration requirements , monitoring and compliance controls , or training requirements .

agencies are also not applying information security program requirements to emerging threats , such as spam , phishing , and spyware , which pose security risks to federal information systems .

spam consumes significant resources and is used as a delivery mechanism for other types of cyber attacks ; phishing can lead to identity theft , loss of sensitive information , and use of electronic government services ; and spyware can capture and release sensitive data , make unauthorized changes to software , and decrease system performance .

the blending of these threats creates additional risks that cannot be easily mitigated with currently available tools .

until agencies effectively and fully implement agencywide information security programs , federal data and systems will not be adequately safeguarded against unauthorized use , disclosure , and modification .

many of the weaknesses discussed have been pervasive for years ; our reports attribute them to ineffective security program management — a void that fisma was enacted to address .

fisma provides a comprehensive framework for developing effective agencywide information security programs .

its provisions create a cycle of risk management activities necessary for effective security program management and include requirements for agencies , igs , nist , and omb .

the government is progressing in its implementation of the information security management requirements of fisma , but challenges remain .

for example , although the agencies report progress in implementing the provisions of the act , many agencies do not have complete , accurate inventories as required .

while the igs have conducted annual evaluations of the agencies' information security programs as required , the lack of a commonly accepted framework for their evaluations has created issues with consistency and comparability .

nist , however , has developed a schedule for its required activities and has begun to issue required guidance , and omb has issued guidance on the roles and responsibilities of both the agencies and nist and has also issued annual reporting guidance and reported annually , as required , to the congress .

our analysis of the annual reporting guidance identified opportunities to increase the usefulness of the reports for oversight .

fisma details requirements for the agencies to fulfill in order to develop a strong agencywide information security program .

these key requirements are shown in figure 2 .

a detailed discussion of each of the requirements follows .

as part of the agencywide information security program required for each agency , fisma mandates that agencies assess the risk and magnitude of the harm that could result from the unauthorized access , use , disclosure , disruption , modification , or destruction of their information and information systems .

risk assessment is the first process in the risk management process , and organizations use risk assessment to determine the extent of the potential threat to information and information systems and the risk associated with an information technology system throughout its systems development life cycle .

risk assessments help ensure that the greatest risks have been identified and addressed , increase the understanding of risk , and provide support for needed controls .

the federal information processing standard ( fips ) 199 , standards for security categorization of federal information and information systems and related nist guidance provide a common framework for categorizing systems according to risk .

the framework establishes three levels of potential impact on organizational operations , assets , or individuals should a breach of security occur — high ( severe or catastrophic ) , moderate ( serious ) , and low ( limited ) — and are used to determine the impact for each of the fisma - specified security objectives of confidentiality , integrity , and availability .

once determined , security categories are to be used in conjunction with vulnerability and threat information in assessing the risk to an organization .

for fiscal year 2003 fisma reporting , omb required agencies to provide the number and percentage of systems assessed for risk .

in fiscal year 2003 , half of the 24 major agencies reported assessing the level of risk for 90 to 100 percent of their systems .

in addition , our review of 4 agencies' processes for authorizing their systems found that only 72 percent of the 32 systems we reviewed had current risk assessments .

furthermore , we identified one large federal agency that did not have risk assessments for many of its systems .

in fiscal year 2004 , agencies were not required by omb to report on the percentage of systems with risk assessments in their fisma reports ; therefore , information on agencies' performance in this area since 2003 is not readily available .

fisma requires agencies to include risk - based policies and procedures that cost - effectively reduce information security risks to an acceptable level and ensure that information security is addressed throughout the life cycle of each information system in their information security programs .

these policies include determining security control costs and developing minimally acceptable system configuration requirements .

to indicate implementation of the security cost - benefit provisions in fisma , omb requires that agencies' budget submissions specifically identify and integrate security costs as part of life - cycle costs for their information technology investments .

it has also provided criteria to be considered in determining such costs and requires that the agencies report the number of their systems that have security control costs integrated into their system life cycles .

fiscal year 2004 data for this measure showed that agencies are reporting increases in integrating the cost of security controls into the life cycle of their systems .

specifically , 19 agencies reported integrating security control costs for 90 percent or more of their systems .

this represents an increase from 9 agencies in 2003 .

governmentwide , omb reported that 85 percent of agencies' systems had security costs built into the life cycle of the system , an increase of 8 percent from fiscal year 2003 .

if agencies do not plan for security costs in the life cycle of their systems , they may not allocate adequate resources to ensure ongoing security for federal information and information systems .

fisma requires each agency to have policies and procedures that ensure compliance with minimally acceptable system configuration requirements , as determined by the agency .

in fiscal year 2004 , for the first time , agencies reported on the degree to which they had implemented security configurations for specific operating systems and software applications .

our analysis of the 2004 agency fisma reports found that 20 agencies reported that they had implemented agencywide policies containing detailed , specific system configurations .

however , these agencies did not necessarily have minimally acceptable system configuration requirements for operating systems and software applications that they were running .

specifically , some agencies reported having system configurations , but they did not always implement them on their systems .

of the remaining 4 agencies , 1 reported that it did not have system configurations , and 3 agencies provided insufficient data to determine their status for this measure .

fisma requires that agencywide information security programs include subordinate plans for providing adequate information security for networks , facilities , and systems or groups of information systems , as appropriate .

these plans are commonly referred to as system security plans .

according to nist guidance , the purpose of these plans is to ( 1 ) provide an overview of the security requirements of the system and describe the controls in place or planned for meeting those requirements and ( 2 ) delineate the responsibilities and expected behavior of all individuals who access the system .

in fiscal year 2003 , federal agencies reported that they had developed system security plans for 73 percent of agency systems .

although omb did not require agencies to report on this measure for fiscal year 2004 , analysis of the ig fisma reports for that year revealed that agencies had weaknesses in their system security plans .

for example , igs noted instances where security plans were not developed for all systems or applications .

other weaknesses included plans that were not updated after the systems were significantly modified .

without current , complete system security plans , agencies cannot be assured that vulnerabilities have been mitigated to acceptable levels .

fisma requires agencies to provide security awareness training to inform personnel , including contractors and other users of information systems that support the operations and assets of the agency , of information security risks associated with their activities and their responsibilities in complying with agency policies and procedures designed to reduce these risks .

in addition , agencies are required to provide appropriate training on information security to personnel with significant security responsibilities .

agencies reported the number and percentage of employees and contractors who received information security awareness training and the number and percentage of employees with significant security responsibilities who received specialized training .

our analysis found that agencies were reporting increases in the number and percentages of employees and contractors who have received security awareness training , but many of the agencies reported a decline in the percentage of employees with significant security responsibilities who have received specialized training .

for example , 18 of the 24 major agencies reported increasing percentages of employees and contractors who received security awareness training in fiscal year 2004 .

furthermore , all 24 agencies reported that they provided security awareness training to 60 percent or more of their employees and contractors for fiscal year 2004 , up from 19 agencies in fiscal year 2003 .

similarly , 17 agencies reported that they provided security awareness training for 90 percent or more of their employees , an increase from 13 agencies in 2003 ( see fig .

3 ) .

however , the governmentwide percentage of employees with significant security responsibilities receiving specialized training decreased from 85 to 81 percent in fiscal year 2004 .

more specifically , 10 agencies reported decreases in this performance measure .

figure 4 shows the fiscal year 2004 results for this area .

failure to provide up - to - date information security awareness training could contribute to the information security problems at agencies .

for example , in our report on wireless networks , we determined that the majority of agencies did not address wireless security issues in security awareness training .

as a result , their employees may not have been aware of the security risks when they set up unauthorized wireless networks .

fisma requires that agency information security programs include periodic testing and evaluation of the effectiveness of information security policies , procedures , and practices to be performed with a frequency that depends on risk , but no less than annually .

this is to include testing of management , operational , and technical controls of every information system identified in the fisma - required inventory of major systems .

periodically evaluating the effectiveness of security policies and controls and acting to address any identified weaknesses are fundamental activities that allow an organization to manage its information security risks proactively , rather than reacting to individual problems ad hoc only after a violation has been detected or an audit finding has been reported .

further , management control testing and evaluation as part of program reviews is an additional source of information that can be considered along with control testing and evaluation in ig and other independent audits to help provide a more complete picture of the agencies' security postures .

omb requires that agencies report the number of systems annually for which security controls have been reviewed .

in 2004 , 23 agencies reported that they had reviewed 90 percent or more of their systems , as compared to only 11 agencies in 2003 that were able to report those numbers ( see fig .

5 ) .

however , agencies have not reported the same progress in addressing reviews of contractor operations .

even though the overall average of contractor operations reviewed for the 24 major agencies increased slightly to 83 percent in fiscal year 2004 , 8 agencies reported reviewing less than 60 percent of their contractor operations ( see fig .

6 ) .

as a result , agencies cannot be assured that federal information and information systems managed by contractors are protected in accordance with agency policies .

our recent report on the oversight of contractor operations indicated that the methods that agencies are using to ensure information security oversight have limitations and need strengthening .

for example , most agencies have not incorporated fisma requirements , such as annual testing of controls , into their contract language .

additionally , most of the 24 major agencies reported having policies for contractors and users with privileged access to federal data and systems ; however , our analysis of submitted agency policies found that only 5 agencies had established specific information security oversight policies .

finally , while the majority of agencies reported using a nist self - assessment tool to review contractor security capabilities , only 10 agencies reported using the tool to assess users with privileged access to federal data and systems , which may expose federal data to increased risk .

another requirement of fisma is that agencies' information security programs include a process for planning , implementing , evaluating , and documenting remedial action to address any deficiencies in information security policies , procedures , and practices .

developing effective corrective action plans is key to ensuring that remedial action is taken to address significant deficiencies .

these remediation plans , called plans of action and milestones by omb , are to list the weaknesses and show estimated resource needs or other challenges to resolving them , key milestones and completion dates , and the status of corrective actions .

omb requires agencies to report whether they have a remediation plan for all programs and systems where a security weakness has been identified .

omb also requested that igs assess whether the agency has developed , implemented , and managed an agencywide process for these plans .

according to the igs' assessments of their agencies' remediation processes , 14 of the 24 major agencies did not almost always incorporate information security weaknesses for all systems into their remediation plans .

the igs also reported that 13 agencies did not use the remediation process to prioritize information security weaknesses more than 95 percent of the time to help ensure that significant weaknesses are addressed in an efficient and timely manner .

without a sound remediation process , agencies cannot efficiently and effectively correct weaknesses in their information security programs .

although even strong controls may not block all intrusions and misuse , organizations can reduce the risks associated with such events if they take steps to detect and respond to them before significant damage occurs .

accounting for and analyzing security problems and incidents are also effective ways for an organization to gain a better understanding of threats to its information and of the cost of its security - related problems .

such analyses can also pinpoint vulnerabilities that need to be addressed to help ensure that they will not be exploited again .

problem and incident reports can , therefore , provide valuable input for risk assessments , help in prioritizing security improvement , and be used to illustrate risks and related trends in reports to senior management .

fisma requires that agencies' information security programs include procedures for detecting , reporting , and responding to security incidents ; mitigating risks associated with such incidents before substantial damage is done ; and notifying and consulting with the information security incident center and other entities , as appropriate , including law enforcement agencies and relevant igs .

nist has provided guidance to assist organizations in establishing computer security incident - response capabilities and in handling incidents efficiently and effectively .

omb requires agencies to report information related to security incident reporting .

this information includes whether the agency follows documented policies and procedures for reporting incidents internally , externally to law enforcement , and to the united states computer emergency readiness team ( us - cert ) .

information reported for this requirement varied widely across the agencies .

some agencies reported relatively few incidents internally ( fewer than 10 ) , while others reported as many as 600,000 incidents .

half ( 12 of 24 ) of the major agencies' cios stated that they reported between 90 and 100 percent of incidents to us - cert .

one agency reported between 75 and 89 percent of incidents to us - cert .

the other agencies said that they reported 49 percent or fewer of their incidents to us - cert or provided information that was not comparable .

omb stated in its march 1 , 2005 , fisma report that it was concerned that very low numbers of incidents were being reported to us - cert .

our work in this area also indicated that agencies were not consistently reporting security incidents .

without adequate reporting , the federal government cannot be fully aware of possible threats .

fisma requires that agencywide information security programs include plans and procedures to ensure continuity of operations for information systems that support the operations and assets of the agency .

contingency plans provide specific instructions for restoring critical systems , including such elements as arrangements for alternative processing facilities in case the usual facilities are significantly damaged or cannot be accessed due to unexpected events such as temporary power failure , accidental loss of files , or a major disaster .

it is important that these plans be clearly documented , communicated to potentially affected staff , and updated to reflect current operations .

the testing of contingency plans is essential to determining whether the plans will function as intended in an emergency situation .

the most useful tests involve simulating a disaster situation to test overall service continuity .

such a test would include testing whether the alternative data processing site will function as intended and whether critical computer data and programs recovered from off - site storage are accessible and current .

in executing the plan , managers will be able to identify weaknesses and make changes accordingly .

moreover , tests will assess how well employees have been trained to carry out their roles and responsibilities in a disaster situation .

to show the status of implementing this requirement , omb required that agencies report the percentage of systems that have a contingency plan and the percentage that have contingency plans that have been tested .

overall , federal agencies reported that 57 percent of their systems had contingency plans that had been tested .

although 19 agencies reported increases in the testing of contingency plans , 6 agencies reported that less than 50 percent of their systems had tested contingency plans ( see fig .

7 ) .

also , three agencies reported having contingency plans for all their systems and only 1 reported testing the plans for all their systems .

without testing , agencies have limited assurance that they will be able to recover mission - critical applications , business processes , and information in the event of an unexpected interruption .

fisma also requires that each agency develop , maintain , and annually update an inventory of major information systems operated by the agency or under its control .

a complete and accurate inventory of major information systems is a key element of managing the agency's information technology resources , including the security of those resources .

the inventory is used to track the agency systems for annual testing and evaluation and contingency planning .

in addition , the total number of agency systems is a key element in omb's performance measures , in that agency progress is indicated by the percentage of total systems that meet specific information security requirements .

thus , inaccurate or incomplete data on the total number of agency systems affect the percentage of systems shown as meeting the requirements .

in fiscal year 2004 fisma reports , 20 of the 24 major agencies reported having complete , accurate inventories that were updated at least annually .

there was disagreement among the agencies and igs regarding the accuracy of the number of programs , systems , and contractor operations or facilities .

for instance , although 20 agencies reported having inventories that were updated at least annually , only 8 igs agreed with the accuracy of those inventories .

without complete , accurate inventories , agencies cannot efficiently maintain and secure their systems .

moreover , the performance measures that are stated as a percentage of systems , including systems and contractor operations reviewed annually , continuity plans tested , and certification and accreditation , may not accurately reflect the extent to which these security practices have been implemented .

in addition to the fisma requirements , omb requires agencies to report on their certification and accreditation process .

certification and accreditation is the requirement that agency management officials formally authorize their information systems to process information ; thereby accepting the risk associated with their operation .

this management authorization ( accreditation ) is to be supported by a formal technical evaluation ( certification ) of the management , operational , and technical controls established in an information system's security plan .

this process is not included in fisma but does include statutory requirements such as risk assessments and security plans .

therefore , omb eliminated separate reporting requirements for risk assessments and security plans .

for annual reporting , omb requires agencies to report the number of systems authorized for processing after completing certification and accreditation .

for fiscal year 2004 , omb's guidance also requested that igs assess their agencies' certification and accreditation process .

data reported for this measure showed overall increases for most agencies .

according to omb , 77 percent of government systems had undergone certification and accreditation for fiscal year 2004 .

for example , 19 of the 24 major agencies reported increasing percentages from fiscal year 2003 to fiscal year 2004 .

in addition , 17 agencies reported percentages of systems certified and accredited at or above 90 percent ( see fig .

8 ) .

although agencies have reported progress in certifying and accrediting their systems , weaknesses in the process remain .

in a previously issued report , we determined that agencies were unclear on the number of systems that undergo the process , were inconsistent in their reporting of certification and accreditation performance data , and lacked quality assurance policies and procedures relating to the certification and accreditation process .

the igs also reported weaknesses in the certification and accreditation process in their fiscal year 2004 fisma reports .

for example , igs reported systems that did not have formal authorization to operate or were missing critical elements such as security plans , risk assessments , and contingency plans .

furthermore , omb's march 2005 report to congress noted that seven igs rated their agencies' certification and accreditation process as poor .

therefore , agencies' reported data may not accurately reflect the status of an agency's implementation of this requirement .

fisma requires the igs to perform an independent evaluation of the information security program and practices of the agency to determine the effectiveness of such programs and practices .

each evaluation should include ( 1 ) testing of the effectiveness of information security policies , procedures , and practices of a representative subset of the agency's information systems and ( 2 ) assessing compliance ( based on the results of the testing ) with fisma requirements and related information security policies , procedures , standards , and guidelines .

the igs have conducted annual evaluations as required and have reported on the results .

however , they do not have a common approach to the annual evaluations .

as a result , igs may not be performing their evaluations with peak effectiveness , efficiency , and adequate quality control .

a commonly accepted framework or methodology for the fisma independent evaluations could provide improved effectiveness , increased efficiency , quality control , and consistency of application .

such a framework may provide improved effectiveness of the annual evaluations by ensuring that compliance with fisma and all related guidance , laws , and regulations is considered in the performance of the evaluation .

igs may be able to use the framework to be more efficient by focusing evaluative procedures on areas of higher risk and by following an integrated approach designed to gather evidence efficiently .

a commonly accepted framework may offer quality control by providing a standardized methodology that can be followed by all personnel .

finally , igs may obtain consistency of application through a documented methodology .

a commonly accepted framework for performing the annual fisma evaluation could offer additional benefits as well .

for example , it might allow the igs to coordinate on information security issues , weaknesses , and initiatives that cross agency lines .

it could also facilitate appropriate coverage of major federal contractors who serve multiple federal agencies .

such a framework could provide assistance to the smaller ig offices by allowing them to leverage lessons learned by larger ig offices , for example , through the development and use of model statements of work for fisma contracts .

finally , the usefulness and comparability of the igs' annual evaluations for oversight bodies may be improved by the adoption of a framework for the fisma independent evaluations .

the current inconsistencies in methodology affect the consistency and comparability of reported results .

as a result , the usefulness of the ig reviews for assessing the governmentwide information security posture is potentially reduced .

the president's council on integrity and efficiency has recognized the importance of having a framework and is working to develop one for fisma reviews .

the council is including both omb and us in its deliberations .

the council , which currently maintains the financial audit manual , a commonly accepted framework for the performance of government financial audits , brings expertise and experience to the development of a fisma evaluation framework .

nist has developed a plan for releasing important guidance for the agencies and fulfilling its other responsibilities under fisma .

nist is required , among other things , to issue guidance on information security policies and practices for the agencies , provide technical assistance , conduct research as needed in information security , and assist in the development of standards for national security systems .

after fisma was enacted , nist developed the fisma implementation project to enable it to fulfill its statutory requirements in a timely manner .

the project is divided into three phases .

phase i focuses on the development of a suite of security standards and guidelines required by fisma as well as other fisma - related publications necessary to create a robust information security program and effectively manage risk to agency operations and agency assets .

nist has already issued one fips , which covers the categorization of systems according to risk .

a second fips concerning the minimum security requirements for each risk category is due out soon .

nist has also issued guidance to assist the agencies in determining the correct risk level for systems and mapping the systems to the correct categories .

this stage is due to be completed in 2006 .

the status of the guidance is shown in figure 9 .

phase ii will focus on the development of a program for accrediting public and private sector organizations to conduct security certification services for federal agencies , as part of agencies' certification and accreditation requirements .

organizations that participate in the organizational accreditation program can demonstrate competency in the application of nist security standards and guidelines .

nist states that developing a network of accredited organizations with demonstrated competence in the provision of security certification services will give federal agencies greater confidence in the acquisition and use of such services .

phase ii is planned for fiscal year 2006 .

phase iii is the development of a program for validating security tools .

the program will rely on private sector , accredited testing laboratories to conduct evaluations of the security tools .

nist will provide validation services and laboratory oversight .

implementation of this phase is also planned for fiscal year 2006 .

the agency has also made progress in implementing other requirements .

for example , it is continuing to provide consultative services to agencies on fisma - related information security issues and has established a web site for federal agencies to identify , evaluate , and disseminate best practices for critical infrastructure protection and security .

in addition , it has established a web site for the private sector to share nonfederal information security practices .

nist has continued an ongoing dialogue with the national security agency and the committee on national security systems to coordinate and take advantage of the security work these entities have under way within the federal government .

in addition to the specific responsibilities to develop standards and guidance , other information security activities undertaken by nist include operating a computer security expert assist team to assist federal agencies in identifying and resolving security problems ; conducting security research in areas such as access control , wireless , mobile agents , smart cards , and quantum computing ; improving the security of control systems that manage key elements of the country's critical infrastructure ; and performing cyber security product certifications required for government procurements .

finally , nist issued its annual status reports as required by fisma in april of 2003 and 2004 .

according to fisma , the director of omb is responsible for developing and overseeing the implementation of information security at the agencies .

omb reported that it has used the information gathered under this act to assist it in focusing its attention and resources on poorly performing agencies .

to oversee the implementation of policies and practices relating to information security , omb has issued guidance to the agencies on their requirements under fisma .

in its annual memorandum on reporting , it instructed agencies that the use of nist standards and guidance was required .

omb has updated its budget guidance to gather data on information security at the agencies .

for example , it asks the agencies to estimate a percentage of the total investment in information technology that is associated with security .

agencies are asked to consider the products , procedures , and personnel that are dedicated primarily to provision of security .

these procedures include fisma requirements , such as risk assessments , security plans , education and training , system reviews , remedial plans , contingency planning and testing , and reviews or inspections of contractor operations .

to oversee agency compliance with fisma , omb relies on annual reporting by the agencies and the igs .

it reported the results of this annual reporting to congress by march 1 in 2004 and 2005 , as required by fisma .

in these reports , it evaluated the agencies' reported data against performance measures it had developed .

on august 23 , 2004 , omb issued its fiscal year 2004 reporting instructions .

the reporting instructions , similar to the 2003 instructions , emphasized a strong focus on performance measures and formatted these instructions to emphasize a quantitative , rather than a narrative , response .

omb stated that it is using a combination of sources to fulfill its requirement under fisma to annually approve or disapprove of agencies' information security programs ; some information is taken from security and privacy information submitted by the agencies during the budget process , and other information comes from the annual reporting .

periodic reporting of performance measures for fisma requirements and related analysis provides valuable information on the status and progress of agency efforts to implement effective security management programs .

however , as we have recently testified , our analysis of omb's annual reporting guidance identified areas where additional reporting requirements would increase usefulness of annual reports for oversight .

these areas include reporting on the quality of agency processes , risk - based reporting of data , including key fisma requirements , and ensuring clarity .

limited assurance of the quality of agency processes current performance measures offer limited assurance of the quality of agency processes that implement key security policies , controls , and practices .

for example , for the annual review process , agencies report the number of agency systems and contractor operations they reviewed .

they also report on , and the igs confirm , whether they used appropriate guidance .

however , reporting on the quality of the reviews , such as whether guidance was applied correctly or if results were tracked for remediation , is not required .

moreover , as mentioned previously , our work in this area revealed that the methods agencies were using for the reviews had limitations and needed strengthening .

providing information on the quality of the review process would further enhance the usefulness of the annually reported data in this area for management and oversight purposes .

omb has recognized the need for assurance of quality for agency processes .

for example , it specifically requested that the igs evaluate the plan of action and milestones process and the certification and accreditation process at their agencies .

the results of these evaluations call into question the reliability and quality of the data reported by several agencies .

therefore , increased risk exists that the performance data reported by the agencies may not accurately reflect the status of agencies' implementation of these information security activities .

data not reported according to system risk performance measurement data are reported on the total number of agency systems but do not indicate the assessed level of risk of those systems .

reporting by system risk could provide information about whether agencies are prioritizing their information security efforts according to risk .

for example , the performance measures for fiscal year 2004 show that 57 percent of the total number of systems have tested contingency plans , but do not indicate to what extent this 57 percent includes the agencies' high or moderate risk systems .

therefore , agencies , the administration , and congress cannot be sure that critical federal operations can be restored if an unexpected event disrupts service .

reporting does not include aspects of key requirements currently , omb reporting guidance and performance measures do not include separate and complete reporting on fisma requirements .

for example , fisma requires agencies to have procedures for detecting , reporting , and responding to security incidents .

currently , the annual reporting developed by omb focuses on incident reporting: how the agencies are reporting their incidents internally to law enforcement and to the us - cert .

although incident reporting is an important aspect of incident handling , it is only one part of the process .

additional questions that cover incident detection and response activities would be useful to oversight bodies in determining the extent to which agencies have implemented capabilities for managing security incidents .

reporting on the remediation process does not include a key aspect of this process .

current reporting guidance asks about the inclusiveness of the plans , i.e .

whether all known information security weaknesses are included ; however , if and how weaknesses are mitigated is not reported .

for example , the agencies do not report what percentage of existing weaknesses they have remedied during the year .

in addition , agencies do not report the risk level of the systems on which the weaknesses are found .

valuable information may be provided to oversight bodies by posing additional questions on the remediation process .

the annual reporting process also does not include separate reporting on certain fisma requirements .

for example , in the 2004 guidance , omb eliminated separate reporting on risk assessments and security plans .

because the guidance on the certification and accreditation process required both risk assessments and security plans , omb did not require agencies to answer separate questions in these areas .

although omb did ask for the igs' assessments of the certification and accreditation process , it did not require them to comment separately on these specific requirements .

as a result , agency management , congress , and omb do not have complete information on the status of agencies' implementation efforts for these requirements .

several questions in omb's 2004 reporting guidance could be subject to differing interpretations by igs and the agencies .

for example , one of the questions asked the igs whether they and their agency used the plan of actions and milestones as a definitive management tool ; however , igs are not required to use these plans .

therefore , a negative answer to this question could mean either that the agency and the ig were not using the plan , or that one of them was not using the plan .

as a result , it may erroneously appear that agencies were not using the plans as the major management tool for remediation of identified weaknesses as required by omb .

another example of differing interpretations was one of the inventory questions .

it asked if the ig and agency agreed on the number of programs , systems , and contractor operations in the inventory .

since the question could be interpreted two ways , the meaning of the response was unclear .

for example , if an ig replied in the negative , it could mean that while the ig agreed with the total numbers in the inventory , it disagreed with how the agency identified whether the inventory entry was a program , system , or contractor operations .

alternatively , a negative response could mean that the ig disagreed with the overall accuracy of the inventory .

additional questions in the areas of configuration management and certification and accreditation also generated confusion .

as a result , unclear reporting instructions may have decreased the reliability and consistency of reported performance data .

federal agencies have not consistently implemented effective information security policies and practices .

as a result , pervasive weaknesses exist in almost all areas of information security controls .

these weaknesses place federal operations and assets at risk of fraud , misuse , and abuse , and may put financial data at risk of unauthorized modification or destruction , sensitive information at risk of inappropriate disclosure , and critical operations at risk of disruption .

in our prior reports , as well as in reports by the igs , specific recommendations were made to the agencies to mitigate identified information security weaknesses .

the government is progressing in implementing fisma requirements ; the agencies , igs , nist , and omb have all made advances in fulfilling their requirements .

however , current reporting under fisma by the agencies produces performance data that may not accurately reflect the status of agencies' implementation of required information security policies and procedures .

oversight entities are not able to determine from the reports a true or complete picture of the adequacy and effectiveness of agencies' information security programs .

however , opportunities exist to improve reporting guidance that might lead to more useful and complete information on the implementation of agencies' information security programs .

until such information is available , there is little assurance that the pervasive weaknesses in agencywide information security programs are being addressed .

we recommend that the director of omb take the following four actions in revising future fisma reporting guidance: request the inspectors general to report on the quality of additional agency processes , such as the annual system reviews ; require agencies to report fisma data by risk category ; ensure that all aspects of key fisma requirements are reported on in the review guidance to ensure clarity of instructions .

in written comments on a draft of this report ( reprinted in app .

ii ) , the administrator , office of e - government and information technology , omb , agreed with our overall assessment of information security at the agencies , but disagreed with one of our recommendations to enhance fisma reporting guidance and provided comments on the others .

in addition , the administrator made several general comments .

in commenting on our recommendation that omb guidance request that the igs report on the quality of additional agency processes , omb stated that their current guidance has provided the igs with the opportunity to include supporting narrative responses for all questions and that the guidance encourages the igs to provide any additional meaningful information they may have .

we acknowledge that omb has given the agency igs the opportunity to include such additional information as they believe may be helpful .

however , since specific information was not requested , the resulting information that was reported , if any , was not consistent or comparable across the agencies and over time .

in our report , we noted that omb has recognized the need for assurance of quality for agency processes .

for example , omb specifically requested that the igs evaluate the plans of actions and milestones and the certification and accreditation processes at their agencies .

we believe that additional processes should be assessed for quality such as the annual system review process .

this would further enhance the usefulness of the annually reported data for management and oversight purposes .

regarding our recommendation to include fisma data by risk category , omb noted in its comments that this recommendation is now addressed by its fiscal year 2005 fisma reporting guidance .

this guidance was issued in june 2005 .

in responding to our recommendation to ensure that all key fisma requirements are reported on in the annual reports , omb disagreed with our assessment that additional sub - elements are necessary in its reporting guidance and stated that its reporting guidance satisfies all fisma requirements through a combination of data collection and specialized questions .

omb cited as examples its performance data on agencies' certification and accreditation processes and its questions to igs regarding the quality of agency corrective plans of actions and milestones .

in addition , it commented that its guidance complied with the remainder of fisma's reporting requirements by having agencies respond to specialized questions .

as noted in our report , some fisma requirements are not specifically being addressed through these means , such as reporting on risk assessments , subordinate security plans , security incident detection and response activities , and whether weaknesses are mitigated .

we agree with omb that the process of certification and accreditation requires agencies to document risk assessments and security plans .

however , as stated in our report , the igs reported the certification and accreditation processes included missing security plans , risk assessments , and contingency plans .

furthermore , seven igs rated their agencies' certification and accreditation processes as poor .

since the quality of the certification and accreditation processes at some agencies has been called into question by the igs , we believe reporting separately on the risk assessments and security plans at this time may provide better information on the status of agencies' information security implementation efforts .

omb commented on our recommendation that it review guidance to ensure clarity of instructions by stating that its staff worked with agencies and the igs throughout the year when developing the guidance and , in particular , during the reporting period to ensure that agencies adequately understood the reporting instructions .

we acknowledge omb's efforts to help ensure better clarity , but believe more needs to be done .

as noted in this report , several questions in the guidance could be subject to differing interpretations .

for example , questions in the areas of plans of actions and milestones , inventory , configuration management , and certification and accreditation generated confusion .

as a result , the reported data may contain erroneous information , and its reliability and consistency could be decreased .

omb also strongly disagreed with any inference in the draft report that its reporting guidance fails to meet the requirements of fisma .

we did not make such a statement .

rather , our report provides that omb needs to enhance its reporting guidance to the agencies so that the annual fisma reports provide more information essential for effective oversight .

similarly , omb commented that our report included the suggestion that , unless it asked a specific question in a particular way and agencies answered those questions once each year , agencies would not implement fisma nor provide adequate cost - effective security for their information and systems .

this characterization of our report is incorrect .

we noted that specific recommendations were previously made to the agencies to remedy identified information security weaknesses .

our recommendations in this report address the need for omb to enhance its fisma reporting guidance to increase the effectiveness and reliability of annual reporting .

our report also emphasized the need to improve fisma data for oversight purposes .

we believe that omb can achieve this by implementing our recommendations .

we are sending copies of this report to the director of omb and to interested congressional committees .

we will also make copies available to others upon request .

in addition , the report will be available on gao's web site at http: / / www.gao.gov .

if you have any questions or wish to discuss this report , please contact me at ( 202 ) 512-6244 or wilshuseng@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iii .

in accordance with the fisma requirement that the comptroller general report periodically to the congress , our objectives were to evaluate ( 1 ) the adequacy and effectiveness of agencies' information security policies and practices and ( 2 ) implementation of fisma requirements .

to assess the adequacy and effectiveness of agencies' information security policies and practices , we analyzed our related reports issued from the beginning of fiscal year 2003 through may of 2005 .

we also reviewed and analyzed the information security work and products of the igs .

both our reports and the igs' products used the methodology contained in the federal information system controls audit manual .

further , we reviewed and analyzed data on information security in federal agencies' performance and accountability reports .

to assess implementation of fisma requirements , we reviewed and analyzed the federal information security management act ( public law 107-347 ) ; the 24 major federal agencies' and office of inspector general fisma reports for fiscal years 2003 and 2004 , as well as the performance and accountability reports for those agencies ; the office of management and budget's fisma guidance and mandated annual reports to congress ; and the national institute of standards and technology's standards , guidance , and annual reports .

we also held discussions with agency officials and the agency inspectors general to further assess the implementation of fisma requirements .

we did not include systems categorized as national security systems in our review , nor did we review the adequacy or effectiveness of the security policies and practices for those systems .

our work was conducted in washington , d.c. , from september 2004 through may 2005 in accordance with generally accepted government auditing standards .

the following are gao's comments on omb's letter dated june 29 , 2005 .

1 .

as noted in our report , some fisma requirements are not specifically being addressed by omb's reporting instructions , such as reporting on risk assessments , subordinate security plans , security incident detection and response activities , and whether weaknesses are mitigated .

we agree with omb that the process of certification and accreditation requires agencies to document components of security planning such as risk assessment .

however , as stated in our report , the igs reported the certification and accreditation process included missing security plans , risk assessments , and contingency plans .

furthermore , seven igs rated their agencies' certification and accreditation processes as poor .

since the quality of the certification and accreditation process has been called into question by some igs , we believe that reporting separately on the components at this time may provide better information on the status of agencies' information security implementation efforts .

also , we disagree that our report indicates that omb's reporting guidance fails to meet the requirements of fisma .

we did not make such a statement .

rather , our report provides that omb needs to enhance its reporting guidance to the agencies so that the annual fisma reports provide more information essential for effective oversight .

2 .

we disagree with omb comments that our report included the suggestion that unless omb asked a specific question in a particular way and agencies answered those questions once each year , agencies would not implement fisma nor provide adequate cost - effective security for their information and systems .

we make no such statement or suggestion .

omb also stated that responsibility and accountability for implementation and compliance with fisma rests with the agencies , including monitoring their own performance throughout the year .

as noted in our report , fisma clearly defines separate roles and responsibilities for federal agencies and their igs , nist , and omb , to provide a comprehensive framework for ensuring the effectiveness of information security controls .

therefore , we cannot fully agree with omb's statement that responsibility and accountability for implementation and compliance with fisma rests with the agencies .

all parties included in the act share in the responsibility .

we do agree , however , that fisma includes the requirement that agencies monitor their own performance throughout the year .

3 .

omb's reporting guidance does not specifically address the issue of the quality of agency processes used to gather information for fisma reporting .

we acknowledge that omb has given the agency igs the opportunity to include such additional information as they believe may be helpful .

however , since specific information has not been requested , the resulting reported information has not been consistent or comparable across the agencies and over time .

in our report we noted that omb has recognized the need for assurance of quality for certain agency processes .

for example , it specifically requested that the igs evaluate the plan of actions and milestones process and the certification and accreditation process at their agencies .

we believe that additional processes should be assessed for quality such as the annual system reviews .

providing information on the quality of the review process would further enhance the usefulness of the annually reported data for management and oversight purposes .

4 .

we acknowledge omb's efforts to help ensure better clarity but believe more needs to be done .

as we noted in our report , several questions could be subject to differing interpretations .

questions in the areas of plans of actions and milestones , inventory , configuration management , and certification and accreditation generated confusion .

as a result , the reported data may contain erroneous information , and its reliability and consistency may be decreased .

5 .

the guidance to report fisma data by risk category was issued on june 13 , 2005 — after our draft report was provided to omb for comment .

reporting by system risk could provide information about whether agencies are appropriately prioritizing their information security efforts .

6 .

in this report , we do not propose solutions to agency information security weaknesses .

rather , we reported that pervasive weaknesses in federal agencies' information security policies and practices place data at risk .

this statement is supported by our prior reports and reports by the igs .

we noted that , in those prior reports , specific recommendations were made to the agencies to remedy identified information security weaknesses .

in this report , we recommended that omb enhance fisma reporting guidance to increase the effectiveness and reliability of annual reporting .

larry crosland , season dietrich , nancy glover , carol langelier , suzanne lightman , and stephanie lee made key contributions to this report .

information security: federal deposit insurance corporation needs to sustain progress .

gao - 05-486 .

washington , d.c.: may 19 , 2005 .

information security: federal agencies need to improve controls over wireless networks .

gao - 05-383 .

washington , d.c.: may 17 , 2005 .

information security: emerging cybersecurity issues threaten federal information systems .

gao - 05-231 .

washington , d.c.: may 13 , 2005 .

continuity of operations: agency plans have improved , but better oversight could assist agencies in preparing for emergencies .

gao - 05- 577 .

washington , d.c.: april 28 , 2005 .

continuity of operations: agency plans have improved , but better oversight could assist agencies in preparing for emergencies .

gao - 05- 619t .

washington , d.c.: april 28 , 2005 .

information security: improving oversight of access to federal systems and data by contractors can reduce risk .

gao - 05-362 .

washington , d.c.: april 22 , 2005 .

information security: internal revenue service needs to remedy serious weaknesses over taxpayer and bank secrecy act data .

gao - 05-482 .

washington , d.c.: april 15 , 2005 .

information security: department of homeland security faces challenges in fulfilling statutory requirements .

gao - 05-567t .

washington , d.c.: april 14 , 2005 .

information security: continued efforts needed to sustain progress in implementing statutory requirements .

gao - 05-483t .

washington , d.c.: april 7 , 2005 .

information security: securities and exchange commission needs to address weak controls over financial and sensitive data .

gao - 05-262 .

washington , d.c.: march 23 , 2005 .

high - risk series: an update .

gao - 05-207 .

washington , d.c.: january 2005 .

financial management: department of homeland security faces significant financial management challenges .

gao - 04-774 .

washington , d.c.: july 19 , 2004 .

information security: agencies need to implement consistent processes in authorizing systems for operation .

gao - 04-376 .

washington , d.c.: june 28 , 2004 .

information technology: training can be enhanced by greater use of leading practices .

gao - 04-791 .

washington , d.c.: june 24 , 2004 .

information security: agencies face challenges in implementing effective software patch management processes .

gao - 04-816t .

washington , d.c.: june 2 , 2004 .

information security: continued action needed to improve software patch management .

gao - 04-706 .

washington , d.c.: june 2 , 2004 .

information security: information system controls at the federal deposit insurance corporation .

gao - 04-630 .

washington , d.c.: may 28 , 2004 .

technology assessment: cybersecurity for critical infrastructure protection .

gao - 04-321 .

washington , d.c.: may 18 , 2004 .

continuity of operations: improved planning needed to ensure delivery of essential services .

gao - 04-638t .

washington , d.c.: april 22 , 2004 .

critical infrastructure protection: challenges and efforts to secure control systems .

gao - 04-628t .

washington , d.c.: march 30 , 2004 .

information security: continued efforts needed to sustain progress in implementing statutory requirements .

gao - 04-483t .

washington , d.c.: march 16 , 2004 .

critical infrastructure protection: challenges and efforts to secure control systems .

gao - 04-354 .

washington , d.c.: march 15 , 2004 .

information security: technologies to secure federal systems .

gao - 04- 467 .

washington , d.c.: march 9 , 2004 .

continuity of operations: improved planning needed to ensure delivery of essential government services .

gao - 04-160 .

washington , d.c.: february 27 , 2004 .

information security: further efforts needed to address serious weaknesses at usda .

gao - 04-154 .

washington , d.c.: january 30 , 2004 .

information security: improvements needed in treasury's security management program .

gao - 04-77 .

washington , d.c.: november 14 , 2003 .

information security: computer controls over key treasury internet payment system .

gao - 03-837 .

washington , d.c.: july 30 , 2003 .

information security: further efforts needed to fully implement statutory requirements in dod .

gao - 03-1037t .

washington , d.c.: july 24 , 2003 .

information security: continued efforts needed to fully implement statutory requirements .

gao - 03-852t .

washington , d.c.: june 24 , 2003 .

information security: progress made , but weaknesses at the internal revenue service continue to pose risks .

gao - 03-44 .

washington , d.c.: may 30 , 2003 .

high - risk series: an update .

gao - 03-119 .

washington , d.c.: january 2003 .

computer security: progress made , but critical federal operations and assets remain at risk .

gao - 03-303t .

washington , d.c.: november 19 , 2002 .

