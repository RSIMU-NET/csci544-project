the department of defense's ( dod ) military health system ( mhs ) offers a full range of health care services to over 9 million eligible beneficiaries , including active duty servicemembers and their dependents , medically - eligible national guard and reserve members and their dependents , and retirees and their dependents and survivors , among others .

these beneficiaries may receive care from military treatment facilities ( mtfs ) — known as direct care — or from civilian hospitals , physicians , and other clinicians participating in dod - sponsored health plans that are administered by contractors — known as purchased care .

while mtfs take the lead in delivering health care to active duty servicemembers , eligible beneficiaries can receive a wide array of primary and specialty care from the mtfs , purchased care providers , or both .

overall , about 60 percent of all the health care services that beneficiaries received in 2017 were delivered through purchased care .

in 2014 , the secretary of defense ordered a comprehensive review of the mhs that found considerable variation in the quality of care delivered .

for example , the review found that 8 of 17 mtfs with high volume surgery programs had higher than expected rates of surgical complications .

furthermore , in the case of purchased care , the review found that dod had limited information on the quality of care delivered by those civilian providers .

the information dod has on the quality of care in the mhs comes from what it collects on various quality measures .

in general , health care quality measures are standard , evidence based metrics — such as the percentage of patients receiving a screening or the rate of hospital readmissions or surgical complications — that health care systems such as the mhs use to quantify health care processes , outcomes , and other aspects of care .

health care quality measures can be linked to performance standards established for providers .

for example , a quality measure may indicate the percentage of patients who receive a diabetes screening , while a related performance standard may be that providers are expected to ensure that at least a certain percentage of applicable patients receive the screening each year .

section 730 of the national defense authorization act for fiscal year 2016 ( ndaa 2016 ) directed dod to develop plans to enhance the experience of beneficiaries receiving care under the mhs and eliminate variation in the quality of care that beneficiaries receive across direct and purchased care .

the act stipulated that dod align the measures used to assess the quality of direct and purchased care to improve care across the mhs as a whole .

in march 2017 , dod issued its response to section 730 , reporting that it had established two sets of quality measures — a set of measures for direct care described as “core measures” and another set of measures for purchased care .

the mhs reported to congress that the core direct care measures and purchased care measures are the key quality measures dod's senior health care leadership use to track dod's progress towards achieving the department's overall strategic goals of providing high quality care across the mhs as a whole .

dod reported that it aligned these quality measures across direct and purchased care where possible .

section 730 of the ndaa 2016 also includes a provision for us to assess the strengths and limitations of dod's plans for achieving the act's objectives .

in this report , we examine 1. the core direct care measures and purchased care measures dod uses to assess the quality of care in the mhs ; and 2. the extent to which dod has established performance standards related to its core direct care measures and purchased care measures and corrective action requirements for providers that do not meet these performance standards .

to examine the core direct care measures and purchased care measures dod uses to assess the quality of care in the mhs , we focused our review on the measures listed on the core dashboard and purchased care dashboard , which are used in direct care and purchased care , respectively .

we focused on the dashboard measures because the mhs reported to congress that these are the measures that dod health care leaders rely on to establish accountability throughout the mhs and identify areas where quality improvement is needed .

the measures on the dashboards are periodically updated , and we examined the measures included on the dashboards as of march 31 , 2018 and the extent to which the measures on one dashboard aligned with those on the other .

we also examined the range of quality care areas and medical conditions assessed by the dashboard measures and compared these to the range of quality care areas and medical conditions assessed by the measures included in the hospital compare measure set for inpatient care and the core quality measure collaborative ( cqmc ) measure sets for outpatient care .

because the hospital compare and cqmc measures for inpatient and outpatient care have been vetted and reviewed by multiple health care stakeholders and widely adopted , we determined that they represented appropriate benchmarks for assessing the scope of the mhs's quality assessment .

we also reviewed dod documents to understand dod senior health leadership's decisions to select and track the measures on the core and purchased care dashboards and not others .

specifically , we systematically reviewed minutes from 335 meetings of the mhs governance bodies — which represent the three military services that provide health care services under the mhs ( army , navy , and air force ) and other components of the mhs — that make final decisions on the measures to be included on the core and purchased care dashboards .

we supplemented this document review with interviews of the mhs officials responsible for managing direct care as well as those responsible for overseeing the mhs's contracting of purchased care .

we also interviewed representatives of the medical commands for each of the three military services to obtain their perspectives on the measures that the mhs had selected to assess the quality of care provided to their active duty members and other beneficiaries .

in addition , we interviewed the chair of the health care subcommittee of the military coalition , a group of 32 military , veterans , and uniformed services organizations .

although not representative , this allowed us to obtain the perspectives of beneficiaries on the mhs's quality measurement efforts .

to examine the extent to which dod has established performance standards related to its core direct care measures and purchased care measures and corrective action requirements for providers that do not meet performance standards , we reviewed policies related to the mhs's oversight of provider performance on the measures on its core and purchased care dashboards .

we also interviewed mhs officials and reviewed relevant mhs documents to determine whether the mhs sets specific performance standards for mtfs and civilian providers related to the quality measures on the core and purchased care dashboards .

we also examined whether or to what extent mhs has established requirements for initiating corrective actions when providers do not meet those performance standards .

the relevant documents we reviewed include the minutes of the mhs governance body meetings noted above ; the mhs reports to congress on direct and purchased care ; documents related to the purchased care contracts ; and reports that contractors submitted to the mhs for purchased care .

additionally , in our review of the mhs governance body meeting minutes , we examined mhs officials' decisions , their rationale , and any actions taken in response to the trends being monitored on the core and purchased care dashboard quality measures .

we compared these mhs efforts to federal standards for internal control related to monitoring .

we conducted this performance audit from june 2017 to september 2018 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

as we have previously reported in reviews of health care quality outside of the mhs , health care quality measures are standard , evidence - based metrics designed to assess the extent to which patients receive health care that increases the likelihood of desired health outcomes and are consistent with current professional knowledge .

these measures may be used to assess the quality of care in various settings , including hospitals and physician offices .

health care quality measures are intended to ( 1 ) inform providers about opportunities for potential improvements in their delivery of care , ( 2 ) encourage or incentivize providers to consistently provide high quality care , and ( 3 ) inform consumers about which providers are most likely to deliver high quality care .

there are broad categories of clinical quality measures that address various aspects of quality of care .

see table 1 for a description of these broad categories of quality measures .

the data used to calculate the results of health care quality measures can come from a number of different sources .

some measures often require detailed clinical information obtained from patient medical records , such as process measures that indicate whether timely and effective care was provided in a specific situation , for example , or whether stroke patients received clot - dissolving medication appropriately .

other measures are designed to use information on patient demographics and diagnoses that can be obtained from more readily accessible sources , such as claims data or other administrative data that have already been collected for other purposes such as billing .

in addition , patients can be asked directly , usually through surveys , to report on their experiences receiving care .

the mhs is a complex organization in which responsibility for the delivery of health care is primarily shared among the military services — army , navy , and air force — and the defense health agency ( dha ) .

the army , navy and air force medical commands report through their service chiefs to their respective military department secretaries and then to the secretary of defense .

dha reports through the office of the assistant secretary of defense for health affairs and the under secretary of defense for personnel and readiness to the secretary of defense .

the office of the assistant secretary of defense for health affairs manages the defense health program appropriation , which funds the medical and health care programs at the medical commands of the military services .

as of fiscal year 2018 , most of the mtfs , including military hospitals and clinics , were under the direction and control of the military services , which are responsible for staffing , training , and equipping those mtfs to meet mission requirements .

dha has responsibility for the managed care support contracts through which the mhs administers its purchased care , and dha also administers several mtfs in the vicinity of washington , dc .

figure 1 depicts the mhs organizational structure .

recently enacted changes will affect the administration of the mtfs in future years .

most notably , dod will alter administration of the mtfs , shifting responsibility from the military services to dha .

section 702 of the national defense authorization act for fiscal year 2017 ( ndaa 2017 ) directed dod to give dha responsibility for the administration of all mtfs , including budgetary matters , information technology , and health care administration and management .

in the conference report for ndaa 2017 , congress stated its intention that the creation of a single agency responsible for all mtfs would improve and sustain readiness , reduce costs , and increase efficiency .

dod has since prepared a series of implementation plans as it works to develop the specific policies and procedures to enable this change to take effect starting october 1 , 2018 .

the most recent plan issued by dod in june 2018 envisions a 3-year transition to be completed october 1 , 2021 .

for purchased care , dod contracts with civilian health care contractors to manage its civilian providers on a regional basis .

the primary responsibilities of these managed care support contractors include the following: developing civilian provider networks , which include hospitals and ensuring adequate access to health care ; referring and authorizing beneficiaries to receive health care ; processing health care claims ; educating providers and beneficiaries ; and conducting utilization management and quality management programs .

there have been several generations of multi - year contracts since 1996 .

in july 2016 , dod awarded its fourth generation of managed care support contracts to two regional contractors , and on january 1 , 2018 , the mhs began health care delivery under these contracts .

according to our review of dod documents , the mhs uses a structured process to select the measures on its dashboards that are used to assess the quality of direct and purchased care .

specifically , dod documents state that the core direct care measures that are on the core dashboard are selected through the mhs's performance management system called partnership for improvement ( p4i ) , which began in 2015 .

the documents show that proposals for potential quality measures are developed by work groups that focus on different specialized areas , such as maternity care or mental health .

these proposals are reviewed and approved by the steering committee for p4i , which develops the list of core quality measures for direct care .

the steering committee then presents the list of core quality measures to a succession of governance bodies — each of which incorporates representation from the three military services plus dha — for review and approval .

dod documents indicate that the mhs repeats this process annually as it decides which quality measures to add , drop , or modify for the coming fiscal year from the core dashboard .

the dod documents we reviewed lay out a parallel process that the mhs follows to select which purchased care quality measures will be tracked in the purchased care dashboard .

a work group that specializes on purchased care issues with representation of dha and the three military services develops the proposed list of quality measures for the purchased care dashboard .

this list is then reviewed and approved by the same succession of governance bodies that decide on the core dashboard measures .

officials told us and dod documents confirmed that the mhs and the purchased care contractors also track additional quality measures that are not included in the core and purchased care dashboards .

for example , mhs clinicians who provide maternity care track a set of measures developed by the national perinatal information center .

similarly , a number of military hospitals report on surgical quality measures to the national surgical quality improvement program .

the mhs also conducts surveys of mhs beneficiaries from which it obtains data for patient experience measures for both direct and purchased care .

additionally , the mhs requires the managed care support contractors that administer the mhs's networks of civilian providers for purchased care to monitor several different sets of quality measures or indicators , many of which focus on patient safety .

these include patient safety indicators , hospital acquired conditions , and serious reportable events .

they also analyze measures selected from hospital compare and the healthcare effectiveness data and information set ( hedis ) , some of which correspond to measures included in the core and purchased care dashboards .

while health care systems in the united states can use a variety of measures to assess the quality of care , two of the most widely adopted sets of quality measures include the hospital compare measure set developed by centers for medicare & medicaid services ( cms ) for inpatient care and the cqmc measure sets jointly developed by cms and major private health insurers for outpatient care .

since 2005 , cms has collected results for individual hospitals on a specific list of health care quality measures that are posted on a website known as hospital compare .

cms does this to make comparable information on the quality of care provided by different hospitals publicly available .

hospital compare currently covers more than 4,000 hospitals that participate in the medicare program .

these hospitals supply data to cms for quality measures of inpatient and emergency department care .

these data reflect the care provided to all patients treated at these hospitals , not just those covered by medicare .

each year cms goes through a formal process , including receiving input from experts and stakeholders , to review and revise the mix of quality measures that these hospitals are expected to report .

the purpose of this review , according to cms , is to ensure that the set of measures reported on hospital compare provides meaningful information for quality improvement while reducing unnecessary administrative burden .

initiated in 2014 , the cqmc is a multi - stakeholder voluntary effort focused on quality measure alignment that has developed eight sets of measures for outpatient primary and specialty care , known as the cqmc measure sets .

in developing the measure sets , cms and private health insurers negotiate sets of core measures on which they agree to focus on measuring care quality for certain conditions .

physician specialty societies , employer groups , consumer groups , and regional collaboratives also participate in the negotiations .

the cqmc measure sets have been adopted by cms for medicare and by 15 major private health insurers for commercial health plans .

additionally , section 728 of the ndaa 2017 directs the mhs to use , to the extent appropriate , these quality measures to assess the quality of direct and purchased care .

cqmc documents show that the members of the cqmc intend to continually update these core measure sets as more meaningful measures are developed over time .

cms and the private health insurers plan to expand their application of these measures incrementally , as cms conducts its annual reviews of medicare's quality measures and the insurers update or renew their contracts with different providers .

the mhs does not use a common set of measures on its core and purchased care dashboards to assess the quality of care provided through direct and purchased care .

in addition , for both direct and purchased care , the mhs uses measures on its dashboards that assess a more limited range of quality care areas and medical conditions as compared to the hospital compare and cqmc measures adopted by medicare and private health insurers .

although the ndaa 2016 directed the mhs to align its quality measures for direct and purchased care , we found that as of march 31 , 2018 , the mhs used separate sets of measures on the core and purchased care dashboards to assess the quality of care delivered in direct and purchased care , respectively .

to assess the quality of direct care , the mhs tracks 43 measures on its core dashboard , and to assess the quality of purchased care , the mhs tracks 18 measures on its purchased care dashboard .

the mhs tracks 8 measures that are the same for both dashboards , leaving 35 measures tracked only on the core dashboard for direct care and 10 measures tracked only on the purchased care dashboard for purchased care .

 ( see fig .

2. ) .

according to mhs officials , since launching the p4i performance management system in 2015 , the mhs has focused on making systematic improvements in the quality of care across the mtfs in direct care .

as a result , the 43 measures they have chosen for the core dashboard reflect their priorities for quality improvement within direct care only .

in the case of purchased care , mhs officials stated that requiring civilian providers to report on the same 43 measures that are used on the core dashboard for direct care would add burden , and the mhs had concerns that this would make civilian providers less likely to participate in purchased care .

instead , the mhs tracks 18 measures on the purchased care dashboard that rely on information sources other than provider reporting , such as claims that the providers submit in the normal course of receiving payment for their services and surveys that the mhs conducts of its beneficiaries .

mhs officials explained that they try to minimize the reporting burden for purchased care providers because for most of these civilian providers , eligible mhs beneficiaries represent only a small proportion of their patient population .

we also found that for direct care , the mhs uses its quality measures on the core dashboard to assess the quality of care delivered to beneficiaries served by individual mtfs , such as hospitals or clinics .

however , for purchased care , the mhs uses its quality measures on the purchased care dashboard to assess the quality of care delivered to the beneficiary population served by each contractor's network as a whole – not the quality of care delivered by individual civilian hospitals , clinicians , or other providers in the network .

specifically: in direct care , the mhs uses the 43 measures on the core dashboard to track the quality of care delivered by individual mtfs .

for example , on a measure of central line - associated bloodstream infections , the mhs tracks the incidence of such infections by individual mtf and by military service ( i.e. , the incidence of such infections in army , navy and air force mtfs ) .

in contrast , in purchased care , the mhs assesses information on the 18 measures on the purchased care dashboard for all beneficiaries in each of the networks administered by the two managed care support contractors .

for example , on a measure of the percentage of beneficiaries with diabetes who have their hemoglobin level tested annually , the mhs calculates an overall rate of hemoglobin testing across all the diabetic patients that receive care in each contractor's network .

the beneficiary population - level reporting on quality measures on the purchased care dashboard reflects the nature of the mhs's relationship with its managed care support contractors for purchased care .

under the terms of the contracts that the mhs has negotiated with the contractors that administer the networks of civilian providers to care for eligible beneficiaries , the contractors bear responsibility for ensuring the quality of care delivered by those providers .

while the mhs requires the managed care support contractors to monitor different sets of quality measures or indicators , such as patient safety indicators , hospital acquired conditions , and serious reportable events to identify possible cases of individual patient harm and determine appropriate interventions , the contractors report this information in annual reports to the mhs for their network as a whole , as opposed to reporting on individual providers .

because the mhs largely uses separate measures for direct and purchased care on its dashboards and tracks the quality of care delivered by civilian providers in purchased care in the aggregate rather than individually , the mhs lacks the information it needs to make comparable assessments of the quality of care delivered across the mhs as a whole .

this , in turn , limits the mhs's ability to ensure it has the information needed to determine whether it is achieving the department's overall strategic goals of providing high quality care across the mhs as a whole and ensuring that beneficiaries receive a consistent level of high quality care regardless of whether that care is delivered in direct or purchased care .

moreover , using a different set of quality of measures on the dashboards for direct and purchased care is inconsistent with section 730 of the ndaa 2016 , which directs the mhs to align its measures for direct and purchased care so it can reduce performance variation across the mhs .

mhs officials acknowledge in principle the value of using aligned measures to assess quality of care in direct and purchased care , but the officials cited a range of factors that pose challenges to achieving this objective , such as the large number of civilian providers and the lack of common health information technology systems .

based on our review , we found that one way the mhs could have a common set of quality measures for both direct and purchased care , without increasing the reporting burden on civilian providers , would be to use , as appropriate , hospital compare and cqmc quality measures .

notably , the mhs states on its website that almost all of the civilian hospitals that are in the contractors' networks for purchased care already report information on the measures posted on the hospital compare website .

as a result , there potentially would be no additional burden for these purchased care providers to report information on the hospital compare quality measures .

similarly , major health plans report that they have begun implementing the cqmc measure sets in their contracts with physicians , meaning that physicians participating in those plans already report information on cqmc outpatient quality measures .

to the extent that those physicians are also in the mhs contractors' networks for purchased care , the information the physicians report on the cqmc measures could be used by the mhs .

we found the mhs is already using some hospital compare and cqmc measures for inpatient and outpatient care .

there are a total of 76 measures that medicare and private health insurers report to hospital compare and a total of 60 cqmc outpatient measures .

besides the measures used in the core and purchased care dashboards , mhs also collects 24 of 76 hospital compare measures and 10 of the 60 cqmc outpatient measures .

for the most part , these measures are not part of the direct and purchased care dashboards that mhs leadership uses to assess the performance of direct and purchased care .

furthermore , mhs officials told us that they have no specific plans to increase the number of measures that the mhs uses from hospital compare for inpatient care delivered in its hospitals .

in the case of outpatient care , our review of dod documents shows that the mhs plans on expanding reporting to only 5 more cqmc quality measures , in large part to minimize its reporting burden .

we found that the measures the mhs uses on its core and purchased care dashboards to assess the quality of direct and purchased care address only a limited range of quality areas and medical conditions when compared with the hospital compare and cqmc measure sets that are adopted by medicare and private health insurers .

according to the national quality forum , which plays a central role in developing and annually reassessing the hospital compare measure set and also was consulted in the development of the cqmc measure sets , the measures used to assess quality of care should comprise an appropriate mix of recognized measure types , including outcome measures , process measures , experience of care measures , and cost and structure measures .

these measures should cover a broad enough range of measure types and medical conditions so that they provide an accurate overall assessment of the quality of care patients receive .

based on our analysis , table 2 below shows the limited range of measures on the core and purchased care dashboards used by the mhs to assess inpatient care , as compared to the range of inpatient measures that medicare hospitals report for hospital compare .

in general , each of the five types of measures shown in the table below addresses different aspects of health care quality in hospital settings .

for direct care , the mhs uses no more than one measure on its core dashboard for all of these five measure types except for “outcome” measures ; for purchased care , the mhs does not use any inpatient care measures on its purchased care dashboard .

similarly , based on our analysis , table 3 below shows the limited range of measures on the core and purchased care dashboards used by the mhs to assess outpatient care , as compared to the range of outpatient measures that are part of the cqmc measure sets adopted by medicare and private health insurers .

the mhs uses measures on its dashboards that assess fewer clinical focus areas and medical conditions as compared with those measures included in the cqmc measure sets .

as with hospital care , the difference is greatest with respect to purchased care .

the limitations we found in the quality measures used by the mhs — the relatively narrow range of measures as well as the relatively few measures used across direct and purchased care — reflect the mhs's priorities in selecting quality measures .

in short , the mhs focuses on the value and impact of implementing individual measures , but does not prioritize aligning the measures used across direct and purchased care or expanding the range of medical conditions and quality areas covered in the aggregate by the measures .

the mhs's annual assessment of quality measures focuses only the core dashboard measures .

for each core dashboard measure for which a change is under consideration — such as dropping , modifying , or adding another quality measure to the core dashboard — mhs officials apply a standard set of criteria involving both the feasibility of collecting the data needed for that measure and the utility of that measure for addressing a strategic priority or promoting performance improvement .

when asked about the potential value of increasing the number of hospital compare measures , mhs officials said they need to make a value - based determination of whether the benefits of obtaining results for any given hospital compare measure justified the costs of collecting and transmitting the data required for that measure .

in discussions about potential measures for the purchased care dashboard , mhs officials also focused on the characteristics of specific measures being considered for inclusion in the dashboard .

because the mhs does not prioritize expanding the range of medical conditions and quality areas covered by common measures across direct and purchased care , the measures the mhs uses provide dod's senior health care leadership with an incomplete picture of the quality of care across the mhs .

as we have noted , the mhs has reported to the congress that its dod health care leaders rely on the core and purchased care dashboard measures to establish accountability throughout the mhs and identify areas where quality improvement is needed .

however , the current approach may not lead to the selection of quality measures for the two dashboards that would enable mhs officials to identify the most critical quality of care issues in the mhs .

the lack of that information , in turn , limits the ability of dod's senior health care leadership to target their performance improvement efforts most effectively in support of dod's overall strategic goals of providing high quality care across the mhs as a whole .

the mhs has established performance standards in direct care related to the core dashboard measures and has corrective action requirements for mtfs that do not meet the standards .

however , the mhs has not established performance standards related to the purchased care dashboard measures for individual civilian providers in purchased care and therefore does not have related corrective action requirements for these providers .

as part of its p4i performance management system for direct care , the mhs has established specific performance standards that each mtf must meet in delivering quality care to mhs beneficiaries .

these standards — some of which are under development — specify a minimum level of performance that each mtf should achieve related to the core dashboard quality measures tracked in direct care .

for example , in the case of the hedis all cause readmission measure on the core dashboard , the mhs's performance standard is that mtfs should have a rate of unplanned acute readmissions within 30 days of an initial hospital admission that is as good as or better than the national 75th percentile .

this performance standard is based on the readmission rates that the national committee for quality assurance , the lead entity for that measure , has observed across u.s. hospitals .

during regularly recurring governance meetings throughout the year , mhs governance bodies review how mtfs have performed relative to the performance standards for the core dashboard measures .

our review found that during these meetings , the governance bodies generally do not examine the circumstances of mtfs that do not perform well on the performance standards related to the core dashboard measures .

consequently , dod's senior health care leadership within the governance bodies may receive limited information on the challenges faced by low - performing individual mtfs .

however , during these meetings , officials from the military services and dha highlight mtfs that are performing well on the established performance standards , and the officials share best practices and specific strategies used to achieve high performance .

we also found that in direct care , the mhs requires mtfs that do not meet the mhs's performance standards related to its core dashboard measures to take corrective actions to improve the quality of care they deliver .

the military services — army , navy and air force — and dha have been responsible for implementing this requirement .

for example , navy officials explained that they periodically review information collected on the mhs's core dashboard quality measures to analyze areas where mtfs do not meet established performance standards tied to these measures and to oversee mtfs' efforts to correct these deficiencies .

officials told us that each of the services exercises its discretion to independently develop and implement the corrective actions that the service determines best address the performance issues identified through the use of the mhs's quality measures .

for example , to help reduce the number of central line - associated bloodstream infections ( clabsi ) , the army began financially awarding mtfs that performed well on the clabsi measure , whereas the air force developed a toolkit to help providers prevent clabsi .

as the mhs moves to transfer administration of the mtfs from the individual military services to dha as directed by section 702 of the ndaa 2017 , the approach for assessing performance and implementing corrective actions is likely to change .

the mhs's recently issued implementation plan as of june 2018 outlines some alterations to the current performance assessment process .

specifically , mtfs will create and submit a performance plan that will be reviewed and approved by dha .

dha will host monthly review sessions with mtfs to track performance on the plan .

mtfs will be evaluated using a set of measures aligned to the quadruple aim that will include many but not all of the core dashboard measures .

the mhs has not established performance standards related to the 18 purchased care dashboard measures for individual civilian hospitals , clinicians , or other providers in purchased care .

instead , the mhs has established performance standards related to the 18 purchased care dashboard measures that mhs officials use to track the performance of each of the two managed care support contractors .

according to mhs officials , the mhs does not require the contractors to ensure that each individual hospital , physician , or other provider in these networks meets the performance standards related to the purchased care dashboard measures .

for example , in the case of a measure on the use of imaging for low back pain , the mhs has set a performance standard for each managed care support contractor , one that aims at avoiding excessive imaging across the beneficiary population in the contractor's network .

however , officials told us that the information that the mhs collects on the measure — the number of beneficiaries in each of the contractors' networks who receive imaging services for low back pain — does not indicate the extent to which each individual civilian provider in the contractor networks meets or fails to meet the performance standard .

thus , the information the mhs obtains on the quality measure and its related performance standard does not identify which hospitals , clinicians , or other providers need to improve their performance in order for all beneficiaries to receive the expected level of care quality that the performance standard represents .

because the mhs has not established performance standards related to the purchased care dashboard measures for individual civilian hospitals , clinicians , or other providers in purchased care , there are no related requirements for corrective action .

instead , the mhs requires its managed care support contractors to undertake other activities to promote improved quality of care across civilian providers in their networks .

these include investigations of quality issues , focused reviews , analyses of hospital compare data , and value - based purchasing pilots , as discussed further below .

however , our review found that these efforts are not applied comprehensively across all individual purchased care providers .

investigations of quality issues .

one approach the mhs uses to promote improved quality of care across purchased care providers is to direct its managed care support contractors to investigate whether individual beneficiaries have experienced what the mhs refers to as a quality issue .

potential quality issues are defined by the mhs as any instance when there are indications that a purchased care provider has deviated from what the managed care support contractors deem acceptable standards of professional practice .

the contractors can identify these potential quality issues through beneficiary complaints ; analyses of patient safety indicators , hospital acquired conditions , and serious reportable events ; or by the mhs or contractor staff .

once potential quality issues are identified , they are investigated by a clinician , who reviews the patient's complete medical record .

based on the clinician's review of the patient's medical records , the clinician verifies whether or not a quality issue has occurred and , if so , assigns the quality issue a severity level .

to address the quality issue , the managed care support contractors may take a range of steps , including educating the provider , monitoring the provider , notifying the appropriate state or federal bodies , and removing the provider from the mhs's purchased care provider network .

in practice , however , mhs officials said and documents we reviewed show that providers are rarely removed from the network .

for example , mhs officials reported that one contractor estimated that one provider was removed from its network over quality issues every 1 to 2 years .

focused reviews .

another way the mhs uses its managed care support contractors to promote improved quality of care across purchased care providers is through focused reviews .

during these reviews , the managed care support contractors review the medical records for a selected patient population to determine the extent to which a specified quality concern is a widespread problem .

for example , in 2015 one contractor reviewed the medical records of 96 beneficiaries to determine the frequency of obstetric trauma , an injury related to vaginal deliveries .

if a focused review determines that there is a widespread quality problem , the contractor may implement a quality improvement initiative designed to prompt all of its network providers to address that concern , as opposed to targeting specific providers .

analyses of hospital compare data .

the mhs also requires the contractors to conduct an annual examination of the performance of hospitals in their networks on the different quality measures reported on medicare's hospital compare .

however , the managed care support contractors have considerable flexibility in deciding how to structure these analyses and how to follow - up on results .

consequently , the two managed care support contractors have adopted different analytical approaches to define and identify hospitals with relatively low performance .

for example , the managed care support contractors chose to examine different quality measures and use different criteria to identify hospitals with relatively low performance .

in their most recent annual reports issued during 2017 , both managed care support contractors indicated that they were considering contacting the lower performing hospitals to prompt remedial action , but because no action had yet occurred , the reports leave open what steps were ultimately taken and how these hospitals responded .

nonetheless , these activities suggest that the managed care support contractors have the ability to use hospital compare to analyze and address individual provider performance on a standard set of quality measures .

however , the mhs has not specified how this process should proceed , leaving it to the managed care support contractors to decide what and how much they will do in conducting these analyses of individual hospitals .

value - based purchasing pilots .

the mhs has recently begun to test different approaches to incentivize purchased care providers to deliver high quality care through several value - based purchasing pilots .

for example , in february 2018 the mhs launched a maternity care pilot that pays providers more for better performance on specified quality measures .

the pilot also implements a ‘steerage model' approach that identifies higher performing providers in directories provided to patients by indicating providers as “gold stork” or “silver stork.” these pilots may provide the mhs another way to influence the quality of care provided by certain subsets of its purchased care providers .

mhs officials stated that although dod has not arrived at specific goals , it plans to expand these pilots to cover around 20 to 25 percent of its purchased care services by 2020 .

the use of performance standards and corrective action requirements for individual hospitals , clinicians , or other providers who serve mhs beneficiaries is consistent with federal internal control standards for monitoring , which state that management should establish monitoring activities , evaluate the results , and remediate any deficiencies .

while the mhs has established performance standards related to its core dashboard measures in direct care and has corrective action requirements for mtfs that do not meet those standards , it has not done so for individual civilian hospitals , clinicians , or other providers in purchased care related to its purchased care dashboard measures .

additionally , if the mhs aligned quality measures on the core and purchased care dashboards at the provider level , the mhs could require its managed care support contractors to monitor the performance of individual civilian providers relative to set performance standards comparable to the ones that the mhs has established for mtfs .

this approach would allow the mhs to determine the extent of performance variability , both among individual civilian providers and across mtfs and individual civilian providers .

by not establishing consistent performance standards at the provider - level for direct and purchased care and requiring corrective action requirements to ensure that these standards are met by providers in both direct and purchased care , the mhs is limited in its ability to address variation in the quality of care delivered .

this further limits the mhs's ability to ensure that it is achieving the department's overall strategic goals of providing high quality care across the mhs as whole and ensuring that beneficiaries receive a consistent level of high quality care regardless of whether that care is delivered in direct or purchased care .

congress directed dod to reduce variation in the quality of care beneficiaries receive through the mhs .

dod has taken important steps towards this goal by identifying a set of core measures that dod senior health care leadership use to assess quality of care in direct care and another set of measures that they use to assess quality in purchased care .

dod health care leaders rely on these measures on their core and purchased care dashboards to establish accountability throughout the mhs and identify areas where quality improvement is needed .

however , with few exceptions , the mhs uses different measures on its core and purchased care dashboards to assess the quality of direct and purchased care , making it difficult to determine the extent to which it is ensuring consistent quality across the mhs as a whole .

furthermore , for both direct and purchased care , the mhs uses measures on its dashboards that assess a limited range of quality areas and medical conditions when compared to the widely used quality measure sets adopted by medicare and private insurers .

without using a broader range of available quality measures available — measures that many purchased care providers already report to cms and private health insurers — dod is missing an opportunity to better target the most critical quality of care issues in the mhs .

the limitations we identified in the mhs's core and purchased care dashboard quality measures reflect the fact that in its annual measure selection process , the mhs does not prioritize aligning the quality measures across direct and purchased care and expanding the range of measures it uses across the two systems of care .

finally , our review shows that while dod has established performance standards for the core measures in direct care and corrective action requirements for mtfs that do not meet these standards , dod has not done so for individual purchased care providers .

notably , dod does not set clear expectations that individual purchased care providers should meet the performance standards related to the quality measures on the purchased care dashboard .

performance standards and related corrective action requirements are critical for holding both mtfs and individual civilian providers accountable for providing quality care .

without consistent standards and related corrective action requirements across the mhs , dod is limited in its ability to ensure that beneficiaries consistently receive high quality care , regardless of whether they receive that care in the direct or purchased care systems .

we are making two recommendations to the assistant secretary of defense for health affairs .

as mhs governing bodies conduct their recurring reviews of quality measures selected for mhs's core dashboard and purchased care dashboards , the assistant secretary of defense for health affairs should direct those bodies to prioritize , as appropriate , the selection of measures that apply to both direct and purchased care at the provider level and that expand the range of quality measure types and medical conditions that are assessed .

 ( recommendation 1 ) the assistant secretary of defense for health affairs should establish , as appropriate , performance standards related to the purchased care dashboard measures that are consistent with the mhs's performance standards for direct care ; ensure they are applied to individual purchased care providers ; and take steps , such as amending its managed care support contracts , if necessary , to require corrective actions to be taken when providers do not meet those standards .

 ( recommendation 2 ) .

we provided a draft of this report to dod for review , and dod provided written comments , which are reprinted in appendix i .

in its written comments , dod concurred with both of our recommendations .

with regards to the first recommendation , dod stated that it plans to enhance the process for selecting quality measures that apply to both direct and purchased care ; optimize use of data on hospital compare to expand the types and medical conditions evaluated ; augment their governance reporting structure so that senior leadership can review quality measures included on the core dashboard and purchased care dashboard ; and implement the cqmc measure sets for outpatient care .

additionally , dod stated that it has efforts underway to create a library of all quality measures used across direct and purchased care .

with regards to the second recommendation , dod acknowledged the need to strengthen accountability for meeting performance standards that apply to both direct and purchased care providers .

it also agreed that measures of individual provider performance in purchased care should be augmented and consistent with measures in direct care , where possible .

dod noted , however , that because it works through managed care support contractors for purchased care , it can hold the contractors accountable for meeting performance standards but cannot currently take action against individual providers based solely on performance .

instead , dod stated that rather than taking a corrective action approach , it plans to expand its value - based purchasing efforts and incentivize providers that meet and exceed certain quality standards .

this raises concerns , as dod's current plans to expand its value - based purchasing efforts would only be applicable for between 20 and 25 percent of the services mhs beneficiaries receive from purchased care providers by 2020 , as we noted in our report .

without having all providers managed consistently and subject to prompt remediation of deficiencies , dod is missing an opportunity to improve the quality of purchased care , and it increases the risk that not all beneficiaries will receive a consistent level of high quality care across the mhs .

acknowledging dod's comment that it cannot currently take action against individual providers based solely on performance , we have modified our recommendation to clarify that dod should take the steps it determines are necessary , such as amending its managed care support contracts , to institute corrective action requirements for purchased care providers .

we are sending copies of this report to the secretary of defense and appropriate congressional committees .

the report is also available at no charge on gao's website at http: / / www.gao.gov .

if you or your staff has any questions regarding this report , please contact me at ( 202 ) 512-7114 or silass@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix ii .

in addition to the contact named above , rashmi agarwal , assistant director ; eric peterson analyst - in - charge ; muriel brown ; shaunessye curry ; michael erb ; krister friday ; jacquelyn hamilton ; and colbie holderness made key contributions to this report .

defense health reform: steps taken to plan the transfer of the administration of the military treatment facilities to the defense health agency , but work remains to finalize the plan .

gao - 17-791r .

washington , d.c.: sep 29 , 2017 .

health care quality: hhs should set priorities and comprehensively plan its efforts to better align health quality measures .

gao - 17-5 .

washington , d.c.: oct 13 , 2016 .

va health care quality: va should improve the information it publicly reports on the quality of care at its medical facilities .

gao - 17-741 .

washington , d.c.: sep 29 , 2017 .

