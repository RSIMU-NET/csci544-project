our nation faces a variety of homeland security threats — including terrorism , cyberattacks , and natural disasters — that continue to evolve and present an array of challenges .

given the wide range of threats facing the nation and the multitude of governmental and non - governmental stakeholders involved in preventing and responding to these threats , it is vital that the department of homeland security ( dhs ) comprehensively examine the homeland security strategy of the nation and make changes and recommendations as necessary .

the implementing recommendations of the 9 / 11 commission act of 2007 ( 9 / 11 commission act ) requires that beginning in fiscal year 2009 and every 4 years thereafter , dhs conduct a review that provides a comprehensive examination of the homeland security strategy of the united states .

according to the 9 / 11 commission act , the review is to delineate and update , as appropriate , the national homeland security strategy , outline and prioritize critical homeland security missions , and assess the organizational alignment of dhs with the homeland security strategy and missions .

the act further requires that dhs conduct the quadrennial review in consultation with stakeholders , such as heads of federal agencies ; key officials of the department ; state , local , and tribal governments ; private sector representatives ; and academics and other policy experts .

dhs issued its first quadrennial homeland security review ( qhsr ) in february 2010 , which we evaluated in two reports .

we reported in september 2011 that dhs outlined a strategic framework to guide the homeland security efforts of the department and its partners , including federal , state , local , and tribal government agencies ; the private sector ; and non - governmental organizations .

we found that time frames provided for stakeholder consultations and outreach to nonfederal stakeholders could be improved and that dhs did not use risk information to inform qhsr implementation .

we recommended that in future reviews , dhs provide sufficient time for stakeholder consultations , explore options for consulting with nonfederal stakeholders , and examine how risk information could be considered in prioritizing qhsr implementation mechanisms .

dhs concurred with the recommendations and has taken some actions toward addressing them , but has not fully implemented the recommendations , as discussed later in this report .

in december 2010 , we issued a report on the extent to which the qhsr addressed the 9 / 11 commission act's required reporting elements .

we reported that of the nine qhsr reporting elements , dhs addressed three and did not fully address six .

elements dhs addressed included a description of homeland security threats and an explanation of underlying assumptions for the qhsr report .

elements not fully addressed included a prioritized list of homeland security missions and discussions of cooperation between the federal government and state , local , and tribal governments .

we made no recommendations in the december 2010 report .

in june 2014 , dhs issued its second qhsr , which described changes in the overall security environment and refined dhs's five homeland security missions .

in this light , you asked us to review dhs's second qhsr , including dhs's process for conducting the review and for implementing the qhsr strategy .

this report addresses the following questions: ( 1 ) to what extent has dhs examined and used risk information to inform the qhsr and its implementation ? .

 ( 2 ) to what extent has dhs aligned its budget and performance measures with the mission goals in the qhsr ? .

 ( 3 ) to what extent did dhs collaborate with stakeholders during the 2014 qhsr process ? .

this report also examines whether the qhsr and dhs strategic plan addressed the reporting elements specified for the qhsr in the 9 / 11 commission act , which we describe in appendix i .

to determine the extent to which dhs has examined and used risk information to inform the qhsr and its implementation , we analyzed dhs documentation on its risk analysis process and results , such as dhs's current strategic environment and future strategic environment reports and classified risk characterization results .

we also interviewed current and former dhs office of strategy , plans , analysis , and risk ( spar ) officials responsible for developing the qhsr risk analyses .

we compared dhs's risk assessment process and documentation to the national infrastructure protection plan's ( nipp ) key characteristics of a successful risk assessment .

specifically , we evaluated dhs's documentation to determine the extent to which the qhsr's risk assessment was complete , documented , defensible , and reproducible .

further , we evaluated dhs's use of risk information in the qhsr against risk management guidance in the nipp and dhs's risk management fundamentals , as well as against our prior work on key characteristics for risk assessment and management .

to determine the extent to which dhs has aligned its budget and performance measures with the mission goals in the qhsr , we analyzed dhs documents related to the 2014 qhsr and the fiscal years 2014- 2018 strategic plan , including: dhs budget in brief documents from 2015 through 2017 to determine dhs's budget priorities since issuance of the first qhsr ; fiscal years 2012 through 2015 future years homeland security program ( fyhsp ) reports ; excerpts from dhs's fiscal years 2017-2021 and 2018-2022 resource planning guidance to determine the extent to which budget guidance reflects the dhs missions and goals ; and dhs reports on its progress implementing a common appropriations structure .

further , we reviewed congressional research service reports on dhs's appropriations from fiscal year 2015 and 2016 .

we also interviewed dhs officials from the office of the chief financial officer , spar , and from u.s. customs and border protection ( cbp ) , u.s. coast guard ( uscg ) , federal emergency management agency ( fema ) , u.s. immigration and customs enforcement ( ice ) , national protection and programs directorate ( nppd ) , and transportation security administration ( tsa ) .

we selected these components based on their share of the overall dhs fiscal year 2015 budget , breadth of homeland security responsibilities , and other factors .

views from these components are not generalizable to all dhs components .

we interviewed component officials to determine the extent to which they used dhs guidance in developing their annual budget requests and the extent to which such guidance reflects the qhsr missions and goals .

with respect to performance measures , we reviewed dhs's annual performance plans from fiscal years 2013-2015 and 2014-2016 , reviewed our prior work on key attributes of successful performance measures and the gpra modernization act of 2010 ( gprama ) .

we also interviewed dhs officials from spar and the office of program analysis and evaluation ( pa&e ) and from cbp , uscg , fema , ice , nppd , and tsa components in order to determine the extent to which dhs developed performance measures that aligned with mission goals .

we compared dhs's process for monitoring and measuring performance to federal internal control standards and our prior work on best practices for implementation of strategies and initiatives .

to determine the extent to which dhs consulted with stakeholders in developing the qhsr , we conducted a survey of 182 qhsr stakeholders identified by dhs with a response rate of about 51 percent .

the stakeholders were identified by dhs and included representatives from federal departments and agencies ; state , local , and tribal organizations ; and dhs components , directorates and offices .

dhs identified these stakeholders based on 2014 qhsr participation .

we asked open - ended questions regarding the qhsr stakeholder consultation process , including ways in which dhs elicited stakeholder input , how revisions to timeframes may have impacted stakeholder responsibilities , any challenges in collaborating with dhs and suggestions for improving future qhsrs .

of the 93 individual stakeholders who responded to our survey , 75 respondents provided narrative comments .

we analyzed these comments to determine common benefits and challenges they identified regarding dhs consultations during the qhsr .

the comments received from these respondents are not generalizable to the entire group of stakeholders , but the feedback provided insights into stakeholder perspectives on how qhsr stakeholder consultations were conducted and how they could be improved .

we compared dhs's stakeholder consultation efforts to project management standards .

to assess the extent to which the 2014 qhsr and fiscal years 2014- 2018 strategic plan addressed reporting elements listed in the 9 / 11 commission act , we determined the extent to which each element was incorporated into the reports .

to make this determination , three gao analysts independently compared the qhsr and strategic plan to each of the nine reporting elements to determine whether each element was addressed , not fully addressed , or not addressed .

in cases when the analysts disagreed , they reviewed and discussed their independent assessments to reach concurrence .

in addition , we interviewed dhs officials involved in the quadrennial review to determine dhs's position on how dhs addressed the 9 / 11 commission act reporting requirements .

we conducted this performance audit from january 2015 to april 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

see appendix ii for a more detailed discussion of our objectives , scope , and methodology .

section 707 of the homeland security act of 2002 , as amended by the 9 / 11 commission act , requires a review of the nation's homeland security every four years .

under the 9 / 11 commission act , dhs is responsible for developing the qhsr and for submitting a report that is to include multiple elements , such as: a description of the threats to the assumed or defined national homeland security interests of the united states ; the national homeland security strategy , including a prioritized list of the critical homeland security missions of the united states ; an assessment of the organizational alignment of dhs with the applicable national homeland security strategy and the homeland security mission areas outlined ; and a discussion of the status of cooperation among federal agencies in the effort to promote national homeland security , among other elements .

the department initiated the second qhsr in summer 2012 .

led by spar within the office of policy , the department reviewed the homeland security strategic environment as well as the dhs missions and goals .

in 2013 , dhs issued its terms of reference outlining the framework for conducting the second quadrennial review and identified threats and assumptions to be used in conducting the review .

the qhsr was conducted in four phases , as shown in figure 1 , and released in june of 2014 .

based on the assessments conducted in the preparation phase , dhs leadership directed five qhsr studies , as shown above .

each study group was composed of officials from across dhs offices and components , led by a dhs spar official , and facilitated by an independent subject matter expert from the homeland security studies and analysis institute .

these study groups conducted their analysis over a 6 month period and shared their work products , such as outline missions and assumptions , with other stakeholder groups in order to develop goals and objectives for each homeland security mission .

at the end of the study group period , dhs senior leadership , including the deputy secretary of homeland security , the office of general counsel , and office and component heads , met multiple times to review and discuss the study group recommendations .

dhs spar consolidated the study groups' recommendations into a draft qhsr report and obtained and incorporated feedback on the draft report from other federal agencies and stakeholder groups , including stakeholders listed in the 9 / 11 commission act with which dhs was to consult in conducting the 2014 qhsr review .

dhs solicited input from various stakeholder groups in conducting the second qhsr .

the 9 / 11 commission act specifically required dhs to consult with the heads of seven federal agencies .

dhs consulted with these agencies and also sought input from a range of other stakeholders , including its directorates , offices , and components ; other federal departments and agencies ; and nonfederal governmental and nongovernmental entities and representatives , such as state , local and tribal governmental associations , members of congress , private sector representatives , academics , and other policy experts .

dhs spar consulted with the office of intergovernmental affairs and the office of state and local law enforcement to identify and contact relevant stakeholder organizations .

we , congress , the 9 / 11 commission , and others have recommended that federal agencies with homeland security responsibilities use a risk management approach to help ensure that finite resources are dedicated to assets or activities considered to have the highest security priority .

in its risk management fundamentals and other guidance , dhs articulates a risk management framework to guide its homeland security planning , preparation , and execution of its missions .

dhs states that risk management is the process for identifying , analyzing , and communicating risk and accepting , avoiding , transferring , or controlling it to an acceptable level .

the national infrastructure protection plan ( nipp ) also defines dhs's risk management framework and includes key principles for an effective risk assessment .

specifically , a risk assessment should be complete , documented , reproducible , and defensible , as defined in table 1 .

dhs uses a planning , programming , budgeting , and execution ( ppbe ) process to allocate resources .

dhs's ppbe process produces the multi - year funding plans presented in the future years homeland security program ( fyhsp ) .

according to dhs guidance , at the outset of the annual ppbe process , the department's office of policy and the chief financial officer ( ocfo ) should provide planning and fiscal guidance , respectively , to the department's 16 component agencies .

in accordance with this planning and fiscal guidance , the components should produce 5- year funding plans — called resource allocation plans — that are submitted to the cfo and reviewed by dhs's senior leaders .

dhs senior leadership is expected to modify the plans in accordance with their priorities and assessments and submit them to the office of management and budget ( omb ) , which uses the plans to inform the president's annual budget request .

dhs guidance establishes approximate timelines for when guidance is provided to components and when budget plans are due , as shown below in figure 3 .

the 2014 qhsr outlines the same five missions set forth in the first qhsr in 2010 , but the 2014 review refined the missions to reflect evolving threats .

the five missions are to ( 1 ) prevent terrorism and enhance security , ( 2 ) secure and manage our borders , ( 3 ) enforce and administer our immigration laws , ( 4 ) safeguard and secure cyberspace , and ( 5 ) strengthen national preparedness and resilience .

changes to the dhs missions were primarily in mission 4 to safeguard and secure cyberspace .

specifically , the 2014 qhsr provides enhanced goals for cybersecurity protection that include leveraging technology and enhancing investigative capabilities , as shown in figure 4 .

dhs assesses and reports on progress for the 2014 qhsr mission goals in its annual performance report , which provides suites of performance measures that assess progress for each qhsr mission goal area .

the annual performance report includes performance targets as well as information on agency priority goals , initiatives , and challenges .

the performance results identified in the report are organized around the missions and goals outlined in the dhs strategic plan .

the dhs fiscal year 2014-2018 strategic plan focuses on how dhs plans to implement the goals laid out in the 2014 qhsr .

specifically , the strategic plan describes the qhsr homeland security missions and goals and lists strategies to achieve the goals .

for example , for mission 1 ( prevent terrorism and enhance security ) , to achieve goal 1.1 ( prevent terrorist attacks ) , one strategy listed in the strategic plan is to analyze , fuse , and disseminate terrorism information by sharing it with stakeholders across the homeland security enterprise .

in addition , for mission 4 ( safeguard and secure cyberspace ) , to achieve goal 4.2 ( secure the federal civilian government information technology enterprise ) , one strategy listed in the strategic plan is to ensure government - wide policies and standards are consistently and effectively implemented .

see figure 5 for a list of additional strategies linked to homeland security missions and goals .

move mouse over goal to see the objectives .

for a noninteractive version , see appendix iv .

dhs conducted a risk assessment for the second qhsr , which it referred to as the homeland security strategic environment assessment ( hssea ) .

according to dhs , the purpose of the hssea was to characterize those risks , threats , current and future trends , and critical uncertainties that will most affect homeland security in the 2015 to 2019 timeframe .

the hssea is the product of several different assessments that dhs developed for this effort , including the current strategic environment , future strategic environment , homeland security planning threat assessment , homeland security national risk characterization ( hsnrc ) , and the system mapping initiative .

all combined , dhs intended these documents to inform the qhsr's narrative describing the homeland security strategic environment as well as informing the selection of priority strategic issues to study during the 2014 qhsr , among other goals as shown in figure 6 .

for the hssea , dhs evaluated threat information and assessed relative likelihood and consequences across various hazards that dhs determined to be significant , including intentional acts of terrorism , natural hazards , and technological accidents and infrastructure failures ; however , dhs did not incorporate other key elements of a successful risk assessment into its risk assessment methodology .

specifically , dhs did not clearly document how its various analyses were synthesized to generate risk results ; did not design an assessment that could produce comparable , repeatable results ; and did not communicate the implications of any uncertainty in the results .

dhs's performance in each nipp element — complete , documented , reproducible , defensible — is discussed in further detail below .

the hssea generally follows the nipp standard for a complete risk assessment in that it assesses consequence , vulnerability , and threat .

regarding threat information , dhs officials said that they relied on two primary sources — the classified homeland security planning threat assessment , developed by dhs intelligence and analysis ( i&a ) , and the publically available 2012 worldwide threat assessment of the us intelligence community , which is prepared by the office of the director of national intelligence ( odni ) .

the odni assessment discusses the rapid changes in the threat environment which odni states is now more diverse and interconnected than any other time in history .

dhs officials said that they used the unclassified assessment as well as select assessments from the i&a homeland security planning threat assessment so that they did not face classification challenges when sharing information with partners .

dhs i&a reported using i&a and intelligence community data , as well as data from component - level intelligence units .

further , the odni - developed assessment had been vetted through the intelligence community , which dhs officials said added to its legitimacy .

regarding consequence and vulnerability , dhs primarily assessed these two factors in the homeland security national risk characterization ( hsnrc ) , where it evaluated the likelihood and potential consequences of 40 hazards ranging from acts of terrorism to hurricanes .

dhs compared the impacts of these hazards according to their direct economic impact , loss of life , and potential for injuries and illnesses in order to identify what the department referred to as standout risks — risks that dhs believed would result in substantial negative consequences — and to allow decision makers to evaluate risk management alternatives in terms of their effect on increasing or decreasing risk .

additionally , dhs sought to increase the usefulness of the qhsr risk assessment by including an analysis of current and future strategic trends into its broader analysis .

specifically , dhs officials said that the system mapping initiative , 2012 current strategic environment , and 2013 future strategic environment reports provided important insights on trends and other factors for the qhsr and resulted in what dhs referred to as a dynamic risk assessment .

documented the methodology and the assessment must clearly document what information is used and how it is synthesized to generate a risk estimate .

any assumptions , weighting factors , and subjective judgments need to be transparent to the user of the methodology , its audience , and others who are expected to use the results .

the types of decisions that the risk assessment is designed to support and the timeframe of the assessment ( eg , current conditions versus future operations ) should be given .

as mentioned previously , the hssea is the product of several different assessments and was intended to be dynamic — in that , according to dhs , it captures possible future scenarios and can help decision - makers be more strategic — but dhs did not fully document how the findings and results of the various assessments were synthesized to generate the qhsr risk results , among other issues .

for the hsnrc — where dhs ranked various hazards according to their likelihood and potential consequences — dhs did not fully document how its results ( from both its quantitative and qualitative analyses ) were synthesized to generate its list of standout hazards — a key element of the nipp standards for documentation .

specifically , in the documentation provided by dhs , we identified dhs's steps for conducting the hsnrc , the hazard scope , consequence categories , and methodological caveats .

in separate classified documentation , we reviewed a rank - ordering of those hazards that dhs spar officials said resulted from its hsnrc analysis .

however , dhs's documentation included only a limited description of how and what data dhs relied on to generate its standout hazards , and no description of how any data or methodological limitations should be interpreted by users of the results .

additionally , dhs's documentation included only limited information on data sources and the specific roles of subject matter experts .

for example , regarding data sources , dhs cited “historical record” and “subject matter expert judgment,” without providing further detail on what record or judgements were relied upon .

in classified risk summary sheets , dhs officials reported documenting additional detail about each hazard , including the data sources and likelihood and consequence estimates ; however , this documentation does not clarify how the information was synthesized to generate the final risk analysis results .

in addition , dhs reported that in light of limited available data , it relied on the expertise of subject matter experts ; however , dhs did not document how these subjective judgements were weighed against other available data to generate results , and it is unclear how much or how little the subject matter experts' opinions were the primary basis for dhs's findings .

in a 2010 review of dhs's approach to risk assessment , the national academies also found that dhs had not documented how subject matter expert assumptions were made , which limits the ability to test the validity of those assumptions , bring to light dissenting views of experts , or inform future updates and improvements to the risk models .

last , dhs did not document or provide an explanation of how all of the various hssea elements — the system maps , the risk ranking from the hsnrc , the trends analysis , or the threat report — were combined to generate the qhsr risk narrative and other risk findings .

according to the nipp , sufficient documentation can help improve or modify a risk methodology so that the investment and expertise they represent can be used to support risk management activities .

dhs provided an explanation that its various analyses were combined in order to generate insights , but no other description of the weighting factors , assumptions , and subjective judgments that went into synthesizing static and dynamic risk in the hssea .

dhs did , however , describe the types of decisions the hssea is designed to support , as called for in the nipp .

specifically , the hssea should , according to dhs , reveal blind spots , place homeland security events into a broader context , and identify key challenges and opportunities , among other goals .

however , beyond informing a strategic context , it is unclear how decision - makers should use and interpret the hssea results .

reproducible the methodology must produce comparable , repeatable results , even though assessments of different critical infrastructure and key resources may be performed by different analysts or teams of analysts .

it must minimize the number and impact of subjective judgments , leaving policy and value judgments to be applied by decision makers .

defensible the risk methodology must logically integrate its components , making appropriate use of the professional disciplines relevant to the analysis , as well as be free from significant errors or omissions .

uncertainty associated with consequence estimates and confidence in the vulnerability and threat estimates should be communicated .

dhs's lack of documentation also limits the reproducibility and defensibility of the results , since the assessment cannot easily be validated or the assumptions tested , further hindering dhs's ability to improve future iterations of the assessment .

specifically , in the hsnrc — the element of the hssea that seeks to generate risk rankings — dhs evaluates the likelihood and consequences of 40 hazards that cover terrorism , natural hazards , and technological accidents or infrastructure failures .

however , given the level of uncertainty cited regarding the analysis of these hazards , it is unclear how dhs determined their risk - based rank - order , as well as what findings could be drawn from the results .

for example , with available data , dhs found that it could only compare consequences across three consequence categories — fatalities , injuries and illnesses , and direct economic loss .

the specific definitions for injuries and illness as well as direct economic loss vary across the threats and hazards , and dhs caveated its findings by noting that some hazards used different definitions of economic consequences , which resulted in substantially different levels of consequences , thus limiting the hazards' comparability and making it difficult to determine their relative severity .

last , dhs caveated its findings by acknowledging that there are large bands of uncertainty , especially for those estimates that rely on subject matter expert judgement .

although dhs stated these and other limitations in its supporting documentation and on the presentation of its results , dhs did not communicate any implications this uncertainty would have on use and interpretation of the results except to say that simultaneously considering multiple consequence categories makes ascertaining the top risks very difficult .

despite these limitations , dhs did provide a clear explanation of its guiding principles for selecting the hsnrc hazard scope , which included national - level significance , relevance to dhs , relevance to the 2014 qhsr , and availability of data .

further , dhs provided definitions of all the hazards for which it evaluated frequencies and consequences , as well as which consequences it considered .

dhs also explained that it evaluated hazard frequencies using the uscg's national maritime security risk assessment frequency categories ( which looks at frequencies ranging from over 550 events per year to 1 event every 180 or more years ) .

last , the technical working group that developed the hsnrc provided several recommendations for future hsnrc work and a list of next steps , which included developing a departmental risk modeling and analytical resource toolbox .

dhs officials said that conducting and documenting a risk assessment of this scale was a complex undertaking which was limited by both time and available personnel and that finding comparable or reliable data was challenging .

officials said that the qhsr risk assessment process was continually evolving and the assessment team was learning and adapting as they conducted the analysis .

nonetheless , in its risk management fundamentals , dhs states that those affected by a risk management approach should be able to understand how results were derived and the process for doing so .

further , the nipp provides guidance on how to document a risk assessment methodology and key information — such as the implications of uncertainty in the estimates , such as uncertainty in the number of fatalities or dollars of economic loss — that should be communicated to users of the risk results .

moreover , without sufficient documentation of its hssea risk methodology , dhs is hindered in its ability to reproduce the assessment for future qhsrs and limits the defensibility of the results .

incorporating the key principles of a successful risk assessment methodology can help dhs demonstrate the basis of its risk management strategies and help ensure their validity for guiding qhsr missions and goals .

in the qhsr , dhs described a range of strategic risks — from the evolving terrorist threat to the impacts of aging critical infrastructure systems — but did not compare or prioritize risks to identify where mitigation efforts are most needed , as called for in the nipp .

specifically , dhs describes the homeland security hazards it assessed as ( 1 ) strategic priorities , ( 2 ) the key areas of change ( which dhs refers to as the threats and hazards to the nation ) , ( 3 ) the prevailing challenges that pose the most risk , and ( 4 ) areas of ongoing priority and emphasis , as shown in figure 7 .

for the qhsr risk analysis , dhs officials said they not only wanted to develop a homeland security risk characterization , but to augment this information to provide more useful tools for dhs - wide and component decision making .

however , despite dhs's goals for the qhsr assessment , officials from the six components we met with ( cbp , uscg , fema , ice , nppd , and tsa ) stated that the risk results reported in the qhsr did not affect their component's resource allocation , operational planning , or strategic planning decisions .

in addition , officials from 5 of the 6 components reported not using any of the stand - alone qhsr risk products in their own risk assessment or strategic planning efforts .

component officials reported that the qhsr risk results were highly generalized and encompassed essentially all of dhs's missions — in other words , they did not offer priorities or a sense of relative risks .

component officials added that since the qhsr results were not specific or granular , they generally relied on their own analyses when making strategic , operational , or resource planning decisions .

for example , fema officials agreed with the qhsr insights that climate change and natural disasters were a serious threat to homeland security ; however , officials said they have been monitoring these issues through fema's multi - year strategic foresight initiative .

further , officials provided several reasons why they do not use or are unable to use the stand - alone risk products .

for example , officials from one component questioned the quality of the threat information and said they would like to see a more specific ranking of threats , while officials from another component said the results were too broad .

finally , officials from 3 of the 6 components were unaware of the stand - alone risk documents .

dhs officials stated that the qhsr presented a list of key homeland security areas and explained that they chose not to rank or prioritize within those areas because of concerns on the part of senior leadership , among other issues .

for instance , former dhs officials who led the development of the hssea said that there were some hazards that stood out as high risk across multiple consequence categories , but reported dhs did not rank the risks because they were unable to develop criteria for risk tiers ( such as what would be high risk , medium risk , or low risk , for example ) .

further , officials were concerned that risk - ranked priorities might imply the need to make resource changes to particular areas , when risk is just one of many inputs for decision - making .

former dhs officials who managed the qhsr risk assessment also said that conducting a dhs - wide risk characterization was a challenge on many levels .

it required substantial dedicated resources and consensus on what the analysis would describe ( eg , which scenarios and models should be used ) .

the officials added that there are not enough resources at dhs to put sufficient effort into an enterprise - wide risk assessment that includes prioritization of risk outcomes .

further , the officials acknowledged that risk communication — including communicating the process for and implications of prioritized risk - rankings — is a challenge .

officials said that integrating risk - informed decision - making throughout the department will require continued growth of dhs's risk analysis community .

the national academies 2010 review of dhs's approach to risk management echoed these statements in their recommendations to dhs , which included building a strong risk culture at dhs and incorporating robust social science capabilities into risk analyses and risk management practices .

dhs officials said that they used the hssea results and qhsr to broadly inform department - level strategic planning .

for example , officials said the system mapping initiative helped inform the development of the southern border and approaches campaign plan and strategy .

officials added that the risk results helped inform the selection of strategic priorities in the dhs strategic priorities framework and were incorporated into the annual budget guidance dhs provides to components .

because the strategic priorities framework and annual budget guidance are considered internal deliberative work products , we were unable to review the complete documents in order to determine the extent to which the hssea and qhsr risk results were included .

however , officials from ice reported that the strategic priorities framework was useful for understanding dhs's position on where to accept risk .

the 2013 risk management supplement to the nipp states that comparing and prioritizing the risks faced by different entities helps identify where risk mitigation is most needed and determines and helps justify the selection of the most cost - effective risk management options .

this risk prioritization supports resource allocation decisions , guides investments in these programs , and highlights the measures that offer the greatest return on investment .

according to the nipp , the risk prioritization process involves aggregating , combining , and analyzing risk assessment results to determine which assets , systems , networks , sectors , or combinations of these face the highest risk so that risk management priorities can be established .

it also provides the basis for understanding potential risk - mitigation benefits that are used to inform planning and resource decisions .

the qhsr risk assessment describes a wide range of homeland security challenges and is a valuable step toward using risk information to prioritize and select risk management activities .

while the qhsr makes use of risk information , it provides limited information to support resource allocation or risk - based strategic planning , such as a relative risk ranking of the department's strategic priorities .

without determining and communicating prioritized risk analysis outcomes , dhs is missing an opportunity to more efficiently implement programs , strategies , and policies to mitigate risk and is limited in its ability to identify the resources required for addressing different levels and types of risks .

the department's annual budget request was generally presented in alignment with the qhsr mission areas , but dhs has faced challenges accounting for its spending by mission , which it is taking actions to address .

specifically , the manner in which dhs's annual appropriation is structured does not directly track to the dhs missions , and dhs officials reported that significant budget disparities and inconsistencies between its components and their appropriations and programs have contributed to a lack of transparency , inhibited comparisons between programs , and complicated managerial decision making .

the president's annual budget request for the department , as reflected in the dhs's budget in brief for fiscal years 2015 and 2016 , generally described funding priorities and requests at an organizational level ( such as by component , office , and directorate ) , not by qhsr mission area .

the budget in brief does , however , highlight select programs and activities that fall within each of the department's qhsr mission areas .

for example , the fiscal year 2016 budget in brief provided that within qhsr mission area 1 — preventing terrorism and enhancing security — the department requested $3.7 billion for tsa screening operations , $101 million for radiological and nuclear detection equipment acquisition , and $94.5 million for infrastructure security compliance funding to secure high risk chemical facilities , among other requests .

the fiscal year 2016 budget in brief provided similar examples within each dhs mission area , as well as examples of requests for other departmental initiatives .

in general , dhs receives its funding through the enactment of an annual appropriations act .

historically , dhs's annual appropriations have generally been organized into five titles , within which over 70 individual appropriation accounts and over 100 programs , projects , and activities ( ppas ) are funded .

the ppas within dhs's appropriation are generally not organized by mission - based programs , and according to dhs officials do not afford transparency or an easy understanding of how federal funds are being used .

to provide increased visibility , comparability , and information on which to base resource allocation decisions , the report of the committee on appropriations of the house of representatives accompanying the department's fiscal year 2015 appropriations bill directed dhs to develop a common appropriation structure ( cas ) for implementation in the fiscal year 2017 budget cycle .

according dhs's fiscal year 2017 budget in brief , the president's budget for the department was submitted under a cas that will improve dhs's planning , programming , budgeting , and execution processes through a common framework consolidating its over 70 appropriations accounts into four standard appropriations and will better align programs to the dhs strategic missions and goals .

officials from the office of the chief financial officer ( ocfo ) explained some of the potential benefits they hope to achieve through the cas .

for example , ocfo officials explained that while under the current system dhs is able to report broadly — such as on the amount spent on border security — it cannot report on specific obligations and expenditures within that category because the funding spans multiple agencies with different accounting systems .

however , the cas ( in conjunction with another ongoing project called the accounting classification structure ) , is intended in part to help dhs better bridge its budget requests with execution of the qhsr strategy .

specifically , officials said their top level of accounting will reflect the life cycle of funds , while the second level will be standardized to newly defined mission programs .

officials said this change will make it easier to understand and compare what is currently captured by 100-plus ppas that do not have a direct link to the qhsr missions and goals .

dhs currently tracks this information to some extent , but in what they referred to as a shadow system that is not sustainable over the long term .

although dhs expects the cas to improve accountability of funds and better align its ppa structure to focus on mission programs , dhs has reported that migrating over 70 appropriations accounts to four basic appropriation fund types will entail changes to the department's ppa structure and that dhs has already faced challenges upgrading and integrating the many varied dhs financial systems , as well as maintaining oversight over the funding .

dhs budget officials stated that dhs is working to manage these and other challenges through regular communication with component - level leadership and by briefing congress regarding the budget and staffing levels needed to successfully complete the project .

dhs has taken action to improve its guidance to components for their annual budgeting processes — one of many actions underway as part of the department's unity of effort initiative .

officials from each component we interviewed ( cbp , uscg , fema , ice , nppd , tsa ) said the department's annual resource planning guidance ( rpg ) mirrored the priorities listed in the qhsr and fiscal year 2014-2018 strategic plan .

further , officials from 5 of 6 components said that the rpg was an improvement over the previous budget guidance , known as the integrated planning guidance , since the rpg's development was more transparent and the priorities were clearer .

however , officials from 5 of the 6 components said the most recent guidance — for the fiscal years 2017- 2021 budget cycle — was not issued with sufficient time to be incorporated into the budgeting process , which requires components to submit their budgets to dhs in the spring of each year .

specifically , officials said they did not receive the guidance until february 2015 for an april 2015 deadline .

officials said that this potentially limited their ability to staff issue teams to explore budget issues and to engage in more detailed planning and analysis .

component officials reported that receiving the guidance in the fall would be preferable .

dhs policy officials are aware of this concern and issued its fiscal years 2018 through 2022 guidance in december 2015 and stated that the department plans to issue future guidance to components before the end of each calendar year .

dhs developed performance measures that link with each of the sixteen 2014 qhsr mission goals , as shown in table 2 , thus meeting one of the attributes of successful performance measures — that they should link , or align , with an agency's goals and missions .

we reported in 2011 that dhs had not developed performance measures for all of the 2010 qhsr missions , goals , and objectives .

specifically , dhs had developed performance measures for 13 of the 14 mission goals , having not yet developed performance measures for goal 2.3 , disrupt and dismantle transnational criminal organizations .

for the 2014 qhsr , as mentioned above , the number of mission goals increased to 16 ( instead of 14 ) , and dhs had established performance measures for all 16 mission goals — including goal 2.3 — as well as new measures related to new mission 4 goals for cybersecurity .

dhs's annual performance report , which presents dhs's performance measures and applicable results aligned to missions , and provides the planned performance targets and priority goals , indicated that at the end of fiscal year 2014 , 63 percent of all of dhs's measures met their targets , and a review of trends in the results showed that 71 percent of the measures sustained or improved performance from fiscal year 2013 .

however , according to dhs , not all of the mission goals have credible outcome measures .

we did not assess the quality or usefulness of the performance measures for the 2014 qhsr mission goals , as this was outside the scope of our review .

according to dhs spar and pa&e officials , both the 2010 and 2014 qhsr reports informally relied on feedback from dhs performance measures to inform changes to the qhsr .

in addition , dhs has developed an approach relying on an existing process — referred to as the strategic review process — that assesses whether changes are needed to broad dhs planning documents , such as the qhsr , based on performance measure results .

in 2014 , dhs conducted its first strategic review process while the second qhsr was in its final clearance and publication phase .

according to dhs officials , findings from the strategic review process may help provide feedback for areas of focus and new measure development .

further , according to officials , the use of the dhs annual performance report is just one of multiple resources dhs spar will use to inform development of the next qhsr .

dhs took steps to expand its outreach in 2014 qhsr process to elicit input from a broader set of stakeholders , including additional nonfederal entities such as state , local , and tribal governments ; private organizations and foreign governments .

in addition to the seven federal agencies specified by the 9 / 11 commission act , dhs consulted directly with two additional federal agencies and doubled the number of stakeholder organizations that it contacted during the 2014 qhsr process .

dhs also provided briefings to five foreign governments — australia , canada , mexico , new zealand , and the united kingdom — and provided regular briefings to members of congress , the executive office of the president , and other federal partners .

in total , dhs estimates that it contacted about 40,000 homeland security stakeholders via email requesting their input and expertise in the 2014 qhsr process .

although dhs spar officials used multiple mechanisms to reach stakeholders during the 2014 qhsr process , including briefings , meetings and existing committee structures , it relied primarily on its electronic tools to elicit input from nonfederal stakeholders .

figure 8 provides an overview of the collaboration mechanisms used to engage stakeholders .

according to dhs officials , the electronic tools elicited the views of more than 2,000 registered participants and informed the analytical studies that ultimately shaped the final qhsr report .

given the volume and diversity of views among the stakeholders , dhs determined that using the electronic tool mechanism was the most efficient way to capture the majority of the input from the nonfederal entities for the 2014 qhsr review .

in 2011 , we recommended that dhs provide more time for consulting with stakeholders during the qhsr process to help ensure that stakeholders have the time needed to review qhsr documents and provide input into the review .

we recommended that dhs build this time into the department's project planning for the 2014 qhsr .

yet , this recommendation was not implemented and the timeliness issue persisted in the 2014 qhsr , based on what qhsr stakeholders told us .

in a survey we conducted of qhsr stakeholders , we asked whether dhs provided a clear overview of the timeframes and stakeholder responsibilities during each of the four phases of development .

stakeholders varied in their responses from about fourteen percent reporting that they did not receive a clear overview of the timeframes and responsibilities in phase 1 to 34 percent in phase 4 of the qhsr process .

stakeholder narrative responses also indicate that these timeframes shifted and that overall time constraints persisted throughout the qhsr process .

for example , in the narrative portion of our survey , almost all of the dhs respondents ( 14 out of 16 ) who replied to a question on timeliness stated that time constraints during the consultation process either led to disruptions or may have hindered their ability to properly identify and consult with appropriate subject matter experts within their agency .

one respondent noted that accelerated timeframes negatively impacted their ability to ensure substantive engagement with the state , local , and tribal leaders while another noted that “arbitrary” and “unpredictable” timeframes resulted in time away from their mission .

in addition , in our interviews with federal stakeholders , officials from five of nine federal agencies stated that involving the agencies earlier in the process could help alleviate compressed timeframes in the final review phase .

according to program management standards , stakeholder and program time management are recognized practices , among others , for operating programs successfully .

because stakeholders are defined as those whose interests might be affected by the program outcomes and play a critical role in the success of any program , stakeholder consultations should include an active exchange of accurate , consistent and timely information that reaches all relevant stakeholders .

time management is necessary for program components and entities to keep the overall program on track and produce a final product .

according to spar officials , the time constraints for the 2014 qhsr were related to a combination of factors such as a communication delay associated with the government shutdown and the change in dhs leadership in 2013 , delays in the report vetting process , and inadequate planning in the early stages of the review .

for example , the delay in the release of the terms of reference document led to delays in other areas such as the establishment of study groups and ultimately delayed the efforts to conduct outreach to stakeholders .

dhs officials responsible for conducting stakeholder outreach expressed frustration with the delays and noted that they were unable to move forward with planned outreach activities .

in addition , dhs spar officials acknowledged that engaging the stakeholder community early and regularly needs to be built into the planning for the review .

we continue to believe that taking steps to ensure stakeholders have the time necessary to provide quality input is critical for dhs to incorporate their expertise and perspectives .

we recognize the possibility of leadership changes and report vetting delays , but it is precisely because of such contingencies that planning for and building in sufficient time would better ensure that all key stakeholders can fully participate in the event of such delays .

as a result of time constraints , the qhsr process may not have benefitted from the full participation of all relevant stakeholders and may have missed opportunities to incorporate their perspectives .

according to qhsr planning documents and dhs policy officials , obtaining and incorporating the perspectives of the entire homeland security enterprise , including relevant federal and nonfederal representatives was a key step in the development of the 2014 qhsr .

federal and nonfederal survey respondents indicated , however , that qhsr stakeholder outreach meetings did not allow for interactive exchange between stakeholders and dhs officials .

in the narrative responses to our survey , 43 of 61 respondents to one question in our survey stated that collaboration with stakeholders could be improved .

these respondents included federal and nonfederal stakeholders .

for example , one survey respondent noted that stakeholders were asked to react to information provided by dhs rather than participating in formulating the approach and execution of the studies .

in addition to indications of collaboration challenges in our stakeholder survey results , during our interviews with federal departments and agencies , six of nine federal representatives stated that they felt dhs's communication with them was “one - way” and led to an overall sense that stakeholder input was not valued or genuinely sought after .

dhs also held working meetings with internal dhs qhsr stakeholders , including senior and component leadership , to elicit input and feedback .

however , the after action report also stated that some stakeholders believed that meetings included issues that had already been resolved or decided upon by dhs leadership .

specifically , the report noted that the dhs components viewed the meetings as opportunities to “check the box” that internal dhs stakeholders were consulted instead of true opportunities for input .

the report recommended that future qhsr stakeholder consultation sessions follow a structure where leaders ask for information , groups present findings for discussion , and leaders review and provide feedback until a resolution is reached .

project management standards state that effective stakeholder engagement involves gaining and maintaining stakeholder “buy in” for the program's objectives , benefits , and outcomes throughout the effort .

specifically , program managers should employ communication methods that target specific stakeholder needs , expectations , and wants and also consider interactive “two way” communication since it is the most efficient way to ensure common understanding by all participants on specified topics .

dhs spar officials stated that although they initially planned to employ interactive meetings , particularly to reach the nonfederal stakeholders , staff , resource , and time constraints restricted dhs's ability to engage in a fully collaborative effort and hindered its ability to employ other mechanisms that would have enabled more interactive feedback .

dhs used mechanisms such as existing groups within dhs and events to connect with nonfederal stakeholders , but dhs officials stated that these events did not provide interactive feedback with the audience .

for example , dhs briefed stakeholders from the private sector via meetings and although these meetings are helpful in contacting relevant stakeholders and informing them of qhsr issues , these sessions did not allow for stakeholder responses and exchange .

dhs spar officials further acknowledged that the effort to reach out to stakeholders via electronic tools became more of an information sharing exercise instead of a means for interactive feedback .

in addition , dhs's 2014 qhsr after action report noted that the online tools were used to validate study findings instead of informing them as originally planned .

by not fostering interactive communication with federal and nonfederal stakeholders , dhs may have missed opportunities to fully engage the entire homeland security enterprise and thereby may not have fully informed the qhsr effort .

a means for engaging both federal and nonfederal stakeholders in interactive communication could help ensure common understanding across the enterprise and elicit more robust contributions for stakeholders .

in order to facilitate collaboration and information sharing among the internal dhs stakeholders , dhs policy requested and received detailee staff at the supervisory level from each of the dhs internal components to serve a 6 month assignment with the qhsr core team led by dhs spar .

specifically , detailees were to serve as primary analysts supporting the qhsr studies and perform liaison activities between dhs spar and component leadership .

according to dhs spar officials , the detailee program was a useful mechanism in ensuring that dhs components had a voice in the qhsr process .

dhs spar officials added that the detailees provided valuable insights and contributions to the qhsr process .

however , in the narrative portion of our survey and in our interviews with dhs components , respondents expressed concerns regarding the purpose and utilization of these staff .

for example , dhs officials at 4 of 9 components told us that the staff detailed to support the qhsr effort either could have used additional clarity or did not have a clear understanding of their roles and responsibilities .

one of the detailees stated that they had not been used to communicate information between the component and dhs spar .

in addition , the dhs after action report acknowledged that some detailees were not utilized effectively , seemed to lack clear tasks to perform on a regular basis , and did not have subject matter expertise needed to support the studies .

for example , the report noted that some detailees struggled comprehending the terminology used during the studies and therefore were confused as to how they could best support the effort .

the after action report stated that the components receive more advanced notice on the type of detailee that would be needed to support the qhsr process and consider identifying the study topics in advance of requesting the detailees so that the components can provide detailees with relevant expertise .

according to key principles of inter - agency collaboration , identifying and clarifying the roles and responsibilities of staff , such as component detailees , by ensuring that they have appropriate knowledge , skills , and abilities , can strengthen collaboration .

such clarification would better enable dhs to derive the benefit of obtaining homeland security enterprise - wide input and feedback .

however , dhs spar officials stated that some of the confusion about detailee roles and responsibilities may have been because spar received a detailee at the supervisory level from each component , but later recognized that it needed individuals with relevant analytical skill sets to inform the qhsr — not just supervisory skills .

although the initial dhs policy letter requesting detailees from components specified the need for analytical skills , it did not specify the types of or areas of expertise needed .

the after action report also stated that by requesting study topics earlier there would be additional time to identify detailees with relevant subject matter expertise .

spar officials stated that in the future , they would consider specifying the types of expertise needed from the component staff in advance of their request .

without recruiting detailees with the appropriate subject matter expertise and identifying and clarifying the roles and responsibilities , component stakeholders may not have the information that they need to fully participate and be invested in the process , and may thereby not be fully committed to the qhsr effort .

the homeland security threats to the nation are continuously evolving and in recent years have included cyber security breaches , mass shootings , and natural disasters that have devastated portions of the united states .

in order to effectively respond to the nation's changing security conditions , dhs must regularly review and refine the nation's homeland security strategy , missions , and goals .

both the first and second quadrennial homeland security reviews were massive undertakings involving considerable time and resources on the part of dhs , as well as the input of numerous federal agencies , state and local government entities , and academics .

in developing its second qhsr , dhs took important steps toward assessing homeland security risks and also sought to engage a wider audience of stakeholders in developing and reviewing the strategy .

dhs officials said the qhsr risk assessment was highly complex and they faced limited time , personnel , and available data with which to conduct and document the assessment .

however , not fully documenting the assessment and its methodology lessens the defensibility of the results and limits the assessment's reproducibility for future qhsrs .

furthermore , these data and methodological limitations , along with concerns on the part of senior leadership with using risk assessment results to support a relative risk - ranking of the department's strategic priorities , resulted in dhs missing an opportunity to use the qhsr to more efficiently implement programs , strategies , and policies to address different levels and types of risks .

last , insufficient forums for multi - directional collaboration and dhs spar's unclear expectations of component detailees resulted in dhs missing opportunities to engage with the full range of homeland security stakeholders capable of informing the qhsr effort .

for its next qhsr , dhs has an opportunity to build on its progress to date in order to ensure its missions , goals , and strategy addresses the most significant homeland security risks and is representative of the full breadth of homeland security stakeholders .

to ensure the quality of the risk assessments used to inform its future qhsr processes , the secretary of homeland security should direct the assistant secretary for policy to ensure future qhsr risk assessment methodologies reflect key elements of successful risk assessment methodologies , such as being: documented , which includes documenting how risk information was integrated to arrive at the assessment results , reproducible , which includes producing comparable , repeatable defensible , which includes communicating any implications of uncertainty to users of the risk results .

to enable the use of risk information in supporting resource allocation decisions , guiding investments , and highlighting the measures that offer the greatest return on investment , the secretary of homeland security should direct the assistant secretary for policy to refine its risk assessment methodology so that in future qhsrs it can compare and prioritize homeland security risks and risk mitigation strategies .

to ensure proper management of the qhsr stakeholder consultation process , the secretary of homeland security should direct the assistant secretary for policy to identify and implement stakeholder meeting processes to ensure that communication is interactive when project planning for the next qhsr .

to ensure proper management of the internal qhsr stakeholder consultation process , the secretary of homeland security should direct the assistant secretary for policy to clarify component detailee roles and responsibilities when project planning for the next qhsr .

we requested comments on a draft of this report from dhs .

on april 4 , 2016 , dhs provided written comments , which are reprinted in appendix v. dhs concurred with our four recommendations and described actions planned to address them .

with regard to our first recommendation that dhs ensure future qhsr risk assessment methodologies reflect key elements of successful risk assessment methodologies — such as being documented , reproducible , and defensible — dhs stated that it believed that the 2013 homeland security national risk characterization ( hsnrc ) was complete , documented , reproducible , and defensible , consistent with the national infrastructure protection plan guidance .

dhs further stated that the hsnrc was developed using sound risk analysis methodologies informed by well - established analytical protocols and reproducible data provided by multiple dhs and component programs and subject matter experts , and that analysis was reviewed by the dhs risk executive steering committee and documented throughout the development of the hsnrc .

however , our review of dhs's hsnrc documentation , as well as documentation on the homeland security strategic environment assessment ( of which the hsnrc is a part ) , found that dhs did not fully document how its risk results ( from both its quantitative and qualitative analyses ) were synthesized to generate its list of standout hazards and included only a limited description of data dhs relied on to generate its results .

further , dhs did not provide a description of how any data or methodological limitations should be interpreted by users of the results .

our review of dhs's documentation also found that dhs did not provide an explanation of how all of the various homeland security strategic environment assessment elements — the system maps , the risk ranking from the hsnrc , the trends analysis , or the threat reports — were combined to generate the qhsr risk narrative or other risk findings .

dhs provided an explanation that its various analyses were combined in order to generate insights , but did not provide descriptions of the weighting factors , assumptions , and subjective judgments that went into synthesizing what dhs referred to as static and dynamic risk .

in addition , beyond informing a strategic context , it is unclear how ( if at all ) decision - makers should interpret and use the qhsr risk results .

incorporating the key principles of a successful risk assessment methodology can help dhs demonstrate the basis of its risk management strategies and help ensure their validity for guiding qhsr mission and goals .

regarding our second recommendation that dhs refine its risk assessment methodology so that in future qhsrs it can compare and prioritize homeland security risks and risk mitigation strategies , dhs stated that it will continue to refine its risk assessment methodology and expand its use of comparative risk analysis in the next hsnrc .

regarding our third recommendation that dhs identify and implement stakeholder meeting processes to ensure that communication is interactive when project planning for the next qhsr , dhs stated it is developing an extensive stakeholder outreach plan to include leveraging the homeland security information network and its access to a broad community of federal , state , and local stakeholders across the homeland security enterprise .

the outreach plan is to include using on - line tools , in - person subject matter expert interviews , and extensive interagency coordination to facilitate information exchanges , document reviews , and feedback throughout the analysis and review phases of the next qhsr .

in regards to the fourth recommendation that dhs clarify component detailee roles and responsibilities when project planning for the next qhsr , dhs stated that it will request dhs directorate and component detailees with specific skill sets and provide clearly defined timelines and objectives to support the qhsr .

dhs also provided technical comments , which we incorporated as appropriate .

we also requested comments on a draft of this report from the departments of agriculture , defense , health and human services , justice , state , transportation , treasury , and veterans affairs , the environmental protection agency , and the office of the director of national intelligence .

the department of state provided comments in an email received march 31 , 2016 , emphasizing the importance of risk - based resource allocation as well as the importance of linking operations and performance metrics to risk information .

in an e - mail received from a departmental liaison on march 23 , 2016 , the department of agriculture indicated that it had no comments on the report .

in e - mails received from departmental liaisons on march 29 , 2016 , the department of transportation and department of veterans affairs indicated that they had no comments on the report .

in e - mails received from departmental liaisons on march 30 , 2016 , the department of health and human services , department of defense , and the office of the director of national intelligence indicated that they had no comments on the report .

in an e - mail from a departmental liaison on april 1 , 2016 , the department of justice indicated that it had no comments on the report .

in an e - mail received on april 4 , 2016 from an agency liaison , the environmental protection agency indicated that it had no comments on the report .

in an e - mail received on april 8 , 2016 , from the department of the treasury's director for emergency programs the department indicated that it had no comments on the report .

we are sending copies of this report to the secretaries of agriculture , defense , health and human services , homeland security , state , transportation , treasury and veterans affairs ; the attorney general ; the director of national intelligence ; administrator of the environmental protection agency ; and selected congressional committees .

in addition , this report will be available at no charge on the gao web site at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 213 ) 830-1011 or vonaha@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix v .

of the nine reporting elements specified in the implementing recommendations of 9 / 11 commission act of 2007 ( 9 / 11 commission act ) for inclusion in the qhsr report , the department of homeland security ( dhs ) addressed five and did not fully address four through the 2014 qhsr report , finalized in june 2014 , and the dhs fiscal years 2014-2018 strategic plan ( strategic plan ) , released in december 2014 , as shown in table 4 .

elements dhs addressed in those documents included a description of homeland security threats , discussions of the status of cooperation among federal agencies and between the federal government and state , local , and tribal governments , an explanation of underlying assumptions for the qhsr report , and other matters considered important .

elements not fully addressed included a prioritized list of homeland security missions , a description of the budget plan required to execute the full range of missions , and an assessment of the alignment of dhs with the qhsr missions .

dhs officials agreed with our overall assessment , but asserted that the specifications for some of the elements we found as not fully addressed were reported through other relevant documents .

for example , according to dhs officials , the specification for identifying a budget plan was met through the fy2015-2019 future years homeland security program report , published on august 11 , 2014 .

dhs also stated that alignment of human resources systems was addressed in dhs's fy2015-2019 human capital strategic plan .

for the purposes of evaluating whether dhs addressed the qhsr reporting elements , we limited our review to the qhsr report and dhs's strategic plan , which references the qhsr report and further articulates homeland security missions , goals and strategies .

we did not review any additional documents that dhs had published pertaining to issues identified for inclusion in the qhsr report , like the budget or human resources - related matters .

therefore , we did not evaluate whether dhs addressed the reporting requirements through means outside of these two documents .

the statute establishing the qhsr provides that each such review “shall be a comprehensive examination of the homeland security strategy of the nation , including recommendations regarding the long - term strategy and priorities of the nation for homeland security and guidance on the programs , assets , capabilities , budget , policies , and authorities of the department.” the statute further requires that dhs submit to congress a report regarding the qhsr , and identifies specific elements the report is to include .

our review of the qhsr report and the strategic plan concluded that while dhs had addressed five of the elements mandated for inclusion , it did not fully address four of the elements .

consequently , to the extent congress anticipated the submission of a single comprehensive qhsr report that fully addressed each of the nine elements specified in the 9 / 11 commission act , rather than multiple dhs products that may collectively address each element , the report submitted to congress on june 18 , 2014 , falls short .

in addition , dhs issued the qhsr report after december 31 , 2013 , the date contemplated in the 9 / 11 commission act for dhs to report on the results of the quadrennial review conducted in 2013 .

according to dhs officials , dhs released the qhsr report after this date because leadership changes , specifically the appointment of a new homeland security secretary in october 2013 , occurred prior to the completion of the 2014 qhsr and thus extended the report's review time frames .

to determine the extent to which the department of homeland security ( dhs ) has examined and used risk information to inform the quadrennial homeland security review and its implementation , we analyzed dhs documentation on its risk analysis process and results for the homeland security strategic environment assessment ( hssea ) — the risk analysis conducted for the qhsr .

we reviewed dhs's current and future strategic environment reports , the systems mapping initiative report , the homeland security national risk characterization ( hsnrc ) , and classified hssea results .

we also reviewed the 2012 and 2013 worldwide threat assessment of the u.s. intelligence community , prepared by the office of the director of national intelligence ( odni ) , which dhs reported relying on when assessing threat information for the hssea .

in addition to the hssea reports themselves , we analyzed all available supporting documentation provided by dhs on the development of these reports , including briefings , videos , meeting summaries , and descriptions of hssea processes and results .

we evaluated the sufficiency of this documentation and the overall completeness of the hssea risk assessment using the standards set forth in the 2013 national infrastructure protection plan ( nipp ) and its supplemental tool on executing a critical infrastructure risk management approach .

the nipp states that in order to be complete , a risk assessment must consider threat , vulnerabilities , and consequences ; must be sufficiently documented ; must be reproducible ; and must be defensible .

in order to be sufficiently documented , the methodology and the assessment must clearly document what information is used and how it is synthesized to generate a risk estimate .

any assumptions , weighting factors , and subjective judgments need to be transparent to the user of the methodology , its audience , and others who are expected to use the results .

the types of decisions that the risk assessment is designed to support and the timeframe of the assessment ( eg , current conditions versus future operations ) should be given .

we also looked to a 2010 review by the national academies of science on dhs's risk management approach , as well as our previous work evaluating dhs's approach to risk assessment , in order to ensure that we used a consistent approach to evaluating dhs's assessment efforts .

to supplement and clarify dhs's written documentation on the hssea , we interviewed current and former dhs officials from the office of strategy , plans , analysis , and risk ( spar ) who were responsible for developing the qhsr risk analyses .

we asked officials to discuss the hssea process and how results were translated into the qhsr , including the extent to which uncertainty in the risk estimates was incorporated into the final results and communicated to users of the results — a nipp aspect of a defensible risk assessment .

further , we evaluated dhs's use of risk information in the qhsr to risk management guidance in the nipp and dhs's risk management fundamentals , as well as our prior work on key characteristics for risk assessment and management .

last , we met with the authors of a december 2015 paper published in homeland security affairs on a comparative ranking of homeland security hazards in order to discuss current challenges and developments in the field of homeland security risk analysis .

to determine the extent to which dhs has aligned its budget and performance measures with the mission goals in the qhsr , we analyzed dhs documents related to the 2014 qhsr and the fiscal years 2014- 2018 strategic plan , including: dhs budget in brief documents from 2015 through 2017 to determine dhs's budget priorities since issuance of the first qhsr ; fiscal years 2012 through 2015 future years homeland security program ( fyhsp ) reports ; excerpts from dhs's fiscal years 2017-2021 and 2018-2022 resource planning guidance to determine the extent to which budget guidance reflects the dhs missions and goals ; and dhs reports on its progress implementing a new common appropriations structure .

further , we reviewed congressional research services reports on dhs's appropriations from fiscal year 2015 and 2016 .

we also interviewed dhs officials from the office of the chief financial officer , office of strategy , plans , analysis , and risk ( spar ) , and from u.s. customs and border protection ( cbp ) , u.s. coast guard ( uscg ) , federal emergency management agency ( fema ) , u.s. immigration and customs enforcement ( ice ) , national protection and programs directorate ( nppd ) , and transportation security administration ( tsa ) .

we selected these components based on their share of the overall dhs fiscal year 2015 budget , breadth of homeland security responsibilities , and other factors .

views from these components are not generalizable to all dhs components .

we interviewed component officials to determine the extent to which they used dhs guidance in developing their annual budget requests and the extent to which such guidance reflects the qhsr missions and goals .

with respect to performance measures we reviewed dhs's annual performance plans from fiscal years 2013-2015 and 2014-2016 , reviewed our prior work on key attributes of successful performance measures , reviewed the gpra modernization act of 2010 ( gprama ) , and interviewed dhs officials from spar and the office of program analysis and evaluation ( pa&e ) and from cbp , uscg , fema , ice , nppd , and tsa components in order to determine the extent to which dhs developed performance measures that aligned with mission goals .

we compared dhs's process for monitoring and measuring performance to internal control standards and our prior work on best practices for implementation of strategies and initiatives .

to determine the extent to which dhs consulted with stakeholders in developing the qhsr , we distributed a web - based survey to 222 qhsr stakeholders identified by dhs based on 2014 qhsr participation .

the stakeholders included representatives from 9 federal departments and agencies ; 12 dhs components , directorates and offices ; about 20 state , local , tribal , private and academic organizations .

the stakeholders dhs identified did not include those who participated solely online and , as a result , we did not include these individuals within the scope of our review .

we conducted 5 pretests with respondents from dhs , other federal agencies , and related think tanks to verify that ( 1 ) the questions were clear and unambiguous , ( 2 ) terminology was used correctly , ( 3 ) the questionnaire did not place an undue burden on respondents , ( 4 ) the information could feasibly be obtained , and ( 5 ) the survey was comprehensive and unbiased .

we made changes to the content and format of the questionnaire after the pretests based on the feedback we received .

before we administered the survey , we revised the questionnaire to reflect comments from an independent reviewer within gao .

we identified 40 respondents that either had an undeliverable email address , were no longer employed with the federal government and / or did not participate in the 2014 qhsr .

we removed these stakeholders from our final distribution list , resulting in about 180 possible respondents out of the original 222 that were identified by dhs .

questionnaires were completed by 93 individual stakeholders overall , resulting in a response rate of fifty - one percent .

since the survey is not based on a sample , it does not have sampling errors .

however , the practical difficulties of conducting any survey may introduce errors , commonly referred to as non - sampling errors .

for example , difficulties in interpreting a particular question , sources of information available to respondents , or entering data into a database or analyzing them can introduce unwanted variability into the survey results .

we took steps in developing the questionnaire , collecting the data , and analyzing them to minimize such non - sampling error .

for example , social science survey specialists designed the questionnaire in collaboration with gao staff with subject matter expertise .

then , we pre tested the draft questionnaire to ensure that the questions were relevant , clearly stated , and easy to understand .

when we analyzed the data , an independent analyst checked all computer programs .

since this was a web - based survey , respondents entered their answers directly into the electronic questionnaire , eliminating the need to key data into a database and thereby minimizing error .

we also asked open - ended questions regarding the qhsr stakeholder consultation process , including ways in which dhs elicited stakeholder input , how revisions to timeframes may have impacted stakeholder responsibilities , any challenges in collaborating with dhs and suggestions for improving future qhsrs .

of the 93 individual stakeholders that responded to our survey , 74 respondents provided narrative comments .

we analyzed these comments to determine common benefits and challenges they identified regarding dhs consultations during the qhsr .

the comments received from these respondents are not generalizable to the entire group of stakeholders , but the feedback provided insights into stakeholder perspectives on how qhsr stakeholder consultations were conducted and how they could be improved .

we compared dhs's stakeholder outreach efforts to project management standards .

to assess the extent to which the 2014 qhsr and fiscal years 2014- 2018 strategic plan reports addressed reporting elements listed in the 9 / 11 commission act , we determined the extent to which each element was addressed in the reports .

to accomplish this determination , three gao analysts independently compared the qhsr and strategic plan to each of the nine reporting elements to determine whether each element was addressed , not fully addressed , or not addressed .

in cases when the analysts disagreed , they reviewed and discussed their independent assessments to reach concurrence .

we considered an element addressed if all portions of it were included in either the qhsr or strategic plan , not fully addressed if one or more but not all portions of the element were included , and not addressed if neither the qhsr nor the strategic plan addressed any part of the element .

in addition , we interviewed dhs officials involved in the quadrennial review to determine dhs's position on how the 9 / 11 commission act reporting requirements were implemented .

we conducted this performance audit from january 2015 to april 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

analyze , fuse , and disseminate terrorism information ; deter and disrupt operations ; strengthen transportation security ; and counter violent extremism .

goal 1.3: reduce risk to the nation's critical infrastructure , key leadership , and events chemical , biological , radiological , and nuclear materials and weapons .

enhance security for the nation's critical infrastructure from terrorism and criminal activity ; and protect key leaders , facilities , and national special security events .

goal 2.3: disrupt and dismantle transnational criminal organizations and other illicit actors promote u.s. economic security and competitiveness .

identify , investigate , disrupt , and dismantle transnational criminal organizations ; and disrupt illicit actors , activities , and pathways .

promote lawful immigration ; effectively administer the immigration services system ; and promote the integration of lawful immigrants into american society .

prevent unlawful entry , strengthen enforcement , and reduce drivers of unlawful immigration ; and arrest , detain , and remove priority individuals , including public safety , national security , and border security threats .

enhance the exchange of information and intelligence on risks to critical infrastructure and develop real - time situational awareness capabilities that ensure machine and human interpretation and visualization ; partner with critical infrastructure owners and operators to ensure the delivery of essential services and functions ; identify and understand interdependencies and cascading impacts among critical infrastructure systems ; collaborate with agencies and the private sector to identify and develop effective cybersecurity policies and best practices ; and reduce vulnerabilities and promote resilient critical infrastructure design .

goal 4.2: secure the federal civilian government information technology enterprise coordinate government purchasing of cyber technology to enhance cost - effectiveness ; equip civilian government networks with innovative cybersecurity tools and protections ; and ensure government - wide policies and standards are consistently and effectively implemented and measured .

goal 4.4: strengthen the cyber ecosystem deter , disrupt , and investigate cybercrime .

drive innovative and cost effective security products , services , and solutions throughout the cyber ecosystem ; conduct and transition research and development , enabling trustworthy cyber infrastructure ; develop skilled cybersecurity professionals ; enhance public awareness and promote cybersecurity best practices ; and advance international engagement to promote capacity building , international standards , and cooperation .

goal 5.3: ensure effective emergency response regulation , resilient design , effective mitigation , and disaster risk reduction measures ; and prevent incidents by establishing , and ensuring compliance with , standards and regulations .

provide timely and accurate information ; conduct effective , unified incident response operations ; provide timely and appropriate disaster assistance ; and ensure effective emergency communications .

ensure continuity and restoration of essential services and functions ; and support and enable communities to rebuild stronger , smarter , and safer .

in addition to the contact named above , ben atwater ( assistant director ) , nanette barton , chuck bausell , jr. , charlotte gamble , susan hsu , thomas lombardi , amanda miller , and katrina taylor made key contributions to this report .

