full and effective implementation of the digital accountability and transparency act of 2014 ( data act ) offers the promise of a much more complete and accurate understanding of federal spending by enabling — for the first time — the federal government as a whole to track these funds at multiple points in the federal spending lifecycle , and significantly increasing the types and transparency of data available to agencies , congress , and the general public .

since the data act became law in may 2014 , the office of management and budget ( omb ) and the department of the treasury ( treasury ) have taken significant steps to implement it .

however , the transition to a new administration may present risks tom the implementation of the data act , including potential shifting of priorities or a loss of momentum .

omb , treasury , and federal agencies need to address a range of evolving and complex policy and technical issues to ensure the data act is effectively implemented .

as we have previously reported , agencies have identified several areas of concern including inadequate guidance , tight time frames , competing priorities , a lack of funding , and system integration issues .

our prior work has identified concerns related to standardizing data element definitions and developing a technical schema , concerns that , if not addressed , could lead to agencies inconsistently and inaccurately reporting data and delaying implementation .

finally , we also reported that although omb appears to be on track with designing its pilot for developing recommendations to reduce recipient reporting burden , much of the work of actually implementing those plans remains .

addressing these challenges will require ongoing and focused commitment to maintain progress implementing key provisions of the data act .

this review is part of an ongoing effort to provide interim reports on the progress being made in implementing the data act and meets the reporting requirements mandated by the act .

this report addresses the following areas: ( 1 ) steps taken to establish a clear data governance structure , which is particularly important for the transition to a new administration , ( 2 ) challenges reported by chief financial officers act of 1990 ( cfo act ) agencies in their implementation plan updates , ( 3 ) the operationalization of government - wide data standards and the technical specifications for data reporting , and ( 4 ) updated designs for the pilot for reducing recipient reporting burden and progress made in its implementation .

to describe the extent to which omb's and treasury's efforts to implement a data governance structure for the data act were consistent with key practices , we assessed omb's and treasury's efforts against a set of common key practices for establishing effective data governance structures .

we identified this common set of key practices from a range of organizations , including domestic and international standard - setting organizations , industry groups or associations , and federal agencies , to ensure we had a comprehensive understanding of data governance key practices across several domains .

we also met with omb staff and treasury officials to obtain information on the status of their efforts to address our previous recommendation that they establish a data governance structure .

to identify implementation challenges reported by agencies , we reviewed implementation plan updates and supplemental information submitted by federal agencies and assessed it against new omb guidance and the revised treasury data act implementation playbook .

we compared the implementation plan updates we received to the initial implementation plans submitted by the cfo act agencies in 2015 .

we also interviewed omb staff and treasury officials and reviewed documentation of their processes and controls for reviewing the updated implementation information and monitoring agencies' progress .

we met with omb and treasury to obtain information on the status of efforts to address our previous recommendations related to agency implementation plans .

to assess the operationalization of data standards and technical specifications for reporting , we reviewed applicable technical guidance and documentation related to data act information model schema ( daims ) , version 1.0 , and the data act broker .

we reviewed various versions of the broker made available by treasury through open source code posted on a public website .

in addition , we observed several demonstrations of how agencies submit their data to a prototype of the broker .

we also interviewed knowledgeable officials from omb , treasury , and selected federal agencies and staff from their offices of inspector general , as well as enterprise resource planning ( erp ) vendors assisting federal agencies with technical implementation .

to obtain additional information on agencies' use of the technical guidance , we selected three agencies — the department of health and human services ( hhs ) , the department of agriculture ( usda ) , and the corporation for national and community service ( cncs ) .

although the information obtained from these three agencies is not generalizable to all agencies , they illustrate a range of conditions under which agencies are implementing the act .

at each agency , we reviewed data act implementation plan updates and interviewed officials responsible for implementing the act , including data act implementation team members .

we met with omb and treasury to obtain information on the status of efforts to address our previous recommendations related to providing policy and technical guidance .

to assess the design of the pilot for reducing recipient reporting burden ( called the section 5 pilot ) , we reviewed section 5 of the federal funding accountability and transparency act of 2006 , as amended by the data act ; assessed omb and its partners' draft design documents ; and spoke with cognizant staff implementing these pilots at omb , hhs , and general services administration ( gsa ) .

we met with omb to obtain information on the status of efforts to address our previous recommendations related to designing the pilot for reducing recipient reporting burden .

additional details regarding our objectives , scope , and methodology are provided in appendix i .

we conducted this performance audit from may 2016 to december 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

signed into law on may 9 , 2014 , the data act expanded on previous federal transparency legislation to link federal agency spending to federal program activities so that taxpayers and policymakers can more effectively track federal spending .

the data act requires government - wide reporting on a greater variety of federal funds as well as tracking of these funds at multiple points in the federal spending lifecycle .

the act also calls for the federal government to set government - wide data standards , identify ways to reduce reporting burdens for grantees and contractors ( section 5 pilot ) , and regularly review data quality to help improve the transparency and accountability of federal spending data .

omb and treasury have taken significant steps toward implementing the act's various requirements including standardizing data element definitions , issuing guidance to help agencies develop their implementation plans , and designing a pilot for developing recommendations to reduce recipient reporting burden .

we have previously reported on these efforts and others and have identified a number of ongoing challenges that will need to be addressed in order to successfully meet the act's requirements .

throughout our ongoing oversight of omb's and treasury's efforts to implement the act , we have coordinated closely with omb and treasury to provide timely feedback and have made a number of recommendations that , if addressed , could help ensure the full and effective implementation of the act .

omb and treasury have made progress implementing 5 of our recommendations related to data act implementation .

however , additional effort is needed to address 11 previous gao recommendations that remain open .

see appendix ii for a list of our previous recommendations relating to the data act and their implementation status .

omb and treasury are developing a governance structure , but more work will be needed to ensure that this structure is consistent with key practices for developing and maintaining the integrity of data standards over time .

in july 2015 , we reported that omb and treasury took initial steps to develop organizational structures for project governance but had not yet established a formal framework for providing data governance throughout the lifecycle of developing and implementing standards .

such a framework is key for ensuring that the integrity of data standards is maintained over time .

accordingly , we recommended that omb and treasury establish a clear set of policies and procedures for developing and maintaining data standards that are consistent with leading practices .

omb and treasury generally agreed with our recommendation and , in response , engaged a contractor to interview key stakeholders and develop a set of potential next steps .

the first of these steps was to establish a new data standards committee that will be responsible for maintaining established standards and developing new data elements or data definitions that could affect more than one functional community ( eg , financial management , financial assistance , and procurement ) .

according to omb staff , the data standards committee held its inaugural meeting on september 15 , 2016 , and will meet on a monthly basis .

the committee has also drafted a charter that will delineate the scope of the committee's work , as well as the composition and responsibilities of its members .

according to omb staff , members include representatives from a range of federal communities including the grants , procurement , financial management and human resources communities , as well as representatives of several interagency councils including the chief information officers council and the performance improvement council .

omb staff told us that the committee will focus on clarifying existing data standard definitions , including the definition of predominant place of performance , and identifying new standards that may be needed going forward .

in october 2016 , according to omb staff , the charter was under review by the data act executive steering committee .

several data governance models exist that could inform omb's and treasury's efforts to ensure the integrity of the data standards over time .

these models define data governance as an institutionalized system of decision rights and accountabilities for planning , overseeing , and controlling data management .

many of these models promote a common set of key practices that include establishing clear policies and procedures for developing , managing , and enforcing data standards .

a common set of key practices endorsed by standards setting organizations recommend that data governance structures should include the key practices shown in the text box below .

we have shared these key practices with omb and treasury .

key practices for data governance structures i .

developing and approving data standards .

ii .

managing , controlling , monitoring , and enforcing consistent application of data standards .

iii .

making decisions about changes to existing data standards and resolving conflicts related to the application of data standards .

iv .

obtaining input from stakeholders and involving them in key decisions , as appropriate .

v. delineating roles and responsibilities for decision - making and accountability , including roles and responsibilities for stakeholder input on key decisions .

omb and treasury have not yet institutionalized and clearly documented policies and procedures that are consistent with these key practices .

for example , processes have not been developed to both approve new standards and ensure that already established standards are consistently applied and enforced across the federal government .

one reason why having a robust , institutionalized data governance structure is important is to provide consistent data management during times of change and transition .

the transition to a new administration presents one such situation .

we have previously reported that , given the importance of continuity when implementing complex , government - wide initiatives , the potential for gaps in leadership that can occur as administrations change can impact the effectiveness and efficiency of such efforts , potentially resulting in delays and missed deadlines .

such transitions may disrupt the momentum for meeting implementation timeframes or cause the government to fail to continue to build on previous accomplishments .

the absence of a robust and institutionalized data governance structure presents additional potential risks regarding the integrity of data standards over time and the ability of agencies to meet their statutory timelines in the event that priorities shift with the incoming administration or momentum is lost .

in june 2016 , omb directed the 24 cfo act agencies to update their initial data act implementation plans that they submitted in response to omb's may 2015 request .

each agency was to ( 1 ) update its timeline and milestones and explain the agency's progress to date and the remaining actions it would take to implement the act in accordance with the suggested steps in treasury's data act implementation playbook ( version 2.0 ) ( playbook 2.0 ) , ( 2 ) report costs to date and estimated total future costs , and ( 3 ) explain any new challenges and mitigation strategies .

in reviewing the 24 cfo act agencies' implementation plan updates that we obtained from the agencies , we found the following: each of the 24 cfo act agencies' updates included timelines and milestones and most of the updates included most of the omb required information .

for example , most of the 24 cfo act agencies included remaining actions the agencies would take to implement the suggested steps in playbook 2.0 .

some of the cfo act agencies did not include information about some of the remaining actions to implement the suggested steps in playbook 2.0 .

for example , 5 of the 24 cfo act agencies did not include information about testing for completeness and accuracy of data elements submitted to treasury , 11 cfo act agencies did not include information about workflows for addressing validation errors and revisions needed to agency data submissions , and 13 cfo act agencies did not include information about testing linkages of program and financial data or possible interim solutions to link such data , if needed .

without such information in agencies' updates , it may be more difficult for omb and treasury to determine where to target their monitoring and assistance efforts to help ensure the data act is successfully implemented .

our review of the cfo act agencies' august 2016 implementation plan updates found that 21 of the 24 cfo act agencies reported costs to date and future estimated costs to implement the data act reporting requirements .

one agency reported future estimated costs , but did not report costs to date .

two agencies did not provide any cost estimates .

total cumulative and future estimated costs for full data act implementation that was reported by 22 cfo act agencies in their implementation plan updates ranged from approximately $1.0 million to $59.1 million , for a total of about $202.4 million .

this total estimated cost reported by cfo act agencies to implement the data act includes costs for systems integration and modernization .

it is important to note that the estimated total costs reported by cfo act agencies to implement the data act requirements is relatively small when compared to the almost $81 billion spent on information technology by the cfo act agencies in fiscal year 2016 alone .

see appendix iii for more details about the information that omb required cfo act agencies to include in their implementation plan updates , remaining actions to implement the suggested steps in playbook 2.0 , and the number of cfo act agencies that included the information .

in our july 2016 report , we reported on challenges agencies included in their initial implementation plans .

the implementation plan updates indicate that 19 of the 24 cfo act agencies continue to face challenges in their efforts to implement the data act .

based on our review of the 24 cfo act agency implementation plan updates , we identified four overarching categories of challenges reported by agencies that may impede their ability to effectively and efficiently implement the data act: systems integration issues , lack of resources , evolving and complex reporting requirements , and inadequate guidance .

see table 4 in appendix iii , which describes the categories of challenges and the number of cfo act agencies reporting challenges in each category .

some of the challenges reported by the cfo act agencies in their updates include the following: systems integration .

nineteen of the 24 cfo act agencies reported challenges related to systems integration , which include concerns with systems limitations , modernization efforts , and timing .

for example , one agency reported that validation presents challenges because its financial systems are not properly integrated with procurement and grant systems .

similarly , the agency reported that several of its components are undergoing grant , procurement , or financial system improvements that coincide with implementing the data act , which could pose a risk to timely data act implementation if the improvements are delayed .

another agency reported that , for one of its legacy systems , obtaining the unique identifier to generate award financial data will likely be a manual process .

the lack of properly integrated systems increases the risk that agencies may have difficulty compiling and validating the information they are required to report under the data act by the may 2017 reporting deadline for agencies to submit their financial and payment information .

resources .

fourteen of the 24 cfo act agencies reported challenges related to staffing issues or funding constraints .

for example , one agency reported that expertise related to feeder systems and data will be needed to successfully implement the data act , but such subject matter experts may not be available .

another agency reported that meeting the reporting deadline is highly dependent on receiving requisite funding and resources .

the lack of sufficient resources , including staff expertise and proper funding , increases the risk that agencies may have difficulty taking all the actions needed in a timely manner to fully implement the requirements of the data act .

reporting .

thirteen of the 24 cfo act agencies reported challenges related to mandatory data act reporting requirements , including concerns with data quality and their ability to report all the required data elements in their initial data act submissions , as well as senior accountable officials ( sao ) certification and reporting non - financial data .

for example , one agency reported that its sao may be unable to certify the quality of data if omb's guidance for the sao certification cannot be supported by existing processes .

another agency reported concerns with the burden of reconciling account data with financial and award data .

in addition , two agencies reported challenges with reporting beginning balances at the level of detail required by the data act .

two agencies reported concerns with protecting sensitive and classified data .

one agency also reported ongoing issues with inconsistent quality of data submitted from their financial systems .

another agency reported that certain data elements are not currently available for all document types , and is considering pulling these data elements from other source systems to the extent possible .

a lack of complete and accurate agency data increases the risk that agencies may not be able to meet the data act reporting requirements within the mandated timeframes .

guidance .

eleven of the 24 cfo act agencies reported ongoing challenges related to the timely issuance of , and ongoing changes to , omb policy and treasury guidance .

eight agencies reported that if policy or technical guidance continues to evolve or be delayed , the agencies' ability to comply with the may 2017 reporting deadline could be affected .

some agencies also reported concerns about the requirement for saos to certify the data reported quarterly .

for example , one agency reported that if guidance clarifying certification procedures is delayed , it may not have time to implement appropriate validation steps needed to give assurance over the data .

because of the lack of timely and consistent guidance , agencies may need to continuously update or change their processes , which could adversely affect their ability to meet the data act requirements .

as noted above , the information reported by the cfo act agencies in their implementation plan updates indicates that some agencies are at increased risk of not meeting the may 2017 reporting deadline because of these challenges .

in addition , inspectors general for some agencies , such as the departments of labor and housing and urban development , have issued readiness review reports that also indicate their respective agencies are at risk of not meeting the reporting deadline .

as discussed further below , the technical software requirements for agency reporting are still evolving , so any changes to the technical requirements over the next few months could also affect agencies' abilities to meet the reporting deadline .

in august 2016 , in response to our prior recommendation , omb established procedures for reviewing and using agency implementation plan updates that include procedures for identifying ongoing challenges .

in its procedures document , omb states that it has received input from a significant number of agency staff via office hours , emails , regular meetings , agency visits , and other methods regarding the challenges agencies are experiencing as they work toward implementation since the submission of their original plans .

omb's document also states that it has worked to address these challenges and provide both policy and technical guidance as needed .

further , the document stated that requiring agencies to update plans will allow omb to address challenges that agencies are not directly reaching out to omb about or that numerous agencies are experiencing .

according to the procedures document , omb will also be monitoring progress toward the statutory deadline and setting up meetings with any of the 24 cfo act agencies that omb identifies as being at risk of not meeting the implementation deadline .

omb will schedule these visits by reviewing the implementation plan updates and discerning which agencies appear to be experiencing the most challenges to implementation .

to help address their challenges , 16 of the 24 cfo act agencies reported that they use certain mitigating strategies in their implementation plan updates .

based on our review , we identified seven overarching categories of mitigating strategies reported by these agencies to address data act implementation challenges: making changes to internal policies and procedures , leveraging existing resources , using external resources , continuing communications , employing manual and temporary workarounds , monitoring and developing guidance , and enhancing existing systems .

these strategies , as a whole , were similar to the mitigating strategies reported by agencies in their initial implementation plans .

the most commonly reported categories of mitigating strategies were changing internal policies and procedures and leveraging existing resources .

see table 5 in appendix iii for descriptions of the categories of mitigating strategies and the number of cfo act agencies that report using strategies from each category .

in may 2016 , in response to our prior recommendation , omb released additional guidance on reporting financial and award information required under the act to address potential clarity , consistency , and quality issues with the definitions of standardized data elements .

in january 2016 we reported that ensuring that data definitions are generally consistent with leading practices is important because limitations with the definitions could lead to inconsistent or inaccurate reporting , among other issues .

we also reported that although the standardized data element definitions issued by omb largely adhered to leading practices for establishing data definitions , several definitions had limitations that could lead to inconsistent reporting .

while omb's additional guidance addresses some of the limitations we identified , it does not address all the clarity issues we identified .

specifically , omb's additional guidance addresses ( 1 ) reporting financial and award level data , ( 2 ) establishing linkage between agency award and financial systems using a unique award identifier , and ( 3 ) providing assurances that data submitted to treasury for publication on usaspending.gov is sufficiently valid and reliable .

for example , omb's management procedures memorandum no .

2016-03 directs agencies to leverage existing procedures for providing assurances of the quality of their data act data submissions and directs agency saos to provide reasonable assurance that their internal controls support the reliability and validity of the data submitted to treasury for publication on usaspending.gov .

omb's memorandum notes that assurance means that , at a minimum , the data reported are based on appropriate internal control and risk management strategies identified in omb circular a - 123 .

omb expects sao assurance of the data through this process would mean that data submitted to treasury by may 2017 complies with existing controls for ensuring the data quality .

however , our prior work has shown that relying on these quality assurance processes is not sufficient to address the accuracy and completeness challenges that we have previously identified .

additionally , as we reported in august 2016 , offices of inspector general , which are required to assess the completeness , timeliness , quality , and accuracy of data submitted under the act , have expressed concerns about agencies' abilities to provide assurances of the quality of their data .

the inspectors general are particularly concerned about their agencies' ability to provide quality assurances for data that are not directly provided by the agency , such as data submitted by non - federal entities who receive federal awards .

to address these concerns , omb released draft guidance in august 2016 that specifies data act reporting responsibilities when an intragovernmental transfer ( both allocation transfers and buy / sell transfers ) is involved , explains how to report financial assistance awards with personally identifiable information ( pii ) , and clarifies the sao assurance process over the data submitted to the broker .

omb staff told us that this most recent policy guidance was drafted in response to questions and concerns reported by agencies in their implementation plan updates , as well in meetings with senior omb and treasury officials intended to assess agency implementation status .

among other challenges , agencies indicated the need for additional guidance on reporting intergovernmental transfers , providing assurances over their data , and reporting insurance information .

for example , officials from usda , one of our case example agencies , told us that they are waiting for guidance on insurance and indemnity reporting , but no guidance has been issued .

absent any new guidance , they plan to report insurance as they have under the federal funding and accountability and transparency act of 2006 ( ffata ) .

omb staff told us that they received feedback from 30 different agencies and reviewed over 200 comments on the draft guidance .

the final guidance , omb m - 17-04 , was issued on november 4 , 2016 .

although omb has made some progress with these efforts , other data definitions lack clarity — including primary place of performance and award description — which still needs to be addressed to ensure agencies report consistent and comparable data .

these challenges , as well as the challenges identified by agencies , underscore the need for omb and treasury to fully address our prior recommendation to provide agencies with additional guidance to address potential clarity issues .

omb staff told us that the newly established data standards committee will be responsible for developing guidance to provide additional operational clarity regarding these data definitions ; however , they were unable to provide a specific timeframe for when this would be done .

treasury released the schema version 1.0 on april 29 , 2016 — 4 months later than planned and approximately a year before reporting is required to begin under the act .

the schema version 1.0 is intended to standardize the way financial assistance awards , contracts , and other financial data will be collected and reported under the data act .

treasury expects the guidance provided in the schema version 1.0 will provide a stable base for agencies to develop the necessary data submission procedures .

we have previously reported that a significant delay in releasing version 1.0 of the schema would likely have consequences for timely implementation of the act .

agencies are using schema version 1.0 to plan what changes are needed to systems and business processes to be able to capture and submit the required data .

under the act , agencies must report data in compliance with established standards by may 2017 .

toward that end , omb and treasury have directed agencies to begin submitting data by the beginning of the second quarter of fiscal year 2017 ( january 2017 ) with the intention of publically reporting that data by may 2017 .

omb's summary of agencies' implementation plan updates acknowledged that the delay in the release of schema version 1.0 delayed agency timelines for implementation .

this document also recognized that the iterative approach being used to develop and release guidance has posed challenges for some agencies as changes in the guidance may require them to re - work some of their implementation project plans .

our analysis of the implementation plan updates submitted by the agencies to omb confirms this .

we found that 11 of the 24 cfo act agencies highlighted challenges related to the guidance provided by omb and treasury in their implementation plan updates .

one of the commonly cited challenges concerned complications arising due to the iterative nature or late release of the guidance .

for example , one agency reported that developing its implementation plan was highly dependent upon the concurrent development of the schema version 1.0 and technical guidance being developed by treasury .

this agency stated that any delays or changes to these components will significantly affect its solution design , development and testing schedule , and cost estimate .

a key component of the reporting framework laid out in the schema version 1.0 is the data act broker , a system to standardize data formatting and assist reporting agencies in validating their data prior to submitting it to treasury .

see figure 1 for a depiction of how treasury expects the broker to operate .

treasury's software development team has been iteratively testing and developing the broker using what treasury describes as an agile development process .

treasury released the first version of the broker in spring 2016 and it continues to develop the system's capabilities through 2-week software development cycles , called sprints .

on september 30 , 2016 , treasury released a version of the broker , which it stated was fully capable of performing the key functions of extracting and validating agency data .

treasury officials told us that although they plan to continue to refine the broker to improve its functionality and overall user experience , they have no plans to alter these key functions .

according to treasury guidance documents , agencies are expected to use the broker to upload three files containing data pulled from the agencies' internal financial and award management systems .

these files will undergo two types of validation checks in the broker before being submitted to treasury: data element validations and complex validations .

data element validations check whether data elements comply with specific format requirements such as field type and character length .

complex validations perform tasks such as checking data against other sources or using calculation rules to verify whether certain data elements sum up to each other .

treasury has configured these complex validation rules so that if a rule is not met , the broker can either produce a warning message while still accepting the data for submission or produce a fatal error , which prevents submission of the data altogether .

as of september 30 , 2016 , data uploaded to the broker needs to successfully meet less than a quarter of these complex validation checks in order to be accepted for submission to treasury .

treasury officials said that this choice was made in order to allow agencies more flexibility to test the broker , and that the data submissions will be required to pass more of these validation rules at a later date .

according to treasury documents , in a future release of the broker , data uploaded to the broker will need to successfully meet about half of the complex validation checks in order to be accepted for submission to treasury .

treasury officials said that having about half of the validation rules produce warnings rather than fatal errors would provide agency officials with the flexibility to correct issues flagged by the broker or not to do so , depending on their knowledge of the context and situation of specific data elements .

for example , for some of the programs , grants award - level information may not be reported for security reasons .

in addition to assisting agencies in collecting and validating agency - generated data , the broker also extracts award and sub - award information from existing government - wide award reporting systems and helps ensure these files are in the standard format .

this function was added during software development efforts in late september and early october 2016 .

unlike the files submitted by agencies , these extracted files with award and sub - award information are not subject to any validations in the broker .

however , treasury implemented additional validation checks on the file containing agency financial assistance award information through its source system , the award submission portal .

these checks include verifying that required information is present and formatted correctly .

treasury officials told us that the responsibility for ensuring the accuracy of these files lies with the data act sao at each agency .

for example , omb management procedures memorandum 2016-03 specifies that saos must provide reasonable assurance that their internal controls support the reliability and validity of the agency account - level and award - level data submitted to treasury for publication .

before final submission of the data files in the broker , the sao is responsible for assuring that , at a minimum , the data reported are based on appropriate internal control and risk management strategies identified in omb circular a - 123 .

treasury officials said that if saos are not able to provide this assurance , their agency will be prevented from submitting the files and their data will not be included in the data reporting based on the current broker design .

currently , the broker does not allow agencies to submit their data with qualifications , such as known quality limitations , so data that does not completely meet the criteria for sao assurance will not be reported , even with qualifications .

omb staff and treasury officials said that they are reconsidering this position and are exploring ways that agencies can submit data with qualifications and how these qualifications can be conveyed to the public .

agencies have made progress toward creating their data submissions and testing them in the broker , but work remains to be done before actual reporting can begin .

treasury has made empty sample files available to agencies so they can begin testing their data files in the broker without having completed building all of them .

as of october 2016 , 21 of 24 cfo act agencies reported that they had begun testing their data files in the broker , but only the national aeronautics and space administration had completed testing the broker and revised its data files accordingly .

treasury also collects data from the four shared service providers that are helping to manage data submissions for their agency clients .

as of october 2016 , two of these shared service providers reported to treasury that they had finished building the data files for submission to the broker .

in august 2016 , we reported that agencies we reviewed are relying on a series of software patches from their enterprise resource planning ( erp ) vendors to facilitate their data submissions .

erp vendors are developing patches that will extract data to help their clients develop files that comply with data act requirements .

according to vendors , these patches will help link an agency's financial and award systems , create additional fields in existing systems to report new data elements , and extract data files formatted for submission to treasury .

patches that will facilitate the generation of agency file submissions were planned to be completed between august 2016 and february 2017 .

as of september 2016 , the release of one of these patches has been delayed .

oracle , one of the erp vendors developing these patches , had planned to release a patch that would allow award attributes to be captured in their clients' core purchasing systems and general ledger journals in august 2016 , but the release was delayed until september 13 , 2016 .

representatives from sap , another such erp vendor , said that they were able to deliver one of the needed patches to their clients in august 2016 and an additional patch in october .

but , they also said that changes and adjustments to the broker had delayed their progress towards creating a patch that can format their clients' data files for submission .

it will be more difficult for agencies that are relying on erp vendor patches to test their data files in the broker until the patches have been implemented since the patches will enable them to construct and format their files for submission to the broker .

two agencies reported in their implementation plan updates that a delay in the release of the patches could jeopardize complete and timely data submission for may 2017 .

treasury officials told us that agencies should still be able to create and submit the required files to the broker without these patches .

these officials said that when designing the schema and broker , they chose to use a simple file format for data submissions so that agencies would be able to create these files without a specialized software solution .

treasury officials acknowledged that patches will make the submission process easier , but also pointed out that not every agency is able to take advantage of software patches .

some agencies reported in their implementation plan updates that they developed plans for interim solutions to construct these files until the patches can be developed , tested , and configured .

however , some of these interim solutions rely on manual processing , which can be burdensome and increase the risk for errors .

for example , usda officials said that the effort to create an interim solution has been very resource intensive .

this process involved surveying usda's bureaus to identify how their systems are configured and using that information to modify the financial system .

hhs has also developed an interim reporting solution that can generate the required files without depending on a patch .

however , hhs officials said this interim solution is complex and their processes cannot be fully automated until the oracle patch is released .

furthermore , since these processes are not fully automated , they carry a risk of errors being introduced though human error .

agencies that are developing interim solutions will only have until may 2017 to test the data before the reporting deadline .

an omb document commended these agencies for developing robust contingency plans since this will better position them for timely implementation , but acknowledged that that long - term reporting solutions are still needed .

as required by the data act , omb is conducting a pilot program , known as the section 5 pilot , aimed at developing recommendations for reducing reporting burden for grantees and contractors .

the section 5 pilot has two primary focus areas — federal grants and federal contracts ( procurements ) .

omb partnered with hhs to design and implement the grants portion of the pilot and with the general services administration ( gsa ) to implement the procurement portion .

as the executing agent for the grants portion of the pilot , hhs developed six “test models” to evaluate different approaches to potentially reducing grantee reporting burden .

on the procurement portion of the pilot , omb's office of federal procurement policy ( ofpp ) worked with gsa's 18f to develop and test a proof of concept reporting portal for reports required by the federal acquisition regulation ( far ) and is piloting it with the centralized reporting of certified payroll by contractors working construction projects in the united states .

in march 2016 , a revised plan describing the design of the grants portion of the pilot was released , which updated the november 2015 version we previously reviewed .

this was followed , in july 2016 , by a revised version of the design for the procurement portion .

see table 1 for a summary of the test models components that comprise the grants and procurement portions of the section 5 pilot .

we determined that the updated design for both portions of the section 5 pilot meets the statutory requirements for the pilot established under the data act .

specifically , the data act requires that the pilot program should include the following design features: ( 1 ) collect data during a 12- month reporting cycle ; ( 2 ) include a diverse group of federal award recipients and , to the extent practicable , recipients that receive federal awards from multiple programs across multiple agencies ; and ( 3 ) include a combination of federal contracts , grants , and subawards with an aggregate value between $1 billion and $2 billion .

based on our review of design documents as well as interviews with cognizant agency staff , there has been substantial improvement in this area since our last review , when the design lacked specifics in the procurement portion of the pilot , which made it difficult to determine whether the design of the overall pilot would meet these requirements .

both the grants and procurement portions of the pilot showed substantial improvements in the extent to which they reflect leading practices for pilot design ( shown in the textbox below ) .

we found that hhs's march 2016 revised design for the grants portion of the pilot partly reflects all five of the leading practices for effective pilot design — an improvement from our prior assessment .

for example , in our april 2016 review we found that the grants design lacked specific details regarding how the data will be analyzed and how conclusions will be reached about integrating the pilot activities into overall grant reporting efforts .

based on our feedback , omb and hhs developed a plan to analyze survey and other data prior to the start of data analysis .

this plan specifies the types of quantitative and qualitative data analysis hhs intends to conduct for each test model and how that assessment links back to the stated hypotheses .

hhs also added a sampling plan and information on participant outreach efforts to the design of the grants portion of the pilot which helped it to meet the leading practices for effective pilot design .

leading practices for effective pilot design 1 .

establish well - defined , appropriate , clear , and measurable objectives .

2 .

clearly articulate an assessment methodology and data gathering strategy that addresses all components of the pilot program and includes key features of a sound plan .

3 .

identify criteria or standards for identifying lessons about the pilot to inform decisions about scalability and whether , how , and when to integrate pilot activities into overall efforts .

4 .

develop a detailed data - analysis plan to track the pilot program's implementation and performance and evaluate the final results of the project and draw conclusions on whether , how , and when to integrate pilot activities into overall efforts .

5 .

ensure appropriate two - way stakeholder communication and input at all stages of the pilot project , including design , implementation , data gathering , and assessment .

omb's july 2016 revision of the design of the procurement portion of the section 5 pilot also showed substantial improvements in reflecting the leading practices for effective pilot design .

compared to the previous version , dated november 2015 , we identified progress in several areas .

for example , the revised procurement design identified hypotheses for each objective and contained objectives that were linked to metrics that should facilitate omb's ability to collect appropriate evaluation data .

the revised design also provides additional details regarding the procurement portion's intended assessment methodology .

it specifies that participants will submit payroll information to the centralized test portal on a weekly basis and that omb will use focus groups to collect qualitative data from agency staff that use these data for contract management and oversight purposes .

furthermore , the revised design includes a data - analysis plan that describes how omb will collect , track , and analyze data produced by the pilot .

finally , the revised procurement design provides additional detail about how potential findings could be scalable from the experiences of the individual pilot participants to the larger population of contractors required to submit certified payroll reports in compliance with davis bacon requirements .

toward that end , the revised procurement pilot design contains a sampling plan that provides criteria for selecting a diverse group of participants .

we found some areas where the revised procurement design does not fully reflect leading practices for effective pilot design .

these largely relate to how omb intends to broaden the pilot's initial focus on centralizing certified payroll reporting to other types of far - required reporting .

the procurement design presents a reasonable set of factors for why omb decided to initially select certified payroll reporting for testing the potential usefulness of a centralized reporting portal to reduce reporting burden .

however , the plan does not take the next step of clearly describing and documenting how findings related to centralized certified payroll reporting will be more broadly applicable to the many other types of required reporting under the far beyond citing general concepts such as data pre - population and system integration .

more specifically , the current design lacks a plan for testing the assumption that the experiences contractors have with centralized certified payroll reporting will be similar when they use the system to meet different reporting requirements and other databases .

this is of particular concern given the diversity of reporting requirements contained in the far .

in fact , omb staff have identified over 100 different types of far reporting requirements with different reporting frequencies , mechanisms , and required information .

omb staff told us that they expect to test the centralized portal on other types of far - required reporting and the revised design briefly mentions other far requirements such as those for service contracts and affirmative action plans .

however , the revised design does not provide any details on how this will be done .

the absence of an assessment methodology and an approach to test the scalability of the design when applied to procurement reporting requirements beyond certified payroll reporting is inconsistent with leading practices for pilot design and raises questions about whether the pilot design will meet its stated objective of reducing procurement reporting burden more broadly .

hhs has taken a number of steps to begin implementing the design of the grants portion of the pilot .

for example , they are recruiting participants for all of the test models and have begun administering data collection instruments for all of the test models .

hhs has engaged in a number of outreach efforts to recruit participants for its test models .

these officials told us that they have attended an estimated 70 events since 2015 to discuss the grants pilot , during which they provided information to interested attendees on how to get involved .

additionally , as of august 2016 , hhs officials reported e - mailing almost 8,000 potential participants and plan on emailing additional prospects , if needed , in order to reach an established minimum number of participants for each test model .

gsa's 18f completed a prototype for the procurement portion of the section 5 pilot at the end of may 2016 and presented it to omb in june 2016 .

18f's role was to explore how an electronic certified payroll reporting portal could reduce contractor burden for federal davis - bacon contracts .

in august 2016 , gsa's federal acquisition service , the implementation lead for the pilot , awarded nuaxis the contract to build the prototype from information obtained as a result of the 18f prototype process .

gsa officials told us that starting in september 2016 , nuaxis began developing a web - based reporting interface that will allow users to centrally enter and submit certified payroll data .

they plan to make this interface compatible with other existing systems , such as the system for award management ( sam ) and wage determination online ( wdol ) to access relevant data sources .

in late november 2016 , omb staff and gsa officials informed us that they decided to delay launching the portal to conduct the procurement portion of the pilot in order to ensure that security procedures designed to protect personally identifiable information ( pii ) were in place .

gsa officials told us that the centralized reporting portal that would be used to collect data on certified payroll did not receive the required authority to operate because it did not include necessary security measures to protect the pii that would be submitted by contractors participating in the pilot .

before the portal can be used to collect pii , gsa officials said they needed to issue a system of records notice and redesign the certified payroll reporting platform so that it conforms to agency security procedures .

as a result of these additional steps , gsa officials expect to be able to begin collecting data through the centralized reporting portal sometime between late january 2017 and late february 2017 .

omb staff said that despite the security - related delay , they still plan on collecting 12 months of data through the procurement pilot as required by the act .

in order to meet the act's requirement that omb deliver a report to congress on ways to reduce recipient reporting burden by august 2017 , omb staff told us that they plan to only include data collected up to june or july 2017 in order to allow for sufficient time to analyze the results and incorporate them into the report's findings .

however , these staff said that that they plan to continue to collect data through the procurement portion of the pilot until they obtain a full 12 months of contractors' experiences with centralized payroll reporting .

afterwards , omb plans to analyze this data , compare it to the smaller data set produced for the august 2017 report to congress and , if necessary , make any needed revisions to the findings and recommendations contained in the report previously submitted to congress .

across the federal government , agencies have efforts under way to implement the data act by the may 2017 deadline and the success of these efforts will depend on , among other things , omb and treasury's efforts to address agency - reported challenges and build an infrastructure to effectively support government - wide implementation .

omb and treasury have made progress but still need to fully address the recommendations we have made in our previous reports .

for example , omb and treasury can build upon the initial step of establishing a data standards committee responsible for maintaining already established standards and identifying new standards towards the goal of establishing an institutionalized system of data management that follows key practices and ensures the integrity of the data standards over time .

in this context , implementing our prior recommendations will be critical to omb's and treasury's progress .

among the areas where progress has been made in setting a foundation for successfully implementing the act is the section 5 pilot to reduce reporting burden .

in particular , the design of the procurement portion of the pilot has improved substantially , including the extent to which it reflects leading practices of pilot design .

however , despite advances in several areas , the current design remains limited by its lack of specifics regarding how a pilot focused on assessing contractors' experiences with a centralized portal designed for certified payroll reporting will be applicable to many other federal procurement reporting requirements .

by addressing issues such as this and continuing to focus on implementing the act , the administration greatly increases the likelihood of creating a system that will achieve the goals of the act — to increase the transparency of financial information and improve the usefulness of that data to congress , federal managers , and the american people .

in order to ensure that the procurement portion of the section 5 pilot better reflects leading practices for effective pilot design , we recommend that the director of omb clearly document in the pilot's design how data collected through the centralized certified payroll reporting portal will be used to test hypotheses related to reducing reporting burden involving other procurement reporting requirements .

this should include documenting the extent to which recommendations based on data collected for certified payroll reporting would be scalable to other far - required reporting and providing additional details about the methodology that would be used to assess this expanded capability in the future .

we provided a draft of this report to the secretaries of agriculture , health and human services , and the treasury ; the director of omb ; the chief executive officer of the corporation of national and community service ; and the administrator of the general services administration for review and comment .

omb , treasury , cncs , hhs , and gsa provided us with technical comments which we incorporated as appropriate .

usda had no comments .

omb and treasury also provided written comments which are summarized below and reproduced in appendices iv and v , respectively .

in written comments submitted to us , omb provided an overview of their implementation efforts since the passage of the data act .

these efforts include issuing three memoranda providing implementation guidance to federal agencies ; finalizing 57 data standards for use on usaspending.gov ; establishing the data standards committee to develop and maintain standards for federal spending ; and developing and executing the section 5 pilot .

the omb response also noted that omb and treasury met with each of the 24 cfo act agencies to discuss their implementation timelines , risks , and mitigation strategies , and took steps to address issues that could affect successful implementation .

through these meetings , omb staff learned that 19 of the 24 cfo act agencies expect that they will fully meet the may 2017 deadline for data act implementation .

omb neither agreed nor disagreed with gao's recommendation .

in their written response , treasury provided an overview of the steps they have taken to implement the data act's requirements and assist agencies in meeting their requirements under the act including omb's and treasury's issuance of uniform data standards , treasury's data act implementation playbook , version 2.0 , and the data act information model schema version 1.0 .

the treasury response also noted that as a result of the aggressive implementation timelines specified in the act and the complexity associated with linking hundreds of disconnected data elements across the federal government , they made the decision to use an iterative approach to provide incremental technical guidance to agencies .

according to treasury , among other things , this iterative approach enabled agencies and other key stakeholders to provide feedback and contribute to improving the technical guidance and the public website .

we are sending copies of this report to the secretaries of agriculture , health and human services , and the treasury ; the director of omb ; the chief executive officer of the corporation of national and community service ; the administrator of the general services administration ; as well as interested congressional committees and other interested parties .

this report will be available at no charge on our website at http: / / www.gao.gov.if you or your staff has any questions about this report , please contact j. christopher mihm at ( 202 ) 512-6806 or mihmj@gao.gov or paula m. rascona at ( 202 ) 512-9816 or rasconap@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of our report .

key contributors to this report are listed in appendix iv .

this review is part of an ongoing effort to provide interim reports on the progress being made in implementing the digital accountability and transparency act of 2014 ( data act ) , while also meeting the reporting requirements for us mandated by the act .

this report examines: ( 1 ) steps taken to establish a clear data governance structure which is particularly important during the upcoming transition to a new administration ; ( 2 ) challenges reported by chief financial officers act of 1990 ( cfo act ) agencies in their implementation plan updates ; ( 3 ) the operationalization of government - wide data standards and the technical specifications for data reporting ; and ( 4 ) updated designs for the section 5 pilot for reducing recipient reporting burden and progress made in its implementation .

to describe the office of management and budget's ( omb ) and the department of the treasury's ( treasury ) efforts to implement a data governance structure for the data act , we identified common key practices for establishing effective data governance structures .

to identify key practices for data governance we reviewed our past reports to identify applicable laws , regulations , and guidance , as well as reports from other entities that could inform our work .

to select the sources we used to identify key practices for establishing an effective data governance program , we identified organizations that had data governance expertise , had previously published work on data governance , were frequently cited as a primary source , or some combination of these qualifications .

in addition , because the data act requires that established data standards incorporate widely accepted common data elements such as those developed by international voluntary consensus standards bodies , federal agencies with authority over contracting and financial assistance , and accounting standards organizations , we selected a range of organizations , including domestic and international standards - setting organizations , industry groups or associations , and federal agencies , to ensure we had a comprehensive understanding of data governance key practices across several domains .

all of the organizations we identified endorse establishing and using a governance structure to oversee how data standards , digital content , and other data assets are developed , managed and implemented .

based on these selection factors we drew on work from the following organizations to help us identify data governance key practices: american institute of certified public accountants , american national standards institute , carnegie - mellon university - software engineering institute , data governance institute , data management association international , oracle , national association of state chief information officers , national institute of standards and technology , digital services advisory group and the department of education - privacy technical assistance center .

we also met with omb and treasury to obtain information on the status of their efforts to address our previous recommendation that they establish a data governance structure .

to determine the implementation challenges reported by cfo act agencies in their data act implementation plan updates , we requested and received the updates from the 24 cfo act agencies .

we reviewed these implementation plan updates and assessed the information against omb's requirements and the revised guidance in treasury's data act implementation playbook ( version 2.0 ) ( playbook 2.0 ) to determine whether the updates contained the information required by omb — ( 1 ) an updated timeline and milestones with an explanation of the agency's progress to date and the remaining actions it would take to implement the act in accordance with the suggested steps in playbook 2.0 , ( 2 ) costs to date and estimated total future costs , and ( 3 ) an explanation of any new challenges and mitigation strategies .

we analyzed the agency - reported challenges and mitigating strategies and categorized them .

we compared the categories of challenges reported by the cfo act agencies in their implementation plan updates to the challenges that had been reported in their initial implementation plans in 2015 to identify any new categories of challenges .

we interviewed cognizant omb and treasury officials and obtained any supporting documentation to further understand the implementation challenges reported by agencies in their implementation plan updates and omb and treasury's processes and controls for reviewing the updated implementation information and monitoring agencies' progress .

we also met with omb and treasury to obtain information on the status of efforts to address our previous recommendations related to agency implementation plans .

to assess efforts to date to operationalize government - wide standards we reviewed omb policy guidance intended to facilitate agency reporting as well as guidance intended to respond to agency requests that omb clarify how to report specific transactions .

we also interviewed omb staff and treasury officials to obtain information about plans for additional guidance as well as to assess the extent to which issued guidance is responsive to agency questions , requests for additional clarity on their reporting requirements , or both .

we met with omb and treasury to obtain information on the status of efforts to address our previous recommendation related to the provision of policy guidance .

to examine the technical structure and specifications for reporting , we assessed treasury's processes for developing technical guidance and reviewed applicable technical documentation related to the schema version , 1.0 and the broker .

we reviewed the broker made available by treasury through open source code posted on a public website ( github repositories associated with the data act ) in order to understand its functionality and validations .

in addition , we observed several demonstrations of how agencies submit their data to a prototype of the broker and the feedback produced by the system regarding data verification .

we also interviewed knowledgeable officials from omb , treasury , and selected federal agencies and inspectors general , as well as enterprise resource planning ( erp ) vendors assisting federal agencies with technical implementation .

to obtain specific information on how agencies use the technical guidance , we selected three agencies based on whether they were in compliance with existing federal requirements for federal financial management systems , the type of federal funding provided ( such as grants , loans , or procurements ) , and their status as a federal shared service provider for financial management .

based on these selection factors , we chose the department of health and human services ( hhs ) , the department of agriculture ( usda ) , and the corporation for national and community service ( cncs ) .

although the information obtained from these three agencies is not generalizable to all agencies , they illustrate a range of conditions under which agencies are implementing the act .

these are the same three agencies we selected for our january 2016 and august 2016 reports .

this allowed us to assess progress in data act implementation at these agencies since our last review .

at each agency , we reviewed data act implementation plan updates and interviewed officials responsible for implementation and data act implementation team members .

we met with omb and treasury to obtain information on the status of efforts to address our recommendation related to providing technical guidance .

to assess whether the section 5 pilot designs meet statutory design requirements , we reviewed section 5 of the federal funding accountability and transparency act of 2006 , as amended by the data act , to understand the deadlines and design requirements .

we reviewed the draft design documents to assess omb and its partners' plans for meeting these requirements .

to supplement our review of those plans , we also spoke with cognizant staff implementing these pilots at omb , hhs , and general services administration .

to assess the extent to which the section 5 pilot designs adhered to leading practices for effective pilot design , we reviewed the documented designs for both the grants and procurement portions of the pilot .

to evaluate the grants portion of the pilot , we reviewed the draft design document from march 2016 as well as data collection instruments such as surveys and quizzes .

we supplemented our assessment with information hhs officials provided to us during subsequent interviews , as appropriate .

for the procurement portion , we reviewed the draft design document from july 2016 .

additionally , we supplemented our assessment with information officials from omb's office of federal procurement policy ( ofpp ) provided to us during subsequent interviews , as appropriate .

to assess the grants and procurement portions of the pilot , we applied the five leading practices for effective pilot design we identified to both portion's design documents .

each of these analyst assessments were subsequently verified by a second analyst .

we determined that the design met the criteria when we saw evidence that all aspects of a leading practice were met .

when we were unable to assess whether all aspects of a leading practice were met , we determined that the design partially met the criteria .

finally , when we saw no evidence of a leading practice , or if we identified a critical gap or shortcoming related to the practice , we determined that the criteria were not met .

in continuation of our constructive engagement approach for working with agencies implementing the data act , we provided hhs and omb with feedback on the design of the grants and procurement portions of the pilot during our review .

these officials generally accepted our feedback as useful and , in some instances , noted that they have or planned to make changes to their design as a result of our input .

we also met with omb to obtain information on the status of efforts to address our recommendation related to the design of the pilot for reducing recipient reporting burden .

we conducted the work upon which this report is based from may 2016 to december 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in may 2015 , the office of management and budget ( omb ) directed federal agencies to submit digital accountability and transparency act of 2014 ( data act ) implementation plans to omb concurrent with the agencies' fiscal year 2017 budget requests .

in june 2015 , the department of the treasury ( treasury ) issued guidance — data act implementation playbook ( version 1.0 ) — to help agencies prepare their implementation plans .

we reviewed these implementation plans and on july 29 , 2016 , we issued a report on the results of our review .

in june 2016 , omb directed chief financial officers act of 1990 ( cfo act ) agencies to submit updates to their initial data act implementation plans by august 12 , 2016 .

the updates were to ( 1 ) update timeline and milestones and explain the agency's progress to date and the remaining actions it would take to implement the act in accordance with the suggested steps in the data act implementation playbook ( version 2.0 ) ( playbook 2.0 ) , ( 2 ) report costs to date and estimated total future costs , and ( 3 ) explain any new challenges and mitigation strategies .

treasury's data act implementation playbook ( version 1.0 ) contained eight suggested steps and a timeline for agencies to use as they began to develop their data act implementation plans .

steps 1 through 4 were to be completed by september 2015 .

however , as of october 2016 , only 16 of the 24 cfo act agencies reported that they had completed all steps 1 through 4 .

for example , there were four agencies reporting that they had not completed their inventory of data and identified the gaps in systems and processes for data elements ( step 3 ) .

data act implementation playbook ( version 1.0 ) indicated that agencies would be working on steps 5 through 8 throughout fiscal years 2016 and 2017 .

playbook 2.0 — issued june 24 , 2016 — includes , among other things , expanded guidance on actions to be included in steps 5 through 8 .

playbook 2.0 did not include expected timeframes for agencies to complete each step , rather , it referred agencies to treasury's implementation roadmap , which includes high level milestones for treasury's technical deliverables .

playbook 2.0 states that agencies can use the milestones in treasury's implementation roadmap to help determine their own implementation milestones .

descriptions of steps 5 through 8 from playbook 2.0 follow: step 5: prepare data for submission to the broker .

this step involves reviewing the schema version 1.0 , extracting data from source systems , mapping agency data to the schema version 1.0 , and implementing system changes as needed to collect and link data .

step 6: test broker outputs and ensure data are valid .

agencies may use the broker to verify the data files the agency plans to submit to treasury .

the broker uses validation rules to test the completeness and accuracy of the data elements and linkages between financial and award data .

the broker also tests whether the data passes basic validations within the schema version 1.0 .

step 7: update data .

this step involves updating information and systems .

if data does not pass validation ( see step 6 ) , the broker will provide error details to the agency .

the agency should then reference the authoritative data sources and address the discrepancies .

step 8: submit data .

once the data is linked , validated , and standardized , agencies are to submit the data to treasury for posting on usaspending.gov or a successor system .

agency senior accountable officials ( sao ) are to provide reasonable assurance that their internal controls support the reliability and validity of the agency account - level and award - level data they submit to treasury .

this assurance is to be provided quarterly with data submissions beginning with fiscal year 2017 second quarter data .

the sao assurance means , at a minimum , that data reported are based on appropriate internal controls and risk management strategies identified in omb circular a - 123 .

table 3 shows the information that omb required cfo act agencies to include in their implementation plan updates , information on remaining actions the agencies should take to implement suggested steps 5 through 8 in playbook 2.0 , and the number of cfo act agencies that included the information .

table 4 describes the categories of challenges reported by 19 of the 24 cfo act agencies in their implementation plan updates and the number of agencies reporting challenges in each category .

five cfo act agencies did not identify any challenges in their implementation plan updates .

table 5 describes the mitigating strategies reported by 16 of the 24 cfo act agencies in their implementation plan updates and the number of agencies reporting mitigating strategies in each category .

in addition to the above contacts , peter del toro ( assistant director ) , michael laforge ( assistant director ) , kathleen drennan ( analyst - in - charge ) , diane morris ( analyst - in - charge ) , michelle sager , shirley hwang , aaron colsher , katherine morris , sophia tan , thomas hackney , charles jones , laura pacheco , maria belaval , carrol warfield , jr. , mark canter , james sweetman , jr. , andrew j. stephens , carl ramirez and jenny chanley made major contributions to this report .

additional members of gao's data act internal working group also contributed to the development of this report .

