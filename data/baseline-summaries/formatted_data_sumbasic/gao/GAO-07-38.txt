recognizing the potential of small businesses to be a source of significant innovation , the congress established the small business innovation research ( sbir ) program in 1982 .

from fiscal year 1983 through fiscal year 2004 , federal agencies that participated in the sbir program awarded over $17 billion in grants , contracts , or cooperative agreements to over 82,000 projects .

the primary goals of the sbir program are to stimulate technological innovation , meet federal research and development ( r&d ) needs , foster participation by minority and disadvantaged persons in technological innovation , and increase the commercial success ( commercialization ) of innovation that is derived from federally funded r&d .

because the congress did not define what constitutes commercial success of federally funded r&d or how best to measure it , agencies have used different commercialization outcomes for the sbir program , such as the sale of the resulting sbir - funded product or process , the extent to which sbir firms have received non - sbir funding , or the creation of new jobs or products .

the sbir program is currently scheduled to expire on september 30 , 2008 .

every federal agency with an r&d budget of $100 million or more is required to establish and operate an sbir program funded by 2.5 percent of the agency's budget for research conducted by others , called extramural research .

currently , 11 federal agencies participate in the sbir program .

each agency manages its own program , including targeting research areas , reviewing proposed projects , and making research awards through grants , contracts , or cooperative agreements .

the small business administration ( sba ) plays a central administrative role by , for example , issuing policy directives to the participating federal agencies , collecting data from participating agencies on awards and recipients , and reporting program results annually to the congress .

over the last 24 years , the sbir program has been reauthorized and modified by the congress at various times .

for example , the small business research and development enhancement act of 1992 directed sba and participating agencies to , among other things , emphasize the goal of increasing commercialization of research results and to improve the government's dissemination of program - related data .

as a result , agencies were required to include commercialization potential as a criterion for selecting award recipients .

during this same period , sba began to develop a publicly available database , known as tech - net , that contained information on all awards made through the sbir program .

the tech - net database is intended to be , among other things , an electronic gateway of technology information and resources for researchers , scientists , and government officials about federally - funded leading edge technology research .

the small business innovation research program reauthorization act of 2000 formalized this database by requiring sba to develop , maintain , and make available to the public a searchable , up - to - date , electronic database that contained sbir award information .

the 2000 reauthorization act also required sba to develop and maintain another restricted government database that would contain additional information on commercialization not contained in the public tech - net database , thereby allowing better evaluations of the sbir program on an ongoing basis .

this database was to be established by mid - 2001 and made available only to government agencies and certain other authorized users .

as the program has evolved over time , congressional direction has focused , among other things , on the ability of sbir award recipients to commercialize the results of their research , as evidenced by the increased emphasis on commercialization in the 1992 and 2000 reauthorizations of the program .

at various points in the life of the program , we have reported that the sbir program has been successful in increasing commercialization of research results and that agencies have used various methods to measure the commercial success of the projects they fund .

largely these methods have consisted of surveys of award recipients to obtain data on indicators of commercial success and soliciting “success stories” voluntarily provided by sbir award recipients .

however , we also reported that these methods provided only “snapshots” of commercial success and did not allow for a systematic demonstration of changes in program commercialization rates over time .

we reported that the lack of clarity on how much emphasis agencies should place on commercialization versus other sbir program goals had also created challenges for assessing the program's results .

in the context of efforts to monitor and evaluate the success of the sbir program , you requested that we identify the ( 1 ) types of data that participating sbir agencies are reporting to sba for inclusion in the tech - net database ; ( 2 ) extent to which agencies provide data for the tech - net database in a standard format to enable program evaluation ; ( 3 ) extent to which sba has met the mandate to establish , by mid - 2001 , a government - use database that can be used for program evaluation ; and ( 4 ) extent to which participating sbir agencies have developed and implemented techniques to track the commercialization success of sbir projects .

in conducting this study , we reviewed the sbir - related activities at 8 of the 11 sbir participating agencies , which account for over 98 percent of the total dollars awarded by the program in fiscal year 2005 .

to determine the types of data these participating agencies are reporting to sba and the extent to which sba has complied with the requirement to establish a government - use database that can be used for program evaluation purposes , we compared the provisions in the small business innovation research program reauthorization act of 2000 , sba's amended policy directive implementing the act issued in september 2002 , and other guidance with agency sbir tech - net database reports .

to determine the extent to which data for the tech - net database are provided in a standard format to enable program evaluation , we compared the data from participating agencies with data in sba's tech - net database for fiscal years 2004 and 2005 , the 2 most recent years for which data were available .

our data reliability review focused on sba's data system and internal controls , rather than on the systems and internal controls agencies use to create the data provided to sba .

to assess the reliability of the data in sba's tech - net database , we interviewed sba officials about the database and reviewed related documentation .

we determined that the data are sufficiently reliable for our purpose , which is to report on sba's efforts to ensure consistency and completeness of the data it receives .

we used gao's data reliability guidance to identify key attributes of data quality that can facilitate program evaluation .

we also interviewed sba and agency officials to determine the extent to which the government - use database requirements have been implemented .

to determine the extent to which participating agencies and sba have developed and implemented techniques to evaluate commercialization success of sbir projects , we reviewed agency documentation and interviewed sba and agency officials .

appendix i contains a detailed discussion of the scope and methodology of our review .

we conducted our review from april 2006 through september 2006 in accordance with generally accepted government auditing standards .

the small business innovation development act of 1982 established the sbir program and identified four program goals: technological innovation , commercialization of the research results , the use of small businesses to meet agencies' r&d needs , and participation in federal r&d by minorities and disadvantaged persons .

the legislation provided for a competitive three - phased program: phase i to determine the technical and scientific merit and feasibility of a proposed research idea ; phase ii to further develop the idea , taking into account its commercial potential ; and phase iii to commercialize the resulting product or process with private or federal investment but no additional sbir funding .

under the sbir program provisions , federal agencies that have external r&d budgets of $100 million or more are required to use 2.5 percent of these budgets to establish and operate an sbir program .

sba oversees and coordinates the efforts of the eleven agencies currently participating in the program .

in this capacity , sba coordinates the participating agencies' schedules to announce opportunities for firms to apply for awards , called a solicitation , and provides access to these solicitations through its web site .

as part of its oversight effort , sba collects sbir data from the participating agencies , aggregates the data , and uses the data to , among other things , monitor the program and report annually to the congress .

in reauthorizing the sbir program in 1992 , the congress stated its intention to expand and improve the program by emphasizing its goal of increasing private sector commercialization , increasing participation in federal r&d by small businesses , and improving the government's dissemination of program - related information .

one of the new provisions under the 1992 legislation requires agencies , when evaluating phase ii proposals , to consider their commercial potential , including the recipients' experiences commercializing the results from previous sbir awards , commitments accompanying the proposals for developmental funding from sources other than the sbir program , and other factors .

the sbir program was again reauthorized in 2000 by the small business innovation research program reauthorization act of 2000 .

the 2000 legislation directed sba and participating agencies to , among other things , expand the scope of publicly available information on specific awards and to annually report data on their sbir programs to sba .

the act required that sbir phase ii award recipients be requested to voluntarily provide information to the agencies describing the outputs and outcomes of their sbir award .

the act also required sba to establish , by mid - 2001 , a searchable and up - to - date electronic database available for public use , and a restricted government - use database .

to accomplish this mandate , sba envisioned expanding the electronic database , known as tech - net , that it had developed in the late 1990s , into two sections: a public - use section and a restricted government - use section .

the public - use section of the tech - net database would provide access to nearly all of the statutorily - required award information for sbir awards gathered by the agencies .

the public - use section was intended to be an electronic gateway of technology information and resources for researchers , scientists , and government officials who are seeking information on potential small business partners , contractors , or leading edge technology research .

the government - use section would be solely used for program evaluation purposes accessible only to government agencies and other authorized users , and would contain commercialization data voluntarily supplied by sbir recipients upon completion of their phase ii sbir funding agreement , such as revenue from the sale of new products or services resulting from the research undertaken with the award .

in addition , applicants for phase ii awards would be required to update information on the commercialization success of any prior sbir awards they had received .

currently , sba has created and is maintaining the public - use section of the tech - net database , which is available on the internet to the general public .

while federal agencies participating in the sbir program submit a wide range of descriptive award information to sba annually , these agencies are not consistently providing all of the required information .

as outlined in sba's guidance , each year sbir participating agencies are required to collect and maintain information from recipients and provide it to sba so that it can be included in the tech - net database .

specifically , participating agencies are required to provide over 40 data elements for each sbir award they make .

these data include award - specific information , such as the date and amount of the award , an abstract of the project funded by the award , and a unique tracking number for each award .

participating agencies are also required to provide data about the award recipient , such as gender and socio - economic status , and information about the type of firms that received the awards , such as number of employees and geographic location .

much of the data collected by participating agencies are provided by the sbir applicants at the time they apply for an award .

agencies provide additional information , such as the grant / contract number and the dollar amount of the award , after the award is made .

for the most part , all of the eight agencies we reviewed provided the majority of the sbir award data requested by sba , including the program identification number ; company name , address , and contact information ; award year and amount ; a unique tracking number that will stay with the award through both phase i and phase ii ; and the title and abstract of the project funded .

however , we also determined that some of the agencies are not providing the full range of information required by sba .

for example , two of the eight agencies we reviewed had not provided sba data on the gender or socio - economic status of sbir award recipients in 2004 and 2005 .

similarly , in 2005 , five of the eight agencies failed to provide data on the number of employees working at the firms that received the awards .

as a result , sba does not have information on the number of employees at sbir awardee firms for about one - third of all the awards reported by these agencies in 2004 and 2005 .

sba officials acknowledged that agencies do not routinely provide all of the information requested because either they do not capture the information in their agency databases or they are not requesting the information from sbir applicants .

officials at the participating agencies also cited other reasons for the incomplete data they provided to sba .

for example , nih officials stated that for the past several years , the sba tech - net annual reporting requirements have changed each year .

at the end of calendar year 2003 , sba changed the field description from “minority” to “socially and economically disadvantaged small business.” according to nih officials , because the sbir information is captured by the agency at the time the application is submitted / received , there is a lag in time between when application data is input into the nih database and when the agency receives new sba data field requirements .

according to these officials , responding to sba's changes in field names presents significant challenges to nih for collecting the data needed to complete the tech - net reports , especially if the requirements change annually .

as a result , these officials stated that complying with the changing requirements necessitates significant nih resources and efforts to research and identify the information needed for the new data fields , not all of which can be provided .

in commenting on a draft of this report , sba stated that it has only requested minor clarifications of data requirements and has not made frequent changes as stated by the agencies .

sba believes that this may have been caused by lack of clear communication to the agencies .

the agencies also noted that data for certain tech - net fields will be absent from their reports to sba if the data fields do not exist in the nih application or in its awards database .

similarly , usda officials stated that although they try to keep their records as up - to - date as possible , problems occur when company or contact information changes and the sbir recipient fails to provide updated information to the agency , such as the e - mail address for the central contact person .

additionally , like nih , usda officials stated that certain information requested by sba is not collected by their agency .

for example , as long as sbir applicants have certified that they meet the criterion of being a small business ( under 500 employees ) , they do not ask for nor do they record information on the number of employees in the firm .

participating agencies are providing some data that do not comply with sba's formatting guidance , and while some of these inconsistencies are corrected by sba's quality assurance processes , others are not .

as a result , some data elements in the tech - net database may be inconsistent or inaccurate thereby , compromising the value of these data for program evaluation .

sba's quality assurance efforts focus on obtaining complete and accurate data for those fields essential to tracking specific awards , such as the tracking number and award amount , rather than on those fields that contain demographic information about the award recipient .

because the data contained in the public - use section of tech - net will be incorporated into the government - use section of the database , inaccurate data in one section of the database will be replicated in the other , and these inaccurate data will limit evaluations of the sbir program .

both sba and agency officials acknowledge that sba has worked with participating agencies since 2000 to help ensure greater consistency in the formatting of the sbir award data reported by agencies each year .

to assist agencies in formatting the data and to minimize the number of inconsistencies in the data reported to sba , sba has taken a number of steps to improve the data formatting process .

specifically , sba provided all of the participating agencies specific guidance on its requirements for the data , including its preferred program application for submitting the data , the length of each data field , and whether data should be entered as numbers , characters , or a mix of both .

sba has also included discussions of the tech - net database as an agenda item at its quarterly meetings with sbir program managers from each of the participating agencies .

additionally , sba developed a reporting template for agencies to use that includes the required data fields and instructions for appropriate data entry .

under the current process , participating agencies aggregate all of the data provided by sbir recipients in their award applications with additional information on the award amounts and submit the combined data to sba by march 15 of each year .

sba then electronically checks the data to locate and reformat inconsistencies , and adds the data to the tech - net database .

sba officials told us that when they detect inconsistencies in data fields essential to tracking a specific award , such as the award tracking number , contact information for the recipient or principal investigator , or awarding agency , they contact the agency to obtain the correct information .

however , sba does not currently take steps to ensure that agency - provided data are accurate and complete .

for example , sba does not require agencies to submit a random sample of applications so that it can compare the data submitted by agencies with the original applicant information to ensure that the submitted data contain all the relevant application information .

instead , sba relies on the agencies to fully report all the required application information on the awards they make .

sba officials told us that they believe that over the past two years the quality and consistency of the data received from participating agencies had greatly improved .

in reviewing the sbir tech - net data that the eight agencies reported to sba in 2004 and 2005 , we determined that almost a quarter of the data provided by five agencies was incorrectly formatted for one or more fields .

for example , phone number and award amount fields contained both characters and numbers and first and last names of principal investigators were combined into a single word that was used as both the first and last names .

moreover , we found that agency - provided data on gender and socio - economic status for over half of the awards reported in 2004 were incorrectly formatted .

sba officials said that detecting and correcting some of these formatting errors required a considerable amount of time and effort , and that their electronic check does not detect all of the errors that we identified .

the formatting inconsistencies that we identified arise primarily because the sba reporting template used by agencies to submit required data can be edited .

consequently , agencies can and do edit the template .

agencies can change the names of various data fields in sba's template , delete fields altogether , and enter data as numbers , characters , or both , regardless of what sba has specified .

one of the data format issues identified by sba was the deletion of fields that agencies do not consider relevant or necessary .

for example , dod is the only agency that uses the field called “branches” to specify which component of dod , such as the army , made the award ; other agencies have deleted this field because it does not relate to the structure of their agency .

similarly , we found instances where agencies had entered data on the gender or socio - economic status of the recipient and award amount in a format that differed from the numerical format specified by sba .

for example , one agency entered “y” and “n” rather than “0” and “1.” according to sba officials , by fiscal year 2007 , this issue should be resolved because agencies will have to submit their data through an internet interface that will contain edit checks and should eliminate many of these problems .

we also determined that inconsistencies or inaccuracies can arise in certain data fields because sba interprets the absence of certain data elements as a negative entry without confirming the accuracy of such an interpretation with the agency .

in other words , if an agency did not provide information on whether the recipient is a woman or a member of a socio - economically disadvantaged group , sba has entered a “no” into the database .

sba stated that they generally do not contact agencies to obtain correct information on data elements that are not used to track specific awards , such as gender or socio - economic status of the recipient .

however , this inaccurate data on the award recipients could limit efforts to use these fields for comprehensive program evaluation .

information in the tech - net database will be used to populate the government - use section of the database that sba is developing ( as discussed below ) for the purpose of supporting sbir program evaluations .

however , sba has no plans to correct any of the errors or inconsistencies in the database that relate to the historical data already collected .

as a result , the errors in the existing database will migrate to the government - use section of the database and we believe will compromise the usefulness of the government - use database for program evaluation purposes .

sba has not met its obligation to implement a restricted government - use database that would allow sbir program evaluation as directed by the 2000 sbir reauthorization act .

as outlined in the legislation , sba , in consultation with federal agencies participating in the sbir program , was to develop a secure database by june 2001 and maintain it for program evaluation purposes by the federal government .

sba planned to meet this requirement by expanding the existing tech - net database to include a restricted government - use section that would be accessible only to government agencies and other authorized users .

in constructing the government - use section of the database , sba planned to supplement existing data already gathered for the public - use section of the tech - net database with information from sbir recipients and from participating agencies on commercialization outcomes for phase ii sbir awards .

however , according to sba officials , the agency has been unable to meet this requirement , primarily because of increased security and other information technology project requirements , agency management changes , and budgetary constraints .

sba's current goal for having the government - use section of the tech - net database operational is october 1 , 2006 .

in commenting on a draft of this report , sba modified this date , stating that they anticipate having the government - use section of the tech - net database operational early in fiscal year 2007 .

to date , with the help of two contractors , sba has developed the framework for importing data into the government - use section of the tech - net database and for an internet - based interface that would allow agencies and award recipients to access the database and enter commercialization information .

according to sba officials , as currently envisioned , the government - use section of the tech - net database will include the records of all applicants , including those that did not receive sbir awards .

participating sbir agencies will be asked to provide a unique business identification number , called the data universal numbering system or duns number , for each award recipient , information about sbir applicants that were not funded , and any historical data they have obtained about the commercialization of sbir funded technologies .

sba has developed a standardized electronic commercialization questionnaire to gather data for the government - use section of the database from applicants and award recipients .

information that will be captured in the questionnaire will include the number of sbir awards the company has received , the number of patents or copyrights that have resulted from the award , sales revenue realized as a result of the sbir award , and sources of additional investment funding .

sba officials told us that the commercialization questionnaire will become an integral part of the sbir application process in the future , and any company applying for an sbir award will be required to complete and update the relevant information on phase ii sbir awards previously received by the company at the time the application is submitted .

according to sba officials , applications will not be accepted until this information is completed , and failure to submit the information may affect an applicant's ability to receive an award .

in addition , sbir award recipients will be requested to voluntarily update the commercialization information in the government - use section of the tech - net database annually for a minimum period of five years following the completion of their sbir - funded project .

although sba has developed the majority of the functions needed to populate the government - use section of the tech - net database with the data currently gathered for the public - use section of the database , it can not be made operational until certain security issues are resolved .

for example , because the government - use section of the database will contain information from recipients that is considered proprietary and confidential , sba needs to ensure that adequate security measures are in place to prevent unauthorized access to the data .

this entails the successful completion of a series of security and development checks to ensure that the database system is operating as designed .

while sba officials expect the government - use section of the database to be operational by october 1 , 2006 , they also recognize that additional enhancements , such as improving the user - friendliness of the interface for online submission of sbir data by participating agencies and recipients , will be needed after the system is made operational .

according to sba officials , the agency's priority is to get the government - use section of the database up and running before considering further improvements to the database .

seven of the eight participating agencies we reviewed have implemented techniques to track the commercialization success of their sbir - funded projects , and the eighth is planning to do so , although the methodological rigor of these techniques varies significantly .

under the program's authorizing legislation and sba's implementation guidance , agencies have been given considerable flexibility to design , monitor , and evaluate the extent to which their sbir programs have achieved commercialization success .

for example , while some agencies use more systematic approaches to gathering data , such as periodically surveying sbir award recipients , other agencies are less methodical , choosing instead to follow up periodically with a relatively small sample of sbir award recipients .

regardless of how they track commercialization success , both sba and agency officials generally agree that several factors complicate their efforts to obtain this information .

of the eight agencies we reviewed , five systematically and periodically survey sbir recipients to gather a variety of data on program participation , including the recipients' commercialization experiences .

specifically , since 2000 , dod has systematically gathered information electronically on the commercialization of phase ii awards from all phase i and phase ii applicants and award recipients and maintains the information in a commercialization database .

commercialization outcomes that dod monitors include such measures as ( 1 ) sales revenue from new products and non - r&d services resulting from the phase ii technology ; ( 2 ) additional investment from sources other than the federal sbir program in activities that further the development , commercialization , or both of the phase ii technology ; ( 3 ) whether the phase ii technology has been used in a dod system or acquisition program , and if so , which system or program ; ( 4 ) the number of patents resulting from the contractor's participation in the sbir program ; ( 5 ) growth in the number of employees at the firm ; and ( 6 ) whether the firm has completed an initial public offering of stock resulting , in part , from the phase ii project .

dod uses the accumulated data to assign a commercialization score to applicants that have received four or more prior sbir awards based on a comparison of their commercialization experience with the average experience of other comparable applicants and uses the score to help select proposed projects for funding .

in addition , recipients of phase ii awards are required to update the information one year after the start of the project , at the completion of the project , and subsequently when the recipient submits a new sbir application to dod .

firms that do not submit a new sbir application are asked to voluntarily provide updates on an annual basis after the completion of their phase ii project .

according to dod officials , 66 percent of phase ii award recipients updated their commercialization information when they submitted a new application , 11 percent provided the information without submitting a new application , and 23 percent did not update their information .

for over 23 years , doe has conducted an annual survey of sbir phase ii recipients , both active and inactive , to track the commercialization success of its sbir - funded projects .

the survey requests recipients to ( 1 ) list all products and services derived from their sbir projects ; ( 2 ) report on sales , phase iii investment related to these products and service , or both ; and ( 3 ) identify which phase ii projects contributed to the development of the products and services .

according to doe , approximately 90 percent of its phase ii recipients respond to these annual surveys .

nasa has systematically gathered information on the commercialization of sbir awards through annual surveys of phase ii award recipients from 1997 to 2002 .

in these surveys , nasa obtained data on various commercial outcomes , such as sales to nongovernment markets of the sbir - funded research results , procurement of the research results by nasa or other federal agencies , cumulative private capital funding , royalty and licensing revenue from nongovernment sources based on the sbir - funded research results , creation of new business ventures based on the sbir - funded research results , and number of patents and patent applications resulting from these awards .

according to nasa , approximately 91 percent of its phase ii award recipients responded to these annual surveys .

nih also surveys sbir award recipients to gather commercialization information .

specifically , in 2002 , nih conducted a comprehensive evaluation of its sbir program .

as part of this evaluation , nih surveyed recipients of phase ii awards between 1992 and 2001 to obtain data relating to the range of sbir program goals , including commercialization of research results .

according to nih officials , the 2002 survey results formed a baseline that nih staff could use to systematically monitor and evaluate the program .

in 2004 and 2005 , nih again contacted award recipients to update the information obtained in the 2002 survey .

commercialization outcomes tracked by nih include ( 1 ) sales realized for a product or service that resulted from the sbir - funded research ; ( 2 ) status of the food and drug administration ( fda ) approval process for the sbir - funded research results ; ( 3 ) receipt of fda approval for sbir - funded research results ; and ( 4 ) receipt of additional non - sbir funding or capital .

since about 1998 , nsf has collected historical commercialization information from all phase ii award recipients at the time an sbir application is submitted .

this information is used in the proposal review process to help select proposed projects for funding .

in 2005 , nsf developed an annual survey of phase ii award recipients that will be used to gather information three , five , and eight years following their awards .

specific outcomes on which nsf will gather data include sales revenue based on the sbir - funded research results , growth of overall company sales and employment , receipt of additional non - sbir funding , and patents related to the sbir funded research .

in contrast , two of the remaining three agencies we reviewed have focused their efforts on gathering anecdotal success stories and conducting periodic follow - up with a relatively smaller sample of sbir award recipients .

for example , over the past 7 years , epa has contacted all phase ii award recipients after their projects end to learn about their commercial successes .

based on these contacts , officials estimate that approximately 25 percent of the phase ii projects funded by epa have been commercialized .

epa defines “success” as the receipt of more than $300,000 in revenue from sales of the sbir - funded project , an amount greater than the sbir funds awarded by epa .

similarly , usda has periodically contacted a sample of about 20 to 25 percent of award recipients to obtain information about sales of their sbir - funded research results .

usda last surveyed its phase ii award recipients in 1997 .

usda publishes the success stories on its web site and in an agency newsletter .

about 2,500 people receive the newsletter and usda makes copies of the success stories available at sbir conferences .

according to usda officials , in the future they hope to gather data more systematically and conduct site visits to the sbir firms .

the eighth agency we reviewed , nist , has recently developed a web - based survey that it plans to send in 2006 to all of its sbir - award recipients .

although each of the eight agencies we reviewed has implemented or plans to implement a method for gathering commercialization data , agency officials identified several factors that complicate their efforts .

first , agency officials stated that it is difficult to track commercialization because it can take years before companies achieve commercial success .

for example , usda officials stated that , even over the short term , the effort to contact past award recipients consumes considerable effort .

during this time , companies may move , change names , start a new business , or be purchased by other firms , all of which make it difficult for the agencies to track and link companies to the original sbir awards .

second , because the authorizing legislation lacks a clear definition of what constitutes “commercialization” success , agencies not only differed on the types of commercialization outcomes they captured , but also in how they tracked commercial success .

sba officials acknowledged that its guidance has provided considerable latitude to agencies on this issue in light of the wide range of industries represented by the participating agencies .

commercialization outcomes captured by the participating agencies included sales revenue based on the sbir - funded research results , receipt of additional non - sbir funding to further develop the research results , marketing activities ongoing or completed , and public offering of company stock .

however , not all agencies are tracking all of these outcomes ; therefore , assessing overall commercial success of the sbir program across the various agencies remains a challenge .

third , agency officials stated that sbir award recipients may be reluctant to provide information related to their trade and business operations , which they consider proprietary and sensitive .

companies are often not willing to provide comprehensive data on their sales and particularly the investments they receive due to competitive concerns .

finally , agency officials told us that past recipients have no incentive to voluntarily complete commercialization surveys and update the information on their commercial experience unless they are applying for a new sbir award .

as a result , they do not expect that a large percentage of recipients will complete the information needed for the government - use section of the tech - net database .

agency officials believe that despite their best efforts , the data needed to conduct evaluations of the sbir program are likely to be incomplete .

in the last 5 years , sba has been unable to meet the congressional directive to develop a government - use database that would provide better information on the sbir program and allow for program evaluation .

although it has established a public - use tech - net database and has worked with participating agencies to achieve greater consistency in the data submitted for the database , the quality of the data remains a concern .

the steps on which sba relies to ensure that data are complete and accurate are inadequate and it has no plans to correct errors or supply missing data associated with the historical data already in the database .

we believe that unless necessary controls are established and implemented to ensure the completeness , consistency , and accuracy of the sbir data reported to sba by participating agencies , the government - use section of the tech - net database , which depends on the public - use tech - net database , will be of limited use for program evaluation purposes when it becomes operational .

we recommend that the administrator , sba , and the sbir participating agencies work together to strengthen efforts to ensure that the data collected for sba's tech - net database are complete , consistent , and accurate .

we provided sba and the eight sbir participating agencies included in this review a draft of this report for their review and comment .

sba and the eight agencies generally agreed with the report's findings and sba and five of the eight agencies also stated their concurrence with the recommendation .

three agencies — epa , nist , and nsf — did not indicate whether they agreed or disagreed with the recommendation .

in addition , sba stated that it was concerned that our conclusions did not reflect the fact that it plans to have the government - use section of the tech - net database operational by early fiscal year 2007 .

we have not modified our conclusions because the fact remains that sba has not met the congressional directive to establish a government - use database during the last five years .

moreover , throughout this review , sba officials told us that the database would be operational by october 1 , 2006 .

however , in its official comments , the agency has again modified this date to some time early in fiscal year 2007 .

sba also provided us with technical comments that we have incorporated as appropriate .

sba's letter is included in appendix ii and the letters that we received from dod , nasa , and nih are included in appendix iii through v. as agreed with your office , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies of this report to interested congressional committees ; the administrators of the environmental protection agency , national aeronautics and space administration , and small business administration ; the directors of the national institutes of health , national institute of standards and technology , and national science foundation ; the secretaries of agriculture , defense , and energy ; and other interested parties .

we will also make copies available to others upon request .

in addition , the report will be available at no charge on the gao web site at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-3841 or mittala@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made contributions to this report are listed in appendix vi .

our objectives for this review were to identify ( 1 ) the types of data that participating small business innovation research ( sbir ) program agencies are reporting to the small business administration ( sba ) for inclusion in the tech - net database , ( 2 ) the extent to which agencies provide data for the tech - net database in a standard format to enable program evaluation , ( 3 ) the extent to which sba has met the mandate to establish by early 2001 a government - use database that can be used for program evaluation , and ( 4 ) the extent to which participating sbir agencies have developed and implemented techniques to track the commercialization success of sbir projects .

in conducting this study , we reviewed sba and the sbir - related activities of 8 of the 11 sbir participating agencies — department of defense ( dod ) , department of energy ( doe ) , environmental protection agency ( epa ) , national aeronautics and space administration ( nasa ) , national institutes of health ( nih ) , national institute of standards and technology ( nist ) , national science foundation ( nsf ) , and department of agriculture ( usda ) .

these eight agencies account for over 98 percent of the total dollars awarded by the program in fiscal year 2005 .

to determine the types of data these participating agencies are reporting to sba and the extent to which sba has complied with the requirement to establish a government - use database that can be used for program evaluation purposes , we compared the provisions in the small business innovation research program reauthorization act of 2000 , relevant legislative histories , sba's policy directive implementing the act issued in september 2002 , and other guidance with agency sbir tech - net database reports .

we identified and interviewed sbir program officials at each agency and officials responsible for submitting program data to sba .

for these interviews , we used a protocol guide to obtain information on program operations , data reporting , data quality , and the tech - net database , including development of the government - use section of the database .

we also reviewed documentation from each of the eight agencies and sba regarding data elements and formatting instructions .

to determine the extent to which data for the tech - net database are provided in a standard format , enabling program evaluation , we compared data provided to sba by the eight participating agencies with data in sba's tech - net database for fiscal years 2004 and 2005 , the 2 most recent years for which data were available .

the agency data included information about the award itself , such as the award amount , a descriptive abstract of the project , and a unique tracking number ; information about the award recipient , such as gender and socio - economic status ; and information about the type of firm that received the award , such as number of employees and geographic location .

to assess the reliability of the data provided by the agencies , we reviewed sba's data system , internal controls , and related guidance , rather than the systems and internal controls participating agencies use to create the data provided to sba .

to assess the reliability of the data in sba's tech - net database , we interviewed sba officials about the database and reviewed related documentation .

we also conducted tests of the data themselves .

we used analytic software to compare the data provided by participating agencies with the data maintained by sba .

we focused our review on data fields considered critical by sba officials , such as the awarding agency , the date of award , the award recipient , the amount of the award , and the purpose of the award .

we also reviewed data fields related to sbir program goals , such as gender and socio - economic status of the recipient , and data on the number of employees at the recipient firm .

we used gao's data reliability guidance to identify key attributes of data quality that facilitate program evaluation .

these attributes include completeness , accuracy , and consistency in format .

finally , we reviewed internal quality control procedures .

we determined that the data are sufficiently reliable for our purpose , which is to report on sba's efforts to ensure consistency and completeness of the data it receives .

to determine the extent to which the government - use database requirements have been implemented , we interviewed sba officials , and reviewed related documentation , such as minutes from meetings of sba and sbir program directors , and overviews of the existing and planned data systems .

in addition , we attended a demonstration of the proposed internet interface for the government - use section and interviewed the current contractor assisting sba about implementation progress .

we also reviewed a contractor - prepared analysis of the functional and data requirements for the integration of the public - and government - use sections of the tech - net database .

at each of the eight participating agencies , we interviewed sbir officials regarding the extent to which sba had consulted them in the development of the government - use database .

to determine the extent to which participating agencies have developed and implemented techniques to evaluate commercialization success of sbir projects , we reviewed agencies' documentation about their commercialization assistance and monitoring efforts .

specifically , we reviewed surveys that agencies had administered to award recipients , resulting reports on survey results , and anecdotal descriptions of commercialization success .

we also reviewed provisions in sbir legislation , relevant legislative histories , and sba's policy directive regarding commercialization of sbir - funded projects , as well as past gao reports .

in addition , we interviewed officials at each of the eight participating agencies to obtain information on the specific commercialization outcomes they monitor , the history of each agency's data collection efforts , and the agencies' experience in obtaining such information from current and past award recipients .

we conducted our work from april 2006 through september 2006 in accordance with generally accepted government auditing standards .

the following are gao's comments on the small business administration's ( sba ) letter dated october 6 , 2006 .

1 .

we revised footnote 2 to more clearly reflect the 11 sbir participating agencies .

2 .

we revised the text to clarify this statement .

3 .

we deleted reference to sba in footnote 7 .

4 .

we added sba's position to the report .

5 .

we added sba's position to the report .

however , because sba has not met the congressional deadline to develop a government - use database , we did not modify our conclusions .

in addition to the contact named above , cheryl williams , assistant director ; bernice h. dawson ; vondalee r. hunt ; and marcus l. oliver made key contributions to this report .

also contributing to this report were nancy crothers , grant mallie , gregory marchand , and rebecca shea .

