the department of defense ( dod ) is spending more than $18 billion annually to develop , acquire , and operate satellites and other space - related systems .

moreover , dod is on the threshold of investing in several new major satellite acquisition programs .

these programs are intended to help transform how information is collected on capabilities and intentions of potential adversaries as well as how military forces communicate and navigate and attack targets .

we reported to you in june 2003 that the majority of satellite programs we have reviewed over the past 2 decades experienced problems during acquisition that significantly increased costs and delayed schedules , often to the point where programs needed to be restructured by dod .

dod has recently implemented a new acquisition management policy for space systems , which sets the stage for making decisions on individual space programs .

as you requested , we assessed the new policy — specifically whether it will enable dod to match requirements ( that is , what the system needs to do and how well it needs to perform ) to resources ( time , money , and technical knowledge ) at the onset of product development .

our work shows that achieving this match is the most critical determinant for successful outcomes of acquisitions .

dod's current space network is comprised of constellations of satellites , ground - based systems , and associated terminals and receivers .

among other things , these assets are used to perform intelligence , surveillance , and reconnaissance functions ; perform missile warning ; provide communication services to dod and other government users ; provide weather and environmental data ; and provide positioning and precise timing data to u.s. forces as well as national security , civil , and commercial users .

dod is now implementing a new acquisition management policy tailored to its space systems .

it expects to finalize the policy this fiscal year .

the policy is similar to the one used by the national reconnaissance office ( nro ) .

the policy is different from a new acquisition management policy dod is implementing for most other weapons - related acquisitions in several respects .

key decisions , including the decision to start product development and to start building and testing a satellite , will be made earlier in the development process .

according to dod , this is because satellites incur most of their costs during the early phases of development .

the decision to build and produce a satellite will be made at the same time instead of sequentially .

according to dod , this is because satellites are produced in very small numbers as compared to other acquisitions .

figure 1 provides an overview of differences in key decision points .

the new space acquisition policy is also different than dod's policy for other weapon systems in terms of decision - making support .

for example , the new policy has created an advisory board distinct from the dod's defense acquisition board ( dab ) .

the defense space acquisition board ( dsab ) , comprised of senior - level dod officials and mission partners , will advise the under secretary of the air force , as the milestone decision authority , on whether significant investments should move forward in the development process .

also , temporary independent program assessment teams ( ipa ) will be used to conduct an intensive review before key decisions are made .

under dod's process for other weapon systems , standing integrated product teams ( ipt ) are used to help programs conduct key analyses as well as to advise the dab .

table 1 provides more details on these differences .

dod is already applying this new process to major satellite programs , including the space - based infrared system ( high ) ( sbirs - high ) , the transformational communications satellite ( tsat ) , the advanced extremely high frequency ( aehf ) system , the mobile user objective system ( muos ) , the global positioning system ( gps ) , the national polar - orbiting operational environmental satellite system ( npoess ) , and the space - based radar ( sbr ) system .

 ( see app .

i for a further description of dod's current and planned systems. ) .

sbr is the first system to receive approval for the first key decision point — key decision point ( kdp ) a — which begins a study phase .

other systems will come in at a later decision point — kdp b , which starts the acquisition program , or kdp c , which starts the process of building , testing , and launching the satellite .

some space - related systems , such as user equipment , are produced in mass numbers .

they will be overseen under a process that is more similar to the dod - wide acquisition process .

the majority of satellite programs we have reviewed over the past 2 decades experienced problems during acquisition that drove up costs and schedules and increased technical risks .

several programs were restructured by dod in the face of delays and cost growth .

we have found that these problems , which are common among many weapon systems , are largely rooted in a failure to match the customer's needs with the developer's resources — technical knowledge , timing , and funding — when starting product development .

in other words , commitments were made to satellite launch dates and achieving certain capabilities without knowing whether technologies being pursued could really work as intended .

time and costs were consistently underestimated .

leading commercial firms expect that their program managers will deliver high quality products on time and within budgets .

doing otherwise could result in losing a customer in the short term and losing the company in the long term .

thus , these firms have adopted practices that put their individual program managers in a good position to succeed in meeting these expectations on individual products .

collectively , these practices ensure that a high level of knowledge exists about critical facets of the product at key junctures during its development and is used to deliver capability as promised .

while dod is different from the commercial world in terms of its need to push for cutting edge technology to maintain military superiority , its policies for major weapon systems recognize that maturing technology outside of product development allows needed stability in executing budgets and allows capability to be delivered to the warfighter sooner .

our reviews have shown that there are three critical junctures at which firms must have knowledge to make large investment decisions .

first , before product development is started , a match must be made between the customer's needs and the available resources — technical and engineering knowledge , time , and funding .

second , a product's design must demonstrate its ability to meet performance requirements and be stable about midway through development .

third , the developer must show that the product can be manufactured within cost , schedule , and quality targets and is demonstrated to be reliable before production begins .

the process is building block in nature as the attainment of each successive knowledge point builds on the proceeding one .

while the knowledge itself builds continuously without clear lines of demarcation , the attainment of knowledge points is sequential .

in other words , production maturity cannot be attained if the design is not mature , and design maturity cannot be attained if the key technologies are not mature .

in applying the knowledge - based approach , the most leveraged decision point of the three junctures is matching the customer's needs with the developer's resources .

this initial decision sets the stage for the eventual outcome — desirable or problematic .

the match is ultimately achieved in every development program , but in successful development programs , it occurs before product development .

in successful programs , negotiations and trade - offs occur before product development is started to ensure that a match exists between customer expectations and developer resources .

technologies that are not mature continue to be developed in the technology base ( for example , a research laboratory ) .

with achievable requirements and commitment of sufficient investment to complete the development , programs are better able to deliver products at cost and on schedule .

our past work has shown that space programs have not typically achieved a match between requirements and resources before starting product development .

product development was often started based on a rigid set of requirements that proved to be unachievable within a reasonable development time frame .

at times , even more requirements were added after the program began .

when problems arose , adding resources in terms of time and money became the primary option for solving problems , since customer expectations about the product's performance had already become hardened .

for example: after starting its aehf satellite program , dod substantially and frequently changed requirements .

in addition , after the failure of one of dod's legacy communications satellites , dod decided to accelerate its plans to build aehf satellites .

the contractors proposed , and dod accepted , a high risk schedule that turned out to be overly optimistic and highly compressed , leaving little room for error and depending on a chain of events taking place at certain times .

moreover , at the time dod decided to accelerate the program , it did not have funding needed to support the activities and manpower needed to design and build the satellites quicker .

the effects of dod's inability to match requirements to resources were significant .

cost estimates produced by the air force reflected an increase from $4.4 billion in january 1999 to $5.6 billion in june 2001 — a difference of 26 percent .

although considered necessary , many changes to requirements were substantial , leading to cost increases of hundreds of millions of dollars because they required major design modifications .

also , schedule delays occurred when some events did not occur on time , and additional delays occurred when the program faced funding gaps .

scheduling delays eventually culminated into a 2-year delay in the launch of the first satellite .

we also reported that there are still technical and production risks that need to be overcome in the aehf program , such as a less - than - mature satellite antenna system and complications associated with the production of the system's information security system .

the sbirs - high contract for engineering , manufacturing and development amounted to $2.4 billion .

in the fall of 2001 , dod identified cost growth of $2 billion or more , triggering a mandatory program review and recertification under 10 u.s.c .

section 2433 .

currently , sbirs - high is under contract for $4.4 billion .

we reported that when dod's sbirs - high satellite program began in 1994 , none of its critical technologies were mature .

moreover , according to a dod - chartered independent review team , the complexity , schedule , and resources required to develop sbirs - high , in hindsight , were misunderstood when the program began .

this led to an immature understanding of how requirements translated into detailed engineering solutions .

even though the program was restructured by dod , the independent review team noted that sbirs - high still faced significant risks .

dod has initiated several programs and spent several billion dollars over the past 2 decades to develop low - orbiting satellites that can track ballistic missiles throughout their flight .

however , it has not launched a single satellite to perform this capability .

we have reported that a primary problem affecting these programs was that dod and the air force did not relax rigid requirements to more closely match technical capabilities that were achievable .

program baselines were based on artificial time and / or money constraints .

over time , it became apparent that the lack of knowledge of program challenges had led to overly optimistic schedules and budgets that were funded at less than what was needed .

attempts to stay on schedule by approving critical milestones without meeting program criteria resulted in higher costs and more slips in technology development efforts .

for example , our 1997 and 2001 reviews of dod's $1.7 billion sbirs - low program showed that the program would enter into the product development phase with critical technologies that were immature and with optimistic deployment schedules .

some of these technologies were so critical that sbirs - low would not be able to perform its mission if they were not available when needed .

dod eventually restructured the sbirs - low program because of the cost and scheduling problems , and it put the equipment it had partially built into storage .

in view of the program's mismatch between expectations and what it could achieve , the congress directed dod to restructure the program ( now known as the space tracking and surveillance system or stss ) as a research and development effort .

we recently reported on crosscutting factors that make it more difficult for dod to achieve a match between resources and requirements for space acquisitions .

in particular , space programs often involve a diverse array of organizations with competing interests involved in overall satellite development — from the individual military services , to testing organizations , contractors , civilian agencies , and in some cases , even international partners and industry .

this creates challenges in making tough tradeoff decisions .

in addition , like other weapon programs , space acquisition programs have historically attempted to satisfy all requirements in a single step , regardless of the design challenge or the maturity of technologies to achieve the full capability .

this approach has made it more difficult to match requirements to available resources .

dod's new space acquisition oversight process may help increase insight into gaps between requirements and resources .

in particular , tools being adopted , such as technology readiness assessments , alternatives analyses , and independent cost estimates , may help provide more consistent and robust information on technologies , requirements , and costs .

however , the value of these tools depends largely on whether or not the knowledge is used to make decisions .

according to dod officials , similar tools are also being adopted by other weapon system programs .

first , dod is requiring that all space programs conduct technology maturity assessments before key oversight decisions to assess the maturity level of technology .

one tool used by many weapon systems is known as technology readiness levels ( trl ) .

the tool associates different trls with different levels of demonstrated performance , ranging from paper studies to proven performance on the intended product .

the value of using a tool based on demonstrated performance is that it can presage the likely consequences of incorporating a technology at a given level of maturity into a product development , enabling decision - makers to make informed choices .

the tool is even more valuable if it is commonly used .

our previous reviews have found the use of trls to be a best practice .

 ( app .

ii describes trl levels. ) .

second , dod is requiring space programs to more rigorously assess alternatives , consider how their systems will operate in the context of larger families of systems , and think through operational , technical , and system requirements before programs are started .

for example , programs will be required to develop an architecture that specifies the structure of system components , their relationships , and the principles and guidelines governing their design and evolution over time .

it is important for dod to increase attention to requirements earlier in the acquisition process and force dod to think through whether there are more cost - effective alternatives to pursue .

a recent dod study found that understanding of requirements often occurs too late to affordably change the system and , more specifically , that space programs do not always understand how systems fit in with other systems with which they need to interact and that often a lack of mutual understanding of requirements exists between the government and contractors .

the sbirs independent review team also found a need across space programs for more rigorous up front development of requirements .

in addition , in previous reviews , we found that space programs often do not examine potentially more cost - effective approaches .

in 2001 , for example , we reported that dod's sbirs - low program was not adequately analyzing alternatives to sbirs - low that could satisfy critical missile defense requirements , such as navy ship - based radar capability .

at the time , other studies supported the possibility that other types of sensors could be used to track missiles in the midcourse of their flight and to cue interceptors .

third , the new policy seeks to improve the accuracy of cost estimates by establishing an independent cost estimating process in partnership with dod's cost analysis improvement group ( caig ) and by adopting methodologies and tools used by the nro .

to ensure timely cost analyses , the caig will augment its own staff with cost estimating personnel drawn from across the entire national security space cost estimating community , including cost estimating teams belonging to the intelligence communities , the air force , nro , the army , and the navy .

the policy also calls on programs to produce performance metrics that compare estimated to actual costs .

the policy allows programs to request assistance from the caig for purposes other than dsab reviews .

however , there is no point in the process that requires dod to commit to fully fund a space program .

improving reliability of cost estimates is critical .

several of our studies — such as ones on gps , evolved expendable launch vehicle ( eelv ) , and aehf — have called attention to problems with estimating system costs , such as errors , omissions , and conflicting assumptions .

for example , in 1980 we reported that the cost to acquire and maintain gps satellites through 2000 increased from $1.7 billion to $8.6 billion due largely to estimates not previously included for replenishment of satellites , launches , and user equipment .

moreover , recent dod studies found initial cost estimates for the aehf program as well as sbirs - high did not accurately capture program content and risk and were based on optimistic assumptions .

we also reported that costs would be better estimated if dod required more knowledge before starting a program .

without knowing that technologies can work as intended , for example , programs cannot reliably estimate costs and schedules .

another tool that could be useful in gaining insight into whether programs are positioned for success is the ipa team .

ipa teams are to be drawn from experts who are not directly affiliated with the program .

they are to spend about 8 weeks on - site working full - time with program officials to study the program , particularly by assessing the acquisition strategy , contracting information , cost analyses , system engineering , and requirements .

after this study , they are to conclude their work with recommendations to the dsab on whether or not to allow the program to proceed , typically using the traditional “red,” “yellow,” and “green” assessment colors to indicate whether the program has satisfied key criteria in areas such as requirements setting , cost estimates , and risk reduction .

the under secretary of the air force , however , makes the decision on whether to allow the program to proceed .

ipa team studies already performed have called attention to risks faced by the gps iii , npoess , and sbr programs .

the npoess study , for example , noted that risk mitigation plans needed to be strengthened and that independent cost estimates needed to include the winning contractor's negotiated contract .

the sbr study found that the program needed to better define how the system would operate in the context of dod's transformational communications architecture and work with key intelligence systems , such as the planned distributed common ground station .

both reviews recommended that the programs move forward ( npoess into the build phase and sbr into the study phase ) on the condition that these programs address areas of concern .

an ipa team studying gps iii found the program was too optimistic in estimating resources that would be needed .

for example , the study noted that the program budget was not sufficient to support the program plan by several hundred million dollars .

the team also pointed out that the system's architecture and acquisition strategy were not sufficiently defined .

dod's new acquisition management policy for space systems does not alter dod's practice of committing major investments before knowing what resources will be required to deliver promised capability .

instead , the policy allows programs to continue to mature technologies while they are designing the system and undertaking other product development activities .

while space systems are different than other weapon systems in terms of how they are developed and tested , it is still necessary to mature technology before starting product development and match resources to requirements in order to prevent cost increases and schedule delays .

we previously recommended that dod should not allow technologies to enter into a weapon system's product development until they are assessed at a trl 7 , meaning that a prototype has been demonstrated in an operational environment .

according to dod officials , the new space acquisition policy does not set trl criteria for deciding what the threshold for being mature should be .

however , dod officials stated that technologies may well enter into product development at a trl 5 , meaning basic components have only been tested in a laboratory , or an even lower level of maturity .

this means that programs will design the system and conduct other program activities at the same time they build representative models of key technologies and test them in an environment that simulates the conditions of space .

in essence , dod will be concurrently building knowledge about technology and design — an approach with a problematic history .

as shown in figure 2 , the knowledge building approach for space stands in sharp contrast to that followed by successful programs and the approach recommended by dod's new acquisition policy for weapon systems .

successful programs will not commit to undertaking product development unless they have high confidence that they have achieved a match between what the customer wants and what the program can deliver .

technologies that are not mature continue to be developed in an environment that is focused solely on technology development .

this puts programs in a better position to succeed because they can focus on design , system integration , and manufacturing .

by contrast , allowing technology development to carry over into product development increases the risk that significant problems will be discovered late in development .

addressing such problems may require more time , money , and effort to fix because they may require more extensive retrofitting and redesign as well as retesting .

the approach also makes it more difficult for programs to demonstrate the same level of design stability since technology and design activities will be done concurrently .

further , the consequences of problems experienced during development will be much greater for space programs since the design review occurs at the same time as the commitment to build and deliver the first product to a customer .

space acquisition officials we spoke with acknowledged the added risks that come when programs concurrently develop technologies and design the system .

however , they maintain that concurrent technology and product development is necessary for space acquisitions for several reasons .

first , while some testing on satellites can be done on the ground in thermovac or other environmental simulation chambers and some systems can also be tested via aircraft , the only way to test satellites in a true operational space environment is to build one or more demonstrator satellites and launch them into orbit .

launching demonstrators is costly and time consuming .

our prior reports have recognized that space systems are uniquely difficult to test in a true operational environment .

however , dod has found ways to test sensors and other critical technologies on experimental satellites and it has built and launched technology demonstrator satellites .

second , in view of the length of time it takes to develop space systems , dod asserts that it will not be able to ensure that satellites , when launched , will have the most advanced technologies , unless program managers are continually developing technologies .

dod officials have stated that they would reduce the added risks of their approach by not allowing programs to start if too many technologies were deemed to be immature or by deferring certain capabilities if it turned out that technologies did not test well .

we agree that continuing to develop leading edge technology is important for all system capabilities , not just space systems .

however , history has shown and we have repeatedly reported that conducting technology development within a product environment consistently delays the delivery of capability to the user , robs other programs of necessary funds through unanticipated cost overruns , and consequently , can result in money wasted and fewer units produced than originally stated as necessary .

a technology development environment is more forgiving and less costly than a delivery - oriented acquisition program environment .

events such as test “failures,” new discoveries , and time spent in attaining knowledge are considered normal in this environment .

further , judgments of technology maturity have proven to be insufficient as the basis for accurate estimates of program risks relative to cost , schedule , and capability .

finally , because operation and support costs make up a smaller portion of total costs for satellites than other weapon programs , dod asserts that earlier insight and decisions are needed on space programs .

we agree that early insight into programs is important , as we have reported that over 80 percent of the cost of a weapon system program is determined by requirements set at the beginning .

however , moving decisions to an earlier point in the product development process without additional knowledge may actually increase the risk of promising more than can be delivered and at higher costs .

the growing importance of space systems to military and civil operations requires dod to develop cutting edge technologies and achieve timely delivery of capability .

dod's new space acquisition policy does not position space programs to do either .

by allowing major investment commitments to continue to be made with unknowns about technology readiness , requirements , and funding , programs will likely continue to experience problems that require more time and money to address than anticipated .

over the long run , the extra investment required to address these problems may well prevent dod from pursuing more advanced capabilities .

by contrast , dod is taking steps to better position other weapon systems for success .

by separating technology development and product development , the policy will help to align customer expectations with resources , and therefore minimize problems that could hurt the program in its design and production phases .

in finalizing dod's new space acquisition management policy , we recommend that the secretary of the air force , who is dod's executive agent for space , modify the policy to ensure that customer expectations can be matched to resources before starting product development ( phase b ) .

specifically , we recommend that the secretary separate technology development from product development .

to ensure that this is done , we also recommend that the secretary set a minimum threshold of maturity for allowing technologies into a program .

as noted in our report , we previously recommended that dod should not allow technologies to enter into a weapon system's product development until they are assessed at a trl 7 , meaning that a prototype has been demonstrated in an operational environment .

in commenting on a draft of this report , the assistant secretary of defense for networks and information integration disagreed with our finding that the new space policy perpetuates risks for space programs since it does not separate technology development from product development .

dod disagreed with our recommendations as well , citing its need to keep up with the fast - paced development of advanced technologies for space systems and a requirement in its draft policy for technology readiness assessments to be conducted at appropriate milestones .

in fact , it is dod's long - standing and continuous inability to bring the benefits of technology to the warfighter in a timely manner that underlies the report's findings and recommendations .

in our reviews of numerous dod programs , including many satellite developments , it has been clear that committing to major investments in design , engineering , and manufacturing capacity without knowing a technology is mature and what resources are needed to ensure that the technology can be incorporated into a weapon system has consistently resulted in more money , time , and talent spent than either was promised , planned for , or necessary .

the impact of such mistakes in individual programs has also had a damaging effect on military capability as other programs are taxed to meet unplanned cost increases and production units are often cut because unit costs increase and funds run out .

although each dod program differs in its characteristics , gao's work with successful product developers in dod and the commercial sector has found that the process of developing leading edge technology and products that have more capability than their predecessors does not differ .

in fact , successful product developments are marked by adherence to a disciplined process that collects metrics and establishes and uses common and consistent criteria for decision - making .

we have found that companies that adopt these best practices often do so out of necessity , when their existence is threatened .

while the air force has taken some promising steps in drafting the policy to address dod's poor record of developing satellites within cost and schedule targets and with promised performance , it will miss an opportunity to dramatically improve outcomes if it does not adopt similar practices .

therefore , we have not changed our recommendation .

dod's detailed comments and our responses are provided in appendix iii .

in conducting our review , we analyzed dod's new interim acquisition management policy for space .

because of the limited time of our review , we focused on the question of whether the policy will enable dod to match requirements to resources at the onset of product development , which our work has shown to be the most critical determinant for successful outcomes of acquisitions .

we compared the new space policy to dod's new acquisition policy for other weapon systems as well as our past reviews of the best practices of commercial and military acquisitions .

in addition , we discussed this policy with air force space acquisition officials .

we analyzed ipa studies performed under the new policy on dod's npoess , gps iii , and sbr programs .

we also analyzed our past reviews of space programs as well as dod studies on the sbirs - high program and on space systems development growth .

see related gao products at the end of this report for a list of past gao reports we relied on .

we conducted our review from june 2003 through august 2003 in accordance with generally accepted government auditing standards .

we are sending copies of this report to the secretaries of defense and the air force and interested congressional committees .

we will also make copies available to others upon request .

in addition , the report will be available at no charge on the gao web site at http: / / www.gao.gov .

if you or your staff have any questions concerning this report , please contact me at ( 202 ) 512-4841 .

key contributors to this report were cristina chaplain , jean harker , natalie britton , and bradley terry .

space - based infrared system ( high ) national reconnaissance office ( nro ) ultra high frequency follow - on satellite global positioning system ( gps ) .

lowest level of technology readiness .

scientific research begins to be translated into applied research and development .

examples might include paper studies of a technology's basic properties .

2 .

technology concept and / or application formulated .

invention begins .

once basic principles are observed , practical applications can be invented .

the application is speculative and there is no proof or detailed analysis to support the assumption .

examples are still limited to paper studies .

3 .

analytical and experimental critical function and / or characteristic proof of concept .

active research and development is initiated .

this includes analytical studies and laboratory studies to physically validate analytical predictions of separate elements of the technology .

examples include components that are not yet integrated or representative .

4 .

component and / or breadboard validation in laboratory environment .

basic technological components are integrated to establish that the pieces will work together .

this is relatively “low fidelity” compared to the eventual system .

examples include integration of “ad hoc” hardware in a laboratory .

5 .

component and / or breadboard validation in relevant environment .

fidelity of breadboard technology increases significantly .

the basic technological components are integrated with reasonably realistic supporting elements so that the technology can be tested in a simulated environment .

examples include “high fidelity” laboratory integration of components .

6 .

system / subsystem model or prototype demonstration in a relevant environment .

representative model or prototype system , which is well beyond the breadboard tested for technology readiness level ( trl ) 5 , is tested in a relevant environment .

represents a major step up in a technology's demonstrated readiness .

examples include testing a prototype in a high fidelity laboratory environment or in simulated operational environment .

7 .

system prototype demonstration in an operational environment .

prototype near or at planned operational system .

represents a major step up from trl 6 , requiring the demonstration of an actual system prototype in an operational environment , such as in an aircraft , vehicle or space .

examples include testing the prototype in a test bed aircraft .

8 .

actual system completed and “flight qualified” through test and demonstration .

technology has been proven to work in its final form and under expected conditions .

in almost all cases , this trl represents the end of true system development .

examples include developmental test and evaluation of the system in its intended weapon system to determine if it meets design specifications .

9 .

actual system “flight proven” through successful mission operations .

actual application of the technology in its final form and under mission conditions , such as those encountered in operational test and evaluation .

in almost all cases , this is the end of the last “bug fixing” aspects of true system development .

examples include using the system under operational mission conditions .

the following are gao's comments on the department of defense's letter dated september 5 , 2003 .

1 .

we agree that there are consistencies between the two policies in terms of how they enhance the development of requirements .

however , the policies are very different in terms of their views on technology development .

dod's policy for weapon systems clearly requires technologies to be mature ( demonstrated in a relevant , preferably operational environment ) before beginning product development .

the space policy does not .

in fact , dod officials stated that , under the space policy , technologies may well enter product development without being demonstrated in a relevant environment .

this might not occur until dod is close to making its production decision .

in our view , this difference will be a detriment to the future success of space programs .

2 .

dod contended that our recommendation to set a minimum threshold of maturity for allowing technologies into a program ignores differences among programs and ignores evolutionary acquisition .

we disagree with these points .

technology maturity is fundamental to the success of all programs and cannot be ignored as part of a satellite's business case .

while it is possible to take a gamble on a key technology and have it work out in the end , dod's experiences show that this is an unlikely result .

moreover , this is not an approach that successful product developers emulate .

in addition , technology maturity is essential to successful evolutionary acquisitions .

the principle of evolutionary development is reaching full capability in more doable steps .

technical maturity essentially defines what is doable for each increment or block .

3 .

dod asserted that it is not feasible for space programs to separate technology development from product development because it would delay delivery of the product and make its technologies obsolete .

we disagree .

separation of technology development from product development has been found to be essential to reducing overall development cycle times and delivering new products within estimated resources .

the dod policy for other weapons acquisitions is quite clear on this as well .

in successful programs , the technologies are matured , hybrid organizations and agreements between the technologists and the product developers are established , and preliminary designs are done , thus providing the basis for a match between the user's needs and the developer's resources - - all before the commitment to product development is made .

by maturing technologies before committing significant time and money to product development and following an evolutionary approach , the product development cycle time is reduced , while opportunities for inserting new technologies are more frequent .

4 .

dod asserted that satellite programs cannot be demonstrated in an operational environment ( trl 7 ) .

we disagree .

nasa , the creator of trls , tests some technologies to a trl 7 if they are mission critical .

moreover , while we recognize the difficulties in attaining this level of maturity for space systems , the space policy does not even encourage programs to demonstrate technologies in a relevant environment before committing to a program .

in fact , according to dod officials , under the space policy , technologies could enter product development with a trl 5 or even lower .

the policy is silent on what the minimum threshold for maturity should be , leaving that decision to the milestone decision authority .

5 .

dod stated that none of our prior best practices case studies included a commercial satellite producer , making the knowledge points irrelevant to space systems .

this assertion is wrong .

in the report that first promulgated the knowledge points ( gao / nsiad - 98-56 ) , one of the key case studies was hughes space and communications and its experience with the hs - 702 satellite .

we deliberately included hughes because it was a low - volume , high technology producer .

hughes insisted on having process control for all key processes and proved them either through use on other satellite production or through statistical process control techniques .

hughes was also included as part of our best practice study on technology development ( gao / nsiad - 99-162 ) .

6 .

dod asserted that moving decision points to an earlier point in the program reduces risks , rather than increases them as our report states .

we disagree .

the space policy proposes to make commitments to product development ( including point estimates on cost , schedule , and performance ) before sufficient knowledge has been achieved and requires decision makers to commit first to product development without having technology in hand and second to production of the first two products without production knowledge in hand .

this is the traditional dod approach , which has consistently resulted in capability being delivered much later and much more expensively than planned .

the commitment to product development ( and the requisite estimates ) can be done more confidently and the product development cycle time can be much shorter only if decisions are knowledge - based .

7 .

while officials have told us that the intent of the policy is to complete technology development during phase b , they acknowledged that the policy does not identify an end point for technology development and that , in some cases , it could continue until the point the program is ready to begin building the first satellite .

military space operations: common problems and their effects on satellite and related acquisitions .

gao - 03-825r .

washington , d.c.: june 2 , 2003 .

polar - orbiting environmental satellites: project risks could affect weather data needed by civilian and military users .

gao - 03-987t .

washington , d.c.: july 15 , 2003 .

missile defense: alternate approaches to space tracking and surveillance system need to be considered .

gao - 03-597 .

washington , d.c.: may 23 , 2003 .

military space operations: planning , funding , and acquisition challenges facing efforts to strengthen space control .

gao - 02-738 .

washington , d.c.: september 23 , 2002 .

polar - orbiting environmental satellites: status , plans , and future data management challenges .

gao - 02-684t .

washington , d.c.: july 24 , 2002 .

defense acquisitions: space - based infrared system - low at risk of missing initial deployment date .

gao - 01-6 .

washington , d.c.: february 28 , 2001 .

defense acquisitions: assessments of major weapon programs .

gao - 03-476 .

washington , d.c.: may 15 , 2003 .

defense acquisitions: matching resources with requirements is key to the unmanned combat air vehicle program's success .

gao - 03-598 .

washington , d.c.: june 30 , 2003 .

best practices: better acquisition outcomes are possible if dod can apply lessons from f / a - 22 program .

gao - 03-645t .

washington , d.c.: april 11 , 2003 .

best practices: setting requirements differently could reduce weapon systems' total ownership costs .

gao - 03-57 .

washington , d.c.: february 11 , 2003 .

best practices: capturing design and manufacturing knowledge early improves acquisition outcomes .

gao - 02-701 .

washington , d.c.: july 15 , 2002 .

defense acquisitions: dod faces challenges in implementing best practices .

gao - 02-469t .

washington , d.c.: february 27 , 2002 .

best practices: dod teaming practices not achieving potential results .

gao - 01-510 .

washington , d.c.: april 10 , 2001 .

best practices: better matching of needs and resources will lead to better weapon system outcomes .

gao - 01-288 .

washington , d.c.: march 8 , 2001 .

best practices: a more constructive test approach is key to better weapon system outcomes .

gao / nsiad - 00-199 .

washington , d.c.: july 31 , 2000 .

defense acquisitions: employing best practices can shape better weapon system decisions .

gao / t - nsiad - 00-137 .

washington , d.c.: april 26 , 2000 .

best practices: better management of technology development can improve weapon system outcomes .

gao / nsiad - 99-162 .

washington , d.c.: july 30 , 1999 .

best practices: successful application to weapons acquisitions requires changes in dod's environment .

gao / nsiad - 98-56 .

washington , d.c.: february 24 , 1998 .

