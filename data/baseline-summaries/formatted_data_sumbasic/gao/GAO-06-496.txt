more than 150,000 manufacturing workers lost their jobs in fiscal year 2004 due to international trade .

most of these workers were eligible for services under the trade adjustment assistance ( taa ) program , the primary federal employment and training program serving trade - affected workers .

taa , funded at about $1 billion in fiscal year 2005 , provides workers with a variety of services , including training and income support after they exhaust their unemployment insurance ( ui ) benefits .

the u.s. department of labor ( labor ) oversees the program , and states and local areas administer services to taa participants .

despite the role the taa program plays in helping trade - affected workers transition to new employment , program outcomes have shown mixed results .

labor collects some key performance information from states and uses it to track program performance against three national goals in the areas of employment , job retention , and wages .

since 2001 , the taa program has exceeded the national goal for job retention in every year but one .

however , it has failed to meet at least one of the national goals each year , and in fiscal year 2003 , the program failed to meet all three .

further , the program assessment rating tool ( part ) — a diagnostic tool that the administration uses to help formulate the budget — rated the program ineffective , in part because it failed to meet its national goals .

it is unclear , though , whether the outcomes reported in the goals accurately reflect the program's achievements .

our previous work and work by labor's inspector general have identified problems with the performance data states submitted to labor — information was often incomplete , and many states did not validate the information they reported to labor .

while labor has taken some steps to improve the performance data , it is not known whether the data currently collected on taa performance are reliable .

in the current tight budgetary environment , program performance is likely to be an increasingly significant factor used to help policymakers assess programs and determine funding levels .

given concerns over the quality of taa data and the importance of having meaningful information to assess program performance , we examined ( 1 ) whether the taa performance data provide a credible picture of the program's performance , ( 2 ) what taa performance data labor makes available to the public and states and the usefulness of the data for managing the program , and ( 3 ) what labor is doing to address issues with the quality of taa data submitted by states .

to address these questions , we conducted a web - based survey of workforce officials in the 46 states that were allocated taa funds in fiscal year 2005 , and we obtained a 100 percent response rate .

in addition , to gather in - depth information about how states manage their taa performance data , we conducted site visits in california , iowa , ohio , texas , and virginia , where we interviewed state officials and visited at least one local area in each state .

we selected these states because they represent different taa data collection approaches ( that is , states where data are entered into information technology systems at the local level and those where data are entered at the state level ) , received a relatively large share of taa funds in fiscal year 2005 , and are geographically dispersed .

in addition , to gather insights into data management strategies and requirements , we interviewed labor officials in headquarters and in the regional offices and experts on data quality .

we also reviewed legislation , guidance , summaries of state taa performance outcome information , participant data submitted by states to labor , and other relevant reports and literature related to data quality .

our work was conducted between december 2004 and march 2006 in accordance with generally accepted government auditing standards .

 ( see app .

i for a detailed discussion of our scope and methodology. ) .

to assist workers who are laid off as a result of international trade , congress passed the trade expansion act of 1962 and created the trade adjustment assistance program .

historically , the main benefits available through the program have been extended income support and training .

participants are generally entitled to income support , but the amount of funds available for training is limited by federal statute .

labor certifies groups of laid - off workers as potentially eligible for taa benefits and services by investigating petitions that are filed on the workers' behalf .

workers are eligible for taa if they were laid off as a result of international trade and were involved in making a product or supplying component parts to or performing finishing work for directly affected firms .

workers served by the taa program have generally been laid off from the manufacturing sector .

congress has amended the taa program a number of times since its inception .

for example , in 1974 congress eased program eligibility requirements , and in 1988 congress added a requirement that workers be in training to receive income support .

in 1993 congress created a separate north american free trade agreement transitional adjustment assistance ( nafta - taa ) program specifically for workers laid off because of trade with canada or mexico .

the most recent amendments to the taa program were included in the taa reform act of 2002 ( pub .

l. no .

107-210 ) , which was signed into law in august 2002 .

the reform act consolidated the former taa and nafta - taa programs into a single taa program , doubled the amount of funds available for training annually , expanded program eligibility to more workers , extended the time periods covered by the program , and added new benefits .

under the current taa program , eligible participants have access to a wider range of benefits and services than before , including: training .

participants may receive up to 130 weeks of training , including 104 weeks of vocational training and 26 weeks of remedial training ( eg , english as a second language or literacy ) .

on - the - job training is also available under taa .

participants in taa - approved training must attend training full - time .

extended income support , or trade readjustment allowances ( tra ) .

participants may receive up to 104 weeks of extended income support benefits after they exhaust the 26 weeks of ui benefits available in most states .

this total includes 78 weeks while participants are completing vocational training and an additional 26 weeks , if necessary , while participants are completing remedial training .

the amount of extended income support payments in a state is set by statute at the state's ui benefit level .

during their first 26 weeks of extended income support , participants must be enrolled in training , have completed training , or have a waiver from this requirement ; to qualify for more than 26 weeks of extended income support , participants must be enrolled in training .

the taa statute lists six reasons why a taa participant may receive a waiver from the training requirement , including that the worker possesses marketable skills or that the approved training program is not immediately available .

states must review participants' waivers at least every 30 days and if necessary may continue to renew participants' waivers each month throughout the initial 26 weeks of extended income support .

job search and relocation benefits .

payments are available to help participants search for a job in a different geographical area and to relocate to a different area to take a job .

participants may receive up to a maximum of $1,250 to conduct a job search .

the maximum relocation benefit includes 90 percent of the participant's relocation expenses plus a lump sum payment of up to $1,250 .

health coverage tax credit ( hctc ) .

eligible participants may receive a tax credit covering 65 percent of their health insurance premiums for certain health insurance plans .

to be eligible for the credit , trade - affected workers must be either receiving extended income support payments , or they must be eligible for extended income support but are still receiving ui payments , or they must be recipients of benefits under the wage insurance program .

as a result , trade - affected workers who are still receiving ui rather than extended income support may register for the hctc only if they are in training , have completed training , or have a waiver from the training requirement .

wage insurance .

the wage insurance program — known as the alternative taa ( ataa ) program — is a demonstration project designed for workers age 50 and older who forgo training , obtain reemployment within 26 weeks , but take a pay cut .

provided the participant's annual earnings at his or her new job are $50,000 or less , the benefit reimburses 50 percent of the difference between the participant's pre - and postlayoff earnings up to a maximum of $10,000 over 2 years .

the process of enrolling trade - affected workers in the taa program begins when a petition for taa assistance is filed with labor on behalf of a group of laid - off workers .

petitions may be filed by entities including the employer experiencing the layoff , a group of at least three affected workers , a union , or the state or local workforce agency .

the taa statute lays out certain basic requirements that all certified petitions must meet , including that a significant proportion of workers employed by a company be laid off or threatened with layoff .

in addition to meeting these basic requirements , a petition must demonstrate that the layoff is related to international trade .

the law requires labor to complete its investigation , and either certify or deny the petition , within 40 days after it has received it .

when labor has certified a petition , it notifies the relevant state , which has responsibility for contacting the workers covered by the petition , informing them of the benefits available to them , and telling them when and where to apply for benefits .

workers generally receive services through a consolidated service delivery structure called the one - stop system , where they can access a broad range of services beyond taa , including the workforce investment act ( wia ) dislocated worker program , the wagner - peyser employment service ( es ) program , and services funded by the wia national emergency grants .

training for trade - affected workers may be funded by taa or by one of the wia funding sources .

workers often meet one on one with a case manager who may assess worker's skills and help decide what services they need .

because the taa program has limited funds that can be used for case management and program administration , these case management services are often performed by es or wia dislocated worker program staff .

when this occurs , participants are often co - enrolled in wia or es as well as taa .

about $750 million was appropriated for income support for trade - affected workers for fiscal year 2005 , while another $259 million was appropriated for training , job search and relocation allowances , and administrative costs .

of the $259 million , $220 million is set aside for training , and labor allocates 75 percent of it to states according to a formula that takes into account each state's previous year allocations , accrued expenditures , and participant levels .

labor holds the remaining 25 percent of training funds in reserve , to distribute to states throughout the year according to need .

to cover administrative costs associated with training under the taa program , labor allocates additional administrative funds to each state equal to 15 percent of its training allocation .

labor is responsible for monitoring the performance of the taa program .

in fiscal year 1999 , labor introduced a new participant outcomes reporting system , the trade act participant report ( tapr ) , that was designed to collect national information on taa program participants , services , and outcomes .

states are required to submit tapr reports to labor each quarter , with data on individuals who exited the taa program .

the tapr data submitted by states are used to calculate national and state outcomes on the taa performance measures for each fiscal year , which include ( 1 ) the percentage of participants that found jobs after exiting the program ( reemployment rate ) , ( 2 ) the percentage of those participants who were employed after exiting the program who were still employed 9 months later ( retention rate ) , and ( 3 ) the earnings in their new jobs compared to prior earnings ( wage replacement rate ) .

labor's guidance requires states to include in their tapr submissions all taa participants who exit the program , that is , stop receiving benefits or services .

under labor's guidance , a participant is defined as any individual who receives any taa benefit or service , including extended income support payments , training , or job search and relocation allowances .

according to this definition , participants would include those who , for example , received only extended income support and a waiver that allowed them to forgo training .

tapr reports include data on each exiter's characteristics , services received , and employment outcomes .

data on characteristics , for example , should include the worker's date of birth , gender , ethnicity , educational level , and layoff date .

data on services received should include data on training ( such as dates the participant entered and completed training , and the type of training received ) , on other taa benefits received ( such as extended income support , job search allowance , and relocation allowance ) , and on co - enrollment in wia or other federal programs .

data on outcomes should include the date the worker exited the taa or other federal program , whether the worker was employed in the first full quarter after exit , whether the worker was employed in the third full quarter after exit , and the worker's earnings in these quarters .

where possible , outcome data are to be obtained from state ui wage records .

labor uses the tapr data to track taa program outcomes against national goals .

unlike the wia programs , however , taa has no individual state performance goals , and states do not receive incentives or sanctions based on their performance levels , nor are they otherwise held accountable for their performance .

at the national level , the taa program has failed to meet at least one of its performance goals each year since 2001 , the first year for which goals were set .

table 1 shows goals and outcomes for fiscal years 2004 and 2005 .

in addition to submitting tapr data , states also submit data to labor on taa services and expenditures each quarter through the form 563 .

form 563 includes counts of participants receiving taa services , while tapr includes individual - level data on former participants who have exited the program .

states are required to submit each quarter's form 563 data about 1 month after the end of the quarter .

form 563 includes data on services such as the number of new training participants ( by type of training — occupational , remedial , and on - the - job ) , the number of workers in training at the end of the quarter , the number of training waivers issued , and the number of recipients of job search and relocation allowances , and expenditures on extended income support .

in response to an office of management and budget ( omb ) initiative , labor recently began requiring states to implement common performance measures for wia programs .

omb established a set of common measures to be applied to most federally funded job training programs that share similar goals .

labor further defined the common measures for all of its employment and training administration programs and required states to implement these measures beginning july 1 , 2005 .

because it operates on a fiscal year rather than a program year basis , labor required the taa program to implement the measures by october 1 , 2005 .

in addition to standardizing the performance measures , the common measures guidance also standardizes the definition of exiters across all programs .

an exiter is defined as any participant who has not received a service funded by the program or funded by a partner program for 90 consecutive calendar days and is not scheduled for future services .

the exit date is defined as the last date of service .

for taa participants , the exit date may be the training completion date , but if additional services are provided after training is completed , or if the participant is continuing to receive tra , he or she would not be exited from the program .

some services are not significant enough to delay exiting , however .

these include receiving ui benefits , some case management services , and postplacement follow - up .

the process of collecting and reporting taa performance data involves all three levels of government .

participant forms and case files are generally collected and organized by frontline staff in local areas , usually at the one - stop .

in some states , local staff may enter some of the information into an it system that is either integrated with the state's it system or able to create an electronic file to transmit to the state .

in other states , paper case files are physically transferred to state officials for data entry .

at the state level , taa data are often maintained in more than one it system .

for example , benefit payment information is usually in the same it system that houses unemployment insurance payment information .

however , information on participant characteristics and services ( including status of training and whether or not the individual has exited ) resides in one or more other systems .

in some states , this participant information remains as a paper case file until it is determined that the participant has exited , and it is time to include him or her in the tapr submission .

to compile the tapr submission , state agencies administering taa typically match participant records to their state's ui wage record system to determine whether these former participants are employed and , if so , the wages they are earning .

in some states , staff must manually enter information obtained from the ui wage record system into the tapr file , while other states have it systems capable of automatically matching ui data with participants' records .

states may also use the wage record interchange system ( wris ) to match participant records to other states' ui wage records for participants who found jobs in other states .

some states may link participant records to other partner programs' it systems to track activities across programs or to determine if the participant has exited all programs .

once labor receives the tapr data , officials perform edit checks and calculate performance levels at the national and state level .

taa performance data are incomplete and may be inaccurate .

states report that they are not including all taa participants in their tapr performance data , despite labor's requirement that all participants be included after they exit the program .

in addition , some states may not have documentation to verify the accuracy of participants' exit dates in tapr and are not using all available data sources to determine taa participants' employment outcomes .

furthermore , 1 state in 5 is using manual rather than automated processes to compile tapr data , and others have it systems with limited capacity to control for errors .

having such it systems could hinder states' ability to ensure that the data are complete and accurate .

however , many states are planning to make improvements to their taa it systems' capabilities this year .

some state taa officials said that resource constraints have made it difficult to ensure their data are complete and accurate .

many states are not including all exiting participants in the tapr submissions that labor uses to calculate performance outcomes for taa participants , such as the reemployment and retention rates .

participants who received training were most likely to be included in states' tapr data , but those who had training waivers and had not received training were least likely to be included .

only 23 of the 46 states we surveyed reported that they are including in their tapr submissions to labor all exiting participants , regardless of the type of benefit or service they received .

fourteen states reported that participants who received waivers but did not receive training were unlikely to be included in the tapr ( see fig .

1 ) , and 3 states reported that they do not include any participants unless they receive training .

this finding is consistent with a review by pennsylvania's state auditor that found that participants who received waivers from training were not included in their tapr submissions .

our review of the tapr data states submitted to labor during fiscal year 2005 confirms our survey results — some states appear to be excluding some of their participants in their tapr data files .

for example , 9 states only included in their tapr submissions participants who received training .

another 12 states had tapr submissions composed almost exclusively ( 97 to 99 percent ) of participants who received training ( see table 2 ) .

however , several states did include relatively more of the participants who had not received training .

for example , for 6 states , under 60 percent of the participants reported in the tapr had received training .

we have no other reliable source of data to help us assess what proportion of participants nationwide actually receive training and , therefore , what the proportion in the tapr should be .

in a recent study that examined services and outcomes for five trade - related layoffs , however , we found that between 9 and 39 percent of potentially eligible taa participants enrolled in training .

excluding certain participants from the tapr could skew the taa performance outcomes calculated by labor because the outcomes may be disproportionately based on participants who received taa - funded training .

labor does not have a process in place to ensure that states are including in their tapr submissions all exiting taa participants .

labor's regional offices may review whether states' tapr submissions are complete during their state monitoring visits .

however , because labor has not had a standard monitoring tool , there has been no assurance that the regional offices were consistently reviewing whether all exiting participants are reported in states' tapr data .

labor officials tell us that they are currently developing a core monitoring guide , but it is not clear if the guide will address this issue .

despite the importance of accurately identifying exiters , the exit dates themselves may not be accurate because some states do not consistently obtain proper documentation to verify the dates .

accurate exit dates are critical to taa performance data for two reasons .

first , a participant's exit date determines if the individual should be included in the state's tapr submission to labor .

second , the timing of the date of exit determines when a participant's employment outcomes will be assessed .

labor's guidance requires that states have documentation for participants' exit dates but does not specify the type of information that needs to be included in the documentation .

for example , for participants who received training , it does not specify that the documentation should demonstrate that training was actually completed .

such documentation could include certificates of training completion , attendance records , or reports from training providers .

taa officials in 4 of the 5 states we visited said they had a process for obtaining documentation to show that participants completed training , but it is not clear whether such processes are uniformly followed by states .

officials in 3 states said that they receive training certifications , either from participants or from trainers , that show that training was completed .

in another state , a taa official said that the state sends participants a follow - up survey after training to verify that the training was completed , but some participants do not return the survey .

officials in 1 of the 5 states we visited said they did not have a process for certifying or documenting that participants completed training .

a recent review in 4 other states by labor's office of inspector general ( oig ) confirmed that states do not have effective processes for verifying exit dates .

in its review of 150 taa case files , the oig found that there was no documentation in any of the reviewed files to verify that the participants had completed the program on the recorded date of exit .

oig reported that states often recorded an anticipated date of exit when participants first entered the program , but did not collect any further documentation to confirm that participants had completed the training , and if so , whether they had completed training on the originally recorded date .

the oig recommended that labor ensure that states collect and record taa participants' actual date of exit , maintain the source documentation for such exit dates , and make the documentation readily available for review .

according to an oig official , labor had not implemented these recommendations as of january 2006 .

some states are not using all available data sources to determine taa participants' employment outcomes .

labor requires states to use ui wage records to determine the employment outcomes of participants reported in the tapr .

however , each state's wage record database includes only wage data on workers within the state and does not have data on participants who found employment in another state .

to help track employment outcomes of taa participants across state lines , states can obtain their employment and earnings information using other methods .

labor encourages states to use wris , a data clearinghouse that makes ui wage records available to participating states seeking information on taa participants who may have found employment outside their state .

thirty - four of the 46 states we surveyed reported that they routinely use wris to obtain employment outcome data on former taa participants ( see fig .

2 ) .

three states reported that they do not use wris but instead routinely use interstate agreements with individual states to obtain employment outcome data .

opting to use interstate agreements with individual states instead of using wris is likely to result in access to fewer states' ui wage records than states would have if they used wris and may result in lower reported outcomes .

seven states use only their own states' ui wage records to determine participants' employment outcomes .

state taa officials cited several reasons for not using wris , including that it took too long to receive the needed information and it was not a priority for the state .

six states that do not currently use wris said that they plan to begin using this system in the future .

nearly half of the 46 states are not routinely using other supplemental information sources even though it may be the only way to collect outcome information for certain participants .

ui wage records , which cover about 94 percent of workers , do not include some categories of workers , such as self - employed persons , most independent contractors , military personnel , federal government workers , and postal workers .

to document the employment status of these workers in the tapr , states can use supplemental data , such as pay stubs and follow - up surveys sent to participants after they leave the program .

using supplemental data is likely to provide a more complete picture of participant outcomes because it helps states avoid inaccurately recording participants as unemployed in the tapr .

in an earlier report on wia performance data , 23 of the 50 states told us they needed to use supplemental data in order to meet their expected performance levels for the reemployment measure under wia .

twenty - two states reported that they rarely if ever collect supplemental data to obtain outcome information on taa participants ( see fig .

3 ) .

state taa officials said that they did not collect supplemental data because states' taa it systems lacked the capacity to record supplemental data ; they judged data collected through ui wage records and wris as sufficient , or collecting supplemental data was not required ; and they lacked sufficient resources .

some states reported it system limitations that could hinder the states' ability to ensure their taa data are complete and accurate .

gao , workforce investment act: states and local areas have developed strategies to assess performance , but labor could do more to help , gao - 04-657 ( washington , d.c.: june 1 , 2004 ) .

data on employment outcomes into their tapr data rather than electronically transferring the data from the ui wage record file .

using manual rather than automated processes increases the opportunity for errors to be introduced into the data through data entry .

six states responding to our survey expressed concern that errors in data entry may be one of the main causes of incomplete or inaccurate taa data .

one state's process for manually compiling the tapr illustrates opportunities to introduce errors into the data .

in this state , staff at the state level enter data on taa participants' training contracts into a contract database .

to compile the tapr , they identify participants in the contract database whose training was scheduled to be completed during the quarter covered by the tapr , and they enter data on those participants into a new spreadsheet .

to identify employment outcomes for the tapr , the staff look up the exiting taa participants on printouts from the state's ui wage record system and manually enter data on the participants' employment status and wages into the spreadsheet .

the data from the spreadsheet are then converted into the tapr reporting format and sent to labor .

limited it system capabilities .

many states' it systems for compiling taa data do not have certain it system capabilities , such as performing edit checks , that help a state report complete and accurate data to labor .

only 15 of the 46 states we surveyed had taa it systems with each of three such capabilities: performing edit checks to prevent data errors: edit checks aid in identifying invalid data , such as an entry in a date field that is not a date .

identifying dates taa participants completed wia - funded services: the ability to identify when taa participants complete wia - funded services can help ensure that taa participants are not counted in the tapr report while they are still receiving services under wia .

if participants are still receiving services , then it is too soon to assess their employment outcomes in the tapr report .

allowing staff to query the system to assess data reliability and completeness: queries allow staff to pull certain information out of the system to answer questions , and without this capability , staff may not be able to properly assess data quality and diagnose data problems .

for example , in one local area we visited , a taa specialist who is responsible for reporting on numerous taa participants described having great difficulty determining if training completion dates had been entered for participants as appropriate because the specialist could not query the system to get a list of participants and their training status .

more than half of the states told us they had plans to make at least one of these system improvements during the next year .

for example , 17 states reported plans to improve their taa it systems' capability to perform edit checks ( see fig .

4 ) .

some states with electronic systems may have the capability to track taa participants across other programs serving them , but several do not .

out of the 37 states that told us they had electronic systems to compile their tapr data , 29 states said this same system captures program information for wia programs , and similarly , 29 said the system captures information for employment services .

thirteen states said that these capabilities extended to all six programs and benefits that we examined , which includes , in addition to wia and es , trade readjustment allowance , national emergency grants , veterans employment and training program , and ui .

see appendix ii for a complete listing of states' systems linkages .

in addition , several states commented on our survey that they have planned enhancements to their taa it systems that may help coordinate across programs and increase the likelihood of capturing more outcomes: improving coordination of data across programs: six states reported planning changes , such as developing a single case management system for several programs that would allow more coordination of data across programs .

transitioning from manual to electronic processes: two states that have been using manual processes reported plans to develop electronic interfaces to capture needed data for the tapr .

adding capacity to record supplemental data: two states reported that their it system changes will enable them to begin recording supplemental data for use in determining taa participants' employment outcomes .

some states reported that limited taa administrative funds hindered their ability to ensure the quality of the taa performance data they collect and maintain .

to cover their taa program's administrative costs , states receive an allocation each year equal to 15 percent of their taa training allocation .

in fiscal year 2006 , 9 states received less than $100,000 in taa administrative funds , and another 10 states received between $100,000 and $300,000 .

these funds are used to cover all the administrative activities of the program , such as reviewing waivers and training plans , processing applications for job search or relocation allowances , and any associated data collection and reporting .

some states also use these funds for direct case management services to participants because they are the only taa funds available to provide these services .

however , we recently reported that state officials told us the taa administrative funds were often insufficient to meet the case management needs of the program and they relied on other programs to provide those services .

 ( for a complete listing of each state's taa training and administrative funds , see app .

iii. ) .

state and local taa officials said that resource shortages contribute to difficulties in identifying exit dates , using supplemental data sources , and entering data in a timely manner .

for example , one state official commented on our survey that taa case managers often do not have enough time to follow up with participants to learn about their status after they have been sent to training .

another state official said that insufficient case management can delay the identification of participants exiting the program .

officials in 2 other states told us that supplemental data were too time - consuming and burdensome to collect , given the program's current funding levels .

officials said that resource limitations also presented challenges in entering the data in a timely manner .

an official in one local area we visited reported a tremendous backlog in entering taa participant data into the it system because there were just two staff to handle approximately 1,000 taa cases .

similarly , in another local area , the office manager told us that taa staff were spread too thinly , a condition that adversely affected the collection and entry of taa data .

labor reports data on taa petition and certification activity , program participation , and key performance measures , but this information may not be useful for gauging current program performance .

the information may be helpful in providing a long - term national picture of program outcomes , but it represents past , rather than current , performance .

ui wage records — the primary data source for tracking taa performance — provide a fairly consistent national view of taa performance and allow for tracking outcomes over time .

at the same time , the ui wage records suffer from time delays and , together with the use of longer - term outcome measures , affect the timing of states' performance reports to labor and , subsequently , the information that labor makes publicly available .

most of the outcome data reported in a given program year actually reflect participants who left the program up to 2 years earlier .

in addition , labor does not consistently report taa data by state or industry or by services or benefits received — a step that would make the data more useful to policymakers .

states responding to our survey reported that they would like additional information from labor , such as how their taa performance compares to the performance of other states and other federal employment and training programs .

labor makes some taa statistics available through postings on its web site and through published reports , but they do not provide useful information on current performance .

labor provides some taa activity and participant data by fiscal year including number of petitions received , certifications issued , and denials by state ; distribution of certifications by industry ; number of new participants receiving extended income support payments or training ; and summary statistics on former taa participants ( such as race , education level , and benefits and services received ) .

in addition to reporting on taa activity and participant data , labor also reports on three key taa performance measures .

the tapr data submitted by states are used to calculate national and state outcomes on the taa performance measures — wage replacement , reemployment , and retention — for each fiscal year .

in 2005 , labor made state - by - state taa outcome information publicly available for the first time .

according to labor officials , making this information public represents an effort to emphasize performance , and they intend to post state - by - state outcome information on the web site for all future fiscal years .

labor's regional offices directly provide states with information on their taa performance relative to the program's national goals .

some regional offices also provide states with reports showing the performance of all states in the region , according to officials we interviewed .

however , the information labor makes publicly available may not provide a clear picture of current taa performance because , in addition to being incomplete and perhaps inaccurate , the data represent past performance and are not consistently reported by type of service , state , or industry .

data represent past performance .

because taa performance is measured using ui wage records and long - term performance measures such as employment retention , the most up - to - date taa performance data currently available may represent performance from several years in the past .

use of wage records: using ui wage records to measure outcomes provides a common yardstick for making long - term comparisons across states because they contain wage and employment information on most workers .

at the same time , these files suffer delays between the time an individual gets a job and when this information appears in wage records .

state procedures for collecting and compiling wage information from employers can be slow and time - consuming .

data are collected from employers only once every quarter , and employers in most states have 30 days after the quarter ends to report the data to the state .

for example , the wage report for the last calendar quarter of the year ( ending on december 31 ) is due to the state on january 31 .

we previously reported that for the majority of states , the delay between the time an individual gets a job and the time this information appears in wage records is up to 4 months .

design of measures: in addition to using a job placement measure , labor also uses two longer - term measures to gauge taa performance — an earnings measure and a job retention measure .

these measures may be useful for assessing how well the program is meeting its long - range goals to increase the employment , retention , and earnings of participants .

however , the use of these measures requires states to wait from one to three quarters after participants exit the taa program before measuring the outcomes .

for example , although states record whether participants entered employment in the first quarter after exit , two more quarters must elapse before employment retention is measured .

participants who exit the taa program have their outcomes assessed in the first , second , and third quarters after exit .

however , data to measure all outcomes are not available until the fifth quarter after exit , and the outcomes are not submitted to labor until midway through the sixth quarter .

figure 5 illustrates the time it takes before a taa participant would be included in performance outcome calculations .

while approximately one - third of the states found taa performance information they currently receive from labor to be greatly useful , some would like labor to provide them with additional information to help manage their program .

nearly half of the 46 states we surveyed told us that they find the performance information they receive from labor to be moderately useful ( see fig .

7 ) , and 8 states reported that labor's taa performance information is of little or no use for program management .

nearly half of the states we surveyed told us that they routinely develop information on their own performance beyond what they submit to labor .

for example , an official in 1 state reported that it calculates its own outcomes before receiving them from labor in order to make managers and executives aware of the state's performance , and it uses this information to engage state and local taa staff in making program adjustments .

in addition , approximately one - third of the states routinely develop information on their local areas' performance .

labor does not provide analysis of local area performance to states because it does not collect this type of information in the tapr .

while many states provide the performance information of their own state and that of other states to their local area taa staff , few states provide information on their local areas' performance to local taa staff .

only 27 of the 46 states in our survey reported that they share information from labor with local area staff on how their state's performance compares to national taa performance goals .

in addition , only 7 of the 16 states that generate additional performance information for local areas reported that they share this information with local taa staff .

one expert we spoke with told us that regularly sharing performance information with local program staff enables them to understand how the data they collect are being used and the importance of complete and accurate data for producing reliable performance information .

our recent report on performance measurement also noted that frequent and routine communication of performance information helps program staff and stakeholders use such information to accomplish program goals as they pursue day - to - day activities .

these practices could lead to better program management and produce more reliable performance data to assess taa performance in the future .

states said that they would like to receive additional performance information from labor to help manage their taa program .

thirty - four states would like more information than they currently receive on their own state's performance , and 39 states reported they would like information comparing their states' taa performance to their wia dislocated worker performance ( see fig .

8 ) .

according to one state official we spoke with , receiving additional taa performance information that is displayed by type of service and by state would enable officials to respond more effectively to performance problems and to learn what strategies states with similar taa populations are using to achieve different performance outcomes .

while it has limited authority to hold states accountable , labor has taken steps to improve the quality of taa data states submit , but these steps do not fully address all issues .

labor has no mechanism to sanction states for poor performance or poor - quality data because the law and current regulations do not provide one .

however , labor has begun an initiative that requires states to review a sample of their data for accuracy .

it is too soon to fully assess whether labor's efforts have improved data quality , but most states reported on our survey that labor's new requirements have increased awareness of data quality at the state and local levels .

states also report that they would like more opportunities to share lessons learned about issues related to data quality .

labor is requiring changes in some taa performance measures to align them with measures for other federally funded job training programs .

many states reported that the changes are burdensome , and some states are experiencing delays in implementing the changes .

to address data quality concerns , labor developed a process for states to use to validate the tapr data they submitted to labor .

starting with data submitted in fiscal year 2003 , labor required states to review a sample of participants' records and compare what was reported for certain data elements to data in source files .

state staff review the source files and record whether each data element is supported by source documentation and , therefore , passed data validation .

if the source files show a data element was incorrect or was not supported with documentation , the data element fails .

states use labor's software to calculate error rates , and they submit the results to labor .

while it is too soon to assess whether labor's data validation efforts have improved data quality , many states said that the efforts are having a positive effect .

thirty - five states reported that efforts have improved the accuracy of the data .

thirty - seven of the 46 states told us they have helped increase the awareness of data quality at the state level , and 25 states told us they have improved awareness at the local level ( see fig .

9 ) .

until recently , labor has not had a standard process for ensuring that states performed data validation correctly .

labor officials tell us , however , that beginning in 2006 , regional offices are conducting data validation compliance reviews of a subsample of validated records to ensure that the records were accurately validated and the files contained all required source documents .

while states report that labor's data validation requirements are having some positive effects , labor's data validation efforts do not address two key problems .

first , guidance for data validation defined for the first time the type of source documents needed to validate tapr data elements , including exit dates .

however , the guidance does not specify that the source documents for training completion dates should show that participants actually completed training .

second , data validation does not provide for assessing whether tapr submissions are complete .

because the data validation process only covers participant records included in states' tapr submissions for the year , it does not look beyond those records to determine whether all exiting participants were included .

in addition to implementing data validation , labor has taken various actions to better instruct states and to provide tools for improving the data they submit to labor .

technical assistance and training: in 2005 and 2006 , labor brought together state taa staff for training conferences on the new data requirements for implementing common measures .

according to labor officials , labor's regional offices periodically hold roundtables with states to discuss issues that sometimes include data quality .

labor provides technical assistance , as needed , to states through telephone calls and e - mails .

according to labor officials , labor is planning to start holding quarterly conference calls with states about taa issues , including data quality .

guidance on data reporting: labor issued guidance and instructions for taa data reporting , such as instructions defining how “date of exit” is to be determined under common measures .

in may 2005 , labor issued a guidance letter to states addressing several issues with data quality , such as the use of wris and supplemental data to determine employment outcomes .

in general , states reported that the guidance and training they had received from labor provided a clear understanding of certain data requirements , such as the requirements for data validation and for using ui wage records .

states were somewhat less likely to say that labor had provided a clear understanding of the documentation needed for the date of exit and how supplemental data could be used to document taa employment outcomes .

monitoring: labor's regional offices conduct monitoring visits to review states' taa programs .

in the past , labor did not have a standard protocol for these monitoring visits , and the monitoring did not always cover the quality of the taa data being submitted by states .

however , as of march 2006 , labor was developing a standard monitoring guide for its regional staff .

pilot project on federal employment data: labor collaborated with the office of personnel management , the u.s .

postal service , and the department of defense to create a pilot data exchange system to provide states access to wage record information on federal and military employment .

the system that began operating in november 2003 can help states obtain more complete employment outcome data on participants who exited job training programs because it provides information on federal employment that is not available in state ui wage records .

many states are using the system to help determine employment outcomes for job training programs , such as those funded under the workforce investment act .

however , only 3 of the 46 states we surveyed reported that they were routinely using this system to obtain employment outcomes for the taa program .

despite labor's efforts to improve data quality , most states would like more help .

most states reported that they do not currently have opportunities to share lessons learned with other states on topics related to taa data quality , such as how to use supplemental data , and they expressed interest in having such opportunities .

for example , 29 states told us they do not currently have opportunities to share lessons learned on data validation , and 44 states told us more opportunities to do so would be helpful ( see fig .

10 ) .

in response to an omb initiative , labor made changes to some of the taa performance measures and to taa reporting requirements in order to implement common measures ( see table 3 ) .

omb established a set of common performance measures to be applied to most federally funded job training programs that share similar goals .

labor further defined the common measures for all of its employment and training administration programs and required states to start reporting taa data under the revised requirements in fiscal year 2006 .

moving to common measures may increase the comparability of outcome information across programs and make it easier for states and local areas to collect and report performance information across the full range of programs that provide services in a one - stop system .

prior to common measures , many federal job training programs had performance measures that tracked similar outcomes but had variation in the terms used and the way the measures were calculated .

for example , the programs used different time periods to assess whether participants got jobs .

under common measures , the time period used to assess employment outcomes is uniform across all covered programs .

implementation of common measures involved some changes in the data states collect for the tapr: standardized exit definitions: labor's guidance on common measures provides for a clearer understanding of when taa participants should be exited from the program than did earlier taa guidance .

under labor's guidance , states must wait 90 days after participants receive their last service or benefit — from taa , wia , or other related programs — to record them as exiters .

prior to this change , states could exit participants without waiting 90 days .

most states reported that the guidance and training they received from labor provided a clear understanding of the definition of exit under common measures , but 7 states disagreed .

coordination of exit dates: under common measures , states are encouraged to establish a common exit date for each participant who is co - enrolled in more than one program .

for example , if a participant receives services under taa and under wia , then the two programs should use the same exit date for the participant .

coordinating exit dates improves data quality by avoiding the problem of counting a participant as unemployed in the program's performance measures when , in fact , the participant is still receiving services in another program and is not ready to be counted in the performance measures .

changes in it systems: a number of data fields were added or changed in the tapr as part of the new common measures policy , requiring states to add or change data fields in their it systems and to instruct staff on changes in data to be collected on participants and employment outcomes .

most states reported that the guidance and training they received from labor provided a clear understanding of the changes needed in the tapr to implement common measures ; however , 7 states disagreed .

although moving to common measures may ultimately make it easier for states to collect and report performance information across programs , most states reported that making changes to implement common measures had been a burden in terms of time and cost ( see fig .

11 ) , and often viewed coordinating exit dates as burdensome .

states were nearly evenly divided in their views , however , on whether they had been given sufficient time by labor to complete the changes .

nineteen states said they had not been given sufficient time , while 18 states said they had .

twenty - six states reported that they will have provided guidance to staff or changed data elements in their it systems by the time the first quarterly tapr is due in fiscal year 2006 ( see fig .

12 ) .

other states reported that they would have these changes completed sometime later in 2006 , while some states said they could not estimate when they will complete the changes .

coordinating exit dates was the change that states considered the most burdensome .

seventeen states were unable to estimate when they would be able to coordinate exit dates across programs .

in a previous study , we cautioned that rushed implementation of reporting changes may not allow states and local areas enough time to fully meet the requirements and could negatively affect the data quality of the information reported .

since the passage of the taa reform act of 2002 , the taa program has evolved to become one of the most important means to help the workers affected by our nation's trade policies rejoin our nation's workforce .

the program has seen substantial increases in the population it serves and in the funds available to serve them .

unfortunately , efforts to monitor the program's performance have not kept pace with the program's development .

four years after the passage of the reforms , we still do not know whether the program is achieving what lawmakers intended .

the taa program has suffered a history of problems with its performance data that have undermined the data's credibility and limited their usefulness .

and while we see that labor has taken some steps aimed at improving the performance data , the data remain suspect .

they fail to capture outcomes for some of the program's participants , and many participants are not included in the final outcomes at all .

these failures may have contributed to the program's poor performance in achieving its national goals .

labor lacks the authority to hold states accountable for their outcomes or for the quality of their data , and as a result , some states may not see the value of investing more effort to ensure their data are complete and accurate .

in truth , officials tell us the funding to support their efforts is small , and it fluctuates from year to year , making such an investment difficult to sustain .

but the success of the program is being judged by the outcomes the program achieves and whether or not it meets its goals .

the current budgetary environment makes it risky not to take all necessary steps to ensure that the outcomes are an accurate and credible reflection of the program's performance .

labor has taken a major step toward improving the quality of its performance data through its new data validation requirements .

states report that these requirements have significantly raised the awareness of data quality at the state and local levels – an essential component in any effort to improve the accuracy of the data .

but these efforts do not fully address all issues .

no steps have been taken to ensure that all participants are included in the taa performance data or that exit dates are adequately documented .

monitoring can help address data issues , but labor is just now developing a standard monitoring guide that would help ensure that key problems are identified during monitoring visits .

until these steps are complete , the data can not be verified and may remain incomplete .

providing opportunities for states to share lessons learned may make states more aware of effective approaches for ensuring data quality , and several states expressed an interest in more such opportunities .

labor has recently improved the availability of taa performance information by posting the information on its web site and by making some state - by - state performance data available .

however , the performance data are not as informative as they could be because they aggregate all participants and do not show the outcomes of participants based on the types of services they received .

as a result , policymakers lack the information they need to understand program participation and performance and to assess future needs .

while labor has taken steps to share information with states and to improve data quality , more work is needed .

to help ensure that taa participant data reported by states are consistent , complete , and accurate , labor should clarify through guidance and other communications with states that all participants who exit the program should be included in the tapr and the documentation needed to verify the training completion date ; ensure that the core monitoring guide currently under development for regional office site visits includes guidance for assessing whether states' data collection processes for performance reporting capture all participants ; and provide states with opportunities to share lessons learned with other states on issues that may affect data quality .

to make taa performance information more useful for program management , labor should provide this information by the type of services received by taa participants .

we provided a draft of this report to labor for review and comment .

in its comments , labor did not disagree with our findings and recommendations and said the report will be helpful in its continuing efforts to improve the quality of taa performance data .

labor noted that the issues raised in the report about administrative costs and the burden of new reporting requirements are compounded by having a workforce investment system that is duplicative in its service delivery design , resulting in separate record - keeping and reporting systems .

labor also identified a number of actions that it is taking to ensure that performance accountability is an expectation of the program .

a copy of labor's response is in appendix iv .

as arranged with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution of this report until 30 days from the date of this report .

at that time , we will send copies of this report to the secretary of labor , relevant congressional committees , and others who are interested .

copies will also be made available to others upon request .

the report is also available on gao's home page at http: / / www.gao.gov .

if you or members of your staff have any questions about this report , please contact me at ( 202 ) 512-7215 or nilsens@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix v .

we examined ( 1 ) whether the trade adjustment assistance ( taa ) performance data provide a credible picture of the program's performance , ( 2 ) what taa performance data labor makes available to the public and states and the usefulness of the data for managing the program , and ( 3 ) what labor is doing to address issues with the quality of taa data submitted by states .

to learn more about the factors that affect taa data quality and to learn what states are doing to ensure data quality , we conducted a web - based survey of state taa officials and conducted site visits in five states , where we interviewed state officials and visited local areas or one - stop centers .

we also collected information on the quality of taa data through interviews with department of labor officials in headquarters and all six regional offices , nationally recognized experts , and reviewed relevant literature .

our work was conducted between december 2004 and march 2006 in accordance with generally accepted government auditing standards .

to determine the factors that affect the quality of taa performance data , we conducted a web - based survey of workforce officials in the 46 states that were allocated taa funds in fiscal year 2005 , and we obtained a 100 percent response rate .

these officials were identified using labor's list of state taa officials .

we e - mailed the contacts , and they confirmed that they were the appropriate contact for our survey or identified and referred us to another person at the state level .

survey topics included ( 1 ) the current status of taa data collection and reporting systems , ( 2 ) implementation of the u.s. department of labor's data validation requirements , ( 3 ) state and local efforts to ensure the quality of taa data , and ( 4 ) the implementation of common measures .

the survey was conducted using a self - administered electronic questionnaire posted on the web .

we contacted respondents via e - mail announcing the survey , and sent follow - up e - mails to encourage responses .

the survey data were collected between november 2005 and january 2006 .

we received completed surveys from all 46 states that were allocated taa funding in fiscal year 2005 ( a 100 percent response rate ) .

we did not include washington , d.c. , and u.s. territories in our survey .

we worked to develop the questionnaire with social science survey specialists .

because this was not a sample survey , there is no sampling error .

however , the practical difficulties of conducting any survey may introduce errors , commonly referred to as nonsampling errors .

for example , differences in how a particular question is interpreted or in the sources of information that are available to respondents can introduce unwanted variability into the survey results .

we took steps in the development of the questionnaire , the data collection , and data analysis to minimize these nonsampling errors .

for example , prior to administering the survey , we pretested the content and format of the questionnaire with four states to determine whether ( 1 ) the survey questions were clear , ( 2 ) the terms used were precise , ( 3 ) respondents were able to provide the information we were seeking , and ( 4 ) the questions were unbiased .

we made changes to the content and format of the final questionnaire based on pretest results .

we also performed computer analyses to identify inconsistencies in responses and other indications of error .

in addition , a second independent analyst verified that the computer programs used to analyze the data were written correctly .

we visited five states — california , iowa , ohio , texas , and virginia — and traveled to local areas or one - stop centers in each of these states .

we selected these states because they represent different taa data collection approaches ( that is , states where data are entered into information technology systems at the local level and those where data are entered at the state level ) , received a relatively large share of taa funds in fiscal year 2005 , and are geographically dispersed .

from within each state , we judgmentally selected local areas to visit ( see table 4 ) .

in each state , we interviewed state taa officials about their collection and use of taa data , it systems used to compile taa performance data , and efforts to ensure the data are complete and accurate .

similarly , we interviewed local area officials about their collection and use of taa data .

information that we gathered on our site visits represents only the conditions present in the states and local areas at the time of our site visits , from january 2005 through october 2005 .

we cannot comment on any changes that may have occurred after our fieldwork was completed .

furthermore , we cannot generalize the findings from our site visits beyond the states and local areas we visited .

in our survey , states were asked whether the it system they use to compile data for the trade act participant report ( tapr ) currently captures program information for certain other labor programs or benefits .

the taa reform act authorizes up to $220 million per year for training under the taa program .

labor allocates 75 percent of the training funds to states according to a formula that takes into account each state's previous year allocations , accrued expenditures , and participant levels .

labor holds the remaining 25 percent of training funds in reserve to distribute to states throughout the year according to need .

to cover administrative costs associated with training under the taa program , labor allocates to each state additional administrative funds equal to 15 percent of its training allocation .

table 6 shows labor's initial 75 percent allocation for training and associated administrative expenses .

states also receive an additional 15 percent of any reserve ( 25 percent ) funding and job search / relocation allowances for program administration .

dianne blank , assistant director kathy peyman , analyst - in - charge in addition , the following staff made major contributions to this report: vidhya ananthakrishnan , melinda cordero , laura heald , adam roye , and leslie sarapu served as team members ; amanda miller and carolyn boyce advised on design and methodology issues ; rachael valliere advised on report preparation ; jessica botsford advised on legal issues ; lise levie verified our findings .

trade adjustment assistance: most workers in five layoffs received services , but better outreach needed on new benefits .

gao - 06-43 .

washington , d.c.: january 31 , 2006 .

workforce investment act: labor and states have taken actions to improve data quality , but additional steps are needed .

gao - 06-82 .

washington , d.c.: november 14 , 2005 .

workforce investment act: substantial funds are used for training , but little is known nationally about training outcomes .

gao - 05-650 .

washington , d.c.: june 29 , 2005 .

unemployment insurance: better data needed to assess reemployment services to claimants .

gao - 05-413 .

washington , d.c.: june 24 , 2005 .

workforce investment act: labor should consider alternative approaches to implement new performance and reporting requirements .

gao - 05-539 .

washington , d.c.: may 27 , 2005 .

trade adjustment assistance: reforms have accelerated training enrollment , but implementation challenges remain .

gao - 04-1012 .

washington , d.c.: september 22 , 2004 .

workforce investment act: states and local areas have developed strategies to assess performance , but labor could do more to help .

gao - 04-657 .

washington , d.c.: june 1 , 2004 .

national emergency grants: labor is instituting changes to improve award process , but further actions are required to expedite grant awards and improve data .

gao - 04-496 .

washington , d.c.: april 16 , 2004 .

workforce investment act: improvements needed in performance measures to provide a more accurate picture of wia's effectiveness .

gao - 02-275 .

washington , d.c.: february 1 , 2002 .

trade adjustment assistance: experiences of six trade - impacted communities .

gao - 01-838 .

washington , d.c.: august 24 , 2001 .

trade adjustment assistance: trends , outcomes , and management issues in dislocated worker programs .

gao - 01-59 .

washington , d.c.: october 13 , 2000 .

