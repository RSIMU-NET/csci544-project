in february 2009 , facing what was generally reported to be the most serious economic crisis since the great depression , congress enacted the american recovery and reinvestment act of 2009 ( recovery act ) to , among other things , preserve and create jobs , promote economic recovery across the nation , and invest in transportation and other infrastructure to provide long - term economic benefits .

the recovery act appropriated $48 billion for transportation investments , including $1.5 billion for discretionary grants available to state and local governments , including organizations such as transit agencies , port authorities , and metropolitan planning organizations , among others , and to be administered by the department of transportation ( dot ) for capital investments in surface transportation , including highway , transit , rail , port , and other projects .

the transportation investment generating economic recovery ( tiger ) discretionary grants were designed to fund merit - based projects expected to have a significant impact on the nation , a metropolitan area , or a region .

in making awards , the legislation directed dot to address several statutory requirements .

in december 2009 , congress appropriated $600 million to dot for a “tiger ii” discretionary grant program similar to the original tiger program's structure and objectives .

dot announced the projects selected for tiger grants in february 2010 and projects selected for tiger ii grants in october 2010 .

you expressed interest in dot's evaluation and selection process for the tiger grants and the extent to which information about that process was made public .

in response , we examined ( 1 ) the criteria and process established by dot to evaluate tiger applications and award grants ; ( 2 ) the outcomes of dot's process to evaluate tiger applications and award grants ; and ( 3 ) the extent to which dot communicated the tiger criteria , evaluation process , and outcomes to applicants and the public .

this report also addresses , in appendix i , lessons learned from tiger that were applied in tiger ii .

to carry out this work , we reviewed the act and its requirements for tiger grant awards and the department's criteria for selecting awardees as published in the federal register and other tiger guidance materials , such as the dot evaluation score sheets that defined what characteristics would meet each criterion .

we reviewed documentation such as the tiger grant selection process summary and dot's march 2009 financial assistance guidance manual , which provides guidance on discretionary grant processes .

we analyzed ( 1 ) available data from the applications such as the amount of the request , transportation mode , and region ; ( 2 ) the initial ratings from a competitive review focused on project merits ; ( 3 ) which applications were advanced for further review and which were not ; and ( 4 ) recommendations of senior staff that described the strengths and weaknesses of projects recommended for award .

however , because dot did not document its reasons for key decisions , our review was limited to draft minutes that were not finalized or approved and that summarized initial assessments of advanced projects .

to gain insight into award decisions , we asked dot officials to reconstruct and discuss why projects were recommended or rejected for award , and , while this offers some insight , such information has significant limitations .

specifically , it is testimonial in nature and reflects officials' recollections several months after tiger grants were announced .

it may therefore contain a greater level of uncertainty and error than documentation created while decisions were made .

we assessed dot's level of public communication regarding the criteria and evaluation process for tiger grants by comparing it to office of management and budget guidance on publishing selection criteria .

we also compared dot's communication of tiger grant awards to other recovery act discretionary grant programs .

finally , we reviewed tiger ii guidance and training resources to identify changes between tiger and tiger ii .

we also interviewed 8 of the 51 tiger awardees , selecting them based on funding level , region , transportation mode , and jurisdiction size .

we conducted this performance audit from june 2010 through march 2011 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

for more information on our scope and methodology , see appendix ii .

the recovery act provided the secretary of transportation $1.5 billion for the purpose of awarding discretionary grants on a competitive basis .

eligible projects included capital investments in roads , highways , bridges , or transit ; passenger and freight rail ; and port infrastructure , as well as bicycle and pedestrian - related improvements .

the tiger program's purpose was to fund merit - based projects that would provide a significant impact on the nation , a metropolitan area , or a region and required dot to develop criteria to evaluate the merits of and select grants that would meet the goals of the program .

the recovery act also directed the secretary to meet several statutory requirements in making the final award selections including: 1. ensuring an equitable geographic distribution of funds ; 2. achieving an appropriate balance in addressing the needs of urban and 3. giving priority to projects for which federal funding would be required to complete an overall financing package that includes nonfederal sources ; and 4. giving priority to projects that are expected to be completed within 3 years of enactment of the act and obligating all tiger funds by september 30 , 2011 .

the recovery act also allowed dot to provide up to $200 million to support projects eligible for federal credit assistance .

the legislation required that dot make individual awards of no less than $20 million and no more than $300 million .

however , the legislation gave the department discretion to waive the minimum grant size for the purpose of funding significant projects in smaller cities , regions , or states , and dot opted to do so in certain cases .

traditionally , federal surface transportation funding has been primarily delivered through formula grant programs — about $40 billion annually — based on distributions prescribed by federal statute .

in addition , to address concerns about the “equity” of how federal aid is distributed among states , congress has included legislative provisions for geographic distribution in every surface transportation reauthorization act since 1982 .

for highway programs , dot's distribution formulas include provisions to ensure that states receive a guaranteed portion — 92 percent since fiscal year 2008 — of the estimated share of taxes highway users in each state contributed for a subset of highway programs .

the grant funds are then administered by the state or passed through an intermediary or subrecipient , such as a local government .

compared with formula programs , discretionary grant programs are rarely used to distribute surface transportation funding .

in a discretionary grant program , agencies rely on a competitive process in which congress gives award discretion to federal agencies to review applications in light of legislative and regulatory requirements as well as published selection criteria established for a program .

the review process gives agencies the discretion to determine which applications best address the program requirements and are , therefore , most worthy of funding .

the tiger program was a new discretionary grant program for dot , wherein dot had to establish criteria and an evaluation process that could be used to assess applications from several different transportation modes .

by including the requirement that awards achieve an equitable geographic distribution , among others , dot had to design a process that addressed both competitive selection criteria and statutory requirements .

the recovery act set short time frames for dot to implement the tiger program so that these funds — like other programs in the recovery act — would produce a stimulative effect on the economy .

specifically , the act required dot to announce all projects selected to be funded by tiger grants by february 17 , 2010 , 1 year after enactment and to obligate all tiger funds by september 30 , 2011 .

dot published its notice of funding availability on june 17 , 2009 ; applications were due by september 15 , 2009 , and awards announced by the statutory deadline ( see fig .

1 for a timeline of tiger activities ) .

the consolidated appropriations act for fiscal year 2010 appropriated $600 million to dot for national infrastructure investment grants in support of a tiger ii discretionary grant program .

similar to the tiger program's structure and objectives , these grants were to be awarded on a competitive basis for projects that are expected to have a significant impact on the nation , a metropolitan area , or a region .

tiger ii had many of the same statutory requirements that tiger had , as well as some additional ones , including a requirement that dot ensure selection of a variety of transportation modes .

to meet the recovery act requirement that dot develop criteria to evaluate the merits of tiger program applications and select grants , dot published criteria in a may 2009 interim notice of funding availability after the passage of the recovery act , and in june 2009 , when dot published its final notice of funding availability , we evaluated the criteria .

we concluded that dot had followed key federal guidance and standards for developing selection criteria .

for example , dot's criteria clearly indicated that projects should produce long - term benefits such as improving the state of repair of existing transportation infrastructure , reducing fatalities and injuries through safety investments , and increasing economic competitiveness by improving the efficient movement of workers or goods .

in addition , a benefit - cost analysis was generally required to determine if a project's expected benefits outweighed its costs .

developing rigorous criteria for discretionary grants is important because criteria focus the competitive selection process and helps agencies , like dot , address national and regional priorities and achieve the highest possible return on federal investments .

as we have reported , many federal surface transportation programs do not effectively address key challenges because federal goals and roles are unclear , programs lack links to performance , and some programs do not use the best tools and approaches to ensure effective investment decisions .

for these and other reasons , surface transportation funding remains on gao's high - risk list .

our previous work has called for a more performance - oriented approach to funding surface transportation , and in particular policies that ensure that goals are well - defined and focused on the federal interest and that recipients of federal funds are accountable for results .

specifically , we have recommended that a criteria - based selection approach — like that developed in tiger — be used to direct a portion of federal funds in programs designed to select transportation projects with national and regional significance .

such an approach — one rarely used to fund surface transportation — represents a significant departure from the formula - based approach regularly used to fund the nation's surface transportation program .

formula programs distribute over $40 billion annually to states and urbanized areas for highway and transit projects ( compared with the $1.5 billion one - time appropriation provided for tiger ) .

in fiscal year 2009 , this included almost $36 billion for highway infrastructure projects through the federal highway administration ( fhwa ) and approximately $10 billion in transit grants to urbanized areas and states through the federal transit administration .

the federal - aid highway program in particular poses considerable challenges to introducing a merit - based performance orientation for selection of projects of national or regional significance .

this is because this program distributes funding through a complicated process in which the underlying data and factors are ultimately not meaningful because they are overridden by other provisions designed to yield a largely predetermined outcome — that of returning revenues to their state of origin .

moreover , once the funds are apportioned , states have considerable flexibility to reallocate them among highway and transit programs .

as we reported in june 2010 , this flexibility , coupled with a rate - of - return orientation , essentially means that the federal - aid highway program functions , to some extent , as a cash transfer , general purpose grant program .

this formula - based approach can potentially result in meritorious projects of national or regional significance — in particular those involving multiple modes of transportation or those that cross state boundaries — not competing well at the state level for available funds .

tiger selection criteria reflected federal interest in specific goals , such as improving the state of repair of transportation infrastructure .

specifically , dot developed and applied two primary criteria — ( 1 ) long - term outcomes and ( 2 ) job creation and economic stimulus — and two secondary criteria — innovation and partnerships .

dot further defined its primary and secondary criteria with the concepts described in table 1 to help tiger reviewers determine how well a proposed project aligned with each criterion .

dot described these criteria in its final notice of funding availability , noting that primary criteria were weighted more heavily than secondary criteria , while the concepts defining each selection criterion were weighted equally .

the criteria were designed to help dot reviewers and applicants determine which projects were closely aligned with the goals of the tiger program .

some criteria assessed the direct effects — such as reductions in travel time and the number of fatalities and injuries — that are common metrics used in evaluating the performance of transportation projects .

for example , to assess whether a project achieved a “state - of - good repair” within the long - term outcomes criterion , evaluators had to determine if a project was relevant to regional , state , or local efforts to maintain transportation facilities ; if failing to rehabilitate the condition of infrastructure would threaten future economic growth and stability ; and if a sustainable source of revenue was available for the long - term operation and maintenance of the infrastructure , among other issues .

the beartooth highway reconstruction project in park county , wyoming , a project awarded $6 million , proposed to improve the state of repair of a 7-mile segment of a highway , including replacing a critical bridge in deficient condition , connecting yellowstone national park with the shoshone national forest by completing its reconstruction .

fhwa deemed this segment of highway inadequate and substandard in 1994 .

other criteria were intended to help dot assess the potential for a project to produce indirect effects such as improved quality of life , coordinated economic development , and better land use .

one factor also within the long - term outcomes criterion — fostering livable communities or “livability” — represented a new focus for dot projects .

dot defined livability as: enhancing mobility through the creation of more convenient transportation options for travelers , increasing modal connectivity between various transit and other transportation options , improving accessibility to transportation for economically disadvantaged populations , and coordinating transportation and land - use planning decisions .

for example , the saint paul , minnesota , union depot multi - modal transit and transportation hub , a project awarded $35 million , was given funding to renovate the city's historic union depot to colocate amtrak , intercity bus carriers , local buses , light rail services , taxis , and bicycle accommodations , as well as offer new space for commercial development .

the award announcement indicated that colocating these transportation services would increase connectivity between transportation modes and create commercial space that would promote economic growth and redevelopment in the downtown area .

for more discussion of how dot defined its criteria , see appendix iii , which shows the score sheet evaluation teams used to assess applications .

to meet the recovery act's direction that the secretary meet several statutory requirements in making the final award selections , dot published and made potential applicants aware of these requirements in its notice of funding availability .

in addition , dot developed internal guidance to clarify these requirements in the award process .

for example , according to officials , dot defined achieving an equitable geographic distribution of funds by establishing four regions based on a methodology that accounted for population sizes , geographic proximities , and the existing distribution of federal surface transportation formula funds .

in addition , dot sought to ensure within regions that awards were not clustered in one or two states , but were reasonably well distributed within a region .

to give priority to projects for which federal funding would be required to complete an overall financing package , dot gave priority to projects that included significant state , local , or private co - investment , required projects to demonstrate “independent utility,” meaning that projects created a complete and operable segment that would produce significant transportation benefits upon completion , according to officials .

in some cases , this meant dot funded a project in its entirety , while in others it funded a segment of a larger application as long as that segment resulted in complete and operable infrastructure .

dot's process for competitively selecting applications involved several teams of reviewers — evaluation teams assessed and rated applications and a senior - level review team made final award recommendations .

in addition , other teams evaluated the consistency of the ratings and assessed the accuracy of applicants' economic analyses and project readiness .

the tiger selection process is described in figure 2 .

dot used 10 evaluation teams of five reviewers each — primarily career employees with technical knowledge — who represented the different dot operating administrations , including the federal highway administration , federal railroad administration , federal transit administration , the maritime administration , and the office of the secretary of transportation ( ost ) .

this team design meant that applications were reviewed by an intermodal team that included members with subject matter expertise from several different transportation modes .

although applications were assigned randomly , dot did ensure that at least one team member had expertise in the mode presented in the application .

the teams assessed over 1,450 applications that requested almost $60 billion , and each team evaluated approximately 150 applications .

evaluation team members were directed to select projects that they judged had the greatest potential to meet the primary and secondary criteria .

individual team members provided a rating of “highly recommended,” “recommended,” “not recommended,” or “negative” for each of the elements defining the primary and secondary criteria — for instance , state of good repair , livability , and others — and an overall score based on these criteria .

individuals also drafted short narratives supporting their assessment .

table 2 presents the definition of each adjectival rating once the team members completed their individual evaluations , the team met as a whole to come to consensus on an overall team rating for each application and a narrative describing their assessment of each project .

the evaluation teams prioritized applications receiving an overall team rating of highly recommended and advanced these projects to the review team for further evaluation .

in determining the overall project rating , dot's guidance encouraged evaluation teams to identify and advance for further review projects that best met the merit - based criteria .

these applications were to be ranked “highly recommended” and were to be subject to additional review by additional teams on a wide range of factors — a time - consuming process that needed to be reserved for a smaller group of applications .

dot's guidance to individual evaluation team members indicated they should in general give an overall rating of highly recommended to projects that receive a highly recommended in multiple selection criteria and that a negative score on any of the selection criteria reduced the likelihood that the project would receive a highly recommended overall rating .

furthermore , dot's guidance stated that evaluation teams generally should advance projects that received an overall highly recommended score from four to five of the individual team members .

those receiving three highly recommended overall scores were to be advanced only on a case - by - case basis in consultation with other teams involved in the review process .

projects receiving one to two highly recommended overall scores generally were not to be advanced .

finally , dot's guidance noted that evaluation teams should not advance any project unable to demonstrate a likelihood of significant long - term benefits in the long - term outcome criterion .

as the evaluation teams' primary responsibility was to conduct a merit - based technical review of applications based on the criteria dot developed , according to dot officials , they were not responsible for addressing other factors in the tiger review: the evaluation teams were directed to consider information presented in the applications — including project benefits and costs and the project's completion of national environmental policy act requirements — but not confirm its accuracy .

evaluation teams were told that separate economic analysis and environmental teams would determine the accuracy of the benefits and costs and would validate projects' environmental readiness .

the evaluation teams were not responsible for ensuring that applications selected would meet the recovery act's statutory requirements , including achieving an equitable geographic distribution of funds and balancing the needs of urban and rural communities .

the teams did contribute to prioritizing projects expected to be completed within the 3-year time frame as part of project readiness , but they did not have to ensure projects met this requirement .

finally , with regard to prioritizing applications in which tiger funding would complete a funding package , while the evaluation teams could make recommendations on funding levels and whether segments of a project ( rather than the entire project ) should be funded , determining what level of funding to present to the secretary of transportation as part of an award fell primarily to the senior - level review team .

a control and calibration team — led by a deputy assistant secretary for policy with two staff members from ost's office of policy — also reviewed and advanced applications , and it did so both during the evaluation teams' assessments as well as later in the process when the review team identified projects for award .

according to dot officials , the control and calibration team advanced applications primarily in two ways: it used a statistical analysis to assess the ratings across the 10 evaluation teams and ensure that projects of similar types and quality were advanced consistently to the review team .

this analysis was also intended to make certain that there were no significant disparities in ratings among the different transportation modes — an issue that , while not a requirement in tiger , officials believed was worth monitoring given tiger's unique approach .

the control and calibration team also advanced projects at the request of the review team .

in several cases , the review team asked to assess projects of similar types in an effort to ensure that the most meritorious projects of this type were selected for award .

for instance , the review team requested an analysis of the effect on port projects of the expansion of the panama canal as well as a side - by - side comparison of all streetcar applications and projects on indian reservations and federal lands .

the review team also asked the control and calibration team to identify additional projects to help them meet statutory requirements such as geographic distribution and providing some funding in the form of credit assistance .

in response , the control and calibration team , in consultation with the evaluation team leads , identified additional projects beyond those initially advanced by the evaluation teams for the review team to consider , which resulted in additional projects being advanced that received an overall ranking from the evaluation teams of recommended rather than highly recommended .

dot required applicants to include a description of the status of environmental approvals as well as information on the project's benefits and costs .

applications advanced to the review team were reviewed by an environmental analysis team that assessed each advanced project's ability to substantially meet federal environmental readiness requirements .

in addition , an economic analysis team composed of nine dot economists — including the chief economist and economists from relevant operating administrations — assessed the economic analysis from each advanced application to determine whether the analysis was “useful” or “not useful” in its presentation of information and variables considered and whether the total benefits of a proposed project were reasonably likely to outweigh its costs .

dot required applicants to provide different types of information of benefits and costs depending on the amount the application requested .

specifically , projects requesting more than $100 million were required to calculate the net benefits of a project , indicate the value assigned to qualitative benefits , and describe the methodology used to arrive at this calculation .

dot directed applicants requesting more than $20 million and less than $100 million to provide estimates of expected benefits in the five long - term outcomes .

applicants requesting less than $20 million did not have to submit a benefit - cost analysis .

the economic analysis and environmental analysis teams presented their findings to the review team , which considered this information along with other factors in its assessment of applications .

the review team consisted of 12 senior dot staff , including the deputy secretary , under secretary , three assistant secretaries , the chief of staff , the general counsel , and administrators from the cognizant operating administrations — the federal highway administration , federal railroad administration , federal transit administration , maritime administration , and the research and innovative technology administration .

this team assessed all applications advanced by the evaluation teams and control and calibration team .

the review team was responsible for addressing four broad areas: first , it was responsible for ensuring that the award recommendations made to the secretary , taken as a whole , met all statutory requirements , including ensuring an equitable geographic distribution of funds , balancing the needs of urban and rural communities , prioritizing projects for which federal funding would complete an overall funding package that included nonfederal sources , and prioritizing projects that could be completed within 3 years of the act's enactment .

second , it assessed the merits of advanced projects by considering the tiger criteria applied by the evaluation teams and whether project benefits outweighed costs .

it accomplished this by receiving technical presentations from the evaluation team leaders and the economic analysis team .

third , it had to ensure that potential awardees were in fact eligible , ready - to - go , and that information in the application — such as expected benefits — was accurate .

to accomplish this , the review team requested more information on some advanced projects .

for example , in some cases , validating environmental readiness required a follow - up conversation with applicants to obtain clarification about the documentation submitted or assurances provided in their applications .

fourth , it recommended to the secretary of transportation which projects to fund and whether an application should receive partial or full funding .

the review team's initial assessments were conducted during a series of meetings that occurred over about 2 months .

in each meeting , the review team evaluated about 6 to 12 projects , discussed project strengths and weaknesses , identified areas for clarification or follow - up , and ranked each project in a tier based on the likelihood that the team would fund the project .

at the conclusion of its assessment , the review team developed a memo with a final list of projects that it recommended for award .

this memo included a description of each project's strengths , benefits , and how the project aligned with tiger criteria .

this memo was sent to the secretary of transportation who approved all the recommended projects and announced the tiger recipients and award amounts in february 2010 .

of the 1,457 applications submitted , 8 percent or 115 applications received an overall team rating of highly recommended and were advanced by the evaluation team for further review .

these 115 applications made requests for funding that totaled about $7.7 billion — about five times the $1.5 billion available for award .

about 33 percent of the 1,457 applications received an overall team rating of recommended .

the remaining 59 percent received a not recommended or negative rating or were excluded from evaluation for reasons such as eligibility , readiness , or other factors that made the application not acceptable to receive funding .

table 3 shows how all applications were rated by the evaluation teams .

in addition to projects advanced by the evaluation team , the control and calibration team advanced 50 recommended projects and 1 not recommended project to the review team , for a total of 166 advanced projects .

as noted , the review team ultimately selected for approval by the secretary of transportation 51 of the 166 advanced projects for award .

the secretary approved awards for each of these 51 applications .

tiger awards were distributed across the country with 41 states and the district of columbia receiving awards and with roughly equal funding levels ( from 20 to 27 percent of funding ) going to the four geographic regions dot established , as shown in figure 3 .

awardees represented a balance between the needs of urban and rural communities , as both groups received awards in about the same proportion as applications submitted and advanced .

however , rural projects tended to receive smaller awards and received 11 percent of the total funds .

the average tiger award was just under $30 million .

the largest award was $105 million for a large freight rail project in two states that would improve intermodal domestic rail service .

the smallest award was $3.15 million for a project to improve a road and waterfront bike path in vermont .

figure 3 shows the distribution of awards by region , jurisdiction size , transportation mode , and funding level .

while there was no requirement to distribute awards across different modes of transportation , tiger funding supported highway , transit , rail , port , and other projects — including bridge replacements , streetcar lines , and bicycle - pedestrian networks ( see table 4 ) .

transit projects received the most funding with 12 projects receiving $469 million .

although tiger grants were not awarded to intercity passenger rail projects , freight rail projects received about 25 percent of the total award funds .

although these projects received less funding overall than transit , funding levels tended to be higher per project with 5 freight projects receiving a total of $354 million .

in addition , tiger - funded projects were eligible for federal credit assistance through the transportation infrastructure finance and innovation act ( tifia ) , which provides direct loans , loan guarantees , and standby lines of credit to finance surface transportation projects of national and regional significance .

tiger funds used for tifia grants allow dot to make a smaller financial commitment to support much larger projects — specifically , dot estimates that each dollar of federal funds can provide up to $10 in tifia credit assistance .

dot offered tifia awards to five applicants in the amount of either $10 million or $20 million each .

one applicant had applied for and received a tifia award , and four applicants , while applying for a regular grant , were offered an opportunity to use the grant funds as a tifia award , at their discretion .

three of these four applicants opted to take the award as a grant and one took a tifia award .

dot officials said that , as required by the recovery act and part of dot's partnership criterion , applicants who had secured funding commitments from third parties such as state and local government and private industry fared better in the tiger process .

specifically , dot noted in the review team's memo to the secretary that 11 of the 51 awardees had arranged funding partnerships for their projects and were seeking tiger funding to complete a funding package .

while all tiger awards were directed to projects that applicants indicated could be completed as a result of the award , these 11 awardees received 40 percent of the awarded funds .

see appendix iv for additional information on the awardees and selection process and appendix v for information on the status of obligations and outlays for tiger grants .

the review team selected 26 awardees from the pool of 115 highly recommended applications advanced by the evaluation teams' competitive review process .

these applicants received about $950 million of the funds .

the other 25 applications selected for award , which received about $549 million of tiger funds , were from the pool of applications advanced by the control and calibration team .

applications advanced by the control and calibration team included 50 that received an overall rating of recommended from the evaluation teams and one that received a not recommended rating: cincinnati's streetcar project .

dot officials said this project was advanced to the review team because it provided additional context for the review team's analysis of streetcar projects , and it was not awarded a tiger grant .

figure 4 shows the results of the tiger selection process , including applications advanced by the evaluation teams and the control and calibration team .

the recommended projects advanced by the control and calibration team tended to fare less well in the technical review process .

as mentioned earlier , each project received an overall rating from individual evaluation team members as well as a consensus overall rating from the team as a whole .

the recommended projects advanced by the control and calibration team not only received lower overall consensus ratings from the evaluation teams ( recommended versus highly recommended ) , they also received fewer overall highly recommended ratings from individual evaluation team members .

for example , as shown in table 5 , the 51 projects advanced by the control and calibration team received a highly recommended overall rating from individual team members less than one - fourth of the time .

by comparison , projects advanced by the evaluation teams received highly recommended overall ratings from individual team members about two - thirds of the time .

because the review team was responsible for considering a wider range of factors than the evaluation teams , it is not unreasonable to expect that the review team's deliberations could produce a different result .

however , while dot thoroughly documented the evaluation teams' assessments and the reasons for its decisions and the review team's memo to the secretary described the strengths and benefits of projects recommended for award , dot did not document the review team's reasons for its decisions , including the reasons for selecting recommended projects over highly recommended ones .

most significantly , dot did not document review team meetings in which final decisions to recommend or reject a project for award were made .

documentation of the review team's deliberations was limited to draft minutes from the team's initial assessments of advanced projects — a process that occurred in meetings held over a period of about 2 months .

the minutes were never finalized or approved and were provided to us in draft form .

we analyzed these draft minutes and found that they reflected questions review team members raised about the strengths and weaknesses of various applications — questions consistent with tiger criteria and requirements .

for instance , the review team raised questions about the following projects , none of which received an award: the extent to which financial commitments of project partners had been secured .

for instance , the coos bay rail line rehabilitation project in oregon proposed rehabilitating track so that a shortline railroad could serve regional industrial operations , distribution facilities , and marine terminals around the coos bay harbor and other locations in southwest oregon .

the project would also have reconnected these facilities to the national rail system .

the review team raised questions about the project's financial commitments — specifically , whether there would be any significant cost - sharing by the state or other commitments to the project .

whether projects were sufficiently ready - to - go .

for example , the north corridor commuter rail project in north carolina proposed to upgrade 25 miles of rail to permit faster passenger operations as well as construct new passenger and maintenance facilities and acquire additional equipment .

the review team was concerned that this project would require an environmental impact statement to satisfy the environmental readiness requirements , which could substantially delay the project's initiation .

whether a project's economic benefits were overstated .

the west shoreway project in cleveland , ohio , proposed to reconstruct 2.5 miles of limited access highway along cleveland's lakefront into a boulevard with six intersections , providing improved waterfront access .

however , the economic analysis team characterized the analysis provided by the applicant as “not useful” and therefore insufficient to demonstrate that the project's benefits exceeded its cost .

in response , the review team asked whether more data could be found on the potential benefits and economic merits of the project .

according to dot officials , producing a useful benefit - cost analysis was a challenge for many tiger applicants .

 ( see appendix i for a discussion of steps dot took to improve applicant benefit - cost analyses in tiger ii. ) .

our review of these narratives suggests that , on the whole , the team asked reasonable questions and raised some valid concerns about many of the projects they did not recommend for award .

however , dot officials told us that these questions did not necessarily reflect the reason a project was ultimately recommended or rejected for award .

furthermore , some of the draft minutes simply noted that the review team did not see what made a certain project more compelling than similar projects — a comment that yields limited insight into why certain projects were selected and others rejected .

to gain insight into the review team's final decisions , we asked dot officials with the control and calibration team overseeing the tiger process to reconstruct and discuss the reasons why projects were recommended or rejected for award by the review team .

while these discussions offered some insight , such information has significant limitations .

specifically , it is testimonial in nature and reflects officials' recollections from several months after the completion of the tiger grant awards .

it may therefore contain a greater level of uncertainty and error than documentation created while decisions were being made .

according to these dot officials , one important factor affecting award decisions was the need to achieve an equitable geographic distribution of funds ( which , as noted earlier , dot defined as distributing funding in roughly equal amounts across four regions and without concentrating projects in any one state within a region ) .

dot met this requirement by rejecting some highly recommended projects to limit the number of awards to regions that would have been overrepresented and by making awards to recommended projects in regions that would have been underrepresented .

specifically , officials stated that that 15 highly recommended projects in the west and the central regions were rejected to limit the awards to these regions .

in addition , although the evaluation teams advanced 23 highly recommended projects from the south , the review team recommended only 2 of these projects for award .

dot officials indicated that these projects were rejected for a wide range of reasons such as limited financial partnerships or the availability of other funding sources such as tolls or user fees to support the project , among others .

as a result , the south was underrepresented for awards .

to address this , officials told us they advanced 14 additional southern region applications that had received lower overall ratings of recommended from the evaluation teams , and 6 of these 14 recommended projects received an award .

while the dot's draft minutes and our discussions with ost officials provide some insight into the deliberations of the review team , because there was no internal documentation from the review team meetings in which final decisions to recommend or reject projects for award were made , dot cannot definitively demonstrate the basis for its award selections , particularly the reasons why recommended projects were selected for half the awards over highly recommended ones .

for example , without documentation dot cannot demonstrate why statutory requirements such as geographic distribution and other priorities such as projects being ready - to - go and documenting their benefit costs analysis could not have been achieved by selecting $1.5 billion of applications from among the $7.7 billion in highly recommended applications advanced by the evaluation teams .

as our previous work has noted , documentation of agency activities is a key part of accountability for decisions .

furthermore , dot's office of inspector general ( oig ) has published several documents in which it raised questions about dot's discretionary grant selections , noting that projects were not always selected based on the relative priority assigned in a technical review .

according to the oig , when decisions to fund projects deemed to be of lower - priority in a technical review over higher - priority projects , a more thorough review and analysis of project alternatives and documentation of the rationale used to support decisions are necessary .

dot's march 2009 financial assistance guidance manual also stresses the importance of documenting such decisions .

this manual provides a standardized set of procedures for dot in processing and awarding grants , and it states that decisions not to fund projects with the highest priority from a technical review shall be documented .

the absence of an insightful internal record of award decisions and the reasons why final selections differ from the priorities recommended from the technical review can give rise to challenges to the integrity of the decisions made .

dot's lack of documentation of key decisions — particularly those in which it selected recommended projects for award over those receiving a highly recommended rating in the technical evaluation — makes it vulnerable to criticism that projects were selected for reasons other than merit .

dot externally communicated information on the tiger evaluation criteria and selection process , and some of the applicants we interviewed , each of which received awards , said they understood the criteria and found dot's guidance helpful .

according to grant policies and guidance from the office of management and budget , funding announcements that clearly state selection criteria promote competition and fairness in the selection of grantees .

dot's notice of funding availability for tiger included information on all of the statutory requirements and competitive criteria that dot used to evaluate the applications , as well as the relative weights of the competitive criteria , and some of the applicants we interviewed specifically said they understood the criteria and found the information clear .

for example , a burlington vermont waterfront transportation improvements north project official said that they were able to find information on all of the criteria and application process through publicly available sources , including the dot web site that posted several “questions and answers” regarding tiger .

several applicants we interviewed said that dot officials responded to questions in writing online for the benefit of all applicants .

dot made less information publicly available on the outcome of its selection process — for instance , it did not publish the reasons for the review team's decisions or why some applications were selected while others were rejected .

however , in our review , we did not find any requirements or guidance instructing federal programs to publicly disclose the reasons for their selection decisions .

congress and the president have emphasized the need for accountability , efficiency , and transparency and have made these a central principle of the recovery act , but the act did not define the attributes of transparency or how deep into the deliberative process an agency's actions should be transparent .

to assess the extent to which dot publicly communicated outcome information , we compared the information tiger externally communicated to the information communicated by 22 other similar recovery act competitive grant programs ( for a list of these programs , see app .

ii ) .

only one of the programs communicated more outcome information on technical scores and comments .

although it was not required in the recovery act to do so , the department of education's race to the top grant fund published all of its ratings and decisions regarding its applicants on its web site , including the application , the score sheet summarizing how the application was rated , narratives on the application that describe the ratings , the application's progression through the selection process , and whether each applicant received an award .

in addition to these recovery act grant programs , we also compared the tiger program to the federal transit administration's discretionary new starts program — the federal government's primary program for supporting capital investments in rail and bus rapid transit systems .

like race to the top , dot's new starts program also published all scores .

however , the evaluations in these two programs were not structured identically to tiger .

specifically , new starts did not have a second round of review and used the ratings from its evaluative process as the basis for recommending awards to congress .

race to the top used a different approach from tiger to gain further insight into applicants being considered for award — namely , it invited small groups of applicants to give oral presentations to a panel before awards were finalized .

dot officials told us they took actions to provide feedback to applicants but have not yet developed a strategy for disclosing additional information to the public .

specifically , officials noted that they provided one - on - one discussions between dot staff and applicants that requested feedback on their tiger applications .

however , dot officials also told us they recognize that they will need to make the process more transparent .

for instance , officials told us they are exploring plans to increase the program's level of communication with the public for tiger ii and future discretionary grant programs , although they have not yet decided what additional information they would make available .

officials said they are considering providing a summary abstract for each tiger ii application that describes the project and its strengths and also indicates the rationale for why it was selected or not selected .

officials said this approach could increase transparency , show accountability for dot's decisions , and offer an opportunity to improve applications in subsequent discretionary programs .

however , dot officials also expressed concern that public disclosure of considerations or opinions — favorable or unfavorable — taken into account by individuals or groups during the application review and selection processes could hamper deliberation in future discretionary grant selection processes .

although dot is not required to make this kind of complete and detailed information public , in not doing so , it may be missing an opportunity to better meet congress' and applicants' needs .

tiger is a unique program that distributes surface transportation funds based on merit and performance across many modes of transportation on a competitive basis — a new approach for dot .

tiger also made federal investments in projects like ports and freight rail infrastructure that rarely compete for federal transportation funds .

congress expressed an interest in continuing this new approach when it enacted tiger ii , and dot has proposed a new $2 billion discretionary grant program in its fiscal year 2012 budget modeled after tiger .

were dot to make additional information on its selection decisions publicly available , congress would have more information to help them better understand the basis on which the funding is being distributed , and thus would have additional information about the merits of this new approach and more confidence in the outcome .

in addition , the demand for tiger funds was substantial , with over 1,450 applications received .

were dot to make additional information on its selection decisions publicly available , potential applicants would have better information on how to develop and submit well - developed projects that address significant regional and national transportation challenges .

the tiger program represented an important step toward investing in projects of regional and national significance on a merit - based , competitive basis .

allocating federal funding for surface transportation based on performance in general , and directing some portion of federal funds on a competitive basis to projects of national or regional significance in particular , is a direction we have recommended to more effectively address the nation's surface transportation challenges .

tiger — and the tiger ii program that followed — was a novel approach to funding surface transportation in that it distributed funds across many modes of transportation and allowed projects like ports and freight railroads that rarely compete for existing federal transportation funds to participate .

while congress , when it enacted tiger ii , and the administration have expressed an interest in this new approach , the role of discretionary grants in the funding the nation's overall surface transportation program is evolving .

formula funding is — and will likely continue to be — the primary mechanism for distributing federal funds for surface transportation .

congress has struck a careful balance in formula programs to achieve equity among the states in how surface transportation funds — in particular , highway funds — are distributed and to allow states to select projects that reflect state and local priorities .

there is a natural tension between providing funding based on merit and performance and providing funds on a formula basis to achieve equity among the states .

consequently , meritorious projects of national or regional significance , in particular those involving multiple modes of transportation or those that cross geographic boundaries , may not compete well at the state level for formula funds .

given that the recovery act was intended to create and preserve jobs and promote economic recovery nationwide , congress believed it important that tiger grant funding be geographically dispersed .

in the future , however , surface transportation competitive grant programs provide congress the opportunity to consider the appropriate balance between funding projects based on merit and performance and providing funds to achieve equity among the states .

tiger was a new program for dot , and the recovery act set short time frames for establishing and administering the program .

dot met these deadlines and developed a sound set of criteria to evaluate the merits of applications and select grants that would meet the goals of the program .

furthermore , it maintained good documentation of the criteria - based evaluation conducted by its evaluation teams in the technical review and effectively communicated information about its criteria to applicants — an important step in promoting competition and fairness .

by thoroughly documenting how its technical teams considered and applied the criteria , clearly communicating selection criteria to applicants , and publicly disclosing some information on the attributes of the projects that were selected , dot took important steps to build the framework for future competitive programs and its institutional capacity to administer them .

this foundation is important if there are going to be future rounds of tiger or similarly structured programs .

congress needs to have the best information on how well the tiger program has worked , and dot needs to gain the confidence of congress and the public so that it can fairly and expertly administer a multi - modal , multi - billion dollar discretionary program .

the absence of documentation — in particular , the lack of documentation regarding decisions to select recommended projects for half the awards over highly recommended ones — can give rise to challenges to the integrity of the decisions dot made and subject it to criticism that projects were selected for reasons other than merit .

documenting key decisions , as good internal control practices and dot's guidance already require , could provide a roadmap for administering future competitive grant programs and help build confidence in dot's institutional ability to administer this type of program .

furthermore , while federal agencies rarely publicly disclose the reasons for their selection decisions in a competitive review process , the uniqueness of the tiger approach and dot's limited experience with it suggests that publicly disclosing additional information about selection decisions would give congress a better basis to assess the merits of this new approach and the information it needs to judge whether and how to continue with it .

given dot's concerns about the potential effect on internal deliberations , the decision of what information to disclose publicly is best made by dot in consultation with the congress , balancing dot's concerns with the congress' need for information .

if congress enacts competitive discretionary grant programs such as the tiger program in the future , it may wish to consider balancing the goals of funding projects through merit - based selection with achieving an equitable geographic distribution of funds by establishing thresholds and other mechanisms to limit , as appropriate , the influence of geographic considerations .

to ensure that future rounds of the tiger program or other similarly structured competitive grant programs are accountable to congress , transparent to the public , and provide meaningful feedback to applicants , we recommend that the secretary of transportation ( 1 ) document key decisions for all major steps in the review of applications , particularly the reasons for acceptance or rejection of applications and decisions in which lower - rated applications are selected for award over higher - rated applications , and ( 2 ) in consultation with the congress , develop and implement a strategy to disclose information regarding award decisions .

gao provided dot with a draft of this report for its review and comment .

dot officials provided technical comments via e - mail which we incorporated as appropriate .

dot officials stated the department would consider our recommendations .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies of this report to congressional subcommittees with responsibilities for surface transportation issues and the secretary of transportation .

in addition , this report will be available at no charge on gao's web site at http: / / www.gao.gov if you or your staff have any questions about this report , please contact me at ( 202 ) 512-2834 or herrp@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made significant contributions to this report are listed in appendix vi .

the department of transportation ( dot ) identified several challenges during the transportation investment generating economic recovery ( tiger ) evaluation process that it sought to address as “lessons learned” in the tiger ii process .

in tiger , many projects were given a full review multiple times before dot determined their eligibility and readiness .

the evaluation teams tried to identify projects that were not eligible or were not ready - to - go with respect to environmental approvals or securing other financial commitments .

however , some of these applications still advanced to the review team and were thus reviewed again by the economic analysis team or the control and calibration team before their final status was determined .

the solution in tiger ii was to implement a pre - application process that required applicants to provide documentation that would determine if each project or planning activity was ( 1 ) eligible , ( 2 ) ready - to - go , and ( 3 ) had secured the necessary nonfederal funding match claimed in the application .

as stated in the tiger and tiger ii notice of funding availability ( nofa ) , dot officials required documentation such as project schedules , environmental and legislative approvals , state and local planning , and technical and financial feasibilities for review .

dot officials said this pre - application process provided more assurance that the final applications being reviewed were eligible and ready - to - go , which improved efficiency and allowed teams to focus on the merits of qualified applications .

a second challenge resulted from the fact that applications were randomly assigned to the 10 evaluation teams , which also caused dot to have to review them a number of times .

as a result of the random assignment , each evaluation team reviewed projects from a mix of transportation modes , which prevented a side - by - side comparison of the merits and benefits for similar types of projects .

although the evaluation teams assessed all applications and advanced only highly recommended projects for further review , the review team wanted to review certain projects that had significant similarities to ensure that the most meritorious projects had in fact been advanced .

for example , the control and calibration team advanced five recommended streetcar applications and several recommended port projects that cited benefits from the expansion of the panama canal .

the review team reevaluated them all to determine which projects were the most meritorious .

the solution in tiger ii was to assign similar types of projects to evaluation teams so that the initial review assessed the merits of applications from the same types of projects side - by - side at the beginning of the process .

projects advanced for further review were evaluated all together without respect for mode .

dot officials told us this change allowed them to substantially improve the efficiency of the review process and make awards expeditiously in tiger ii .

a third challenge in tiger was for dot to meet the statutory requirement to prioritize awards to projects for which federal funding would complete a funding package — a challenge , in part , because of the high demand for tiger funds and the statutory requirement that funds be equitably distributed across the nation .

in tiger , dot interpreted this requirement to mean that it would give priority to projects that included substantial co - investment , and that it would fund discrete project segments from within larger applications as long as these segments demonstrated “independent utility,” which dot defined as a segment of a larger application that provided significant transportation benefits and created an operable project when completed .

however , although the tiger nofa did state it would consider one or more components of a large project that met selection criteria , it did not explicitly state that dot would consider funding project segments .

further , dot officials said that the extent to which applications provided information on how projects could be segmented varied .

as a result , dot had to contact some applicants the review team was considering for award to discuss whether projects could be segmented to achieve operable and complete projects and at what funding level .

in tiger ii , dot provided explicit guidance in the nofa defining independent utility and the potential for large applications to receive partial funding .

further , tiger ii guidance requires the applicant to identify and clearly describe the benefits of each discrete project segment and how this segment aligns with selection criteria .

according to dot officials , a final challenge in tiger was that many applications evaluated by the economic analysis team were deemed to not have useful analyses of expected project benefits and costs .

further , dot economists stated that many applicants also substituted economic impact analyses , which typically focus on local and regional benefits rather than national benefits .

because of this , the economic analysis team individually assessed the economic analyses from the 166 advanced applications to determine the actual benefits and costs to present accurate information to the review team , which they stated was a time - consuming process .

dot officials thought the limited usefulness of applicants' economic analyses was largely a consequence of applicants lacking familiarity with how to properly conduct such analyses .

for tiger ii , dot provided specific benefit - cost guidance that roughly accounted for about one - third of the information in the tiger ii nofa .

dot also provided question and answer webinars on how to conduct a benefit - cost analysis .

lastly , dot provided training seminars for applicants explaining the differences between benefit - cost and other analyses , the standards for conducting proper benefit - cost analyses , and the characteristics of a useful benefit - cost analysis .

dot also indicated in these sessions and in its guidance that not including useful benefit - cost analyses might be the basis for denying an award .

as a result , dot officials hoped to improve the quality of the benefit - cost analyses applicants provided and that it would be able to conduct an efficient assessment of them .

to determine what criteria and processes were used in evaluating applications and making award selections , we reviewed goals and objectives for the tiger program provided in the law , the federal register , and dot documents .

we also reviewed guidance and documentation of training provided to individuals serving as reviewers in the grant evaluation process .

further , we reviewed prior gao work evaluating dot's tiger grant criteria and guidance developed by dot and the office of management and budget on leading practices for managing discretionary grant programs .

to describe the outcomes of dot's evaluation process , we requested documentation of the evaluation and review teams' assessments of applications .

due to the level of documentation dot maintained , our ability to analyze this information differed substantially between the two teams .

evaluation teams: dot maintained thorough documentation of the evaluation teams' reviews , including individual team member and team ratings , as well as associated narratives describing the strengths and weaknesses of each application .

we assessed the reliability of these data by interviewing the leaders of each of the 10 evaluation teams , as well as dot officials who helped develop the process for evaluation teams to record their assessments .

ratings of each application by each individual team member were recorded in spreadsheets along with narratives describing the individual team member's assessment .

then , when the entire evaluation team met to discuss scores and develop team ratings , these scores and accompanying narratives were also recorded in a spreadsheet .

we reviewed these data for missing information , errors , and other indicators of reliability .

we determined that the data were sufficiently reliable for the purposes of this report .

we used these data to summarize information on the initial pool of applicants , those advanced to the review team , and those selected for an award .

specifically , we categorized projects by award amount , region , transportation mode , jurisdictional size , and other measures to describe patterns in the characteristics of the projects and patterns of awards .

review team: dot provided draft minutes that were never finalized or approved from 15 of the 16 review team meetings .

in each of these meetings , the review team evaluated about 6 to 12 projects and made an initial assessment and as needed identified issues in need of follow - up , such as confirming financial commitments .

the minutes did not include what we understood was the final meeting to rate the remaining applications ( about 15 projects did not appear in the draft minutes ) .

the minutes also did not include information about the final award decisions .

because dot did not document the rationale for selecting recommended projects for award over highly recommended ones , to gain insight into award decisions , we asked dot officials to reconstruct and discuss why projects were recommended or rejected for award .

this approach provided some insight , but such information also has significant limitations .

specifically , it is testimonial in nature and reflects officials' recollections from several months after the completion of the tiger grant awards .

it may therefore contain a greater level of uncertainty and error than documentation created while decisions were being made .

we also examined the extent to which dot's competitive selection process helped dot to achieve statutory requirements for tiger as defined in the american recovery and reinvestment act of 2009 ( recovery act ) .

we accomplished this by analyzing data on geographic location , jurisdiction size , and other factors among applications submitted , advanced , and awarded .

we summarized information on the extent to which dot officials documented their decisions to advance applications for the next round of review , and to select applications for an award .

to determine the extent to which dot communicated the criteria , process , and outcomes to applicants and the public , we compared application review documents , including technical evaluation guidance and information used to make awards decisions , with information communicated to potential applicants through the federal register .

in addition , we interviewed dot program officials , including technical evaluation panelists , as well as examined outreach presentations and documentation to understand the level of communication between potential applicants and dot officials regarding the tiger process and outcomes .

we also interviewed a judgmental selection of tiger awardees to get their perspective on dot's level of communication .

we spoke to eight awardees because they could discuss the entire process and outcomes .

we judgmentally selected awardees based their funding level , region , transportation mode , and jurisdiction size .

because this was not a random or representative sample , the views of these applicants cannot be generalized .

we also reviewed other recovery act discretionary grant program web sites — 22 in total — as well as dot's new starts discretionary grant program to determine the types of information these programs make publicly available , and compared this level of communication to the tiger grant program .

table 6 lists these programs .

to determine what challenges dot faced and the steps dot took to address them in tiger ii , we interviewed relevant dot officials involved in the tiger evaluation process , including all 10 of the evaluation team leaders and 2 members of the review team .

we also reviewed dot webinars , reviewed guidance dot issued in the form of “question and answer” documents on the tiger web site , and reviewed supplemental guidance .

we also made comparisons between the tiger and tiger ii guidance documents to understand what had been changed or clarified from the first round of review to the second .

we conducted this performance audit from june 2010 through march 2011 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

dot's tiger program received 1,457 applications requesting almost $60 billion .

the applications were distributed among the regions with the south submitting both the highest number of applications and the highest percentage of the total funding request .

see table 7 for a summary of the regional distribution of the applications .

highway project applications by far represented the largest number of applicants by project type comprising over half the number of applicants and amount requested .

transit projects accounted for the second largest percentage with about 15 percent of applications and almost one - fifth of the amount requested .

see table 8 for a summary of the distribution of project types among the applications submitted .

considering the size of jurisdiction , urban areas made up the majority of applications and funding requests with rural areas representing slightly over one - quarter of applications and slightly less than one - quarter of funds .

from this initial applicant pool , dot officials from both the evaluation teams and the control and calibration team advanced 166 applications requesting approximately $11 billion in tiger funds for further review .

of these , dot advanced just over one - fifth of applications from the northeast , central , and south regions .

the west region , however , had more applications advanced than the other regions .

the northeast , central , and west regions requested around the same proportion of funds requested by forwarded applications , but the south requested substantially more , around one - third of the total .

the requested amounts for advanced projects were roughly in line with the funding requests for all applicants within each region .

as discussed in the report , decisions on which applications to advance were a combination of the applications' ratings against dot's selection criteria and other factors such as geographic distribution requirements .

see table 9 for a summary of the regional distribution of the advanced applications .

approximately 40 percent of the advanced applications were for highway projects .

transit projects were about one - quarter of the total advanced applications and requested funds .

rail , port , and other projects each had about one - tenth of applications forwarded .

these applicants also requested less funding overall .

see table 10 for a summary of the distribution of project types among the advanced applications .

both urban and rural applications were advanced in roughly the same proportion in number and funding level requested as they had applications submitted .

dot officials selected 51 projects to receive about $1.5 billion in tiger funds .

of the many characteristics of the tiger awardees , there was one discernable trend with respect to which projects were selected to receive the most funds .

dot officials said that awardees with significant leveraged funds from third parties fared well in the process .

for example , while dot noted leveraging or partnerships for 11 of the 51 awardees in its decision rationale document , these 11 awardees received 40 percent of the distributed funds .

dot officials said that this trend occurred because they selected applicants that could leverage funding from third parties , allowing dot to complete funding packages for more applicants .

in conjunction with the tendency to select leveraged projects , dot also awarded partial funding to all but six applicants .

the average amount of funds made available was about half of what had been requested with some applicants receiving only 3 percent of what they had requested .

however , dot officials said that all awards went to applicants that could complete a project with independent utility .

tiger awards ranged from 20 percent to 27 percent of funds awarded over the four geographic regions .

the four regions received roughly the same percentage of tiger funds with the northeast and the west receiving 27 percent each and the south receiving 20 percent .

of note , while the south requested 39 percent of funds in the initial application pool and 33 percent of funds for advanced applications , it ultimately received about one - fifth of the funding .

this was due in part to questions about the economic benefits of projects and additional funds of some highly recommended southern applications , as well as lower evaluative ratings for southern projects overall .

see table 11 for a summary of the regional distribution of the awardees .

funding awards among selected project types ranged from 7 percent to 31 percent .

for example , transit projects received about 31 percent of the total funds , whereas port projects received 7 percent of the total .

see table 12 for a summary of the distribution of project types among the tiger awardees .

there was no discernable trend for urban or rural projects in terms of the number of projects selected for funding , as both locality groups received funding amounts in about the same proportions as applications submitted and advanced .

however , rural projects tended to be smaller and received only 11 percent of the tiger funds .

as of february 2011 , dot had executed all but two of the 59 grant agreements and obligated $1,468 million in tiger funds .

in addition , dot has outlayed $39 million of the obligated funds .

dot delegated responsibility for completing grant agreements , obligating funds , and overseeing the projects to the operating administrations based on the project's transportation mode and the applicant .

the federal railroad administration ( fra ) and maritime administration have executed all of their grant agreements and obligated all of their funds .

the two outstanding grant agreements are both transportation infrastructure finance and innovation act ( tifia ) projects , which required additional time to complete .

for example , one project in colorado opted to use its $10 million grant as tifia assistance , and doing so required additional traffic and revenue studies before the agreement could be finalized .

recovery.gov tracks the amount of funds obligated by state , but not the grant agreements .

dot divided oversight responsibilities among the operating administrations , depending upon the transportation mode of the project in each grant agreement as well as prior institutional relationships between the applicant and dot .

specifically , dot considered the capacity of the operating administrations and whether there was an existing oversight relationship between a grantee and a federal agency .

for example , some rail projects were delegated to the federal highway administration ( fhwa ) because fhwa has existing relationships with the relevant states and freight railroads , and fra has limited capacity for overseeing grants , especially with the large volume of high speed and intercity passenger rail grants fra is overseeing .

also , projects such as improving grade crossings can be overseen by fhwa because fhwa has a history of oversight with these types of projects as they affect both rail and highways .

according to officials , dot is interested in performance measurement and is taking steps to begin building knowledge on this subject across the department .

our prior work has shown that measuring performance allows organizations to track the progress they are making toward their goals and gives managers crucial information on which to base their organizational and management decisions .

tiger presents an opportunity to focus on performance and results in transportation projects , and dot officials incorporated performance measurements into grant agreements .

officials believe that every tiger project can incorporate and collect performance measures , but regions and states have varying capabilities .

for example , localities with existing data collection programs and resources may be able to collect and manage performance information ; however , other localities may find such a task more challenging , according to dot officials .

in these cases , dot has asked these awardees to collect information that would serve as a precursor to performance measurements , which should help to build capacity and experience among these localities .

dot is currently developing and experimenting with the best methods for measuring objectives and collecting data , and it is working collaboratively with applicants to weigh different options for performance measurements .

in addition to the contact named above , gao staff who made major contributions to this report are steve cohen ( assistant director ) , joah iannotta ( analyst - in - charge ) , carl barden , aisha cabrer , david hooper , sarah jones , saraann moessbauer , amy rosewarne , and max sawicky .

