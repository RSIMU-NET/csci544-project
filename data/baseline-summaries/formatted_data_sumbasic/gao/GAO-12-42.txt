the environmental protection agency's ( epa ) integrated risk information system ( iris ) program supports epa's mission to protect human health and the environment by providing the agency's scientific position on the potential human health effects that may result from exposure to various chemicals in the environment .

iris was created in 1985 to help epa develop consensus opinions within the agency about the health effects from chronic exposure to chemicals , and its importance has increased over time .

the iris database contains quantitative toxicity assessments of the health effects of more than 550 chemicals and provides fundamental scientific components — qualitative hazard identification and quantitative dose - response assessment — of human health risk assessments .

epa's iris program develops new iris assessments and , as needed , updates existing iris values contained in the iris database .

these iris assessments , in turn , provide scientific input for risk management decisions , such as whether epa should establish air or water quality standards to protect the public from exposure to toxic chemicals or set cleanup standards for hazardous waste sites .

consequently , iris assessments are a critical component of epa's capacity to support scientifically sound decisions , policies , and regulations .

state and local environmental programs and some international regulatory bodies also rely on iris for managing their environmental protection programs .

in 2008 , we reported that the iris database was at serious risk of becoming obsolete because the agency had not been able to keep its existing assessments current , decrease its ongoing assessments workload to a manageable level , or complete assessments of the most important chemicals of concern .

in addition , we reported that as of december 2007 , most of the ongoing assessments being conducted at that time had been in process for more than 5 years and that some assessments of key chemicals — chemicals that are likely to cause cancer or other significant health effects — had been in process even longer .

for example , the formaldehyde and dioxin assessments had been ongoing for 11 and 17 years , respectively .

we also reported that new office of management and budget ( omb ) - required reviews of iris assessments by omb and other federal agencies — called interagency reviews — were conducted in a manner that limited the transparency and credibility of the assessments and hindered epa's ability to manage the iris assessment process .

because of these issues , we recommended that epa revise its iris assessment process to develop the timely chemical risk information the agency needs to effectively conduct its mission and to better ensure the development of transparent , credible chemical assessments .

epa issued a revised process in april 2008 that we concluded , in testimony before congress , would further exacerbate the timeliness and credibility concerns we had identified .

because the agency had not developed sufficient chemical assessment information to limit public exposure to many chemicals that may pose substantial health risks — and , in particular , because of epa's lack of responsiveness to our march 2008 recommendations — in january 2009 , we added epa's processes for assessing and controlling toxic chemicals to our list of areas at high risk for waste , fraud , abuse , and mismanagement or in need of broad - based transformation .

in response to our 2008 report and subsequent high - risk designation , epa revised its iris assessment process in may 2009 to , among other things , restore epa's control of the process and increase its transparency .

our biennial review of high - risk areas in 2011 concluded that the epa administrator needs to continue to demonstrate a strong commitment to and support of the iris program to ensure that epa's 2009 reforms are implemented effectively and that the program can routinely provide timely , transparent , and credible assessments .

in this context , you asked us to review epa's iris assessment process .

our objectives were to evaluate ( 1 ) epa's progress in completing iris assessments under the may 2009 process and ( 2 ) the challenges , if any , that epa faces in implementing the iris program .

in conducting our work , we analyzed epa's may 2009 assessment process ; data from fiscal year 1999 through september 30 , 2011 , on iris productivity , such as the number of iris assessments initiated and completed ; the status of iris assessments that are currently in progress ; and epa's goals for completing assessments .

to assess the reliability of the data , we conducted interviews and e - mail exchanges with epa officials about the data system , the method of data input , and internal data controls and documentation , among other things .

we found the data to be sufficiently reliable for the purposes of our report .

we also interviewed officials from epa's office of research and development's ( ord ) national center for environmental assessment ( ncea ) , which manages the iris program .

in addition , we interviewed officials from other federal agencies involved in the iris process — including omb and the department of defense ( dod ) — and groups that have knowledge of the iris program .

we did not evaluate the scientific content or quality of iris assessments , but we reviewed the suggestions to epa in peer review reports on overall improvements to the development of iris assessments and information on other issues affecting the iris program .

a more detailed description of our scope and methodology is presented in appendix i .

we conducted this performance audit from july 2010 to december 2011 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

this section discusses epa's risk assessment and risk management practices and the may 2009 iris process .

epa's iris program is an important source of information on health effects that may result from exposure to chemicals in the environment .

as figure 1 shows , the toxicity assessments in the iris database fulfill the first two critical steps of the risk assessment process — providing qualitative hazard identification and dose - response assessment ( see definitions below ) .

iris information can then be used with the results of exposure assessments ( typically conducted by epa's program or regional offices ) to provide an overall characterization of the public health risks for a given chemical in a given situation .

epa defines a risk assessment , in the context of human health , as the evaluation of scientific information on the hazardous properties of environmental agents ( hazard characterization ) , the dose - response relationship ( dose - response assessment ) , and the extent of human exposure to those agents ( exposure assessment ) .

in final form , a risk assessment is a statement regarding the probability that populations or individuals so exposed will be harmed and to what degree ( risk characterization ) .

the development of risk assessments is directly dependent on the development of toxicity assessments such as those developed by the iris program .

a typical iris toxicity assessment is based on two sequential analyses: qualitative hazard identification and quantitative dose - response assessment .

among other things , a hazard identification identifies health hazards that may be caused by a given chemical at environmentally relevant concentrations ; this identification describes the potential noncancer and cancer health effects of exposure to a chemical that research studies have suggested or determined .

for cancer effects , epa describes the carcinogenic potential of a chemical in a narrative which includes one of five weight - of - the - scientific - evidence descriptors , ranging from “carcinogenic to humans” to “not likely to be carcinogenic to humans.” the second analysis is the dose - response assessment , which characterizes the quantitative relationship between the exposure to a chemical and the resultant health effects ; this assessment describes the magnitude of hazard for potential noncancer effects and increased cancer risk resulting from specific exposure levels to a chemical or substance .

the quantitative dose - response analysis relies upon credible research data , primarily from either animal ( toxicity ) or human ( epidemiology ) studies .

the noncancer dose - response assessments may include  an oral reference dose ( rfd ) — an estimate of the daily oral exposure to a chemical that is likely to be without an appreciable risk of deleterious effects during a person's lifetime — expressed in terms of milligrams per kilogram per day and  an inhalation reference concentration ( rfc ) — an estimate of the daily inhalation exposure to a chemical that is likely to be without an appreciable risk of deleterious effects during a person's lifetime — expressed in terms of milligrams per cubic meter .

the focus of iris toxicity assessments has been on the potential health effects of long - term ( chronic ) exposure to chemicals .

according to omb , epa is the only federal agency that develops qualitative and quantitative assessments of both cancer and noncancer risks of exposure to chemicals , and epa does so largely under the iris program .

the risk characterization information , which is derived from toxicity and exposure assessments — exposure assessments identify the extent to which exposure actually occurs — can be used to make risk management decisions designed to protect public health .

for example , iris assessments support scientifically sound decisions , policies , and regulations under such key statutes as the clean air act , the safe drinking water act , and the clean water act , as well as for setting superfund cleanup standards of hazardous waste sites .

risk management , as opposed to risk assessment , involves integrating the risk characterization information with other information — such as economic information on the costs and benefits of mitigating the risk , technological information on the feasibility of managing the risk , and the concerns of various stakeholders — to decide when actions to protect public health are warranted .

more specifically , an initial risk management decision would be to determine whether the health risks identified in a chemical risk assessment warrant regulatory or other actions .

as a result , the development of iris assessments is of key interest to stakeholders , such as other federal agencies and their contractors , chemical companies , and others who could be affected if regulatory actions were taken .

that is , stakeholders could face increased cleanup costs and other legal liabilities if epa issued an iris assessment for a chemical that resulted in a risk management decision to regulate the chemical to protect the public .

epa's process for developing iris assessments — established in may 2009 — consists of seven steps .

in announcing its revised process in may 2009 , epa noted that the new process would ensure that the majority of assessments would be completed within 2 years ( 23 months ) — a significantly shorter time than the estimated completion time frame of about 6 to 8 years under the previous process .

we note that the seven steps are preceded by a literature search and data call - in , which is not included as part of the process or its time frames .

results of the literature search are posted on the iris website and announced in the federal register , along with a request for information — the data call - in — about any pertinent studies not listed .

according to epa officials , the literature search and data call - in are not part of the process because the agency does not dedicate full - time staff to them .

epa officials told us that after the literature search , they place iris assessments in one of three categories — standard , moderately complex , or exceptionally complex — on the basis of such factors as the number of available scientific studies on the chemical , the number of potential health effects identified in these studies , the staff resources required to complete the assessment , and the level of stakeholder interest .

however , this process , as written , does not distinguish among different types of assessments with varying complexity .

table 1 outlines the steps in the iris assessment process , along with the planned time frames established by epa .

all iris assessments undergo external peer review , but exceptionally complex assessments are generally peer reviewed by epa's science advisory board panels and in some cases by national academies panels .

these peer reviews typically require more planning and take longer than the reviews for less complicated assessments .

peer reviews for all other assessments are typically conducted by expert panels that are independently assembled by an epa contractor .

all panel members , including science advisory board and national academies panels , are composed of individuals with expertise in various scientific and technical disciplines who retain their primary involvement in academia , industry , state government , and environmental organizations .

as we reported in 2008 , an overarching factor that can affect epa's ability to complete iris assessments in a timely manner is the compounding effects of delays .

once a delay in the assessment process occurs — for example , suspending work on an assessment to wait for additional studies — work that has been completed can become outdated , necessitating rework of some or all of the steps in the assessment process .

even a single delay can have far - reaching , time - consuming consequences , in some cases requiring that the assessment process essentially start over .

epa's may 2009 iris assessment process addresses some of the problems we identified in our march 2008 report .

however , progress in other areas has been limited .

epa's initial gains in productivity under the revised process have not been sustained .

epa has not significantly reduced its workload of ongoing assessments , which would enable the agency to routinely start new assessments and keep existing assessments current .

epa has not met established time frames for iris assessment process steps .

epa has addressed concerns we raised in our march 2008 report regarding the transparency of the iris process .

since may 2009 , all federal agency and white house office comments from both the interagency science consultation and discussion ( steps 3 and 6b of the iris process ) are available to the public on epa's iris website .

in addition , epa has made publicly available documents that show epa's responses to selected “major” interagency comments for all draft iris assessments that have completed an interagency review step since june 2011 .

as we have previously reported , we believe that interagency coordination can enhance the quality of epa's iris assessments .

previously , omb considered its comments and changes , and those of other federal agencies , to be “deliberative” — that is , they were not part of the public record .

we believe the input from other federal agencies is now obtained in a manner that better ensures that epa's scientific analysis is given appropriate weight .

as a result , stakeholders , including epa regional and program offices , the public , and industry , can now see which other federal agencies comment and the nature of their comments , making iris assessments more transparent .

transparency is especially important because agencies providing input , such as dod and nasa , may have a vested interest in the outcome of the assessment should it lead to regulatory or other actions .

for example , these agencies may be affected by the potential for increased environmental cleanup costs and other legal liability if epa issued an iris assessment that resulted in a decision to regulate a chemical to protect the public .

officials we spoke with from other federal agencies — including dod , nasa , and the department of health and human services ( hhs ) — all agreed that making their comments publicly available was a good practice .

in addition , epa now manages the interagency science consultation and discussion ( steps 3 and 6b of the iris process , formerly omb - managed interagency reviews ) .

as we recommended in 2008 , the process now includes time limits for all parties , including omb and other federal agencies , to provide comments to epa on draft assessments .

prior to may 2009 , omb managed these steps , and epa was not allowed to proceed with assessments until omb notified epa that it had sufficiently responded to comments from omb and other federal agencies .

epa has also streamlined its iris process , as we recommended in our 2008 report , by consolidating some process steps and eliminating others that had provided opportunities for other federal agencies to suspend iris assessments to conduct additional research .

shortly after it implemented its revised iris assessment process in may 2009 , epa experienced a surge of productivity in terms of the number of iris assessments it issued .

specifically , from may 2009 through september 30 , 2011 , epa completed 20 iris assessments — more than doubling the total productivity it achieved during fiscal years 2007 and 2008 .

however , 16 of these were completed in the first year and a half of implementing the revised process , and productivity fell sharply during fiscal year 2011 , with epa issuing 4 iris assessments ( see fig .

2 ) .

in completing 4 iris assessments in fiscal year 2011 , epa fell significantly short of its original plan to complete 20 assessments — a goal that it had revised to 9 as of august 2011 .

in addition , epa is unlikely to meet its fiscal year 2012 goal of completing 40 assessments .

as of september 30 , 2011 , 12 of the 40 assessments that epa plans to complete in fiscal year 2012 are still being drafted ( step 1 of the iris process ) .

see appendix ii for the status of chemicals in the iris assessment process as of september 30 , 2011 .

on the basis of the planned time frames epa established under its revised process , once these 12 iris assessments are drafted , epa will require at least 345 days , or 11½ months , to complete the remaining iris process steps and issue the assessments — making it unlikely these will be completed in 2012 .

the increased productivity occurring after may 2009 does not appear to be entirely attributable to the revised iris assessment process .

according to our analysis of epa data , the agency's ability to complete more assessments was not due to a fundamental gain in how quickly assessments are completed , but rather to epa's ability to clear up the backlog of assessments that had undergone work under the previous iris process and had been delayed for multiple reasons .

most of the assessments completed from may 2009 through september 2011 had been in process 5 years or longer and thus had already passed through some key process steps prior to the implementation of the revised process .

in addition , most of these completed iris assessments were for standard and moderately complex assessments — that is , they were less challenging to complete than those for more complex chemicals .

specifically , 17 of 20 assessments issued from may 2009 through september 30 , 2011 , were in process for 5 years or longer , and 2 of the 20 were for exceptionally complex assessments ( see table 2 ) .

for example , 1 exceptionally complex assessment that epa did complete was for trichloroethylene ( tce ) .

for information on tce , as well as on some other key chemicals for which epa has not completed iris assessments , see appendix iii .

as of september 30 , 2011 , epa had 55 iris assessments ongoing and 14 on hold — down from the 88 assessments that were in various stages of development when it implemented its revised iris assessment process in may 2009 .

since may 2009 , epa has undertaken 6 new assessments , dropped 5 assessments that it determined were no longer required , completed 20 assessments , and continued to have 14 assessments on hold ( see table 3 ) .

according to epa officials , assessments that have been put on hold will be resumed when the agency has resources available to staff them .

however , this tally of iris assessments does not reflect the true extent of epa's workload or the backlog of demand for iris assessments .

beyond the 55 ongoing iris assessments and 14 on hold , the demand for additional iris assessments is unclear .

with existing resources devoted to addressing its current workload of ongoing assessments , epa has not been in a position to routinely start new assessments .

in late 2010 , for the first time since 2007 , epa solicited nominations for new iris assessments from epa program and regional offices , as well as from the public and federal agencies that participate in iris interagency reviews .

however , as of september 30 , 2011 , epa officials had not decided which chemicals to include on the iris agenda and thus include in their workload .

moreover , instead of nominating new chemicals for assessment in 2010 , one regional office requested that the iris program focus its efforts on completing assessments currently under way .

in addition , in 2007 , the office of air and radiation — which develops national programs , policies , and regulations for controlling air pollution and radiation exposure — requested that ongoing assessments be expedited for 28 chemicals that it identified as high - priority and required to fulfill its regulatory mandates .

as of september 30 , 2011 , 17 of the 28 assessments the office identified are ongoing , and 3 are on hold .

see appendix iv for epa's expected completion dates for iris assessments currently in the assessment process .

in addition , other assessments in the iris database may need to be updated .

as we reported in march 2008 , epa data from 2001 through 2003 indicated that 287 of the assessments in the iris database at that time may need to be updated .

in october 2009 , epa announced in the federal register the establishment of the iris update project .

the stated purpose of the project was to update iris toxicity values , such as oral reference doses or inhalation reference concentrations , that are more than 10 years old .

however , according to epa officials , since the project was announced , little progress has been made toward updating these assessments .

we note that even if epa were to overcome the significant productivity difficulties it has experienced in recent years and meet its goal of completing 40 assessments in fiscal year 2012 , it is not clear that this level of productivity would meet the needs of epa program offices and other users .

iris assessments have taken longer than the time frames established under the revised iris process .

since implementing the revised process , most iris assessments have exceeded the established time frames for each step of the process .

epa officials , however , told us that the time frames established for the steps in the revised iris assessment process apply only to standard assessments — and not to moderately or exceptionally complex assessments .

while epa officials have said that they are trying to hold moderately complex assessments to the established time frames , epa does not have a written policy that describes the applicability of these time frames or written criteria for designating iris assessments as standard , moderately complex , or exceptionally complex .

consequently , it is unclear how iris users will know which assessments are standard , moderately complex , or exceptionally complex and what time frames will be required to complete them .

according to epa officials , ncea management , including iris program management , is tracking the time it takes for each iris assessment to complete the various steps in the iris process .

however , epa has not yet analyzed these data to determine whether the time frames established for each step or the overall 23-month process are realistic .

according to epa officials , they do not yet have the data needed to draw conclusions regarding completion time frames .

on the basis of our analysis of epa data , however , we determined how long each iris process step was taking on average compared with the time frames established for each step under the may 2009 revised process .

we performed this analysis for the 55 assessments that were ongoing , as of september 30 , 2011 , and the 20 assessments that were completed after may 2009 .

because none of the 20 iris assessments completed from may 2009 through september 2011 were initiated after the revised process was implemented , it was not possible to fully evaluate the extent to which epa is adhering to the new 23-month time frame .

further , we combined our analysis of steps 4 and 5 because epa data do not indicate when step 4 ends and when step 5 begins , and we combined steps 6 and 7 for the same reason .

according to our analysis , on average , assessments of all types have taken longer than the established time frames for every step in the iris process ( see table 4 ) .

some other federal agencies that participate in interagency reviews expressed concern that in some cases time and resource constraints present challenges as they try to meet epa's time frames for the two interagency review steps .

in addition to the time limits established under the revised process , in an effort to increase productivity and complete more iris assessments , epa officials said that , beginning in april 2011 , the agency began to accelerate the number of draft assessments sent through the interagency review steps .

however , officials from other federal agencies — including hhs and dod — told us that they have advised epa that the accelerated pace of interagency reviews in the second half of fiscal year 2011 strained their resources .

in addition , the official from nasa told us that not only are the increased pace of reviews straining the agency's resources , but that it has also affected the ability to provide in - depth independent technical reviews and interagency comments .

epa officials also told us that the interagency reviewer at nasa is so concerned with the pace of the interagency reviews under the revised process that nasa officials have asked omb to form an interagency work group to discuss the reviews .

epa faces both long - standing and new challenges in implementing the iris program .

first , the national academies has identified recurring issues with how the iris program develops and presents its assessments and has suggested improvements .

second , epa has not consistently provided reliable information on ongoing and planned iris assessments to iris users .

third , unresolved discussions with omb regarding epa's responses to data quality act challenges may impede epa's ability to issue completed iris assessments .

the national academies and epa's science advisory board have identified several recurring issues with how epa develops and presents iris assessments .

for example , in april 2011 , the national academies in its independent scientific review of epa's draft iris assessment of formaldehyde provided a critique of epa's development and presentation of draft iris assessments .

overall , the national academies noted some recurring methodological problems in the draft iris assessment of formaldehyde .

in addition , in the report the national academies also identified recurring issues concerning clarity and transparency with epa's development and presentation of its draft iris assessments .

the national academies and science advisory board have identified similar clarity and transparency issues in peer review reports over the past 5 years .

some of these reports stated that epa should more clearly explain its reasons for including or excluding the scientific studies supporting draft iris assessments .

in addition , some reports stated that epa should more transparently present its justifications for its methodological approaches .

independent of its review of the formaldehyde assessment , the national academies also provided a “roadmap for revision” that made suggestions for improvements to the iris draft development process , during which epa selects and evaluates evidence ( the literature search ) and drafts an assessment ( step 1 ) .

the national academies' “roadmap for revision” suggested that epa take the following steps , among others:  use clear , standardized methods to identify and select study evidence ;  use a standardized approach to evaluate and describe study strengths and weaknesses and the weight of evidence , describe and justify the assumptions and models used , and adopt a standardized approach to characterizing uncertainty factors ; and  present methodology and findings more clearly and more concisely through better use of graphics and tables and use a template to facilitate a consistent description of the approach to study selection .

the national academies' report on the draft iris assessment of formaldehyde specifically noted that epa should not delay the finalization of the assessment in order to implement any of the suggestions it made regarding the overall iris process .

as of september 30 , 2011 , according to epa officials , the agency is revising the assessment in response to the national academies' suggestions , but the status page on epa's website for formaldehyde lists “tbd” — to be determined — as the posting date for the final assessment .

in july 2011 , epa announced that it planned to respond to the national academies' suggestions by implementing changes to the way it develops draft iris assessments .

in announcing the planned changes , epa stated that it would take the following actions:  enhance its approach to identifying and selecting scientific study  provide more complete documentation of its approach to evaluating scientific study evidence and indicate which criteria were most influential in its evaluation of the weight of evidence ; and concisely state the criteria used to include or exclude studies , continue to use existing iris guidelines to enhance the clarity and transparency of its data evaluation and presentation of findings and conclusions , eliminate the need for some report text using standardized tables , and portray toxicity values graphically .

according to epa officials , in implementing these changes , epa will subject those assessments that are in earlier stages of development to more extensive changes than those in later stages of development .

it will change the latter “as feasible” without repeating steps in the overall iris process .

however , epa has not provided a more detailed description of how the national academies' suggestions will apply to each of the assessments in its current inventory of iris assessments .

without a more precise description of which drafts would be considered “in the earlier stages of development” or what “more extensive changes” would entail , it is too soon to provide a comprehensive assessment of epa's approach .

in addition , it is not transparent to stakeholders and other interested parties which assessments will be subject to these changes and which will not .

epa established the board of scientific counselors ( bosc ) , an advisory committee composed of non - epa technical experts from academia , industry , and environmental communities , to provide independent advice , information , and suggestions to the office of research and development ( ord ) research program — which houses the iris program .

part of bosc's mission is to evaluate and provide advice concerning the utilization of peer review within ord to sustain and enhance the quality of science in epa .

it is unclear if bosc will have a role in reviewing epa's response to the national academies' suggestions .

we reviewed two iris assessments — one completed and one still in draft form — that reflect changes epa has made in response to the national academies' suggestions .

first , for its assessment of urea , finalized in july 2011 , epa streamlined the report by moving sections of text from the body to an appendix , which shortened the body of the assessment from 89 to 57 pages , making it more concise .

in addition , we reviewed the draft iris assessment of diisobutyl phthalate ( dibp ) , which epa provided to us , that was undergoing agency review ( step 2 ) and reflects some of the national academies' suggestions regarding presentation .

for example , it includes ( 1 ) descriptive and pictorial explanations of the study selection methods used ; ( 2 ) tables that , among other things , give side - by - side comparisons of studies considered in determining the oral reference dose for the chemical ; and ( 3 ) brief descriptions of the strengths and weaknesses of various studies considered .

for these two assessments , it appears that epa has begun to enhance the readability of its assessments by making changes that appear to be in line with the suggestions made by the national academies .

epa uses two primary mechanisms — the iris agenda and a website feature known as iristrack — to make information on the status of iris assessments available to epa program and regional offices , other federal agencies , and the public .

epa has not effectively used these two mechanisms , or a third that we recommended in march 2008 — that the agency provide a 2-year notice of its intent to assess specific chemicals — to consistently provide reliable information on iris assessments to stakeholders and other interested parties .

first , epa has not published an iris agenda in the federal register — identifying the chemicals that epa plans to assess ( both new and ongoing assessments ) — since it announced its 2008 iris agenda in december of 2007 .

epa started developing an annual iris agenda and providing it to the public in a notice in the federal register in 1997 .

in late 2010 , epa began to solicit nominations for its fiscal year 2011 iris agenda from its program and regional offices , as well as from the public and federal agencies that participate in iris interagency reviews .

however , as of september 30 , 2011 , epa had not published its fiscal year 2011 agenda .

in addition , some of the information provided in the federal register notices about the iris agenda has been incomplete .

for example , an october 2010 federal register notice contained a list of chemicals currently on the iris agenda but did not distinguish between chemicals the agency was actively assessing and those it had designated for future assessment .

we reported on similar issues in march 2008 — noting that epa had identified some assessments that had been suspended as ongoing .

second , epa has not kept information on the status of the individual ongoing assessments up to date in iristrack — an issue we also reported on in 2008 .

epa's iristrack , a feature of its website , is intended to provide stakeholders and other interested parties with information on draft iris assessments — specifically , estimated start and end dates for steps in the iris process .

for example , officials from the office of water indicated that that their office relies heavily on iristrack for information about the status of iris assessments .

in addition to not updating iristrack , epa recently removed some key information presented in iristrack .

now , in some cases , the iristrack date for the beginning of draft development ( step 1 ) understates the actual duration of an assessment — sometimes by many years .

for example , iristrack indicates that draft development for the dioxin assessment began in the first quarter of fiscal year 2009 ; in fact , as we have reported , epa has been assessing dioxin since 1991 .

iristrack also understates the duration of assessments of other chemicals of key concern — for formaldehyde , naphthalene , and tce .

therefore , current and accurate information regarding when an assessment will be started , which assessments are currently ongoing , and when an assessment is projected to be completed is presently not publicly available .

third , epa does not provide at least 2 years' notice of its intent to assess specific chemicals , as we recommended the agency should do in our march 2008 report to give agencies and other interested parties the opportunity to conduct research needed to fill any data gaps .

in commenting on our report , epa agreed to consider our recommendation , and epa officials recently stated that they continue to agree with it , but as of september 30 , 2011 , the agency still had not taken steps to implement our recommendation .

discussions between epa and omb officials regarding data quality act challenges related to specific draft iris assessments have been ongoing for over a year without resolution .

if these unresolved discussions continue , they could contribute to delays of iris assessments .

according to epa officials , omb would like to return to its role in the prior assessment process , in which it managed interagency reviews and made the final determination as to whether epa has satisfactorily responded to comments from omb and officials in other federal agencies .

the information quality act , commonly called the data quality act , requires omb to issue governmentwide guidelines to “ensure and maximize the quality , objectivity , utility , and integrity of information , including statistical information,” disseminated to the public .

in addition , it required agencies to issue their own guidelines , set up administrative mechanisms to allow affected parties to seek the correction of information they considered erroneous , and report periodically to omb information about data quality act challenges ( “requests for correction” of agency information ) and how the agencies addressed them .

under its data quality guidelines , when epa provides opportunities for public participation by seeking comments on information , such as during a rulemaking , the agency uses the public comment process rather than epa guidelines to address concerns about epa's information .

this is consistent with omb's data quality guidelines , which encourage agencies to incorporate data quality procedures into their existing administrative practices rather than create new and potentially duplicative or contradictory processes .

according to epa's data quality guidelines , the public comment period serves the purposes of the guidelines , provides an opportunity for correction of information , and does not duplicate or interfere with the orderly progression of draft documents through an established process — in this case , the iris assessment process .

that is , the external peer review and associated public comment period provide the public with the opportunity to raise questions regarding the quality of the information being used to support an iris assessment .

according to epa officials , federal agency responses to data quality challenges must be cleared by omb before epa sends responses to the parties filing challenges — although no law or guidance specifically provides for such reviews .

in june and july 2010 , epa received data quality act challenges regarding two draft iris assessments .

according to epa officials , in its draft responses to these data quality challenges , epa declined to review the challenged data because , according to agency policy , draft iris documents are not subject to data quality challenges .

epa used the same approach in 2006 when responding to and declining a similar challenge regarding a draft iris assessment ; at that time , omb approved the epa response .

epa sent its draft responses for the two more recent challenges to omb for approval in september 2010 and january 2011 .

epa's data quality guidelines set a goal of responding to data quality act challenges within 90 days , but epa officials said that they still await a decision by omb .

according to epa officials , omb is delaying a decision because omb would like to return to its role in the prior assessment process , in which it managed interagency reviews and made the final determination as to whether epa has satisfactorily responded to comments from omb and officials in other federal agencies .

epa officials told us that as of september 30 , 2011 , the issues regarding data quality challenges had not delayed the progress of draft iris assessments .

meanwhile , omb staff told us that they had sent comments to epa on the draft responses and await epa's reply to their comments .

it appears to gao that the discussions of these issues between epa and omb officials , which have been ongoing for over a year without resolution , have highlighted the agencies' differences regarding the revised iris process .

if these differences persist , they could contribute to the compounding effects of delays in the iris process , discussed here and in our earlier work .

for example , in august 2011 , epa received a third data quality challenge on an assessment that epa had expected to be finalized at the end of fiscal year 2011 .

for reasons that remain unclear , epa now projects that this assessment will not be finalized until fiscal year 2012 .

we note that the assessment had entered the interagency science discussion ( step 6b ) in july 2011 .

epa asked interagency reviewers to submit written comments by august 26 , 2011 , but as of september 2011 , omb reviewers have not yet submitted comments .

the iris process reforms epa began implementing in may 2009 have restored epa's control of the process and increased its transparency .

notably , epa has addressed concerns we raised in our march 2008 report regarding the transparency of comments from both the interagency science consultation and discussion steps in the iris process .

making these comments publicly available is especially important because agencies providing input may have a vested interest in the outcome of the assessment should it lead to regulatory or other actions .

as a result , stakeholders , including epa regional and program offices , the public , and industry , can now see which other federal agencies comment and the nature of their comments , making iris assessments more transparent .

in addition , epa now manages the interagency science consultation and discussion steps and has streamlined the iris process .

progress in other areas , however , has been more limited .

for example , even for its less challenging assessments , epa took longer than its established time frames for accomplishing steps in the revised process — calling into question the feasibility and appropriateness of the established time frames in the iris assessment process for standard assessments .

thus , the established time frames may not be feasible .

it is also unclear whether the established time frames apply to moderately complex assessments because epa does not have a written policy that describes the applicability of the time frames , although epa officials said they are trying to hold moderately complex assessments to the 23-month time frame .

similarly , epa does not have written criteria for designating iris assessments as standard , moderately complex , or exceptionally complex .

we note that epa has not analyzed the time frames to determine whether the actual time taken for each step of the overall 23-month process is realistic .

such an analysis would provide more accurate information for epa to use in establishing time frames for these assessments .

not having established time frames for these assessments also creates uncertainty for many stakeholders with significant interest in iris assessments .

epa also faces both long - standing and new challenges in implementing the iris program .

notably , the national academies and science advisory board have identified recurring issues of clarity and transparency of draft iris assessments .

consequently , as part of its independent scientific review of epa's draft iris assessment of formaldehyde , the national academies also provided suggestions in a “roadmap for revision” that included suggestions for improving epa's development and presentation of draft iris assessments in general .

the report identified recurring methodological issues with how the iris program develops and presents its assessments and suggested improvements .

epa announced that it intends to address the issues raised in the national academies' report but has not publicly indicated how these proposed changes would be applied to its current inventory of iris assessments .

many of the issues raised in the national academies' report have been brought to the agency's attention previously .

it is unclear whether any independent entity with scientific and technical credibility , such as epa's board of scientific counselors , will have a role in reviewing epa's planned response to the national academies' suggestions to ensure that epa addresses these long - standing issues .

in addition , epa has not addressed other long - standing issues regarding the accuracy and availability of information on the status of iris assessments to iris users — including stakeholders such as epa program and regional offices , other federal agencies , and the public .

for example , since 2007 , epa has not published in the federal register an iris agenda that includes information on chemicals the agency is actively assessing or when it plans to start assessments of other listed chemicals .

the agency also has not updated iristrack to display all current information on the status of assessments on the iris agenda , including estimated start dates and end dates of steps in the iris process .

in addition , epa has recently removed some key information presented in iristrack that showed the duration of iris assessments .

now , in some cases , the iristrack date for the beginning of draft development underestimates the actual duration of an assessment — sometimes by many years .

therefore , current and accurate information regarding when an assessment will be started , which assessments are currently ongoing , and when an assessment is projected to be completed is presently not publicly available .

finally , as we recommended the agency should do in our march 2008 report , epa does not provide at least 2 years' notice of its intent to assess specific chemicals , which would give agencies and other interested parties the opportunity to conduct research needed to fill any data gaps .

to improve epa's iris assessment process , we are making the following six recommendations: to better ensure the credibility of iris assessments by enhancing their timeliness and certainty , we recommend that the epa administrator require the office of research and development to  assess the feasibility and appropriateness of the established time frames for each step in the iris assessment process and determine whether different time frames should be established , based on complexity or other criteria , for different types of iris assessments , and should different time frames be necessary , establish a written policy that clearly describes the applicability of the time frames for each type of iris assessment and ensures that the time frames are realistic and provide greater predictability to stakeholders .

to better ensure the credibility of iris assessments by enhancing their clarity and transparency , we recommend that the epa administrator require the office of research and development to submit for independent review to an independent entity with scientific and technical credibility , such as epa's board of scientific counselors , a plan for how epa will implement the national academies' suggestions for improving iris assessments in the “roadmap for revision” presented in the national academies' peer review report on the draft formaldehyde assessment .

to ensure that current and accurate information on chemicals that epa plans to assess through iris is available to iris users — including stakeholders such as epa program and regional offices , other federal agencies , and the public — we recommend that the epa administrator direct the office of research and development to  annually publish the iris agenda in the federal register each fiscal indicate in published iris agendas which chemicals epa is actively assessing and when epa plans to start assessments of the other listed chemicals ; and  update iristrack to display all current information on the status of assessments of chemicals on the iris agenda , including projected and actual start dates , and projected and actual dates for completion of steps in the iris process , and keep this information current .

we provided a draft of this report to the administrator of epa for review and comment .

in written comments , which are included in appendix v , epa agreed with the report's recommendations .

epa also provided technical comments , which we incorporated into the report as appropriate .

specifically , epa agreed that it should ( 1 ) assess the feasibility and appropriateness of the established time frames for each step in the iris assessment process by using available program performance measures collected since the current iris process was established to evaluate determine whether different time frames should be established , based on complexity or other criteria , for different types of iris assessments , ( 2 ) determine if different time frames are necessary , establish a written policy that clearly describes the applicability of the time frames for each type of iris assessment and ensures that the time frames are realistic and provide greater predictability to stakeholders , ( 3 ) continue to implement the 2011 suggestions for improving iris assessments in the “roadmap for revision” presented in the national academies' peer review report on the draft formaldehyde assessment and seek independent review through the science advisory board to ensure that the agency is addressing the recommendations , ( 4 ) annually publish the iris agenda in the federal register each fiscal year , ( 5 ) indicate in published iris agendas which chemicals epa is actively assessing and when epa plans to start assessments of the other listed chemicals , and ( 6 ) update iristrack to display all current information on the status of assessments of chemicals on the iris agenda , including projected and actual start dates , and projected and actual dates for completion of steps in the iris process , and keep this information current .

as agreed with your office , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the administrator of epa , the appropriate congressional committees , and other interested parties .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff members have any questions about this report , please contact me at ( 202 ) 512-3841 or trimbled@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix vi .

this appendix details the methods we used to assess the environmental protection agency's ( epa ) management of its integrated risk information system ( iris ) .

for this review , our objectives were to evaluate ( 1 ) epa's progress in completing iris assessments under the may 2009 process and ( 2 ) the challenges , if any , that epa faces in implementing the iris program .

to address these objectives , we reviewed relevant epa documents , including documents outlining the april 2008 and the may 2009 versions of the iris assessment process ; documents related to iris performance metrics ; chemical nomination forms submitted by epa regional and program offices , federal agencies , and others ; and documents and other information on the public epa website , including the iris database and iristrack , the assessment tracking system available at the iris website .

in addition , we reviewed other relevant documents , including federal register notices announcing , among other things , iris agendas , as well as documents related to epa's meetings with other federal agencies involved in interagency reviews of draft iris assessments .

we did not evaluate the scientific content or quality of iris assessments ; however , we did review the national academies' peer review report on the draft iris assessment of formaldehyde to evaluate their suggestions for overall improvements to the development of iris assessments and other peer review reports by the national academies and epa's science advisory board to evaluate their suggestions for improvements to draft iris assessments .

in addition , we interviewed officials from epa's national center for environmental assessment ( ncea ) who manage the iris program , including the acting center director , the associate director for health , and the iris program acting director , to obtain their perspectives on , among other things , the may 2009 iris process and the effects of changes from the april 2008 iris process , the extent to which epa has made progress in completing timely , credible chemical assessments , challenges epa faces in completing assessments , and epa's process for responding to data quality act challenges .

we interviewed officials from epa's office of environmental information to obtain their perspectives on epa's process for responding to data quality challenges .

we also attended two board of scientific counselors ( bosc ) meetings to understand the board's role in providing advice , information , and recommendations about the office of research and development ( ord ) research programs , including iris .

for the first objective , we obtained and analyzed data from fiscal year 1999 through september 30 , 2011 , including data , spreadsheets , project plans , and other documents used in iris assessment planning , development , and completion .

from the data we gathered , we analyzed information on iris productivity , including information on the number of iris assessments completed and initiated , the status of iris assessments that are currently in progress or on the iris agenda , and the completion dates and durations of iris assessment process steps completed or currently in progress for given chemical assessments .

in addition , we assessed the reliability of the data we received from epa for our first objective .

our assessment consisted of interviews and e - mail exchanges with epa officials about the data system , the method of data input , and internal data controls and documentation , among other areas .

we also corroborated the data with other sources , where possible .

for example , we verified the information provided in tables of iris assessment start dates and completion dates of iris assessment process steps through interviews and e - mail exchanges with the ncea officials responsible for maintaining these data .

through our assessment , we determined that the data were sufficiently reliable for our purposes .

for the second objective , we interviewed the chair of the national academies committee to review epa's draft iris assessment of formaldehyde to obtain his perspective on the national academies' suggestions for improvements to the iris assessment process .

we interviewed officials from the office of management and budget's ( omb ) office of information and regulatory affairs ( oira ) to obtain their perspectives on interagency review of draft iris assessments , omb's process for responding to epa with regard to data quality act challenges , and omb's process for reviewing and approving epa guidance documents .

in addition , we interviewed officials from the department of defense ( dod ) , the national aeronautics and space administration ( nasa ) and the department of health and human services ( hhs ) — including representatives from the centers for disease control and prevention's national center for environmental health ( nceh ) / agency for toxic substances and disease registry ( atsdr ) , national institute for occupational safety and health ( niosh ) .

we also interviewed hhs officials from the food and drug administration ( fda ) ; the national institute of environmental health sciences / national toxicology program and the office of the secretary .

we also interviewed representatives from a chemical industry group and a nonprofit research and educational organization .

we conducted this performance audit from july 2010 to december 2011 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

step 2 – epa internal review ( 8 assessments in step ) step 3 – interagency science consultation ( 2 assessments in step ) step 4 – external peer review and public comment ( 9 assessments in step ) step 5 – epa draft revision ( 7 assessments in step ) step 6a and b – final epa review / interagency science discussion ( 1 assessment in step ) step 7 – completion and posting ( 4 assessments in step ) benzopyrene polychlorinated biphenyls ( pcbs ) ( noncancer ) arsenic , inorganic ( cancer ) dichloro - benzene , 1,2- dichloro - benzene , 1,3- dichloro - benzene , 1,4- formaldehyde polycyclic aromatic hydrocarbon ( pah ) mixtures tetrachloro - dibenzo - p - dioxin , 2,3,7,8- ( dioxin ) dichloro - methane ethylene oxide ( cancer ) tetrachloro - ethylene ( perchloro - ethylene or perc ) tetrahydrofuran ( thf ) .

 trichloroethylene ( tce ) .

in september 2011 , epa finalized and posted an iris assessment of tce , 13 years after initiating it .

a degreasing agent used in industrial and manufacturing settings , tce is a common environmental contaminant in air , soil , groundwater , and surface water .

tce has been found in the drinking water at camp lejeune , a large marine corps base in north carolina .

it has also been found at superfund sites and many industrial and government facilities , including aircraft and spacecraft manufacturing operations .

tce has been linked to cancer , including childhood cancer , and other significant health hazards , such as birth defects .

in 1995 , the international agency for research on cancer , part of the world health organization , classified the chemical as “probably carcinogenic to humans,” and in 2000 , the department of health and human services' national toxicology program concluded that tce is “reasonably anticipated to be a human carcinogen.” however , between 1989 and september 2011 , the iris database contained no quantitative or qualitative data on tce .

because of questions raised by peer reviewers about the iris cancer assessment for tce , epa withdrew it from the iris database in 1989 and did not initiate a new tce cancer assessment until 1998 .

in 2001 , epa issued a draft iris assessment of tce that characterized tce as “highly likely to produce cancer in humans.” the draft assessment was peer reviewed by a science advisory board panel and released for public comment .

in the course of these reviews , issues arose concerning , among other things , epa's use of emerging risk assessment methods and the uncertainty associated with these new methods .

to help address these issues , epa and other agencies sponsored a national academies peer review panel to provide guidance .

the national academies panel recommended in its 2006 report that epa finalize the draft assessment using available data , noting that the weight of evidence of cancer and other health risks from tce exposure had strengthened since 2001 .

nonetheless , the tce assessment was returned to draft development .

it then underwent a third peer review , again through science advisory board , which issued its report in january 2011 .

epa revised the draft in response to the science advisory board's comments and , in september 2011 , finalized and posted the tce assessment .

 dioxin .

the term “dioxin” applies to a family of chemicals that are often the byproducts of combustion and other industrial processes .

complex mixtures of dioxins enter the food chain and human diet through emissions into the air that settle on soil , plants , and water .

when animals ingest plants , commercial feed , and water contaminated with dioxins , the dioxins accumulate in the animals' fatty tissue .

epa's initial assessment of dioxin , which was published in 1985 , focused on the dioxin tcdd ( 2,3,7,8-tetrachlorodibenzo - p - dioxin ) , which animal studies dating to the 1970s had shown to be the most potent cancer - causing chemical studied to date .

epa began work on updating this assessment in 1991 .

from 1995 through 2000 , the revised draft assessment underwent a full peer review , as well as three peer reviews of key segments of the draft .

as we have reported previously , epa officials said in 2002 that the version of the revised assessment then in progress would conclude that dioxin may adversely affect human health at lower exposure levels than had previously been thought , and that most exposure to dioxins occurs from eating such american dietary staples as meat , fish , and dairy products .

epa was moving closer to finalizing the assessment when , in 2003 , a congressional appropriations committee directed the agency not to issue the assessment until it had been peer reviewed by the national academies .

the national academies issued its peer review report in july 2006 .

epa then revised the draft assessment in response to the national academies' recommendations , releasing it for public comment in may 2010 and sending it to the science advisory board for another peer review .

in august 2011 , the science advisory board panel issued its peer review report .

having been tasked with evaluating epa's responses to the national academies review and its incorporation of studies that have become available since 2006 , the panel concluded that the draft iris assessment of dioxin was “generally clear , logical , and responsive to many but not all of the suggestions of the nas.” among other things , the science advisory board panel recommended that epa discuss both linear and nonlinear models for cancer risks associated with dioxin exposure in its revised report .

three days after the science advisory board issued its report , epa announced that it would split the dioxin assessment into two parts , completing the noncancer portion of the assessment first and then addressing the science advisory board's comments and completing the cancer portion of the assessment .

epa expects to complete the noncancer portion of the dioxin assessment by january 2012 , and states that it will complete the cancer portion as expeditiously as possible thereafter .

the effort to update the assessment of dioxin , which could have significant health implications for all americans , has been ongoing for 20 years .

 formaldehyde .

formaldehyde is a gas widely used in such products as pressed wood , paper , pharmaceuticals , leather goods , and textiles .

the iris database currently lists formaldehyde as a “probable human carcinogen” ; however , the international agency for research on cancer classifies it as “carcinogenic to humans.” in june 2011 , the department of health and human services' national toxicology program classified formaldehyde as “known to be a human carcinogen” in its report on carcinogens .

the report stated that epidemiological studies “have demonstrated a causal relationship between exposure to formaldehyde and cancer in humans” — specifically , nasopharyngeal cancer , sinonasal cancer , and myeloid leukemia .

the current iris assessment of formaldehyde dates to 1989 , when the cancer portion of the assessment was issued , and 1990 , when the noncancer portion was added .

the last significant revision of the formaldehyde assessment dates to 1991 .

as we have reported previously , epa began efforts to update the iris assessment of formaldehyde in 1997 .

in 2004 , epa received a congressional directive to await the results of a national cancer institute study that was expected to take , at most , 18 months before finalizing the draft assessment .

that study was completed in may 2009 , and in june 2010 , epa released the draft assessment , which assessed both cancer and noncancer health effects , to the national academies for peer review .

in may 2011 , the national academies published its peer review report .

as of september 30 , 2011 — 14 years after epa began work to update the iris formaldehyde assessment — the agency had indicated no timetable for finalizing the assessment .

continued delays in the revision of the iris assessment of formaldehyde have the potential to affect the quality of epa's regulatory actions .

for example , in august 2011 , epa announced a proposed rule under the clean air act related to certain emissions from natural gas processing plants .

because a newer iris assessment of formaldehyde has not been completed , the proposed rule relies on the existing iris value for formaldehyde , last updated in 1991 .

epa had expected to complete the formaldehyde assessment by the end of fiscal year 2011 , but withdrew the projected completion date from the iris website after the publication of the national academies' peer review report on the draft assessment .

as of april 2011 , epa expected to complete the formaldehyde assessment in the fourth quarter of fiscal year 2011 .

however , as of september 30 , 2011 , the iris website provided no projected completion date for the assessment .

 tetrachloroethylene ( perc ) .

tetrachloroethylene — also called perchloroethylene or perc — is a manufactured chemical used in , for example , dry cleaning , metal degreasing , and textile production .

perc is a widespread groundwater contaminant and the national toxicology program has determined that it is “reasonably anticipated to be a human carcinogen.” currently , the iris database contains only a noncancer assessment based on oral exposure to perc , posted in 1988 ; it gives no information on potential cancer effects or potential noncancer effects associated with inhalation of perc .

epa began work to update this assessment , and to include information on cancer and noncancer inhalation risk , in 1998 .

as we have reported previously , epa completed its internal review of the draft perc assessment in february 2005 and the interagency review in march 2006 .

however , when the assistant administrator of epa's office of research and development requested that additional analyses be conducted , epa was delayed in sending the draft assessment to the national academies for peer review .

in june 2008 , epa sent the draft assessment to the national academies , which released its peer review report in february 2010 .

epa is in the process of responding to the national academies' suggestions , 13 years after the agency began work on the draft perc assessment .

as a result , iris users , including epa regional and program offices , continue to lack both cancer values and noncancer inhalation values to help them make decisions about how to protect the public from this widespread groundwater contaminant .

epa had expected to complete the perc assessment by the end of fiscal year 2011 , but as of september 30 , 2011 , it had not done so .

 naphthalene .

naphthalene is used in jet fuel and in the production of such widely used commercial products as moth balls , dyes , insecticides , and plasticizers .

the current iris assessment of naphthalene , issued in 1998 , lists the chemical as a “possible human carcinogen” ; since 2004 , the national toxicology program has listed it as “reasonably anticipated to be a human carcinogen.” as we have reported previously , epa began updating the cancer portion of its naphthalene assessment in 2002 .

by 2004 , epa had drafted a chemical assessment that had completed internal peer reviews and was about to be sent to an external peer review committee .

once it returned from external review , the next step , at that time , would have been a formal review by epa's iris agency review committee .

if approved , the assessment would have been completed and released .

however , in part because of concerns raised by dod , omb asked to review the assessment and conducted an interagency review of the draft .

in their 2004 reviews of the draft iris assessment , both omb and dod raised a number of concerns about the assessment and suggested to epa that it be suspended until additional research could be completed to address what they considered to be significant uncertainties associated with the assessment .

although all of the issues raised by omb and dod were not resolved , epa continued with its assessment by submitting the draft for external peer review , which was completed in september 2004 .

however , according to epa , omb continued to object to the draft iris assessment and directed epa to convene an additional expert review panel on genotoxicity to obtain recommendations about short - term tests that omb thought could be done quickly .

according to epa , this added 6 months to the process , and the panel , which met in april 2005 , concluded that the research that omb was proposing could not be conducted in the short term .

nonetheless , epa officials said that the second expert panel review did not eliminate omb's concerns regarding the assessment , which they described as reaching a stalemate .

in september 2006 , epa decided , however , to proceed with developing the assessment .

by 2006 , the naphthalene assessment had been in progress for 4 years , and epa decided that the noncancer portion of the existing iris assessment was outdated and needed to be revisited .

having made this decision , the agency returned both portions of the assessment , cancer and noncancer , to the drafting stage .

we reported in march 2008 that epa estimated a 2009 completion date for the naphthalene assessment .

as of september 30 , 2011 , however , the assessment remained in the draft development stage , even though epa program offices had identified the naphthalene assessment as a high - priority need for the air toxics and superfund programs .

as of september 30 , 2011 , epa expects to complete the naphthalene assessment in the third quarter of fiscal year 2013 .

 royal demolition explosive .

this chemical , also called rdx or hexahydro - 1,3,5-trinitro - 1,3,5-triazine , is a highly powerful explosive used by the u.s. military in thousands of munitions .

currently classified by epa as a “possible human carcinogen,” this chemical is known to leach from soil to groundwater .

rdx can cause seizures in humans and animals when large amounts are inhaled or ingested , but the effects of long - term , low - level exposure on the nervous system are unknown .

as we reported in march 2008 , as is the case with naphthalene , the iris assessment of rdx could require dod to undertake a number of actions , including steps to protect its employees from the effects of this chemical and to clean up many contaminated sites .

we reported at that time that epa had started an iris assessment of rdx in 2000 , but it had made minimal progress on the assessment because epa had agreed to a request by dod to wait for the results of dod - sponsored research on this chemical .

in 2007 , epa resumed work on the assessment , although some of the dod - sponsored research was still outstanding at the time .

epa decided to suspend work on the assessment in 2009 in order to focus on assessments that were further along in the iris process .

according to epa's project plan for rdx , in march 2010 , epa received a letter from dod requesting that epa complete the assessment .

in addition , in 2010 , epa's superfund program labeled the rdx assessment as a high priority because of the presence of the chemical at federal facilities .

in june 2010 , epa renewed work on the rdx assessment , but as of september 30 , 2011 , it remained in the draft development stage ( step 1 ) .

an epa official told us in october 2011 that epa plans to contact dod officials to confirm that the draft assessment of rdx adequately captures the findings of the dod - sponsored research .

in addition , the epa official said that the agency plans to contact officials at hhs's agency for toxic substances and disease registry to ensure that the two agencies have coordinated research efforts on this chemical .

epa projects that it will finalize the assessment of rdx in the first quarter of fiscal year 2013 .

in addition to the individual named above , diane lofaro , assistant director ; christine fishkin , assistant director ; summer lingard ; mark braza ; jennifer cheung ; nancy crothers ; lorraine ettaro ; robert grace ; gary guggolz ; richard p. johnson ; michael kniss ; nadia rhazi ; and kiki theodoropoulos made key contributions to this report .

also contributing to the report were tim bober , michelle cooper , anthony pordes , benjamin shouse , jena sinkfield , and nicolas sloss .

