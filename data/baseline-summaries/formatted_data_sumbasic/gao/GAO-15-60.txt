geostationary environmental satellites play a critical role in our nation's weather forecasting .

these satellites — which are managed by the department of commerce's national oceanic and atmospheric administration ( noaa ) — provide information on atmospheric , oceanic , climatic , and solar conditions that help meteorologists observe and predict regional and local weather events .

they also provide a means of identifying the large - scale evolution of severe storms , such as forecasting a hurricane's path and intensity .

noaa , through collaboration with the national aeronautics and space administration ( nasa ) , is procuring the next generation of geostationary weather satellites , called the geostationary operational environmental satellite – r ( goes - r ) series .

the goes - r series consists of four satellites and is to replace the current series of geostationary environmental satellites as they reach the end of their useful lives .

this new series is expected to provide the first major improvement in the technology of goes instruments since 1994 and , as such , is considered critical to the united states' ability to maintain the continuity of data required for weather forecasting through the year 2036 .

noaa is facing a potential gap where it may not have a backup satellite in orbit between now and the launch of the first goes - r satellite .

because of the criticality of satellite data to weather forecasting , the likelihood of data gaps in noaa's satellite programs , and the potential impact of a gap on the health and safety of the u.s. population and economy , we added mitigating gaps in weather satellite data to our high risk list in 2013 .

this report responds to your request that we review noaa's goes - r program .

specifically , our objectives were to ( 1 ) assess progress on the goes - r program with respect to planned schedule , cost , and functionality ; ( 2 ) assess efforts to identify and address issues discovered during integration and testing ; and ( 3 ) evaluate the likelihood of a gap in satellite coverage and analyze the adequacy of contingency actions in place to prevent or mitigate such a gap .

to assess noaa's progress in developing goes - r with respect to cost , schedule , and functionality , we analyzed monthly program status briefings to identify current status , recent development challenges , and both expected and potential changes in functionality .

we compared current and past status briefings to determine delays over time to key milestones .

we also analyzed cost reserve and earned value data information to understand the program's current cost posture .

to assess noaa's efforts to identify and address issues discovered during integration and testing , we analyzed defect management policies and practices against criteria from industry best practices .

we also compared defect trend data and metrics over time , and interviewed contractor officials responsible for testing and defect management .

to ensure the reliability of cost and defect data , we compared data across monthly reports and other agency data sources , compared formulas from the gao cost guide to the program's earned value management approach , and sought corroboration from agency and contractor officials .

to evaluate the likelihood of a gap in satellite coverage and analyze contingency actions , we analyzed program documentation to determine the likely length of a gap , and followed up on our previous effort to compare the goes - r contingency plan to best practices in contingency planning identified by leading organizations .

we also interviewed noaa and goes - r program officials regarding program status , defect management , and contingency planning .

we conducted this performance audit from january 2014 to december 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

see appendix i for a complete description of our objectives , scope , and methodology .

since the 1970s , geostationary satellites have been used by the united states to provide meteorological data for weather observation , research , and forecasting .

noaa's national environmental satellite , data , and information service is responsible for managing the civilian operational geostationary satellite system , called goes .

geostationary satellites can maintain a constant view of the earth from a high orbit of about 22,300 miles in space .

noaa operates goes as a two - satellite system that is primarily focused on the united states ( see fig .

1 ) .

these satellites provide timely environmental data about the earth's atmosphere , surface , cloud cover , and the space environment to meteorologists and their audiences .

they also observe the development of hazardous weather , such as hurricanes and severe thunderstorms , and track their movement and intensity to reduce or avoid major losses of property and life .

the ability of the satellites to provide broad , continuously updated coverage of atmospheric conditions over land and oceans is important to noaa's weather forecasting operations .

to provide continuous satellite coverage , noaa acquires several satellites at a time as part of a series and launches new satellites every few years ( see table 1 ) .

noaa's policy is to have two operational satellites and one backup satellite in orbit at all times .

three viable goes satellites — goes - 13 , goes - 14 , and goes - 15 — are currently in orbit.with goes - 13 covering the eastern united states ( goes - east in figure 1 ) and goes - 15 covering the western united states ( goes - west ) .

goes - 14 is currently in an on - orbit storage mode and is available as a backup for the other two satellites should they experience any degradation in service .

the goes - r series is the next generation of satellites that noaa is planning .

both goes - 13 and goes - 15 are operational satellites , each of the operational geostationary satellites continuously transmits raw environmental data to noaa ground stations .

the data are processed at these ground stations and transmitted back to the satellite for broadcast to primary weather services and the global research community in the united states and abroad .

raw and processed data are also distributed to users via ground stations through other communication channels , such as dedicated private communication lines and the internet .

figure 2 depicts a generic data relay pattern from a geostationary satellite to the ground stations and commercial terminals .

noaa established the goes - r program to develop and launch the next series of geostationary satellites and to ensure the continuity of geostationary satellite observations .

the goes - r satellite series is designed to improve upon the technology of the prior satellite series in terms of system and instrument improvements .

noaa expects that the goes - r series will significantly increase the clarity and precision of the observed environmental data .

in addition , the data generated by the satellites are to be both developed and transmitted more quickly .

since its inception , the goes - r program has undergone several changes in cost and scope .

as originally envisioned , goes - r was to encompass four satellites hosting a variety of advanced technology instruments and providing 81 environmental products .

the first two satellites in the series ( called goes - r and goes - s ) were expected to launch in september 2012 and april 2014 .

however , in september 2006 , noaa decided to reduce the scope and technical complexity of the goes - r program because of expectations that total costs , which were originally estimated to be $6.2 billion , could reach $11.4 billion .

specifically , noaa reduced the minimum number of satellites from four to two , cancelled plans for developing an advanced instrument ( which reduced the number of planned satellite products from 81 to 68 ) , and divided another instrument into two separate acquisitions .

the agency estimated that the revised program would cost $7 billion and kept the planned launch dates unchanged .

subsequently , noaa made several other important decisions about the cost and scope of the goes - r program .

in 2007 , noaa established a new program cost estimate of $7.67 billion and moved the launch dates for the first two satellites to december 2014 and april 2016 .

further , to mitigate the risk that costs would rise , program officials decided to remove selected program requirements from the baseline program and treat them as contract options that could be exercised if funds allowed .

these requirements included the number of products to be distributed , the time to deliver the remaining products ( product latency ) , and how often these products would be updated with new satellite data ( refresh rate ) .

for example , program officials eliminated the requirement to develop and distribute 34 of the 68 envisioned products , including low cloud and fog , sulfur dioxide detection , and cloud liquid water .

program officials included the restoration of the requirements for the products , latency times , and refresh rates as options in the ground system contract that could be acquired at a later time .

program officials later reduced the number of products that could be restored as a contract option ( called option 2 ) from 34 to 31 because they determined that two products were no longer feasible and two others could be combined into a single product .

in late 2009 , noaa changed the launch dates for the first two satellites to october 2015 and february 2017 .

more recently , noaa restored two satellites to the program's baseline , making goes - r a four - satellite program once again .

in february 2011 , as part of its fiscal year 2012 budget request , noaa requested funding to begin development for two additional satellites in the goes - r series — goes - t and goes - u .

the program estimated that the development for all four satellites in the goes - r series — goes - r , goes - s , goes - t , and goes - u — would cost $10.86 billion through 2036 , an increase of $3.19 billion over its 2007 life cycle cost estimate of $7.67 billion for the two - satellite program .

in august 2013 , the program announced that it would delay the launch of the first two satellites in the program , due in part to the effects of sequestration .

specifically , the launch of the goes - r satellite was delayed from october 2015 to the quarter ending march 2016 , and the expected goes - s satellite launch date was moved from february 2017 to the quarter ending june 2017 .

see table 2 for an overview of key changes to the goes - r program .

while noaa is responsible for goes - r program funding and overall mission success , it implemented an integrated program management structure with nasa for the goes - r program since it relies on nasa's acquisition experience and technical expertise .

the noaa - nasa program management council is the oversight body for the goes - r program , and is co - chaired by the noaa deputy undersecretary for operations and the nasa associate administrator .

noaa also located the program office at nasa's goddard space flight center .

the goes - r program is divided into flight and ground projects that have separate areas of responsibility and oversee different sets of contracts .

the flight project , which is led by nasa , includes instruments , spacecraft , launch services , satellite integration , and on - orbit satellite initialization .

the ground project , which is led by noaa , is made up of three main components: the core ground system , an infrastructure of antennas , and a product access subsystem .

in turn , the core ground system comprises four functional modules supporting operations , product generation , product distribution , and configuration control .

figure 3 depicts the integrated program management structure and the organization of the flight and ground projects within that structure , while table 3 summarizes the goes - r instruments and their planned capabilities and table 4 describes key components of the ground project .

in recent years , we issued a series of reports aimed at addressing key areas of focus included weaknesses in the goes - r program .

 ( 1 ) cost , ( 2 ) technical challenges and changes in requirements , and ( 3 ) contingency plans .

addressing cost risks: in june 2012 , we reported that the goes - r program might not be able to ensure that it had adequate resources to cover unexpected problems in remaining development .

we recommended the program strengthen its process for planning and reporting on reserves .

more recently , in september 2013 , we reported on weaknesses in the process for reporting reserves to management and recommended the agency take action to brief senior executives on a regular basis regarding the status of reserves .

the agency agreed with our recommendations and took steps to address them by identifying needed reserve levels and providing a more detailed breakdown of reserve percentage calculations .

however , noaa is not yet identifying the reserves associated with each satellite in the series .

technical issues and changes in requirements: we previously reported on issues related to goes technical challenges and requirements .

in 2012 , we reported that key instruments were experiencing technical challenges and required additional redesign efforts .

for example , emissions for the geostationary lightning also , the mapper instrument were outside the specified range .

ground project was experiencing ongoing technical problems — for example , the definition of ground system software requirements and integration of flight instruments .

as a result , revisions were made to the core ground system's baseline development plan and schedule .

more recently , in september 2013 , we reported that noaa made changes to several of the goes - r requirements — including decreasing the accuracy requirement for the hurricane intensity product and decreasing the timeliness of the lightning detection product — and that end users were concerned by many of these changes .

we recommended that the program improve communications with users on changes in goes - r requirements by assessing impacts , seeking input from users , and disseminating information on changes .

noaa agreed with this recommendation and took steps to explore further avenues of user communication such as customer forums and interagency working groups .

contingency planning: in february 2013 , due to the importance of environmental satellite data and the potential for a gap in this data , we added mitigating weather satellite gaps to our biennial high - risk list .

gao - 12-576 .

in that report , we noted that noaa had established a contingency plan for a potential gap in the goes program , but it needed to demonstrate its progress in coordinating with the user community to determine their most critical requirements , conducting training and simulations for contingency operations scenarios , evaluating the status of viable foreign satellites , and working with the user community to account for differences in product coverage under contingency operations scenarios .

we also stated that noaa should update its contingency plan to provide more details on its contingency scenarios , associated time frames , and any preventative actions it is taking to minimize the possibility of a gap .

more recently , in september 2013 , we reported that , while noaa had established contingency plans for the loss of the goes satellites , these plans still did not address user concerns over potential reductions in capability , and did not identify alternative solutions and timelines for preventing a delay in the goes - r launch date.recommended the agency revise the satellite and ground system contingency plans to address weaknesses , including providing more information on the potential impact of a satellite failure and coordinating with key external stakeholders on contingency strategies .

the agency agreed with these recommendations and took steps to address them by identifying and refining program contingency plans .

nasa and noaa are following nasa's standard space system life cycle on the goes - r program .

this life cycle includes distinct phases , including concept and technology development ; preliminary design and technology completion ; final design and fabrication ; system assembly , integration and testing , and launch ; and operations and sustainment .

key program reviews are to occur throughout each of the phases , including preliminary design review , critical design review , and system integration review .

noaa and nasa jointly conduct key reviews on the flight and ground segments individually as well as for the program as a whole , and then make decisions on whether to proceed to the next phase .

figure 4 provides an overview of the life cycle phases , key program reviews , and associated decision milestones .

in addition , the key reviews are described in table 5 .

the goes - r program has completed important steps in developing its first satellite .

specifically , the program completed its critical design review in november 2012 , its mission operations review in june 2014 , and its system integration review in july 2014 .

based on the results of the system integration review , in september 2014 , noaa and nasa decided to move the program to the next phase , the system assembly , integration and test , and launch and checkout phase .

to prepare for the recent reviews and milestones , the program completed numerous important steps on both the flight and ground projects .

key accomplishments include: completing testing on individual components including the six flight instruments , the spacecraft core and system modules , and ground system components ; releasing key ground system software components on enterprise infrastructure and mission management in december 2013 and april 2014 , respectively , and completing the dry run of another ground system release that includes all planned products for the goes - r satellite ; replacing and successfully demonstrating a new engineering analysis tool , which will perform trending and offline analysis ; completing installation and testing of antenna dishes at noaa's satellite operations facility , continuing installation and testing at noaa's primary satellite communications site , and beginning training in use of the antenna system ; completing two key readiness reviews on the product distribution and access system ; and completing connectivity tests throughout system hardware components .

moving forward , the next major program milestones are the flight operations review and the operational readiness review .

in preparation for these milestones , the program plans to conduct a series of five end - to - end tests.the space and ground segments before the launch of the first satellite .

noaa's estimated life cycle cost for the goes - r program has held relatively steady .

noaa's current life cycle cost estimate for the goes - r program is $10.83 billion , which is slightly less than the $10.86 billion lifecycle cost estimate from august 2013 .

the $30 million change in the life cycle cost estimate from last year is the net result of moving selected management functions outside the program and addressing program commitments impacted by funding reductions associated with sequestration in late 2013 .

however , program data show that individual components are costing more than expected .

federal agencies and private industry organizations often implement earned value management ( evm ) as a tool for ensuring work completed is on track with expected costs and schedules .

management tool that , among other things , produces early warning signs of impending schedule slippages and cost overruns .

key evm metrics include cost and schedule variances , which measure the value of work accomplished in a given period and compares it with the planned value of work scheduled for that period and with the actual cost of work accomplished .

for example , an increase in cost variance means that the program spent more than expected to produce the work .

an analysis of evm data for three key components — the goes ground system , the abi instrument , and the glm instrument — shows that each experienced a growing cost variance .

specifically , over the twelve - month period ending july 2014 , the cost variance for the ground system increased to 8.4 percent of total cumulative budgeted cost and for glm , the cost variance increased to 5.1 percent .

for a third key component , the abi instrument , cost variance increased slightly from 2.4 to 2.6 percent .

figures 6 , 7 , and 8 show monthly cost variance data for the three key components for the year ending july 2014 .

gao - 09-3sp .

gao - 09-3sp .

data for the glm and abi instruments we found inconsistencies in the contractor's monthly and cumulative reports that made it more difficult for noaa to effectively oversee the contractor's performance .

specifically , we found inconsistencies between cumulative and monthly budget totals in contractor performance reports that ranged from hundreds of thousands to millions of dollars .

for instance , the cumulative amount of budget allocated to complete work for glm between february 2013 and march 2013 increased by just under $2 million , while the stated monthly change was $3.8 million .

also , the cumulative amount of budgeted work accomplished for abi between may 2013 and june 2013 increased by $3.2 million , while the stated monthly change was $5.4 million .

month - to - month discrepancies such as this occurred in each of 6 months for the glm instrument and each of 9 months for the abi instrument in the period between august 2013 and july 2014 .

program officials stated that these issues were addressed in later contractor reports , and that program analysts communicate with contractors and program management regularly to resolve any found discrepancies .

however , more recent monthly reports continue to show discrepancies .

if the instrument's cost data are unreliable , it is difficult for managers and program officials to make financial projections and assess reserve needs and usage .

the goes - r program is considering eliminating or deferring planned functionality on its ground system due to issues experienced during development .

specifically , the goes - r program is considering deferring functionality on the ground system in order to provide schedule relief in the case of further delays .

program and contracting officials recently revised the composition of the software releases it will be delivering on the ground system .

in doing so , the goes - r program identified “off - ramps,” or decision points , at which time they could remove or defer a specific function from pre - launch to post - launch if it is not ready in time for testing .

as of september 2014 , officials identified 50 potential decision points for deferring functionality .

to date , the program has decided to implement five of the deferrals , including one to remove the ability to play back information from alternate abi data sets outside the goes ground system , and another to remove a low - level navigation capability .

in addition , program officials decided against deferring 30 of the functions , leaving 16 deferrals that could be implemented in the future .

the off - ramps still under consideration include a reduction in the amount of verification and validation activities that will be conducted .

a key element of a successful test phase is appropriately identifying and handling any defects or anomalies that are discovered during testing .

key aspects of a sound defect management process include defect management planning , defect identification and classification , defect analysis , defect resolution , defect tracking , and defect trending and reporting .

leading industry and government organizations consider defect management and resolution to be among the primary goals of testing.these organizations have identified best practices for managing defects and anomalies that arise during system testing .

table 7 outlines the best practices of a sound defect management process .

the goes - r program has sound defect management policies in place and it , along with its contractors , is actively performing defect management activities .

specifically , the program has fully satisfied 13 of the 20 best practices , and partially satisfied the remaining 7 practices .

for example , the program has defect management procedures in place as part of its overall testing program .

defect management is incorporated in the program's mission assurance , configuration management , and verification / validation functions .

in addition , for three key components we reviewed — abi , glm , and the ground system — defects are entered into automated systems , from which they are analyzed and resolved .

the program also tracks , and regularly reports weekly and monthly , on defect totals and metrics to noaa management .

however , there are several areas in which defect management policies and practices are inconsistent , including in performing and recording information pertinent to individual defects , and in reporting and tracking defect information .

table 8 provides an assessment of how the goes - r program and key contractors performed on each of the best practices , and is followed by a more detailed discussion of shortfalls .

among the shortfalls seen in table 8 are a number of cross - cutting themes: variation among contractors in managing and reporting metrics: the goes - r program affords its contractors and subcontractors wide latitude in making decisions on how to manage , track , and report defects , which results in variation among program components .

for example , the program established a minimum set of metrics that must be reported and recorded for each software defect , but has not done so for hardware defects .

no clear definition of defects: in its guidance , noaa did not fully define the terminology of defect management .

as a result , the program and contractors use terms such as defect , anomaly , nonconformance , incident reports , and trouble reports without explaining clearly how they are related to each other .

without understanding these relationships , variations from expected performance are likely to be treated differently throughout the program .

for example , some issues that occur after formal integration and testing are complete are not considered as defects , which means that they are not all reported on the statistics provided to program management .

in another case , an issue on instrument data algorithms was uncovered during user testing and required rework ; however , it was not counted as a defect .

program officials stated that this was a documentation issue and noted that they do not track documentation issues as defects .

however , the issue affected more than documentation .

it was addressed by reworking the software algorithms ; thus , it should have been tracked as a software defect .

no clear definition of priority / severity: in its contract requirements and other guidance documents , the goes - r program did not establish specific guidance to its contractors on how to prioritize or establish the severity of defects .

at most , documents list a severity classification as one of many defect attributes that contractors should review as necessary .

a program official explained that , for hardware defects , there is no programwide policy for defect metrics , including priority or severity .

as a result , the information tracked , trended , and reported to management on defect totals also varied by contractor , and thus often by instrument or component .

unrealistic testing schedule: effective defect management requires a realistic schedule in that it takes time to be able to fully identify , analyze , prioritize , resolve , and track defects .

however , in may 2014 , an internal noaa report stated that the current program testing schedule is “unrealistically aggressive.” the goes - r program has chosen to compress its remaining testing schedule , which increases the risk that there will not be sufficient time to address defects before moving to the next stage of testing .

effects of this type can already be seen ; the program reported that some defects that were open for a long period of time have been delayed due to the need for all available resources to be applied in resolving new , current defects .

limited trend analysis: while the program and noaa's mission assurance team have analyzed contractor - provided trends in the volume and severity of defects over time for the ground system and spacecraft , they do not routinely analyze trend data for all components .

for example , on the abi and glm instruments , the program and mission assurance team do not analyze trend data monthly for hardware defects .

instead , these groups only assess individual defect reports for this subset of defects .

it is important for the program to assess defect trends over time in order to provide to management a more complete picture of testing status .

assessing trends in defect handling can result in better resource allocation to components of greatest need , and more attention to the effectiveness of resolving defects .

although the goes program has defect management policies in place and its contractors are actively tracking , analyzing , and reporting on defects , the discrepancies between contractors' data could cause issues in completing the remainder of the program's integration and testing period .

for example , without consistent defect metrics , it is more difficult for managers to obtain a complete picture of the status of open , closed , and high priority defects across the program .

program officials stated that the program did not contractually specify any best practices , but that it assumed that contractors with high - level professional certifications would employ all practices necessary for the development effort .

unless the program can find a way to unite these disparate approaches to provide consistency in the methods by which defects are identified , prioritized , captured , and tracked , it will be more difficult for management to analyze and understand trends in opening and closing high - priority defects or to make decisions on how to best resolve the defects .

moreover , until the program addresses shortfalls in its defect management processes , it may not have a complete picture of remaining defects and runs the risk of not having sufficient time to resolve them .

while effectively and efficiently addressing and resolving defects is an important part of a sound system testing approach , the goes - r program has not efficiently closed defects on selected components .

as noted earlier , the program does not obtain or maintain defect trend data for the program as a whole ; however , data on individual components and portions of components show that a large number of defects remain open , including several high - priority defects .

specifically , data for the goes ground system shows that 500 defects remained open as of september 2014 , including 36 high - priority defects .

defect data for the spacecraft show that it is taking an increasing amount of time to close hardware - related defects , but that the program is making progress in closing software defects .

specifically , as of april 2014 , 42 software and 332 hardware defects were unresolved .

defect totals on goes instruments declined as the program approached the deadline for them to be completed in order to be integrated with the spacecraft .

specifically , for the glm instrument , the total number of both hardware and software defects declined .

hardware defects declined from 117 in may 2014 to 13 in september 2014 , and there were no remaining software defects by january 2014 .

for the abi instrument , the number of newly opened hardware and software defects each month has declined over time , with only one unresolved defect remaining in july 2014 .

table 9 depicts summary information on defects for selected components at different points in time .

in addition , appendix ii provides more information on defect trends for these components .

program officials noted that in some cases , due to time concerns , lower - priority defects which have been determined to not have a major effect on performance are not closed until later in the testing process .

also , program officials have stated that they are having difficulty in closing defect - related incident reports due to insufficient manpower .

until the program reduces the number of longstanding unresolved defects , it faces an increased risk of further delays to the goes - r launch date should an open defect affect future performance .

goes satellite data are considered a mission - essential function because of their criticality to weather observations and forecasts .

these forecasts — such as those for severe storms , hurricanes , and tornadoes — can have a substantial impact on our nation's people , infrastructure , and economy .

because of the importance of goes satellite data , noaa's policy is to have two operational satellites and one backup satellite in orbit at all times .

this policy proved useful in december 2008 and again in september 2012 , when the agency experienced problems with one of its operational satellites , but was able to move its backup satellite into place until the problems had been resolved .

however , noaa is facing a period of up to 17 months when it will not have a backup satellite in orbit .

specifically , in april 2015 , noaa expects to retire one of its operational satellites ( goes - 13 ) and to move its backup satellite ( goes - 14 ) into operation .

thus , the agency will have only two operational satellites in orbit — and no backup satellite — until goes - r is launched and completes an estimated 6-month post - launch test period .

if goes - r is launched in march 2016 , the earliest it could be available for operational use would be september 2016 .

figure 9 shows the potential gap in backup coverage , based on the launch and decommission dates of goes satellites .

during the time in which no backup satellite would be available , there is a greater risk that noaa would need to either rely on older satellites that are beyond their expected operational lives and may not be fully functional , request foreign satellite coverage , or to operate with only a single operational satellite .

agency officials stated that the risk of a gap may be reduced , because noaa satellites have historically remained in operation longer than their expected life .

while many satellites outlive their expected lifespans , the current goes satellites are operating with reduced functionality , and one has experienced two major outages .

without a full complement of operational goes satellites , the nation's ability to maintain the continuity of data required for effective weather forecasting could be compromised .

this , in turn , could put the public , property , and the economy at risk .

any delay to the goes - r launch date would extend the time without a backup to more than 17 months .

as discussed earlier in this report , further delays to the committed launch date of the first goes - r satellite are possible due to continued technical issues encountered during testing and integration .

government and industry best practices call for the development of contingency plans to maintain an organization's essential functions — such as goes satellite data — in the case of an adverse event .

in september 2013 , we reported on weaknesses in the contingency plans for noaa's satellites .

at that time , we compared noaa's plans to 17 best practices associated with three main areas: identifying failure scenarios and impacts , developing contingency plans , and validating and implementing contingency plans .

we reported that while noaa identified failure scenarios , recovery priorities , and minimum levels of acceptable performance , the satellite contingency plan contained areas that fell short of best practices , such as working with the user community to account for potential reductions in capability under contingency operations .

furthermore , the agency did not identify alternative solutions or timelines for preventing a goes - r launch delay .

in february 2014 , noaa released a new satellite contingency plan in response to these recommendations .

this plan improved in comparison to many , but not all , of the best practices .

specifically , the plan improved in 6 areas and stayed the same in 4 areas .

table 10 compares our assessment of the current satellite contingency plan with our september 2013 analysis for all best practices that were not fully met .

program officials stated that it is not feasible to include strategies to prevent delays in launch of the first goes - r satellite in the contingency plan , because such strategies are not static .

they explained that options for preventing a delay vary greatly over time based on issues that occur during the satellite's development .

they further stated that the program's monthly presentations to noaa management provide a summary of current threats to the launch date and strategies to mitigate those threats .

for example , noaa is considering whether or not to remove or delay selected ground system functions to post - launch , and the program provides monthly updates on this issue .

while actively managing the program to avoid a delay is critical , it is also important that noaa management and the goes - r program consider and document feasible alternatives for avoiding or limiting such a launch delay .

this will allow stakeholders throughout noaa to be aware of , respond to , and plan for the potential implementation of each alternative , not only the small number of alternatives the program is actively considering in any given month .

until noaa addresses the remaining shortfalls in its goes - r gap mitigation plan , the agency cannot be assured that it is exploring all alternatives or that are able to effectively prepare to receive goes information in the event of a failure .

after spending 10 years and just over $5 billion , the goes - r program is nearing the launch of its first satellite .

however , it continues to face challenges in maintaining its schedule and controlling its costs .

the program continues to experience delays in remaining major milestones , which could result in further delays to the launch date .

costs are increasing faster than expected for key program components and contractor data is often inconsistent from month to month .

until the agency ensures its contractor cost data are consistent , it will be more difficult for managers and program officials to make financial projections and assess reserve needs and usage .

as the goes - r program progresses through its testing and integration phase , it is essential that it is able to appropriately handle defects that arise during testing .

while noaa and its contractors have implemented a defect management process which is successful in many areas , there are shortfalls in how the program defines defects , monitors trends , and reports on defects and defect metrics .

in particular , noaa has not established a standard set of metric information for all defects , including the dates on which defects were identified and resolved , or an indication of a defect's severity .

also , noaa did not clearly define the type of issue that constitutes a defect .

furthermore , multiple defects remain open on some program components , including several that have remained open for more than six months .

until the program addresses these shortfalls and reduces the number of open defects , it may not have a complete picture of remaining issues and faces an increased risk of further delays to the goes - r launch date .

noaa could experience a gap in satellite data coverage if goes - r is delayed further and one of the two remaining operational satellites experiences a problem .

noaa has made improvements to its satellite contingency plan , but the plan still does not sufficiently address mitigation options for a launch delay , potential impacts , or minimum performance levels .

until such information is available , it will be difficult to integrate mitigation efforts , or to coordinate with users in the event of a failure .

to address risks in the goes - r program development and to help ensure that the satellite is launched on time , we are making the following four recommendations to the secretary of commerce .

specifically , we recommend that the secretary of commerce direct the noaa administrator to: investigate and address inconsistencies totaling hundreds of thousands of dollars in monthly earned value data reporting for the glm and abi instruments ; address shortfalls in defect management identified in this report , including the lack of clear guidance on defect definitions , what defect metrics should be collected and reported , and how to establish a defect's priority or severity ; and reduce the number of unresolved defects on the goes ground system and spacecraft .

in addition , because noaa has not fully implemented our prior recommendation to improve its satellite gap mitigation plan , we recommend that the secretary of commerce direct the noaa administrator to: add information to the goes satellite contingency plan on steps planned or underway to mitigate potential launch delays , the potential impact of failure scenarios in the plan , and the minimum performance levels expected under such scenarios .

we sought comments on a draft of our report from the department of commerce and nasa .

we received written comments from the deputy secretary of commerce transmitting noaa's comments .

noaa concurred with all four of our recommendations and identified steps that it plans to take to implement them .

it also provided technical comments , which we have incorporated into our report , as appropriate .

noaa's comments are reprinted in appendix iii .

on november 14 , 2014 , an audit liaison for nasa provided an e - mail stating that the agency would provide any input it might have to noaa for inclusion in noaa's comments .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to interested congressional committees , the secretary of commerce , the administrator of nasa , the director of the office of management and budget , and other interested parties .

the report also will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions on the matters discussed in this report , please contact me at ( 202 ) 512-9286 or at pownerd@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iv .

our objectives were to ( 1 ) assess progress on the goes - r program with respect to planned schedule , cost , and functionality ; ( 2 ) assess efforts to identify and address issues discovered during integration and testing ; and ( 3 ) evaluate the likelihood of a gap in satellite coverage and analyze the adequacy of contingency actions in place to prevent or mitigate such a gap .

to assess noaa's progress on the goes - r program with respect to planned schedule , cost , and functionality , and to identify risks that could lead to further schedule delays , we analyzed data from monthly program management meetings .

we evaluated progress made in completing key program components and major program reviews , and compared planned and actual completion dates for key program milestones over the last two to three years to determine the degree to which these dates have changed .

to ensure that the program's schedule data were consistent and reliable , we compared milestone data over several months and contacted agency officials to corroborate events that occurred over the course of our engagement .

we analyzed earned value management ( evm ) data to compare levels of cost variance over time for key program components , and calculated earned value management metrics using program cost performance reports .

to ensure that the program's cost data were reliable , we compared formulas from the gao cost guide to the program's evm approach .

we also compared evm data across a series of monthly program cost performance reports .

in doing so , we found inconsistencies in the monthly evm data for selected components , and reported on those inconsistencies in this report .

however , the data were sufficient for our purpose of assessing overruns because these inconsistencies were small in comparison to cost variances .

we assessed recently enacted and potential changes in functionality for key program components .

we also interviewed program officials regarding changes in schedule milestones , cost performance and reserve funding , and functionality .

to assess efforts to identify and address issues discovered during integration and testing , we identified best practices in defect management from leading industry and government organizations .

we compared noaa policy documents and defect management artifacts by the goes program , its contractors , and an independent noaa mission assurance group to the best practices .

we selected three components , which are critical to the program's mission requirements , and evaluated recent test results and defects .

specifically , we identified two recent tests for each component and analyzed artifacts associated with defects identified during those tests .

we compared the defects against each best practice to determine if noaa and its contractors fully implemented , partially implemented , or did not implement the best practices .

the agency and contractor had to meet all aspects of the best practice to achieve a fully implemented score , some aspects to achieve a partially implemented score , and no aspects to achieve a not implemented score .

to identify the program's recent performance in closing and managing defects , we analyzed basic defect trend information — such as number of defects opened and closed , and defect severity — for each of several program components .

we developed charts to demonstrate defect trends .

to ensure the data were reliable , we compared defect data from individual defect reports to agency trend charts , and sought corroboration from agency and contractor officials .

we also interviewed agency and contractor officials to discuss their defect management processes and practices , and to confirm information we found while analyzing individual defect reports and trend charts .

to evaluate the likelihood of a gap in satellite coverage , we reviewed monthly program management presentations and other review board documentation .

to analyze the adequacy of contingency actions in place to prevent or mitigate such a gap , we compared noaa's latest satellite contingency plan to best practice criteria from industry and government .

we focused specifically on the ten areas we identified as weak in our prior report .

for each of the ten areas , we rated noaa's contingency plan as having partially or fully implemented the best practice criteria .

in addition , we interviewed agency officials regarding the likely amount of a gap in on - orbit backup coverage of goes satellites , the potential for a gap in operational coverage , and efforts to improve the goes contingency plan .

we conducted this performance audit from january 2014 to december 2014 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

as noted earlier , the goes - r program does not obtain or maintain defect trend data for the program as a whole ; however , data on individual components and portions of components show that a large number of defects remain open , including several high - priority defects .

the following sections provide more details on recent data trends for the goes - r ground system and spacecraft as well as the abi and glm instruments .

it is important to note that the sections do not provide consistent information among components because the program does not require consistent metrics and the contractors document different data .

as of the end of september 2014 , the ground system had 500 open defects , an increase from 342 open defects at the end of september 2013 .

also , as of the end of september 2014 , 96 defects that were identified prior to january 2014 remained open , and 36 high - priority defects ( those rated as critical or moderate ) remained open .

program and contractor officials provided rationale and insight into the mitigating circumstances surrounding these defects .

program officials stated that the number of open defects during the integration and test phase is as expected for a ground system of a magnitude similar to goes .

contractor officials reported that none of the 96 longstanding defects were in either of the two highest severity categories .

they also noted that most of the open high - priority defects had been opened during testing events conducted over the previous 3 months , which is a reasonable length of time to close a defect .

furthermore , according to contractor officials , many of the longstanding open defects were in categories such as documentation - related defects which are considered less severe .

officials also stated that defects in these categories are often kept open for specific reasons , such as to gain cost efficiencies or to wait for an already - planned test event rather than creating a new test event .

however , as of september 2013 , 193 of the 342 defects were not related to documentation and this number rose to 416 of the 500 open defects in september 2014 .

figure 10 shows the increase in open defects in the period from september 2013 to august 2014 for the goes - r ground system .

as allowed by noaa's guidance , contractors on the spacecraft track defects differently than the ground system contractors do .

thus , it is not possible to compare opened and closed defects over time as depicted above for the ground system .

instead , spacecraft contractors track hardware and software defects independently .

they also track when new defects are identified and how long they stay open .

for spacecraft hardware , the defect data show that the average time it took to resolve defects increased over time .

specifically , the average age for hardware defects increased from 99 days in may 2013 to a high of 167 days in april 2014 , at which point 58 percent of all open defects had been open for at least 90 days .

program officials stated that they began continuous 24-hour a day , 7-day a week testing in october 2014 , which means that they should be able to make progress in closing the remaining defects .

while the backlog of hardware - related defects on the spacecraft remains high , noaa has been effective in recent months in greatly reducing the number of software - related defects on the spacecraft .

the total number of open software - related defects increased and remained high through february 2014 , but then declined significantly in march and april 2014 .

defect data for the glm instrument showed a decline in the total number of defects for both hardware and software components .

while there were 117 unresolved hardware defects in may 2014 , only 13 hardware defects remained unresolved as of september 2014 .

trend data also showed a decline in the number of unresolved software defects .

specifically , the total number of software - related defects remaining open never increased above 7 over the period from march 2013 to january 2014 .

for half the year , there was no more than one open defect .

metrics for the abi instrument show that all hardware defects and all but one software defect have been closed , likely because the first unit of the instrument was completed .

the number of hardware defects occurring each month declined to near zero during the period february 2013 to april 2014 .

less than ten abi software defects were open at any point from september 2012 onward , and only 11 defects were newly opened during that time .

figure 11 shows the number of opened and closed abi hardware defects by month , and figure 12 shows opened and closed defects for abi software .

in addition to the contact named above , individuals making contributions to this report included colleen phillips ( assistant director ) , alexander anderegg , christopher businsky , shaun byrnes , james macaulay , and karl seifert .

