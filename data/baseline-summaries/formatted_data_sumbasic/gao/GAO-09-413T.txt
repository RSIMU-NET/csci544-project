thank you for the opportunity to participate in today's hearing on the 2010 census .

the u.s. census bureau ( bureau ) is relying on both the acquisition of new systems and the enhancement of existing legacy systems for conducting operations for the 2010 decennial census .

as you know , the census is mandated by the u.s. constitution and provides data that are vital to the nation .

these data are used , for example , to reapportion and redistrict the seats of the u.s. house of representatives , realign the boundaries of the legislative districts of each state , and allocate federal financial assistance .

carrying out the census is the responsibility of the department of commerce's census bureau , which is relying on automation and technology to improve the coverage , accuracy , and efficiency of the 2010 census .

because the accuracy of the 2010 census depends in part on the proper functioning of these systems , both individually and when integrated , thorough testing of these systems before their actual use is critical to the success of the census .

as you know , in march 2008 , we designated the 2010 decennial census as a high - risk area , citing a number of long - standing and emerging challenges , including weaknesses in the bureau's management of its information technology ( it ) systems and operations .

the 2010 decennial census remained as one of our high - risk areas in our recent high - risk update issued in january 2009 .

this statement summarizes the findings in our report , being released by the subcommittee today , on the status and plans of testing of key 2010 decennial it systems .

our work for this report was performed in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objective .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objective .

the bureau's mission is to provide comprehensive data about the nation's people and economy .

the 2010 census enumerates the number and location of people on census day , which is april 1 , 2010 .

however , census operations begin long before census day and continue afterward .

for example , address canvassing for the 2010 census will begin in april 2009 , while the secretary of commerce must report tabulated census data to the president by december 31 , 2010 , and to state governors and legislatures by march 31 , 2011 .

the decennial census is a major undertaking for the bureau that includes the following major activities: establishing where to count .

this includes identifying and correcting addresses for all known living quarters in the united states ( address canvassing ) and validating addresses identified as potential group quarters , such as college residence halls and group homes ( group quarters validation ) .

collecting and integrating respondent information .

this includes delivering questionnaires to housing units by mail and other methods , processing the returned questionnaires , and following up with nonrespondents through personal interviews ( nonresponse follow - up ) .

it also includes enumerating residents of group quarters ( group quarters enumeration ) and occupied transitional living quarters ( enumeration of transitory locations ) , such as recreational vehicle parks , campgrounds , and hotels .

it also includes a final check of housing unit status ( field verification ) where bureau workers verify potential duplicate housing units identified during response processing .

providing census results .

this includes tabulating and summarizing census data and disseminating the results to the public .

automation and it are to play a critical role in the success of the 2010 census by supporting data collection , analysis , and dissemination .

several systems will play a key role in the 2010 census .

for example , enumeration “universes,” which serve as the basis for enumeration operations and response data collection , are organized by the universe control and management ( uc&m ) system , and response data are received and edited to help eliminate duplicate responses using the response processing system ( rps ) .

both uc&m and rps are legacy systems that are collectively called the headquarters processing system .

geographic information and support to aid the bureau in establishing where to count u.s. citizens are provided by the master address file / topologically integrated geographic encoding and referencing ( maf / tiger ) system .

the decennial response integration system ( dris ) is to provide a system for collecting and integrating census responses from all sources , including forms and telephone interviews .

the field data collection automation ( fdca ) program includes the development of handheld computers for the address canvassing operation and the systems , equipment , and infrastructure that field staff will use to collect data .

paper - based operations ( pbo ) was established in august 2008 primarily to handle certain operations that were originally part of fdca .

pbo includes it systems and infrastructure needed to support the use of paper forms for operations such as group quarters enumeration activities , nonresponse follow - up activities , enumeration at transitory locations activities , and field verification activities .

these activities were originally to be conducted using it systems and infrastructure developed by the fdca program .

finally , the data access and dissemination system ii ( dads ii ) is to replace legacy systems for tabulating and publicly disseminating data .

as stated in our testing guide and the institute of electrical and electronics engineers ( ieee ) standards , complete and thorough testing is essential for providing reasonable assurance that new or modified it systems will perform as intended .

to be effective , testing should be planned and conducted in a structured and disciplined fashion that includes processes to control each incremental level of testing , including testing of individual systems , the integration of those systems , and testing to address all interrelated systems and functionality in an operational environment .

further , this testing should be planned and scheduled in a structured and disciplined fashion .

comprehensive testing that is effectively planned and scheduled can provide the basis for identifying key tasks and requirements and better ensure that a system meets these specified requirements and functions as intended in an operational environment .

in preparation for the 2010 census , the bureau planned what it refers to as the dress rehearsal .

the dress rehearsal includes systems and integration testing , as well as end - to - end testing of key operations in a census - like environment .

during the dress rehearsal period , running from february 2006 through june 2009 , the bureau is developing and testing systems and operations , and it held a mock census day on may 1 , 2008 .

the dress rehearsal activities , which are still under way , are a subset of the activities planned for the actual 2010 census and include testing of both it and non - it related functions , such as opening offices and hiring staff .

the dress rehearsal identified significant technical problems during the address canvassing and group quarters validation operations .

for example , during the dress rehearsal address canvassing operation , the bureau encountered problems with the handheld computers , including slow and inconsistent data transmissions , the devices freezing up , and difficulties collecting mapping coordinates .

as a result of the problems observed during the dress rehearsal , cost overruns and schedule slippage in the fdca program , and other issues , the bureau removed the planned testing of several key operations from the dress rehearsal and switched key operations , such as nonresponse follow - up , to paper - based processes instead of using the handheld computers as originally planned .

through the dress rehearsal and other testing activities , the bureau has completed key system tests , but significant testing has yet to be done , and planning for this is not complete .

table 1 summarizes the status and plans for system testing .

effective integration testing ensures that external interfaces work correctly and that the integrated systems meet specified requirements .

this testing should be planned and scheduled in a disciplined fashion according to defined priorities .

for the 2010 census , each program office is responsible for and has made progress in defining system interfaces and conducting integration testing , which includes testing of these interfaces .

however , significant activities remain to be completed .

for example , for systems such as pbo , interfaces have not been fully defined , and other interfaces have been defined but have not been tested .

in addition , the bureau has not established a master list of interfaces between key systems , or plans and schedules for integration testing of these interfaces .

a master list of system interfaces is an important tool for ensuring that all interfaces are tested appropriately and that the priorities for testing are set correctly .

as of october 2008 , the bureau had begun efforts to update a master list it had developed in 2007 , but it has not provided a date when this list will be completed .

without a completed master list , the bureau cannot develop comprehensive plans and schedules for conducting systems integration testing that indicate how the testing of these interfaces will be prioritized .

with the limited amount of time remaining before systems are needed for 2010 operations , the lack of comprehensive plans and schedules increases the risk that the bureau may not be able to adequately test system interfaces , and that interfaced systems may not work together as intended .

although several critical operations underwent end - to - end testing in the dress rehearsal , others did not .

as of december 2008 , the bureau had not established testing plans or schedules for end - to - end testing of the key operations that were removed from the dress rehearsal , nor has it determined when these plans will be completed .

these operations include enumeration of transitory locations , group quarters enumeration , and field verification .

the decreasing time available for completing end - to - end testing increases the risk that testing of key operations will not take place before the required deadline .

bureau officials have acknowledged this risk in briefings to the office of management and budget .

however , as of january 2009 , the bureau had not completed mitigation plans for this risk .

according to the bureau , the plans are still being reviewed by senior management .

without plans to mitigate the risks associated with limited end - to - end testing , the bureau may not be able to respond effectively if systems do not perform as intended .

as stated in our testing guide and ieee standards , oversight of testing activities includes both planning and ongoing monitoring of testing activities .

ongoing monitoring entails collecting and assessing status and progress reports to determine , for example , whether specific test activities are on schedule .

in addition , comprehensive guidance should describe each level of testing and the types of test products expected .

in response to prior recommendations , the bureau took initial steps to enhance its programwide oversight ; however , these steps have not been sufficient .

for example , in june 2008 , the bureau established an inventory of all testing activities specific to all key decennial operations .

however , the inventory has not been updated since may 2008 , and officials have no plans for further updates .

in another effort to improve executive - level oversight , the decennial management division began producing ( as of july 2008 ) a weekly executive alert report and has established ( as of october 2008 ) a dashboard and monthly reporting indicators .

however , these products do not provide comprehensive status information on the progress of testing key systems and interfaces .

further , the assessment of testing progress has not been based on quantitative and specific metrics .

the lack of quantitative and specific metrics to track progress limits the bureau's ability to accurately assess the status and progress of testing activities .

in commenting on our draft report , the bureau provided selected examples where they had begun to use more detailed metrics to track the progress of end - to - end testing activities .

the bureau also has weaknesses in its testing guidance .

according to the associate director for the 2010 census , the bureau did establish a policy strongly encouraging offices responsible for decennial systems to use best practices in software development and testing , as specified in level 2 of carnegie mellon's capability maturity model® integration .

however , beyond this general guidance , there is no mandatory or specific guidance on key testing activities such as criteria for each level or the type of test products expected .

the lack of guidance has led to an ad hoc — and , at times — less than desirable approach to testing .

in our report , we are making ten recommendations for improvements to the bureau's testing activities .

our recommendations include finalizing system requirements and completing development of test plans and schedules , establishing a master list of system interfaces , prioritizing and developing plans to test these interfaces , and establishing plans to test operations removed from the dress rehearsal .

in addition , we are recommending that the bureau improve its monitoring of testing progress and improve executive - level oversight of testing activities .

in written comments on the report , the department had no significant disagreements with our recommendations .

the department stated that its focus is on testing new software and systems , not legacy systems and operations used in previous censuses .

however , the systems in place to conduct these operations have changed substantially and have not yet been fully tested in a census - like environment .

consistent with our recommendations , finalizing test plans and schedules and testing all systems as thoroughly as possible will help to ensure that decennial systems will work as intended .

in summary , while the bureau's program offices have made progress in testing key decennial systems , much work remains to ensure that systems operate as intended for conducting an accurate and timely 2010 census .

this work includes system , integration , and end - to - end testing activities .

given the rapidly approaching deadlines of the 2010 census , completing testing and establishing stronger executive - level oversight are critical to ensuring that systems perform as intended when they are needed .

mr. chairman and members of the subcommittee , this concludes our statement .

we would be pleased to respond to any questions that you or other members of the subcommittee may have at this time .

if you have any questions about matters discussed in this testimony , please contact david a. powner at ( 202 ) 512-9286 or pownerd@gao.gov or robert goldenkoff at ( 202 ) 512-2757 or goldenkoffr@gao.gov .

other key contributors to this testimony include sher`rie bacon , barbara collier , neil doherty , vijay d'souza , elizabeth fan , nancy glover , signora may , lee mccracken , ty mitchell , lisa pearson , crystal robinson , melissa schermerhorn , cynthia scott , karl seifert , jonathan ticehurst , timothy wexler , and katherine wulff .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

the published product may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

