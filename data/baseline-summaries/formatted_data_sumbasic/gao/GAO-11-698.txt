small businesses have been collectively described as an engine for economic growth and innovation .

according to the small business administration ( sba ) , such businesses have been responsible for creating 64 percent of net new jobs over the past 15 years and have produced 13 times more patents per employee than larger firms .

to assist small businesses in undertaking and obtaining the benefits of research and development ( r&d ) , congress first passed legislation authorizing the small business innovation research ( sbir ) program in 1982 .

sba's office of technology administers the program , which presently has four overarching purposes: to use small businesses to meet federal r&d needs , stimulate technological innovation , increase commercialization of innovations derived from federal r&d efforts , and encourage participation in technological innovation by small businesses owned by disadvantaged individuals and women .

since the program was first authorized in 1982 , there has been increased congressional interest in its results , particularly the commercialization aspect .

every federal agency with a budget of $100 million or more for extramural r&d — which is conducted by nonfederal employees outside federal facilities — is required to establish and operate an sbir program funded by 2.5 percent of that budget .

eleven agencies currently participate in the program .

in fiscal year 2009 ( the most recent year for which sba data are available ) , the 11 agencies reported more than $2.2 billion in sbir awards .

although each of these agencies manages its own program , sba oversees and coordinates agency efforts by setting policy , collecting program data , reviewing agency progress , and reporting annually to congress .

since the creation of the sbir program 29 years ago , it has been reauthorized , modified , and extended by congress at various times .

the small business reauthorization act of 2000 extended the program through september 30 , 2008 .

this act was succeeded by a series of temporary extensions , the most recent of which extended the program through september 30 , 2011 .

in this context , you asked us to examine the practices of participating agencies .

accordingly , we agreed to determine ( 1 ) how participating agencies have addressed the sbir program's four overarching purposes when implementing their programs and ( 2 ) the extent of sbir program data available to evaluate progress in increasing commercialization of sbir technologies .

our review of the program focused on sba and five agencies that accounted for about 96 percent of the total dollars awarded by the program in 2009: the department of defense ( dod ) , the department of energy ( doe ) , the national aeronautics and space administration ( nasa ) , the department of health and human services' national institutes of health ( nih ) , and the national science foundation ( nsf ) .

at two of these agencies — dod and nih — we also reviewed program activities conducted by the three subcomponent agencies with the largest sbir budgets because some key activities are carried out at that level .

specifically , for dod , we examined the sbir programs of the army , air force , and navy and for nih , we examined the programs of the national institute of allergy and infectious diseases ; the national cancer institute ; and the national heart , lung , and blood institute .

in conducting our review , we analyzed documentation from these agencies for fiscal years 2008 through 2010 and , when possible , for fiscal year 2011 .

the documentation we reviewed included , among other things , policy guidance , solicitations for applications for sbir awards , and descriptions of commercialization assistance provided to sbir awardees .

we also reviewed applicable laws and regulations .

in addition , we interviewed sbir program officials at the agencies , as well as inspector general staff at nsf and knowledgeable stakeholders , including staff of the national academy of sciences' national research council and representatives of trade associations .

we selected the trade associations based on their familiarity with the program , the technologies on which they focus , and whether their membership includes small businesses owned by disadvantaged individuals and women .

to obtain further context for our review , we attended two national conferences on the sbir program , as well as a workshop conducted by the national research council .

we conducted this performance audit from june 2010 to august 2011 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence we obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

a more detailed description of the scope of our review and the methods we used is contained in appendix i .

sba coordinates and oversees the efforts of the 11 agencies currently participating in the sbir program .

sba coordinates the agencies' schedules for issuing solicitations — announcements of opportunities for small businesses to apply for awards — and provides access to these solicitations through its web site .

as part of its oversight effort , sba collects sbir data from the participating agencies , aggregates the data , and uses the data to , among other things , monitor the program and report to congress .

sba also provides guidance to participating agencies on the general conduct and operation of the program , which it periodically updates , for example , in response to changes in the program's authorizing legislation .

under the legislation and sba's guidance , agencies have considerable flexibility to design their programs .

for example , each agency determines , in consultation with sba , such items as the number of solicitations to be issued during a fiscal year and the dates applications are due .

agencies also have discretion to determine what type of research to include in their solicitations , how to review applications for technical and scientific merit , which applications to fund , and the size of the award , among other things .

the small business innovation development act of 1982 provided for a competitive three - phased sbir program .

in phase i , participating agencies award up to $150,000 for a period of about 6 to 9 months to small businesses to conduct experimental or theoretical r&d .

small businesses whose phase i projects demonstrate scientific and technical merit , in addition to commercial potential , may compete for phase ii awards of up to $1 million to continue the r&d for an additional period , normally not to exceed 2 years .

phase i and ii award funds may be used for costs related to conducting the research , such as salaries , fringe benefits , equipment , and consulting services , as well as for profits and fees .

to be eligible for a phase i or ii sbir award , a business must have 500 or fewer employees , be organized for profit with a place of business in the united states , and operate primarily in the united states or make a significant contribution to the u.s. economy .

generally , a business must also be at least 51 percent owned and controlled by one or more individuals who are u.s. citizens or permanent resident aliens .

these eligibility requirements apply at the time that a phase i or ii award is made .

during phase iii , businesses must secure non - sbir funding to develop the commercial potential of the innovative technologies resulting from their sbir projects ; such funding may come from the private sector , federal agencies , or other sources .

as the program has been reauthorized over the years , legislation has established a number of requirements related to the program's purposes .

for example , the small business research and development enhancement act of 1992 directed sba to make more information available about the sbir program , particularly about participation by small businesses owned by disadvantaged individuals and women , and required that agencies increase their outreach to such businesses .

in addition , the small business reauthorization act of 2000 directed that applicants for phase ii sbir awards be required to submit commercialization plans , and it mandated that sba develop , maintain , and make available to the public a database that contained sbir award data .

in addition , the act required sba to develop and maintain , by june 2001 , a restricted government - use database that would contain award - related data from the public database , as well as additional confidential data that would be accessible only to government agencies and other authorized users .

the act stated that this database would be used exclusively for program evaluation — which , as we have noted in past work , involves the systematic collection and analysis of accurate , comparable , and complete data on program results .

the act required the government - use database to contain , among other things , data that applicants for phase ii awards would be required to supply on the commercialization success of any prior phase ii awards , such as data on sales of or additional investment in the technologies funded under the awards .

the act further specified that the government - use database would contain annual updates to these data , which phase ii award recipients would be requested to voluntarily provide for 5 years after the period covered by the award .

to accomplish this mandate , sba envisioned expanding an electronic database , known as tech - net , which it had developed in the late 1990s , into two sections: a public - use portion and a government - use portion containing commercialization data .

the public - use portion of the database has been available since 2000 , according to sba , and it contains such award - related data as the phase of the award , amount of the award , name and location of the business receiving the award , an abstract of the work to be conducted under the award , and whether the business is categorized as owned by disadvantaged individuals or women .

in october 2006 , however , we reported that some sbir agencies did not consistently provide or correctly format the awards - related data for several fields in the public - use portion of the database .

for example , two of the eight agencies we reviewed had not consistently provided data on whether the businesses receiving the awards were categorized as owned by disadvantaged individuals or women .

at that time , we also reported that sba had not implemented the government - use portion of the database , primarily , according to sba officials , because of increased security requirements for the database , agency management changes , and budgetary constraints .

additionally , we reported that while five of the agencies we reviewed had systematically collected commercialization data , their data collection efforts differed in ways that made it challenging to evaluate the program across agencies .

in august 2009 , we testified before congress that sba said the database would no longer accept incorrectly formatted awards - related data from participating agencies .

a committee of the national academy of sciences' national research council has conducted a series of assessments of the sbir program , both within and across agencies , as part of a legislatively mandated study .

the results were summarized in a single report , in which the committee stated that sbir is making significant progress in achieving congressional goals .

the study concluded that the sbir program is “sound in concept and effective in practice.” the study also recommended changes that could make the program more effective .

among other things , the study recommended that sba and participating agencies improve the collection of data that track participation in the sbir program by businesses owned by disadvantaged individuals and women , develop targeted outreach to such businesses that is based on an analysis of factors that affect their participation , and improve documentation of commercialization success .

the national research council is now undertaking another round of assessments to provide a second snapshot of the program's progress in achieving its legislative purposes .

for fiscal years 2008 through 2011 , the five participating agencies we reviewed addressed the sbir purposes of using small business to meet federal r&d needs and stimulating technological innovation through their solicitations .

agencies also used solicitations , as well as technical assistance or matching funds programs , to address the sbir purpose of increasing commercialization of innovations derived from federal r&d efforts .

to address the remaining program purpose — encouraging participation in technological innovation by small businesses owned by disadvantaged individuals and women — agencies relied mainly on outreach activities aimed at a broader audience .

all of the participating agencies that we reviewed designed the sbir solicitations that they issued for fiscal years 2008 through 2011 to meet federal r&d or mission needs and stimulate technological innovation .

all of these agencies selected research topics for their solicitations that were designed to meet their respective r&d or mission needs and specified that applications would be evaluated on the basis of responsiveness to those topics .

the agencies that purchase sbir - funded technologies for their own use — dod , doe , and nasa — tended to select solicitation topics that met specific agency needs for r&d .

for example , in fiscal year 2011 , dod solicited applications to develop a fuel cell system capable of converting ethanol into electricity in an efficient , small , lightweight , portable power system .

according to the solicitation , such advanced fuel cell systems could provide soldiers power to complement batteries and to charge rechargeable batteries , reducing the number of batteries required for extended time in the field .

in contrast , nih and nsf , which generally do not purchase sbir - funded technologies , tended to issue solicitations for a broader spectrum of r&d to support their missions of advancing biomedical and other scientific and engineering disciplines .

among the agencies we reviewed , nih and its components gave applicants the most leeway in addressing agency needs: rather than limiting applications to specific research topics identified in solicitations , nih and its components usually listed suggested topics and encouraged applicants to propose innovative projects that fit the agency's mission .

concerning innovation , each of the agencies included instructions in its sbir solicitations about the type of information applicants had to provide about the innovativeness of the proposed work .

for example , nasa informed phase i and ii applicants that a competitive application would describe the proposed innovation relative to state - of - the - art knowledge in the field , among other things .

in addition , these agencies explained to applicants how reviewers would consider evidence of the innovativeness of the applicants' proposed research approaches .

for example , in its fiscal year 2010 solicitation , nsf stated that applications would be evaluated , in part , on the basis of whether they reflected state - of - the - art knowledge in the major research activities proposed and whether the work was likely to advance state - of - the - art knowledge .

the participating agencies we reviewed addressed the sbir purpose of increasing commercialization of innovations through solicitations , as well as through technical assistance or matching funds programs .

solicitations .

of the five agencies we reviewed , all but nih required in their solicitations for fiscal years 2008 through 2011 that applicants for phase i awards submit a commercialization strategy demonstrating that the applicants had taken steps such as identifying a market for their sbir technologies , planning to secure financing , and estimating expected future sales .

for phase ii awards , all of the agencies we reviewed required that applicants submit a commercialization plan .

in general , the solicitations we reviewed required that phase ii commercialization plans discuss the potential market and competitors ; the qualifications of key management and technical personnel ; as well as financing , marketing , and manufacturing plans , among other things .

the agencies we reviewed differed in their stated processes for evaluating the commercial potential of applications .

for example , dod guidance to applicants outlined a systematic process for how the agency would consider commercialization potential when evaluating applications submitted by small businesses that had received multiple prior awards .

dod indicated that , under this process , it would assign a commercialization achievement score to applicants that had completed the work for four or more phase ii awards from any agency ; this score would reflect how the applicants' commercialization experience compared with historical averages .

applicants whose scores fell within the lowest 20 percent would not be allowed to receive more than half the maximum number of points possible for commercialization potential , which was to be assessed on the basis of several factors , including the commercialization strategy or plan .

dod guidance stated that businesses with fewer than four completed phase ii awards would not be affected by the absence of a commercialization achievement score .

although the other four agencies we reviewed did not outline as systematic a process for evaluating past commercialization success as a gauge of commercialization potential , they still indicated that commercialization potential would be taken into account in reviewing applications .

for example , doe's solicitation instructions encouraged phase i applicants to seek firm commitments for private - sector or non - sbir federal funding prior to applying for a phase ii award .

the instructions further stated that phase ii applicants that obtained such commitments were more likely to receive full credit for commercialization planning during the evaluation of their applications .

in the case of nsf , solicitation instructions stated that proposals are usually reviewed by 3 to 10 outside experts in fields related to the proposal ; according to nsf officials , these reviewers have business experience .

nsf's solicitation instructions further stated that the agency would not review applications that lacked sufficient information on commercial potential .

in 2010 , two agencies we reviewed also issued sbir solicitations under new programs that were explicitly oriented toward increasing commercialization .

specifically , in july 2010 , doe launched a program under which it solicited applications for phase iii of sbir , the commercialization phase .

doe documents indicated that the agency would make available approximately $30 million , including funding from the american recovery and reinvestment act ( recovery act ) , for phase iii awards , which are intended to allow businesses to pursue commercial applications of work performed under phase i and ii awards .

in addition , nih's national cancer institute began a program under which it solicited phase i applications to continue development of technologies that have originated in its laboratories , with the goal of advancing these technologies toward commercial products .

sba has designated the use of the sbir program to encourage commercialization of agencies' internal research as a best practice on its sbir web site .

technical assistance .

all five agencies included in our review provided technical assistance to help award recipients build their capacity to commercialize their technologies .

to provide the assistance , the agencies contracted with vendors and consultants who have experience in bringing technologies to market .

with the exception of nasa , the agencies supported the technical assistance at least in part through the use of sbir funds .

in fiscal years 2008 to 2010 , dod , doe , nih , and nsf spent sbir funds on technical assistance for phase i award recipients .

some of the assistance was in the form of interactive training webinars or online tools directed toward a broad spectrum of sbir applicants and award recipients .

for example , the navy offered phase i award recipients the use of a software tool , known as webtrims , that helps identify , quantify , and track risks associated with sbir technology development and covers topics such as contracting strategies , business and transition planning , and manufacturing readiness .

other phase i assistance was more customized .

for example , doe offered phase i award recipients customized technical assistance designed to help them develop a commercialization plan complete with an implementation schedule and suggestions for product design .

similarly , on a first - come , first - served basis , nih offered phase i award recipients assessments of their sbir - funded technologies' likely niche in the existing commercial market , which could help recipients develop commercialization plans for phase ii applications .

additionally , nsf offered phase i award recipients personalized mentoring and coaching sessions with an advisor .

according to nsf officials , 92 percent of phase i recipients chose to participate in the technical assistance program in 2010 .

nasa did not provide technical assistance for phase i award recipients ; nasa officials told us they believed technical assistance would have the most utility for phase ii nasa award recipients .

during at least a portion of the period we reviewed , all five agencies offered individualized technical assistance for phase ii award recipients , although doe curtailed such assistance in 2010 , and nasa discontinued its assistance in 2008 .

award recipients were selected for assistance on the basis of factors such as recommendations from sbir program staff and the award recipients' potential for rapidly moving their technologies to phase iii .

the assistance consisted of in - depth training and one - on - one assistance from advisors and industry experts .

for example , as part of its commercialization pilot program , the army assisted selected phase ii sbir award recipients in assessing commercialization potential , developing business plans , and matching their technologies with potential government and industry customers .

at doe , staff could nominate phase ii award recipients for assistance in preparing to negotiate business deals , for example , including joint ventures and licensing agreements for use of their technologies .

doe officials told us that in 2010 the agency curtailed its use of sbir funds for phase ii technical assistance , spending such funds on assistance only for award recipients that had specifically budgeted for it in their applications .

in 2007 and 2008 , nasa partnered with the navy to pilot a technical assistance program for nasa phase ii recipients .

the program was designed to help sbir businesses develop a plan for transitioning to phase iii , among other things .

in 2007 , 17 phase ii companies with 19 sbir projects participated in the program , and in the following year , 19 phase ii companies with 20 sbir projects participated .

the program was not renewed for 2009 ; nasa officials told us that they believed the program was generally successful , but that they preferred to use sbir funds to make larger awards .

nih offered selected current or past phase ii award recipients the opportunity to work one - on - one with an advisor over a 9-month period to develop business plans to commercialize their technologies , as well as to prepare materials to help attract potential investors or partners .

since 2004 , almost 700 award recipients have received the assistance , including the 80 award recipients currently participating , according to nih officials .

finally , nsf offered customized assistance to phase ii award recipients through its innovation accelerator initiative .

according to nsf officials , through this initiative , award recipients received help in connecting with potential investors and negotiating company acquisitions and mergers .

nsf officials told us that , in 2010 , approximately 33 percent of nsf's phase ii recipients received this assistance .

in some cases , agencies that we reviewed used non - sbir funds to broaden the scope of the technical assistance they provided to help award recipients commercialize their technologies .

for example , dod used non - sbir funds to host its annual beyond phase ii conference and technology showcase , a 3-day event that features matchmaking sessions with sbir award recipients and prime contractors .

similarly , the navy used non - sbir funds to maintain databases with advanced searching capability to help award recipients identify potential business partners .

the navy also used non - sbir funds for its transition assistance program , which provides individualized help with commercialization planning , culminating in a conference designed to facilitate interaction with potential business partners .

moreover , in 2011 , the national cancer institute launched its regulatory assistance program using non - sbir funds .

according to agency officials and information from the agency's web site , this program provides sbir award recipients time with consultants experienced in various regulatory requirements — such as those for anticancer therapies , imaging technologies , and medical devices — to prepare strategies for obtaining regulatory approvals required before the technologies can be commercialized .

the national cancer institute also used non - sbir funds to support its investor forum , which provides competitively selected sbir award recipients an opportunity to showcase their technologies and enter into discussions with the biotech investment community .

in 2010 , 14 award recipients that were selected on the basis of strength of research , impact on cancer , product development , and market potential participated in the forum along with more than 175 potential investors , according to the agency's web site .

matching funds programs .

through matching funds programs , agencies provide additional sbir funds to award recipients that obtain monetary commitments above certain thresholds from outside investors .

sba has designated matching funds programs as a best practice on its sbir web site , and all of the agencies we reviewed except doe have established such programs .

for example , for award recipients that obtain a minimum of $100,000 from an outside investor , nsf will match up to 50 percent of the outside investment for a maximum of $500,000 in nsf matching funds .

nasa and nih officials said that matching funds programs encourage outside investment during the early stages of r&d — a time when many investors are reluctant to invest .

in particular , officials at the national cancer institute said that matching funds can help attract outside investment because they can be used as leverage to increase investors' potential returns .

dod and nsf offer matching funds to award recipients at the end of phase i and during phase ii , while nasa and the national cancer institute offer matching funds during phase ii .

doe has not established a matching funds program for its sbir program .

doe officials told us , however , that they are exploring whether to do so and have held discussions with other sbir participating agencies about their matching funds programs .

officials at dod , nasa , and nih said they have not collected data to compare the commercialization success of recipients that received matching funds with the success of those that did not .

nsf conducted a study to assess the effect of the $18 million in matching funds it invested in fiscal year 2006 for 48 phase ii award recipients that had raised a total of $58 million from outside investors .

according to nsf officials , results of this study showed that , in the 5 years following the start of these phase ii projects , 70 percent of recipients that had received matching funds achieved commercial success compared with a 30 percent success rate for recipients that had not received such funds .

sba's guidance states that small businesses owned by disadvantaged individuals and women must compete for sbir awards on the same basis as all other small businesses .

however , to meet requirements for greater outreach to small businesses owned by disadvantaged individuals and women , sba has encouraged participating sbir agencies to reach out to such businesses and to develop methods that encourage their participation .

sba has also raised the topic of outreach during recent quarterly meetings of agency sbir program managers .

officials at all of the agencies we reviewed told us they generally reach out to such businesses through activities directed toward a broader audience , such as by attending sbir national conferences and industry - sponsored events and by sharing information via web sites or e - mail lists .

agency officials also noted that they try to accommodate requests for speakers at events sponsored by , or likely to be attended by , small businesses owned by disadvantaged individuals and women — for example , events sponsored by trade organizations for minority - or women - owned businesses .

however , officials from some trade organizations for businesses owned by disadvantaged individuals and women told us that the outreach of agencies we reviewed was often ineffective in educating the organizations' members about the sbir program .

of the agencies we reviewed , nih and nsf have made specific efforts , including the following , to improve their outreach:  for fiscal years 2010 and 2011 , nih developed a goal to increase awareness of its sbir program among businesses owned by disadvantaged individuals and women , and it outlined specific activities aimed at reaching this goal .

 both nih and nsf offered various fellowships for postdoctoral research conducted by disadvantaged individuals and women ; these fellowships were available to support sbir projects , as well as other research .

in 2010 , nsf assigned a full - time staff member to help it develop a plan to increase participation in sbir by businesses owned by disadvantaged individuals and women in response to a recommendation from its sbir advisory committee .

 through a review of academic literature , as well as informal polling of nsf applicants and award recipients , nsf has identified barriers to sbir participation by small businesses owned by disadvantaged individuals and women , nsf officials told us .

these barriers include disparities in the owners' levels of education and access to capital compared with those of other entrepreneurs .

to address identified barriers , nsf is , among other things , establishing partnerships with industry and academia to expose african american , latino , and other college students to entrepreneurship in scientific and technical fields , according to nsf officials .

evaluation of the effectiveness of agencies' outreach efforts is hindered by a lack of accurate and complete data .

although sba collects data on the number and dollar value of awards to small businesses owned by disadvantaged individuals and women , sba officials told us that they cannot accurately tabulate data on such awards , particularly awards to women - owned businesses , because of inconsistencies in the data on business ownership .

according to the officials , sba has taken steps to correct the inconsistencies for data submitted after 2006 but has not done so for earlier years .

moreover , sba does not collect data on the number of applications submitted by businesses owned by disadvantaged individuals and women .

as a result , sba's data do not allow for an examination of trends in the submission of applications from such businesses , analysis of the percentage of applications from these businesses that lead to awards , or correlation of these trends and percentages with outreach efforts .

sba officials told us in march 2011 that they were considering whether their database should include information on the numbers of applications submitted by these businesses .

sba has not yet developed the government - use portion of its database for collecting comparable commercialization data on sbir technologies , but it is taking steps to do so .

in the interim , agencies have , for their own purposes , independently gathered commercialization data that are not comparable ; the accuracy of these data is largely unknown .

implementing the government - use portion of the database should improve the comparability of the data .

however , programwide evaluation of progress in increasing commercialization may continue to be impaired by long - standing challenges .

as of june 2011 , sba had not met the legislative mandate to develop and implement , by june 2001 , a government - use database that can provide data on commercialization for evaluating the sbir program .

however , the agency's efforts to develop such a database recently gained additional prominence and resources .

specifically , sba linked development of the government - use portion of its database to one of the agency's high - priority performance goals for fiscal years 2011 and 2012 .

additionally , in september 2010 , sba allocated $1.4 million in recovery act funds to hire a new contractor to develop the government - use portion's capacity to accept commercialization data submitted by participating sbir agencies and award recipients , as well as to make other improvements to the database .

for example , sba said that it has been working with the contractor to consolidate data on previous awards .

sba officials said that past award recipients have been assigned unique identifiers that will be used to track awards issued to those recipients over the lifetime of the sbir program ; unique identifiers are also to be assigned to small businesses newly entering the program .

in the future , sba intends for the unique identifiers to allow agencies to validate business information by comparing it against information in other federal databases such as the central contractor registration database , which contains information on businesses that want to contract with the federal government .

sba officials told us that they expect to implement the government - use portion of sba's database by august 2011 and to provide for its basic maintenance and support despite reductions in the agency's overall budget .

the government - use portion is intended to allow both participating agencies and award recipients to enter commercialization data in a comparable format to assist in program evaluation .

sba officials told us that they have worked with participating agencies to develop common metrics for commercialization data , as well as a standardized data collection instrument that will accommodate the various types of sbir technologies the agencies fund to meet their different missions .

these metrics , which will correspond to fields in the database , include the following: indication of whether an award resulted in a commercialized technology and whether other sbir awards contributed to commercialization of the technology ;  estimated investment ( other than sbir funding ) ;  any patents applied for or received related to the award ; and  any initial public offering , merger , or sale of the business that resulted , at least in part , from the award .

sba officials told us in may 2011 that they plan to implement the metrics and data collection instrument in august 2011 .

sba is requesting that participating agencies voluntarily begin entering historical commercialization data into the government - use database before august 2011 .

to facilitate this process , sba is working with its contractor to ensure that historical agency data can be matched to fields in the new database .

nevertheless , officials from sba and participating sbir agencies said that some agencies may not enter historical data or may be delayed in doing so because they either did not collect such data or do not have the data in electronic form .

for example , nasa officials stated that much of their commercialization data are stored in paper format and expressed doubt that the agency would be able to convert the data into the required format for entering by sba's august deadline .

sba officials also told us that , after the government - use portion of the database is available , some agencies may instruct applicants and award recipients to submit their commercialization data directly into the database .

other agencies , such as dod , may continue to require applicants and recipients to submit commercialization data directly to the agencies , which would then upload the data into the database .

as of may 2011 , sba officials were unsure which approach agencies would take , noting that agencies may wait to see how the database works before making a decision .

in the absence of the government - use portion of sba's database , the five participating sbir agencies we reviewed have independently collected commercialization data that are not comparable .

the agencies collected these data using various methods for their own purposes , as summarized in table 1 .

in conducting their data collection efforts , agencies differed in the extent to which they asked award recipients to do the following , among other things: identify the type of customer and the amount of sales or further investment for sbir - funded technologies .

for example , most agencies asked award recipients to report federal and nonfederal sales separately , but nih and nsf asked award recipients to report combined sales .

 account for indirect sales and nonfinancial indicators of commercialization .

nasa , nih , and nsf asked award recipients to indicate whether an sbir - funded technology had resulted in licensing agreements with other businesses to sell the technology , while dod and doe did not ask that question .

nasa further asked award recipients to estimate the financial value of such agreements , while the other agencies did not .

similarly nasa , nih , and nsf asked award recipients to indicate whether specific sbir - funded technologies had resulted in patents , while dod and doe asked award recipients to report the total number of patents resulting from all their sbir awards .

 quantify the dollar values of cumulative sales .

while most agencies asked award recipients to report a specific dollar amount in cumulative sales resulting from their sbir - funded technologies over a period of time , nih asked award recipients to report such sales by choosing among ranges , beginning with “$50,000 or less” and extending to “$50,000,000 or more.” because nih has reported cumulative sales in ranges rather than specific dollar amounts , comparing its results with those reported by other agencies is difficult .

while each agency's data collection efforts resulted in , among other information , estimates of total or average sales of sbir technologies , differences in the agencies' data collection efforts make it difficult to compare results across agencies .

the following are examples of commercialization data reported by agencies:  dod estimated that commercialization of sbir technologies that it funded generated federal and nonfederal sales and non - sbir funding of $22 billion on a program investment of $11 billion from 2000 through march 2010 .

 doe estimated that , from 1986 through 2007 , sbir technologies developed by recipients of phase ii awards resulted in a total of $2.4 billion in federal and nonfederal sales and $1.6 billion in non - sbir investment .

on average , award recipients reported receiving more than $3 million in sales related to sbir - funded technologies .

during the same period , doe reported that it had invested $1.6 billion in phase i and ii sbir awards .

 nasa estimated that , as of 2002 , sbir technologies developed by award recipients that received a phase ii award from 1983 through 1996 had generated approximately $2.8 billion in federal and nonfederal sales and non - sbir funding compared with $1.1 billion in sbir investment from nasa .

in nih's 2002 survey , which covered 1992 through 2001 , 27 percent of respondents reported an estimated total of $821 million in sales of sbir technologies ; the other respondents did not report any sales .

nih estimated that it invested $2.2 billion in phase i and phase ii awards from 1992 through 2001 .

for the 2008 survey , which covered 2002 through 2006 , 33 percent of respondents reported an estimated total of $396 million in federal and nonfederal sales of sbir technologies .

nih estimated that it invested $2.7 billion in phase i and phase ii awards from 2002 through 2006 .

nih was the only agency we reviewed that reported sales lower than its sbir investment for the periods it examined .

according to nih officials , many of the technologies that the agency supports through its sbir program , such as drugs and medical devices , take longer to commercialize than those funded by other agencies because of the need for extensive clinical testing and regulatory approval .

 nsf officials estimated that recipients marking the eighth anniversary of the receipt of their awards from july 2005 through may 2010 had realized a total of $1.05 billion in commercial revenue .

nsf estimated that it invested $628 million in sbir awards during roughly the same period .

further , with the exception of dod , agencies we reviewed generally did not take steps to verify commercialization data that they received from award recipients , so the accuracy of the data is largely unknown .

as officials from some of the agencies in our review noted , award recipients may have an incentive to overstate their commercialization success in the hope of improving their prospects of receiving future sbir awards .

while sba has worked with sbir agencies to identify best practices in other areas of sbir program management , it has not identified best practices for agencies to use in verifying the accuracy of commercialization data .

without consistent practices for verifying the accuracy of these data , the usefulness of the government - use portion of sba's database as a tool for evaluating the sbir program's success in increasing commercialization may be limited .

to verify the accuracy of award recipients' commercialization data , dod performs an annual review of all projects in its company commercialization database , which contains the commercialization data it gathers from award recipients .

this review includes checks to ensure that prior award recipients applying for new awards are not reporting the same project results more than once , substituting the results of one project for that of another , or incorrectly reporting sales to third parties .

according to dod officials , after its 2010 review , the agency sent approximately 300 e - mail queries to applicants whose reported commercialization data were identified as having potential problems .

the officials said that applicants that do not respond to such queries are blocked from submitting further applications until concerns related to their commercialization reports are addressed .

even with these verification activities , however , army officials expressed concern to us about the accuracy of the applicants' self - reported commercialization data ; these officials stated their preference for using data from the federal procurement data system , which contains government information on federal contracts , including sales .

moreover , a navy official acknowledged the possibility that additional verification activities , such as selective spot visits to sbir award recipients , could further deter recipients from misrepresenting their commercialization success , although he noted that such activities would compete with other administrative priorities .

similarly , officials from doe and nih stated that additional verification activities would be useful but also said that they needed to devote program administration resources to higher priority activities , such as preparing solicitations and supporting review panels for applications .

sba's implementation of the government - use portion of its database should improve the comparability of commercialization data available for programwide evaluation .

nevertheless , long - standing challenges may continue to impair programwide evaluation of progress in increasing commercialization of sbir - funded technologies .

as we reported in october 2006 , notable among these challenges is that prior award recipients that are no longer participating in the sbir program are not required to provide updated commercialization data and may prefer not to do so .

for example , dod indicated in written comments to us that , from 2008 to 2010 , 46 percent of nonparticipating prior phase ii award recipients did not provide updates despite dod's request that they update commercialization data annually after their awards ended .

similarly , in a report on its 2002 survey , nasa observed that many recipients of multiple awards elected not to respond to its survey despite “extensive telephone follow - up” and that many recipients that ultimately responded “would likely have preferred not to.” some award recipients may be reluctant to provide commercialization data because the data are business - sensitive .

sba officials told us that mechanisms to require or encourage nonparticipating recipients to report their data need to be explored .

a nasa official told us that effective incentives to encourage wider voluntary reporting might include publicizing commercial success or giving monetary prizes for success .

the difficulties agencies face in persuading prior award recipients to volunteer commercialization information can be compounded by challenges in maintaining contact with them .

specifically , prior award recipients can change names or personnel , go out of business , or be sold during the 10 or more years that it can take for an sbir - funded technology to reach the marketplace .

in nih's 2002 survey of award recipients , for example , the portion of the sample that was “unusable” — a group that consisted primarily of recipients that no longer existed or could not be found — increased from 2 percent in the first year after the end of the award to 52 percent in the tenth year .

programwide evaluation — particularly efforts to compare commercialization success across agencies — can also be complicated by differences in the time required to commercialize various types of sbir - funded technologies .

comparing agencies' commercialization results at a given point in time may not present a true picture of each agency's success because some agencies fund technologies that are relatively close to being market - ready while others fund technologies that need more extensive development or regulatory approval .

furthermore , as we have previously reported , the sbir program's other goals remain important , and comparisons that focus on commercialization may not adequately take into account progress toward these goals .

for example , one agency official told us that some sbir - funded technologies , such as those related to national security , may never have great commercial potential but are important to the agency's mission .

dod , doe , nasa , nih , and nsf have designed their sbir solicitations to address the program's purposes of using small businesses to meet federal r&d needs , stimulating technological innovation , and increasing commercialization of innovations derived from federal r&d efforts , and they have further addressed commercialization by providing technical assistance or matching funds to award recipients .

these agencies have also conducted outreach and other activities to address the sbir purpose of encouraging participation in technological innovation by small businesses owned by disadvantaged individuals and women .

however , evaluation of progress in achieving the program's purposes is impeded by a lack of accurate , comparable , and complete data on program results .

for example , it is difficult to evaluate the program's effectiveness in encouraging small businesses owned by disadvantaged individuals or women to participate in technological innovation because sba does not collect data on the number of applications submitted by such businesses .

it is also difficult to evaluate the program's effectiveness in increasing commercialization of sbir - funded technologies because , although agencies participating in the program have gathered commercialization data for their own purposes , comparable data on commercialization are not available across agencies .

sba's planned implementation of a government - use portion of its database should go some way toward improving the comparability of the commercialization data as they are systematically collected using common metrics .

however , the commercialization data that the database is intended to contain are largely self - reported by award recipients that may have an incentive to overstate their commercialization success .

dod has adopted practices for verifying the accuracy of commercialization data it collects from prior award recipients , but most of the participating agencies we reviewed did not verify the accuracy of commercialization data from their prior award recipients , and sba has not identified best practices for participating agencies to use in doing so .

as long as participating agencies do not consistently verify the accuracy of commercialization data , the usefulness of the government - use portion of sba's database as a tool for evaluating the sbir program's success in increasing commercialization may be limited .

to build upon efforts to implement a government - use database for program evaluation , we recommend that the administrator of the small business administration work with participating sbir agencies to take the following two actions: collect data on the number of applications submitted by small businesses owned by disadvantaged individuals and women , and identify best practices for verifying the accuracy of data related to progress in increasing commercialization .

we provided a draft of this report to sba , the departments of defense and energy , the national aeronautics and space administration , the national institutes of health , and the national science foundation for review and comment .

sba generally agreed with our findings as well as our recommendations , which it offered an action plan to address .

specifically , with respect to our first recommendation , sba stated that , beginning in fiscal year 2012 , it plans to use its database to collect information from agencies about applicants that did not receive awards — information that could include whether the applicants were small businesses owned by disadvantaged individuals or women .

further , sba indicated that it plans to hold a workshop in fall 2011 for participating sbir agencies to share best practices for reaching out to small businesses owned by disadvantaged individuals .

according to sba , the workshop should result in a commitment from agencies to develop baselines for numbers of applications from such businesses .

regarding our second recommendation , sba indicated that it will seek to identify best practices and methods for verifying the accuracy of commercialization data and will work with agencies toward implementation of those practices and methods .

sba also noted that its effort to collect commercialization data is intended to establish a baseline , against which sba can review progress in increasing commercialization .

sba's letter conveying its comments is contained in appendix ii .

among the sbir participating agencies that we reviewed , doe and nsf concurred with our recommendations and provided general comments , which are included in appendixes iii and iv , respectively .

both doe and nsf also made technical comments , which we have incorporated into our report as appropriate .

in its general comments , doe stated that it collects information on the number of applications submitted by small businesses owned by disadvantaged individuals and women and is willing to report the data to sba .

doe further stated that it does not verify commercialization data because of resource limitations — not a belief that verification is of limited value — and it expressed an interest in learning about best practices for verification of these data .

in addition , doe commented that , until universal metrics are identified for measuring the success of sbir programs across agencies , the compatibility of available data among agencies will remain a secondary concern .

nsf stated that it concurs with the underlying goals of our recommendations .

moreover , nsf affirmed its commitment to implementation of a government - use database for program evaluation , collection of data on participation in small business innovation , and identification of best practices for verification of commercialization data .

the remaining agencies — dod , hhs , and nasa — neither agreed nor disagreed with our recommendations but provided technical comments , which we have incorporated into our report as appropriate .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the appropriate congressional committees , administrators of sba and nasa , secretaries of defense and energy , directors of nih and nsf , and other interested parties .

in addition , this report will be available at no charge on the gao web site at http: / / www.gao.gov .

if you or your staff members have any questions about this report , please contact me at ( 202 ) 512-3841 or ruscof@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix v .

in conducting this study , we reviewed small business innovation research ( sbir ) program - related activities of the small business administration ( sba ) and 5 of the 11 sbir participating agencies — the department of defense ( dod ) , department of energy , national aeronautics and space administration , department of health and human services' national institutes of health ( nih ) , and national science foundation ( nsf ) .

for the two agencies with the largest sbir budgets — dod and nih — we reviewed program activities conducted by the three participating subcomponent agencies with the largest sbir budgets because some key activities are carried out at that level .

specifically , for dod , we examined the sbir programs of the army , air force , and navy , and for nih , we examined the programs of the national institute of allergy and infectious diseases ; the national cancer institute ; and the national heart , lung , and blood institute .

the five participating agencies we reviewed accounted for about 96 percent of the total dollars awarded by the program in fiscal year 2009 .

we reviewed applicable laws and regulations and literature on the sbir program , including our prior reports and assessments by a committee of the national academy of sciences' national research council .

to obtain further context for our review , we attended two national conferences and a national research council workshop on the sbir program , and we interviewed national research council staff with program expertise .

more specifically , to determine how participating agencies have addressed the sbir program's four overarching purposes when implementing their programs , we reviewed sba documents and data , including sba's policy directive on implementation of the sbir program , minutes from selected meetings of sba and sbir program directors , sba's sbir annual report for fiscal year 2008 ( the latest year for which an annual report was available ) , and data on the dollar value of sbir awards by participating agencies in fiscal year 2009 ( the latest year for which sba could provide the data ) .

we examined relevant documents from participating agencies for fiscal years 2008 through 2010 , and for fiscal year 2011 when possible .

documents we reviewed included solicitations for applications issued by each of these agencies , instructions to applicants , minutes from meetings of sba and sbir program directors , performance plans and reports , descriptions of commercialization assistance provided to sbir awardees , and minutes from meetings of agency advisory committees .

in addition , we also identified and interviewed sbir program officials at each agency and officials responsible for implementing programmatic goals .

for these interviews , we asked a standard set of questions to help ensure that we obtained consistent information about the sbir programs at each of the agencies .

we also interviewed inspector general staff at nsf , which facilitated sbir - related activities conducted by the council of inspectors general on integrity and efficiency .

finally , we interviewed representatives of trade associations about their views of the sbir program .

we selected the trade associations on the basis of their familiarity with the program , the technologies on which they focus , and whether their membership includes small businesses owned by disadvantaged groups and women .

the views of the representatives of these associations cannot be generalized to other associations .

to determine the extent of sbir program data available to evaluate progress in increasing commercialization of sbir technologies , we reviewed documents related to sba's sbir database , including terms of work , work schedules , and proposed guidance related to the development of the government - use portion of the database .

for the five sbir participating agencies whose programs we reviewed , we examined documents dating from 2002 through 2011 ; these documents reflected commercialization data for sbir award recipients that had received awards from 1983 ( the first year in which agencies issued sbir awards ) through 2010 .

the documents we reviewed included surveys and other data collection instruments that the agencies used to gather commercialization information from award recipients ; reports on data collection results , including any information on sbir award spending during the years corresponding to those covered in each of the commercialization data collection efforts ; and anecdotal descriptions of commercialization success .

we also reviewed agency solicitations from fiscal years 2008 through 2010 — and for fiscal year 2011 when possible — that contained reporting requirements for award recipients .

we interviewed officials at sba and each of the five participating agencies included in our review to obtain information on the specific commercialization metrics they use to monitor the commercialization experience of award recipients , the history of each agency's data collection efforts , and the agencies' experience in obtaining such information from current and past award recipients .

we conducted this performance audit from june 2010 to august 2011 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence we obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the individual named above , key contributors to this report include cheryl williams , assistant director ; antoinette capaccio ; stephen carter ; nancy crothers ; laurie ellington ; cindy gilbert ; cynthia norris ; christine senteno ; and kiki theodoropoulos .

