the march 2004 bombings of the rail system in spain , july 2005 bombings of london's subway system , and august 2006 alleged terror plot to bring liquid explosives through airport security checkpoints in the united kingdom and detonate them on board aircraft bound for the united states , are striking reminders that transportation systems have continued to be a target for terrorist attack .

after the september 11 , 2001 terrorist attacks , the aviation and transportation security act ( atsa ) was enacted , creating the transportation security administration ( tsa ) and mandating that it assume responsibility for security in all modes of transportation .

for the last 5 years , tsa has spent billions of dollars to screen airline passengers and checked baggage and to implement regulations and initiatives designed to strengthen the security of commercial aviation .

tsa has also taken action to strengthen the security of surface modes of transportation , which includes mass transit and passenger rail , freight rail , and highways .

despite varying levels of progress in these respective areas , questions remain about the effectiveness of tsa's security programs and procedures .

one method that can be used to identify and mitigate vulnerabilities , measure the effectiveness of security programs , and identify needed changes to training procedures and technologies is undercover , or covert testing — also known as red team testing — which was advocated by the president's july 2002 national strategy for homeland security to identify security vulnerabilities in the nation's critical infrastructure and to help prepare for terrorist attacks .

regarding aviation security , and in accordance with requirements established in law , tsa conducts covert testing of passenger and checked baggage screening operations , as well as airport perimeter security and access controls , and requires that transportation security officers ( tso ) who fail tests to undergo remedial training .

prior to the creation of tsa , the federal aviation administration ( faa ) was responsible for ensuring compliance with aviation screening regulations and testing the performance of passenger and checked baggage systems in detecting threat objects .

tsa began conducting covert testing in commercial aviation in september 2002 .

covert testing is conducted at the national level by tsa's office of inspection ( oi ) and at the local , or individual airport level by the office of security operations ( oso ) — the division within tsa responsible for overseeing passenger and checked baggage screening at airports .

during these tests , undercover inspectors attempt to pass threat objects , such as simulated explosive devices , through airport passenger screening checkpoints and checked baggage screening systems .

inspectors also attempt to access secure areas of the airport undetected , such as through doorways leading to aircraft and the airport's perimeter .

the tests are designed to approximate techniques that terrorists may use in order to identify vulnerabilities in the people , processes , and technologies that comprise the aviation security system .

with respect to some non - aviation modes of transportation , specifically mass transit , passenger rail , and maritime ferries , tsa has initiated pilot programs designed to test the feasibility of implementing screening of passengers at a centralized checkpoint , similar to the aviation system .

according to oi officials , during these pilot programs , oi conducted covert testing to determine if they could pass threat objects through the passenger screening procedures and equipment that was being tested in these systems .

in addition , tsa's may 2007 transportation system sector specific plan ( ts - ssp ) for mass transit describes tsa's strategy for securing mass transit and passenger rail , and encourages that transit and rail agencies should develop covert testing exercises .

we have previously reported on the results of tsa's national and local aviation covert tests , both of which have identified vulnerabilities in the aviation security system , and the results of our investigators' tests of tsa's passenger checkpoint and checked baggage security systems , which have also identified vulnerabilities .

the department of homeland security ( dhs ) office of inspector general has also conducted its own covert testing of airport passenger and checked baggage screening , as well as perimeters and access controls , and has also identified vulnerabilities in these areas , most recently in march 2007 .

in light of the security vulnerabilities that covert testing has identified and concerns regarding the effectiveness of existing security procedures , you asked that we review tsa's national and local covert testing programs .

in response , on may 13 , 2008 , we issued a classified report addressing the following key questions: ( 1 ) what is tsa's strategy for conducting covert testing of the transportation system , and to what extent has the agency designed and implemented its covert tests to achieve identified goals ? .

and ( 2 ) what have been the results of tsa's national aviation covert tests conducted from september 2002 to june 2007 , and to what extent does tsa use the results of these tests to mitigate security vulnerabilities in the commercial aviation system ? .

as our may 2008 report contained information that was deemed to be either classified or sensitive , this version of the report is intended to generally summarize our overall findings and recommendations while omitting classified or sensitive security information about tsa's covert testing processes and the results of tsa's covert tests conducted from september 2002 to june 2007 .

as our intent in preparing this report is to convey , in a publicly available format , the non - classified , non sensitive results of the classified may 2008 report , we did not attempt to update the information here to reflect changes that may have occurred since the publication of the may 2008 report .

to identify tsa's strategy for conducting covert testing of the transportation system and the extent to which the agency has designed and implemented tests to achieve its goals , we reviewed applicable laws , regulations , policies , and procedures for national and local covert testing .

we interviewed tsa oi officials responsible for conducting national aviation covert tests , and oso officials responsible for local aviation covert tests , regarding tsa's strategy for designing and implementing these tests , including the extent to which they used threat information to guide their efforts .

we also observed oi inspectors during covert tests at seven airports , including airports with heavy passenger traffic and those with just a few flights per day , as well as airports with both tsos and contract screeners .

during these covert tests , we accompanied oi inspectors during all phases of the test including planning , testing , and post - test reviews with tsos and their supervisors .

we interviewed tsos and their supervisors that were involved in covert tests at each airport where we observed tests to discuss their experience with the national and local covert testing programs .

we also interviewed the federal security director ( fsd ) at each airport where we observed covert tests to obtain their views of the testing program and the results of tests at their airports .

while these seven airports represent reasonable variations in size and geographic locations , our observations of oi's covert tests and the perspectives provided by tsa officials at these airports cannot be generalized across all commercial airports .

however , our observations at the seven airports provided us with an overall understanding of how oi conducts covert tests and useful insights provided by tsos , their supervisors , and fsds at these airports .

we also reviewed tsa's procedures for screening passenger and checked baggage to determine how these procedures are used in designing and implementing national aviation covert tests .

we interviewed oi officials and officials from tsa's office of transportation sector network management ( tsnm ) , which is responsible for developing security policies for non - aviation modes of transportation , regarding the extent to which covert testing has been conducted in non - aviation modes , the applicability of covert testing in other modes , and future plans for conducting covert testing in other modes .

to understand how entities outside of tsa have used covert testing in non - aviation modes of transportation , we interviewed officials from dhs components and organizations that conduct covert testing , including u.s. customs and border protection , dhs domestic nuclear detection office ( dndo ) , amtrak , the united kingdom's department for transport security ( transec ) , and transportation industry associations , such as the american association of railroads and the american public transportation association .

to determine the results of tsa's national covert tests and the extent to which tsa used the results of these tests to mitigate security vulnerabilities in the aviation system , we obtained and analyzed a database of the results of tsa's national covert tests conducted from september 2002 to june 2007 .

to determine how tsa gathers covert testing data , we reviewed the data collection instruments used at the airports where we observed covert tests , as well as other methods oi uses to gather covert testing data and observations .

we also reviewed tsa's internal controls for collecting and maintaining the results of covert tests .

we assessed the reliability of tsa's covert testing data and the systems used to produce the data by interviewing agency officials responsible for maintaining the database .

we determined that the data were sufficiently reliable for our analysis and the purposes of this report .

we also interviewed oi officials regarding how the results of covert tests are used in developing their recommendations to tsa management .

we reviewed oi reports on the results of covert tests completed between march 2003 and june 2007 that were submitted to tsa's administrator and oso to identify oi's recommendations for mitigating the vulnerabilities identified during covert tests .

we further obtained and analyzed a summary of the actions that oso had taken to address oi's recommendations for mitigating vulnerabilities made from march 2003 to june 2007 .

more detailed information on our scope and methodology is contained in appendix i .

we conducted this performance audit from october 2006 to may 2008 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

congress and the administration have advocated the use of covert or red team testing in all modes of transportation .

following the terrorist attacks on september 11 , 2001 , on november 19 , 2001 , the president signed atsa into law , with the primary goal of strengthening the security of the nation's commercial aviation system .

atsa created tsa within the department of transportation ( dot ) as the agency responsible for securing all modes of transportation .

among other things , atsa mandated that tsa assume responsibility for screening passengers and their property , which includes the hiring , training , and testing of the screening workforce .

atsa also mandated that tsa conduct annual proficiency reviews and provide for the operational testing of screening personnel , and that tsa provide remedial training to any screener who fails such tests .

in 2002 , the president issued the national strategy for homeland security that supports developing red team tactics in order to identify vulnerabilities in security measures at our nation's critical infrastructure sectors , including the transportation sector .

in 2007 , tsa issued the ts - ssp that outlines its strategy and associated security programs to secure the transportation sector .

while the ts - ssp does not address covert testing in aviation , it does identify that mass transit and passenger rail operators should develop covert testing exercises .

moreover , the implementing recommendations of the 9 / 11 commission act of 2007 requires dhs to develop and implement the national strategy for railroad transportation security , which is to include prioritized goals , actions , objectives , policies , mechanisms , and schedules for assessing the usefulness of covert testing of railroad security systems .

furthermore , the explanatory statement accompanying division e of the consolidated appropriations act , 2008 ( the dhs appropriations act , 2008 ) , directs tsa to be more proactive in red teaming for all modes of transportation .

specifically , the statement directs approximately $6 million of tsa's appropriated funds for red team activities to identify potential vulnerabilities and weaknesses in airports and air cargo facilities , as well as in transit , rail , and ferry systems .

prior to the creation of tsa , the department of transportation's federal aviation administration ( faa ) monitored the performance of airport screeners .

faa created the “red team,” as it came to be known , to assess the commercial aviation industry's compliance with faa security requirements and to test whether u.s. aviation passenger and checked baggage screening systems were able to detect explosives and other threat items .

tsa began its covert testing program in september 2002 .

tsa's covert testing program consists of a nationwide commercial aviation testing program conducted by oi , and a local commercial airport testing program implemented by oso and fsds at each airport .

oi conducts national covert tests of three aspects of aviation security at a commercial airport: ( 1 ) passenger checkpoint ; ( 2 ) checked baggage ; and ( 3 ) access controls to secure areas and airport perimeters .

oi conducts covert tests by having undercover inspectors attempt to pass threat objects , such as guns , knives , and simulated improvised explosive devices ( ied ) , through passenger screening checkpoints and in checked baggage , and to attempt to access secure areas of the airport undetected .

oi officials stated that they derived their covert testing protocols and test scenarios from prior faa red team protocols , but updated the threat items used and increased the difficulty of the tests .

according to oi officials , they also began conducting tests at airports on a more frequent basis than faa .

initially , oi conducted tests at all of the estimated 450 commercial airports nationwide on a 3-year schedule , with the largest and busiest airports being tested each year .

tsa also began using threat information to make tests more closely replicate tactics that may be used by terrorists .

the number of covert tests that oi conducts during testing at a specific airport varies by the size of the airport .

the size of the oi testing teams also varies depending upon the size of the airport being tested , the number of tests that oi plans to conduct , and the number of passenger checkpoints and access points to secure areas at a particular airport .

oi testing teams consist of a team leader who observes the tests and leads post - test reviews with tsos , and inspectors who transport threat items through passenger checkpoints and secure airport areas and record test results .

team leaders usually have previous federal law enforcement experience , while inspectors often include program analysts , administrative personnel , and other tsa personnel .

prior to testing , each team leader briefs their team to ensure that everyone understands their role , the type of test to be conducted , and the threat item they will be using .

for tests at passenger checkpoints and in checked baggage , oi uses different ied configurations and places these ieds in various areas of each inspector's body and checked baggage to create different test scenarios .

figure 1 provides an overview of tsa's passenger checkpoint and checked baggage screening operations and equipment .

according to oi officials , on the day of testing , oi typically notifies the airport police about one half hour , and the local fsd 5 minutes , before testing begins and instructs them not to notify the tsos that testing is being conducted .

oi officials stated that they provide this notification for security and safety reasons .

during passenger checkpoint testing , each team of inspectors carries threat items through the passenger checkpoint .

if the tso identifies the threat item during screening , the inspector identifies him or herself to the tso and the test is considered a pass .

if the tso does not identify the threat item , the inspector proceeds to the sterile area of the airport and the test is considered a failure .

for each test , inspectors record the steps taken by the tso during the screening process and test results , and the team leader assigns any requirements for remedial training as a consequence of a failed test .

the specific types of covert tests conducted by tsa at the passenger checkpoint is sensitive security information and cannot be described in this report .

covert tests of checked baggage are designed to measure the effectiveness of the tsos' ability to utilize existing checked baggage screening equipment , not to test the effectiveness of the screening equipment .

in covert tests of checked baggage screening , an inspector poses as a passenger and checks their baggage containing a simulated threat item at the airline ticket counter .

the bag is then screened by tsos using one of two checked baggage screening methods .

at airports that have explosive detection systems ( eds ) , the tso uses these machines to screen each bag .

at airports that do not have eds and at airports where certain screening stations do not have eds , such as curbside check - in stations , the tsos use an explosive trace detection ( etd ) machine to screen checked baggage .

during the etd screening process of both carry - on and checked baggage , tsos attempt to detect explosives on passengers' baggage by swabbing the target area and submitting the swab into the etd machine for chemical analysis .

if the machine detects an explosive substance , it alarms , and produces a readout indicating the specific type of explosive detected .

the tso is then required to resolve the alarm by performing additional screening steps such as conducting a physical search of the bag or conducting further etd testing on and x - raying of footwear .

when testing eds and etd screening procedures , oi uses fully assembled objects such as laptop computers , books , or packages .

whether using eds or etd , if the tso fails to identify the threat item , the inspectors immediately identify themselves to stop the checked baggage from being sent for loading onto the aircraft , and the test is considered a failure .

if the tso identifies the threat item , the inspectors also identify themselves and the test is considered a pass .

if the oi inspector determines that the test failure was due to the screening equipment not working correctly , the test is considered invalid .

oi conducts two types of checked baggage covert tests: opaque object: this test is designed to determine if a tso will identify opaque objects on the x - ray screen and conduct a physical search of the checked bag .

during these tests , oi inspectors conceal a threat item that cannot be penetrated by the x - ray and appears on the eds screen as an opaque object among normal travel objects within checked baggage .

ied in bag: this test is designed to determine if a tso will identify an ied during a search of the bag and use proper etd procedures to identify it as a threat .

during these tests , oi inspectors conceal a simulated ied within checked baggage .

in addition , the ied may be contained within other objects inside of the bag .

oi inspectors conduct covert tests to determine if they can infiltrate secure areas of the airport , such as jet ways or boarding doors to aircraft .

each u.s. commercial airport is divided into different areas with varying levels of security .

secure areas , security identification display areas ( sida ) , and air operations areas ( aoa ) are not to be accessed by passengers , and typically encompass areas near terminal buildings , baggage loading areas , and other areas that are close to parked aircraft and airport facilities , including air traffic control towers and runways used for landing , taking off , or surface maneuvering .

figure 2 is a diagram of the security areas at a typical commercial airport .

if inspectors are able to access secure areas of the airport or are not challenged by airport or airline employees , then the test is considered a failure .

oi conducts four types of covert tests for airport access controls .

access to sida: during these tests , oi inspectors who are not wearing appropriate identification attempt to penetrate the sida through access points , such as boarding gates , employee doors , and other entrances leading to secure areas to determine if they are challenged by airport or airline personnel .

access to aoa: during these tests , oi inspectors who are not wearing appropriate identification attempt to penetrate access points leading from public areas to secured areas of the aoa , including vehicle and pedestrian gates through the perimeter fence , cargo areas , and general aviation facilities that provide a direct path to passenger aircraft in secure areas to determine if they are challenged by airport or airline personnel .

access to aircraft: during these tests , oi inspectors who are not wearing appropriate identification or who do not have a valid boarding pass attempt to penetrate access points past the passenger screening checkpoint which lead directly to aircraft , including boarding gates , employee doors , and jet ways to determine if they are challenged by airport or airline personnel .

sida challenges: during these tests , oi inspectors attempt to walk through secure areas of the airport , such as the tarmac and baggage loading areas , without appropriate identification to determine if they are challenged by airport personnel .

if not challenged , then the test is considered a failure .

after testing at the airport is complete , team leaders conduct post - test reviews with the tsos , supervisors , and screening managers involved in the testing .

these post - test reviews include a hands - on demonstration of the threat items used during each test and provide an opportunity for tsos to ask questions about the test .

according to oi officials , the purpose of these post - test reviews is to serve as a training tool for tsos .

following the post - test review , oi officials meet with the airport fsd to discuss the test results and any vulnerabilities identified at the airport .

oi also provides the fsd with the names of each tso required to undergo remedial training .

oi usually completes all aspects of its covert tests at an airport within several days .

after completing tests at each airport , oi staff document test results on standardized data collection instruments and meet to discuss the results and identify the actions that they will recommend to tsa management to address the vulnerabilities identified by the tests .

the airport testing data collected are then inputted into a database by oi headquarters staff , who develop reports that summarize the tests results and the vulnerabilities identified .

these reports are then presented to tsa management , such as the administrator .

oi staff also regularly brief tsa's administrator and management , such as the assistant administrator of oso , on the results of covert tests .

since 2003 , when oi completed its first covert testing report , most of oi's reports contained specific recommendations aimed at addressing the vulnerabilities identified during covert testing .

in february 2004 , oso authorized fsds to conduct their own testing of local passenger and checked baggage screening operations at their airports to serve as a training tool for the tsos and to measure their performance .

referred to as screener training exercises and assessments ( stea ) , fsds conducted these local covert tests using federal employees , such as tsos from other local airports and other federal law enforcement officers , and were given discretion to determine the number of tests conducted at their airports , the manner with which the tests were conducted , and the type of tests conducted .

oso considered stea a tool for training tsos in detecting threat items , and issued modular bomb kits ( mbs ii kits ) containing simulated ieds to be used during local testing .

during stea tests , staff placed simulated ieds in passenger and checked baggage to determine if they would be detected by tsos .

unlike oi's national covert tests , stea tests did not include tests of airport access controls .

tsos that failed stea tests were required to undergo remedial training .

in may 2005 , we reported that tsa officials stated that they had not yet begun to use data from stea testing to identify training and performance needs for tsos because of difficulties in ensuring that local covert testing was implemented consistently nationwide .

for example , because fsds had discretion regarding the number of tests conducted , some airports conducted stea tests regularly , while others rarely conducted tests .

in addition , we previously reported that fsds had difficulty in finding enough staff to help conduct stea tests on a consistent basis .

oso officials recognized the limitations of the stea program and , as a result , began to re - structure the program in september 2006 .

this local covert testing program was renamed the aviation screening assessment program ( asap ) .

asap is designed to test the performance of passenger and checked baggage screening systems and identify security vulnerabilities at each airport .

in april 2007 , oso began its initial 6-month cycle of asap , in which 1,600 tests were conducted in each grouping of airports — category x ( 27 airports ) , category i ( 55 airports ) , and category ii through iv ( 369 airports ) .

oso compliance inspectors at each airport conduct the tests .

specific test requirements are distributed to fsds before the start of each 6-month cycle .

these test requirements stipulate the percentage of tests to conduct during peak and non - peak passenger screening periods ; the percentage of basic , intermediate , or advanced tests to be conducted ; and specific types of threat items that should be used during each type of test , such as ieds or weapons .

following each test , inspectors are to brief the tsos , supervisors , and screening managers involved in the tests on the results and notify the fsd of the results .

with the first cycle of tests initiated in april 2007 , tsa officials plan that any recommendations resulting from asap tests will be submitted to oso management and other offices within tsa that need to know the test results .

although the testing requirements , including the level of frequency and types of tests , will not change during the initial 6-month cycle to preserve the validity of the test results , tsa officials plan to analyze the results of the tests and evaluate the need to revise the structure of the tests or the type of threat items used after testing is complete .

according to oso officials , the first cycle of asap tests are complete , but the results are still being analyzed by tsa to determine the overall findings from the tests .

tsa's national and local aviation covert testing programs contribute to tsa's broader risk management approach for securing the transportation sector by applying principles of risk assessment to identify vulnerabilities in commercial aviation .

risk management is a systematic and analytical process to consider the likelihood that a threat will endanger an asset , individual , or function , and to identify actions to reduce the risk and mitigate the consequences of an attack .

risk management , as applied in the homeland security context , can help federal decision - makers determine where and how to invest limited resources within and among the various modes of transportation .

in recent years , the president , through homeland security presidential directives ( hspd ) , and laws such as the intelligence reform and terrorism prevention act of 2004 , have provided that federal agencies with homeland security responsibilities should apply risk - based principles to inform their decision making regarding allocating limited resources and prioritizing security activities .

the 9 / 11 commission recommended that the u.s. government should identify and evaluate the transportation assets that need to be protected , set risk - based priorities for defending them , select the most practical and cost - effective ways of doing so , and then develop a plan , budget , and funding to implement the effort .

in 2002 , the president issued the national strategy for homeland security that instructs the federal government to allocate resources in a balanced way to manage risk in our border and transportation security systems while ensuring the expedient flow of goods , services , and people .

further , the secretary of dhs has made risk - based decision - making a cornerstone of departmental policy .

in may 2007 , tsa issued the ts - ssp and supporting plans for each mode of transportation that establish a system based risk management approach for securing the transportation sector .

we have previously reported that a risk management approach can help to prioritize and focus the programs designed to combat terrorism .

a risk assessment , one component of a risk management approach , consists of three primary elements: a vulnerability assessment , a threat assessment , and a criticality assessment .

a vulnerability assessment is a process that identifies weaknesses in physical structures , personnel protection systems , processes , or other areas that may be exploited by terrorists , and may suggest options to eliminate or mitigate those weaknesses .

tsa uses both national and local aviation covert testing as a method to identify and mitigate security vulnerabilities in the aviation sector .

a threat assessment identifies and evaluates threats based on various factors , including capability and intentions as well as the lethality of an attack .

criticality assessment evaluates and prioritizes assets and functions in terms of specific criteria , such as their importance to public safety and the economy , as a basis for identifying which structures or processes require higher or special protection from attack .

tsa has designed and implemented risk - based national and local covert testing programs to achieve its goals of identifying vulnerabilities in and measuring the performance of passenger checkpoint and checked baggage screening systems and airport perimeters and access controls , and has begun to determine the extent to which covert testing will be used to identify vulnerabilities and measure the effectiveness of security practices related to non - aviation modes of transportation .

oi used information on terrorist threats to design and implement its national covert tests and determine at which airports to conduct tests based on analyses of risks .

however , oi inspectors did not systematically record specific causes for test failures related to tsos , procedures , or screening equipment that did work properly .

oi also did not systematically collect and analyze information on effective screening practices that may contribute to tsos ability to detect threat items .

without systematically recording reasons for test failures , such as failures caused by screening equipment not working properly , as well as reasons for test passes , tsa is limited in its ability to mitigate identified vulnerabilities .

tsa recently redesigned its local covert testing program to address limitations in its previous program .

the new program , asap , should provide tsa with a measure of the performance of passenger and checked baggage screening systems and help to identify security vulnerabilities .

furthermore , tsa has begun to determine the extent to which covert testing will be used to identify vulnerabilities and measure the effectiveness of security practices in non - aviation modes of transportation .

while tsa coordinates with domestic and foreign organizations regarding transportation security efforts , they do not have a systematic process in place to coordinate with these organizations regarding covert testing in non - aviation settings , and opportunities for tsa to learn from these organizations' covert testing efforts exist .

oi uses threat assessments and intelligence information to design and implement national covert tests that meet its goals of identifying vulnerabilities in passenger checkpoint and checked baggage screening systems , and airport perimeters and access controls .

while oi currently focuses it covert tests on these three areas of aviation security , it has recently begun to establish procedures for the testing of air cargo facilities .

according to oi officials , as of march 2008 , oi has not yet conducted any tests of air cargo .

in designing its covert tests , oi works with dhs's transportation security laboratory to create threat items to be used during covert tests .

oi also uses threat information to replicate tactics that may be used by terrorists .

the tactics that oi uses are all designed to test the capabilities of passenger checkpoint and checked baggage screening systems to identify where vulnerabilities exist .

the process oi uses to select which airports to test has evolved since covert testing began in september 2002 to focus more on those airports determined to be at greater risk of a terrorist attack .

initially , oi's goals were to conduct covert tests at all commercial airports , with tests being conducted more frequently at those airports with the largest number of passenger boardings than smaller airports with fewer flights .

in august 2005 , when tsa began focusing on the most catastrophic threats , oi changed its testing strategy to utilize a risk - based approach to mitigate those threats .

oi inspectors record information on the results of national covert tests on data collection instruments after each test is conducted , including the extent to which tsos properly followed tsa screening procedures and whether the test was passed or failed .

after airport testing is complete , oi headquarters analysts input the covert test results into a centralized database .

while analysts input whether the test was a pass or a fail and inspectors observations regarding some tests , they do not systematically capture oi's assessment of the cause of the test failure and include that information in the database .

test failures could be caused by ( 1 ) tsos not properly following existing tsa screening procedures , ( 2 ) screening procedures that are not clear to tsos , ( 3 ) screening procedures that lack sufficient guidance to enable tsos to identify threat items , and ( 4 ) screening equipment that does not work properly .

moreover , when inspectors determine the cause of a covert test failure to be due to screening equipment , such as the walk through metal detector , the hand - held metal detector , or etd not alarming in response to a threat item , oi considers these tests to be invalid .

while oi officials stated that they report instances when equipment may not be working properly to the airport fsd and officials from the transportation security laboratory , they do not input that equipment caused the failure in the covert testing database .

tsa management may find this information useful in identifying vulnerabilities in the aviation system that relate to screening equipment not working properly .

oi officials stated that they do not record information on equipment failures because there is always a possibility that the simulated threat item was not designed properly and therefore should not have set off the alarm .

further , they stated that dhs's transportation security laboratory is responsible for ensuring that screening equipment is working properly .

however , the laboratory does not test screening equipment at airports in an operational environment .

furthermore , according to oi officials , identifying a single cause for a test failure may be difficult since covert testing failures can be caused by multiple factors .

however , in discussions with oi officials about selected individual test results , inspectors were able in their view , in most of these cases , to identify the cause they believed contributed most to the test failure .

according to the standards for internal control in the federal government , information should be recorded and communicated to management and others in a form and within a time frame that enables them to carry out their internal control and other responsibilities .

the standards further call for pertinent information to be identified , captured , and distributed in a form and time frame that permits people to perform their duties efficiently .

by not systematically inputting the specific causes for test failures in its database , including failures due to equipment , oi may be limiting its ability to identify trends that impact screening performance across the aviation security systems tested .

in addition to not identifying reasons the inspectors believed caused the test failures , oi officials do not systematically record information on screening practices that may contribute to covert test passes .

however , oi inspectors occasionally captured information of effective practices used by tsos to detect threat items during covert tests in the data collection instruments used during these tests .

further , during covert tests that we observed , oi inspectors routinely discussed with us those practices used during certain tests that they viewed as effective , such as effective communication between tsos and supervisors in identifying threat items .

in 2006 , oso officials requested a tsa internal review of differences in checkpoint screening operations at three airports to identify whether the airports employed certain practices that contributed to their ability to detect threat items during covert tests , among other things .

between june and october 2006 , oi's internal reviews division ( ird ) reviewed passenger checkpoint covert test results for each airport , observed airport operations , interviewed tsa personnel , and reviewed documents and information relevant to checkpoint operations .

ird's review identified a number of key factors that may contribute to an airport's ability to detect threat items .

while ird conducted this one time review of effective screening practices that may have led to higher test pass rates , oi does not systematically collect information on those practices that may lead to test passes .

as discussed earlier in this report , standards for internal control in the federal government stated the need for pertinent information to be identified and captured to permit managers to perform their duties efficiently .

without collecting information on effective screening practices that , based on the inspectors' views , may lead to test passes , tsa managers are limited in their ability to identify measures that could help to improve screening performance across the aviation security system .

in april 2007 , tsa initiated its local covert testing program , the aviation screening assessment program ( asap ) .

tsa is planning to use the results of asap as a statistical measure of the performance of passenger checkpoint and checked baggage screening systems , in addition as a tool to identify security vulnerabilities .

tsa asap guidance applies a standardized methodology for the types and frequency of covert tests to be conducted in order to provide a national statistical sample .

if implemented as planned , asap should provide tsa with a measure of the performance of passenger and checked baggage screening systems and help identify security vulnerabilities .

according to oso officials , the first cycle of asap tests were completed , but the results are still being internally analyzed by tsa to determine the overall findings from the tests .

as a result , it is too soon to determine whether asap will meet its goals of measuring the performance of passenger and checked baggage screening systems and identifying vulnerabilities .

similar to oi's national covert testing program , oso applies elements of risk in designing and implementing asap tests .

unlike national covert tests , the asap program does not use elements of a risk - based approach to determine the location and frequency of the tests because , according to tsa officials , in order to establish a national baseline against which tsa can measure performance , all airports must be tested consistently and with the same types of tests .

oso officials plan to analyze the results of the tests and evaluate the need to revise the tests or the type of threat items used after the first and second testing cycle and annually thereafter .

furthermore , oso officials stated that they plan to assess the data , including the types of vulnerabilities identified and the performance of the tsos in detecting threat items , and develop recommendations for mitigating vulnerabilities and improving screening performance .

officials stated that oso also plans to conduct follow - up testing to determine whether vulnerabilities that were previously identified have been addressed or if recommendations made were effective .

according to tsa's asap guidance , individuals conducting the asap tests will be required to identify specific causes for all test failures .

in addition to identifying test failures attributed to tsos , such as the tso not being attentive to their duties or not following tsa screening procedures , individuals conducting asap tests are also required to identify and record causes for failures related to tsos , screening procedures that tsos said were not clear or lack sufficient detail to enable them to detect threat items , and screening equipment .

oso officials further stated that they plan to develop performance measures for the asap tests after the results of the first 6 month cycle of tests are evaluated .

however , officials stated that performance measures for the more difficult category of tests will not be developed because these tests are designed to challenge the aviation security system and the pass rates are expected to be low .

furthermore , tsa officials stated that the results of asap tests will not be used to measure the performance of individual tsos , fsds , or airports , but rather to measure the performance of the passenger checkpoint and checked baggage screening system .

tsa officials stated that there will not be a sufficient number of asap tests to measure individual tso , fsd , or airport performance .

we previously reported that tsa had not established performance measures for its national covert testing program and that doing so would enable tsa to focus its improvement efforts on areas determined to be most critical , as 100 percent detection during tests may not be attainable .

while tsa has chosen not to establish performance measures for the national covert testing program , as stated above , they plan to develop such measures for only the less difficult asap tests .

since the initiation of tsa's covert testing program in 2002 , the agency has focused on testing commercial aviation passenger checkpoints , checked baggage , and airport perimeters and access controls .

however , tsa in is the early stages of determining the extent to which covert testing will be used to identify vulnerabilities and measure the effectiveness of security practices in non - aviation modes of transportation .

in addition , tsa officials stated that it would be difficult to conduct covert tests in non - aviation modes because these modes typically do not have established security screening procedures to test , such as those in place at airports .

specifically , passengers and their baggage are not generally physically screened through metal detectors and x - rays prior to boarding trains or ferries as they are prior to boarding a commercial aircraft , making it difficult to conduct tests .

oi officials also stated that they do not currently have the resources necessary to conduct covert tests in both aviation and non - aviation modes of transportation .

although oi does not regularly conduct covert tests in non - aviation modes of transportation , it has conducted tests during three tsa pilot programs designed to test the feasibility of implementing airport style screening in non - aviation modes of transportation to include mass transit , passenger rail , and maritime ferry facilities .

in 2004 , tsa conducted a transit and rail inspection pilot program in which passenger and baggage screening procedures were tested on select railways .

tsa also tested similar screening procedures at several bus stations during the bus explosives screening technology pilot in 2005 .

in addition , tsa has also been testing screening equipment on ferries in the maritime mode through the secure automated inspection lanes program .

according to oi officials , during these three pilot programs , oi conducted covert testing to determine if they could pass threat objects through the piloted passenger screening procedures and equipment .

however , these tests were only conducted on a trial basis during these pilot programs .

while oi has not developed plans or procedures for testing in non - aviation modes of transportation , the office has begun to explore the types of covert tests that it might conduct if it receives additional resources to test in these modes .

in addition to oi , tsa's office of transportation sector network management ( tsnm ) may have a role in any covert tests that are conducted in non - aviation modes of transportation .

tsnm is responsible for securing the nation's intermodal transportation system and has specific divisions responsible for each mode of transportation — mass transit , maritime , highway and motor carriers , freight rail , pipelines , commercial airports , and commercial airlines .

tsnm is also responsible for tsa's efforts to coordinate with operators in all modes of transportation .

a tsnm official stated that tsnm has only begun to consider using covert testing in mass transit .

in april 2007 , tsa coordinated with the los angeles county metropolitan transportation authority , amtrak , and los angeles sheriff's department during a covert test of the effectiveness of security measures at los angeles' union station .

during the test , several individuals carried threat items , such as simulated ieds , into the rail system to determine if k - 9 patrols , random bag checks , and other random procedures could detect these items .

the official from tsnm's mass transit office stated that the agency is incorporating the use of covert testing as a component of the mass transit and passenger rail national exercise program being developed pursuant to the implementing recommendations of the 9 / 11 commission act of 2007 .

however , tsnm has not developed a strategy or plan for how covert testing will be incorporated into these various programs .

the tsnm official further stated that he was not aware of other mass transit or passenger rail operators that are currently conducting or planning covert testing of their systems .

furthermore , tsnm does not have a systematic process in place to coordinate with domestic or foreign transportation organizations to learn from their covert testing experiences .

the use of covert or red team testing in non - aviation modes of transportation has been supported in law .

the implementing recommendations of the 9 / 11 commission act of 2007 directs dhs to develop and implement the national strategy for railroad transportation security , which is to include prioritized goals , actions , objectives , policies , mechanisms , and schedules for assessing , among other things , the usefulness of covert testing of railroad security systems .

furthermore , the explanatory statement accompanying the homeland security appropriations act , 2008 , directed tsa to be more proactive in red teaming for airports and air cargo facilities , as well as in transit , rail , and ferry systems .

specifically , the statement directed approximately $6 million of tsa's appropriated amount for red team activities to identify vulnerabilities in airports and air cargo facilities , as well as in transit , rail , and ferry systems .

regarding covert testing of non - aviation modes of transportation , the report of the house of representatives appropriations committee , which accompanies its fiscal year 2008 proposal for dhs appropriations , directed tsa to randomly conduct red team operations at rail , transit , bus , and ferry facilities that receive federal grant funds to ensure that vulnerabilities are identified and corrected .

dhs has also identified covert , or red team , testing as a priority for the department .

the president's july 2002 national strategy for homeland security identified that dhs , working with the intelligence community , should use red team or covert tactics to help identify security vulnerabilities in the nation's critical infrastructure , which includes the transportation sector .

the strategy further identifies that red team techniques will help decision makers view vulnerabilities from the terrorists' perspective and help to develop security measures to address these security gaps .

in addition , tsa's may 2007 ts - ssp identified that transit agencies should develop meaningful exercises , including covert testing , that test the effectiveness of their response capabilities and coordination with first responders .

however , the ts - ssp does not provide any details on the type of covert testing that transit agencies should conduct and does not identify that tsa itself should conduct covert testing in non - aviation modes of transportation .

domestic and foreign transportation organizations and dhs component agencies that we interviewed conduct covert testing to identify and mitigate vulnerabilities in non - aviation settings that lack the standardized passenger screening procedures found in the commercial aviation sector and measure the effectiveness of security measures .

our previous work on passenger rail security identified foreign rail systems that use such covert testing to keep employees alert about their security responsibilities .

one of these foreign organizations — the united kingdom department for transport's transport security and contingencies directorate ( transec ) — conducts covert testing of passenger rail and seaports in addition to aviation facilities to identify vulnerabilities related to people , security processes , and technologies .

according to a transec official , transec's non - aviation covert testing includes testing of the nation's passenger rail system and the united kingdom's side of the channel tunnel between the united kingdom and france .

transec conducts a number of covert tests to determine whether employees are following security procedures established by transec or the rail operator , whether processes in place assist employees in identifying threat items , and whether screening equipment works properly .

a transec official responsible for the agency's covert testing program stated that these tests are carried out on a regular basis and are beneficial because , as well as providing objective data on the effectiveness of people and processes , they encourage staff to be vigilant with respect to security .

in our september 2005 report on passenger rail security , we recommended that tsa evaluate the potential benefits and applicability — as risk analyses warrant and as opportunities permit — of implementing covert testing processes to evaluate the effectiveness of rail system security personnel .

like transec in the united kingdom , tsa has existing security directives that must be followed by passenger rail operators that could be tested .

tsa generally agreed with this recommendation .

in responding to the recommendation , tsa officials stated that the agency regularly interacts and communicates with its security counterparts in foreign countries to share best practices regarding passenger rail and transit security and will continue to do so in the future .

tsa officials further stated that the agency has representatives stationed overseas at u.s. embassies that are knowledgeable about security issues across all modes of transportation .

while tsa coordinates with domestic and foreign organizations regarding transportation security efforts , they do not have a systematic process in place to coordinate with these organizations regarding covert testing in non - aviation modes of transportation , and opportunities for tsa to learn from these organizations' covert testing efforts exist .

in the united states , amtrak has conducted covert tests to identify and mitigate vulnerabilities in their passenger rail system .

amtrak's office of inspector general has conducted covert tests of intercity passenger rail systems to identify vulnerabilities in the system related to security personnel and amtrak infrastructure .

the results from these tests were used to develop security priorities that are currently being implemented by amtrak .

according to an amtrak official , as the security posture of the organization matures , the covert testing program will shift from identifying vulnerabilities to assessing the performance of existing rail security measures .

transportation industry associations with whom we spoke , who represented various non - aviation modes of transportation , supported the use of covert testing as a means to identify security vulnerabilities and to test existing security measures .

officials from the american association of railroads ( aar ) , which represents u.s. passenger and freight railroads , and the american public transportation association ( apta ) , which represents the u.s. transit industry , stated that covert testing in the passenger rail and transit industries would help to identify and mitigate security vulnerabilities and increase employee awareness of established security procedures .

aar and apta officials stated that covert testing might include placing bags and unattended items throughout a rail station or system to see if employees or law enforcement personnel respond appropriately and in accordance with security procedures .

aar and apta officials further stated that any testing conducted by tsa would require close coordination with rail operators to determine what should be tested , the testing procedures to be used , and the practicality of such testing .

within dhs , the u.s. customs and border protection ( cbp ) also conducts covert testing at land , sea , and air ports of entry in the united states to test and evaluate cbp's capabilities to detect and prevent terrorists and illicit radioactive material from entering the united states .

according to cbp officials , the purpose of cbp's covert testing program is to identify potential technological vulnerabilities and procedural weaknesses related to the screening and detection of passengers and containers entering the united states with illicit radioactive material , and to assess cbp officers' ability to identify potential threats .

as of june 2008 , cbp tested and evaluated two land border crossings on their capabilities to detect and prevent terrorists and illicit radioactive material from entering the united states .

in addition , cbp covertly and overtly evaluated the nation's 22 busiest seaports for radiation detection and the effectiveness of the non - intrusive imaging radiation equipment deployed at the seaports .

cbp officials also stated that the agency is planning to expand testing to address overseas ports that process cargo bound for the united states .

in addition to cbp , the dhs domestic nuclear detection office ( dndo ) conducts red team testing to measure the performance of and identify vulnerabilities in equipment and procedures used to detect nuclear and radiological threats in the united states and around the world .

according to dndo officials , the agency uses the results of red team tests to help mitigate security vulnerabilities , such as identifying nuclear detection equipment that is not working correctly .

dndo also uses red team testing to determine if unclassified information exists in open sources , such as on the internet , which could potentially be used by terrorists to exploit vulnerabilities in nuclear detections systems .

dndo's program , according to its officials , provides a means to assess vulnerabilities that an adversary is likely to exploit , and to make recommendations to either implement or improve security procedures .

tsa's national aviation covert testing program has identified vulnerabilities in select aspects of the commercial aviation security system at airports of all sizes ; however , the agency is not fully using the results of these tests to mitigate identified vulnerabilities .

the specific results of these tests are classified and are presented in our classified may 2008 report .

covert test failures can be caused by various factors , including tsos not properly following tsa procedures when screening passengers , screening equipment that does not detect a threat item , or tsa screening procedures that do not provide sufficient detail to enable tsos to identify the threat item .

senior tsa officials , including tsa's administrator , are routinely briefed on the results of covert tests and provided with oi reports that describe the vulnerabilities identified by these tests and recommendations to correct identified vulnerabilities .

however , oso lacks a systematic process to ensure that oi's recommendations are considered , and does not systematically document its rationale for why it did or did not implement oi's recommendations .

oso and oi also do not have a process in place to assess whether the corrective action implemented mitigated the identified vulnerabilities through follow - up national or local covert tests , and if covert test results improved .

according to oso officials , tsa has other methods in place to identify whether corrective actions or other changes to the system are effective ; however , officials did not provide specific information regarding these methods .

moreover , in those cases where oso took no action to address oi's recommendation , they did not systematically document their rationale for why they took no action .

in the absence of a systematic process for considering oi's recommendations , documenting their decision - making process , and evaluating whether corrective actions mitigated identified vulnerabilities , tsa is limited in its ability to use covert testing results to improve the security of the commercial aviation system .

oso senior leadership stated that opportunities exist to improve the agency's processes in this area .

between september 2002 and june 2007 , oi conducted more than 20,000 covert tests of passenger checkpoints , checked baggage screening systems , and airport perimeters and access control points collectively at every commercial airport in the united states regulated by tsa .

the results of these tests identified vulnerabilities in select aspects of the commercial aviation security system at airports of all sizes .

while the specific results of these tests and the vulnerabilities they identified are classified , covert test failures can be caused by multiple factors , including tsos not properly following tsa procedures when screening passengers , screening equipment that does not detect a threat item , or tsa screening procedures that do not provide sufficient detail to enable tsos to identify the threat item .

tsa cannot generalize covert test results either to the airports where the tests were conducted or to airports nationwide because the tests were not conducted using the principles of probability sampling .

for example , tsa did not randomly select times at which tests were conducted , nor did they randomly select passenger screening checkpoints within the airports .

therefore , each airport's test results represent a snapshot of the effectiveness of passenger checkpoint screening , checked baggage screening , and airport access control systems , and should not be considered a measurement of any one airport's performance or any individual tso's performance in detecting threat objects .

although the results of the covert tests cannot be generalized to all airports , they can be used to identify vulnerabilities in the aviation security system .

tsa officials stated that they do not want airports to achieve a 100 percent pass rate during covert tests because they believe that high pass rates would indicate that covert tests were too easy and therefore were not an effective tool to identify vulnerabilities in the system .

after completing its covert tests , oi provides written reports and briefings on the test results to senior tsa management , including tsa's administrator , assistant administrator of oso , and area fsds .

in these reports and briefings , oi officials provide tsa management with the results of covert tests , describe the security vulnerabilities identified during the tests , and present recommendations to oso that oi believes will mitigate the identified vulnerabilities .

tsa's administrator and senior oso officials stated that they consider the aviation security system vulnerabilities that oi presents in its reports and briefings as well as the recommendations made .

however , oso officials we spoke with stated that they do not have a systematic process in place to ensure that all of oi's recommendations are considered or to document their rationale for implementing or not implementing these recommendations .

furthermore , tsa does not have a process in place to assess whether corrective actions taken in response to oi's recommendations have mitigated identified vulnerabilities .

specifically , in those cases where corrective actions were taken to address oi's recommendation , neither oso nor oi conducted follow - up national or local covert tests to determine if the actions taken were effective .

for example , in cases where oi determined that additional tso training was needed and oso implemented such training , oso or oi did not conduct follow - up national or local covert testing to determine if the additional training that was implemented to address the recommendation helped to mitigate the identified vulnerability .

according to oso officials , tsa has other methods in place to identify whether corrective actions or other changes are effective ; however , officials did not provide specific information regarding these methods .

standards for internal control in the federal government require that internal controls be designed to ensure that ongoing monitoring occurs during the course of normal operations .

specifically , internal controls direct managers to ( 1 ) promptly evaluate and resolve findings from audits and other reviews , including those showing deficiencies and recommendations reported by auditors and others who evaluate agencies' operations , ( 2 ) determine proper actions in response to findings and recommendations from audits and reviews , and ( 3 ) complete , within established time frames , all actions that correct or otherwise resolve the matters brought to management's attention .

the standards further identify that the resolution process begins when audit or other review results are reported to management , and is completed only after action has been taken that ( 1 ) corrects identified deficiencies , ( 2 ) produces improvements , or ( 3 ) demonstrates the findings and recommendations do not warrant management action .

in the absence of a systematic process for considering and resolving the findings and recommendations from oi's covert tests and ensuring that the effectiveness of actions taken to address these recommendations are evaluated , tsa management is limited in its ability to mitigate identified vulnerabilities to strengthen the aviation security system .

while neither oso nor oi have a systematic process for tracking the status of oi covert testing recommendations , at our request , oso officials provided information indicating what actions , if any , were taken to address oi's recommendations .

from march 2003 to june 2007 , oi made 43 recommendations to oso designed to mitigate vulnerabilities identified by national covert tests .

to date , oso has taken actions to implement 25 of these recommendations .

for the remaining 18 of oi's 43 recommendations , oso either took no action to address the recommendation , or it is unclear how the action they took addressed the recommendation .

oi did not make any recommendations to oso related to screening equipment .

the specific vulnerabilities identified by oi during covert tests and the specific recommendations made , as well as corrective actions taken by oso , are classified .

tsa has developed a risk - based covert testing strategy to identify vulnerabilities and measure the performance of select aspects of the aviation security system .

oi's national covert testing program is designed and implemented using elements of a risk - based approach , including using information on terrorist threats to design simulated threat items and tactics .

however , this program could be strengthened by ensuring that all of the information from the tests conducted is used to help identify and mitigate security vulnerabilities .

for example , without a process for recording and analyzing the specific causes of all national covert test failures , including tsos not properly following tsa's existing screening procedures , procedures that are unclear to tsos , or screening equipment that is not working properly , tsa is limited in its ability to identify specific areas for improvement , such as screening equipment that may be in need of repair or is not working correctly .

moreover , without collecting and analyzing information on effective practices used at airports that performed particularly well on national covert tests , tsa may be missing opportunities to improve tso performance across the commercial aviation security system .

tsa has only recently begun to determine the extent to which covert testing may be used to identify vulnerabilities and measure the effectiveness of security practices in non - aviation modes of transportation if it receives additional resources to test in these modes .

nevertheless , several transportation industry stakeholders can provide useful information on how they currently conduct covert tests in non - aviation settings , and systematically coordinating with these organizations could prove useful for tsa .

national aviation covert tests have identified vulnerabilities in the commercial aviation security system .

however , tsa could better use the covert testing program to mitigate these vulnerabilities by promptly evaluating and responding to oi's findings and recommendations .

we recognize that tsa must balance a number of competing interests when considering whether to make changes to tso training , screening procedures , and screening equipment within the commercial aviation security system , including cost and customer service , in addition to security concerns .

we further recognize that , in some cases , it may not be feasible or appropriate to implement all of oi's recommendations .

however , without a systematic process in place to consider oi's recommendations , evaluate whether corrective action is needed to mitigate identified vulnerabilities , and evaluate whether the corrective action effectively addressed the vulnerability , oso is limited in the extent to which it can use the results of covert tests to improve the security of the commercial aviation system .

to help ensure that the results of covert tests are more fully used to mitigate vulnerabilities identified in the transportation security system , we recommended in our may 2008 classified report that the assistant secretary of homeland security for tsa take the following five actions: require oi inspectors to document the specific causes of all national covert testing failures — including documenting failures related to tsos , screening procedures , and equipment — in the covert testing database to help tsa better identify areas for improvement , such as additional tso training or revisions to screening procedures .

develop a process for collecting , analyzing , and disseminating information on practices in place at those airports that perform well during national and local covert tests in order to assist tsa managers in improving the effectiveness of checkpoint screening operations .

as tsa explores the use of covert testing in non - aviation modes of transportation , develop a process to systematically coordinate with domestic and foreign transportation organizations that already conduct these tests to learn from their experiences .

develop a systematic process to ensure that oso considers all recommendations made by oi in a timely manner as a result of covert tests , and document its rationale for either taking or not taking action to address these recommendations .

require oso to develop a process for evaluating whether the action taken to implement oi's recommendations mitigated the vulnerability identified during covert tests , such as using follow - up national or local covert tests to determine if these actions were effective .

we provided a draft of this report to dhs for review and comment .

on april 24 , 2008 , we received written comments on the draft report , which are reproduced in full in appendix ii .

dhs and tsa concurred with the findings and recommendations , and stated that the report will be useful in strengthening tsa's covert testing programs .

in addition , tsa provided technical comments , which we incorporated as appropriate .

regarding our recommendation that oi document the specific causes of all national covert testing failures related to tsos , screening procedures , and equipment in the covert testing database , dhs stated that tsa's office of inspection ( oi ) plans to expand the covert testing database to all causes of test failures .

dhs further stated that the specific causes of all oi covert testing failures are documented in data collection instruments used during covert tests and within a comment field in the covert testing database when the cause can be determined .

however , tsa acknowledged that covert test failures caused by screening equipment not working properly are not recorded in the database in a systematic manner .

documenting test failures caused by equipment should help oi better analyze the specific causes of all national covert testing failures and assist tsa management in identifying corrective actions to mitigate identified vulnerabilities .

concerning our recommendation that oi develop a process for collecting , analyzing , and disseminating information on practices in place at those airports that perform well during national and local covert tests in order to assist tsa managers in improving the effectiveness of checkpoint screening operations , dhs stated that it recognizes the value in identifying factors that may lead to improved screening performance .

tsa officials stated that , while oi or asap test results can be used to establish a national baseline for screening performance at individual airports , the results are not statistically significant .

as a result , additional assessments would be required to provide a statistical measure for individual airports .

according to dhs , oi plans to develop a more formal process for collecting and analyzing test results to identify best practices that may lead to test passes .

officials stated that when specific screening practices indicate a positive effect on screening performance , tsa plans to share and institutionalize best practices in the form of management advisories to appropriate tsa managers .

developing a more formal process for collecting and analyzing test results to identify best practices that may lead to test passes should address the intent of this recommendation .

in response to our recommendation that tsa develop a process to systematically coordinate with domestic and foreign transportation organizations as the agency explores the use of covert testing in non - aviation modes of transportation to learn from their experiences , dhs stated that it is taking a number of actions .

specifically , according to dhs , tsnm has worked closely with transit agencies and internal tsa covert testing experts during red team testing exercises and is currently exploring programs in which covert testing may be used to evaluate the effectiveness of security measures .

for example , tsnm is considering incorporating covert testing as a part of its intermodal security training and exercise program .

while considering the use of covert testing in its programs should help tsa evaluate the effectiveness of security measures , it is also important that tsa establish a systematic process for coordinating with domestic and foreign organizations that already conduct testing in non - aviation modes of transportation to learn from their experiences .

dhs further stated that it plans to take action to address our recommendation that the agency develop a systematic process to ensure that oso considers all recommendations made by oi as a result of covert tests in a timely manner , and documents its rationale for either taking or not taking action to address these recommendations .

specifically , dhs stated that oso is coordinating with oi to develop a directive requiring that oi's covert testing recommendations be formally reviewed and approved by tsa management , and oso is establishing a database to track all oi recommendations and determine what action , if any , has been taken to address the recommendation .

taking these steps should address the intent of this recommendation and help tsa to more systematically record whether oi's covert testing recommendations have been addressed .

concerning our recommendation that oso develop a process to evaluate whether the action taken to implement oi's recommendations mitigated the vulnerability identified during covert tests , such as using follow - up national or local covert tests or information collected through other methods , to determine if these actions were effective , dhs stated that oso established a new program to study various aspects of tso and screening performance in 2007 that considers recommendations originating from oi national covert tests and asap tests .

according to dhs , after completing each study , recommendations resulting from this analysis will be provided to tsa leadership for consideration .

dhs further stated that the results of asap tests will also likely be a focus of these future studies .

while these actions should help to address the intent of this recommendation , it is also important that oso assess whether the actions taken to mitigate the vulnerabilities identified by oi's national covert tests are effective .

as agreed with your office , unless you publicly announce its contents earlier , we plan no further distribution of this report until 30 days after its issue date .

at that time , we will send copies of this report to the secretary of homeland security , assistant secretary of dhs for the transportation security administration , and the ranking member of the committee on homeland security , house of representatives , and other interested congressional committees as appropriate .

we will also make this report available at no charge on gao's web site at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-3404 or at berrickc@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

other key contributors to this report were john hansen , assistant director ; chris currie ; yanina golburt ; samantha goodman ; art james ; wendy johnson ; thomas lombardi ; and linda miller .

this report addresses the following questions: ( 1 ) what is the transportation security administration's ( tsa ) strategy for conducting covert testing of the transportation system , and to what extent has the agency designed and implemented its covert tests to achieve identified goals ? .

and ( 2 ) what have been the results of tsa's national aviation covert tests conducted from september 2002 to june 2007 , and to what extent does tsa use the results of these tests to mitigate security vulnerabilities in the commercial aviation system ? .

to identify tsa's strategy for conducting covert testing of the transportation system and the extent to which the agency has designed and implemented its covert tests to achieve identified goals , we reviewed applicable laws , regulations , policies , and procedures to determine the requirements for conducting covert testing in the transportation sector .

to assess tsa's strategy specifically in the aviation covert testing program , we interviewed tsa office of inspection ( oi ) officials responsible for conducting national covert tests and office of security operations ( oso ) officials responsible for local covert tests regarding the extent to which information on risks is included in the design and implementation of tests .

we also interviewed the transportation security officers ( tso ) , supervisors , screening managers , and federal security directors ( fsd ) who participated in covert tests at each airport where we observed tests to discuss their experience with the national and local covert testing programs .

we observed oi inspectors during covert tests at seven airports including airports with heavy passenger traffic and those with just a few flights per day , as well as airports with both federal and contract tsos .

during these observations , we accompanied oi inspectors during all phases of the covert test including planning and observations , testing , and post test reviews with tsos , supervisors , and screening managers .

while these seven airports represent reasonable variations in size and geographic locations , our observations of oi's covert tests and the perspectives provided by tsa officials at these airports cannot be generalized across all commercial airports .

however , our observations at the seven airports provided us an overall understanding of how oi conduct covert tests and useful insights provided by tsos , their supervisors , and fsds at these airports .

we analyzed tsa documents including established protocols for national and local covert testing , procedures for screening passengers and checked baggage , and oi covert testing reports issued from 2002 to 2007 to identify procedures for designing and implementing tsa's covert testing program .

furthermore , to determine the extent to which tsa met the goals of the program , we conducted a detailed analysis of the data collection instrument and methods that oi used to collect covert testing data for the seven airports where we observed covert tests .

we also assessed the adequacy of tsa's internal controls for collecting and maintaining the results of covert tests by evaluating tsa's processes for collecting covert testing data and inputting this data into its database .

in assessing the adequacy of internal controls , we used the criteria in gao's standards for internal control in the federal government , gao / aimd 00-21.3.1 , dated november 1999 .

these standards , issued pursuant to the requirements of the federal managers' financial integrity act of 1982 ( fmfia ) , provide the overall framework for establishing and maintaining internal control in the federal government .

also pursuant to fmfia , the office of management and budget issued circular a - 123 , revised december 21 , 2004 , to provide the specific requirements for assessing the reporting on internal controls .

to assess tsa's strategy for conducting covert tests in non - aviation modes of transportation , we interviewed officials from tsa's office of transportation sector network management ( tsnm ) regarding the extent to which tsa has conducted covert testing in non - aviation modes of transportation , the applicability and potential use of covert testing in other modes , and their future plans for conducting covert testing in other modes .

to understand how other organizations and federal agencies have used covert testing in the non - aviation arena , we interviewed officials from selected federal agencies and organizations that conduct covert testing including amtrak , the united kingdom department for transport security ( transec ) , u.s. customs and border protection ( cbp ) , dhs domestic nuclear detection office ( dndo ) , and select transportation industry associations .

we reviewed the president's national strategy for homeland security and tsa's transportation systems sector specific plan , including individual plans for each mode of transportation , to determine the role and use of covert testing across the transportation system .

we also reviewed the fiscal year 2008 dhs appropriations legislation , enacted as division e of the consolidated appropriations act , 2008 , and associated committee reports and statements to identify any funding allocated to tsa to conduct covert testing in non - aviation modes .

to determine the results of tsa's national covert tests and the extent to which tsa used the results of these tests to mitigate security vulnerabilities in the aviation system , we obtained and analyzed a database of the results of tsa's national covert tests conducted from september 2002 to june 2007 .

we analyzed the test data according to airport category , threat item , and type of test conducted between september 2002 and june 2007 .

we also examined trends in pass and failure rates when required screening steps were or were not followed and examined differences in covert test results between private and federal airports .

we assessed the reliability of tsa's covert testing data by reviewing existing information about the data and the systems used to produce them , and by interviewing agency officials responsible for maintaining the database .

we determined that the data were sufficiently reliable for our analysis and the purposes of this report .

tsa provided us with a copy of their covert testing database which contained a table with one record , or entry , per test for all of the tests conducted between 2002 and 2007 .

in order to accurately interpret the data , we reviewed information provided by oi officials regarding each of the fields recorded in the database and information about how they enter test results into the database .

we also conducted manual testing of the data , conducting searches for missing data and outliers .

to further assess the reliability of the data , we reviewed the source documents used to initially collect the data as well as oi's published reports .

we also interviewed oi officials regarding how the results of covert tests are used in developing their recommendations to tsa management .

we reviewed oi reports on the results of covert tests issued between march 2003 and june 2007 that were submitted to tsa's administrator and oso to identify oi's recommendations for mitigating the vulnerabilities identified during covert tests .

we obtained and analyzed a summary of the actions that oso had taken to address oi's recommendations for mitigating vulnerabilities made from march 2003 to june 2007 .

we also asked officials to discuss the extent to which oso has addressed and implemented recommendations made by oi based on covert test results , and we analyzed information provided by tsa regarding the status of each covert testing recommendation made by oi from 2003 to 2007 .

we conducted this performance audit from october 2006 to may 2008 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on out audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

