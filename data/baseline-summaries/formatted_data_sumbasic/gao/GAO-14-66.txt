federal agencies plan to spend over $82 billion on information technology ( it ) in fiscal year 2014 .

of this amount , at least $59 billion was reported by the agencies to be spent on operations and maintenance ( o&m ) .

o&m investments consist of existing legacy systems ( i.e. , steady state ) and systems that are in both development and o&m ( known as mixed life cycle ) .

given the size and magnitude of these investments , it is important that agencies effectively manage the operations and maintenance of existing investments to ensure they ( 1 ) continue to meet agency needs , ( 2 ) deliver value , and ( 3 ) do not unnecessarily duplicate or overlap with other investments .

the office of management and budget ( omb ) directs agencies to periodically examine the performance of these investments against , among other things , established cost , schedule , and performance goals .

specifically , omb calls for agencies to perform annual operational analyses ( oa ) , which are a key method for examining the performance of such investments in o&m .

the objectives of our current review were to: identify the federal it o&m investments with the largest budgets , including their responsible agencies and how each investment supports its agency's mission ; determine the extent to which these investments have undergone assess whether the responsible agency's major it investments are in development , mixed life cycle , or steady state and the extent to which funding for investments in o&m have been transferred and used to fund investments in development .

to do so , our work focused on the 10 federal it investments with the largest reported budgets in o&m and the eight responsible agencies — namely , the departments of defense ( dod ) , energy , homeland security ( dhs ) , health and human services ( hhs ) , the treasury , and veterans affairs ( va ) , and the national aeronautics and space administration and social security administration — that operate these investments .

in addition , we determined how these 10 investments supported their agencies' mission by analyzing omb and agency documentation and conducting interviews with agency officials responsible for these investments .

we also addressed whether the agencies conducted oas to manage these 10 investments in accordance with omb guidance .

more specifically , we assessed whether an analysis had been performed on each of the 10 investments during fiscal year 2012 ( because it was the last full year for completing oas ) and if so , we compared it to the omb guidance criteria to identify any gaps and their causes .

further , to assess whether each of the eight agency's major it investments are in development , mixed life cycle , or steady state , we analyzed omb budget documentation on the agencies' planned spending on each it investment by phase ( i.e. , development , mixed , or steady state ) .

moreover , to assess the extent to which these agencies' had used their o&m funds on development activities , we compared what the agencies had planned to spend on development and o&m ( in fiscal year 2012 ) with what was reported to have been spent in order to identify any variances that indicated o&m funds had been reprogrammed and used to fund development activities .

we also conducted interviews with agency officials and reviewed agency documentation to verify whether any such reprogramming of funds had occurred , their causes , and the extent to which such changes were subject to management oversight .

we conducted this performance audit from december 2012 to october 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

details on our objectives , scope , and methodology can be found in appendix i .

the president's fiscal year 2014 budget request included plans for the federal government to spend over $82 billion on it .

the stated goal of the president's it budget request is to support making federal agencies more efficient and effective for the american people ; it also states that the strategic use of it is critical to success in achieving this goal .

of the $82 billion budgeted for it , the budget provides that 26 key agencies plan to spend the bulk of it , approximately $76 billion .

further , of the $76 billion , over $59 billion is to be spent on o&m investments with the remainder ( $17 billion ) being budgeted for development of new capabilities .

as shown in figure 1 , the $59 billion represents a significant majority ( i.e. , 77 percent ) of total budgeted spending for these agencies ( $76 billion ) .

although o&m spending by these agencies is about 77 percent of total it spending , the amount spent by each agency varies from a high of 98 percent to a low of 46 percent ( as shown in the following table ) .

development spending , which is intended for the inclusion of new capabilities , accounts for approximately 23 percent of the total amount to be spent on it in fiscal year 2014 by these agencies .

however , the investments in development vary greatly , from 54 percent by the department of transportation to a low of 2 percent by the national aeronautics and space administration .

further , in addition to including amounts to be spent on it development and o&m , the budget also further specifies how the total $76 billion budgeted for it is to be spent on agency it investments by the following three categories: those solely under development ( $6 billion ) , those involving activities and systems that are in both development and o&m — known as mixed life cycle ( $40 billion ) , and those existing operational systems — commonly referred to by omb as steady state investments — that are solely in o&m ( $30 billion ) .

to assist agencies in managing their investments , congress enacted the clinger - cohen act of 1996 , which requires omb to establish processes to analyze , track , and evaluate the risks and results of major capital investments in information systems made by federal agencies and report to congress on the net program performance benefits achieved as a further , the act places responsibility for result of these investments.managing investments with the heads of agencies and establishes chief information officers to advise and assist agency heads in carrying out this responsibility .

in carrying out its responsibilities , omb uses several data collection mechanisms to oversee federal it spending during the annual budget formulation process .

specifically , omb requires federal departments and agencies to provide information to it related to their it investments ( called exhibit 53s ) and capital asset plans and business cases ( called exhibit 300s ) .

exhibit 53 .

the purpose of the exhibit 53 is to identify all it investments — both major and nonmajor within a federal organization .

information included on agency exhibit 53s is designed , in part , to help omb better understand what agencies are spending on it investments .

the information also supports cost analyses prescribed by the clinger - cohen act .

as part of the annual budget , omb publishes a report on it spending for the federal government representing a compilation of exhibit 53 data submitted by agencies .

according to omb guidance , a major it investment requires special management attention because of its importance to the mission or function to the government ; significant program or policy implications ; high executive visibility ; high development , operating , or maintenance costs ; unusual funding mechanism ; or definition as major by the agency's capital planning and investment control process .

exhibit 300 .

the purpose of the exhibit 300 is to provide a business case for each major it investment and to allow omb to monitor it investments once they are funded .

agencies are required to provide information on each major investment's cost , schedule , and performance .

in addition , in june 2009 , to further improve the transparency into and oversight of agencies' it investments , omb publicly deployed a website , known as the federal it dashboard ( dashboard ) , which replaced its management watch list and high - risk list .

as part of this effort , omb issued guidance directing federal agencies to report , via the dashboard , the performance of their it investments .

currently , the dashboard publicly displays information on the cost , schedule , and performance of major federal it investments at key federal agencies .

in addition , the dashboard allows users to download exhibit 53 data , which include information on both major and nonmajor investments .

according to omb , these data are intended to provide a near real - time perspective of the performance of these investments , as well as a historical perspective .

further , the public display of these data is intended to allow omb , other oversight bodies , and the general public to hold the government agencies accountable for results and progress .

since the dashboard has been implemented , we have reported and made recommendations to improve the data accuracy and reliability .

in 2010 , 2011 , and 2012 , we reported on the progress of the dashboard and made recommendations to further improve how it rates investments relative to current performance .

omb concurred with our recommendations and has actions planned and underway to address them .

further , omb has developed guidance that calls for agencies to develop an oa policy for examining the ongoing performance of existing legacy it investments to measure , among other things , that the investment is continuing to meet business and customer needs and is contributing to meeting the agency's strategic goals.provide for an annual oa of each investment that addresses the following: cost , schedule , customer satisfaction , strategic and business results , financial goals , and innovation .

to address these areas , the guidance specifies the following 17 key factors that are to be addressed: this guidance calls for the policy to assessment of current costs against life - cycle costs ; a structured schedule assessment ( i.e. , measuring the performance of the investment against its established schedule ) ; a structured assessment of performance goals ( i.e. , measuring the performance of the investment against established goals ) ; identification of whether the investment supports customer processes as designed and is delivering goods and services it was designed to deliver ; a measure of the effect the investment has on the performing a measure of how well the investment contributes to achieving the organization's business needs and strategic goals ; a comparison of current performance with a pre - established cost areas for innovation in the areas of customer satisfaction , strategic and business results , and financial performance ; indication if the agency revisited alternative methods for achieving the same mission needs and strategic goals ; consideration of issues , such as greater utilization of technology or consolidation of investments to better meet organizational goals ; an ongoing review of the status of the risks identified in the investment's planning and acquisition phases ; identification of whether there is a need to redesign , modify , or terminate the investment ; an analysis on the need for improved methodology ( i.e. , better ways for the investment to meet cost and performance goals ) ; lessons learned ; cost or schedule variances ; recommendations to redesign or modify an asset in advance of potential problems ; and overlap with other investments .

with regard to overseeing the agencies' development of policies and annual performance , omb officials responsible for governmentwide oa policy stated that they expect agencies to perform all the steps specified in the guidance and to be prepared to show documentation as evidence of compliance with the guidance .

in october 2012 we reported on five agencies' use of oas ( during fiscal year 2011 ) and how they varied significantly .

specifically , of the five agencies , we found that three — namely , dod , treasury , and va — did not perform analyses on their 23 major steady state investments with annual budgets totaling $2.1 billion .

the other two agencies — dhs and hhs — performed analyses but did not do so for all investments .

for example , dhs analyzed 16 of its 44 steady state investments , meaning 28 investments with annual budgets totaling $1 billion were not analyzed ; hhs analyzed 7 of its 8 steady state investments , thus omitting a single investment totaling $77 million from being assessed .

we also found that of those oas performed by these two agencies , none fully addressed all the key factors .

specifically , our analysis showed that only about half of the key factors were addressed in these assessments .

consequently , we recommended , among other things , that the agencies conduct annual oas and in doing , ensure they are performed for all investments and that all factors are fully assessed .

to ensure this is done and to provide transparency into the results of these analyses , we also recommended that omb revise its guidance to include directing agencies to post the results on the dashboard .

omb and the five agencies agreed with our recommendations and have efforts planned and underway to address them .

in particular , omb issued guidance ( dated august 2012 ) to the agencies directing them to report oa results along with their fiscal year 2014 budget submission documentation ( eg , exhibit 300 ) to omb .

according to omb officials , they are currently establishing a process on how agencies are to provide the information to omb which they plan to have in place over the next 6 months .

as part of this , omb is defining a process for what they plan to do with the information once they receive it .

the 10 federal it o&m investments with the largest budgets , identified during our review , support agencies in a variety of ways such as providing worldwide telecommunications infrastructure and information transport for dod operations ; enabling hhs to conduct research , award grants , and disseminate biomedical research and health information to the public and national institutes of health stakeholders ; and providing ssa the capability to maintain demographic , wage , and benefit information on all american citizens .

including ensuring the availability , changeability , stability , and security of ssa's it operations for the entire agency .

these investments are operated by eight agencies , such as the department of energy ( doe ) , the national aeronautics and space administration ( nasa ) , and social security administration ( ssa ) .

in total , the investments accounted for about $7.9 billion in o&m spending for fiscal year 2012 , which was approximately 14 percent of all such spending for federal it o&m .

the following table identifies the 10 investments and describes the agency responsible for each investment , the amount budgeted for o&m and development for fiscal year 2012 , investment type , and how each investment supports the organization's mission .

although required to do so , seven of the eight agencies did not conduct oas on their largest o&m investments .

specifically , of the 10 o&m it investments ( with the largest budgets ) we reviewed , only one agency — dhs — conducted an analysis on its investment .

in doing so , the department addressed most of the required omb factors .

however , the other seven agencies — dod , doe , hhs , treasury , va , nasa , and ssa — did not conduct oas on their o&m investments , which have combined annual o&m budgets of $7.4 billion .

the following table lists the 10 investments and whether an analysis was completed for fiscal year 2012 .

further , it provides the total o&m amount for the investment that had an oa and for the investments that did not have one — $529 million and $7.4 billion , respectively .

with regard to the oa dhs performed on its investment ( the customs and border protection infrastructure ) , the department addressed 14 of the 17 omb factors .

for example , in addressing the factor on assessing performance goals , dhs made efforts to consolidate software licenses and maintenance in order to eliminate redundancy and reduce costs associated with software licenses and maintenance .

although dhs addressed these factors , it excluded 3 factors .

specifically , the department did not ( 1 ) assess current costs against life - cycle costs , ( 2 ) perform a structured schedule assessment , and ( 3 ) compare current performance against cost baseline and estimates developed when the investment was being planned .

these factors are important because , among other things , they provide information to agency decision makers on whether an investment's actual annual o&m costs are as they were planned to be and whether there is a need to examine more cost effective approaches to meeting agency mission objectives .

table 5 shows our analysis of dhs's assessment of its customs and border protection infrastructure investment .

with regard to why dhs's analyses did not address all omb factors , officials from the dhs office of the chief information officer ( who are responsible for overseeing the performance of oas departmentwide ) attributed this to the department still being in the process of updating their management directive 102-01 and its related guidance , which will provide additional instructions for completing oas .

as part of this update , department officials told us they plan to provide additional guidance on conducting oas for programs once they have achieved full operational capability .

the department expects the guidance to be completed in calendar year 2014 .

further , according to dhs , once completed , this guidance will complement existing program review processes — referred to by dhs as program health assessments — that requires all major it investments , in support or mixed lifecycle phases , to complete an oa every 12 months .

the other seven agencies attributed not performing oas on these investments to several factors , including relying on other management and performance reviews — such as those used as part of developing their annual exhibit 300 submissions to omb — although omb has stated that these reviews are not to be a substitute for conducting annual analyses .

the specific reasons cited by each agency are as follows: dod: officials from dod's defense information systems agency stated that they did not conduct an oa for the defense information systems network due to the fact that the investment undergoes constant oversight through weekly meetings to review issues such as the project status and accomplishments .

further , they said that the program manager exercises cost , schedule , and performance oversight using earned value management techniques .

in addition , they stated that monthly reviews of actual versus planned spending are collected to flag any discrepancies from expected cost and schedule objectives .

while these reviews are important steps to monitoring performance management , omb states such ongoing efforts to manage investment performance are not a substitute for conducting an annual oa .

according to the omb guidance , oas are to be conducted for all existing it investments to ensure that , among other things , an investment is continuing to meet business and customer needs and is contributing to meeting the agency's strategic goals .

with regard to the next generation enterprise network , officials from the navy who manage and oversee this investment stated an oa was not performed due to it going through a transition from a mature fielded system to a new service delivery model , which will become operational in 2014 .

nonetheless , omb guidance calls for agencies to also conduct annual analyses on all existing it investments as part of ensuring that such investments continue to deliver value and support mission needs .

doe: officials from the office of the chief information officer stated that an oa was not conducted on its consolidated infrastructure , office automation , and telecommunications program investment because in the summer of 2012 they began to separate it into smaller , more manageable pieces — referred to by these agency officials as deconsolidation — to better provide insight into the departmentwide infrastructure .

in addition , to gain further insight into the infrastructure spending , the doe chief information officer led an in - depth analysis in collaboration with senior it executives , which included a commodity it techstat review in the fall of 2011 , and a commodity it portfoliostat review in the fall of 2012 .

while these latter reviews are helpful in monitoring performance , our analysis shows that they do not fully address all 17 omb factors .

specifically , the reviews do not address , among other things , factors in the areas of customer satisfaction , strategic and business results , and financial performance .

addressing these factors is important because it provides information to agency decision makers on whether the investment supports customer processes and is delivering the goods and services it was designed to deliver .

hhs: according to officials from the department's national institutes of health , the national institutes of health it infrastructure investment , which had an annual budget of $371 million for fiscal year 2012 , did not undergo an oa because this investment is an aggregation of all the components' infrastructure and not a particular system or set of systems suited for this kind of macro analysis .

in addition , they noted that national institutes of health does monitor the operational performance of its it infrastructure and conducts a more strategic analysis of services within its it infrastructure to evaluate the operational effectiveness at a strategic level .

while these types of performance monitoring efforts are important , omb guidance nonetheless calls for agencies to also conduct annual analyses on all existing it investments as part of ensuring that such investments continue to deliver value and support mission needs .

treasury: officials from the department's it capital planning and investment control branch ( within the office of treasury's chief information officer ) noted that its internal revenue service main frames and servers services and support investment , which had a budget of $482 million for fiscal year 2012 , was deconsolidated in fiscal year 2011 to allow for greater visibility into the infrastructure and that it is currently undergoing an oa but were not able to provide documentation at the time of our work .

va: officials from va's office of information and technology said an oa was not conducted on its medical it support or enterprise it support investments because performance is currently being reported monthly via the federal it dashboard and internally through monthly performance reviews .

the officials added that the department plans to develop a policy and begin conducting oas on investments .

however , va has not yet determined when these analyses will be completed .

nasa: officials from nasa's office of the chief information officer stated while they did not conduct a formal oa on the nasa it infrastructure investment , they did review the performance of the investment using monthly performance status reviews and bimonthly service delivery transition status updates .

the officials noted that these reviews address financial performance , schedule , transformation initiatives , risks , customer satisfaction , performance metrics , and business results .

according to officials , the investment underwent a service delivery transition status update and a performance status review in may 2012 .

while these nasa reviews are essential it management tools , they do not incorporate all 17 omb factors .

for example , the reviews do not address , among other things , innovation and whether the investment overlapped with other systems .

fully addressing the omb factors is essential to ensuring investments continue to deliver value and do not unnecessarily duplicate or overlap with other investments .

ssa: according to officials from ssa's office of the chief information officer , ssa's infrastructure data center investment did not undergo an analysis because it has significant development content and therefore an earned value analysis was conducted , which is called for by ssa guidance for mixed life - cycle investments .

officials stated they generally perform either an earned value analysis or oa , as applicable to the investment .

while earned value management analyses are important to evaluating investment performance , omb guidance nonetheless calls for agencies to also conduct annual oas on all existing it investments as part of ensuring that such investments continue to deliver value and support mission needs .

until the agencies address these shortcomings and ensure all their o&m investments are fully assessed , there is increased risk that these agencies will not know whether these multibillion dollar investments fully meet intended objectives , including whether there are more efficient ways to deliver their intended purpose , therefore increasing the potential for waste and duplication .

for the eight selected agencies , the majority of their 401 major it investments — totaling $29 billion — were in the mixed life - cycle phase in both spending and number of investments .

specifically , of the $29 billion , our analysis , as shown in figure 2 , found that mixed life - cycle investments accounted for approximately $18 billion , or 61 percent ; steady state investments accounted for approximately $8 billion , or 27 percent ; and development investments accounted for approximately $3 billion , or 12 percent .

with regard to the number of investments by phase , our analysis , as shown in figure 3 , found that of the total 401 investments 193 , or 48 percent , were in the mixed life - cycle phase , 139 , or 35 percent , were in the steady state phase , and 69 or 17 percent , were in the development phase .

on an individual agency basis , table 6 provides the total amount each agency reportedly spent on it .

it also shows of how each agency allocates this total by development , mixed life cycle , or steady state investments .

further for the mixed investments , it shows the amounts for o&m and development .

further , the following table provides for each of the eight agencies , their total number of investments and of that total , the number of investments in development , mixed life cycle , and steady state .

the implications of the above analyses — especially the results in table 6 that show mixed investments having significant amounts of funding for both development and o&m activities — are noteworthy , particularly as it relates to the oversight of such investments .

more specifically , overseeing these investments will involve a set of it management capabilities for those portions of the investment that are operational and a different set of it management capabilities for those portions that are still under development .

in the case of those portions that are operational , this will include agencies having the capability to perform thorough oas , the importance of which is discussed earlier in this report .

for those portions still under development , omb guidance and our best practices research and experience at federal agencies show such effective oversight will involve agencies having structures and processes — commonly referred to as it governance and program management disciplines — that include instituting an investment review board to define and establish the management structure and processes for selecting , controlling , and evaluating it investments ; ensuring that a well - defined and disciplined process is used to select new it proposals ; and overseeing the progress of it investments — using predefined criteria and checkpoints — in meeting cost , schedule , risk , and benefit expectations and to take corrective action when these expectations are not being met .

having these disciplines are important because they help agencies , among other things , ensure such investments are supporting strategic mission needs and meeting cost , schedule , and performance expectations .

however , our experience at federal agencies has shown that agencies have not yet fully established effective governance and program management capabilities essential to managing it investments .

for example , we reported in april 2011 that many agencies did not have the mechanisms in place for investment review boards to effectively control their investments .

more specifically , we reported that while these agencies largely had established it investment management boards , these boards did not have key policies and procedures in place for ensuring that projects are meeting cost , schedule , and performance expectations .

in addition , our experience at federal agencies , along with the results from this audit , has found that agencies do not consistently conduct oas .

specifically , as noted in the background , we reported in 2012 on five agencies' use of them and how they varied significantly .

of the five agencies , we found that three — namely , dod , treasury , and va — did not perform analyses on 23 major steady state investments with annual budgets totaling $2.1 billion .

the other two agencies — dhs and hhs — performed them but did not do so for all investments .

accordingly , we have made recommendations to these agencies to improve their use of oas and fully implement effective governance and program management capabilities .

they have in large part agreed to our recommendations and have efforts underway and planned to implement them .

gao - 13-87 .

reprogram it o&m funds to be used on development activities and we identified no evidence to the contrary ; two agencies — treasury and va — reported they did so in two instances .

with regard to treasury , the department — on its cade 2 investment which has a total o&m budget of $40 million — reallocated a total of $10,000 to fund development activities planned for the investment .

according to treasury documentation , the cost of the investment's operations and maintenance came in under budget by $10,000 so the department reallocated the funds to be used on new cade 2 development efforts .

treasury reported this reallocation was discussed and approved by the internal revenue service's investment review board ( the internal revenue service is responsible for overseeing cade 2 ) during its monthly executive steering meetings held during fiscal year 2012 .

with regard to va , it reprogrammed a total of $13.3 million from o&m to development on investments within an investment category which va referred to as a portfolio .

specifically , during fiscal year 2012 , the department reprogrammed $13.3 million from an o&m investment within its medical portfolio to investments under development within the portfolio requiring additional funding .

this reprogramming of funds was approved by the secretary of veterans affairs in june 2012 .

the 10 largest federal o&m it investments represent a significant part of the federal government's multibillion dollar commitment to operating and maintaining its it investments .

although omb has established that agencies are to use oas to evaluate the performance of such investments , their use by the agencies on these investments was very limited .

dhs was the only agency to perform such an assessment and in doing so largely addressed the required omb factors .

while treasury and va had planned to perform analyses , they had not done so .

further , dod , doe , hhs , nasa , and ssa had not intended to perform these analyses on their large o&m investments .

this limited use of oas is due in part to a number of factors , including agencies relying on other types of performance oversight reviews that can be helpful but are not intended to be a substitute for these assessments .

until these agencies address these shortcomings and ensure all their large o&m investments are fully assessed , there is increased risk that these agencies will not know whether these multibillion dollar investments fully meet intended objectives , including whether there are more efficient ways to deliver their intended purpose .

to ensure that the largest it o&m investments are being adequately analyzed , we recommend that the secretary of defense direct appropriate officials to perform oas on the two investments identified in this report , including ensuring the analyses include all omb factors ; secretary of energy direct appropriate officials to perform an oa on the investment identified in this report , including ensuring the analysis includes all omb factors ; secretary of health and human services direct appropriate officials to perform an oa on the investment identified in this report , including ensuring the analysis includes all omb factors ; secretary of treasury direct appropriate officials to perform an oa on the investment identified in this report , including ensuring the analysis include all omb factors ; secretary of veterans affairs direct appropriate officials to perform oas on the two investments identified in this report , including ensuring the analyses include all omb factors ; nasa administrator direct appropriate officials to perform an oa on the investment identified in this report , including ensuring the analysis includes all omb factors ; and commissioner of social security direct appropriate officials to perform an oa on the investment identified in this report , including ensuring the analysis includes all omb factors .

in addition , we recommend that the secretary of homeland security direct appropriate officials to ensure the department's oa for the customs and border protection infrastructure is complete and assesses missing omb factors identified in this report .

in commenting on a draft of this report , four agencies — dhs , nasa , ssa , and va — agreed with our recommendations ; two agencies — dod and doe — partially agreed ; and two agencies — hhs and treasury — had no comments .

the specific comments from the four agencies that agreed are as follows: dhs in its written comments , which are reprinted in appendix ii , stated that it concurred with our findings and recommendation .

it also commented that dhs's office of the chief information officer and the office of information technology within customs and border protection ( the dhs component agency responsible for the customs and border protection infrastructure investment ) are to work closely to ensure future oas conducted on the investment fully address the omb assessment factors .

nasa , in its written comments — which are reprinted in appendix iii — stated it concurred with our recommendation .

nasa also stated that it planned to conduct an oa on its nasa it infrastructure investment in april 2014 that is to include all omb factors .

in its written comments , ssa stated it agreed with our recommendation .

it also stated that since 2008 , ssa has had a process to perform oas on investments that were solely in o&m and that it recently expanded the process to include mixed life cycle it investments that have significant systems in o&m .

ssa further commented that it was in the process of performing oas on the ssa mixed life cycle investment identified in our report and other similar agency investments , with the goal of completing these analyses by september 30 , 2013 .

ssa's comments are reprinted in appendix iv .

va , in its written comments , stated it agreed with our conclusions and concurred with our recommendation .

it also said that it had scheduled oas for the two investments identified in our report to begin in the second half of fiscal year 2014 .

va's comments are reprinted in appendix v. the specific comments of the two agencies that partially agreed are as follows: dod , in its written comments , stated that it partially concurred with our recommendation .

specifically , dod said it agreed with our recommendation that its oas should address all omb assessment factors and said it is establishing an oa policy in coordination with omb .

the department further agreed with our recommendation that it perform an oa on its defense information system network investment .

the department disagreed with our recommendation to perform an oa on its next generation enterprise network investment stating the investment is no longer in o&m and such investments , per omb policy , do not require an oa .

more specifically , as noted earlier in this report , dod is transitioning the investment from a mature fielded system to a new service delivery model , which will become operational in 2014 , and has moved the entire investment back into planning and acquisition .

nonetheless , consistent with our recommendation and as required by omb policy , dod plans to conduct an oa on this investment once the department begins to make it operational in 2014 .

dod's comments are reprinted in appendix vi .

in its written comments — which are reprinted in appendix vii — doe commented that it partially concurred with our recommendation .

doe stated it was not required to perform an oa on the consolidated infrastructure , office automation , and telecommunications program because the investment no longer exists .

specifically , doe said it decided in 2012 to separate this large investment into smaller , more manageable pieces — referred to by doe as deconsolidation — to better provide insight into its departmentwide infrastructure , and that since the investment no longer exists , there is no reason to perform an oa on it .

nonetheless , consistent with our recommendation , doe added that it will ensure that oas are conducted on the o&m components of all current major it investments in doe's it portfolio .

doe stated that it had already performed oas on applicable operational components that used to comprise the consolidated infrastructure , office automation , and telecommunications program .

for example , doe commented that one of the investments created during deconsolidation — called consolidated infrastructure — had already undergone an oa most recently in august 2013 .

while doe reported this progress in its comments to us , it did not provide us with documentation to support that this oa had been performed and whether it addressed all the omb assessment factors .

consequently , we are revising our recommendation to doe that it ensure oas are performed on the applicable operational components that used to comprise the consolidated infrastructure , office automation , and telecommunications program , including the newly created consolidated infrastructure investment .

with regard to hhs and treasury , hhs , in comments provided via e - mail from its gao intake coordinator within the office of the assistant secretary for legislation , stated that it did not have any general comments on this report , and treasury in its written response said it had no comments on our report ; the department's comments are reprinted in appendix viii .

dhs and hhs also provided technical comments , which we incorporated as appropriate .

we are sending copies of this report to interested congressional committees ; the secretaries of the departments of defense , energy , health and human services , homeland security , treasury , and veterans affairs ; the administrator of the national aeronautics and space administration ; and the commissioner of the social security administration .

this report will also be available at no charge on our website at http: / / www.gao.gov .

if you or your staffs have any questions on matters discussed in this report , please contact me at ( 202 ) 512-9286 or pownerd@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix ix .

our objectives were to ( 1 ) identify the federal it o&m investments with the largest budgets , including their responsible agencies and how each investment supports its agency's mission ; ( 2 ) determine the extent to which these investments have undergone oas ; and ( 3 ) assess whether the responsible agency's major it investments are in development , mixed life cycle , or steady state , and the extent to which funding for investments in o&m have been used to finance investments in development .

to identify those federal it o&m investments with the largest budgets , we used data reported to the office of management and budget ( omb ) as part of the budget process , and focused on the 10 largest reported budgets in o&m and the responsible eight agencies ( the departments of defense , energy , homeland security , health and human services , the treasury , and veteran affairs ; and the national aeronautics and space administration and social security administration ) that operate these investments .

in addition , to determine how these 10 investments support their agencies' missions , we reviewed omb and agency documentation ( eg , exhibit 300s , exhibit 53s ) and interviewed agency officials .

to determine the extent to which oas were conducted to manage these investments in accordance with omb guidance , we analyzed agency documentation and interviewed responsible agency officials to determine whether any operational analyses had been performed on these 10 investments during fiscal year 2012 because it was the last full year for completing oas .

in those cases where an oa had been performed , we compared it against omb guidance on conducting them , including the 17 factors that are to be addressed as part of such assessments , to identify any variances .

where there were variances , we reviewed agency documentation and interviewed agency officials responsible for the oa to identify the cause of their occurrence .

in those instances where an analysis was not performed , we reviewed documentation and interviewed agency officials to identify why it was not done .

to assess whether each of the eight agency's major it investments are in development , mixed life cycle , or steady state , we analyzed agencies' reported spending data provided to omb as part of the budget process to determine what phase the majority of the investments were in and where the majority of funds were invested ( i.e. , development , mixed , or steady state ) .

to assess the reliability of the data we analyzed , we corroborated them by interviewing investment and other agency officials to determine whether the omb information we used was consistent with that reported by the agencies ; based on this assessment , we determined the data were reliable for the purposes of this report .

further , to assess the extent to which these and other agency it o&m investments involve development activities , we analyzed agency data and evaluated whether the eight agencies were using their o&m funds for development activities ( i.e. , through the reprogramming or reallocation of funds ) .

specifically , we compared what agencies planned to spend on development and o&m with what was reported to have been spent to identify any variances that indicated o&m funds were reprogrammed and used for development activities .

in addition , we reviewed agencies' documentation to determine if agencies had any processes in place to manage investments transitioning from development to o&m .

lastly , we reviewed agency documentation and interviewed agency it budget and investment officials to verify whether any reprogramming occurred , its causes , and the extent of which any reprogramming was subject to management oversight .

we conducted this performance audit from december 2012 to october 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact name above , individuals making contributions to this report included gary mountjoy ( assistant director ) , gerard aflague , camille chaires , rebecca eyler , and lori martinez .

