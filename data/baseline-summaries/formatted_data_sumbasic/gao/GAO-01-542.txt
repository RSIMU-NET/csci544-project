in 1999 , at least $9 billion in federal funds supported early education and care services for children younger than 5 .

these funds provided a variety of services and support to children and their families to meet a range of goals , from increasing low - income families' access to affordable child care to ensuring that children's educational , health , and social needs are met .

given the large federal investment and the current attention on the importance of early childhood experiences , policymakers are interested in the effectiveness of federally funded early childhood education and care efforts and the types of research designs available for determining whether these programs are meeting their objectives for children .

because of your particular interest in the use of impact evaluations as a way of determining program effectiveness , our objectives were to ( 1 ) describe the value of conducting impact evaluations , ( 2 ) describe their current use in evaluating selected early childhood education and care programs , and ( 3 ) discuss the value of other types of early childhood education and care studies the departments of health and human services ( hhs ) and education currently promote and sponsor .

to understand the use of impact evaluations , we reviewed current government - sponsored studies ( both agency - initiated and congressionally mandated ) of 11 programs that fund early childhood education and care and report serving 25,000 or more children younger than age 5 .

thus , we examined current evaluations and evaluation proposals for two programs focused on early childhood education — head start and even start — and for the following nine programs: child care and development fund ( ccdf ) , temporary assistance for needy families ( tanf ) , twenty - first century community learning centers , three special education programs ( state , preschool , and infant and toddler grants ) , social services block grant ( ssbg ) , migrant education , and title i .

these nine programs provide early childhood education and care though , for most , it is not a primary activity .

we conducted our work between october 2000 and march 2001 in accordance with generally accepted government auditing standards .

the use of impact evaluations to assess the effect of a program or other intervention is an accepted practice in areas as diverse as medicine , economics , and social services .

some frequently cited examples of impact evaluations involve experiments designed to test the efficacy of drugs by randomly assigning participants to a group that will either receive or not receive the experimental drug .

impact evaluations are also used in other areas to assess program effectiveness .

one such study is currently under way for the job corps .

in addition , several state - level impact evaluations are being used to study welfare - to - work programs .

the congress has mandated studies to ensure that agencies conduct the kinds of evaluations it deems necessary .

in both authorizing and reauthorizing legislation , the congress has required evaluations of a program or demonstration program .

impact evaluations have been used to evaluate and develop programs in the early childhood education and care arena .

for example , hhs sponsored an impact evaluation of a demonstration project called the comprehensive child development program to test the effectiveness of the program for low - income families and their young children .

hhs incorporated many of the lessons learned from this study in the early head start program .

the 11 federal programs that serve 25,000 or more young children in some capacity are administered by either education or hhs ( table 1 ) .

the programs differ in a number of ways , including their goals and the portion of funds they devote to young children .

for example , head start's goal is school readiness and most of its budget is spent on children younger than age 5 .

all head start grantees provide services that are designed to enhance school readiness .

in contrast , ssbg , which devotes only 11 percent of its funds for early childhood education and care , is a flexible source of funds that allows states wide discretion to fund a variety of social services , one of which can be child care .

its goal is primarily to help families achieve self - sufficiency .

the other programs we reviewed fund early childhood education and care in various ways but often have primary goals that are only indirectly related to children or school readiness .

the passage of the government performance and results act ( gpra ) of 1993 influenced how agencies assess the effectiveness of their programs .

gpra shifted the focus of accountability for federal programs from inputs , such as staffing and activity levels , to outcomes .

gpra requires that each federal agency develop a multiyear strategic plan identifying the agency's mission and long - term goals .

to develop the plans , each agency must connect its long - term strategic goals with daily activities .

while gpra requires agencies to measure the outcomes of their programs , it does not require agencies to conduct formal program evaluations such as impact evaluations .

however , gpra requires agencies to summarize the findings of program evaluations in their annual performance reports .

many researchers consider impact evaluations to be the best method for determining a program's effect on its participants because they isolate a program's contribution from the effects of other factors that could have influenced participant outcomes .

impact evaluations can be designed in several ways , but most fall into two categories: experimental and quasiexperimental designs .

impact evaluations are used to isolate the influences of a program being studied from other influences in an individual's life .

in the case of a child , many influences affect his or her development ( fig .

1 ) .

as a child grows , he or she acquires new knowledge and new skills .

nutrition , health , family , and community as well as education and care play roles in his or her learning .

in light of all these influences , it becomes difficult to distinguish between the effects of the program and the other factors that influence a child's learning .

to isolate the program's influences on a child , an impact evaluation studies two groups of children: those receiving program services and a similar group not receiving program services .

researchers compare the relevant outcomes , such as reading ability , of these two groups of children to determine the program's effect .

most impact evaluations are one of two types — experimental or quasiexperimental — although they can be designed in several ways .

the two designs differ primarily in the way that the comparison groups are developed .

in an experimental design , the comparison group is referred to as the “control” group .

it is composed of individuals randomly selected from possible program participants .

in a quasiexperimental impact evaluation , the comparison group is composed of individuals who share characteristics with program participants , but who may or may not have ever sought program services .

the more rigorous of the two types of impact evaluations is the experimental design ( fig .

2 ) .

it randomly assigns individuals to either a group that will receive program services or a group that will not receive program services .

as applicants apply for program services , each has an equal chance of being placed in a group that will receive program services or a group that will not receive program services .

although individual applicants are different , random assignment distributes those differences equally between the two groups , resulting in two groups that are presumed to have no systematic differences in their characteristics .

although individuals in the control group do not receive services from the program under study , they may receive similar services through other programs .

at various points during an experimental impact study , researchers measure the relevant outcomes of the members of both groups .

the group that is not receiving services demonstrates what would have happened without the program .

thus , when the progress of the two groups is compared , any differences between them can be attributed to the influences of the program .

this way , the use of a control group serves to rule out alternative explanations for differences in the outcomes of program participants and nonparticipants .

however , because control group members may receive services similar to those provided through the program under study , the differences in outcomes between the two groups may be less than they would have been had the control group not received those similar services .

the denial of the program services under study to eligible individuals in control groups — a necessary aspect of experimental impact evaluations — raises a number of issues .

for example , experimental designs cannot be used when a program must serve all eligible individuals .

the denial of services can also raise ethical issues , the result of which can be reluctance on the part of program staff and officials to participate in impact studies .

these issues , along with other challenges characteristic of complex evaluations , can make experimental impact evaluations especially difficult , time - consuming , and expensive to perform .

ethical issues arise in the selection of an experimental impact evaluation control group .

as we stated earlier , a control group consists of participants who are denied services .

several factors may complicate the creation of the control group , and in fact denying services for the purpose of creating a control group may not be possible .

for example , a program may be required to serve all eligible individuals , as is the case with special education programs .

even when forming a control group does not raise these kinds of issues , program staff and officials may be ethically opposed to denying services to individuals , especially for evaluations requiring several years to complete .

to overcome such opposition , an additional investment of time may be necessary to gain the trust of program staff .

the organization conducting the evaluation may need to provide training to staff so that they understand the need for random assignment and can collect data if necessary .

in addition to the possible opposition of staff members , people seeking program services can be reluctant to agree to forego program participation .

researchers must gain the acceptance and informed consent of both participants and control group members ( or , in the case of evaluations involving minors , their guardians ) .

in some instances , control group members or their families may require monetary or other incentives to participate .

over the course of the evaluation , incentives may need to be sustained or increased .

the ethical issues associated with experimental designs , along with other challenges characteristic of complex evaluations , can make them difficult to complete and add to the time and expense they require .

experimental impact evaluations are often complex , multiyear studies awarded through competitive bids to experienced research firms .

considerable attention must be given to both study planning and execution .

for example , researchers often prepare detailed plans describing the study , its methodologies , and issues that can affect the study .

in many cases , aspects of the study must be pilot tested before the larger study can be undertaken .

then , once evaluations are under way , individuals may need to be tracked over several years .

for example , an evaluation that begins well before a child starts school — for example , at age 3 years — may require 3 years or more of data collection to track the child through the beginning of his or her school years .

in addition , special efforts must be made to limit the number of study participants who leave the study , especially from within the control group .

the other , less rigorous type of impact evaluation is quasiexperimental design .

when randomly assigning individuals to a control group is not a feasible option , quasiexperimental impact evaluations can be used to compare the performance of program participants on various measures to individuals not in the program .

in a quasiexperimental design , methods other than random assignment are used to create a comparison group .

a comparison group can be developed in a variety of ways .

one way is to use a set of individuals who have similar characteristics to the group receiving the program services under study .

for example , the group might live in the same neighborhood as the group receiving services and have family and income characteristics similar to those receiving serivces .

the extent to which quasiexperimental comparison groups are actually similar to program participants is not entirely known .

for this reason , quasiexperimental evaluations cannot rule out all of the factors that influence participants' outcomes .

other factors could explain differences between the two groups , making it difficult to conclude , with certainty , the effect of the program being examined .

when well planned and executed , however , such designs can provide some indication of program impact .

the two programs most focused on early childhood education — head start and even start — are currently being studied using impact evaluations with an experimental design .

hhs is conducting impact studies of head start and early head start , and education is using an impact evaluation to study even start .

both of these programs are intended to improve children's school readiness and educational and developmental outcomes , for example by encouraging enhanced literacy .

impact evaluations are not currently being used to evaluate the early education and care services provided by the other nine programs we reviewed whose goals are not as directly focused on early childhood education as even start and head start .

for many of these programs , providing early childhood education and care is one of many allowable services , not the primary program focus .

the head start evaluation is a $28.3-million , nationally representative , longitudinal impact evaluation .

the contract for the evaluation was awarded in fall 2000 to westat inc. , a research firm , in collaboration with the urban institute , the american institute for research , and decision information resources .

the evaluation is still in its early stages and data collection has not yet commenced .

before data collection begins in fall 2002 , a pilot study will be conducted to test various procedures and measures and to investigate the variations that exist across different communities with respect to head start programs and the availability of other care options for low - income children .

the pilot study will be conducted in spring 2001 .

in fall 2002 , researchers will begin to collect data on about 5,000 to 6,000 3- and 4-year - olds from 75 programs and communities across the country ; data collection will continue through the spring of the children's first grade of elementary school .

it is estimated that this evaluation will take more than 6 years to complete .

the congress mandated this evaluation and specified that it be an impact evaluation by stating that children should be randomly assigned to either a group that will receive head start services or one that will not receive head start services .

the study has two primary goals .

the first is to determine the national impact of head start on children's school readiness by comparing children in head start to children not in head start .

data in areas related to school readiness , such as cognition , physical well - being , social and emotional development , and language usage , will be collected from both groups of children .

in addition , information on parenting practices , family structure , demographics , and socioeconomics will be collected .

the second goal is to determine under which conditions and for which children head start works best .

in crafting the study proposal , westat noted the difficulties inherent in denying services to eligible children in order to create the control group and suggested ways to soften the ethical objections to random assignment .

for example , the proposal allows head start staff to provide information to control group families on alternative services in the community , and exempts a small number of children with significant disabilities from the random assignment .

the plan also acknowledges the need to make parents comfortable with the process and , in some instances , provides financial incentives for participation .

at the same time , westat noted the need to maintain the integrity of the random assignment over a number of years .

to this end , the plan calls for providing information to head start staff about the need for random assignment .

in addition , head start grantees will need to agree to exclude children assigned to the control group from enrolling at other head start centers within their jurisdictional control during the study .

the final report is due in december 2006 .

the issue of head start's effectiveness was highlighted in 1997 when we reported that the body of research on the head start program was insufficient to draw conclusions about its national impact .

the report recommended that a study or studies be undertaken to determine the impact of the program nationally .

the following year , we reiterated these points in another report and added that the federal government's significant financial investment in head start , including plans to increase the number of children served , warranted definitive evaluation studies , even though they may be costly .

based on these recommendations and the testimony of research methodologists and early childhood experts , the congress mandated that hhs fund and conduct an evaluation to determine , on a national level , the impact of head start on the children it serves .

the congress also called for an expert panel to develop recommendations regarding the study design to determine if , overall , head start programs' impacts are consistent with the primary goal of school readiness .

the panel included 30 experts in the areas of program evaluation and research , education , early childhood care and care policy , and economics .

the panel outlined a framework for the impact study and deliberated extensively on the feasibility , ethics , and credibility of random assignment .

it concluded that random assignment represented the best approach for answering the question of head start's impact .

the early head start program is part of head start and serves pregnant women , infants , and toddlers .

the early head start study , which was also congressionally mandated , began in 1995 shortly after the program was established .

it will cost about $21 million and take 6 years to complete .

this longitudinal study of about 3,000 families and their children will assess children 14 , 24 , and 36 months after birth .

the early head start study includes an impact component as well as an implementation study that we discuss later in this report .

mathematica policy research , inc. ( a research organization ) , and researchers at columbia university are conducting the study in collaboration with 15 local research teams .

the impact portion of the study will examine early head start programs at 17 local sites that include a mix of urban and rural sites as well as sites serving individuals with different racial and ethnic backgrounds .

these 17 sites were selected to reflect the characteristics of all programs funded in the early years of the program .

as the early head start grantees recruited families , the families were randomly assigned to either a group that will receive early head start program services or a control group that will not receive program services .

 ( control group families could receive other services in the community. ) .

the final report , which will follow children up to their third birthday , is due in 2002 .

hhs has initiated another study which will follow these children through the spring before their entry into kindergarten to evaluate the program's impact on school readiness , among other things .

this follow - up evaluation was not congressionally mandated .

the estimated $3.6 million even start study will also examine several local projects using an experimental design .

the study is supported through program funds that the congress made available for evaluation .

the mandate for the even start study was included in the program's original legislation and , although that legislation has been amended several times , the requirement for an independent evaluation to determine the performance and effectiveness of even start has remained unchanged .

funded in 1997 , the study provides for an experimental design to test the effectiveness of 18 projects serving 400 even start families and 200 control group families .

the contract , awarded to abt associates , inc. ( a research organization ) , will , among other things , measure children's school readiness .

the study will take 6 years to complete and the final report is expected in summer 2003 .

the current study is actually the second even start impact study conducted using an experimental design .

the first evaluation included an impact evaluation that examined even start programs operated by five grantees .

the small number of sites examined by the study and the lack of information on control group experiences did not permit conclusions about program effectiveness .

impact evaluations are not currently being used to evaluate the early education and care services provided by the other nine programs we reviewed .

their goals are not as focused on early childhood education as those of even start and head start .

for many of these programs , providing early childhood education and care is one of many allowable services , rather than the primary program focus ( fig .

3 ) .

researchers have used a variety of study designs , other than impact evaluations , to understand more about these types of programs with respect to early childhood education and care services .

hhs and education promote and sponsor many types of studies , other than impact evaluations , that can provide a wide variety of data valuable to program managers and policymakers .

different study designs are used depending on the questions to be answered , the nature of the program being studied , and the type of information needed .

often , to answer varied , complex , and interrelated questions , policymakers may need to use several different designs to assess a single program .

policymakers' desire to know a program's effect does not preclude their need to know about its implementation and other details that can be revealed through different types of studies .

an implementation evaluation , also called a process evaluation , can assess the extent to which a program is being administered as the congress anticipated .

an implementation evaluation typically assesses whether program activities conform to statutory and regulatory requirements , program design , and professional standards or customer expectations .

generally , an implementation evaluation necessitates collecting information for comparison to legislative objectives .

for example , if legislation requires a program to serve a particular population with certain characteristics , researchers conducting an implementation evaluation would examine the demographics of participants to determine if the program is indeed serving this population .

implementation evaluations provide information on many aspects of a program .

for example , the first even start study was largely an implementation study , and its findings were used to improve program design and shape future research .

the study was broad in scope , but examined the characteristics of even start participants , projects , and services to assess how closely they resembled what had been envisioned for the program .

the study served as a catalyst for changes in the program's legislation , including a shift in focus on those most in need .

in addition , as a result of the study's findings , teen parents are now eligible for program services .

the early head start study under way also includes an implementation component .

the implementation study gathered information on participants and services to determine if the program was implemented as intended .

information from the implementation study will be integrated with the results of the impact analysis .

an outcome evaluation assesses how closely a program's achievements are aligned with program goals .

this type of evaluation answers the question , “are participants achieving intended outcomes ? ” outcome evaluations can determine how well children are doing at a particular time .

however , without the use of an experimental design , researchers cannot attribute this performance to any one influence .

unlike an impact evaluation , outcome evaluations are unable to isolate the influences of the program under study .

hhs and education use outcome evaluations to find out how well children in agency - sponsored programs perform basic skills .

for example , education is sponsoring two national studies with outcome components for its special education programs .

one study is an early intervention study .

this study will follow a nationally representative sample of children from birth to age 3 , monitoring them during and after the program , to describe their progress in such areas as eating and dressing .

the other study follows 3- to 5-year - olds through early elementary school and will also address questions about children's outcomes .

hhs funded the family and child experiences survey ( faces ) in 1996 to collect outcome data from a nationally representative sample of head start programs , children , and families .

faces collects a range of data that includes cognitive , social , emotional , and physical development of head start children ; the well - being and accomplishments of head start families ; and the quality of head start classrooms .

research studies are used to collect information to improve an agency's understanding about a particular area , such as early childhood education , or the issues surrounding a particular area .

often , research studies are used to test ideas that have arisen in an area but are not yet proven .

for example , hhs believes that increasing the knowledge of how child care systems work is a critical step toward improving the availability and quality of child care services .

to explore whether this is the case , hhs is using research studies to understand the complex nature of child care markets at the state , local , and national levels .

thus , some of the questions framing hhs' child care research agenda include: what does child care look like today ? .

how do child care variations influence child development and well - being ? .

how do child care variations affect family economic self - sufficiency and well - being ? .

we provided a draft of this report to the departments of education and health and human services for comment , and they did not provide comments .

however , education's office of elementary and secondary education and office of special education and rehabilitative services and hhs' administration for children and families provided technical comments , which we incorporated where appropriate .

we are sending copies of this report to the honorable richard durbin , ranking member of the subcommittee on oversight of government management , restructuring and the district of columbia , committee on governmental affairs ; the honorable roderick r. paige , secretary of education ; the honorable tommy g. thompson , secretary of health and human services ; relevant congressional committees , and other interested parties .

we will also make copies available to others on request .

please contact me on ( 202 ) 512-7215 if you or your staff have any questions about this report .

other gao contacts and staff acknowledgments are listed in appendix i .

in addition to those named above , john smale and corinna nicolaou made key contributions to this report .

