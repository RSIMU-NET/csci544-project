regulation is a basic tool of government .

each year , federal agencies issue thousands of regulations to ensure public health and safety , protect the environment , and facilitate the effective functioning of financial markets , among other goals .

the total costs of these regulations are estimated to be in the hundreds of billions of dollars , and the estimated benefits are even higher .

congress and presidents have imposed many procedural and analytical requirements on the regulatory process , in part , because of the substantial costs and benefits of regulations .

the requirements focus predominately on agencies' development of new rules , but some , such as section 610 reviews required by the regulatory flexibility act ( rfa ) , call for the evaluation of existing regulations .

such evaluations can be done through a variety of activities that may be considered retrospective regulatory reviews .

for purposes of this report , we generally use the term retrospective review to mean any assessment of an existing regulation , primarily for purposes of determining whether ( 1 ) the expected outcomes of the regulation have been achieved ; ( 2 ) the agency should retain , amend , or rescind the regulation ; and / or ( 3 ) the actual benefits and costs of the implemented regulation correspond with estimates prepared at the time the regulation was issued .

we have reported that federal and nonfederal stakeholders and experts identified such evaluations as highly desirable and potentially useful but , at the same time , recognized that they may be difficult to do .

to provide insights concerning how agencies evaluate existing regulations , you requested that we examine agencies' implementation of retrospective regulatory reviews and the results of such reviews .

for selected agencies , we are reporting on: 1 ) the magnitude of retrospective review activity and type of retrospective reviews agencies completed from calendar year 2001 through 2006 , including the frequency , impetus ( mandatory or discretionary ) , and purposes of the reviews ; 2 ) the processes and standards that guide agencies' planning , conducting , and reporting on reviews , and the strengths and limitations of the various review processes and requirements ; 3 ) the outcomes of reviews , including the perceived usefulness of the reviews to agencies and the public and how they affected subsequent regulatory activities ; and 4 ) the factors that appear to help or impede agencies in conducting or using retrospective reviews , including which methods , if any , that agencies and we identified as most cost - effective for conducting reviews .

we assessed the activities of nine agencies and their relevant subagencies from 2001 through 2006 , including the departments of agriculture ( usda ) , justice ( doj ) , labor ( dol ) , and transportation ( dot ) ; consumer product safety commission ( cpsc ) ; environmental protection agency ( epa ) ; federal communications commission ( fcc ) ; federal deposit insurance corporation ( fdic ) ; and the small business administration ( sba ) .

we selected these agencies because they include cabinet departments , independent agencies , and independent regulatory agencies covering a wide variety of regulatory activities in areas such as health , safety , environmental , financial , and economic regulation .

we were not able to assess the activities of all regulatory agencies , due to time and resource constraints , but , given the diversity and volume of federal regulation conducted by the nine selected agencies , the results of our assessment should provide a reasonable characterization of the variety of retrospective regulatory reviews and the issues associated with their implementation .

further , our federal rules database showed that the nine agencies accounted for almost 60 percent of all final rules published from 2001 through 2006 .

the nine agencies accounted for almost 36 percent of all major rules ( for example , rules with at least a $100 million impact on the economy ) published during that time period .

to address our four objectives , we reviewed documentation from the selected agencies and interviewed agency officials .

we administered and collected responses to a structured data collection instrument that solicited information on agencies' retrospective review activities and lessons learned .

we supplemented this data collection by obtaining information from the federal register , unified agenda , and published dockets and reports listed on agency web sites , and by conducting a more detailed assessment of a sample of studies completed between 2001 and 2006 .

we also solicited perspectives on the usefulness of agency reviews and factors that help or impede the conduct of reviews from regulatory oversight entities , such as the office of information and regulatory affairs ( oira ) within the office of management and budget ( omb ) , the office of advocacy within sba , and knowledgeable nonfederal parties from a variety of sectors ( academia , business , public advocacy , and state government ) .

we reviewed agency policies , executive orders , and statutory requirements to identify what policies and procedures agencies have in place to guide planning , conducting , and reporting on reviews .

further , to identify the strengths and limitations of the processes , we assessed agencies' use of three systematic review practices that are important to the effectiveness and transparency of agency reviews , including the ( 1 ) use of a standards - based approach , ( 2 ) incorporation of public involvement , and ( 3 ) documentation of review processes and results .

in our more detailed assessment of a limited sample of retrospective reviews completed between 2001 and 2006 , we also assessed the agencies' application of research and economic standards and practices .

the sample that we assessed was too small to be generalizable to all agency retrospective reviews , but this assessment illustrated some of the strengths and limitations that exist in agency reviews .

we conducted our work in accordance with generally accepted government auditing standards from may 2006 through april 2007 .

 ( see app .

i for a more detailed description of our objectives , scope , and methodology. ) .

the performance and accountability of government agencies and programs have attracted substantial attention by congress , the executive branch , and others , including gao .

for example , the government performance and results act of 1993 ( gpra ) established a statutory framework designed to provide congressional and executive decision makers with objective information on the relative effectiveness and efficiency of federal programs and spending .

a central element of the current administration's presidential management agenda is the program assessment rating tool ( part ) , designed by omb to provide a consistent approach to assessing federal programs in the executive budget formation process .

over the past 2 years , we have emphasized that the long - term fiscal imbalance facing the united states and other significant trends and challenges establish the need to reexamine the base of the federal government and its existing programs , policies , functions , and activities .

we noted that a top - to - bottom review of federal programs and policies is needed to determine if they are meeting their objectives .

to support this reexamination , the policy process must have the capacity to provide policymakers not only with information to analyze the performance and results achieved by specific agencies and programs , but that of broad portfolios of programs and tools ( including regulation ) contributing to specific policy goals .

while initiatives such as gpra and part can evaluate regulatory performance at the agency or program level , congress and presidents also have instituted requirements that focus on a more basic element , the agencies' existing regulations .

for example , through section 610 , congress requires agencies to review all regulations that have or will have a “significant economic impact upon a substantial number of small entities” ( generally referred to as seisnose ) within 10 years of their adoption as final rules .

the purpose of these reviews is to determine whether such rules should be continued without change , or should be amended or rescinded , consistent with the stated objectives of applicable statutes , to minimize impacts on small entities .

as discussed later in this report , congress also established other requirements for agencies to review the effects of regulations issued under specific statutes , such as the clean air act .

every president since president carter has directed agencies to evaluate or reconsider existing regulations .

for example , president carter's executive order 12044 required agencies to periodically review existing rules ; one charge of president reagan's task force on regulatory relief was to recommend changes to existing regulations ; president george h.w .

bush instructed agencies to identify existing regulations to eliminate unnecessary regulatory burden ; and president clinton , under section 5 of executive order 12866 , required agencies to develop a program to “periodically review” existing significant regulations .

in 2001 , 2002 , and 2004 , the administration of president george w. bush asked the public to suggest reforms of existing regulations .

the office of advocacy within sba and oira within omb have issued guidance to federal agencies on the implementation of , respectively , the rfa and executive order 12866 .

the available guidance documents , including omb circular a - 4 on regulatory analysis , focus primarily on the procedural and analytical steps required for reviewing draft regulations , but they are also generally applicable whenever agencies analyze the benefits and costs of regulations , including those of existing regulations .

however , the documents provide limited guidance focused specifically on retrospective reviews .

in a short discussion on periodic reviews of existing rules pursuant to section 610 , the office of advocacy's rfa guidance briefly touches on planning , conducting , and reporting the results of reviews , but the omb / oira guidance does not specifically address the executive order's periodic review requirement .

in our prior work on this subject , we found that agencies infrequently performed certain types of reviews and identified potential challenges and benefits of conducting retrospective reviews .

in 1999 , we reported that assessments of the costs and benefits of epa's regulations after they had been issued had rarely been done .

in a series of reports on agencies' compliance with section 610 requirements , we again noted that reviews were not being conducted .

we identified a number of challenges to conducting retrospective reviews .

in general , these included the difficulties that regulatory agencies face in demonstrating the results of their work , such as identifying and collecting the data needed to demonstrate results , the diverse and complex factors that affect agencies' results ( for example , the need to achieve results through the actions of third parties ) , and the long time period required to see results in some areas of federal regulation .

we also identified concerns about the balance of regulatory analyses , because it may be more difficult to estimate the benefits of regulations than it is to estimate the costs .

our report on epa's retrospective studies noted that such studies were viewed as hard to do because of the difficulty in obtaining valid cost data from regulated entities and quantifying actual benefits , among other reasons .

our work on agencies' implementation of section 610 requirements revealed that there was confusion among the agencies regarding the meaning of key terms such as seisnose , what rfa considers to be a “rule” that must be reviewed , and whether amending a rule within the 10-year period provided in section 610 would “restart the clock,” among other things .

however , our prior work also pointed out that retrospective evaluation could help inform congress and other policymakers about ways to improve the design of regulations and regulatory programs , as well as play a part in the overall reexamination of the base of the federal government .

for example , we reported that retrospective studies provided insights on a market - based regulatory approach to reduce emissions that cause acid rain and that the studies found that the actual costs of reducing emissions were lower than initially estimated .

experts and stakeholders whom we consulted during work on federal mandates ( including regulations ) and economic and regulatory analyses told us that they believe more retrospective analysis is needed and , further , that there are ways to improve the quality and credibility of the analyses that are done .

one particular reason cited for the usefulness of retrospective reviews was that regulations can change behavior of regulated entities , and the public in general , in ways that cannot be predicted prior to implementation .

since 2001 , the nine selected agencies conducted multiple retrospective reviews of their existing regulations to respond to mandatory and discretionary authorities .

between 2001 and 2006 , the nine agencies reported completing over 1,300 mandatory or discretionary reviews , but many could not tally the total number of reviews that they have conducted .

the reviews addressed multiple purposes , such as examining the efficiency and effectiveness of regulations and identifying opportunities to reduce regulatory burden .

the mix of reviews conducted — in terms of the impetus to start a review and the purpose of the review — varied not only across but also within the agencies that we examined .

agencies conducted reviews in response to various mandatory requirements , but most agencies indicated that they conducted the majority of reviews based on their own discretion .

agencies reported conducting reviews , at their own discretion , in response to their agencies' own formal policies and procedures to conduct reviews or to respond to accidents or similar events , changes in technology and market conditions , advances in science , informal agency feedback , and petitions , among other things .

among the main mandatory sources of reviews were governmentwide statutory requirements ( such as section 610 of the rfa or the paperwork reduction act ( pra ) ) , agency - or program - specific statutory requirements ( such as section 402 of the telecommunications act of 1996 that requires fcc to review the regulations promulgated under the act every 2 years ) , executive order 12866 on regulatory planning and review ( which requires agencies to periodically conduct reviews of their significant regulations ) , and other executive branch directives ( such as the memorandum on plain language ) .

in addition , agencies conducted reviews in response to omb initiatives to solicit nominations for regulatory reexamination , which were not statutorily mandated reviews or required by a specific executive order , but were a part of executive branch regulatory reform efforts .

the frequency of agency reviews varied based on review requirements .

in some cases , agencies were required to conduct reviews every 2 years to 10 years .

available information on completed reviews indicated that the numbers of reviews completed by individual agencies in any given year varied from a few to more than a hundred .

agencies' officials reported they conducted discretionary reviews more often than mandated studies .

these discretionary reviews were often prompted by drivers such as informal suggestions or formal petitions from regulated entities seeking regulatory changes , suggestions from the agency personnel who implement and enforce the regulations , departmentwide initiatives to review regulations , or changes in particular technologies , industries , or markets .

although these discretionary reviews were often undocumented , our review of publicly available results for retrospective reviews confirmed that , in some instances , agencies like those within dol , dot , and doj cited discretionary drivers as the motivation for their reviews .

among the various reasons for agency - initiated reviews , petitions were a major review driver for almost all of the agencies .

agency officials cited three types of petition activities that largely influenced them to conduct regulatory reviews .

these petition activities included: ( 1 ) petitions for rulemaking where the regulated entities or public requested a modified rule that includes new or updated information , ( 2 ) petitions for reconsideration where regulated entities or the public requested that the agency revisit an aspect of the rule , and ( 3 ) petitions for waivers where the regulated entities or public requested waivers from regulatory requirements .

some agencies , such as dot and msha , have policies to begin a more formal review of the entire regulation when there are a substantial number of petitions .

agencies also reported conducting reviews in response to various mandatory requirements .

however , whether they conducted them more often in response to governmentwide requirements or requirements specific to the policy area or sector that they regulate varied among and within agencies .

for example , dot , usda's aphis , and sba conducted many mandatory reviews in response to section 610 requirements , while others , such as epa and fcc , conducted most mandatory reviews in response to statutes that applied specifically to areas that they regulate .

specifically , all of the mandatory reviews completed by aphis and sba since 2001 were conducted in response to section 610 requirements .

similarly , dot initiated a systematic 10-year plan for reviewing all of its sections of the cfr in order to satisfy the provisions of section 610 , along with other mandatory review requirements .

dot reported completing over 400 reviews between 2001 and 2006 under this 10-year plan .

however , even within dot , variation existed with regard to which review requirements more often prompted reviews .

for example , unlike some other dot agencies , faa conducted the majority of its mandatory reviews in response to industry - specific review requirements rather than governmentwide retrospective review mandates .

while epa , fcc , and fdic also conduct some reviews in response to governmentwide requirements , such as section 610 , they most often conducted mandatory reviews to comply with statutes that apply specifically to areas that they regulate .

epa officials provided a list of seven statutes that require the agency to conduct mandatory retrospective reviews , including requirements in the safe drinking water act , clean air act , clean water act , and federal food , drug and cosmetic act , among others .

similarly , fcc conducts many of its mandatory retrospective reviews to comply with the biennial and quadrennial regulatory review requirements under the communications act , as amended .

one agency in our review , fdic , conducted most of its mandatory reviews in response to the financial - sector - specific economic growth and regulatory paperwork reduction act of 1996 ( egrpra ) , which requires federal financial regulatory agencies to identify outdated , unnecessary , or unduly burdensome statutory or regulatory requirements every 10 years .

finally , agencies also conducted single comprehensive reviews of a regulation as a method to satisfy multiple review requirements .

for example , dol's ebsa and osha , dot , and fdic conducted reviews that incorporated section 610 and other review requirements into broader reviews that the agency initiated as part either of their regular review program or in response to industry feedback and petitions , among other things .

 ( table 1 illustrates the range of mandatory and discretionary reviews conducted by selected agencies included in our scope. ) .

the frequency with which agencies were required to conduct certain reviews varied depending on the statutory requirement .

for example , under some statutory requirements , agencies must review certain regulations every 2 or 3 years .

other requirements cover a longer period , such as section 610's requirement to revisit certain rules 10 years after their issuance , or specify no particular time .

in addition , agency policies on the frequency with which to conduct discretionary reviews varied .

for example , usda has a departmentwide requirement generally to review economically significant and major regulations every 5 years , while faa conducts its reviews on a 3-year cycle .

some agencies , such as dot , had a departmentwide requirement to review all regulations in its cfr within 10 years of the creation of its unified agenda regulatory plan , but provided discretion to its agencies on when to conduct reviews during that period .

despite a perception expressed by some federal and nonfederal parties that agencies are not actively engaged in reviewing their existing regulations , we found that agencies reported results for over 1,300 reviews completed between 2001 through 2006 .

however , even this number may understate the total because it does not account for all of the undocumented discretionary reviews conducted by agencies .

in addition , the available information reported by the agencies ( and others , such as omb ) may include some duplication or fail to capture additional follow - up reviews by the agencies .

it is also important to note that the units of analysis that agencies used in their reviews , and the scope of individual reviews , varied widely .

therefore , the level of agency review activity cannot be compared by only assessing the number of reviews completed .

for example , a review might be as narrowly focused as the review that dot's nhtsa completed in 2005 on 49 cfr part 571.111 ( regarding rearview mirrors ) or as broad as a fdic review that included analyses of 131 regulations within a single review .

dot also pointed out that because rules vary widely in complexity , even a narrowly focused review can be a major undertaking .

for example , nhtsa may review a one - sentence rule that says , “all motor vehicles sold in the u.s. must be equipped with airbags.” in another review , they may look at 131 regs that impose very minor requirements .

it may well be a far more time and resource intensive effort for nhtsa to review the effect of the one - sentence airbag requirement .

further , because some agencies produce many more regulations than others do , the number of reviews that agencies reported conducting also should be considered within the context of their volume of regulations and rulemaking activity .

table 2 lists the number of reviews that agencies reported completing between 2001 and 2006 .

according to agency officials , they conducted reviews for various purposes but most often focused on assessing the effectiveness of regulations .

agency officials reported conducting reviews to evaluate or identify ( 1 ) the results produced by existing regulations , including assessments to validate the original estimates of projected benefits and costs associated with the regulation ; ( 2 ) ways to improve the efficiency or effectiveness of regulatory compliance and enforcement ; and ( 3 ) options for reducing regulatory burdens on regulated entities .

overall , agency officials reported that their reviews more often focused on improving effectiveness , with burden reduction as a secondary consideration , even for review requirements that are geared toward identifying opportunities for burden reduction , such as those within section 610 .

the approaches that agencies reported taking to assess “effectiveness” varied , including measuring whether the regulations were producing positive outcomes , facilitated industry compliance with relevant statutes , and / or were assisting the agency in accomplishing its goals .

for example , dol officials reported that the agency attempts to assess “effectiveness” by measuring improvements resulting from the regulation and by analyzing factors required by section 610 of rfa and section 5 of executive order 12866 , such as whether there is new technology , excessive complexity , conflict with other regulations , or whether cost - effectiveness can be improved .

however , the agency does not conduct what would be considered a traditional benefit - cost economic analysis .

other agencies , such as epa , reported assessing “effectiveness” by determining whether the regulation is achieving its intended goal as identified in related statutes .

for example , officials from epa reported that their retrospective review of the clean water act helped them estimate the extent to which toxic pollutants remained , thereby aiding them to assess the effectiveness of each existing regulation in various sections of the act .

since the goal of the clean water act is zero discharge of pollutants , the review was an indicator of the progress the agency had made toward the statutory goals .

our limited review of agency summaries and reports on completed retrospective reviews revealed that agencies' reviews more often attempted to assess the effectiveness of their implementation of the regulation rather than the effectiveness of the regulation in achieving its goal .

the use of systematic evaluation practices and the development of formal retrospective regulatory review processes varied among and even within the agencies .

to assess the strengths and limitations of various agency review processes , we examined the three phases of the process: the selection of regulations to review , conduct of reviews , and reporting of review results .

we identified three practices that are important for credibility in all phases of the review , including the extent to which agencies ( 1 ) employed a standards - based approach , ( 2 ) involved the public , and ( 3 ) documented the process and results of each phase of the review .

the use of these evaluation practices in agency review processes , and the development of formal policies and procedures to guide their review processes , varied among the agencies .

furthermore , whether agencies used these practices often varied according to whether they conducted discretionary or mandatory reviews .

fewer agencies used standards - based approaches or documented the selection , conduct , or reporting of reviews when they were discretionary .

while more agencies incorporated public involvement in the selection of regulations for review in discretionary reviews , fewer included public involvement in the conduct of those reviews .

generally , agencies did not consistently incorporate the three practices we identified into their discretionary reviews as often as they did for their mandatory reviews .

however , it is important to note that some agencies have recently developed their review programs and others are attempting to find ways to further develop and improve their retrospective review processes ( i.e. , establishing units that focus on retrospective reviews and seeking assistance with establishing prioritization systems ) .

for example , cpsc and ebsa recently established their review programs , and eta recently established a centralized unit to develop retrospective review processes for the agency .

furthermore , although the process has been delayed because of other regulatory priorities , msha recently sought contractor assistance with developing a more standard selection process for its reviews .

 ( additional details on each agency's review process can be seen in apps .

ii through xi ) .

all of the agencies in our review reported that they have practices in place to help them select which of their existing regulations to review .

some of these agencies have established or are establishing standard policies and procedures , and guidance for this selection .

while almost all of the agencies reported having standards to select regulations for their mandated reviews because the mandates identified which regulations agencies must review or prescribed standards for selecting regulations to review , fewer agencies had yet developed formal standards for selecting regulations to review under their own discretion .

agencies that had established such processes reported that they were useful in determining how to prioritize agency review activities .

for example , dol's ebsa and cpsc established detailed standards for the selection of their discretionary reviews , which they used to prioritize their retrospective review activities and the corresponding use of agency resources .

the officials reported that their standards - based selection processes allowed them to identify which regulations were most in need of review and to plan for conducting those reviews .

furthermore , officials from both agencies reported that their prioritization processes allowed them to focus on more useful retrospective review activities , which resulted in identifying important regulatory changes .

we observed that this standards - based approach to selecting regulations also increased the transparency of this phase of the review process .

we were better able to determine how these agencies selected which regulations to review .

further , as identified by cpsc officials and others , applying a standards - based approach to selecting regulations to review can provide a systematic method for agencies to assess which regulations they should devote their resources toward , as they balance retrospective review activities with other mission - critical priorities .

the consequence of not using a standards - based approach could result in diverting attention from regulations that , through criteria , agencies could identify as needing the most consideration .

otherwise , agencies may instead focus their reviews on regulations that would warrant less attention .

in addition — for each phase of the review process — using a standards - based approach can allow agencies to justify the appropriateness of the criteria that they use ( either because they are objective , or at least mutually agreed upon ) , and thus gain credibility for their review .

selecting a different criterion or set of standards for each review could imply a subjective evaluation process and possibly an arbitrary treatment of one regulation versus another .

similarly , agencies varied in their use of a standards - based approach when analyzing regulations in reviews .

while most of the mandatory review requirements identified by the selected agencies establish standard review factors that agencies should consider when conducting their reviews — which agencies reported following — about half of the agencies within our review have formal policies and procedures that establish a standards - based approach for conducting discretionary reviews .

specifically , the five agencies that had formal procedures that established standards defined the steps needed to conduct reviews and review factors used to assess regulations .

other agencies had not yet established written guidance or policies to guide their conduct of reviews or define the analytical methods and standards they should use to assess regulations .

when we identified agencies that did specify objectives and review factors that they used when conducting reviews , they ranged from general ( such as to identify if they were still needed or could be simplified ) to specific ( such as to account for new developments in practices , processes , and control technologies when assessing emission standards ) .

we observed that the more specific sets of evaluative factors that agencies considered in different types of reviews shared several common elements , such as prompting agencies to consider comments and complaints received by the public and the regulation's impact on small entities .

our assessment of a small sample of agency reviews revealed that , even when relevant standards were available to agencies for conducting reviews , they did not always apply them .

in one case , the economic analyses conducted in the agency review did not employ some of the relevant best practices identified for these types of analyses in omb's guidance .

in another case , in conducting a mandated section 610 review , the agency relied only on public comments to evaluate the regulation and did not provide any additional assessment on the other four factors identified in the mandatory review requirements .

according to agency documentation , it ( 1 ) provided no further assessment of the factors and ( 2 ) concluded that the regulation did not need changes , because the agency received no public comments .

conversely , our review of another agency's section 610 assessment of regulations provided an example of how agencies that apply standards can use the reviews to produce substantive results .

because the agency relied both on public comments and its own assessment of the five section 610 review factors / standards , the agency identified additional changes that would not have been identified if it had relied on only one of these standards .

when we assessed whether agencies applied other generally accepted review standards , such as identifying how well they implemented the regulation , whether there was a pressing need for the regulation , or whether intended or unintended effects resulted from the regulation , we observed that some agencies' analyses did not .

most of the agencies within our review had established policies on reporting the results of their mandatory retrospective reviews to senior management officials and to the public , although in some cases , there was no requirement to do so .

for example , section 610 requires federal agencies to report on the initiation of a review , but does not require agencies to report the findings or policy decisions resulting from the review .

nevertheless , as a matter of practice , all of the agencies within our review reported information on the results of their section 610 reviews , though the content and level of detail varied .

conversely , about half of the agencies in our review had not established written policies or procedures for reporting the results of their discretionary retrospective reviews to the public .

as a result , we found inconsistencies in practices within agencies on how and whether they reported the results of these reviews to the public , resulting in less transparency in this process .

for example , agencies within dot , usda , and some within dol indicated that , at times , they report review results of discretionary reviews in the preambles of proposed rule changes or through other mechanisms , but they did not consistently do so .

agencies also reported that they often do not report the results of discretionary reviews at all , if they did not result in a regulatory change .

this lack of transparency may be the cause for assertions from nonfederal parties that they were unaware that agencies conducted discretionary reviews of their existing regulations .

figure 1 illustrates the differences in agencies' use of a standards - based approach in the three phases of the review process , for discretionary and mandatory reviews .

agency practices varied for soliciting and incorporating public input during the selection of regulations to review .

for example , in 2005 dot formally requested nominations from the public on which regulations it should review .

further , in the 2006 semi - annual unified agenda , the agency sought public suggestions for which regulations it should review .

however , agencies in our review more often reported that they solicit public input on which regulations to review during informal meetings with their regulated entities for their discretionary reviews .

techniques used by some of the agencies to obtain public input were informal networks of regulated entities , agency - sponsored listening sessions , and participation in relevant conferences .

for example , usda officials reported that they regularly meet with industry committees and boards and hold industry listening sessions and public meetings to obtain feedback on their regulations .

doj's dea reported holding yearly conferences with industry representatives to obtain their feedback on regulations .

while almost all of the agencies in our review reported soliciting public input in a variety of ways for their discretionary reviews , sba relied primarily on the federal register's unified agenda to inform the public about their reviews .

for mandatory reviews , agencies appeared to do less outreach to obtain public input on the selection of regulations to review .

however , it is important to note that such public input into the selection phase of mandated reviews may not be as appropriate because agencies have less discretion in choosing which regulations to review under specific mandates .

almost all agencies within our review reported soliciting public input into the conduct of their mandatory reviews , either through the notices in the federal register , or in more informal settings , such as roundtable discussions with industries , or both .

for these reviews , agencies appeared to almost always place notices in the federal register , including the semiannual unified agenda , soliciting public comments , but nonfederal parties cited these tools as being ineffective in communicating with the public because these sources are too complicated and difficult to navigate .

our review of the federal register confirmed that agencies often provided such notice and opportunity for public comment on these regulatory reviews .

in addition , some agencies , such as doj's atf , usda's ams , and fcc , reported on the agencies' analysis of the public comments and their effect on the outcome of the review .

however , we were not always able to track such notices or discussions of public input into the conduct of discretionary reviews .

officials from dol's msha and eta stated that , if internal staff generated the review and it was technical in nature , the agency might not include the public when conducting a review .

however , we were able to observe that some agencies , such as fcc , dot , and epa , did post comments received from petitioners and solicited public comments on these types of discretionary reviews in order to inform their analyses .

most agencies within our review did not solicit or incorporate public input on the reported results of their reviews .

we are only aware of a few agencies ( nhtsa , fcc , and epa ) that provided opportunities for additional public feedback on the analysis of their regulations before making final policy decisions .

figure 2 illustrates the difference in agencies' incorporation of public involvement in the three phases of the review process , for discretionary and mandatory reviews .

agency documentation for selecting regulations to review varied from detailed documentation of selection criteria considered to no documentation of the selection process .

for example , dol's ebsa documented its selection process , including selection criteria used , in detail in its regulatory review program .

however , agencies did not always have written procedures for how they selected regulations for discretionary reviews .

sba officials , for example , were not able to verify the factors they considered during the selection of some regulations that they reviewed because employees who conducted the reviews were no longer with the agency and they did not always document their review process .

the officials indicated that the agency considered whether the regulations that they reviewed under section 610 requirements were related to or complement each other , but did not always document selection factors for discretionary reviews .

this lack of documentation was particularly important for sba because the agency reported having high staff turnover that affected maintaining institutional knowledge about retrospective regulatory review plans .

for example , officials reported that within the 8 ( a ) business development program , there is a new director almost every 4 years who sets a new agenda for retrospective regulatory review needs .

however , because of other pressing factors , these reviews are often not conducted .

consequently , we conclude that this lack of documentation may result in duplicative agency efforts to identify rules for review or not including rules that the agency previously identified as needing review .

agency documentation of the analyses conducted in reviews ranged from no documentation to detailed documentation of their analysis steps in agency review reports .

while some agencies reported the analysis conducted in great detail in review reports , others summarized review analysis in a paragraph or provided no documentation of review analysis at all .

some agencies did not provide detailed reports because they did not conduct detailed analyses .

for example , sba officials reported that , for section 610 reviews , they do not conduct any additional analysis of the regulation if the public does not comment on the regulation .

our assessment of a sample of agency review reports revealed that , even for some reviews that provided a summary of their analysis , we could not completely determine what information was used and what analysis the agency conducted to form its conclusions .

further , agencies in our reviews reported that they less often documented the analysis of those reviews conducted on a discretionary basis .

one sba official acknowledged that it would be helpful if the agency better documented its reviews .

for each of the agencies we reviewed , we were able to find reports on the results of some or all of their completed reviews .

nonetheless , the content and detail of agency reporting varied , ranging from detailed reporting to only one - sentence summaries of results .

some agencies told us that they typically only document and report the results if their reviews result in a regulatory change .

further , officials from many agencies primarily reported conveying the results of only mandatory reviews to the public .

agencies employed a variety of methods to report review results to the public , but more often used the federal register and unified agenda .

although agencies in our review often reported the results of their mandatory reviews by posting them in the federal register , agencies like osha , cpsc , fcc , and those within dot also made some or all their review reports available on their web sites .

during our joint agency exit conference , officials indicated that agencies could do more to report their review analysis and results to a wider population of the public by using the latest information technology tools .

specifically , they said that agencies could: ( 1 ) use listserves to provide reports to identified interested parties , ( 2 ) make review analysis and results more accessible on agency web sites , and ( 3 ) share results in web - based forums , among other things .

nonfederal parties also reported that agencies could improve their efforts to report review results to the public and cited similar communication techniques .

additionally , nonfederal parties reported that agencies could improve communication by conducting more outreach to broad networking groups that represent various stakeholders , such as the chamber of commerce , the national council of state legislators , and the environmental council of states , and tailoring their summary of the review results to accommodate various audiences .

figure 3 illustrates the differences in agencies' use of documentation in the three phases of the review process , for discretionary and mandatory reviews .

agency reviews of existing regulations resulted in various outcomes — from amending regulations to no change at all — that agencies and knowledgeable nonfederal parties reported were useful .

mandatory reviews most often resulted in no changes to regulations .

conversely , agency officials reported that their discretionary reviews more often generated additional action .

both agency officials and nonfederal parties generally considered reviews that addressed multiple purposes more useful than reviews that focused on a single purpose .

agency reviews of existing regulations resulted in various outcomes including: changes to regulations , changes or additions to guidance and other related documents , decisions to conduct additional studies , and validation that existing rules were working as planned .

agencies and nonfederal parties that we interviewed reported that each of the outcomes could be valuable to the agency and the public .

however , for the mandatory reviews completed within our time frame , the most common result was a decision by the agency that no changes were needed to the regulation .

there was a general consensus among officials across the agencies that the reviews were sometimes useful , even if no subsequent actions resulted , because they helped to confirm that existing regulations were working as intended .

officials of some agencies further noted that , even when mandatory reviews do not result in changes , they might have already made modifications to the regulations .

our examinations of selected completed reviews confirmed that this is sometimes the case .

among the various outcomes of retrospective reviews were changes to regulations , changes or additions to guidance and other related documents , decisions to conduct additional studies , and validation that existing rules were working as planned .

agencies and nonfederal parties that we interviewed reported that each of the outcomes could be valuable to the agency and the public .

in our review of agency documentation , we confirmed that some reviews resulted in regulatory actions that appeared useful .

our review of agency documentation confirmed that some reviews can prompt potentially beneficial regulatory changes .

for example , osha's review of its mechanical press standard revealed that the standard had not been implemented since its promulgation in 1988 because it required a validation that was not available to companies .

consequently , osha is currently exploring ways to revise its regulation to rely upon a technology standard that industries can utilize and that will provide for additional improvements in safety and productivity .

although some reviews appeared to result in useful changes , the most common result for mandatory reviews was a decision by the agency that no changes were needed to the regulation .

however , there was a general consensus among officials across the agencies that such decisions are still sometimes useful because they helped to confirm that existing regulations were working as intended .

officials of some agencies further noted that , even when mandatory reviews do not result in changes , they might have already made modifications to the regulations .

our examinations of selected completed reviews confirmed that this is sometimes the case .

agency officials reported that their discretionary reviews resulted in additional action — such as prompting the agencies to complete additional studies or to initiate rulemaking to amend the existing rule — more often than mandatory reviews .

in particular , officials from usda's ams and fsis , fcc , sba , epa , doj , and dot reported that section 610 reviews rarely resulted in a change to regulations .

although ams has initiated 19 section 610 reviews since 2001 , ams officials reported that , because of their ongoing engagement with the regulated community , these reviews did not identify any issues that the agency did not previously know , and therefore resulted in no regulatory changes .

similarly , none of the section 610 reviews conducted by sba and dol's ebsa resulted in changes to regulations , and few changes resulted from section 610 reviews conducted by epa , fcc , doj , and dot .

the one apparent outlier in our analysis was fdic , which conducted many of its reviews in response to the financial - sector - specific burden reduction requirement in egrpra .

according to fdic officials and the agency's 2005 annual report , reviews conducted in response to this mandate resulted in at least four regulatory changes by the agency since 2001 and over 180 legislative proposals for regulatory relief that fdic and other members of the ffiec presented to congress .

the legislative proposals led to the passage of the financial services regulatory relief act , which reduced excessive burden in nine areas in the financial sector .

in addition , our analyses of the december 2006 unified agenda revealed that fdic attributed four of its nine proposed or initiated modifications to existing regulations to statutory mandates .

most agencies' officials reported that reviews they conduct at their own discretion — in response to technology and science changes , industry feedback , and petitions — more often resulted in changes to regulations .

as one of many examples , ebsa officials reported that because the reviews initiated and conducted by the agency to date have been precipitated by areas for improvement identified by the regulated community or the agency , virtually all the reviews have resulted in changes to the reviewed rules .

they reported that , in general , these changes have tended to provide greater flexibility ( eg , the use of new technologies to satisfy certain disclosure and recordkeeping requirements ) or the streamlining and / or simplifying of requirements ( eg , reducing the amount of information required to be reported ) .

similarly , dot officials and other agencies' officials reported that reviews that they conduct in response to industry and consumer feedback and harmonization efforts also resulted in changes to regulations more often than mandated reviews .

in addition , some agencies also reported that reviews that incorporated review factors from both their mandatory requirements and factors identified by the agency in response to informal feedback often resulted in useful regulatory changes .

these agencies' reviews incorporated factors identified by the agency as well as ones that were requirements in mandatory reviews .

for example , dol's osha and ebsa selected regulations for review based upon criteria that they independently identified and selection criteria identified by section 610 requirements .

they also incorporated review factors listed in section 610 requirements into a broader set of evaluative factors considered during their discretionary reviews , including assessing: ( 1 ) whether the regulation overlaps , duplicates , or conflicts with other federal statutes or rule ; and ( 2 ) the nature of complaints against the regulation .

as a result , they reported that these reviews generated useful outcomes .

nonfederal parties also indicated that reviews that focus on multiple review factors and purposes are more useful than reviews that focus only one purpose , such as only burden reduction or only enforcement and compliance or only one factor , such as public comments .

because agencies did not always document discretionary reviews that they conducted , it is not possible to measure the actual frequency with which they resulted in regulatory change .

however , we observed that , for cases where agencies reported modifications to regulations , these actions were most often attributed to factors that agencies addressed at their own discretion , such as technology changes , harmonization efforts , informal public feedback , and petitions .

for example , although epa officials reported that they have many mandatory regulatory review requirements , our review of proposed or completed modifications to existing regulations reported in the december 2006 unified agenda showed that 63 of the 64 modifications reported were attributed to reasons associated with agencies' own discretion .

as illustrated in figure 4 , other agencies within our review had similar results .

although agencies reported , and our analysis of the unified agenda indicated , that agencies more often modify existing regulations for reasons attributed to their own discretion , it is important to note that mandatory reviews may serve other valuable purposes for congress .

such reviews may provide congress with a means for ensuring that agencies conduct reviews of regulations in policy areas that are affected by rapidly changing science and technology and that agencies practice due diligence in reviewing and addressing outdated , duplicative , or inconsistent regulations .

for example , congress required fcc to conduct reviews of its regulations that apply to the operation or activity of telecommunication service providers to “determine whether any such regulation is no longer necessary in the public interest as the result of meaningful economic competition between providers of such service.” agencies' officials reported that reviews often had useful outcomes other than changes to regulations , such as changes or additions to guidance and other related documents , decisions to conduct additional studies , and validation that existing rules were working as planned .

for example , osha officials reported that , outside of regulatory changes , their reviews have resulted in recommended changes to guidance and outreach materials and / or the development of new materials or validation of the effectiveness of existing rules .

our review of omb's regulatory reform nominations process confirmed that at least four of osha's reviews conducted in response to omb's manufacturing reform initiative resulted in changes to or implementation of final guidance or the development of a regulatory report .

we observed similar results from omb's regulatory reform process for epa .

similarly , dot officials reported that their reviews also often led to changes in guidance or in further studies , and our examination of review results reported by dot confirmed that this was often the case .

moreover , all of the agencies within our review reported that reviews have resulted in validating that specific regulations produced the intended results .

agencies' officials reported that barriers to their ability to conduct and use reviews included: ( 1 ) difficulty in devoting the time and staff resources required for retrospective review requirements , ( 2 ) limitations on their ability to obtain the information and data needed to conduct reviews , and ( 3 ) constraints in their ability to modify some regulations without additional legislative action , among other important factors .

both agencies and nonfederal parties identified the lack of public participation in the review process as a barrier to the usefulness of reviews .

the nonfederal parties also identified the lack of transparency in agency review processes as a barrier to the usefulness of reviews .

agency officials and nonfederal parties also suggested a number of practices that could facilitate conducting and improving the usefulness of regulatory reviews , including: ( 1 ) development of a prioritization process to facilitate agencies' ability to address time and resource barriers and allow them to target their efforts at reviews of regulations that are more likely to need modifications , ( 2 ) pre - planning for regulatory reviews to aid agencies in identifying the data and analysis methodology that they will need to conduct effective reviews , and ( 3 ) utilizing independent parties to conduct the reviews to enhance the review's credibility and effectiveness , among other things .

while there was general consensus among federal and nonfederal parties on the major facilitators and barriers , there were a few clear differences of opinions between them regarding public participation and the extent to which reviews should be conducted by independent parties .

because only a few agencies track the costs associated with conducting their reviews , one cannot identify the type and approach to retrospective review that may be most cost effective .

however , agency officials told us that the reviews have resulted in cost savings to their agencies and to regulated parties , for example by saving both the agency and the public the costs of repeatedly dealing with petitions for change or waivers in response to difficulties implementing particular regulatory provisions .

all of the agencies in our review reported that the lack of time and resources are the most critical barriers to their ability to conduct reviews .

specifically , they said that it is difficult to devote the time and staff resources required to fulfill various retrospective review requirements while carrying out other mission - critical activities .

agencies' officials reported that , consequently , they had to limit their retrospective review activities during times when they were required to respond to other legislative priorities .

for example , officials from msha reported that they conducted fewer reviews in 2006 because they were heavily engaged in trying to implement the mine improvement and new emergency response act of 2006 ( miner act ) , which congress passed in response to mining accidents that occurred in 2006 .

prior to these events , msha was engaged in soliciting a contractor to assist the agency in prioritizing its retrospective review efforts .

the officials reported that , because of the need to develop regulations pursuant to the act , they stopped the process of looking for a contractor , and conducted fewer reviews .

officials from various agencies reported that retrospective reviews are the first activities cut when agencies have to reprioritize based upon budget shortfalls .

a dot official reported that , despite having high - level management support for retrospective review activities , the department has still experienced funding limitations that have affected their ability to conduct retrospective review activities .

our examination of agency documents confirmed that several agencies indicated that they did not complete all of the reviews that they planned and scheduled for some years within the scope of our review because sufficient resources were not available .

in one example , we found that faa delayed conducting any planned reviews for an extended period because , as reported in the unified agenda , they did not have the resources to conduct them .

many of the agencies in our review did not track the costs ( usually identified in terms of full - time equivalent ( fte ) staff resources ) associated with their reviews ; therefore , they could not quantify the costs of conducting reviews .

most agencies' officials reported that they lack the information and data needed to conduct reviews .

officials reported that a major data barrier to conducting effective reviews is the lack of baseline data for assessing regulations that they promulgated many years ago .

because of this lack of data , agencies are unable to accurately measure the progress or true effect of those regulations .

similar data collection issues were also identified by agencies in the eisner and kaleta study published in 1996 , which concluded that , in order to improve reviews for the future , agencies should collect data to establish a baseline for measuring whether a regulation is achieving its goal , and identify sources for obtaining data on ongoing performance .

agencies and nonfederal parties also considered pra requirements to be a potential limiting factor in agencies' ability to collect sufficient data to assess their regulations .

for example , epa officials reported that obtaining data was one of the biggest challenges the office of water faced in conducting its reviews of the effluent guideline and pretreatment standard under the clean water act , and that as a result the office of water was hindered or unable to perform some analyses .

according to the officials , while epa has the authority to collect such data , the pra requirements and associated information collection review approval process take more time to complete than the office of water's mandated schedule for annual reviews of the effluent guideline and pretreatment standard allows .

while one nonfederal party did not agree that pra restrictions posed a significant barrier to conducting reviews , agencies and nonfederal parties generally agreed that the act was an important consideration in agency data collection .

however , while agencies identified the potential limitations of pra , it is important to recognize that pra established standards and an approval process to ensure that agencies' information collections minimize the federal paperwork burden on the public , among other purposes .

in general , data collection appeared to be an important factor that either hindered or facilitated reviews .

some of the agencies in our review that promulgate safety regulations , such as cpsc , nhtsa , and those within doj , reported that having sufficient access to established sources of safety data , such as death certificates or hospital databases on deaths and injuries related to products , greatly facilitated their ability to conduct retrospective reviews of their regulations .

finally , agencies also reported facing limits on their ability to obtain data on their regulations because of the length of time it takes to see the impact of some regulations and the scarcity of data related to areas that they regulate .

nonfederal parties also cited this data limitation as a challenge to agency reviews .

to make efficient use of their time and resources , various agency officials said that they consider all relevant factors , including effectiveness and burden reduction , whenever they review an existing regulation .

therefore , when reviews that have predetermined or generic schedules and review factors ( such as 10-year section 610 reviews ) arise , the agency might have already reviewed and potentially modified the regulation one or more times , based upon the same factors outlined in section 610 .

the officials reported that , although the subsequent predetermined reviews are often duplicative and less productive , they nevertheless expend the time and resources needed to conduct the reviews in order to comply with statutory requirements .

however , they reported that these reviews were generally less useful than reviews that were prompted because of informal industry and public feedback , petitions , changes in the market or technology , and other reasons .

furthermore , agencies expressed concerns about whether predetermined schedules may conflict with other priorities .

dot acknowledged this issue even as it was establishing an agency policy to require retrospective reviews .

in response to a public suggestion that dot conduct reviews based upon a regular predetermined schedule , the agency cautioned that arbitrary schedules might mean delaying other , more important regulatory activities .

as examples of predetermined reviews that may be duplicative or unproductive , officials from agencies within dot , usda , and dol reported that the regulations that most often apply to their industries may need review sooner than the 10-year mark prescribed by section 610 .

to be responsive to the regulated community , the agencies regularly review their regulations in response to public feedback , industry and technology changes , and petitions , among other things , and make necessary changes before a section 610 review would be required .

our assessment of reviews listed in the unified agenda confirmed that agencies often noted that they had not made changes because of their section 610 reviews , but had previously made changes to these regulations because of factors that previously emerged .

for example , usda's ams reported completing 11 mandated section 610 reviews since 2001 , which resulted in no regulatory changes .

for 9 of these reviews , the related published section 610 reports stated that ams made no changes to the regulations because they were modified “numerous times” in advance of the 10-year section 610 review to respond to changes in economic and other emerging conditions affecting the industry .

similar to agency views on timing , views by an omb official and some nonfederal parties indicated that the period immediately after an agency promulgates a rule may be a critical time for agencies to review certain types of regulations , in part because once the regulated community invests the resources to comply with the regulations and integrates them into their operations , they are less likely to support subsequent changes to the regulation .

in addition , the immediate effects of certain types of regulations , such as economic incentive regulations , may be more apparent and changes , if needed , can be brought about sooner .

nonfederal parties reported that this may be especially important during the time that regulated entities are facing challenges with the implementation of a regulation .

some of these commenters noted that such immediate reviews might be especially appropriate for rules that have a high profile , are controversial , or involve a higher degree of uncertainty than usual .

two agencies within our review that had predetermined deadlines that are set only a few years apart also reported that these schedules affected their ability to produce more useful reviews .

the officials reported that they do not have enough time to effectively complete the reviews prior to beginning another review .

for example , epa and fcc both stated that agency - specific review requirements to conduct reviews of their regulations every few years make it difficult for the agencies because either the agencies do not have enough time to effectively gather data for the reviews or do not have enough time to observe new effects of the regulation between reviews .

as a result , the agencies may be doing a less comprehensive job in conducting the reviews and have more difficulty in meeting their review deadlines .

for requirements that specify a predetermined schedule for conducting reviews , agencies also identified , as a potential barrier , the lack of clarity on when to “start the clock” for regulations that have been amended over time .

for example , as previously mentioned , in order to satisfy section 610 requirements , dot initiated an extensive process for reviewing its sections of the cfr every year .

the agency's officials reported that they adopted this extensive approach because they were unable to determine whether to review a regulation 10 years after its promulgation or 10 years after its last modification .

other agencies included in our review did not take this approach to meeting section 610 requirements .

similarly , in our 1999 report on rfa , we reported that agencies' varying interpretations of section 610 requirements affected when they conducted reviews .

while agencies' officials reported that predetermined schedules can sometimes be ineffective , it is important to note that such schedules can also help ensure that reviews occur .

specifically , some parties have noted that a benefit of prespecifying the timing of reviews is that this provides congress with a way to force agencies to periodically reexamine certain regulations .

in general , as illustrated in table 3 , our review of the timing of reviews and the evaluative factors that agencies are supposed to assess in those reviews revealed that there is considerable overlap in the various mandatory and discretionary review requirements .

various agencies identified scoping issues as a barrier to the usefulness of reviews .

agencies' officials reported significant delays in completing reviews and making timely modifications , as well as obtaining meaningful input in reviews that involved multiple regulations as the unit of analysis .

some agencies , such as dol's msha , reported experiencing delays up to 16 years in completing a review because they scoped their review too broadly .

specifically , msha officials reported that , during a comprehensive review of their ventilation standards , the scope of the review increased due to input from other departmental agencies .

because of this input and the complexity of the rule itself , it took 16 years to complete the modifications , resulting in a major rewrite of the ventilation standards .

in our assessment of this review , the resulting information was not as timely as it otherwise could have been , and therefore may have been less useful .

similarly , officials from other agencies reported that scoping reviews too broadly also affected their ability to conduct expedient reviews .

agencies' officials suggested that having a narrow and focused unit of analysis , such as a specific standard or regulation , is a more effective approach to conducting reviews .

specifically , officials from dot and fdic reported that , when they conducted narrowly defined reviews , the public provided more meaningful input on their regulations .

furthermore , one nonfederal party emphasized that , when agencies choose to analyze a broad unit of analysis , such as an act , it is difficult for the public to discern which regulations are doing well and which are not .

the positive effects of one regulation under the legislation can overshadow the negative effects of other regulations .

therefore , the performance assessment of the relevant regulations is less transparent and , consequently , less useful .

agencies' officials reported that statutory requirements are a major barrier to modifying or eliminating regulations in response to retrospective regulatory reviews because some regulations are aligned so closely with specific statutory provisions .

therefore , the agencies may be constrained in the extent to which they can modify such regulations without legislative action .

for example , officials from msha , fdic , and sba reported that many of their regulations mirror their underlying statutes and cannot be modified without statutory changes .

during its retrospective reviews to reduce burden , fdic along with other banking agencies within the ffiec , identified 180 financial regulations that would require legislative action to revise .

similarly , in our 1999 report on regulatory burden , we found that agencies often had no discretion , because of statutory provisions , when they imposed requirements that businesses reported as most burdensome .

one approach taken by fdic to address this issue was to identify regulations that required legislative action in their review process and to coordinate with congress to address these potential regulatory changes .

because of this approach , congress is actively involved in fdic's regulatory burden relief efforts and has passed changes in legislation to provide various forms of burden relief to the financial sector .

agencies and nonfederal parties identified the lack of public participation in the review process as a barrier to the usefulness of reviews .

agencies stated that despite extensive outreach efforts to solicit public input , they receive very little participation from the public in the review process , which hinders the quality of the reviews .

almost all of the agencies in our review reported actively soliciting public input into their formal and informal review processes .

they reported using public forums , and industry meetings , among other things for soliciting input into their discretionary reviews , and primarily using the federal register and unified agenda for soliciting public input for their mandatory reviews .

for example , usda officials reported conducting referenda of growers to establish or amend ams marketing orders , and cpsc officials reported regularly meeting with standard - setting consensus bodies , consumer groups , and regulated entities to obtain feedback on their regulations .

other agencies reported holding regular conferences , a forum , or other public meetings .

however , most agencies reported primarily using the unified agenda and federal register to solicit public comments on mandatory reviews , such as section 610 reviews .

despite these efforts , agency officials reported receiving very little public input on their mandatory reviews .

nonfederal parties we interviewed were also concerned about the lack of public participation in the retrospective review process and its impact on the quality of agency data used in reviews .

however , these nonfederal parties questioned the adequacy and effectiveness of agencies' outreach efforts .

specifically , 7 of the 11 nonfederal parties cautioned that the federal register and unified agenda are not sufficiently effective tools for informing the public about agency retrospective review activities .

in addition , most of the nonfederal parties we interviewed were unaware of the extent to which agencies conducted reviews under their own discretion , and most of those parties reported that they were not aware of the outreach efforts agencies are making to obtain input for these reviews .

limited public participation in some review activities was cited by both agencies and nonfederal parties as a barrier to producing quality reviews , in part because agencies need the public to provide information on the regulations' effects .

both agency officials and nonfederal parties identified methods for improving communication , including using agency web sites , e - mail listserves , or other web - based technologies ( such as web forums ) , among other things .

nonfederal parties identified the lack of transparency in agency review processes , results , and related follow - up activities as a barrier to the usefulness of reviews to the public .

nonfederal parties were rarely aware of the retrospective review activities reported to us by the agencies in our review .

similarly , in our review of the federal register and unified agenda , we were not always able to track retrospective review activities , identify the outcome of the review , or link review results to subsequent follow - up activities , including initiation of rulemaking to modify the rule .

as stated earlier , some mandatory reviews do not require public reporting and many agencies did not consistently report the results of their discretionary reviews , especially if the reviews resulted in no changes to regulations .

some nonfederal parties told us that lack of transparency was the primary reason for the lack of public participation in agencies' review processes .

agencies and nonfederal parties identified pre - planning for regulatory reviews as a practice that aids agencies in identifying the data and analysis methodology that they need to conduct effective outcome - based performance reviews .

some agencies within our review planned how they would collect performance data on their regulations before or during the promulgation of the relevant regulations or prior to the review .

they cited this technique as a method for reducing data collection barriers .

for example , dot's nhtsa was an agency that omb officials and nonfederal parties identified as appearing to conduct effective retrospective reviews of its regulations .

nhtsa officials reported to us that , to conduct effective reviews , they plan for how they will review their regulations even before they issue them .

prior research on regulatory reviews also cited the need for agencies to set a baseline for their data analysis , in order to conduct effective reviews .

in addition , we have long advocated that agencies take an active approach to measuring the performance of agency activities .

furthermore , we observed that pre - planning for data collection could address some challenges that agencies reported facing with pra data collection requirements , such as the length of time required to obtain approval .

agencies reported that prioritizing which regulations to review facilitated the conduct of and improved usefulness of their reviews .

agencies that developed review programs with detailed processes for prioritizing which regulations to review reported that this prioritization facilitated their ability to address time and resource barriers to conducting reviews and allowed them to target their efforts at more useful reviews of regulations that were likely to need modifications .

as previously mentioned , dol's ebsa and cpsc developed detailed prioritization processes that allowed officials to identify which regulations were most in need of review and to plan for conducting those reviews .

furthermore , this process allowed cpsc to prospectively budget for its reviews and to identify the number of substantive reviews per year that the agency could effectively conduct , while meeting its other agency priorities .

officials from both agencies reported that their prioritization processes allowed them to focus on the most useful retrospective review activities , which identified important regulatory changes .

nonfederal parties that we interviewed also asserted that it is not necessary or even desirable for agencies to expend their time and resources reviewing all of their regulations .

instead , they reported that it would be more efficient and valuable to both agencies and the public for agencies to conduct substantive reviews of a small number of regulations that agencies and the public identify as needing attention .

nonfederal parties and agency officials suggested that factors that agencies should consider when prioritizing their review activities could include economic impact , risk , public feedback , and length of time since the last review of the regulation , among other things .

nonfederal regulatory parties believed that reviews would be more credible and effective if the parties that conduct them were independent .

for example , two different parties who we interviewed said that epa's first report in response to section 812 under the clean air act could have been improved by involving independent analysts .

however , they recognized that it is important to include input from those who were involved in the day - to - day implementation of the regulation and were responsible for producing initial benefit - cost estimates for the regulations .

almost all of the nonfederal parties that we interviewed expressed concern that agency officials who promulgated and implemented regulations may be the same officials who are responsible for evaluating the performance of these regulations .

although the nonfederal parties acknowledged that it is important for officials with critical knowledge about the program to be involved with providing input into the review , they were concerned that officials placed in this position may not be as objective as others may be .

nonfederal parties also expressed concerns about agencies' capacity to conduct certain types of analyses for their reviews , such as benefit - cost assessments .

the nonfederal parties suggested that agencies could consider having an independent body like another agency , inspector general , or a centralized office within the agency conduct the reviews .

during our review , agencies' officials reported that they sometimes contract out their reviews if they do not have the expertise needed to conduct the analyses .

however , during a discussion of this issue at our joint agency exit meeting , agency officials pointed out the difficulty in finding a knowledgeable independent review body to conduct retrospective reviews , and they noted that even contracted reviewers may be considered less independent , because they are paid by the agency to conduct the study .

agencies and nonfederal regulatory parties agreed that high - level management support in the review process is important to the successful implementation of not only individual reviews but also to sustaining the agency's commitment to a review program and following up on review results .

as an example , officials from fdic credited the accomplishments of their review program largely to the support of high - level managers who headed the ffiec effort to reduce regulatory burden on financial institutions .

officials reported that the leadership of the director of the office of thrift supervision , who chaired the ffiec effort , helped to catapult support for reviews at all of the ffiec agencies , including fdic , and helped to free up resources to conduct reviews at these agencies .

almost all of the selected agencies reported involving some high - level management attention in their reviews , but where and how they used this involvement varied .

for example , while almost all of the agencies reported involving high - level management attention in decision - making processes that resulted from reviews , cpsc and ebsa's review programs also involved high - level managers early in their processes , in order to determine which regulations to review .

overall , agencies and nonfederal parties indicated that having high - level management attention is important to obtaining and sustaining the resources needed to conduct reviews and the credibility of agency reviews .

according to agency officials from dot , dol , sba , and fdic , they learned that grouping related regulations together when conducting reviews is a technique that more often generated meaningful comments and suggestions from the public .

for example , officials from fdic stated that categorizing regulations for review and soliciting input over an extended time period proved to be a more effective way of receiving public input .

they reported that placing regulations into smaller groups and soliciting feedback on these categories separately over a 3-year period helped the members of the ffiec to avoid overwhelming the public with the regulatory reviews , and allowed the agencies to receive more thoughtful participation and input .

sba officials reported reviewing related regulations together because a change to one rule can have an impact on the related rules .

similarly , a dot official reported that grouping similar regulations together to solicit public input was an effective technique for faa because the agency regulates a broad policy area .

faa received 1800 suggestions for regulatory changes based upon one such review .

however , the official cautioned that while grouping regulations is an effective technique to obtaining useful public input , defining the categories too broadly can lead to an effort that is too intensive .

in addition , the practice may be less convenient and practical for agencies that write very specific standards , such as nhtsa .

for these agencies it may be more effective to pick related characteristics of rules in order to group regulations to review .

nonfederal parties suggested that agencies need to be more aware of the different audiences that might be interested in their reviews , and target the level of detail and type of product used to report the results to meet the needs of these various audiences .

for example , a product that focuses on specific details of implementing a regulation may be less useful to those interested in the policy effects of a regulation , and vice versa .

further , both agency officials and nonfederal parties identified methods for improving communication , including better use of information technology tools , such as agency web sites , electronic docket systems , e - mail listserves , web - based forums , or other web - based technologies .

agencies have not estimated all of the costs and benefits associated with conducting retrospective reviews , but they believe that retrospective reviews have resulted in cost savings to their agencies .

for example , msha officials reported that their retrospective regulatory reviews related to petitions for modification produce savings for the agency because the reviews prompt the agency to review and modify regulations that are heavily petitioned , which reduces costs associated with reviewing similar petitions .

they reported that these reviews also save the mining industry from the costs associated with repeatedly filing petitions .

in addition to petition - related cost savings , agencies could save costs by reviewing and eliminating regulations that are no longer useful .

therefore , agencies could reduce costs associated with implementing and enforcing outdated or unproductive regulations .

we found that only a few agencies track the costs associated with conducting their reviews , so we were unable to identify which methods are most cost effective .

some agency officials , such as those in msha , reported that tracking direct costs associated with reviews is difficult because reviews are conducted as part of the normal operation of the agencies and in concert with other actions to fulfill the agencies' missions .

however , some agencies like cpsc establish budgets for their reviews , and track the associated costs .

as a result , cpsc determined that conducting about four regulatory reviews per year was a reasonable effort for the associated expense to the agency .

osha also tracks the costs associated with its reviews .

the agency's officials told us that each of its reviews typically requires 2 / 3 of a program analyst fte in the office of evaluations and audit analysis , about 1 / 5 of an attorney fte in the office of the solicitor , 1 / 2 fte for the involvement of staff from other directorates , and approximately $75,000 to $100,000 of contractor support per review .

although agencies did not always track the cost of their reviews , officials reported that they know some reviews are not cost effective .

for example , a usda official reported that , by nature , some regulations are set up by the agency to be reviewed regularly .

therefore , externally imposed reviews only duplicate this effort .

an example of such reviews would be those conducted for regulations that are consistently reviewed by industry committees that are appointed by the secretary of an agency .

ams officials reported that industry committees appointed by the secretary of agriculture oversee many of the agency's regulations and , as one of their main functions , regularly review ams regulations to identify needed changes .

therefore , regulations under the purview of these committees are already constantly being reviewed and updated , and thus may benefit less from a section 610 review than other regulations .

our review revealed that agencies are conducting more reviews , and a greater variety of reviews , than is readily apparent , especially to the public .

to facilitate their reviews , agencies , to greater and lesser extents , have been developing written procedures , processes , and standards to guide how they select which rules to review , conduct analyses of those rules , and report the results .

given the multiple purposes and uses of reviews , we recognize that there is no “one size fits all” approach .

however , there are lessons to be learned from ongoing regulatory reviews that could benefit both the agencies in our scope and others that conduct retrospective regulatory reviews .

because agencies are attempting to find ways to further develop and improve their retrospective review processes ( for example , establishing units that focus on retrospective reviews and seeking assistance with establishing prioritization systems ) , identifying ways to share promising practices could collectively improve agency review activities .

feedback from agency officials and nonfederal parties , as well as our own analysis , indicate that there are procedures and practices that may be particularly helpful for improving the effectiveness and transparency of retrospective review processes .

for example , agencies can be better prepared to undertake reviews if they have identified what data will be needed to assess the effectiveness of a rule before they start a review and , indeed , before they promulgate the rule .

if agencies fail to plan for how they will measure the performance of their regulations , and what data they will need to do so , they may continue to be limited in their ability to assess the effects of their regulations .

given increasing budgetary constraints , both agency officials and nonfederal parties emphasized the need to better prioritize agency review activities , when possible , to more effectively use their limited resources .

agency officials and nonfederal parties recognize that time and resources are too limited to allow for a regular , systematic review of all of their regulations , and that devoting excessive time and scarce resources to a formal review of all of their regulations could result in insufficient attention to other regulatory needs or statutory mandates .

as we have observed , some agencies are already using such prioritization processes .

without a detailed prioritization system , agencies may not be able to effectively target their reviews so that they devote resources to conducting substantive and useful reviews of the regulations that need the most attention .

agencies and nonfederal parties also reported that reviews are more credible and useful to all parties if agencies have assessed multiple review factors in their analyses of the regulations , rather than relying on a single factor , such as public comments .

the failure of agencies to do this could result in reviews that miss assessing crucial information that could provide context to the results of the analysis , such as weighing the benefits against the burdens of the regulation .

further , our assessment of the strengths and limitations of agency reviews revealed that agencies could improve their efforts to employ a standards - based approach to conducting discretionary reviews .

agencies are inconsistently applying a standards - based approach to conducting discretionary reviews .

applying a standards - based approach could enhance the transparency and consistency of reviews .

agencies' reporting of reviews appears largely ineffective .

none of the nonfederal parties we contacted were aware of the extent of agency retrospective review activities .

this lack of awareness might be attributable to two reasons .

first , agencies typically did not report results for discretionary reviews , which account for most of agencies' review activities .

therefore , the public cannot be expected to know about these reviews .

second , when agencies do report on their activities , the mode and content of these communications may not be effective .

for example , although we found that some agencies used multiple modes of communication , for the most part agencies reported that they rely heavily on the federal register .

however , nonfederal parties indicated that reliance on the federal register is not sufficient .

further , the content that agencies do publish does not always provide adequate information about the analysis and results of the reviews .

our own assessment showed that it was sometimes difficult to determine the outcomes of the reviews or the bases for the agencies' conclusions .

some agencies have employed multiple communication modes and provided detailed content in their reports , but still report disappointing levels of public participation .

therefore , it is clear that agencies need to continue to explore methods to more effectively communicate and document information about their reviews and the underlying analyses .

according to agency officials and nonfederal parties , such methods could include using agency web sites , e - mail listserves , or other web - based technologies ( such as web forums ) .

when agencies do not effectively communicate the analysis and results of their reviews , they miss the opportunity to obtain meaningful comments that could affect the outcome of their reviews .

further , without showing the underlying analysis of reviews , the agencies' conclusions may lack credibility .

agencies and nonfederal parties also emphasized the importance of having high - level support for sustaining agency retrospective review activities , and increasing their credibility with the public .

without such attention , agencies will face difficulties in making retrospective review a priority that receives the resources necessary for conducting successful reviews .

agencies provided specific examples that illustrated how high - level management support helped to ensure that they followed through on the results of regulatory reviews .

although agency officials cautioned that even high - level management support might not be sufficient to overcome all budgetary constraints , having such support may ensure that some retrospective review activity will be sustained .

one of the most striking findings during our review was the disparity in the perceived usefulness of mandatory versus discretionary regulatory reviews .

the agencies characterized the results of their discretionary reviews as more productive and more likely to generate further action .

a primary reason for this appears to be that discretionary reviews that address changes in technology , advances in science , informal agency feedback , harmonization efforts , and petitions , among other things , may be more closely attuned to addressing issues as they emerge .

while agencies' officials reported that their discretionary reviews might be more useful than the mandatory reviews , we can not definitively conclude which reviews are most valuable .

we did not assess the content and quality of discretionary reviews , and could not have done so because they often were not documented .

although the officials reported that the bulk of their review activity is associated with discretionary reviews , they could not provide evidence to show definitively that this was so or that discretionary reviews more often generated useful outcomes .

further , one cannot dismiss the value that congress anticipated when establishing the mandatory requirements for agencies to conduct reviews for particular purposes and on particular schedules .

the predetermined time frames of mandatory reviews can both help and hinder .

on one hand , predetermined schedules are one means by which congress can force agencies to periodically reexamine certain regulations .

however , the timing for some mandatory reviews may either be too short or overlap with other review requirements , making it more difficult for agencies to produce meaningful analysis from their reviews .

conversely , from the cursory information that agencies reported for some mandatory reviews that have review periods as long as 10 years , it appears that agencies may devote limited time and resources to conducting these reviews , perhaps partly because the required timelines do not recognize ongoing changes to regulations .

further , the criteria used in mandatory and discretionary reviews may be duplicative .

in general , our review of the timing of reviews and the evaluative factors that agencies are supposed to assess in those reviews revealed that there is considerable overlap in the various mandatory and discretionary review requirements .

to make efficient use of their time and resources , agency officials said that they consider all relevant factors , including effectiveness and burden reduction , whenever they review an existing regulation .

therefore , when there are duplicative review factors ( such as assessing whether the rule is still needed , overly burdensome , or overlaps with other regulations ) , the agency might have already reviewed and potentially modified the regulation one or more times based upon the same factors .

the officials reported that , although the subsequent reviews are often duplicative and less productive , they nevertheless expend the time and resources needed to conduct the reviews in order to comply with statutory requirements .

given the long - term fiscal imbalance facing the united states and other significant trends and challenges , congress and the executive branch need to carefully consider how agencies use existing resources .

in particular , overlapping or duplicative reviews may strain limited agency resources .

as agencies face trade - offs in allocating these limited resources to conducting mandatory and discretionary reviews , as well as conducting other mission - critical activities , they have to make decisions about what activities will produce the most benefit .

in some cases , we observed that agencies like faa delayed conducting any planned reviews for an extended period because they reported that they did not have the resources to conduct them .

given the trade - offs that agencies face , it makes sense to consider the appropriate mix of mandatory and discretionary reviews , and other mission - critical activities , that agencies can and should conduct .

more specifically , our findings and analysis suggest that it may be useful to revisit the scope and timing of some review requirements to see whether there are opportunities to consolidate multiple requirements to enhance their usefulness and make them more cost effective and easier to implement .

if the current state of review requirements remains unchanged , agencies may continue to expend their limited time and resources on conducting pro forma reviews that appear to produce less useful results .

further , agencies may also continue to produce less useful results for reviews that they rush to complete , as identified by epa and fcc officials who reported that their annual and / or biannual review requirements do not provide enough time for them to most effectively complete their reviews and / or observe new changes before starting a subsequent review .

while we believe that employing the lessons learned by agencies may improve the effectiveness of their retrospective reviews , we acknowledge that the review of regulations is only one of the tools that agencies will need to fully understand the implications of their regulatory activities .

in order to fully assess the performance of regulatory activities , agencies will need to consider the performance of the programs that implement their regulations and the statutes that underlie the regulations .

considering any of these elements in isolation will provide an incomplete picture of the impact of regulations on the public .

however , neglecting any of these elements will have the same effect .

in order to ensure that agencies conduct effective and transparent reviews , we recommend that both the director of the office of management and budget , through the administrator of the office of information and regulatory affairs , and the chief counsel for advocacy take the following seven actions .

specifically , we recommend that they develop guidance to regulatory agencies to consider or incorporate into their policies , procedures , or agency guidance documents that govern regulatory review activities the following elements , where appropriate: 1 .

consideration , during the promulgation of certain new rules , of whether and how they will measure the performance of the regulation , including how and when they will collect , analyze , and report the data needed to conduct a retrospective review .

such rules may include significant rules , regulations that the agencies know will be subject to mandatory review requirements , and any other regulations for which the agency believes retrospective reviews may be appropriate .

2 .

prioritization of review activities based upon defined selection criteria .

these criteria could take into account factors such as the impact of the rule ; the length of time since its last review ; whether changes to technology , science , or the market have affected the rule ; and whether the agency has received substantial feedback regarding improvements to the rule , among other factors relevant to the particular mission of the agency .

3 .

specific review factors to be applied to the conduct of agencies' analyses that include , but are not limited to , public input to regulatory review decisions .

4 .

minimum standards for documenting and reporting all completed review results .

for reviews that included analysis , these minimal standards should include making the analysis publicly available .

5 .

mechanisms to assess their current means of communicating review results to the public and identify steps that could improve this communication .

such steps could include considering whether the agency could make better use of its agency web site to communicate reviews and results , establishing an e - mail listserve that alerts interested parties about regulatory reviews and their results , or using other web - based technologies ( such as web forums ) to solicit input from stakeholders across the country .

6 .

steps to promote sustained management attention and support to help ensure progress in institutionalizing agency regulatory review initiatives .

we further recommend that , in light of overlapping and duplicative review factors in statutorily mandated reviews and the difficulties identified by agencies in their ability to conduct useful reviews with predetermined time frames , the administrator of oira and chief counsel for advocacy take the following step .

7 .

work with regulatory agencies to identify opportunities for congress to revise the timing and scope of existing regulatory review requirements and / or consolidate existing requirements .

in order to facilitate agencies' conduct of effective and transparent reviews , while maximizing their limited time and resources , congress may wish to consider authorizing a pilot program with selected agencies that would allow the agencies to satisfy various retrospective review requirements with similar review factors that apply to the same regulations by conducting one review that is reported to all of the appropriate relevant parties and oversight bodies .

we provided a draft of this report to the secretary of agriculture , the attorney general , the secretary of labor , the secretary of transportation , the administrator of epa , the administrator of sba , the acting chairman of cpsc , the chairman of fcc , the chairman of fdic , the director of omb , and the chief counsel for advocacy for their review and comment .

we received formal comments from the sba office of advocacy ; they concurred with the recommendations and , as an attachment , provided a copy of draft guidance that they developed in response to our recommendations ( see app .

xii ) .

the office of advocacy also suggested that it would be more appropriate to direct the recommendations to the chief counsel of advocacy rather than the administrator of sba .

because the chief counsel of advocacy is the official who would need to act upon these recommendations , we made the change .

omb told us that they reviewed our draft report and had no comments .

all other agencies provided technical and editorial comments , which we incorporated as appropriate .

in its technical comments , dot suggested that we expand the recommendation for agencies to identify opportunities for congress to examine the timing and scope of existing requirements and / or consolidate existing requirements , to include executive agency mandated reviews .

however , the focus of the recommendation is on statutory requirements because they tended to have recurring and / or predetermined review schedules .

therefore , we did not expand the recommendation .

as we agreed with your office , unless you publicly announce the contents of this report earlier , we plan no further distribution of it until 30 days from the date of this letter .

we will then send copies of this report to interested congressional committees , the secretary of agriculture , the attorney general , the secretary of labor , the secretary of transportation , the administrator of epa , the administrator of sba , the acting chairman of cpsc , the chairman of fcc , the chairman of fdic , the director of omb , the administrator of oira , and the chief counsel for advocacy .

copies of this report will also be available at no charge on our web site at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-6806 or sciremj@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix xiii .

to provide insights concerning how agencies assess existing regulations , congressional requesters asked us to examine agencies' implementation of retrospective regulatory reviews and the results of such reviews .

accordingly , for selected agencies , we are reporting on: 1. the magnitude of retrospective review activity and type of retrospective reviews agencies completed from calendar year 2001 through 2006 , including the frequency , impetus ( mandatory or discretionary ) , and purposes of the reviews ; 2. the processes and standards that guide agencies' planning , conduct , and reporting on reviews , and the strengths and limitations of the various review processes and requirements ; 3. the outcomes of reviews , including the perceived usefulness of the reviews and how they affected subsequent regulatory activities ; and 4. the factors that appear to help or impede agencies in conducting or using retrospective reviews , including which methods , if any , that agencies and we identified as most cost - effective for conducting reviews .

for purposes of this report , we generally use the term retrospective reviews to mean any assessment of an existing regulation , primarily for purposes of determining whether ( 1 ) the expected outcomes of the regulation have been achieved ; ( 2 ) the agency should retain , amend , or rescind the regulation ; and / or ( 3 ) the actual benefits and costs of the implemented regulation correspond with estimates prepared at the time the regulation was issued .

we defined mandatory reviews as retrospective reviews that agencies conducted in response to requirements in statutes , executive orders , or executive branch directives .

we defined discretionary reviews as reviews that agencies undertook based upon their own initiative .

for calendar years 2001 through 2006 , we assessed the retrospective review activities of nine agencies and their relevant subagencies .

the nine agencies included the departments of agriculture , justice , labor , and transportation ; consumer product safety commission ( cpsc ) ; environmental protection agency ( epa ) ; federal communications commission ( fcc ) ; federal deposit insurance corporation ( fdic ) ; and the small business administration ( sba ) .

the subagencies covered in detail by our review included usda's animal and plant health inspection service , agricultural marketing service , and food safety and inspection service ; department of justice's bureau of alcohol , tobacco , firearms , and explosives ; department of labor's employee benefits security administration , occupational safety and health administration , mine safety and health administration , and employment and training administration ; and the department of transportation's federal aviation administration and national highway traffic safety administration .

we selected these agencies because they include cabinet departments , independent agencies , and independent regulatory agencies covering a wide variety of regulatory activities in areas such as health , safety , environmental , financial , and economic regulation .

further , we selected these agencies because they were actively conducting regulatory reviews or were responsible for responding to multiple review requirements .

we were not able to assess the activities of all regulatory agencies , due to time and resource constraints , but given the diversity and volume of federal regulation conducted by the nine selected agencies , we believe that the results of our assessment should provide a reasonable characterization of the variety of retrospective regulatory reviews and the issues associated with their implementation .

gao's federal rules database , which is used to compile information on all final rules , showed that the nine agencies accounted for almost 60 percent of all final regulations published from 2001 through 2006 .

however , the volume and distribution of reviews covered in this report are not generalizable to all regulatory reviews governmentwide .

to supplement our assessment of these agencies' activities , we also solicited the perspectives of regulatory oversight entities and nonfederal parties knowledgeable about regulatory issues , such as the office of information and regulatory affairs within the office of management and budget , the office of advocacy within sba , and 11 nonfederal parties that represented a variety of sectors ( academia , business , public advocacy , and state government ) .

to address our first objective , we interviewed and obtained documentation from agency officials as well as other knowledgeable regulatory parties on agency retrospective reviews .

we administered and collected responses to a structured data collection instrument that solicited information on agencies' retrospective review activities and lessons learned .

we supplemented this data collection by obtaining information from the federal register , unified agenda , and published dockets and agency reports .

we used information obtained to describe the “types” of reviews that agencies conducted — in terms of impetus ( mandatory or discretionary ) and purpose ( for example , burden reduction or effectiveness ) .

we compared agency review activities in terms of impetus and purpose because important differences can be seen in the processes used , outcomes derived , and lessons learned , based upon these characteristics , which we further analyze in objectives two through four .

although we note that reviews can be described and compared using other characteristics , such as policy area assessed in the review ( such as health , safety , or economic ) or type of analyses conducted ( such as economic benefit - cost analysis , other quantitative , and qualitative ) , we believe our selection of characteristics in describing the types of reviews conducted was most useful and relevant for addressing our objectives .

to address our second objective , we interviewed and obtained documentation from agency officials as well as other knowledgeable regulatory parties on agency retrospective reviews .

we collected responses to the aforementioned structured data collection instrument that solicited information on agencies' retrospective review activities and lessons learned .

we supplemented this data collection by obtaining information from the federal register , unified agenda , and published dockets and agency reports .

we also reviewed agency policies , executive orders , and statutory requirements to identify policies and procedures that guide the planning , conduct , and reporting of agencies' reviews .

further , to identify the strengths and limitations of agency review processes , we assessed agencies' use of three review and economic practices and standards that are important to the effectiveness and transparency of agency reviews , including the ( 1 ) use of a standards - based approach , ( 2 ) incorporation of public involvement , and ( 3 ) documentation of review processes and results .

in prior work , we identified some overall strengths or benefits associated with regulatory process initiatives , including: increasing expectations regarding the analytical support for proposed rules , encouraging and facilitating greater public participation in rulemaking , and improving the transparency of the rulemaking process .

because these strengths or benefits are also relevant and useful for assessing agency retrospective review initiatives , we considered them in our selection of assessment criteria for this review .

other practices that could improve the effectiveness and transparency of reviews may exist and could be considered when developing retrospective review processes .

however , we believe that the three practices that we assessed are among the most important .

while we did not assess whether agencies employed these practices all the time , to the extent possible we did seek documentation and evidence that they were applied .

further , while we assessed whether agencies employed standards - based approaches in their retrospective review processes — within the scope of our review — we did not attempt to assess the quality of such standards .

we compared the strengths and limitations of review processes across agencies , types of reviews , and phases of the review process .

in our more detailed assessment of a limited sample of retrospective reviews completed between 2001 and 2006 , we also evaluated the use of research and economic practices and standards .

the sample that we assessed was too small to generalize to all agency retrospective reviews , but this assessment illustrated some of the strengths and limitations that exist in the agencies we reviewed .

to address the third objective , we interviewed and obtained documentation from agency officials and collected responses on the usefulness of various types of retrospective reviews using the structured data collection instrument identified in objective one .

to obtain the perspectives of nonfederal parties on the usefulness of agency reviews , we identified and interviewed 11 parties that represent a variety of sectors ( academic , business , public , advocacy , and state government ) and points of view .

the parties were selected based on their contributions to prior gao work on regulatory issues and our assessment of their recent publications on regulatory issues .

the opinions expressed by agency officials and these nonfederal parties may be subjective and may not capture the views of all regulatory agencies , experts , and stakeholders on the usefulness of reviews .

however , we believe that our selection represents a reasonable range of knowledgeable perspectives on retrospective reviews .

we supplemented our data collection on the outcomes of agency reviews by reviewing the federal register , unified agenda , and published dockets and reports .

for mandatory and discretionary reviews , we identified the reported results of reviews , including whether the review prompted any change to existing regulations .

we also synthesized and described the usefulness of different types of reviews , as determined by agency officials and nonfederal parties knowledgeable about regulatory issues .

to address the fourth objective , we interviewed and obtained documentation from agency officials , collected responses to a structured data collection instrument , and reviewed existing research on agency regulatory review initiatives .

further , we solicited perspectives of the selected oversight and nonfederal parties on the facilitating factors and barriers to the usefulness of agency reviews .

based on our analysis of agency responses and documentation , we described the lessons learned from the different agencies , and the views of oversight and nonfederal parties on facilitating and impeding practices .

to supplement the lessons identified and to identify the most prevalent and / or critical facilitators or barriers for the conduct and usefulness of reviews , as well as options to overcome any barriers identified , we hosted a joint agency exit conference .

during this joint exit conference , we discussed the collective responses of agencies and nonfederal parties , and similarities and differences in experiences and views .

we had general consensus among federal agencies on the points discussed during this exit conference and report on areas where there was not consensus in agency and nonfederal parties' views .

we conducted our work from may 2006 through april 2007 in accordance with generally accepted government auditing standards .

the three department of agriculture ( usda ) agencies examined in this study actively reviewed their existing regulations under both mandatory and discretionary authorities .

the animal and plant health inspection service ( aphis ) , the agricultural marketing service ( ams ) , and the food safety and inspection service ( fsis ) conducted reviews to reduce burden on small entities under section 610 .

usda conducted discretionary reviews to respond to industry petitions or informal feedback , to meet recommendations from committees , to address new risks in regulated environments , or to update rules due to advances in technology or scientific knowledge .

the agencies use both centralized and decentralized review processes that rely on the input of outside parties to inform their reviews .

the three usda agencies examined in this study actively reviewed their existing regulations under both mandatory and discretionary authorities , with reviews conducted at their own discretion more common than mandated reviews .

for example , during the 2001 through 2006 period covered in our review , aphis reported conducting 18 section 610 reviews and completing rulemakings for 9 , with 8 others currently in progress .

aphis also reported that since 2001 , it has completed a total of 139 regulatory reviews , which resulted in 139 rule modifications across 12 broad content areas .

ams officials reported initiating 19 and completing 11 section 610 reviews since 2001 .

however , ams also reported that it has issued approximately 300 modifications to 30 regulations based on interaction with industry committees between fiscal years 2002 and 2006 .

in addition , ams also reported that since 2001 , the agency has conducted 18 independent assessments of its commodity promotion programs , as required of ams under 7 u.s.c .

§ 7401 .

fsis reported initiating 1 section 610 review since 2001 ; however during the same time period , the agency has conducted 36 reviews of its rules as a result of industry petitions .

the agencies' officials reported that discretionary reviews more often resulted in regulatory changes .

our analysis of the december 2006 unified agenda confirmed that most modifications to the department's regulations were attributed to reasons under usda's own discretion rather than because of mandates .

of the 132 rule changes listed in the unified agenda , 113 resulted from decisions made at agency discretion while 19 of those changes were the result of mandated actions .

the processes employed for review varied by agency , with ams program offices conducting reviews of their own regulations , aphis program offices conducting reviews in concert with centralized offices within the agency , and centralized offices within the agency conducting fsis reviews .

however , all three agencies relied on the input of regulated communities to inform their processes .

as an example of a centralized approach: aphis' technical and policy program staff work with the agency's policy and program development ( ppd ) unit to conduct reviews , and ppd works with the deputy administrators for each regulatory program to set regulatory priorities .

the program staff that oversees the regulation , on the other hand , conducts ams reviews , in - house .

all three agencies reported that they rely on outside parties to inform their review process .

for example , ams reported that the agency conducts periodic referenda of regulated growers of fruit and vegetables to amend agency marketing orders and to identify programs for discontinuance .

aphis reported that its review decisions are influenced by ongoing discussions with industry , state and tribal authorities , and foreign governments regarding setting international trade standards .

aphis also reported that it has acted on recommendations made by outside reviews of its programs conducted by the national plant board and the national association of state departments of agriculture .

fsis reported that it holds industry listening sessions and public meeting to inform its rulemaking and affect the day - to - day implementation of regulations .

figure 5 depicts usda's general process for regulatory review .

while the department of justice ( doj ) is not primarily a regulatory agency , during the 2001 through 2006 period covered in our review , doj component agencies have conducted reviews of their existing regulations under both mandatory review requirements and under their own discretionary authorities .

most doj reviews were discretionary and in response to such drivers as changes in technology or feedback back from regulated entities , among other factors .

the three mandatory reviews conducted by doj since 2001 were driven by separate statutory requirements to review regulations or set enforceable standards for others to follow .

while doj has few formal processes or standards to guide the planning , conduct , and reporting of its internally conducted discretionary reviews , in the conduct of the one section 610 review conducted by doj and evaluated by gao , statutory standards were followed .

doj is not primarily a regulatory agency and officials reported that most of its primary activities , including antiterrorism , investigation , and law enforcement do not involve the department's regulatory process .

officials reported that few of the department's regulations are subject to section 610 review , and one official reported that regulatory review , as a whole , is not a major priority within the agency , compared to its other functions .

however , since 2001 doj agencies reported completing at least 13 reviews of existing regulations .

based on published documents in the federal register or unified agenda , 10 of these reviews were conducted under doj's own discretion , while 3 reviews were in response to mandatory review requirements or to comply with statutory requirements to revise regulations .

the drivers for the discretionary reviews conducted by doj included responding to changes in technology or feedback from regulated entities , among other factors .

for example , fbi officials reported that the bureau has reviewed and is revising a rule preventing the fbi from retaining or exchanging the fingerprints and criminal history record information of nonserious offenses in the fbi's fingerprint identification records system .

according to the proposed rule change resulting from this review , the existing regulations were originally implemented in 1974 and based on the data - processing capabilities of a manual record - keeping environment .

officials reported that advances in information technology precipitated a review of these regulations , which once revised , will enhance the fbi's search capability for fingerprint and criminal history background checks .

doj also cited feedback from regulated entities as an important driver of discretionary reviews .

dea , for example , reported that the controlled substance manufacturer and distributor industries requested that dea provide an electronic method to satisfy the legal requirements for ordering schedule i and ii controlled substances , which previously could only be ordered through a triplicate form issued by dea .

according to officials , dea reviewed its regulations and worked with industry to develop a pilot program to update its system .

after notice - and - comment rulemaking , dea published a final rule revising its regulations on april 1 , 2005 .

in addition to these reviews , atf conducted five discretionary reviews since 2001 , including a reorganization of title 27 in the transition of atf functions from the department of the treasury to doj after the creation of the department of homeland security .

additionally , ojp conducted two discretionary reviews since 2001 and the bop reported that it conducts annual , ongoing reviews of its policy statements , many of which correspond with its regulations in the cfr , to ensure that they are current .

gao was able to identify three mandatory regulatory reviews completed by doj since 2001 , and the impetuses for these reviews varied .

for example , atf in 1997 initiated a section 610 review evaluating the impact of changes to its fireworks storage and record - keeping requirements on small entities .

this review , concluded in a january 29 , 2003 , federal register notice , certified that the revised rule will have a minimal economic impact on the explosives industry , and will no longer have a significant economic impact on a substantial number of small entities .

the review also identified other areas of concern to the public , precipitating further actions .

crt conducted a review pursuant to executive order 12250 , which requires the attorney general to establish and implement a schedule for the review of executive branch agencies' regulations implementing various federal nondiscrimination laws , including the civil rights act of 1964 , among others .

according to officials , this “cureton review project” included an evaluation of the regulations of 23 agencies , including doj , which resulted in clarified statutory language to promote consistent compliance with the various nondiscrimination statutes .

in a third review , crt published an advanced notice of proposed rulemaking ( anprm ) to update regulations implementing title ii and title iii of the americans with disabilities act of 1990 ( ada ) , including the ada standards for accessible design .

according to the anprm , the ada requires doj to adopt accessibility standards that are ‘‘consistent with the minimum guidelines and requirements issued by the architectural and transportation barriers compliance board,” which were revised in july 2004 .

doj has also reported that it may conduct a regulatory impact analysis on the revised ada standards , including a benefit - cost analysis pursuant to executive order 12866 , omb circular a – 4 , and the regulatory flexibility act .

department officials stated that much of doj's regulatory review process was “informally” structured , and without formal procedures and standards .

professional judgment , officials stated , was used in some cases in lieu of documented practices .

however , a gao evaluation of the recent atf explosive materials in the fireworks industry review indicates that doj followed the statutorily defined process for its completion .

as required by section 610 , the review must describe ( a ) the continued need for the rule ; ( b ) the nature of complaints or comments received concerning the rule from the public ; ( c ) the complexity of the rule ; ( d ) the extent to which the rule overlaps , duplicates , or conflicts with other federal rules and , to the extent feasible , with state and local governmental rules ; and ( e ) the length of time since the rule has been evaluated or the degree to which technology , economic conditions , or other factors have changed in the area affected by the rule .

gao's evaluation of this proceeding concluded that atf addressed the requirements for responding to public comments , complaints , and the rule's complexity .

atf's analysis was primarily in response to public comments and a review of its own experience implementing the rule .

in a few cases , atf responded to comments by referencing published experts' opinions and scientific tests .

however , atf provided no overall analysis of the cost of these storage regulations or of their effectiveness in promoting public safety , or law enforcement's ability to trace fireworks to their manufacturer — a specific desired outcome referred to in the notice .

figure 6 depicts the general process for regulatory review in one atf section 610 review .

during the 2001 through 2006 period covered in our review , agencies within the department of labor ( dol ) have actively reviewed their existing regulations in response to both mandatory and discretionary drivers .

specifically , the employee benefits security administration ( ebsa ) , occupational safety and health administration ( osha ) , mine safety and health administration ( msha ) , and employment and training administration ( eta ) have conducted various retrospective reviews of their regulations .

the types of reviews — in terms of impetus and purpose — outcomes of reviews and processes used to conduct the reviews varied among the agencies .

specifically , while ebsa has established a formal and documented regulatory review program , osha , msha , and eta have somewhat less formal review programs , but msha and eta were in the process of developing more standardized processes .

furthermore , while all of the agencies reported that their discretionary reviews more often resulted in subsequent regulatory action , the outcomes of mandatory reviews varied slightly among the agencies .

all of the dol agencies within our review reported actively conducting reviews of their regulations .

however , the types of reviews — in terms of impetus and purpose — and outcomes of reviews varied slightly among the agencies .

all of the dol agencies reported that they conducted ongoing reviews of their regulations , at their own discretion .

however , two of the agencies — osha and ebsa — also incorporated requirements from mandatory reviews into these discretionary reviews .

furthermore , ebsa conducts its discretionary reviews more formally as part of its regulatory review program .

according to documentation that we reviewed on this program , ebsa formally conducted reviews of its existing regulations in response to specific developments and / or changes in the administration of group health , pension , or other employee benefit programs , changes in technology and industries , and legislation .

ebsa also reviewed regulations in response to identified enforcement problems or the need to further the agency's compliance assistance efforts through improved guidance .

furthermore , the review program incorporates section 610 reviews as part of the program .

while osha did not have a program that was as formalized and documented as ebsa , the officials reported and our review of their analyses confirmed that the agency also incorporated section 610 criteria into broader review initiatives that the agency undertook to address informal feedback from industry , stakeholders , and staff .

msha and eta also reported initiating reviews in response to either stakeholder input , technology or policy updates , petitions , or internal identification of needed rule changes .

however , the agencies' officials reported that they have not conducted any section 610 reviews ( which focus on burden reduction ) during the period covered in our review because they have not had any regulations within the last 10 years that had a seisnose effect .

outcomes of reviews varied slightly among the agencies .

while it was not possible to account for all of the reviews conducted by all of the agencies because the agencies did not document some informal reviews , collectively the agencies reported completing at least 60 reviews since 2001 .

according to ebsa documentation , the agency completed at least 7 of its 13 formal retrospective reviews , including 4 section 610 reviews .

all of the discretionary reviews resulted in subsequent regulatory changes , including changes to the regulation , guidance , or related materials .

none of ebsa's section 610 reviews resulted in regulatory changes .

osha completed 4 reviews in response to both discretionary and section 610 requirements which resulted in regulatory changes or changes to guidance documents or related materials .

according to osha documentation , 2 of their completed section 610 reviews and 2 of their standards improvement project reviews recommended regulatory changes , including clarifications to standards or additional outreach or compliance assistance materials .

msha officials reported engaging in a 2004 msha strategic initiative review ( a review of all title 30 cfr regulations ) and a review conducted according to an msha initiative to improve and eliminate regulations that were frequently the subject of petitions for modification .

both of these reviews resulted in changes to regulations .

eta officials reported that , in 2002 , the agency conducted a regulatory cleanup initiative that resulted in updates to individual regulations and that eta has updated individual regulations when the agency's program offices identified a need to do so through their course of business .

the agencies also reported making regulatory changes based upon departmentwide regulatory cleanup initiatives in 2002 , and 2005 / 2006 , which the department's office of the assistant secretary for policy spearheaded .

additionally , the department completed 42 reviews in response to office of management and budget ( omb ) regulatory reform nominations from 2001 to 2004 , which resulted in subsequent regulatory action .

the development of review processes for dol agencies ranged from processes that were documented and formal with established review structures and procedures , to informal undocumented review processes with structures and procedures that were still developing .

for example , ebsa established a formal review program that established a formal structure for reviews , including identification of what resources ( staff ) would be involved , criteria that the agency would use to select and assess regulations , and the method for reporting results .

while osha did not have a documented formal review program , the agency described a somewhat formal structure that it uses to conduct its reviews .

similarly , eta officials reported that they just recently established a more formal structure for their review process , including the creation of a regulations unit that will coordinate the development of regulations for eta legislative responsibilities and formalize regulatory procedures within the agency .

according to the officials , the regulations unit will establish time frames and / or internal triggers for reviews to ensure the agency properly reviews and updates regulations .

however , they noted that , given the recent establishment of this unit , it might take some time to implement these procedures .

msha did not appear to have a documented formal review process or structure for its discretionary and mandatory reviews .

however , the agency reported that it had been engaged in soliciting contractors to develop a more formal process for how to prioritize what regulations that agency would review .

figures 7 and 8 illustrate an example of the variation in the agencies' review processes .

to facilitate sharing practices , in appendix xi we provide a more detailed description of practices within ebsa's review process , which was the most formalized and documented review process that we examined within the scope of our review .

between 2001 and 2006 , department of transportation ( dot ) agencies within the scope of our evaluation actively reviewed their existing regulations under both mandatory and discretionary authorities .

the mandatory reviews conducted by dot agencies addressed governmentwide , departmentwide , and agency - specific review requirements .

dot conducted discretionary reviews in response to formal petitions and informal feedback from the public and in response to accidents or similar events and changes in specific industries , technologies , or underlying standards .

additionally , dot conducted reviews in response to office of management budget ( omb ) regulatory reform initiatives as well as a stand - alone initiative to review all rules under the department's authority .

dot has written policies and procedures guiding the planning , conduct , and reporting of reviews .

while review processes may vary somewhat within dot agencies , overall these agencies follow dot guidelines in the conduct of their reviews .

dot has conducted a number of initiatives to systematically review existing regulations to comply with federal mandates and dot's own policies and procedures for regulatory review .

in order to satisfy section 610 and other review requirements , dot initiated a 10-year plan in 1998 to systematically review some of its sections of the code of federal regulations every year , with the objective of reviewing all of its regulations over a 10-year cycle .

dot also maintains a departmentwide review requirement , instituted in 1979 , to periodically review existing regulations to determine whether they continue to meet the needs for which they originally were designed or whether reviewed rules should be revised or revoked .

more recently , in 2005 , acting under its own discretion , dot initiated and completed a special stand - alone regulatory review in which the department sought public comment on all rules and regulations under dot's authority .

dot also reviewed regulations in response to omb initiatives in 2001 , 2002 , and 2004 , which solicited nominations from the general public for federal regulations and guidance documents for reform .

the agency completed 61 reviews in response to these reform initiatives , and the department took subsequent action on 43 of the regulations it reviewed .

overall , during the 2001 through 2006 period covered in our review , dot has reported conducting over 400 reviews of existing regulations to meet governmentwide review requirements , including those under executive order 12866 on regulatory planning and review , section 610 , and the executive memorandum of june 1 , 1998 , on plain language in government writing .

in addition to reviews conducted under departmentwide requirements , various agencies within dot have reviewed regulations within the specific statutes under their purview .

for example , since 2001 faa has reviewed three regulations pursuant to requirements in the federal aviation reauthorization act of 1996 .

according to agency officials , these reviews included post implementation cost - benefit assessments of three , high - cost faa rules .

fmcsa reported that it also reviews any regulation impacted by the motor carrier act of 1980 ; the motor carrier safety improvement act ; and the safe , accountable , flexible , efficient transportation equity act: a legacy for users ( safetea - lu ) .

although not within the time frame for this study , fta announced in the december 2006 unified agenda that it will undertake a review of its regulations to bring them into conformity with the safetea - lu statute .

in addition to these more formal regulatory review efforts , dot officials reported that the department also reviews its existing regulations at its own discretion as a function of its daily , ongoing activities .

according to officials , such reviews are often the result of petitions from or consultations with parties affected by dot regulations or based on the experience of agency staff members in light of changes in specific industries , technologies , or underlying standards .

dot officials said that , for some of their agencies , reviewing petitions for rulemaking or regulatory waivers is the most productive way to obtain public input on a review of that rule .

an evaluation of nhtsa's entries in dot's december 2005 unified agenda indicated 10 rule change proceedings in various stages of completion which were the result of petitions from regulatory stakeholders .

nhtsa also reported that , since 2001 , it has conducted 17 reviews of federal motor vehicle safety standards ( fmvss ) , including a few studies evaluating the benefits and costs of various standards .

phmsa reported that the granting of numerous waivers of a regulation is a particular signal that new technology or conditions may render that regulation obsolete or in need of amendment .

dot has written policies and procedures guiding the planning , conduct , and reporting of reviews .

while the processes employed by dot agencies may vary somewhat , overall these agencies follow dot guidelines in the conduct of their reviews .

for example , dot's policies and procedures provide guidance for prioritizing regulations for review , including the extent of complaints or suggestions received from the public ; the degree to which technology or economic factors have changed ; and the length of time since the regulations were last reviewed , among other factors .

dot's procedures also provide agencies with discretion in applying the procedures .

for example , nhtsa reported that it gives highest priority to the regulations with the highest costs , potential benefits , and public interest , while phmsa reported that it gives highest priority to initiatives it deems most likely to reduce risk and improve safety .

additionally , while dot officials reported that dot considers omb circular a - 4 on “regulatory analysis” as a guide for cost / benefit analysis of regulatory outcomes , faa reported that it uses a set of flexible procedures recommended by an outside consultant to conduct ex post evaluations of some rules .

with regard to public participation in the review process , appendix d to the department's unified agenda announces the complete schedule for all reviews , requests public comments for reviews in progress , and reports the results of completed reviews and their results .

dot agencies also pointed out that they regularly interact with stakeholders , such as regulated industries , consumers , and other interested parties to obtain feedback on regulations .

for example , faa officials stated that the agency holds conferences with industry and consumer groups to identify regulatory issues for review .

in terms of the reporting of review results , dot publishes brief summaries of completed reviews in appendix d of its unified agenda .

however , agencies may report review results in other ways .

for example , fmcsa documents the results of its section 610 reviews in an annual internal report , while nhtsa publishes the technical reports of its reviews in the federal register , requesting public comments on its determinations .

figure 9 depicts dot's general process for regulatory review .

since 2001 , the consumer product safety commission ( cpsc or the commission ) systematically reviewed its regulations under its own discretion , but has not conducted any mandatory reviews because none of its rules triggered section 610 or other mandatory review requirements .

moreover , agency officials noted that because of its reliance on voluntary consensus standards , the agency does not promulgate as many rules as other regulatory agencies .

however , the primary purpose of cpsc discretionary reviews is to assess whether the regulations that cpsc promulgates remain consistent with the objectives of the commission .

in performing its reviews , cpsc has created systematic processes for the planning , conduct , and reporting of its reviews .

through this process , the commission prospectively budgets for its reviews .

because cpsc's review program is so new , the agency has not completed most of the reviews that it has initiated , but the commission has proposed changes to at least two existing regulations .

in addition , the officials reported that their review program has been useful to the commission .

cpsc actively conducted reviews of its existing regulations under its own discretion .

specifically , the commission implemented a pilot review program in 2004 , with annual follow - up efforts in 2005 and 2006 , which resulted in the initiation of 14 retrospective reviews .

cpsc initiated this review process partly because of an office of management and budget ( omb ) program assessment rating tool ( part ) recommendation that the agency develop a plan to systematically review its current regulations to ensure consistency among them in accomplishing program goals .

the primary purpose of cpsc reviews is to assess the degree to which the regulations under review remain consistent with the commission's program policies and program goals .

cpsc also assesses whether it can streamline regulations to minimize regulatory burdens , especially on small entities .

the officials reported that their review process is so new that they have not yet fully completed it for all of the reviews that they have initiated .

however , they have completed at least 3 of their 14 initiated reviews .

officials reported that , while some of the regulations they reviewed did not need a revision , they have proposed regulatory changes for two regulations , including standards for flammability of clothing textiles and surface flammability of carpets and rugs .

they reported that their reviews could focus on opportunities to either expand or streamline existing regulations .

thus , their reviews could lead to increases or decreases in the scope of cpsc regulations .

as examples , cpsc officials reported that during their review of their existing bicycle regulation they identified that the regulation did not reflect new technology and materials , and therefore needed to be modified and updated .

conversely , their review of their cigarette lighter rule revealed that the agency needed to promote greater compliance and more effective enforcement , which increased the agency's regulatory oversight .

table 8 provides additional detail on the cpsc retrospective reviews .

cpsc established a formal review program that prospectively budgets for the substantive reviews that the agency will conduct .

officials reported that they have conducted about four substantive reviews per year using this process , while still managing other agency priorities .

the process consists of three phases , including: ( 1 ) prioritization and selection of regulations to substantively review , ( 2 ) substantive review of the selected regulations , and ( 3 ) reporting results to the commissioners and the public , for certain reviews .

as part of this process , cpsc staff prioritize which regulations need review by considering: ( 1 ) which rules have the oldest effective dates , ( 2 ) which rules were adopted under various statutes under cpsc's authority , and ( 3 ) which rules staff identified as good candidates for change ( from their experience working with the regulation ) .

as resources allow , the agency selects one substantive regulation from each of their statutes' areas ( with the exception of the refrigerator safety act ) , starting with their earliest regulations .

as part of this prioritization process , the agency considers input from cpsc's technical staff and outside groups .

cpsc staff initiates substantive review of regulations that the commission chooses for review .

in this process , the agency solicits public comments using the federal register , assesses the comments received , conducts an internal technical review of the regulation , and reports the results to the commissioners .

the commissioners make a policy decision on actions the agency will take based upon staff recommendations .

if the agency decides to conduct a follow - on activity to update a rule , it subsequently notifies the public via the federal register .

for rule reviews that result in commission - approved projects for certain rulemaking activities ( such as developing revisions to a rule for commission consideration ) , cpsc makes the briefing packages available on its web site .

other rule reviews ( such as reviews for which staff suggests no action ) are given to the commissioners , but are not posted on the web site .

figure 10 illustrates the general review process .

during the 2001 through 2006 period covered in our review , program offices within environmental protection agency ( epa ) have conducted numerous retrospective reviews of epa existing regulations and standards .

the mix of reviews conducted by epa — in terms of authorities — varied across the agency , but the purposes of these reviews — effectiveness , efficiency , and burden reduction — were similar across the agency .

epa's retrospective review results provided three distinctive outcomes .

while the agency conducts many reviews under its mandates , reviews conducted on its own discretion yielded more changes to existing regulations than mandated reviews .

the review processes within epa's program offices , though different , typically shared similar elements in the planning , conduct , and reporting of results .

overall , epa reported that its retrospective reviews have proven to be useful to the agency .

the office of air and radiation ( oar ) , the office of prevention , pesticides , and toxic substance ( oppts ) , the office of solid waste and emergency response ( oswer ) , and the office of water within epa each conduct mandatory retrospective reviews under their guiding statutes and focus the reviews on what is stated in statute or developed by the agency .

thus , the frequency of mandated reviews varies within epa as well as the program offices .

for instance , the frequency of reviews required by the safe drinking water act ( sdwa ) , conducted by the office of water , ranges from every 3 years to every 7 years , depending on the review requirement , while the oar is required to conduct reviews by the clean air act ranging from every 3 years to every 8 years .

mandated reviews , such as those required by agency - specific statutes , mainly focused on effectiveness , while section 610 reviews and office of management and budget ( omb ) regulatory reform nominations were focused on burden reduction .

according to epa officials , mandatory retrospective reviews have generally resulted in limited or no changes to regulations , while reviews conducted under discretionary authority usually resulted in more changes .

for instance , of the 14 section 610 reviews conducted by the program offices since 2001 , only 1 resulted in change .

moreover , oar noted that most of its reviews validated the need for the regulation or standard .

however , epa's review of regulations in response to omb's manufacturing regulatory reform initiative resulted in 19 regulatory changes and 19 nonregulatory actions , including the development of regulatory guidance and reports .

in addition , gao's review of epa's december 2006 unified agenda entries also revealed that 63 out of 64 rules identified as changed or proposed for changes were the result of decisions made under epa's discretionary authority .

though the use of discretionary authority produced more rules changes , officials reported that retrospective reviews , in general , were valuable in ( 1 ) determining whether new information exists which indicates the need for revisions and ( 2 ) enabling the agency to gain new insights about its analytical methods .

in addition , officials noted that retrospective reviews were useful in determining whether the rule was working as intended and helping to achieve the agency's or statute's goals .

epa's review process varied by program office and by review requirement ; however , most mandatory and discretionary reviews contained consistent elements .

the four epa program offices included in our review perform various functions of the agency that rarely overlap into other program offices duties .

for example , oar exclusively oversees the air and radiation protection activities of the agency , while the office of water solely manages the agency's water quality activities .

these two offices have different guiding statutes that require them to conduct reviews and , within those statutes , processes are sometimes outlined for how the agency should conduct the reviews .

therefore , the processes for these program offices varied .

however , three elements were similar across the offices: these included formal or informal notification of the public ; involvement of the public in the conduct of the review mainly through the request of public comments , science , risk , or policy assessments of the regulation ; and release of the results to the public primarily through the federal register and the epa web site .

in addition , mandatory and discretionary regulatory reviews that were high profile in nature ( eg , because they were conducted in response to emergencies , were contentious , or received heavy attention from the public , congress , or regulatory experts ) had the aforementioned elements as well as high - level management attention from the assistant administrator of the program office or the epa administrator .

for example , the review processes of the mandatory national ambient air quality standards and the lead and copper review , which was initiated after elevated levels of lead were found in the district of columbia , were defined , documented , and included extensive public involvement and high - level management attention .

figure 11 illustrates the general review process for the different review drivers .

the federal communications commission ( fcc or the commission ) actively reviews its existing regulations to meet congressionally mandated review requirements , and to respond to petitions from regulated entities and changes in technology and market conditions , under its own discretionary authority .

while fcc's retrospective review processes vary depending on the review requirement the agency is addressing , fcc's biennial and quadrennial review processes provide opportunities for public participation and transparency .

according to fcc officials , the frequency of the biennial review requirement presents staffing challenges to the agency , while the 10-year requirement for the section 610 review presents a challenge to the usefulness of this review , as regulations may have been previously modified under other requirements prior to the review .

fcc actively reviews its existing regulations to meet congressionally mandated review requirements and to respond to petitions from regulated entities and changes in technology and market conditions under its own discretionary authority .

under the communications act , as amended , the commission is subject to two agency - specific mandated reviews: ( 1 ) the biennial regulatory review of fcc telecommunications rules , and ( 2 ) the quadrennial regulatory review of the broadcast and media ownership rules .

fcc officials reported that these reviews are guided by the deregulatory tenor of the telecommunications act , which instructed the commission to promote competition and reduce regulation in the telecommunications and broadcast industries .

the purpose of these reviews is to identify rules no longer necessary in the public interest so that they may be modified or repealed .

in the 2002 biennial review , the commission conducted and reported 89 separate review analyses of its telecommunications regulations and made more than 35 recommendations to open proceedings to consider modifying or eliminating rules .

the commission is also subject to the governmentwide review requirement to minimize significant economic impact on small entities under section 610 .

fcc has initiated 3 multiyear section 610 review projects ( 1999 , 2002 , 2005 ) , plus 1 single - year review ( 2006 ) , issuing public notices listing all rules subject to section 610 review .

officials pointed out that these reviews rarely result in rulemaking proceedings and cited only one proceeding which resulted in the elimination of obsolete rules as a result of the section 610 process .

in addition to these mandatory requirements , fcc officials reported that the commission reviews existing regulations at its own discretion in response to rapid changes in technology and market conditions and to petitions from regulated entities .

a gao analysis of the december 2006 unified agenda indicated that most of fcc's proposed and final rule changes for that year were the result of decisions made under fcc's discretionary authority .

of the 39 rule changes listed in the unified agenda , 33 were the result of decisions made at the commission's own discretion , while 6 of those changes were the results of mandated actions .

this informal analysis indicates that , in addition to its mandatory review requirements , fcc does make efforts to review and amend regulations under its own discretion .

the rule changes from the 2002 quadrennial review never went into effect .

in 2004 , the u.s. court of appeals remanded back to fcc for further review its rules for cross - media ownership , local television multiple ownership , and local radio multiple ownership ( prometheus radio vs .

f.c.c. , 373 f.3d 372 ( 3rd cir .

2004 ) ) .

additionally , congress overturned fcc's national television ownership rule which would have allowed a broadcast network to own and operate local broadcast stations reaching 45 percent of u.s. television households .

through the consolidated appropriations act of 2004 , congress set the national television ownership limit at 39 percent ( pub .

l. no .

108-199 , 118 stat .

3 , 100 ( jan. 23 , 2004 ) ) .

transparency .

for example , in the 2002 biennial review , fcc bureaus and offices issued public notices listing rules for review under their purview and requesting comments regarding the continued necessity of rule parts under review .

the bureaus and offices published staff reports on the fcc web site summarizing public comments and making determinations as to whether the commission should open proceedings to modify or eliminate any of the reviewed rules .

the commission released notices of proposed rulemaking , seeking further public comments .

officials reported that if the commission modifies or eliminates any regulations as a result of its proceeding , that decision is announced in a rulemaking order , which is published in the federal register .

similarly , in the 2006 quadrennial review ( which was in process at the time this report was written ) the commission released a further notice of proposed rulemaking ( fnpr ) and posted a web page providing background information and hyperlinks to fcc documents relevant to the review .

the fnpr requests public comment on the media ownership rules and factual data about their impact on competition , localism , and diversity .

the commission reported that it will hold six public hearings in locations around the country and make available for public comment 10 economic studies commissioned by fcc on issues related to the media ownership rules .

despite the opportunities for public participation in these regulatory reviews , the mandated structure of some review processes presents a challenge to the usefulness of fcc reviews .

for example , according to an fcc official , the requirement to review the commission's telecommunications rules every 2 years forces bureau staff to be constantly reviewing regulations .

this official reported that the quadrennial requirement is a more appropriate time period for review , as it provides greater opportunity for regulatory changes to take hold .

additionally , an official reported that too much time between reviews can be problematic .

for example , rules that require section 610 review every 10 years may have been modified or previously reviewed as part of an overlapping review requirement or as part of a discretionary review occurring prior to the 10-year review requirement .

during the 2001 through 2006 period covered in our review , the federal deposit insurance corporation ( fdic ) , has performed numerous retrospective reviews of its existing regulations in response to mandatory authorities such as section 610 of the regulatory flexibility act and the economic growth regulatory and paperwork reduction act of 1996 ( egrpra ) and at its own discretion .

the focus of fdic's reviews has been on burden reduction , which is part of the agency's strategic goals .

the process that fdic used to plan , conduct , and report its reviews was coordinated by a larger organizational body .

the centralized review effort helped to leverage the agencies' resources and facilitate the regulatory changes recommended as a result of the egrpra reviews .

fdic , along with members of the federal financial institutions examination council ( ffiec ) has examined 131 regulations under egrpra .

fdic conducted two section 610 reviews after 2001 , but before the initiation of the egrpra reviews in 2003 .

because the egrpra review affected almost all of fdic's regulations , the agency subsequently included section 610 reviews within the egrpra review effort .

also , the agency has conducted discretionary reviews in response to petitions and external emergencies , such as natural disasters .

for instance , the agency reported reviewing its regulations to reduce burden for businesses affected by hurricane katrina .

in doing so , the agency made 8 temporary regulatory changes to ease the burden on affected entities .

fdic also made changes to 4 regulatory areas , which included changes to 3 regulations , as a result of the egrpra reviews .

additionally , gao's review of the december 2006 unified agenda , indicated fdic made changes to 5 regulations as a result of decisions under its own discretion and 4 changes as result of mandates .

fdic and the other banking agencies also worked with congressional staff regarding legislative action as a result of the egrpra reviews .

for example , the agencies reviewed over 180 legislative initiatives for burden relief in 2005 .

furthermore , the agencies testified before the senate banking committee and house financial services committee on a variety of burden reduction measures and upon request , agency representatives offered technical assistance in connection with the development of legislation to reduce burden .

congress later passed and the president signed the financial services regulatory relief act of 2006 on october 13 , 2006 .

fdic and other financial regulatory agencies that are members of the ffiec decided to use the ffiec as the coordinating body for the egrpra review process because the act affected all of the agencies and the agencies wanted to: ( 1 ) establish a centralized process for selecting , conducting , and reporting its reviews ; and ( 2 ) leverage the expertise and resources of all of the member agencies .

egrpra required the agencies to categorize their rules , solicit public comment , and publish the comments in the federal register .

the act also required the agencies to report to congress no later than 30 days after publishing the final summarized comments in the federal register .

the ffiec established additional processes for planning , conducting , and reporting of retrospective reviews conducted under egrpra outside of these specified requirements , such as providing 90 public comment periods , holding outreach meetings with regulated entities as well as consumer groups across the united states , and establishing a web site dedicated to the egrpra reviews .

within all of the processes developed by the ffiec , a high level of management attention was maintained .

for instance , the director of the office of thrift savings , who is also a member of fdic's board of directors , headed the interagency effort .

in this capacity , a political appointee was involved in planning , conducting , and reporting the reviews .

as illustrated by figure 13 , the process involved interagency coordination and review activities within each individual agency , including fdic .

during the 2001 through 2006 period covered in our review , the small business administration ( sba ) has reviewed its existing regulations in accordance with section 610 of the regulatory flexibility act and on it own discretion .

while the purpose of the section 610 reviews was to reduce burden , the purpose of every discretionary review was to increase effectiveness .

sba had written procedures to plan , conduct , and report its section 610 reviews .

however , the agency did not have written processes to guide planning , conduct , and reporting of discretionary reviews .

overall , sba's discretionary reviews have resulted more often in regulatory changes than reviews mandated by statute .

officials reported that sba has conducted discretionary reviews based on congressional interest or industry petitions .

specifically , officials from the hubzone program indicated that their office receives attention from congress about the workings of their regulations , thereby prompting them to review their existing regulations .

in addition , sba's division of size standards completed 27 reviews in response to industry petitions and congressional requests .

sba also completed 4 section 610 reviews in 2005 .

while the purpose of the section 610 reviews was to reduce burden , officials from one division in sba said that they focused many of their retrospective reviews on examining the effectiveness of their regulations by evaluating their progress on outcomes .

however , they stated that because some of their regulations are linked to the regulatory activity of other agencies , they are not always able to achieve the intended outcome of the regulation .

of the reviews conducted by sba , discretionary reviews yielded more changes to existing regulations than mandated reviews .

for instance , there were no changes made to the 4 section 610 reviews completed but there were 23 final or proposed changes to regulations in response to industry petitions .

in addition , gao's examination of sba's december 2006 unified agenda entries indicated that 22 rule changes were the result of the agency's discretionary authority rather than statutory mandates .

sba's section 610 plan in the may 2006 unified agenda described procedures for conducting section 610 reviews .

the plan specifies that sba will consider the factors identified in section 610 .

the plans also specifies that the conduct of the review will be performed by the program office of jurisdiction , which entails reviewing any comments received from the public , in consultation with the office of general counsel ( ogc ) and the office of advocacy .

the document notes that the program office may contact associations that represent affected small entities in order to obtain information on impacts of the rules .

although section 610 does not require agencies to report the results of the reviews , sba reported its results in the unified agenda .

under sba's standard operating procedures each program office is responsible for evaluating the adequacy and sufficiency of existing regulations that fall within its assigned responsibilities .

however , according to the officials , the agency does not have a uniform way to plan , conduct , and report these discretionary reviews .

in general , the agency conducts reviews in an informal manner ; therefore , documentation does not exist for the procedures or standards used to conduct these reviews .

however , officials described considering these factors to prioritize their reviews: ( 1 ) the level of congressional interest in a specific review , ( 2 ) ogc's input on which rules should be reviewed , and ( 3 ) the number of petitions and appeals sba has received regarding a particular rule .

reviews are conducted differently in the various program offices within sba .

moreover , the agency described a high turnover of employees , which makes it important to document sba reviews and processes .

currently , it does not appear that the agency documents its review and processes .

employee benefit security administration's ( ebsa ) retrospective regulatory review process was the most documented and detailed formal review process included in our review .

according to ebsa officials and our review of ebsa documentation on its regulatory review program ( the program ) , the agency established its program as a continuing and systematic process that allows the agency to periodically reviews its regulations to determine whether they need to be modified or updated .

the program takes into account technology , industry , economic , compliance and other factors that may adversely affect a rule's continued usefulness , viewed with respect to either costs or benefits .

according to program documentation , through the integration of prescribed review criteria , regulatory reviews conducted under the program would also help ebsa to satisfy the section 610 requirement for periodic reviews of agency regulations .

in addition , the program provides information and data that assists ebsa in conducting regulatory reviews of ebsa regulations in accordance with the requirements of executive order 12866 .

ebsa's regulatory review process is conducted annually by a regulatory review committee ( rrc ) composed of the counsel for regulation , office of the solicitor's plan benefits and security division ( or his delegate ) , and the directors of the following offices ( or their respective delegates ) : office of regulations and interpretations , office of policy and research , office of enforcement , office of health plan standards and compliance assistance , and office of exemption determinations .

the director of regulations and interpretations ( or his delegate ) chairs the rrc .

ebsa's review process consists of three formal phases: ( 1 ) selection of regulations for further review , ( 2 ) substantive review of the selected regulations , and ( 3 ) reporting review results to high - level management and the public .

need further review in a written report to the assistant secretary , including an explanation of the reasons for its recommendations .

the factors that the rrc considers when preliminarily reviewing the regulations are: whether the regulation is subject to review under the rfa ; whether the regulation is subject to review under statutory or executive order requirements other than the rfa ; absolute age of regulation ( time elapsed since promulgation ) ; time elapsed since regulation was last amended and nature of amendment ( major / minor ) ; court opinions adjudicating issues arising under regulation ; number of ebsa investigations that have found violations of regulation ; number of public requests received for interpretation of regulation ; type ( s ) of plans affected by the regulation ; number of plans affected ; cumulative number of participants and beneficiaries affected by cumulative amount of plan assets affected by regulation ; relative difficulty of compliance with regulation for the regulated entities ( complexity , understandability ) ; potential for cost burden as compared with intended benefits of the extent to which development of new technology or industry practice since promulgation may reduce effectiveness of regulation ; extent to which legal changes ( statutory , regulatory , executive order ) since promulgation of the regulation may affect its validity ; significance of the regulation with respect to ebsa's goals ; significance of the regulation with respect to enforcement , compliance assistance and voluntary compliance efforts ; and availability of information pertinent to evaluating the regulation .

noted in the past , many agencies have not yet taken .

specifically , the program sets threshold criteria for what constitutes “significant impact” and “substantial number of entities.” gao has reported on numerous occasions that the lack of clarity about these terms is a barrier to agency conduct of reviews and has resulted in fewer reviews being conducted .

therefore , this step in the review program appears to be a very useful factor .

under ebsa's approach for measuring these thresholds , the rules to be reviewed each year are first subjected to quantitative analysis to determine whether they are considered to have a significant economic impact on a substantial number of small entities .

for its initial section 610 reviews , ebsa has adopted a uniform standard of $25 per plan participant to measure the discretionary impact of regulations reviewed under section 610 , and whether it constitutes a “significant economic impact.” ebsa's definition of a small entity as an employee pension or welfare plan with fewer than 100 participants is grounded in sections 104 ( a ) ( 2 ) and ( 3 ) of the employee retirement income security act ( erisa ) , which permit the secretary to prescribe simplified annual reports for pension and welfare plans with fewer than 100 participants .

additional details on these definitions and how they were derived can be found in the agency's regulatory review program guidance .

whether the regulation overlaps , duplicates , or conflicts with other federal statutes or rules or with nonpreempted state or local statutes or rules ; whether the regulation is overly complex and could be simplified without whether the regulation may be based on outdated or superseded employment , industrial , or economic practices or assumptions and whether participants and / or beneficiaries of employee benefit plans may be exposed to harm as a result ; whether the regulation may impose significant economic costs on regulated entities and whether the benefit ( s ) or purpose ( s ) of the regulation could be achieved as effectively through an alternative regulatory approach that would impose less economic burden on regulated industries ; whether an alternative regulatory approach that does not increase the compliance burden for regulated industries could better serve the purpose ( s ) of the regulation or provide better protection ( s ) to participants and beneficiaries of employee benefit plans ; and whether it would be in the public interest to initiate particular actions ( eg , contracting a research study , promulgating a request for information , conducting a public hearing ) within the authority of ebsa to develop information or expertise pertinent to the regulation and relevant to consideration of the above issues .

in the federal register , before it issues a notice for proposed rulemaking .

 ( for an illustration of this process , see fig 7 in app .

iv. ) .

mathew j. scire , director , strategic issues ( 202 ) 512-6806 , sciremj@gao.gov .

tim bober , assistant director , and latesha love , analyst - in - charge , managed this assignment .

other staff who made key contributions to this assignment were matt barranca , jason dorn , tim guinane , andrea levine , shawn mongin , bintou njie , joe santiago , stephanie shipman , michael volpe , and greg wilmoth .

