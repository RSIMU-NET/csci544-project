i am pleased to be here today to discuss the federal government's processes for improving the management of information technology ( it ) investments .

as you know , billions of taxpayer dollars are spent on these projects each year .

this number is expected to reach $71 billion for fiscal year 2009 .

given the size of these investments and the criticality of many of the systems to the health , economy , and security of the nation , it is important that they be effectively managed .

to this end , the office of management and budget ( omb ) , which plays a key role in overseeing the federal government's it investments , identifies major projects that are poorly planned by placing them on a management watch list and requires agencies to identify high - risk projects that are performing poorly .

having accurate and transparent project cost and schedule information is also essential to effective oversight .

at times , changes to this information — called a rebaselining — are made to reflect changed development circumstances .

these changes can be done for valid reasons , but can also be used to mask cost overruns and schedule delays .

we have testified on the management watch list and high - risk projects for the past 2 years , highlighting the number and dollar value of the projects identified as poorly planned and / or poorly performing .

you asked us to ( 1 ) provide an update on omb's management watch list and list of high - risk projects , ( 2 ) identify omb's efforts to improve the identification and oversight of these projects , and ( 3 ) summarize our it project rebaselining report , which is being released today .

in preparing this testimony , we analyzed the current management watch list and high - risk project information and reviewed recent actions taken by omb to better identify and oversee these projects .

in completing our rebaselining review we surveyed the managers of a random sample of 180 projects selected from the 778 major it projects the 24 major agencies plan to invest in during fiscal year 2008 and compared agencies' rebaselining policies to best practices identified in our cost assessment guide .

we performed our work in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

each year , omb and federal agencies work together to determine how much the government plans to spend on it projects and how these funds are to be allocated .

federal it spending has risen to an estimated $71 billion for fiscal year 2009 .

omb plays a key role in overseeing the implementation and management of federal it investments .

to improve this oversight , congress enacted the clinger - cohen act in 1996 , expanding the responsibilities delegated to omb and agencies under the paperwork reduction act .

among other things , clinger - cohen requires agencies to better link their it planning and investment decisions to program missions and goals and to implement and enforce it management policies , procedures , standards , and guidelines .

the act also requires that agencies engage in capital planning and performance and results - based management .

omb's responsibilities under the act include establishing processes to analyze , track , and evaluate the risks and results of major capital investments in information systems made by executive agencies .

omb must also report to congress on the net program performance benefits achieved as a result of these investments .

in response to the clinger - cohen act and other statutes , omb developed policy for the planning , budgeting , acquisition , and management of federal capital assets .

this policy is set forth in omb circular a - 11 ( section 300 ) and in omb's capital programming guide ( supplement to part 7 of circular a - 11 ) , which direct agencies to develop , implement , and use a capital programming process to build their capital asset portfolios .

among other things , omb's capital programming guide directs agencies to evaluate and select capital asset investments that will support core mission functions and demonstrate projected returns on investment that are clearly equal to or better than alternative uses of available public resources , institute performance measures and management processes that monitor actual performance and compare it to planned results , and establish oversight mechanisms that require periodic review of operational capital assets to determine if mission requirements have changed and whether the asset continues to fulfill those requirements and deliver its intended benefits .

to further support the implementation of it capital planning practices as required by statute and directed in omb's capital programming guide , we have developed an it investment management framework that agencies can use in developing a stable and effective capital planning process .

it is a tool that can be used to determine both the status of an agency's current it investment management capabilities and the additional steps that are needed to establish more effective processes .

mature and effective management of it investments can vastly improve government performance and accountability , while poor management can result in wasteful spending and lost opportunities for improving delivery of services to the public .

we have previously reported that the federal government faces enduring challenges in effectively managing it investments .

for example , in january 2004 , we reported on the mixed results of federal agencies' use of it investment management practices .

specifically , we reported that , although most of the agencies had it investment boards responsible for defining and implementing the agencies' investment management processes , they did not always have important mechanisms in place for these boards to effectively control investments , including decision - making rules for project oversight , early warning mechanisms , and requirements that corrective actions for underperforming projects be agreed upon and tracked .

accordingly , we made several recommendations to agencies to improve their practices .

in previous work using our investment management framework , we reported that the use of it investment management practices by agencies was mixed .

for example , a few agencies that have followed the framework in implementing capital planning processes have made significant improvements .

in contrast , however , we and others have continued to identify weaknesses at agencies in many areas , including immature management processes to support both the selection and oversight of major it investments and the measurement of actual versus expected performance in meeting established performance measures .

for example , in 2007 , we reported that the department of homeland security and the department of the treasury did not have the processes in place to effectively select and oversee their major investments .

to help ensure that investments of public resources are justified and that public resources are wisely invested , omb began using its management watch list in the president's fiscal year 2004 budget request as a means to oversee the justification for and planning of agencies' it investments .

this list was derived based on a detailed review of each investment's capital asset plan and business case , also known as the exhibit 300 .

the exhibit 300 is a reporting mechanism intended to enable an agency to demonstrate to its own management , as well as to omb , that a major project is well planned in that it has employed the disciplines of good project management ; developed a strong business case for the investment ; and met other administration priorities in defining the cost , schedule , and performance goals proposed for the investment .

in april 2005 , we reported that omb analysts evaluated agency exhibit 300s by assigning scores to each exhibit 300 based on guidance presented in omb circular a - 11 .

as described in this circular , the scoring of a business case consisted of individual scoring for 10 categories ( on a scale from 1 to 5 with 5 being the highest ) , as well as a total composite score of all the categories .

the 10 scoring categories are: support of the president's management agenda , project ( investment ) management , cost / schedule / performance .

when we reported on the management watch list in 2005 , projects were placed on the management watch list if they received low scores ( 3 or less ) in the areas of performance goals , performance - based management systems , security and privacy or if they received a low composite score .

for the fiscal year 2009 budget , omb used more stringent criteria .

specifically , omb placed projects on the management watch list if they had ( 1 ) an overall score of 30 or less , ( 2 ) a security score of 3 or less , or ( 3 ) a non - security score of 2 or less .

projects were also placed on the list if other sources ( such as an inspector general's federal information security management act report or the agency's president's management agenda e - government scorecard ) indicated that the agency did not have qualified project managers or had weaknesses in its implementation of security , privacy , or earned value management techniques .

according to omb , agencies with projects on the management watch list are to submit remediation plans addressing the weaknesses .

those projects that receive specific follow - up attention receive feedback through what is known as the passback process , targeted evaluation of remediation plans designed to address weaknesses , the apportioning of funds made conditional on appropriate remediation plans being in place , and the quarterly e - government scorecards .

according to omb , it removes projects from the management watch list as agencies remediate the weaknesses identified with these projects' business cases .

as originally defined in omb circular a - 11 and subsequently reiterated in an august 2005 memorandum , high - risk projects are those that require special attention from oversight authorities and the highest levels of agency management .

these projects are not necessarily at risk of failure , but may be on the list because of one or more of the following four reasons: the agency has not consistently demonstrated the ability to manage complex projects .

the project has exceptionally high development , operating , or maintenance costs , either in absolute terms or as a percentage of the agency's total it portfolio .

the project is being undertaken to correct recognized deficiencies in the adequate performance of an essential mission program or function of the agency , a component of the agency , or another organization .

delay or failure of the project would introduce for the first time unacceptable or inadequate performance or failure of an essential mission function of the agency , a component of the agency , or another organization .

in 2006 , we reported that , to identify high - risk projects , staff from each agency's office of the chief information officer compare the criteria against their current portfolio to determine which projects met omb's definition .

they then submit the list to omb for review .

according to omb and agency officials , after the submission of the initial list , examiners at omb work with individual agencies to identify or remove projects as appropriate .

according to most agencies , the final list is then approved by their chief information officer .

this year , omb clarified and expanded the high - risk project criteria .

specifically , in the materials supplementing the president's budget for fiscal year 2009 , omb listed the following criteria for identifying high - risk projects: projects with a high degree of political or citizen interest , projects with cross - organizational or agency impact or interdependencies with other systems efforts , major systems on the management watch list at the conclusion of the prior fiscal year that continue to warrant heightened attention during project execution , major systems formally designated as an e - government or line of business shared service provider , e - government initiative migration projects that are planned or underway ( which are removed upon completion ) , existing or legacy agency systems retiring once their functionality has been migrated to a common solution ( also removed once retired ) , and program or program management office activities supporting government - wide common solutions .

for the identified high - risk projects , chief information officers are to assess , confirm , and document projects' performance .

specifically , agencies are required to determine , for each of their high - risk projects , whether the project was meeting one or more of four performance evaluation criteria , which include: establishing baselines with clear cost , schedule , and performance goals ; maintaining the project's cost and schedule variances within 10 percent ; assigning a qualified project manager ; and avoiding duplication by leveraging inter - agency and governmentwide investments .

high risk projects failing to meet any of these four performance evaluation criteria are considered to have “performance shortfalls.” agencies are instructed to document these shortfalls using a standard template provided by omb and provide this template to oversight authorities on request .

upon submission , individual analysts review the quarterly performance reports of projects with shortfalls to determine how well the projects are progressing and , using other performance data already received , whether the actions described in the planned improvement efforts are adequate .

at times , a major it project's cost , schedule , and performance goals — known as a baseline — need to be modified to reflect new circumstances .

while these changes — generally referred to as rebaselining — can be done for valid reasons — including , for example , changes in a project's objectives , scope , requirements , or funding stream — they can also be used to mask cost overruns and schedule delays .

the purpose of a rebaselining is to ensure that project managers have realistic benchmarks for tracking the status of the project .

omb requires that all proposed changes to baselines be submitted to it prior to an agency's budget request ( and that proposed changes should not be assumed to be approved ) .

the information omb requires from agencies includes costs and milestones from both the initial and current baselines ( if the program has been rebaselined ) .

it also asks agencies whether the investment was rebaselined during the past fiscal year and , if so , if the new baseline was approved by the agency head .

the capital programming guide also notes that omb reviews the reasons for deviation from goals , the reasonableness of the corrective actions proposed , and the validity of increased cost estimates .

the guide further states that omb is to consider approving a rebaseline proposal only when the agency has provided justification based on an integrated baseline review , demonstrates that the new goals have a high probability of attainability , and shows that the acquisition will still have a benefit - cost ratio that justifies continued funding after comparing it with the other projects in the portfolio and considering budget limitations .

staff from omb's office of e - government and information technology and the acting chief of omb's information policy and technology branch told us that they review agencies' earned value management policies to determine their compliance with the provisions of the presidential management agenda for e - government .

they stated that , in reviewing these policies , they determine whether rebaselining is adequately addressed .

in addition , the department of defense ( dod ) has statutory requirements involving rebaselining .

each major defense acquisition program is required by statute to establish an approved program baseline before entering into the system development and demonstration phase of the acquisition cycle .

for such programs , a revised baseline is also required for each subsequent milestone authorizing entry into the next phase of the acquisition cycle .

the statute also requires dod to prescribe regulations addressing the content of the baseline , reports of deviations from the baseline , procedures for reviewing such deviations within dod , and procedures for submission to and approval by the secretary of defense of revised baselines .

we also recently issued a draft cost assessment guide on best practices for estimating and managing program costs which , among other things , discusses considerations in rebaselining programs .

for example , the guide identifies key cost , schedule , project execution risk , and data accuracy indicators that can serve as warning signs that a program may need to be rebaselined .

the guide also identifies best practices that are relevant to rebaselining policies .

these practices are: ( 1 ) describing reasons when a rebaseline is warranted , ( 2 ) describing the process for developing a new baseline , ( 3 ) requiring validation of the new baseline , ( 4 ) requiring management review , and ( 5 ) requiring that decisions associated with the rebaselining process are documented .

omb and federal agencies have identified approximately 413 it projects — totaling at least $25.2 billion in expenditures for fiscal year 2009 — as being poorly planned , poorly performing , or both .

specifically , hundreds of projects totaling billions of dollars have been placed on omb's management watch list for fiscal year 2009 .

in addition , projects identified as poorly performing under omb's high - risk process total about $4.8 billion in estimated expenditures for fiscal year 2009 .

finally , 26 projects totaling $3 billion have been identified as both poorly planned and poorly performing .

figure 1 shows the distribution of these projects and their associated dollar values .

each year , omb has placed hundreds of projects totaling billions of dollars on the management watch list .

table 1 provides a historical perspective of the number of these projects and their associated budgets since omb started reporting on the management watch list in the president's budget request for 2004 .

the table shows that while the number of projects and their associated budgets have generally decreased since then , they increased by 239 projects and $13 billion dollars for fiscal year 2009 , and represent a significant percentage of the total budget .

as of july 2008 , omb reported that 352 of the 585 projects , representing $23.4 billion , still remained on the management watch list ( see appendix i for complete list ) .

table 2 shows the number of projects each agency has on the watch list as of july 2008 .

according to omb's evaluation of the exhibit 300s , investments were placed on the watch list primarily because of weaknesses in the way they addressed ( 1 ) cost , schedule , and performance ; ( 2 ) security ; ( 3 ) privacy ; and ( 4 ) acquisition strategy .

figure 2 illustrates the frequency of these reasons for the projects that remained on list as of july 2008 .

appendix ii provides additional detail by agency .

in addition , according to omb , thirty - two of these projects have been on the management watch list since fiscal year 2006 .

the departments of veterans affairs and commerce have had the most projects on the list since then: 14 and 7 , respectively .

table 3 identifies the 32 projects that have been on the management watch list since fiscal year 2006 .

as of june 2008 , the 24 major agencies identified 472 it projects as high risk , at least 87 of which had performance shortfalls collectively totaling about $4.8 billion in funding requested for fiscal year 2009 .

table 4 shows that the number of projects increased , while the number of projects with shortfalls decreased this year .

the fact that the department of veterans affairs has not yet provided information on its number of projects with shortfalls may be a contributing factor .

the majority of projects were not reported to have had performance shortfalls .

further , seven agencies — the department of housing and urban development , the department of state , the national aeronautics and space administration , the nuclear regulatory commission , the national science foundation , the small business administration , and the social security administration — reported that none of their high - risk projects experienced any performance shortfalls .

figure 3 illustrates the number of high - risk projects by agency as of june 2008 , with and without shortfalls .

agencies reported cost and schedule variances that exceeded 10 percent as the most common shortfall .

this is consistent with what they reported about a year ago , and the distribution of shortfall types is similar to that of last year .

figure 4 illustrates the reported number and type of performance shortfalls associated with high - risk projects , and appendix iii provides additional details of the shortfalls associated with each of the poorly performing projects .

seventeen high - risk projects have experienced performance shortfalls for the past four quarters ( see figure 5 ) .

of these projects , two projects have had shortfalls since the list of high - risk projects was established in september 2005: dhs's customs and border patrol secure border initiative network technology program , which is expected to provide on - scene agents near real - time information on attempted border crossings by illegal aliens , terrorists , or smugglers .

dhs's transportation security administration transportation worker identification credentialing , which is to establish a system - wide common secure biometric credential , used by all transportation modes , for personnel requiring unescorted physical and / or logical access to secure areas of the transportation system .

as of july 2008 , 26 projects are on both the management watch list and list of high - risk projects with shortfalls , meaning that they are both poorly planned and poorly performing .

they total about $3 billion in estimated expenditures for fiscal year 2009 .

this is an increase of 5 projects but a decrease of $1.1 billion from when we reported last year .

these projects are listed in table 5 below .

 ( the project names were taken from omb's management watch list released in july 2008 and matched to those in agencies' june 2008 quarterly high - risk reports. ) .

omb has taken steps to improve the identification of the management watch list and high - risk projects since we testified last september , including publicly disclosing reasons for placement on the management watch list , and clarifying high - risk project criteria , however , more needs to be done by both omb and the agencies to fully address recommendations we have previously made to improve the planning , management , and oversight of the poorly planned and poorly performing projects so that potentially billions in taxpayer dollars are not wasted .

management watch list: in order for omb to take advantage of the potential benefits of using the management watch list as a tool for analyzing and following up on it investments on a governmentwide basis , in 2005 we recommended that the agency take the following four actions: ( 1 ) develop a central list of management watch list projects and their deficiencies ; ( 2 ) use the list as the basis for selecting projects for follow - up and for tracking follow - up activities ( including developing specific criteria for prioritizing the it projects included on the list , taking into consideration such factors as their relative potential financial and program benefits , as well as potential risks ) ; ( 3 ) analyze the prioritized list to develop governmentwide and agency assessments of the progress and risks of it investments , identifying opportunities for continued improvement ; and ( 4 ) report to congress on progress made in addressing risks of major it investments and management areas needing attention .

omb has taken steps to address our recommendations for developing a central list of projects and their deficiencies and developing governmentwide and agency assessments .

specifically , as previously noted , omb started issuing a central list of management watch list projects in september 2006 , and publicly disclosing these projects' deficiencies ( i.e. , the reasons for inclusion on the management watch list ) in april .

in addition , omb performed governmentwide and agency - specific analyses of projects' deficiencies in april and in july of this year , which it reported to congress and disclosed publicly .

however , omb needs to continue to use the management watch list to prioritize the projects needing follow - up action and to keep reporting to congress on management areas needing attention .

high - risk projects: to improve the identification and oversight of the high - risk projects , in 2006 we recommended , among other things , that omb establish a structured , consistent process to update the list of high - risk projects on a regular basis , including identifying new projects and removing previous ones to ensure that the list is current and complete .

we also recommended that omb develop a single aggregate list of high - risk projects and their deficiencies and use that list to report to congress progress made in correcting high - risk problems , actions under way , and further actions that may be needed .

omb took several steps to address these recommendations .

as previously noted , the agency clarified the high - risk project criteria this year .

it also asked agencies to identify , in their quarterly reports , reasons for placement on the list and reasons for removal , thereby adding structure and consistency to the process for updating the list .

in addition , as previously reported , omb also started publicly releasing aggregate lists of the high - risk projects in september 2006 , and has been releasing them on their website on a quarterly basis since then .

however , omb has yet to identify the deficiencies ( i.e. , performance shortfalls ) associated with the high - risk projects as we have done in this report ( see appendix iii ) .

as we have stated before , doing so would allow omb and others to better analyze the reasons projects are poorly performing , take corrective actions , and track these projects on a governmentwide basis .

such information would also help to highlight progress made by agencies or projects , identify management issues that transcend individual agencies , and highlight the root causes of governmentwide issues and trends .

in addition , as noted earlier , our prior reviews of federal it management practices have identified ( and continue to identify ) weaknesses at agencies that have yet to be addressed .

while these agencies have taken action to address the many recommendations we have made to improve their practices , more needs to be done as evidenced by the large number of projects that are still poorly planned and poorly performing .

while the actions taken have resulted in better data on the poorly planned and performing projects , additional steps need to be taken by both omb and the agencies to address recommendations we have previously made to improve the planning , management , and oversight of these projects .

these steps include using the management watch list to prioritize follow up activities .

until these additional steps are taken , potentially billion of taxpayer dollars are at risk of being wasted .

given that cost and schedule variances are the primary reason for poorly performing projects , having accurate and transparent cost and schedule information is essential to effective oversight .

in a report being released today , we estimate that about 48 percent of the federal government's major it projects have been rebaselined .

of those rebaselined projects , 51 percent were rebaselined at least twice , and about 11 percent were rebaselined 4 times or more .

these projects were rebaselined for several reasons , including changes in project goals and changes in funding .

while the major agencies have all established rebaselining policies , these policies are not comprehensive .

specifically , none of the policies are fully consistent with best practices , including describing a process for developing a new baseline and requiring the validation of the new baseline , identified in our cost assessment guide .

agencies' policies vary in part because omb has not issued guidance specifying what elements these policies are to include .

in our report we project that 48 percent of the major projects federal agencies plan to fund in fiscal year 2008 have been rebaselined , and about half of those have been rebaselined at least twice .

figure 6 summarizes the percentage of projects rebaselined and figure 7 summarizes the estimated frequencies of the number of times rebaselined major it projects were rebaselined .

table 6 lists the nine projects in our sample that agencies reported having been rebaselined four or more times .

agency officials reported that the key reasons for the most recent rebaselinings were changes in project requirements , objectives , or scope , and changes in funding stream .

table 7 shows the estimated frequencies of each of these reasons .

several rebaselined projects we have performed detailed reviews of have experienced significant cost or schedule changes .

for example , the u.s. coast guard's rescue 21 program is projected to have cost increases of 184 percent and schedule delays of 5 years after rebaselining .

table 8 provides additional examples of projects we have reviewed that experienced significant cost or schedule changes .

we are also reporting that , although the 24 major agencies have rebaselined about half of their major it projects that they planned to invest in during fiscal year 2008 , they have not been guided by comprehensive rebaselining policies .

specifically , while major agencies have all established rebaselining policies , none of the policies are fully consistent with best practices such as describing a process for developing a new baseline .

our recently issued draft cost assessment guide includes five practices that are relevant to rebaselining policies: 1 .

describe reasons when a rebaseline is warranted .

a rebaselining policy should require valid reasons for rebaselining such as that the baseline is no longer useful as a management tool ( eg , cost / schedule variances are so high that they lose meaning ; program scope has significantly changed ) .

2 .

describe the process for developing a new baseline .

a rebaselining policy should describe the development of a new cost estimate and a new project plan that details the scope of the remaining work along with schedule and resource allocation .

3 .

require validating the new baseline .

a rebaselining policy should identify who can validate the new baseline and how the validation is to be done .

4 .

require management review .

a rebaselining policy should identify the authority who decides whether the rebaselining is warranted and the rebaselining plan is acceptable .

in addition , the policy should outline decision criteria used by the decision authority to determine if the rebaseline plan is acceptable .

5 .

require that the process is documented .

a rebaselining policy should identify and document rebaselining decisions , including the reasons for rebaselining ; changes to the approved baseline cost , schedule , and scope ; management review of the rebaseline request ; and approval of new baseline .

the policy should also require an explanation of why the current plan is no longer feasible ; identify the problems that led to the need for a new plan of the remaining work ; and discuss measures in place to prevent recurrence .

our analysis shows that agencies do not have comprehensive rebaselining policies .

specifically , none of the agencies' rebaselining policies are fully consistent with all of the five practices mentioned above .

most policies fully or partially addressed reasons for rebaselining , requiring management review , and requiring that the rebaselining process be documented ( 79 percent , 96 percent , and 88 percent , respectively ) , while describing the process for developing the new baseline and requiring validation of the new baseline were addressed the least ( 46 percent and 54 percent of the policies , respectively , did not address these practices ) .

table 9 summarizes our assessment of agencies' rebaselining polices .

agencies' policies vary in part because no guidance has been issued specifying what elements these policies are to include .

as previously noted , omb has issued guidance which , among other things , requires baseline change requests to be approved by the agency heads and to be submitted to omb for approval .

however , this guidance does not specifically address how agencies are to implement their rebaselining activities , including the key elements that should be addressed in their policies .

in addition , officials from omb's office of e - government and information technology and the acting chief of omb's information policy and technology branch told us that , in their oversight function , they review agencies' earned value management policies , and in doing so determine whether these policies address rebaselining .

however , they noted that they have not established specific criteria to evaluate the earned value management policies ( and therefore their rebaselining aspects ) and acknowledged that having such criteria would improve consistency among the policies and facilitate their oversight process .

without comprehensive policies to guide their rebaselining activities , agencies may not be optimizing the effectiveness of rebaselining as a tool to improve performance management .

in addition , their rebaselining processes may lack the transparency needed to ensure effective oversight .

to address the weaknesses identified with agencies' rebaselining policies , we made recommendations to the director of omb and to the 24 major agencies .

specifically , we recommended that the director of omb issue guidance for rebaselining policies that would include a minimum set of key elements , taking into consideration the criteria used in our report , and each of the heads of the 24 major agencies direct the development of comprehensive rebaselining policies that address the weaknesses we identified .

we received comments on a draft of our report from 20 of the major agencies - - 4 of which stated that they had no comments .

of the remaining 16 agencies , 10 generally agreed with our findings and / or recommendations , and 6 disagreed with our assessment of certain practices associated with their rebaselining policies .

in summary , effective management and oversight of federal it projects remains a crucial task for omb and executive branch agencies .

hundreds of projects , amounting to billions of dollars in expenditures , have been identified as poorly managed , poorly performing , or both .

while omb has taken steps to improve the identification of poorly managed and poorly performing projects , more needs to be done to improve management and oversight , as evidenced by the number of recurring management watch list projects and the surge of these projects at the beginning of every fiscal year .

in addition , without sound policies guiding agencies' rebaselining efforts , changes to projects' cost and schedule goals are not as transparent as desired and may in fact mask cost overruns and schedule delays .

having sound rebaselining guidance from omb and more diligent oversight of rebaselining efforts from federal agencies will result in more accurate information on cost and schedule performance shortfalls and provide the necessary transparency to agency officials , omb , and other oversight organizations .

as we transition to a new administration , it is essential to maintain the current momentum of identifying troubled projects and the reasons they are poorly planned and / or performing and to continue to focus attention more keenly on solutions and long - term improvement efforts .

mr. chairman , this concludes my statement .

i would be happy to answer any questions at this time .

if you should have any questions about this testimony , please contact me at ( 202 ) 512-9286 or by e - mail at pownerd@gao.gov .

individuals who made key contributions to this testimony are sabine paul , assistant director ; neil doherty ; lee mccracken ; kevin walsh and eric winter .

the following provides additional detail on the investments comprising omb's management watch list as of july 2008 .

the project names were taken from omb's management watch list released earlier this month and matched to the list of projects in omb's report on it spending for fiscal years 2007 , 2008 , and 2009 to derive the requested amounts for fiscal year 2009 .

table 11 provides additional detail on the frequency of the reasons for inclusion on the management watch list for each agency for the projects remaining on the list as of july 2008 .

it shows security and cost and schedule performance as being the most common reasons .

table 12 provides additional detail on the high - risk projects that have performance shortfalls as of june 2008 .

these shortfalls were identified by agencies in june 2008 high - risk reports .

 ( the department of veterans affairs has not yet provided its report. ) .

the project names were taken from omb's list of management watch list released earlier this month and matched to the list of projects on agencies' june 2008 high - risk reports .

