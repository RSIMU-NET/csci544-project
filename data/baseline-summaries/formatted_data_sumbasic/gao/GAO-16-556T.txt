i am pleased to be here today to discuss the implementation status of the digital accountability and transparency act of 2014 ( data act ) and to update you on our recent work regarding the progress that has been made to date as well as some key challenges moving forward .

this is a critical period for the implementation of the data act , as its reporting requirements take effect government - wide in 2017 .

congressional oversight during this time will play a vital role in helping to determine whether the act will fulfill its promise for shedding light on how federal funds are spent .

the office of management and budget ( omb ) and the department of the treasury ( treasury ) have taken some significant steps since the may 2014 passage of the data act .

they issued standardized data element definitions , released an eight - step implementation plan to help agencies meet their reporting requirements , and designed a pilot for developing recommendations to reduce recipient reporting burden ( section 5 pilot ) .

despite these accomplishments , continuing challenges will need to be addressed in order to successfully meet the act's requirements .

we have completed several reviews of data act implementation .

in july 2015 , we testified before your subcommittees on the progress made and challenges that needed to be addressed in the first year following passage of the act .

in september 2015 , we issued a report on preserving the capabilities of the recovery operations center .

in january of this year , we issued a report on the establishment of data standards under the act .

today , we are releasing a report on the design of the section 5 pilot .

we also have engagements underway to examine the data act implementation plans submitted by federal agencies and to explore possible approaches for developing an inventory of federal programs as required by the gpra modernization act of 2010 ( gprama ) .

this inventory would assist in the implementation of the data act consistent with its stated purposes .

in addition , we will continue monitoring omb's and treasury's development of technical and operational guidance to agencies on the standardized data element definitions developed last year as well as the implementation of the section 5 pilot design .

this oversight approach will allow us to meet the data act requirements for us to issue reports in 2017 , 2019 , and 2021 assessing and comparing the quality of data submitted under the act as well as agency implementation and use of data standards .

we have coordinated closely with federal inspectors general to leverage information and avoid duplication of effort as they conduct reviews and develop audit guidance and practices .

as part of this effort , we will continue to work with our inspector general colleagues to ensure that sufficient attention is being devoted to agencies' capacities to meet their responsibilities under the act .

my remarks today will address the following topics related to implementation of the data act .

specifically , i will be discussing ( 1 ) what efforts have been made to date to develop government - wide standards and associated technical guidance , ( 2 ) the challenges and mitigation strategies associated with implementation reported by agencies , and ( 3 ) the effectiveness of omb's design of the section 5 pilot to reduce recipient reporting burden .

in addition , i will provide an update on prior gao recommendations relating to the data act and their implementation status ( see appendix i ) .

with the exception of our review of agency implementation plans , my testimony today is based on work that we have either previously issued or are issuing today .

we used multiple methodologies to develop the findings , conclusions , and recommendations for those reports .

details on the objectives , scope , and methodology for each of these issued reports are available in the reports .

for our ongoing review of agency implementation plans , we requested 51 implementation plans submitted pursuant to requirements of omb memorandum m - 15-12 , and we obtained 42 of the 51 implementation plans requested .

most of these plans were submitted to omb in september 2015 .

some agency implementation plans were dated as late as january 2016 .

we analyzed the 42 federal agency implementation plans to identify any reported challenges and mitigating strategies in their data act implementation plans .

we did not evaluate the quality of the information provided in the agencies' plans .

to obtain an update on open recommendations relating to the data act , we met with omb and treasury officials to discuss progress made on addressing our open recommendations .

we provided a draft of this statement to treasury and omb .

treasury officials provided technical comments on the draft statement , which we incorporated as appropriate .

omb had no comments on the draft statement .

the work upon which this statement is based was conducted in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in our january 2016 report on data standards we noted that by the end of august 2015 omb and treasury had issued a list of 57 standardized data elements .

the data act requires that these data standards — to the extent reasonable and practicable — incorporate widely accepted common data elements , such as those developed by international standards - setting bodies .

incorporating leading practices from international standards organizations offers one way to help reduce uncertainty and confusion when reporting and interpreting data standards .

well - crafted data element definitions are needed to ensure that a data standard produces consistent and comparable information .

in our january 2016 report , we noted that these standardized data element definitions largely followed leading practices .

we compared the standardized data elements against leading practices promulgated by the international organization for standardization ( iso ) and found that 12 of the 57 data act data element definitions issued in august 2015 met all of the iso leading practices and each of the remaining 45 definitions met no fewer than 9 leading practices , meaning that even the lowest - rated data elements in our review adhered to almost 70 percent of the iso leading practices .

while this demonstrates good progress , it will be important to clarify data elements that did not adhere to leading practices to reduce the risk that agencies inconsistently apply the definitions .

imprecise or ambiguous data element definitions may allow for more than one interpretation by agency staff collecting , compiling , and reporting on these data and thus could result in inconsistent and potentially misleading reporting when aggregated across government or compared between agencies .

for example , omb and treasury issued four data elements that collectively represent the concept of primary place of performance .

the location or place of performance of specific grant , contract , or other federal spending has long been a data element collected by agencies .

however , agencies have taken varied approaches to reporting place of performance information — sometimes describing where the funded activity takes place , sometimes the recipient of the product or activity , or sometimes the location of the administrative headquarters of the provider or a sub - entity .

we reported that although the definitions standardize some of the mechanics of what primary place of performance covers , such as city , county , state , and zip+4 codes , the definition still leaves room for differing interpretations that could result in agencies capturing and reporting this information differently .

in another example highlighted in our january report , we noted that omb and treasury standardized the definition of program activity as required by the data act .

this definition adhered to all 13 iso leading practices , but we still had concerns regarding the use of this data element .

specifically , omb's and treasury's guidance on program activity acknowledged that program activities can change from one year to the next and that program activity does not necessarily match “programs” as specified in gprama or the catalog of federal domestic assistance .

in responding to this guidance , officials at the u.s. department of agriculture said that when program activities change it is difficult to compare spending over time , underscoring the need for more guidance to ensure that the public can accurately interpret program activity compared to the other common representations of federal programs .

we also raised concerns about omb's efforts to merge data act requirements with certain gprama requirements .

gprama requires the office of management and budget ( omb ) to make information available about each federal program .

a stated purpose of the data act is to link federal contract , loan , and grant spending information to federal programs to allow taxpayers and policy makers to track federal spending .

however , we have reported that initial efforts to develop the program inventory resulted in inconsistent definitions and significant information gaps .

as a result , the inventory does not provide useful information for decision making .

as we have previously testified before this committee , omb needs to accelerate efforts to determine how best to merge data act purposes and requirements with the gprama requirement to produce a federal inventory of programs that meets congressional expectations that federal agencies provide useful and valid information for decision making on all federal government programs .

to help address this issue , we have initiated new work to develop a framework that can inform omb's and agencies' future efforts to develop a viable and useful federal program inventory .

to help ensure that agencies report consistent and comparable data , we recommended that omb and treasury provide agencies with additional guidance that addresses potential clarity , consistency , and quality issues with identified data element definitions .

while omb generally concurred with our recommendation , it took the position that the requirement to standardize data elements applied only to the 11 account level data elements standardized in may 2015 , and efforts to standardize the remaining 46 data elements were conducted pursuant to a larger policy goal to improve the quality of federal spending data reported on usaspending.gov .

however , for reasons put forth in our january 2016 report , we concluded that both the statutory language and the purposes of the data act support the interpretation that omb and treasury are required to establish data standards for award and awardee information in addition to the account level information .

without data standards for award and awardee information , the inconsistent and incomparable reporting that congress sought to remedy through the data act will continue .

in december 2015 , omb and treasury posted a data dictionary on the federal spending transparency website that provides additional information about how each data element is defined , the type of data to be reported ( i.e. , integer , alphanumeric , numeric ) , and how data elements relate to each other .

this data dictionary also includes new data elements , which omb said encompass additional detail required for or consistent with data act reporting , such as finer breakdowns of reported values for obligations and outlays .

although this new guidance improves the clarity of the data definitions by providing additional context and detail , we are still concerned about both the lack of clarity with certain data definitions and the addition of new data elements that agencies are required to report .

in addition , omb and treasury still have not addressed data quality issues with some data elements .

our prior work identified data quality issues with certain data elements , such as award description , which omb and treasury defined as “a brief description of the purpose of the award.” in our previous work on the data quality of usaspending.gov , we identified challenges with this data element , citing the wide range of information that agencies report as the description or purpose .

agencies routinely provided information for this data element using shorthand descriptions , acronyms , or terminology that could only be understood by officials at the agency that made the award .

as we reported in 2010 and 2014 , this lack of clarity can be traced , in part , to guidance which is unclear or leaves room for multiple interpretations .

the lack of basic clarity for certain data elements could make it difficult for people outside the agency to understand the data and would limit the ability to meaningfully aggregate or compare these data across the federal government .

we made recommendations to omb in 2010 and 2014 and to treasury in 2014 to improve the accuracy and completeness of award description , which have yet to be addressed .

at that time , treasury officials neither agreed nor disagreed with our recommendations , while omb staff generally agreed with the recommendations stating that they were consistent with actions required under the data act .

omb and treasury issued initial guidance to federal agencies in may 2015 on meeting the reporting requirements of the federal funding accountability and transparency act of 2006 ( ffata ) , as amended by the data act , in accordance with the new data standards .

omb and treasury also issued a data act implementation playbook and subsequent guidance which , among other things , specified eight key steps for agencies to fulfill their data act requirements .

in our january 2016 report we raised concerns about the completeness and timeliness of the technical guidance omb and treasury developed to facilitate agency data submission .

treasury has issued several iterative versions of the technical schema that describes the standard format for reporting data elements including their description , type , and length , but has not made available a finalized schema that would provide agencies with a stable base from which to develop data submission plans .

omb's and treasury's data act implementation playbook outlines eight specific steps and timelines for implementing the data act at the agency level .

however , the finalized guidance that would help agencies carry out these steps has not been provided in time to coincide with when agencies were expected to carry out key activities outlined in the data act implementation playbook .

given the importance of having a largely stable schema to serve as the foundation for developing subsequent technical processes at the agency level , any significant delay in releasing finalized guidance will likely delay implementation of the act .

accordingly , we recommended that omb and treasury take steps to align the release of finalized technical guidance , including the data act schema and broker , to the implementation time frames specified in the data act implementation playbook .

treasury officials generally concurred with our recommendation , noting that they recognize the importance of providing agencies with timely technical guidance and reporting submission specifications .

treasury issued its updated schema , now referred to as the data act information model schema version 0.7 on december 31 , 2015 , to include schema diagrams depicting how the data elements fit together in context .

this new version builds upon previous work and incorporates additional a - 11 data elements to the schema .

in addition , it increases the level of detail required that we believe may have consequences for timely implementation by federal agencies .

finally , while many of these additional data elements are derivatives of data elements required under ffata , a - 11 or new data elements required under the data act , it could substantially increase the amount of data agencies need to submit .

although schema version 0.7 provides additional context for reporting using the new data standards , we continue to have concerns about the evolving nature of the technical specifications provided to agencies .

for example , the previous version of the schema provided information on the allowed values that could be entered for each data element , such as dc for the district of columbia .

version 0.7 of the schema removed information on allowed values , which could lead to inconsistent and incomparable reporting .

however , treasury officials told us that they have developed other methods to enforce these values .

in responding to a draft of this statement , treasury officials told us they provided final draft technical guidance to agencies for comment .

in addition , they provided a copy of this guidance to us which we will review in future work .

omb and treasury have issued data standards and provided guidance and feedback to federal agencies on their data act implementation plans .

however , our ongoing work in this area indicates that challenges remain and will need to be addressed to successfully implement the data act government - wide .

in may 2015 , omb issued memorandum m - 15-12 , which among other things , directed agencies to develop implementation plans .

omb issued additional guidance to the agencies detailing what should be included in their implementation plans , and asking agencies to describe any potential difficulties or foreseeable challenges , such as competing statutory , regulatory , or policy priorities , which could hinder their implementation of the data act .

this guidance also encouraged agencies to provide suggestions to mitigate the challenges they foresee , help to manage costs , and support investment planning .

our ongoing review of the data act implementation plans from the 24 chief financial officers act agencies as well as 18 smaller federal agencies , dated between august 2015 and january 2016 , provides insight into the challenges agencies face as well as the mitigation strategies they suggest to address them .

based on our preliminary results , we believe the challenges and mitigation strategies reported provide important insight as to the level of effort , communication , collaboration , and resources needed to successfully implement the data act government - wide .

based on our preliminary results from our ongoing review of agency implementation plans , we identified seven overarching categories of challenges reported by agencies to effectively and efficiently implement the data act .

 ( see table 1. ) .

the preliminary results of our review of the 42 agency implementation plans we received indicate that 31 agencies reported specific challenges some of which may overlap with multiple categories .

figure 1 shows that agencies reported challenges , most frequently in the following categories: competing priorities , resources , and systems integration .

competing priorities: of the 31 agencies reporting challenges , 23 reported competing statutory , regulatory , or policy priorities which could potentially affect data act implementation .

one competing priority certain agencies reported is meeting requirements of omb circular no .

a - 11 , which provides agencies with guidance on the budget process , including how to prepare and submit required materials for budget preparation and execution .

for example , one agency noted that the class” and “program activity” reporting create competing priorities both for the agency's software vendors and for the agency's internal resources .

the agency noted that staff with knowledge needed to understand and comment on new data act data element definitions are the same staff different timelines for omb circular no .

a‐11 requirements on “object required to work on the new circular no .

a‐11 reporting requirements ( eg , technical revisions and clarifications ) .

the agency added that its ability to engage effectively on the data act requirements while working to implement the circular no .

a‐11 changes is severely inhibited .

another competing priority some agencies reported is the data requirement set forth in the federal acquisition regulation ( far ) .

specifically , in october 2014 the far was amended to standardize the format of the procurement instrument identifier ( piid ) that must be in effect for new awards issued after october 2017 .

the piid must be used to identify all solicitation and contract actions , and ensure that each piid used is unique government - wide for at least 20 years from the date of the contract award .

some agencies reported they were concerned about the amount of effort involved in also implementing the piid for the data act .

for example , one agency noted that it had implemented a standard piid and developed processes and systems to handle the new identifiers to meet the far requirements , but the extent of any changes necessary to implement the piid for the data act , which also requires a unique identifier , is unknown .

another agency noted that this initiative and other agency initiatives will compete for many of the same resources , including subject matter experts .

resources: limited resources are another concern reported by 23 agencies in their implementation plans .

agencies frequently identified funding and human resources as needs for efficient and effective implementation .

for example , one agency noted that the execution of its implementation plan is highly dependent on receiving the requisite funding and human resources as estimated in the plan , and the agency added that delays in securing additional resources for fiscal years 2016 , 2017 , and beyond will have a direct effect on its data act implementation and schedule .

similarly , another agency pointed out that having insufficient funds for contractor support , managing the overall implementation , testing interfaces between systems , and addressing data mapping issues will pose a challenge for its entities and systems .

some agencies also reported that human resources are key to successful data act implementation .

one agency reported it is concerned about the adequacy of its human resources , which could impair its ability to go beyond basic compliance with the data act and added that this may prevent the agency from being able to address increased public inquiry and scrutiny of their data and operations .

specifically , the agency reported that resources are required for project management , data analysis , analytic expertise , data management , and training for financial inquiry and analysis .

the need for subject matter experts , such as data architects , was raised as a challenge by another agency .

furthermore , one agency noted that the need to share limited resources for data act implementation with other operational activities presents a significant challenge for their implementation strategy .

systems integration: systems integration is another pervasive challenge reported by 23 agencies in their implementation plans .

some agencies noted concerns about the ability of their systems to obtain and easily submit to treasury all the data elements needed to implement the data act , including the requirement to establish a unique award id .

for example , one agency reported that it does not have a systematic link to pull data from multiple systems by a unique award id and it does not have an automated grants management system because the agency noted that it reports grants data manually using spreadsheets .

this agency noted that it needs to replace its financial system and modify supporting systems to fully comply with the data act .

another agency noted that five of the required data elements are not included in its procurement and financial assistance system .

as a result , the agency noted that it will have to modify its system's software to include these elements in order to comply with the data act .

these statements from agency implementation plans indicate that , given the vast number and complexity of systems government - wide that are potentially involved in data act implementation efforts , agencies may face a variety of challenges related to systems integration .

guidance: in their implementation plans , 19 agencies reported the lack of adequate guidance as a challenge to implementing the data act .

several agencies noted that they cannot fully determine how their policies , business processes , and systems should be modified to support data act reporting because in their view , omb and treasury have not yet issued complete , detailed , finalized data act implementation guidance on required data elements , technical schema , and other key policies .

according to these agencies , issuance of such guidance is part of the critical path to meeting their implementation goals .

for example , one agency noted that its implementation plan is highly dependent upon treasury's development of the technical schema for data act implementation .

the agency also reported that any delays or changes to treasury requirements in the technical schema will significantly affect the agency's solution design , development and testing schedule , and cost estimate .

another agency included a list of unanswered questions in its implementation plan that it wanted omb to address in guidance related to time frames , various technical requirements , level of reporting , linking systems , and tracking and reconciling data .

dependencies: eighteen agencies reported in their implementation plans that the completion of certain implementation activities is subject to actions or issues that must be addressed by omb and treasury in order for the agencies to effectively implement the data act .

some agencies also noted that they were relying on their shared service provider's implementation of the data act for agency compliance with the act .

for example , one agency noted that it will rely on its shared service provider to enhance its system , but funding may be restricted to enhance a system that the agency does not own .

another key dependency noted in one agency's implementation plan is the need for treasury to provide detailed information or requirements regarding the data formats , validation module , error correction and resubmission process , and testing schedule .

without this information , the agency noted that it cannot provide complete cost estimates , determine changes to system and business processes , and determine the level of effort and resources required to develop the data submissions .

time frames: in their implementation plans , 16 agencies identified time constraints as a challenge in implementing the data act .

for example , one agency noted that the time frame to get everything done indicated in the original guidance coupled with the complexity of the known issues makes it highly unlikely that its data act initiative will stay on target .

the agency also noted that there is no mitigation strategy for meeting the expected deadline on all aspects of the reporting because even if all tasks were worked concurrently , the schedule is not attainable for the agency .

another agency noted that the current reporting of award and awardee information to usaspending.gov is in accordance with ffata .

this information is reported within 3 days after the award was made for contracts and bi - monthly for financial assistance , while the data act requires reporting of account - level information monthly where practicable but not less than quarterly .

this agency noted that linking financial information with nonfinancial information that is reported with a different frequency creates a “moving target” and poses a challenge to linking the financial and nonfinancial data .

other challenges: agencies reported several other challenges in their implementation plans less frequently than the ones listed above .

for example , a few agencies reported challenges related to the overall policies , procedures , and processes such as governance , risk management , and training .

some agencies also noted challenges related to the level of detail required for information and data required by the data act that differ from existing financial reporting processes , including the ability to reconcile information and data to sources and official records .

finally , agencies reported concern with the quality and integrity of data in underlying agency systems and its effect on data act reporting .

our preliminary results indicate that 26 agencies identified mitigation strategies to address challenges as suggested by omb guidance .

some strategies discussed in the agency implementation plans address multiple challenges .

below are some of the more frequently cited and cross cutting mitigation strategies suggested by agencies in their implementation plans to address specific areas of concern .

communication and information sharing: in their implementation plans , some agencies reported the need for frequent communication with omb , treasury , shared service providers , vendors , and other agencies in order to keep one another updated on their implementation activities , as well as to share best practices and lessons learned throughout the process .

agencies also suggested that reviewing other agencies' implementation plans for best practices , common challenges , and solutions would facilitate information sharing .

for example , one agency pointed out that , in its view , lines of communication between treasury and the agencies must be transparent to help ensure the submission of financial data is accurate and the process for submitting it runs smoothly .

another agency noted that it believes collaboration with other agencies to share common concerns will be beneficial .

monitoring and development of guidance: in their implementation plans , agencies also discussed plans to closely monitor data act implementation guidance in order to adapt agency implementation strategies as the guidance changes .

for example , one agency noted that it will monitor and evaluate the release of data act guidance as well as data elements and technical schema in order to identify the effect on the project .

another agency noted that it plans to use its established governance structure to immediately facilitate solutions when additional guidance is provided .

further , some agencies discussed developing guidance and training materials for internal use .

for example , one agency noted that it plans to create a common set of tools by establishing a “project management toolkit” for agency leaders to ensure data act implementation needs are addressed efficiently and effectively .

leveraging existing resources: to effectively use limited resources , some agencies noted in their implementation plans the importance of leveraging available systems and human resources by reassigning staff , using subject matter experts , and multitasking when possible to maximize efficiency .

for example , one agency reported that it will leverage senior executive support to make the data act implementation a priority and see what resources might be available in the “least expected places,” as well as work on tasks concurrently .

in addition , agencies reported the need to update systems to encompass more data elements and streamline reporting .

for example , one agency reported that it plans to designate a chief data officer to oversee a multi - tiered review of agency data and implement solutions for consolidating agency data .

overall our preliminary work indicates that agency implementation plans contain valuable information on a variety of challenges in implementing the data act , including a lack of funding , inadequate guidance , tight time frames , competing priorities , and system integration issues .

agencies reported working closely with internal and external stakeholders to address these challenges as effectively as possible , but also reported that additional support from omb and treasury is needed for successful implementation of the data act .

in the report that is being issued today , we identified several design challenges involving the development of the section 5 pilot , which the data act required omb to establish .

omb created a two - part pilot that focused on two communities: federal grants and federal contracts ( procurement ) .

for grants , omb designated the department of health and human services ( hhs ) to serve as its executing agent .

on the contracting side , omb's office of federal procurement policy ( ofpp ) is responsible for leading the procurement portion working with the general services administration's 18f and others .

omb launched a number of pilot - related initiatives in may 2015 and expects to continue activities until at least may 2017 .

as the executing agent for the grants portion of the pilot , hhs has developed six “test models” that evaluate a variety of approaches to potentially reduce grantee reporting burden , including the development of a data repository for identifying common data elements and forms intended to eliminate duplicative reporting on consolidated federal financial reports .

detailed descriptions of the objectives and methodologies of each of these six test models can be found in our full report .

the data act identifies three specific requirements related to the section 5 pilot's design .

specifically , the pilot must: ( 1 ) include data collected during a 12-month reporting cycle ; ( 2 ) include a diverse group of recipients ; and ( 3 ) include a combination of federal contracts , grants , and subawards with an aggregate value between $1 billion and $2 billion .

we found that if hhs effectively implements its stated plans for the grants portion of the section 5 pilot , it is likely that it will address these three requirements .

hhs officials told us that they are still determining how to meet the requirement for total award value because they want to ensure the pool of pilot participants is as diverse and large as possible while still being legally compliant .

in addition , we found that the design of the grants portion of the pilot partially adhered to leading practices of pilot design .

we assessed the designs of the grants and procurement portions of the pilot against leading practices that we identified from our prior work and other sources regarding design of a pilot project ( see textbox ) .

leading practices for effective pilot design establish well - defined , appropriate , clear , and measurable objectives .

clearly articulate an assessment methodology and data gathering strategy that addresses all components of the pilot program and includes key features of a sound plan .

identify criteria or standards for identifying lessons about the pilot to inform decisions about scalability and whether , how , and when to integrate pilot activities into overall efforts .

develop a detailed data - analysis plan to track the pilot program's implementation and performance and evaluate the final results of the project and draw conclusions on whether , how , and when to integrate pilot activities into overall efforts .

ensure appropriate two - way stakeholder communication and input at all stages of the pilot project , including design , implementation , data gathering , and assessment .

our analysis found that five of the six grants test models had clear and measurable objectives .

in contrast , five of the six test models did not clearly articulate an assessment methodology .

only one test model had specific details about how potential findings could be scalable to be generalized beyond the context of the pilot .

furthermore , five of six grants test models provided some level of detail on how hhs plans to evaluate pilot results .

finally , hhs has engaged in two - way stakeholder communications for all six test models and has taken a number of actions to obtain input from grant recipients .

we provided our assessment of the design of the grants portion of the pilot to hhs officials , who told us that they generally concurred with our analysis and had updated their plan to address many of our concerns .

however , at the time we were conducting our audit work , hhs officials said they could not provide us with the revised plan because it was under review by omb .

we have since received an updated version of the hhs plan for implementing the grants portion of the pilot .

we plan to fully assess its contents and the extent to which it addresses our concerns in a forthcoming review that will focus on the pilot's implementation .

the procurement portion of the pilot will focus on examining the feasibility of centralizing the reporting of certified payroll .

ofpp staff responsible for this portion of the pilot told us they decided to focus on certified payroll reporting because of feedback they received from the procurement community .

toward this end , the chief acquisitions officers council has entered into an interagency agreement with 18f to design a prototype system that would centralize certified payroll data , which it expects to test in summer 2016 .

this narrow focus on certified payroll stands in contrast to the grants portion of the pilot , where hhs will explore several areas in which grantee reporting burden could be reduced .

based on our review , it is unclear how the design of the procurement portion will address the requirements set forth by section 5 of the act .

as a result of design and development delays , ofpp does not expect to be able to collect meaningful and useful data for the procurement portion of the pilot until summer 2016 .

this is after may 9 , 2016 , the date by which data collection must begin to allow for a 12-month reporting cycle before the required termination date .

further , we found that ofpp does not have a detailed plan for selecting participants that will result in a diverse group of recipients with awards from multiple programs and agencies .

while there is some documentation related to ofpp's approach for selecting participants , they do not clearly convey how the procurement portion of the pilot would specifically contribute to meeting the act's requirement regarding diversity of participants .

however , there is some documentation related to ofpp's approach for selecting participants in their draft procurement pilot plan and in a federal register notice issued on november 24 , 2015 .

for example , the draft plan identifies the federal procurement data system - next generation as the mechanism that will be used for identifying which contracts and contractors to include in the pilot .

ofpp staff also told us that they intend to cover both large and small industries .

while valuable information , it does not clearly convey how the procurement portion of the pilot would specifically contribute to meeting the act's requirement regarding diversity of participants .

in our report being issued today , we recommend that omb determine and clearly document how the procurement pilot will contribute to these requirements .

omb did not offer a view on this recommendation .

in addition , we found that the design of the procurement portion of the pilot did not reflect leading practices for effective pilot design which would help omb develop effective recommendations to simplify reporting for contractors .

ofpp staff told us that certified payroll reporting was selected as the subject of the pilot because they learned that it was a particular pain point for contractors as a result of various outreach efforts including a discovery process conducted by 18f to interview contractors , contracting officers , business owners , government employees , and subject - matter experts .

however , the draft procurement plan does not provide specifics regarding the particular objectives and hypothesis that will be tested by the pilot .

ofpp staff stated that , consistent with their view of agile practices , they intend to further refine their approach as 18f develops its prototype and additional work proceeds with the pilot .

in addition , the draft plan did not address the issue of scalability necessary to produce recommendations that could be applied government - wide , nor did it indicate how data will be evaluated to draw conclusions .

to enable the development of effective recommendations for reducing reporting burden for contractors , our report contains a recommendation that omb ensure that the procurement portion of the pilot reflects leading practices for pilot design .

omb did not did not offer a view on this recommendation .

in conclusion , almost 2 years into the data act's implementation , we are faced with a mixed picture .

given its government - wide scope and complexity , effective implementation of the act requires omb , treasury , and federal agencies to address a range of complex policy and technical issues .

although progress has been made in several areas , we have identified challenges related to the standardization of data element definitions and the development of a technical schema that , if not addressed , could lead to inconsistent reporting .

in their implementation plans , federal agencies have recognized these and other areas of concern including a lack of funding , inadequate guidance , tight time frames , competing priorities , and system integration issues .

finally , although omb appears to be on track with the design of the grants portion of the section 5 pilot , we are concerned that the design of the procurement portion of the pilot could hinder further effective implementation .

chairmen meadows and hurd , ranking members connolly and kelly , and members of the subcommittees , this concludes my prepared statement .

i would be pleased to respond to any questions you may have .

questions about this testimony can be directed to michelle a. sager , ( 202 ) 512-6806 or sagerm@gao.gov .

questions about agencies' data act implementation plans can be directed to paula rascona , ( 202 ) 512- 9816 or rasconap@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this statement .

in addition to the contacts named above , gary engel ( managing director ) ; j. christopher mihm ( managing director ) ; peter del toro ( assistant director ) ; michael laforge ( assistant director ) ; kathleen drennan ; shirley hwang ; carroll warfield , jr. ; aaron colsher ; charles jones ; thomas hackney ; and laura pacheco made major contributions to this statement .

other key contributors include mark canter ; jenny chanley ; robert gebhart ; donna miller ; diane morris ; carl ramirez ; andrew j. stephens ; and james sweetman , jr. other members of gao's data act working group also contributed to the development of this statement .

recommendations the director of omb , in collaboration with the members of the government accountability and transparency board , should develop a plan to implement comprehensive transparency reform , including a long - term timeline and requirements for data standards , such as establishing a uniform award identification system across the federal government .

1 .

to improve the completeness and accuracy of data submissions to the usaspending.gov website , the director of omb , in collaboration with treasury's fiscal service , should clarify guidance on ( 1 ) agency responsibilities for reporting awards funded by non - annual appropriations ; ( 2 ) the applicability of usaspending.gov reporting requirements to non - classified awards associated with intelligence operations ; ( 3 ) the requirement that award titles describe the award's purpose ( consistent with our prior recommendation ) ; and ( 4 ) agency maintenance of authoritative records adequate to verify the accuracy of required data reported for use by usaspending.gov .

implementation status recommendation and expect information on authoritative data sources to be included in final data act technical guidance to be made available in late spring 2016 .

2 .

to improve the completeness and accuracy of data submissions to the usaspending.gov website , the director of omb , in collaboration with treasury's fiscal service , should develop and implement a government - wide oversight process to regularly assess the consistency of information reported by federal agencies to the website other than the award amount .

1 .

to ensure that federal program spending data are provided to the public in a transparent , useful , and timely manner , the director of omb should accelerate efforts to determine how best to merge data act purposes and requirements with the gprama requirement to produce a federal program inventory .

2 .

to ensure that the integrity of data standards is maintained over time , the director of omb , in collaboration with the secretary of the treasury , should establish a set of clear policies and processes for developing and maintaining data standards that are consistent with leading practices for data governance .

open .

as part of their data act implementation efforts , omb and treasury staff told us that they have identified authoritative sources for data and are developing validation rules for spending information to be reported under the data act .

in addition , the inspector general community is working on standard audit methodologies to verify the accuracy and completeness of agency reporting .

omb and treasury staff reiterated that the ultimate responsibility for the quality of data lies with the agencies .

however , treasury's broker service will provide an additional set of validation rules to further improve the quality of data submitted to usaspending.gov .

open .

omb staff told us that identifying “programs” for the purposes of data act reporting would not be completed until after may 2017 .

however , they said they have convened a working group to develop and vet a set of options to establish a government - wide definition for program that is meaningful across multiple communities and contexts ( such as budget , contracting , and grants ) .

open .

a treasury official told us that they are in the process of drafting recommendations for a data governance process that they expect to present to the data act executive steering committee with the goal of completing a process in june 2016 or as soon as practical .

concerns are addressed as implementation efforts continue , the director of omb , in collaboration with the secretary of the treasury , should build on existing efforts and put in place policies and procedures to foster ongoing and effective two - way dialogue with stakeholders including timely and substantive responses to feedback received on the federal spending transparency github website .

implementation status continuing engagement with federal and nonfederal stakeholders through presentations at conferences , roundtable discussions , monthly stakeholder calls , and other venues .

they also noted that they have updated the website they use to solicit public comments to improve user access .

we have requested documentation of the steps omb and treasury have taken to foster ongoing and effective two - way dialogue with stakeholders including timely and substantive responses to feedback .

1 .

to capitalize on the opportunity created by the data act , the secretary of the treasury should reconsider whether certain assets — especially information and documentation such as memoranda of understanding ( mous ) that would help transfer the knowledge gained through the operation of the recovery operations center — could be worth transferring to the do not pay center business center to assist in its mission to reduce improper payments .

additionally , the secretary should document the decision on whether treasury transfers additional information and documentation and what factors were considered in this decision .

open .

treasury officials said that all appropriate assets , such as information and documentation from the recovery operations center , have been transferred to the do not pay center business center .

we requested a list of these assets as well as information on the process treasury used to determine which assets to transfer .

in commenting on a draft of this statement , treasury provided some documentation regarding the transfer of assets .

we will review this information .

1 .

to help ensure that agencies report consistent and comparable data on federal spending , we recommend that the director of omb , in collaboration with the secretary of the treasury , provide agencies with additional guidance to address potential clarity , consistency , or quality issues with the definitions for specific data elements including award description and primary place of performance and that they clearly document and communicate these actions to agencies providing this data as well as to end - users .

open .

omb staff told us that they have a draft version of the clarifying guidance out for agency comment and plan to issue this policy guidance in spring 2016 .

in addition , omb is planning to provide additional clarity to specific data element definitions by updating current reporting documents to be consistent with the new technical requirements .

2 .

to ensure that federal agencies are able to meet their reporting requirements and timelines , we recommend that the director of omb , in collaboration with the secretary of the treasury , take steps to align the release of finalized technical guidance , including the data act schema and broker , to the implementation time frames specified in the data act implementation playbook .

open .

treasury officials told us that a stable draft version 1.0 of the reporting submission specification , which is part of the data act information model schema , has been shared with agencies for comment .

it will be finalized as soon as possible .

treasury officials said they will finalize the broker once a stable version of 1.0 of the schema is complete .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

the published product may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

