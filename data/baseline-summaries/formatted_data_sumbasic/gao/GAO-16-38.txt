the federal emergency management agency ( fema ) , within the department of homeland security ( dhs ) , through its 10 regional offices is responsible for coordinating government - wide disaster response efforts and delivery of all of fema's programs and activities to state , tribal , and local partners ; nongovernmental organizations ; and citizens across the 56 states and territories .

according to fema , disaster response begins and ends with the affected fema regional office in the lead , and regional fema personnel have central roles throughout the life cycle of an incident .

we previously reported how regional coordination efforts of state and local stakeholders can enhance preparedness .

fema regions coordinate with state and local stakeholders in various ways in order to strengthen national preparedness to prevent and respond to domestic terrorist attacks , major disasters , and other emergencies .

for example , from fiscal years 2002 through 2015 , dhs awarded over $40 billion to state , local , tribal and territorial grant recipients in preparedness grants to strengthen national preparedness capabilities , and fema's regional offices are responsible for financial management and , for selected programs , programmatic management of these grants .

the regional offices also work directly with states , tribes , and territories to implement the national incident management system ( nims ) , a standardized approach to guide emergency responders at all levels of government and the private sector to coordinate efforts to respond to incidents and save lives and property .

all states and territories must agree to adopt and implement nims and certify their compliance with nims as a requirement to receive preparedness grant funding from fema .

to enhance coordination with regional stakeholders , regional offices convene regional advisory councils ( rac ) to obtain insight into emergency management issues at the state and local levels .

the post - katrina emergency management reform act of 2006 ( post - katrina act ) was enacted to address various shortcomings in the national response , including federal , state , and local preparedness capabilities , identified in fema's preparation for and response to hurricane katrina .

the post - katrina act included several requirements that address fema's regional coordination with state , local , and tribal governments .

for example , the post - katrina act called for the establishment of regional offices that would work with state , local , and tribal governments to ensure effective , coordinated , and integrated regional preparedness , among other things .

as part of this effort and to address grant management coordination challenges between headquarters and the regions , fema developed plans to transfer grant management functions from headquarters to the fema regions ( regionalization ) .

the post - katrina act also mandated that fema establish a comprehensive system to assess compliance with nims , among other things , and required that each fema regional office establish a rac with members from state , local and tribal stakeholders to advise regional administrators in each of fema's 10 regional offices on emergency management issues specific to their regions .

you requested that we review fema's efforts to enhance coordination for regional preparedness .

this report assesses the extent to which fema headquarters and regional offices have ( 1 ) addressed grant management coordination challenges between headquarters and the regions , ( 2 ) established a comprehensive system to assess nims implementation , and ( 3 ) collaborated with rac members .

to address the first objective , we gathered and reviewed relevant documentation , such as fema assessments of grant management by the grant programs directorate ( gpd ) , fema's previous delegations of grant management responsibilities to regional offices , agency task force reports on advantages and disadvantages of regionalization , fema headquarters and regional office grant management roles and responsibilities , fema documentation on regionalization pilot programs , and other memoranda and internal documents .

we also reviewed prior gao reports on regional preparedness , grant management , and consolidation of management functions .

in addition , we interviewed fema's director of the preparedness grants division within gpd and other senior gpd officials to discuss programmatic grant management as well as previous fema assessments of the impact of moving management responsibilities to fema regional offices .

we also interviewed grant management officials from 4 fema regional offices to discuss financial grant management and coordination of monitoring activities with gpd .

these offices were selected in order to provide a mix of geographic locations and whether the regional office had been selected to participate in fema grant management pilot programs .

similarly , we interviewed officials from 9 states in the 4 fema regions to discuss grant management within the states as well as interactions with fema grant management officials .

these states were selected to reflect a diversity of experiences from fema regions we chose .

while the information gained from these interviews cannot be generalized across all states , it provides useful insights into the nature of fema gpd and regional coordination with states with regard to grant management .

to address the second objective , we reviewed nims - related documents such as the nims doctrine , nims compliance guidance , nims implementation reports , and results of the nims implementation questions in the unified reporting tool ( urt ) .

we also reviewed documents on the homeland security exercise and evaluation program ( hseep ) and on preparedness grants requirements .

we compared fema's efforts in nims implementation and verification with homeland security presidential directive - 5 ( hspd - 5 ) and with language in omb's circular no .

a - 11 , regarding data validation and verification .

we interviewed officials at fema's national preparedness directorate , which includes the national integration center ( nic ) — the office responsible for coordinating and enabling nims implementation to discuss the nic's efforts in implementing nims .

to discuss nims implementation efforts at the regional and state levels , interactions between regional and state officials , and mechanisms for verifying how well nims is being implemented , we also interviewed officials from the 4 fema regional offices and 9 states mentioned above .

in addition , because of the recommendation of officials in several regional offices and states , we interviewed an official from a 10th state from within the selected fema regions .

while the information gained from these interviews cannot be generalized across all regions and states , it provided useful insights into the various efforts in implementing nims .

additionally , we analyzed all 35 full - scale exercise after - action reports ( aar ) that fema received for exercises conducted during fiscal year 2014 in the 4 regions we visited .

the purpose of the analysis was to determine if they could be used to assess the level of participants' implementation of nims .

while the results of these exercises are not generalizable to the country as a whole , they do provide useful insights into their possible use to assess nims implementation .

to address the third objective — to assess regional offices' collaboration with rac members — we interviewed officials at fema headquarters with responsibilities for regional operations and regional office officials from the 4 regions we visited .

we also reviewed fema and dhs office of inspector general ( oig ) reports with information and findings relevant to racs .

in addition , we contacted fema rac liaisons from all 10 regions by e - mail to obtain information about their racs and rac members .

we attended two rac meetings in two regions that took place during the early part of our review , and obtained documentation of agendas and other relevant materials for the racs in all 10 fema regions .

in addition , we conducted a self - administered web - based survey from may 27 through june 29 , 2015 of 110 rac members fema identified as active from all 10 regions and 77 responded , for a response rate of 70 percent .

for further information on our survey , see appendix i ; for the survey questions and results , see appendix ii .

we also used information obtained from interviews with fema headquarters and regional office officials involved in communicating and collaborating with racs .

further details on our objectives , scope , and methodology are contained in appendix i .

we conducted this performance audit from october 2014 to february 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

fema preparedness grant management is composed of different financial and programmatic management functions .

fema created gpd in april 2007 , to consolidate oversight of all fema grants .

gpd , in fema headquarters , provides subject matter expertise in response to regional office and stakeholder inquiries ; develops grant guidance ; and delivers policy , training , and systems and data analysis .

the 10 fema regions are responsible for financial monitoring , implementing corrective action plans , as well as other follow - up activities with grantees .

financial management functions include monitoring grantee expenditures , amending financial terms of grants , and closing out grants .

program management includes developing grant application packages creating program standards , and monitoring grantee activities to ensure alignment with homeland security strategies .

fema's regional offices have program management responsibility for various legacy programs primarily because they managed those programs prior to the establishment of gpd .

the largest of these legacy programs is the emergency management performance grant ( empg ) , which provided over $350 million in fiscal year 2015 to assist local , tribal , territorial , and state governments in enhancing and sustaining all - hazards emergency management capabilities .

gpd has management responsibility for the homeland security grant program , which provides more than $1 billion annually to help strengthen the nation against risks associated with acts of terrorism and other catastrophic events .

fema works with state and local stakeholders to implement nims , a comprehensive , national approach to incident management that is applicable at all jurisdictional levels and across functional disciplines and the full spectrum of potential incidents , hazards , and impacts , regardless of size , location , or complexity .

dhs established nims in 2004 to improve coordination and cooperation between public and private entities in a variety of incident management activities and provide a common standard for overall incident management .

nims implementation consists of training , using a standardized way of defining and categorizing emergency resources known as resource typing , and incorporating a standardized organizational emergency response structure called the incident command system into emergency management plans , policies and procedures , among other things .

states , tribes , and local jurisdictions are required to adopt and self - assess their level of nims implementation , and certify their compliance and report it to fema through the urt in order to receive preparedness grant funding from fema .

additionally , states receiving preparedness grants are required to develop and maintain an exercise program consistent to the degree practical with hseep in support of the national exercise program .

hseep exercises identify exercise objectives and align them to fema's 32 “core capabilities” for evaluation during the exercise .

in order to report on the required exercises , states receiving preparedness grants are required to prepare after - action reports — evaluations of performance — on core capabilities assessed in the exercise , and to submit those to fema .

fema established the nic in 2004 .

the nic , a division of fema's national preparedness directorate , is responsible for the ongoing management and maintenance of nims , including developing guidance to define and categorize the resources and job position qualifications requested , deployed , and used in incidents .

specifically , the nic is to coordinate with state and local stakeholders to develop national standards , guidelines , and protocols for incident management .

in 2008 , fema established new regional positions for federal preparedness coordinators ( fpc ) , who direct and coordinate the activities of each regional national preparedness division to ensure regional implementation of national preparedness programs , policies , goals , and objectives .

fpcs are to evaluate preparedness program activities to assess their effectiveness ; changes in risk or capability ; and the performance of preparedness program activities including after - action reports , training evaluations , lessons learned , and corrective actions .

for example , fpcs are responsible for monitoring nims compliance and implementation , in addition to other national preparedness initiatives .

further , fpcs are to proactively engage stakeholders and acquire an understanding of their preparedness efforts and also assist in the planning , design , execution , and evaluation of federal , state , local , and regional exercises .

fema regional nims coordinators act as subject matter experts regarding nims for the local , state , territorial , and tribal nation governments within their fema regions , as well as for the fema regional administrator and staff .

the post - katrina act requires that each fema regional administrator establish a rac with members from state , local , and tribal entities to provide advice on emergency management issues specific to the region .

while the post - katrina act does not specify how many members a rac should have , the law states that a state , local , or tribal government located within the geographic area served by the regional office may nominate officials , including emergency managers , to serve as members .

each of the 10 fema regional offices established a rac after the post - katrina act was enacted in 2006 .

in august 2011 , fema developed a rac charter template that each of the regional offices voluntarily adopted ; the charters require that racs meet twice annually in order to provide the types of advice on emergency preparedness in their regions to the fema regional administrators listed in the post - katrina act .

in addition to the racs , the post - katrina act also required that fema establish the national advisory council ( nac ) to ensure effective and ongoing coordination of federal preparedness efforts , among other things .

the nac advises the fema administrator on all aspects of emergency management , and incorporates state , local , and tribal governments ; nonprofit ; and private sector input in the development and revision of the national preparedness goal , the national preparedness system , the national incident management system , and other related plans and strategies .

fema's 10 regional offices are the principal conduit for delivery of preparedness programs and activities to state , tribal , and local partners ; non - governmental organizations ; the private sector ; and citizens .

such preparedness activities include , among other things , stakeholder coordination and information sharing , consulting , planning support , capability assessments and reporting , exercise performance and evaluation , and internal and external training .

figure 1 shows fema's 10 regions and the states and territories that compose each region ( the district of columbia is in region iii ) .

currently fema uses a hybrid management model for preparedness grant programs , with shared responsibilities between headquarters and the regions .

in october 2009 , in response to a congressional request , the national academy of public administration ( napa ) conducted a study and recommended that fema transfer all preparedness grant authorities to its regional offices .

similarly , in may 2010 , fema's office of policy and program analysis ( oppa ) reported that fema's hybrid grants management model created significant inconsistencies in managing preparedness grants , and recommended that programmatic management functions for preparedness grants should be transferred to the regional offices .

in september 2010 , gpd's regional implementation of grants ( rig ) task force also reported that programmatic grant management functions for grants should be moved to the 10 regional offices , because of considerations of customer service , efficiency , people , processes , and systems .

in july 2011 , we reported that gpd's efforts to regionalize management responsibilities for preparedness grants were consistent with internal control standards .

on the basis of the results of our review of fema's plans and efforts to regionalize grant management functions , we did not make recommendations at that time .

fema's deputy administrator for protection and national preparedness , in consultation with fema's administrator , decided in early 2012 against pursuing further regionalization of grant management functions , according to fema's assistant administrator for grant programs .

the assistant administrator said their decision was based on , among other things , estimates that the costs of regionalization would be greater than the annual savings identified in the earlier oppa study and fema management's belief that risks associated with the change , such as inconsistent program implementation across the regions , outweighed the potential benefits .

as a result , fema continues to use its hybrid management model for preparedness grant programs , with shared responsibilities between headquarters and the regions .

long - standing challenges associated with the separation of management functions under the hybrid model of grant management , including the lack of coordination of grant - monitoring visits , and coordination and implementation of guidance provided by headquarters officials to state officials , continue to create challenges .

in 2010 , gpd's rig task force report cited examples of how programmatic and financial monitoring visits , conducted by fema gpd staff and regional offices respectively , occurred independently of one another and were disruptive to the state emergency management agency's day - to - day operations .

in response to the lack of coordination in monitoring site visits , gpd's deputy assistant administrator sent a memorandum to staff in 2011 citing concerns that it had become “apparent gpd hq staff continue to do program monitoring visits without proper notification to the regional offices” and directing that headquarters personnel conduct all monitoring visits in conjunction with regional staff , changing the dates of any planned headquarters visits to accommodate regional staff schedules .

while the memorandum called for disciplinary action against any gpd personnel who did not follow the directive , gpd officials did not identify any instances where disciplinary action had been taken .

we also found challenges in the coordination of site visits .

officials in 3 of 9 states we talked with on grants issues stated that monitoring visits from fema gpd and the regional offices do not appear to be well coordinated .

for example , officials in 1 state said that in september 2014 , gpd and regional grants staff conducted site visits during the same week ; however , neither the gpd staff nor the regional staff knew that the other was conducting a monitoring visit that week .

the state officials stated that they had to leave one monitoring meeting early to go to another monitoring meeting by a different group of grant management staff .

similarly , regional grants officials in 2 of the 4 regions we visited said in 2015 that they may or may not receive information on monitoring activities undertaken by gpd officials , depending on who is conducting the monitoring activities .

a grant official in 1 region we visited stated that gpd conducted a site monitoring visit as recently as september 2015 , but did not inform regional staff of this visit .

regional grants management officials in all 4 regions we visited stated that not having the results of programmatic monitoring creates challenges in financial monitoring .

for example , financial monitoring may identify a significant drawdown of grant funds ; however , without program information , regions cannot determine if this corresponds to significant progress in program implementation .

further , challenges related to coordination and implementation of guidance provided by gpd ( headquarters ) officials , fema regional officials , and state officials has been a long - standing problem .

for example , in 2009 , napa identified regional challenges associated with assessment activities including grant monitoring , noting that fema regional and headquarters units “need to reduce burden on states and ensure assessments - requirements are coordinated among fema divisions and the federal sector” and that new documents from fema headquarters “typically have a short review and comment period , and adherence is often required prior to finalization.” similarly , the may 2010 rig task force report noted that “the timeliness of communication and information distribution with the grantee community needs to be improved” and the need to “formally establish regional liaisons to support the consistent prioritization of communication within gpd and with grantees.” we found that these issues related to coordinating guidance provided by headquarters officials to state officials continue to create challenges .

officials from all 4 fema regions we visited said that gpd officials had provided guidance to state grantees that contradicted guidance given by the regional staff .

further , officials in 2 of the 4 regional offices we visited stated that incorrect guidance given by gpd officials to state grantees resulted in deficiencies during financial monitoring conducted by regional grants personnel .

specifically , according to fema grant management officials in 1 region , a grantee , at the advice of gpd officials , shifted funds from one grant program into other grant programs , but regional grants personnel later found , as part of their financial monitoring , that this was a violation of regulations and required that the funding be returned .

similarly , fema grant officials in another region stated that a new grantee that received transit grants drew down the entire grant amount soon after the grant was awarded , which is a violation of fema grant management regulations .

regional officials asked the grantee to return the funds ; however , the grantee stated that gpd officials had told him he could draw down these funds .

regional officials added that had the grantee not returned the funds , the next step would have been to do an official collection ; however , regional offices do not have the authority to do this because the grant program is managed from fema headquarters by gpd .

officials from 3 of the 9 states we visited told us that they had received contradictory information from regional staff and gpd staff regarding the management of grant programs .

gpd officials agreed that there were continuing opportunities to improve coordination and communications in their management of preparedness grants and said that fema had taken steps during the course of our review to facilitate coordination and communication .

for example , gpd officials said that they had taken steps to improve coordination of site visits and that , beginning in fiscal year 2013 , gpd made integrated financial and programmatic monitoring a priority , and incorporated this into its monitoring plans .

according to fema's fiscal year 2014 grants monitoring plan , gpd officials are to contact regional grant staff when monitoring activities are initiated and document this interaction .

gpd officials did not provide any documentation that such coordination had occurred .

nonetheless , they identified two joint gpd and regional office monitoring visits that took place during the summer of 2015 ( at the request of the regions ) .

gpd officials also noted that , in a february 2015 meeting with regional officials , gpd and the regional offices agreed to the following: elevate grant - related issues to regional administrators and to the assistant administrator for grant programs , provide regional grants staff visibility on programmatic grant reviews performed by gpd staff , conduct desk reviews in coordination with the regions and provide copies of the final reports to the regional offices , provide gpd's annual monitoring plan to the regional offices and conduct joint monitoring of the same states for programmatic and financial issues when possible , provide quarterly analytical reports of grant - monitoring - related issues to all regional offices , and schedule regular calls between gpd management and regional grants division directors .

these most recent efforts to improve coordination of preparedness grant management functions are not significantly different from the historical efforts gpd has taken .

for example , gpd cited monthly coordination calls between gpd and the regional offices as a coordinating effort meant to address challenges we identified .

however , fema also cited these calls as a coordination mechanism in 2012 and noted that these calls had been a recurring effort since 2008 .

similarly , providing copies of gpd's annual monitoring plan and copies of reviews performed by gpd do not appear to have resolved the underlying challenges associated with gpd's hybrid grants management model .

gpd officials also said they intend to look at fema's overall grants monitoring efforts to see what can be done to improve the program for fiscal years 2016 and beyond , including risk assessments , general assessments , on - site desk reviews , reports with real - time data and metrics , and corrective action plans .

however , fema has not developed a plan with time frames , goals , metrics , or milestones for how and when it will address long - standing coordination challenges associated with the existing hybrid grants management model identified in previous fema assessments and in our review .

according to fema's assistant administrator , gpd has involved the regions in performance measure development since september 2011 and has communicated the measures and results to the regions .

these performance measures include , among other things , percentage of preparedness grant funds monitored and percentage of grants award determined to be low risk .

however , these performance measures do not address the deficiencies in coordination identified in our review .

according to effective program management practices , specific goals and objectives should be conceptualized , defined , and documented in the planning process , along with the appropriate steps , time frames , and milestones needed to achieve those results .

given the longstanding coordination challenges , establishing a plan with time frames , goals , metrics , and milestones could help fema headquarters and regional offices address these challenges .

the nic uses a self - assessment tool to determine if all states and territories have adopted and implemented nims elements into their emergency response planning and training .

the nic relies on a self - assessment tool , as the post - katrina act requires that fema develop an assessment system to determine compliance with nims but does not require that fema physically verify compliance .

since 2005 , all 56 states and territories have been required to meet nims compliance and implementation requirements to be eligible to receive federal preparedness grants .

the nic began using the latest version of its tool for states to submit self - assessments — the urt — in 2013 .

in the urt spreadsheet , states and territories fill in responses to a series of questions aimed at determining the level of nims implementation .

generally , states and territories gather this information from their subjurisdictions and consolidate the information at a state level to report to fema .

 ( for a list of questions , see app .

iii. ) .

although states generally report high levels of nims implementation in their urts , officials from all four fema regional offices we spoke with and from 9 of the 10 states we spoke with said that the nims self - assessments are perfunctory and do not necessarily measure whether , or how well , nims is being implemented .

for example , in fiscal year 2013 , 100 percent of the states and territories reported having “formally adopted” nims , and incorporated nims principles and concepts into training and exercises .

similarly , in fiscal year 2014 , states and territories reported that 93 percent of their subjurisdictions had formally adopted nims , about 91 percent had incorporated nims concepts and principles into training , and about 93 percent incorporated nims into exercises .

fema regional and state officials we spoke with said there is an incentive to report compliance with nims regardless of the actual status of implementation since it is a requirement for receiving preparedness grants .

according to preparedness grant guidance , there is no requirement for states to verify nims compliance or implementation at the subjurisdiction level .

however , of the states we spoke with on nims implementation , 1 had implemented its own nims compliance check program .

specifically , a state emergency management official in 1 state we spoke with said that his state has initiated its own reviews of nims implementation and found that some reporting of full nims implementation by subjurisdictions were questionable .

for example , in one subjurisdiction , state officials found the following: the subjurisdiction could not produce training records to show that emergency management personnel had received nims training .

the requirement to incorporate nims principles into the subjurisdiction's emergency operations plans had not been completed .

there were no records of exercises or corrective action plans available to identify if nims had been incorporated into the subjurisdiction's exercise program .

while this particular example cannot be generalized to other states , it shows that in some cases , subjurisdictions within one state with a nims compliance check program are reporting levels of nims implementation that may not fully reflect the status of local nims efforts .

officials from all 4 regional offices and from 8 of the 10 states we spoke with said that the best way to assess how well nims has been implemented is by assessing states' performance in preparedness exercises and real - world events .

they all agreed that if nims principles have been well implemented , responses to disasters will be more effective because the objective of nims is to ensure that all levels of government across the nation work together efficiently and effectively using a single , national approach to an incident .

further , according to the nims doctrine , using a comprehensive national approach improves the effectiveness of emergency management personnel's responses to the full spectrum of potential incidents and hazard scenarios , including natural hazards , terrorist activities , and other manmade disasters .

to capture information on states' performance during preparedness exercises and real - world events , states generally develop after - action reports .

the empg grant program , under which all states and territories receive funding , specifically requires participants to develop and maintain an exercise program , consistent to the degree practical with hseep in support of the national exercise program , and to conduct preparedness exercises and submit aars that evaluate the state or territory's performance during the exercises based on one or more core capabilities .

under hseep — which provides a common approach to designing , developing , conducting , and evaluating exercises — planners identify exercise objectives and align them to core capabilities .

in some cases , the exercise objectives test one or more of the nims elements identified by fema that should be incorporated into training .

as such , exercises could also allow for identifying areas of needed improvement in nims implementation , one of the legislative bases for establishing the national exercise program .

fema regional officials we spoke with stated that some of fema's national core capabilities are good proxies for how well nims is being implemented , and that aars — which states submit to the national exercise division — can provide insight into the level of nims implementation when certain of these core capabilities are assessed .

nic officials stated if an exercise objective includes testing an element of nims , then it is possible to assess nims implementation .

for example , evaluating a state's performance related to the core capability of operational coordination could include as an exercise objective to evaluate the command and control of an incident according to nims principles .

similarly , the core capability for operational communications could provide an assessment related to the nims elements for interoperability of compatible communications , technology , and information management .

we analyzed aars for 35 full - scale exercises that were conducted in fiscal year 2014 in 4 fema regions , 33 of which assessed at least one , if not two or all three , of the core capabilities we identified as proxies for nims elements — operational coordination , operational communication , and public information and warning .

of the 35 reports we reviewed , 30 assessed operational coordination , 22 assessed operational communication , and 12 assessed public information and warning .

generally , for the capabilities assessed , the aars identified strengths as well as issues and challenges in performing related activities and tasks .

specifically , 24 of the 30 exercises that assessed operational coordination , 21 of the 22 exercises that assessed operational communication , and 8 of the 12 exercises that assessed public information and warning identified areas for improvement with those capabilities .

while exercises are meant to assess the ability to meet exercise objectives by documenting strengths , areas for improvement , core capability performance , and corrective actions in an aar , some of the aars documented problems with nims - related exercise objectives , indicating that there is room for improvement in nims implementation .

for example , four of the aars found that an incident command system ( ics ) was not established among responding agencies , even though nims calls for using such a structure .

similarly , another aar concluded that responding staff were unfamiliar with their position - specific roles and responsibilities , even though nims calls for emergency management and response personnel to have a clear understanding of their roles and responsibilities .

the report noted that the staff displayed difficulty in monitoring , gathering , receiving , organizing , and sharing incident information — all activities that implementation of nims is designed to facilitate .

another exercise evaluating operational communication found that there was no communication among the different law enforcement agencies and officers during the exercise .

these examples demonstrate that aars can provide a basis for fema to develop a more comprehensive and sophisticated understanding of states' nims implementation , and suggests that there is room for improvement in nims implementation for some jurisdictions .

nic officials said they do not verify the self - reported nims implementation information that states submit because of the scope and breadth of the information .

however , in reviewing aars to help inform fema's understanding of nims implementation , fema regional office staff could be in a better position to assess how well states have actually implemented nims , as regional staff have more direct responsibilities related to states' nims implementation .

specifically , fpcs — who lead regional efforts to implement the national preparedness system across the federal , state , tribal , and local jurisdictional levels — are responsible for monitoring nims compliance and implementation .

fpcs are also responsible for assisting in planning , design , execution , and evaluation of exercises .

in addition , each regional office has a nims coordinator who is responsible for working with states to provide nims information and technical assistance to support , facilitate , and enhance their implementation of nims .

one fpc stated that officials in his region review state aars within the region to identify needed corrective actions that could be taken by states .

similarly , one regional nims coordinator developed a checklist to perform nims implementation state monitoring visits and said he visits 2 states each year in his region to ask questions about implementation of various nims principles and provide assistance .

however , while some of these officials have taken independent steps to assess some level of nims implementation , the regional offices we spoke with do not systematically assess states' level of nims implementation by , for example , reviewing aars because there are no policies or procedures that call for these activities .

specifically , while states are to submit aars to fema's national exercises division , and to the regional empg program manager , as a requirement for receiving empg grants , fpcs and nims coordinators are not required to review them to provide validation of the nic's nims implementation assessment .

fema regional office officials we spoke with , along with several state emergency management officials , agreed that assessing nims implementation using aars could provide fema a way to further assess and elaborate on the information states and territories currently provide .

for example , the national exercise division , another division within the national preparedness directorate , conducted an assessment of nims in 2013 by reviewing aars and found that failures in nims performance were predominantly due to failures in implementation of nims .

the report recommended , among other things , that the agency modify existing training and exercises to allow responders to integrate nims concepts and improve assessments of the ics ( as a component of nims performance ) by incorporating relevant principles as criteria of performance .

according to a nic official , fema has been working on the recommendations and expects to implement the actions when fema releases an update to the nims doctrine .

finally , while the national exercises division did assess nims implementation issues in 2013 by analyzing aars , regional offices and the nic do not systematically or regularly assess nims implementation .

using aars to systematically assess nims implementation over time could allow the regions and the nic to identify recurring issues in jurisdictions .

hspd - 5 calls for fema to ( 1 ) establish a mechanism for ensuring ongoing management and maintenance of the nims , including regular consultation with other federal departments and agencies and with state and local governments , and ( 2 ) develop standards and guidelines for determining whether a state or local entity has adopted nims .

in addition , omb circular no .

a - 11 states that data limitations can lead to bad decisions resulting in lower performance or inaccurate performance assessments , and data limitations can include imprecise measurement and recordings , incomplete data , and inconsistencies in data collection procedures .

consistent verification and validation of performance data support the general accuracy and reliability of performance information , reduce the risk of inaccurate performance data , and provide a sufficient level of confidence to congress and the public that the information presented is credible as appropriate to its intended use .

as we have previously reported , fema's reliance on self - reported data from states and lack of verification for fema preparedness grants has presented reliability concerns .

while aars are also self - reported , they use a narrative format that includes analyses of the various aspects of actions following an exercise or actual event .

state officials from two states we spoke with said that they review aars within their state in order to evaluate nims implementation .

for example , officials from one state said they use aars to identify gaps in nims implementation so they can align resources to support better implementation .

this is because exercises enable stakeholders to identify both capability gaps and areas for improvement .

further , the purpose of exercises is to provide a low - risk environment to test capabilities , familiarize personnel with roles and responsibilities , and foster meaningful interaction and communication across organizations .

as such , evaluating aars could provide an additional opportunity to look for areas of nims implementation that could be improved .

according to nic officials , they meet the requirements of hspd - 5 through ongoing discussions with nims stakeholders , including state emergency managers , to ensure ongoing management and maintenance of nims , and by obtaining self - assessment information provided by states on nims implementation in the urt that provides standards and guidelines .

additionally , in order to meet the requirements of hspd - 5 , in 2006 the nic developed implementation guidance through the nims compliance objectives and metrics for states and territories , tribal nations , and local governments , which was last updated in 2010 .

however , nic officials said that , given the large number of states and their jurisdictions that have adopted nims , any efforts to validate the information states provide on their implementation efforts would be prohibitively difficult and costly .

while verifying each state and jurisdiction's self - reported information may not be feasible , states are already required to develop aars under the epmg program , which could provide a source in addition to the urt by which fema could assess progress made on implementation of nims , as the 2013 assessment by the national exercise division demonstrates .

states are already required to develop aars following their preparedness exercises , based on grant program requirements .

moreover , fema's regional offices have multiple positions with responsibilities for nims implementation , as well as preparedness exercises .

therefore , developing policies and procedures for regional office staff to review and assess information on states' nims implementation , gleaned through a review of exercise aars , would not only help fpcs and nims coordinators better meet their responsibilities for supporting and enhancing regional preparedness , but also provide the nic a means , in addition to the urt , to further evaluate states' self - reported assessments of nims implementation .

as described earlier , the post - katrina act required that each fema region establish a regional advisory council ( rac ) in order to provide the types of advice on emergency preparedness in their regions listed in the post - katrina act to the fema regional administrators .

rac members who responded to our survey reported that they found rac meetings to be a useful collaborative experience , allowing them to obtain good information , have interactions with other rac members and fema officials , and to offer advice to fema on regional emergency - related issues .

for example: about 90 percent said that the rac meetings were moderately or very effective in providing information on how to make the region better prepared for emergencies ; the information communicated at rac meetings was moderately or very effective ( 89 percent ) ; coordination between the rac and the regional office was moderately or very effective ( 89 percent ) ; the quality of the communications from their fema regional office was good or excellent ( 91 percent ) ; their regional office was effective in asking members about their concerns or suggestions about emergency preparedness issues in their region ( 93 percent ) ; and their participation was encouraged ( 93 percent ) .

about 81 percent said that the meetings provide a useful forum in which to offer advice to fema on regional emergency - related issues ; most said that they likely would serve another term , if invited ( 81 percent ) ; the overall preparedness of the region increased moderately or greatly as a result of rac meetings ( 69 percent ) ; and , in general , the meetings were well run , on time , on topic , and relevant to regional emergency - related issues ( 89 percent ) .

many of those fema regional offices that convene rac meetings ( see below for a discussion of the variations in the occurrence of meetings ) prepare and send out agendas in advance of the meetings and collaboratively involve rac members in planning .

conducting early outreach to participants and stakeholders to identify shared interests is an effective collaborative implementation approach identified in gao's implementation approaches used to enhance collaboration in interagency groups .

rac members who responded to our survey reported that they appreciated the information provided to prepare them for the rac meetings .

for example , 96 percent reported that they were notified in advance about the meetings , 86 percent stated that the agendas provided information necessary for preparing for the rac meetings , and 79 percent believed that distributing the minutes after the meeting was a moderately or very effective approach .

although the rac charters adopted by each of the 10 regions require that their racs meet twice annually , some racs have not met routinely in recent years to collaborate with fema regional officials to provide advice and input from regional stakeholders .

the dhs inspector general reviewed the fema region ix office in 2012 and the region v office in 2015 and concluded that because the racs in those regions had not met for a period of years , fema's regional offices could be “missing opportunities to identify and remediate weaknesses or deficiencies in preparedness , protection , response , recovery , and mitigation activities.” figure 2 summarizes the number of rac meetings in each region since 2007 through august 2015 ( including both in - person meetings and meetings conducted as interactive webinars ) .

one region cited the fact that they did not have funds to reimburse rac members for travel expenses , and another cited travel costs as a problem for rac members in a region as geographically large as theirs .

another region stated that while they paid for the travel expenses , this necessarily had to come from their available funds and that therefore , it meant having less for other potential needs .

in our survey of rac members , respondents cited several reasons why they did not attend rac meetings .

for example , 68 percent of respondents cited scheduling commitments and conflicts , 26 percent cited insufficient or no funding for travel , and 11 percent said that the meeting locations were inconvenient .

some rac members said that their rac should definitely or probably meet more frequently ( 41 percent ) , while others did not ( 30 percent said “probably” or “definitely not” and 23 percent said they were unsure or had no opinion ) .

in open - ended comments on rac meetings attended by rac members , 6 rac members stated that they would prefer having more in - person meetings versus teleconferences or videoconferences .

fema region v , in which the rac did not meet for several years , took steps starting in august 2014 to address a lack of interest from the majority of the members .

for example , regional officials invited rac members to other regional meetings with other federal agencies — a process used by some other regions .

in 2015 , the regional office resumed having rac meetings , with one taking place in mid - january with 11 of 12 members attending .

according to the regional rac liaison , the high attendance was the result of the regional administrator having personally reached out to the individuals who had been recommended for rac membership and inviting them to participate .

he said this individualized communication with each person on the team helped to instill interest and motivate involvement in the meeting , in the view of the liaison , and that the personal involvement of the regional administrator makes the rac more effective .

the post - katrina act requires fema regional offices to establish racs in order to provide input to each regional administrator on regional emergency management issues by identifying any geographic , demographic , or other characteristics peculiar to any state , local , or tribal government within the region that might make preparedness , protection , response , recovery , or mitigation more complicated or difficult , among other things .

additionally , gao's key considerations for implementing interagency collaborative mechanisms identified meetings that bring stakeholders together as an effective collaborative practice , noting particularly that such relationship - building is vital in responding to disasters .

by routinely obtaining input from rac members — whether through in - person meetings or via remote connection or other means — fema regional offices could better ensure they are identifying geographic , demographic , or other issues within the region to enhance emergency preparedness .

additionally , for those fema regional offices that face participation challenges , assessing the reasons for these barriers and identifying targeted solutions , such as consistently offering remote participation , or , as used by one region , direct communication from the regional administrator to rac members , could better ensure they are able to obtain such input from the racs effectively and on a regular basis .

rac members who responded to our survey generally indicated that fema regions were responsive to their suggestions .

seventy - five percent of the rac members said that they had made suggestions concerning issues related to emergency management at rac meetings or between rac meetings ; 79 percent stated that their overall sense that fema was listening to their concerns increased moderately or greatly during the time on which they had served on their rac ; and 74 percent stated that fema was acting to address their concerns .

sixty - seven percent of the respondents said fema had taken action to a moderate , great , or very great extent in response to suggestions made by rac members .

fema rac liaisons we contacted by e - mail reported having taken action in response to rac member suggestions .

specifically , 9 of the 10 fema rac liaisons reported that input from their racs had either led to changes in specific fema policies or led to generally better informing fema about members' concerns .

for example , at the suggestion of their racs , regional offices created a regional training and exercise coordination website to share information ; forwarded a suggestion from a rac to revise fema national policy to include ice storms as a reimbursable emergency ; and developed and distributed monthly preparedness themes to help synchronize federal , state , and local officials' focus on common topics , among other things .

although some fema regional offices have incorporated various recommendations made by rac members , 50 percent of the respondents in our survey of rac members said that fema should provide more detailed feedback to them on suggestions or advice they made at rac meetings .

of the 10 regional offices , 7 reported that they tracked outcomes of rac efforts ; 3 said they posted suggestions on fema's internal website ( which is not accessible to non - fema employees , including rac members ) , and 4 said they used e - mail to forward meeting notes to rac members .

one rac member from our survey commented on the need for a tracking system for the status and resolution of issues raised , and another rac member commented on the need for better follow - up on recommendations .

developing a mechanism , such as a listserve or a dedicated website , to periodically notify all rac members in all 10 regions about the status of suggestions made by racs to regional administrators or to fema could help fema keep rac members aware of the status of their recommendations and thereby address the concerns of those who wanted more detailed feedback .

in march 2014 , fema's nac identified the need for fema to re - examine the outcomes of its existing regional committees and councils , including the racs .

reporting the outcomes of racs' suggestions to the nac could help fema address this identified need .

the nac's recommendation to fema also reflects the key considerations for implementing interagency collaborative mechanisms found in gao's implementation approaches used to enhance collaboration in interagency groups .

as the report stated , many of the meaningful results that the federal government seeks to achieve , such as national preparedness , require the coordinated efforts of more than one federal agency , level of government , or sector .

implementation approaches for interagency collaborative mechanisms include developing a plan to communicate outcomes and track progress , and developing methods to report on the group's progress that are open and transparent .

as noted previously , while some regions have taken steps to track outcomes of rac efforts , none of the regional offices has a process for regularly providing feedback on the status of recommendations .

providing feedback to rac members on their suggestions could enhance fema regional offices' collaboration with their racs .

the nac , established by the post - katrina act , incorporates state , local , and tribal governments , nonprofit , and private sector input with regard to improving emergency preparedness and response to natural and manmade emergencies .

although almost two - thirds of rac members who responded to our survey said they believed their concerns were communicated by fema to the nac , some rac members commented that they wanted more feedback on the nac's responses to suggestions .

however , fema has not established policies and procedures to communicate racs' regional concerns directly to their national - level counterparts on the nac , as proposed in 2011 .

almost two - thirds of respondents said fema was ( very or moderately ) effective in communicating rac concerns and issues to the nac .

however , in open ended comments , six rac members stated they that would like to receive more information about the nac and what it was addressing .

in september 2010 , a fema local , state , tribal , and federal task force for improving national emergency preparedness recommended that communications between the racs and the nac be more robust .

specifically , the task force recommended that racs receive policy information briefings directly from the nac and provide input directly to the nac in order to provide local , state , tribal , and territorial officials with influence across stages of the preparedness policy process and to create an informational exchange between the nac and the racs to make local , state , tribal , and territorial officials fuller partners in the preparedness policy process .

in june 2011 , fema responded to the recommendation from the task force with an implementation plan , stating that , by november 24 , 2011 , it would revise its policies and procedures to systematically link the racs to each other , the nac , and fema headquarters , to help racs influence national emergency management policy .

fema officials said they held a meeting of all the rac regional liaisons in august 2011 to propose options to create a “nac - rac interface,” among other things .

however , they did not identify any additional subsequent actions they had taken to implement the plan .

for example , although fema stated that the august 2011 rac liaison meeting had resulted in adding a “rac report out” by a regional administrator as a standing agenda item for the nac meetings , none of the nac meeting agendas for any nac meeting between august 2011 and september 2015 showed “rac report out” as an agenda item .

in addition , our review of the minutes for all the nac meetings held between august 2011 and september 2015 found only an occasional mention of issues of concern to racs reported on by fema regional administrators or others present .

officials from fema's office of regional operations said that individual racs can transmit their concerns to the nac , such as by letter or through fema .

the fema office of the nac provided a detailed summary of the status of recommendations made by the nac to fema since 2008 to nac members at the september 2015 nac meeting .

however , this summary did not include the status of recommendations or suggestions or communications made by racs to the nac .

as such , these processes do not appear to provide a systematic way in which to ensure that issues raised in rac meetings are consistently brought to the attention of the nac for its consideration or to provide a consistent feedback mechanism for rac members .

in november 2015 , fema's office of the nac said that although it is precluded from establishing a formal mechanism between the racs and the nac , it is working with fema's office of regional operations to informally enhance coordination between the nac and the racs , such as distributing nac recommendation memoranda with the racs for informational purposes .

establishing policies and procedures , as suggested by fema's task force and 2011 implementation plan , to enhance coordination and communication between the racs and the nac could create greater opportunities for regional insights about preparedness to inform national preparedness policies and a two - way informational exchange between the nac and the racs to make local , state , tribal , and territorial officials fuller partners in the preparedness policy process .

because of the key role fema's regional offices play in national disaster preparedness efforts , effective regional coordination and collaboration between fema headquarters , fema regions , and state and local stakeholders is essential .

multiple external and internal assessments and our work have identified challenges , such as lack of coordination in grant - monitoring visits and inconsistent guidance , in fema's grant management .

these challenges continue to hamper the effectiveness of interactions between fema and state officials in implementing the preparedness grants program .

a plan with time frames , goals , metrics , and milestones for addressing these challenges would better enable gpd officials to monitor and improve their efforts to resolve long - standing problems in coordination of monitoring activities and the consistency of guidance given to state grantees .

regarding oversight of fema's efforts to implement the national system for managing incidents , there are opportunities to access more sophisticated and comprehensive information using fema regional staff to better assess nims implementation .

further , using aars that are already required to be developed and submitted could provide a better opportunity to assess nims implementation , including areas of success as well as areas where improvement is needed .

however , without policies and procedures that call for systematically evaluating these reports , regional offices and the nic are missing a key opportunity to better assess national nims implementation , which could enhance regional preparedness .

finally , fema regional offices could more consistently and systematically take steps to fully leverage racs that can provide important inputs to national preparedness efforts .

for example , by ensuring that racs provide feedback to rac members on the status of their recommendations , fema could enhance racs' collaborative efforts and satisfaction of rac members .

similarly , by enhancing racs' connectivity with the nac , fema could increase the potential value of regional coordination and collaboration and the resulting contributions to regional preparedness efforts .

to promote more effective grant management coordination , the secretary of homeland security should direct the fema administrator to develop a plan with time frames , goals , metrics and milestones detailing how gpd intends to resolve longstanding challenges associated with its existing hybrid grants management model , which divides responsibilities between regional and headquarters staff .

to enable more sophisticated and comprehensive awareness of states' nims implementation , the secretary of homeland security should direct the fema administrator to develop policies and procedures for regional staff to review aars from preparedness exercises within their region , and headquarters staff to review these evaluations in order to have a better understanding of nims implementation .

to enhance the value of racs , the secretary of homeland security should direct the fema administrator to take the following three actions: 1 .

ensure that all regional offices routinely obtain input — whether in person , by teleconference or by other remote connection — from their rac members on ways to enhance overall emergency preparedness in their regions .

in cases where rac member participation is low , regional offices should assess and identify targeted solutions for increasing member participation , such as offering remote participation or alternative forums ; 2 .

develop a mechanism to update rac members on the status of recommendations made by racs to fema ; and 3 .

establish processes for enhanced coordination and communication between the racs and the nac .

we provided a draft of this report to dhs for comment .

dhs provided technical comments , which we incorporated as appropriate .

on january 15 , 2016 , dhs also provided written comments , reproduced in full in appendix iv .

dhs concurred with four of our recommendations and did not concur with one .

dhs did not concur with our first recommendation that the secretary of homeland security direct the fema administrator to develop a plan with time frames , goals , metrics , and milestones detailing how gpd intends to resolve longstanding challenges associated with its existing hybrid grants management model .

in its comments , dhs stated that it disagreed with gao's characterization of longstanding challenges in managing preparedness grants .

as we stated in the report , multiple assessments dating back to 2009 have reported challenges with the hybrid model that splits management of preparedness grants between fema's headquarters and regional offices .

as also noted in the report , officials from 4 fema regional offices and officials from 3 states within those regions provided numerous examples of a lack of coordination between headquarters and regional staff in managing preparedness grants , including instances that took place in 2014 and as recently as september 2015 .

based on our review of the past assessments and the audit work we performed , we believe that these long - standing challenges have yet to be resolved .

in its written comments , dhs also stated that fema already empowers its ten regions to coordinate and communicate with headquarters and other regional offices to facilitate working relationships .

while fema has taken various actions since 2008 to improve coordination related to preparedness grants — some actions as recent as february 2015 — these steps have not resolved these challenges , as described in the report .

when we spoke with gpd officials in september 2015 , they agreed that there were continuing opportunities to improve coordination and communications in their management of preparedness grants .

therefore , we continue to believe that fema would benefit from a more strategic approach that a plan , with time frames , goals , metrics , and milestones detailing how officials intend to resolve longstanding challenges associated with the existing hybrid model , could provide .

dhs also expressed concern about the wording of our recommendation and how the recommendation , as worded , could be closed .

specifically , dhs stated that fema is not aware of nor did the recommendation provide any specific criteria that could be used to gauge the success of any proposed plan .

while we recommended that dhs develop a plan with time frames , goals , metrics , and milestones for resolving its longstanding coordination challenges , we did not prescribe specific actions to address these challenges .

however , our work across the federal government has identified implementation approaches used to enhance collaboration that could inform gpd officials' efforts to clearly define short - term and long - term outcomes and track and monitor their progress .

nevertheless , fema could implement this recommendation by developing a plan and we believe that doing so would address the intent of this recommendation .

regarding our second recommendation that the secretary of homeland security direct the fema administrator to develop policies and procedures for regional staff to review aars from preparedness exercises within their region , and headquarters staff to review these evaluations in order to have a better understanding of nims implementation , dhs concurred and said it recognizes that joint efforts by regional and headquarters staff are essential to enable more sophisticated and comprehensive awareness of nims implementation .

however , dhs expressed concerns about overstating the value of aars as a means to improve understanding of nims implementation .

specifically , dhs stated that fema does not agree that the “best way to assess how well nims has been implemented is by assessing states' performance in preparedness exercises and real - world events.” as noted in the report , most all of the officials we spoke with believed that the current method of determining nims implementation — states self - certification via the urt — was not an effective method of determining nims implementation , and officials in all of the fema regions and 8 of the states we interviewed said that looking at how effectively a jurisdiction responds during an exercise or real world event is the best way to assess nims implementation .

dhs also stated that the extent to which a jurisdiction has implemented nims is nuanced and therefore impossible to assess accurately from an aar .

the report does not suggest that reviewing aars would give a comprehensive and definitive assessment of nims implementation but rather that it could provide fema an additional way to assess and elaborate on the information states currently provide .

in fact , fema used aars to conduct an assessment of nims in 2013 , which resulted in some recommendations to help improve nims implementation .

finally , as we have previously reported , the post - katrina act requires fema to carry out the national exercise program .

the act established the program , among other things , as a means for fema to test and evaluate nims implementation efforts .

as a result , we continue to believe that aars , an essential part of the national exercise program , are an important part of fema's efforts to assess nims implementation and we added a reference to this requirement to our final report .

dhs did not identify any specific steps to address this recommendation but said that the national preparedness directorate would work with regional nims coordinators and the states to explore options during calendar year 2016 , with potential changes to be implemented in calendar year 2017 .

in its written comments , dhs concurred with our third , fourth , and fifth recommendations related to enhancing the value of racs .

specifically , regarding the third recommendation that the secretary of homeland security direct the fema administrator to ensure that regional offices routinely obtain input from their rac members , dhs concurred and stated that the regions will conduct two meetings a year with their rac members ; that a rac coordinator within each region will be responsible for the oversight of these meetings ; and that open dialogue will be encouraged between rac members and the regions , with each region establishing a rac coordinator to facilitate this communication .

if implemented as planned , these actions should help address the intent of the recommendation to ensure that regional offices routinely obtain input from their rac .

regarding the fourth recommendation that the secretary of homeland security direct the fema administrator to develop a mechanism to update rac members on the status of recommendations made by racs to fema , dhs concurred and stated that it will build into each rac meeting a briefing by regional personnel on the status of recommendations , if any , made during the previous meeting .

the regional administrator or rac coordinator within the region will be responsible for the brief .

additionally , if rac members are not satisfied with the implementation of rac recommendations , it will be expected that the regional office will provide information on why a specific recommendation was not adopted or why implementation is delayed .

dhs further stated that each region may have its own method of dispensing updates to its rac members between meetings , including monthly email updates , posting on their website , or informational calls .

if implemented as planned , these actions should help address the intent of the recommendation to update rac members on the status of its recommendations to fema .

regarding our fifth recommendation that the secretary of homeland security direct the fema administrator to establish processes for enhanced coordination and communication between the racs and the nac , dhs concurred and stated that regional administrators will continue to attend nac meetings and provide fema regional updates that include rac activities with the regions .

moreover , regional coordinators will ensure that rac members are aware of any nac meeting occurring in their own region , and that the rac sharepoint site will be used as a platform to update rac coordinators on impending nac meetings to share with their rac members .

if implemented as planned , these actions should help address the intent of the recommendation to establish processes for enhanced coordination and communication between the racs and the nac .

we are sending copies of this report to secretary of homeland security , appropriate congressional committees , and other interested parties .

this report is also available at no charge on gao's website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 404 ) 679-1875 or at curriec@gao.gov .

contact points for our office of congressional relations and office of public affairs can be found on the last page of this report .

other major contributors to this report are listed in appendix v .

the objectives of this study were to assess the extent to which the federal emergency management agency ( fema ) headquarters and regional offices have ( 1 ) addressed grant management coordination challenges between headquarters and the regions ; ( 2 ) established a comprehensive system to assess national incident management system ( nims ) implementation ; and ( 3 ) collaborated with regional advisory council ( rac ) members .

to address the first objective , we gathered and reviewed relevant documentation , such as fema assessments of grants managed by grant programs directorate ( gpd ) , fema's previous delegations of grant management responsibilities to regional offices , agency task force reports on advantages and disadvantages of regionalization , fema headquarters and regional office grant management roles and responsibilities , fema documentation on regionalization pilot programs , and other memoranda and internal documents .

we also reviewed prior gao reports on regional preparedness , grant management , and consolidation of management functions .

we interviewed fema's director of the preparedness grants division within gpd and other senior gpd officials to discuss programmatic grant management as well as previous fema assessments of the impact of moving management responsibilities to fema regional offices .

we also interviewed grant management officials from 4 fema regional offices — regions iii , iv , vi , and ix — to discuss financial grant management and coordination of monitoring activities with gpd .

these offices were selected in order to provide a mix of geographic locations , types of disasters typically experienced , and whether the regional office had been selected to participate in fema grant management pilot programs .

similarly , we interviewed officials from 9 states or territories ( arkansas , california , florida , georgia , louisiana , nevada , texas , virginia , and washington , d.c. ) from the 4 fema regions to discuss grant management within the states as well as interactions with fema grant management officials .

these states were selected to reflect a diversity of experiences within the 4 fema regions we chose .

while the information gained from these interviews cannot be generalized across all states , it provides useful insights into the nature of fema gpd and regional coordination with states with regard to grant management .

to address the second objective , we reviewed nims - related documents such as the nims doctrine , nims compliance guidance , nims implementation reports , and results of the nims implementation questions in the unified reporting tool ( urt ) .

we also reviewed documents on the homeland security exercise and evaluation program ( hseep ) and on preparedness grants requirements .

we compared fema's efforts in nims implementation and verification with homeland security presidential directive - 5 and office of management and budget ( omb ) circular no .

a - 11 , regarding data validation and verification .

we interviewed officials at fema's national preparedness directorate , which includes the national integration center ( nic ) — the office responsible for nims implementation — to discuss the nic's efforts in implementing nims .

to discuss nims implementation efforts at the regional and state levels , interactions between regional and state officials , and mecha nisms for verifying how well nims is being implemented , we also interviewed officials from the 4 fema regional offices and the 9 states or territories mentioned above .

in addition , because of the recommendations of officials in several regional offices and states , we interviewed an official from a 10th state ( oklahoma ) from within the selected fema regions .

again , while the information gained from these interviews cannot be generalized across all states , it provided useful insights into the various efforts in implementing nims .

additionally , we analyzed all 35 full - scale exercise after - action reports ( aar ) that fema received for exercises conducted during fiscal year 2014 and in the 4 regions we visited .

we used the aars as they provide qualitative analysis of outcomes of exercises , which are conducted in order to identify capability gaps and areas for improvement .

the purpose of the analysis was to determine if they could be used to assess the level of participants' implementation of nims .

we did this by developing a crosswalk that linked the six nims elements listed in the urt , and that states should incorporate into exercises , to a core capability — the unit by which exercises are evaluated .

in developing this crosswalk , we found three core capabilities that we used as proxies for the six nims elements that are to be incorporated into exercises — operational coordination , operational communication , and public information and warning .

while aspects of nims implementation could be gleaned from other core capabilities , for the purposes of this analysis we used the three core capabilities identified through our crosswalk .

of the 35 reports we analyzed , 33 assessed at least one , if not two or all three , of the core capabilities we identified as proxies .

in those reports where one or more of the core capabilities were addressed , we looked to see if there were issues associated with those core capabilities , and the nature and extent of the issues , by reviewing various sections of the reports .

for the core capability of operational coordination , we also looked at the exercise objectives to see if they aligned with some element of nims components .

if an aar reported that the core capability that we assessed either was performed with some challenges , was performed with major challenges , or was unable to be performed , we included it in our count of a capability that encountered some issues .

from this we could glean the extent to which various nims elements are working well and those that still have room for improvement .

while results of these exercises are not generalizable to the country as a whole , they do provide useful insights into nims implementation in some areas .

to address the third objective , we interviewed fema headquarters and regional office officials and analyzed fema and department of homeland security ( dhs ) office of inspector general ( oig ) reports with information and findings relevant to racs .

we attended two rac meetings in 2 regions that took place during the early part of our review , and obtained documentation of agendas and other relevant materials for rac meetings that occurred between 2007 and 2014 for the racs in all 10 fema regions .

we also reviewed agendas and meeting minutes for nac meetings that took place between august 2011 and september 2015 .

we reviewed relevant federal laws and regulations , federal internal controls standards , and leading practices for program management .

to identify the extent to which rac members view their rac experiences as effective in conveying their concerns to fema , we conducted a self - administered , web - based questionnaire survey of rac members of each fema region's rac ; fema's 10 regional offices identified an initial population of 133 active rac members .

 ( see app .

ii for a copy of the survey questionnaire and the results. ) .

using e - mail addresses provided by each of the fema regions for their rac members ( which included the rac members' names and , in most cases , their place of work or other occupational identifier ) , we e - mailed each rac member a link to a secure survey website , along with a unique identifier and password to control access to each member's questionnaire .

most survey questions were closed - ended , in which rac members selected from a list of possible responses .

to obtain additional narrative and supporting context , survey respondents were given opportunities to provide additional open - ended comments throughout the survey .

the survey began on may 27 , 2015 , and data collection ended on june 29 , 2015 .

we e - mailed the survey link to 126 of the rac members identified by fema regional offices .

of these 126 e - mail contacts , e - mails to 14 were initially undeliverable and 2 were e - mails for fema employees who had been incorrectly listed as rac members ( fema employees cannot be rac members ) .

of the 14 non - fema rac members , we determined that 12 were no longer rac members .

of the remaining 2 , one informed us that she had only recently been appointed to a rac and had not attended any rac meetings , and the other told us in a follow - up telephone call that he had not been a rac member for at least 4 years .

on the basis of this information about rac membership status , we defined all 16 cases as ineligible and excluded them from the survey population .

of the 110 contacted that were still presumed to be eligible members , 77 responded to the survey , resulting in a 70 percent response rate .

of the 77 respondents , 3 answered an initial screening question stating that they were not currently members of the rac in their region , which left a total of 74 respondents whose responses were usable for our analysis of the rest of the questions .

during the course of survey data collection , we sent periodic reminder e - mails to all nonrespondents to encourage participation in the survey .

we also conducted tailored follow - ups by e - mail or telephone with selected nonrespondents , for example , those only partially completing their questionnaires .

because our survey was designed to include the entire population of rac members , our results are not subject to sampling error .

however , the practical difficulties of conducting any questionnaire survey may introduce a variety of non - sampling errors .

for example , differences in how a particular question is interpreted , the sources of information available to respondents , or the types of people who do not respond to the survey or a particular question can introduce error into survey results .

we included steps in the survey design , data collection , and analysis stages to minimize these types of non - sampling errors .

to minimize measurement error and nonresponse error , we designed draft questionnaires in collaboration with gao survey specialists .

we conducted pretests by telephone with three rac members from three regions .

on the basis of survey specialist input and these pretests , we made revisions to questionnaire drafts as necessary to reduce the likelihood of measurement and nonresponse errors ( the types of nonresponse associated with the perceived burden , lack of question clarity or relevance to the respondent ) .

in addition , our analysts answered respondent questions and resolved difficulties that respondents had in completing our questionnaire .

we asked open - ended comment questions at various points in the questionnaire to allow respondents to explain or provide context for their answers , which helped inform and corroborate our interpretation and analysis of the survey results .

we examined survey results to identify and remediate any inconsistencies or other indications of response error .

finally , we made multiple follow - up contacts with non - respondents throughout data collection to reduce nonresponse .

to minimize the possibility of data processing error , a second data analyst independently verified the accuracy of all computer analyses .

in addition , rac members made their responses directly into an automated web survey instrument , preventing errors associated with manual data entry of written answers .

we conducted our work from october 2014 to february 2016 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

below is the text of the survey as it was sent to regional advisory council ( rac ) members .

following the cover page , the questions are shown , along with the results in percentages .

narrative answers to open - ended text questions are not displayed to prevent the identification of individual respondents .

percentages may not always sum to 100 percent because of rounding of decimal figures .

in addition to the contact named above , chris keisling ( assistant director ) , david alexander , chuck bausell , david dornisch , eric hauswirth , susan hsu , valerie kasindi , stuart kaufman , tracey king , marvin mcgill , carl ramirez , robert rivas , and jonathan tumin made key contributions to this report .

