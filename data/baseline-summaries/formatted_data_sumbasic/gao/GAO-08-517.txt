since 1998 , congress has focused considerable attention on the need to improve the quality of care for the nation's 1.5 million nursing home residents , a highly vulnerable population of elderly and disabled individuals for whom remaining at home is no longer feasible .

poor quality of care — worsening pressure sores or untreated weight loss — in a small but unacceptably high number of nursing homes continues to harm residents or place them in immediate jeopardy , that is , at risk of death or serious injury .

about 1 in 5 homes nationwide were cited for such serious deficiencies on state inspections , known as surveys , in fiscal year 2007 ( see app .

i ) .

our previous work , however , demonstrated that state surveys sometimes understated the extent of serious care problems and that federal oversight of state survey activities had weaknesses .

understatement can occur when a state surveyor fails to cite a deficiency altogether or cites a deficiency at too low a level .

the centers for medicare & medicaid services ( cms ) is the federal agency responsible for ensuring the effectiveness of state surveys .

through cms's federal monitoring survey program , federal surveyors either ( 1 ) independently evaluate state surveys by resurveying a home recently inspected by state surveyors and comparing the deficiencies identified during the two surveys , known as a comparative survey , or ( 2 ) directly observe state surveyors during a routine nursing home survey , known as an observational survey .

results from both federal comparative and observational surveys — which are recorded in the federal monitoring survey database — allow cms to gauge states' abilities to accurately assess nursing home quality .

recently , we reported that federal comparative surveys in five large states identified the continuing understatement of serious care problems by state surveyors .

you asked us to look at the understatement of serious deficiencies by state surveyors nationwide .

in this report we address two questions: ( 1 ) what information do federal monitoring surveys provide about understatement nationwide , and ( 2 ) how effective are cms management and oversight of the federal monitoring survey program ? .

to answer the first question , we analyzed the results of comparative and observational surveys nationwide for fiscal years 2002 through 2007 using the federal monitoring survey database .

during this period , federal surveyors conducted 976 comparative surveys and 4,023 observational surveys .

to identify understatement on comparative surveys , we focused our analysis on cases where federal surveyors determined that state surveyors should have cited a deficiency but failed to do so or where state surveyors cited a deficiency at too low a level .

we analyzed the results of observational surveys in order to better understand why understatement might occur .

deficiencies identified during nursing home surveys are categorized according to their scope ( i.e. , the number of residents potentially or actually affected ) and severity ( i.e. , the degree of relative harm involved ) .

homes with deficiencies at the a though c levels are considered to be in substantial compliance , while those with deficiencies at the d through l levels are considered out of compliance .

 ( see table 1. ) .

throughout this report , we refer to deficiencies at the actual harm and immediate jeopardy levels as serious deficiencies .

to ensure reliability of the federal monitoring survey database , we discussed data entry procedures with all 10 cms regional offices , whose staff enter information into the database .

in addition , we conducted several data reliability tests , including ( 1 ) automated checks of data fields to ensure that they contained complete information and ( 2 ) manual reviews of a random sample of all deficiencies cited by federal but not state surveyors to ensure that federal surveyors had used the data fields appropriately .

we also eliminated a small number of deficiencies that did not correspond to a defined severity level or contained illogical survey dates — such as a comparative survey that began prior to the state survey .

based on these activities , we determined that the information was sufficiently reliable for our purposes .

data on comparative surveys , however , cannot be used to project the extent of understatement across all state surveys because the state surveys selected for federal monitoring surveys are not representative of all nursing home surveys or survey teams within each state .

to answer the second question , we reviewed cms guidance for the federal monitoring survey program and interviewed officials in cms headquarters and all 10 regional offices .

our work focused on cms's ( 1 ) efforts to improve the use of comparative surveys as an oversight tool ; ( 2 ) ability to track the understatement of deficiencies ; and ( 3 ) management of the federal monitoring survey database , including the use of the database to oversee regional office implementation of the federal monitoring survey program .

we also analyzed ( 1 ) the comments entered into the federal monitoring survey database by federal surveyors for certain discrepancies between federal and state survey findings and ( 2 ) the consistency between comparative and observational survey results within states and cms regional offices .

we performed our work from july 2007 through may 2008 in accordance with generally accepted government auditing standards .

oversight of nursing homes is a shared federal - state responsibility .

based on statutory requirements , cms ( 1 ) defines quality standards that nursing homes must meet to participate in the medicare and medicaid programs and ( 2 ) contracts with state survey agencies to assess whether homes meet those standards through annual surveys and complaint investigations .

although cms has issued extensive guidance to states on determining compliance with federal quality requirements , we have found that some state surveys understate quality problems at nursing homes .

federal nursing home quality standards focus on the delivery of care , resident outcomes , and facility conditions .

these standards , totaling approximately 200 , are grouped into 15 categories , such as resident rights , quality of life , resident assessment , quality of care , pharmacy services , and administration .

for example , there are 23 standards within the quality of care category ranging from “promote the prevention of pressure development” to “the resident environment remains as free of accident hazards as is possible.” cms has also developed detailed investigative protocols to assist state survey agencies in determining whether nursing homes are in compliance with federal quality standards .

this guidance is intended to ensure the thoroughness and consistency of state surveys and complaint investigations .

every nursing home receiving medicare or medicaid payment must undergo a standard state survey not less than once every 15 months , and the statewide average interval for these surveys must not exceed 12 months .

during a standard survey , teams of state surveyors — generally consisting of registered nurses , social workers , dieticians , or other specialists — evaluate compliance with federal quality standards .

based on the care provided to a sample of residents , the survey team ( 1 ) determines whether the care and services provided meet the assessed needs of the residents and ( 2 ) measures resident outcomes , such as the incidence of preventable pressure sores , weight loss , and accidents .

in contrast to a standard survey , a complaint investigation generally focuses on a specific allegation regarding a resident's care or safety and provides an opportunity for state surveyors to intervene promptly if problems arise between standard surveys .

surveyors generally follow state procedures when investigating complaints , but must comply with certain federal guidelines and time frames .

when deficiencies are identified , federal sanctions can be imposed to help encourage homes to correct them .

sanctions are generally reserved for serious deficiencies — those at the g through l levels — which constitute actual harm and immediate jeopardy .

sanctions for such serious quality problems can affect a home's revenues and provide financial incentives to return to and maintain compliance .

such sanctions include fines known as civil money penalties , denial of payment for new medicare or medicaid admissions , or termination from the medicare and medicaid programs .

state surveys that miss serious deficiencies or cite deficiencies at too low a scope and severity level have enforcement implications because a nursing home may escape sanctions intended to discourage repeated noncompliance .

for example , facilities that receive at least one g through l level deficiency on successive standard surveys or complaint investigations must be referred for immediate sanctions .

in addition , cms guidance calls for higher fines when a home has a poor compliance history and requires that state survey teams revisit a home to verify that serious deficiencies have actually been corrected ( such revisits are not required for most deficiencies cited below the actual harm level — a through f ) .

statutorily required federal monitoring surveys , which are conducted annually in at least 5 percent of state - surveyed medicare and medicaid nursing homes in each state , are a key cms oversight tool in ensuring the adequacy of state surveys .

cms headquarters — specifically , cms's survey and certification group — is responsible for the management of the federal monitoring survey database and for oversight of the 10 cms regional offices' implementation of the federal monitoring survey program .

federal surveyors located in regional offices conduct federal monitoring surveys .

the surveys can be either comparative or observational , with each offering unique advantages and disadvantages as an oversight tool .

for example , an advantage of comparative surveys is that they are an independent evaluation of a nursing home recently surveyed by a state survey agency team .

a disadvantage is that the time lag between the two surveys can make analysis of differences difficult .

comparative survey .

a federal survey team conducts an independent survey of a home recently surveyed by a state survey agency in order to compare and contrast the findings .

this comparison takes place after completion of the federal survey .

when federal surveyors identify a deficiency not cited by state surveyors , they assess whether the deficiency existed at the time of the state survey and should have been cited by entering either yes or no to the question , “based on the evidence available to the , should the team have cited this ? ” this assessment is critical in determining whether understatement occurred because some deficiencies cited by federal surveyors may not have existed at the time of the state survey .

for example , a deficiency identified during a federal survey could involve a resident who was not in the nursing home at the time of the earlier state survey .

by statute , comparative surveys must be conducted within 2 months of the completion of the state survey .

however , differences in timing , resident sample selection , and staffing can make analysis of differences between the state and federal comparative surveys difficult .

on the basis of our prior recommendations , cms has taken several steps to ensure that comparative surveys more accurately capture conditions at the time of the state survey .

for example , cms now calls for the length of time between the state and federal surveys to be between 10 and 30 working days and requires federal surveyors conducting a comparative survey in a nursing home to include at least half of the state survey's sample of residents from that nursing home in the comparative survey sample , making it easier to determine whether state surveyors missed a deficiency .

furthermore , federal comparative survey teams are expected to mimic the number of staff assigned to the state survey .

cms also issued guidance in october 2002 defining the criteria for federal surveyors to consider when selecting facilities for comparative surveys .

these selection criteria can generally be categorized as state survey team performance and facility characteristics .

regional offices were given latitude in their use of these criteria and may supplement them with other selection factors unique to their regions .

for example , some regions use statistics on the prevalence of pressure sores in a nursing home's resident population as a comparative survey selection factor .

observational survey .

federal surveyors accompany a state survey team to a nursing home to evaluate the team's on - site survey performance and ability to document survey deficiencies .

state teams are evaluated in six areas — concern identification , sample selection , general investigation , food - borne illness investigation , medication investigations , and deficiency determination — and are rated in one of five categories for each of the six measures .

the rating categories — from highest to lowest — are extremely effective , very effective , satisfactory , less than satisfactory , and much less than satisfactory .

cms annual state performance reviews require that state survey teams achieve an average rating of satisfactory .

observational surveys allow federal surveyors to provide more immediate feedback to state surveyors and to identify state surveyor training needs .

however , observational surveys are not independent evaluations of the state survey .

because state surveyors may perform their survey tasks more attentively than they would if federal surveyors were not present , observational surveys may not provide an accurate picture of state surveyors' typical performance .

since 2001 , cms has also taken steps to strengthen observational surveys .

for example , the agency issued written guidance defining a standard process for resolving disagreements and a new manual to increase consistency across observational surveys .

the 976 federal comparative surveys conducted from fiscal year 2002 through 2007 ranged from as few as 10 in vermont , which has about 40 facilities , to as many as 49 in california , which has about 1,300 facilities .

of the 4,023 federal observational surveys conducted during the same period , the number ranged from 16 in new hampshire to 346 in california .

the results of federal monitoring surveys , including information on the corresponding state surveys , are entered in the federal monitoring survey database .

in fiscal year 2002 , cms began including information on comparative surveys in the database , and the agency began requiring federal surveyors to determine whether a deficiency cited by federal but not state surveyors had been missed by determining whether state surveyors should have cited the deficiency .

although comparative surveys and the wide variability across states in the proportion of homes with deficiencies at the actual harm and immediate jeopardy levels indicate that state surveyors miss some serious deficiencies , our prior work has also indicated that state surveyors sometimes understate the scope and severity of a deficiency .

in 2003 , we found widespread understatement of actual harm deficiencies in a sample of surveys from homes with a history of harming residents .

overall , 39 percent of the 76 state surveys we reviewed had documented problems that should have been classified as actual harm instead of as lower - level deficiencies .

a substantial proportion of federal comparative surveys identify missed deficiencies at the potential for more than minimal harm level or above .

from fiscal year 2002 through 2007 , about 15 percent of federal comparative surveys nationwide identified state surveys that failed to cite at least one deficiency at the most serious levels of noncompliance — the actual harm and immediate jeopardy levels ( g through l ) .

there was wide variation across states in the proportion of comparative surveys that found at least one missed serious deficiency , from more than 25 percent in nine states to none in seven others .

in contrast to missed serious deficiencies , missed deficiencies at the potential for more than minimal harm level ( d through f ) were considerably more widespread , with such missed deficiencies greater than 40 percent in all but five states .

every state had at least one comparative survey with missed d through f level deficiencies .

at both levels of noncompliance , the most frequently missed deficiencies involved quality of care standards .

federal observational survey results and prior gao reports have highlighted several factors that may contribute to the understatement of deficiencies .

about 15 percent ( 142 ) of the 976 comparative surveys conducted from fiscal year 2002 through 2007 identified state surveys that missed at least one deficiency at the actual harm or immediate jeopardy level ( g through l ) , the most serious levels of noncompliance .

this proportion fluctuated from a high of 17.5 percent in fiscal year 2003 to a low of 11.1 percent in fiscal year 2004 , but it has remained relatively constant at about 15 percent for the last several fiscal years ( see fig .

1 ) .

this proportion is small , but cms maintains that any missed serious deficiencies are unacceptable .

from fiscal year 2002 through 2007 , federal surveyors identified missed serious deficiencies in 25 percent or more of their comparative surveys in nine states .

the proportion of missed serious deficiencies in these nine states ranged from 26.3 percent in tennessee to 33.3 percent in new mexico , south carolina , south dakota , and wyoming ( see table 2 ) .

the total number of missed deficiencies at the g through l levels also varied across these nine states , from a low of 4 in south dakota to a high of 19 in south carolina .

federal surveyors identified no missed serious deficiencies in seven states ( see app .

ii for complete state results ) .

in contrast to missed serious deficiencies , missed deficiencies at the potential for more than minimal harm level ( d through f ) were considerably more widespread on comparative surveys conducted during fiscal years 2002 through 2007 .

approximately 70 percent of comparative surveys conducted nationwide identified state surveys that missed at least one deficiency at the potential for more than minimal harm level ( d through f ) , with such missed deficiencies identified on greater than 40 percent of comparative surveys in all but five states — alaska , ohio , vermont , west virginia , and wisconsin .

on average , state surveys selected for comparative surveys failed to identify 2.5 d through f level deficiencies per survey .

undetected care problems at the d through f level are of concern because they could become more serious over time if nursing homes are not required to take corrective actions .

missed deficiencies at the potential for more than minimal harm level were not isolated to a single year during the 6 fiscal years we examined and continued to be a problem for states in fiscal year 2007 .

nationally , the proportion of comparative surveys identifying at least one missed d through f level deficiency in fiscal year 2007 was about 74 percent ( see fig .

2 ) .

for results by state , see appendix iii .

our analysis found that the most frequently missed deficiencies at both the potential for more than minimal harm ( d through f ) and the actual harm or immediate jeopardy ( g through l ) levels occurred in quality standards under cms's quality of care category .

missed deficiencies in this category involved residents' receipt of the necessary care and services to attain and maintain the highest practicable physical , mental , and psychosocial well - being — such as prevention of pressure sores , nutrition and hydration , accident prevention , and assistance with bathing and grooming .

from fiscal year 2002 through 2007 , 11.9 percent of federal comparative surveys ( 116 ) cited at least one quality of care deficiency at the actual harm or immediate jeopardy level that state survey teams failed to cite .

these 116 surveys contained a total of 143 missed serious quality of care deficiencies .

the category with the next highest frequency of missed serious deficiencies was resident behavior and facility practices , with only 2.2 percent of total federal comparative surveys .

at the potential for more than minimal harm level , quality of care was one of two categories with the highest frequency of missed deficiencies — 31.7 percent .

for the percentage of missed deficiencies in each of the cms quality standard categories , see appendix iv .

both federal observational surveys and our prior reports have identified factors that may contribute to the understatement of deficiencies by state survey teams .

from fiscal year 2002 through 2007 , 80 percent of the 4,999 federal monitoring surveys were observational .

our review of observational survey data — which are collected during direct observation of state survey teams — found that some of the lowest state survey team ratings nationwide were in the general investigation and deficiency determination areas .

together , these two areas directly affect the appropriate identification and citation of deficiencies .

the general investigation segment of an observational survey evaluates the effectiveness with which the state survey team collected information to determine how the facility's environment and care of residents affect residents' quality of life , health and safety , and ability to reach their highest practicable physical , mental , and psychosocial well - being .

this segment includes observations of state survey team actions such as collection of information , discussion of survey observations , interviews with facility residents , and implementation of cms investigative protocols .

the deficiency determination segment of an observational survey evaluates the skill with which the state survey teams ( 1 ) integrate and analyze all information collected and ( 2 ) use the guidance to surveyors and regulatory requirements to make accurate compliance determinations .

this segment includes observations of state survey team actions such as reviews of regulatory requirements , team participation in deficiency discussions , presentation of complete information , accurate decision making , and accurate citation of deficiencies .

nationwide , 7.7 percent of the state survey teams observed by federal surveyors received below satisfactory ratings on the general investigation measure from fiscal year 2002 through 2007 .

during the same 6 fiscal years , 9.2 percent , or about 1 in 11 , of the state survey teams observed by federal surveyors received below satisfactory ratings on the deficiency determination measure .

our analysis found variation across states in survey team performance in general investigation and deficiency determination .

sixteen states had more teams than the national average receive below satisfactory ratings for both measures , while 28 states had fewer teams than the national average receive below satisfactory ratings ( see app .

v ) .

poor performance on these observational survey measures may be a contributing factor to the understatement of deficiencies by state survey teams .

for example , of the nine states in table 2 with the highest percentage of missed serious deficiencies on comparative surveys , six had more teams than the national average receive below satisfactory ratings for both general investigation and deficiency determination ( see table 3 ) .

our prior reports have described some other factors that may contribute to survey inconsistency and the understatement of deficiencies by state survey teams: ( 1 ) weaknesses in cms's survey methodology , such as poor documentation of deficiencies ; ( 2 ) confusion about the definition of actual harm ; ( 3 ) predictability of surveys , which allows homes to conceal problems if they so desire ; ( 4 ) inadequate quality assurance processes at the state level to help detect understatement in the scope and severity of deficiencies ; and ( 5 ) inexperienced state surveyors as a result of retention problems .

in ongoing work , we are investigating the factors that contribute to understatement .

cms has taken steps to improve the federal monitoring survey program , but weaknesses remain in program management and oversight .

for example , cms has improved processes to ensure that comparative surveys more accurately reflect conditions at the time of the state survey , has switched control of the federal monitoring survey database to the office responsible for ensuring the effectiveness of state surveys , and has begun examining how to use monitoring survey data to improve oversight .

despite this progress , the management and oversight potential of the program has not been fully realized .

in particular , cms ( 1 ) has only begun exploring options for identifying understatement that occurs in cases where state surveys cite deficiencies at too low a level , for possible implementation in fiscal year 2009 , and ( 2 ) is not effectively managing the federal monitoring survey database or using the database to oversee consistent implementation of the federal monitoring survey program by its regional offices .

cms has taken steps in three areas — time between surveys , resident sample , and survey resources — to ensure that comparative surveys more accurately capture the conditions at the time of the state survey .

time between surveys .

in fiscal year 2002 , cms initiated a policy that shortened the length of time between state and comparative surveys from 2 months to 1 month .

cms relaxed the 1 month standard by changing the requirement to 30 working days in fiscal year 2003 .

as a result of shortening the time between the two surveys , the conditions at the time of the comparative survey are more likely to reflect those at the time of the state survey ; for example , the same residents are still likely to be in the nursing home .

comparative surveys during fiscal year 2007 took place on average 21.4 working days ( 30.9 calendar days ) after state surveys .

resident sample .

beginning in fiscal year 2003 , cms policy required that comparative surveys include at least half of the residents from state survey investigative samples .

officials from several regional offices said that examining the same resident allows for more clear - cut determinations of whether the state should have cited a deficiency .

since the policy change , about 78 percent of comparative surveys from fiscal year 2003 through 2007 included at least half the residents from state surveys' investigative samples .

by comparison , only 13 percent of comparative surveys met that 50 percent threshold in fiscal year 2002 , the year before the policy went into effect .

survey resources .

beginning in fiscal year 2003 , cms initiated a policy that each comparative survey should have the same number of federal surveyors as its corresponding state survey , again to more closely mirror the conditions under which the state survey was conducted .

we found that in fiscal year 2007 , the average state survey team ( 3.4 surveyors ) was larger than the average federal survey team ( 3.0 surveyors ) .

however , on average , federal surveyors remained on - site longer than state surveyors — 4.3 days for federal surveyors compared with 3.7 days for state surveyors .

when the number of surveyors and time on - site are taken together , state surveys averaged 12.6 surveyor - days and federal comparative surveys averaged 12.9 surveyor - days .

given these improvements , we asked the regional offices how receptive state survey teams were to feedback that they had missed deficiencies .

most regional office officials told us that in general the feedback session with state surveyors on missed deficiencies was not contentious and that state surveyors generally accepted the feedback provided .

however , cms established a formal dispute resolution process for comparative surveys in october 2007 .

the process is similar to the process already in place for resolving disagreements about observational survey results .

while cms requires federal surveyors to determine whether a deficiency cited on a comparative but not a state survey was missed by state surveyors , there is no comparable requirement for deficiencies that are cited at different scope and severity levels .

as a result , comparative surveys do not effectively capture the extent of the understatement of serious deficiencies by state surveyors .

as with missed deficiencies , a discrepancy between federal and state survey results does not automatically indicate understatement .

for example , the deficiency could have worsened by the time of the federal survey .

although cms does not require federal surveyors to evaluate scope and severity differences between the two sets of surveys , we found that some regional offices used the validation question for missed deficiencies — ”based on the evidence available to the , should the team have cited this ? ” — to make such a determination .

using the validation question to make these determinations is contrary to cms guidance issued in october 2003 , which instructed comparative survey teams to only answer this question when the state failed to cite the deficiency altogether .

to assess whether differences in scope and severity levels were actually understated — rather than deficiencies that worsened between the state and federal surveys — we first identified all 71 deficiencies on comparative surveys conducted from fiscal year 2002 through 2007 where federal survey teams cited actual harm or immediate jeopardy deficiencies that state survey teams cited at a lower scope and severity level .

we then examined the comment fields in the federal monitoring survey database associated with those deficiencies .

our analysis identified 27 deficiencies ( 38 percent ) in which federal survey teams determined that a state's scope and severity citation was too low .

for another 22 deficiencies ( 31 percent ) , federal survey teams found that the state's lower scope and severity determination was appropriate , given the circumstances at the time of the state survey .

the remaining 22 deficiencies ( 31 percent ) did not have comments or contained remarks that were inconclusive about whether the state deficiency citation was too low .

when the confirmed scope and severity understatement was included with understatement caused by missed deficiencies , the total percentage of comparative surveys with understatement of serious deficiencies increased by an average of about 1 percentage point over the 6 fiscal years we analyzed ( see fig .

3 ) .

while cms headquarters does not require federal surveyors to determine whether a deficiency cited by state survey teams was cited at too low a scope and severity level , some regional offices have developed their own procedures to track this information and use it to provide feedback to state survey agencies .

for example , in one regional office an individual reviews all comment fields for a year's worth of comparative surveys , makes a hand count of scope and severity differences that states should have cited , and then shares this with the state survey agencies during their annual performance reviews .

because the federal monitoring survey database does not automatically collect data on scope and severity determinations , cms headquarters does not have access to the data analyses the regions have independently conducted .

some of the regional offices told us that they would like to have a specific way that the federal monitoring survey database could track scope and severity understatement that is similar to how deficiencies missed by state surveyors are tracked .

in january 2008 , cms officials told us that they had initiated a pilot program in october 2007 to test the collection of data on understatement of scope and severity differences .

according to cms , the pilot , which will run through 2008 for possible fiscal year 2009 implementation , is necessary because the agency needs to determine which scope and severity understatement differences should be captured .

for example , cms is uncertain whether regions should only focus on differences that would raise the scope and severity level to actual harm or immediate jeopardy and not assess differences for understatement that occurs at lower scope and severity levels .

our analysis found that cms headquarters was not effectively managing the federal monitoring survey database or using the database to oversee consistent implementation of the federal monitoring survey program by regional offices .

while cms uses data from comparative and observational surveys to provide feedback to state survey agencies during state performance reviews , cms officials told us that they recognized the need to improve their management and use of the database for better oversight of the agency's 10 regional offices .

we identified two problems in cms's management of the federal monitoring survey database .

cms was not aware that ( 1 ) the results of a considerable number of comparative surveys were missing from the database and ( 2 ) the validation question for missed deficiencies was being used by some regional offices to identify scope and severity differences , contrary to cms guidance .

missing data .

in october 2007 , we identified missing comparative surveys for two regional offices dating back to 2005 and asked cms to follow up with officials in those regions .

at least one of the regions had completed the surveys but had failed to upload them into the national database .

we also found that cms had not included data in the federal monitoring survey database from 162 contractor - led comparative surveys conducted between fiscal years 2004 and 2007 .

use of validation question contrary to cms guidance .

some regional offices were using the missed deficiency validation question to make determinations about whether scope and severity differences constituted understatement , making it difficult to distinguish between missed deficiencies and scope and severity understatement .

in addition , we found that the regional office answer to the validation question was not always consistent with the information recorded in the comment box .

similarly , we identified weaknesses in cms's use of the database for regional office oversight .

for example , cms was not ( 1 ) examining comparative survey data to ensure that regional offices comply with cms guidance intended to ensure that comparative surveys more accurately capture the conditions at the time of the state survey and ( 2 ) using the database to identify inconsistencies between comparative and observational survey results .

ensuring regional office compliance .

while cms has provided guidance to its regional offices to help ensure that comparative surveys more accurately capture the conditions at the time of the state survey , the agency is not fully using available data to ensure that the regional offices implement the agency's guidance .

for example , we found that the length of time between state and comparative surveys varied broadly by cms region .

in 2007 , the average time gap ranged from a low of 15.4 working days ( 22.5 calendar days ) in the boston region to a high of 38.5 working days ( 54.4 calendar days ) in the new york region .

furthermore , while 78 percent of comparative surveys from fiscal year 2003 through 2007 followed cms's guidance to include at least half of the residents from state surveys' investigative samples , 22 percent of comparative surveys did not meet this threshold .

finally , when we contacted officials in cms headquarters to ask clarifying questions about the data variables needed to conduct these analyses , the headquarters officials were not familiar with a number of the variables and referred us to a cms staff person in one of the regional offices .

together , these three examples suggest that cms is not effectively using the data to hold regional offices accountable for implementing guidance .

identify inconsistencies between comparative and observational results .

cms officials told us that they have begun to explore regional office differences in less than satisfactory ratings for state survey teams on observational surveys .

however , cms officials told us that they do not plan to use the database to identify inconsistencies between comparative and observational surveys that may warrant follow - up to ensure that regional offices are adhering to cms guidance and consistently assessing state surveyor performance .

for example , some states that performed below the national average in identifying serious deficiencies on comparative surveys received above - average marks on observational survey measures for deficiency determination and general investigation .

wyoming's 33.3 percent rate for surveys with missed serious deficiencies was more than double the national average of about 15 percent for surveys conducted during fiscal years 2002 and 2007 .

yet wyoming never received a below satisfactory rating on its general investigation or deficiency determination measures during 18 observational surveys over that same 6-year period .

we found similar inconsistencies in the results of federal monitoring surveys for south dakota and a few other states .

although inconsistencies between comparative and observational surveys may not necessarily indicate a problem , they may warrant investigation .

for example , in a small state like wyoming it is likely that comparative and observational surveys have evaluated the same group of state surveyors .

further , wyoming and south dakota are two of six states whose federal monitoring surveys are conducted by cms's denver regional office .

of the 140 observational surveys conducted from fiscal year 2002 through 2007 , federal surveyors from the denver regional office gave one below satisfactory rating on the deficiency determination measure .

that 0.7 percent rate of below satisfactory performance was more than four times lower than the regional office with the next - lowest percentage — the chicago regional office — which awarded below satisfactory ratings to 3.3 percent of state survey teams it observed .

with about 1 in 6 comparative surveys concluding that state survey teams had missed a serious deficiency or understated its scope and severity level , it is evident that state survey agency performance limits the federal government's ability to obtain an accurate picture of how often nursing home residents face actual harm or are at risk of serious injury or death .

these missed serious deficiencies most frequently involved quality of care , reflecting shortcomings in fundamental provider responsibilities such as ensuring proper nutrition and hydration , accident prevention , and preventing pressure sores .

observational survey results also underscore problems state surveyors may face in identifying facility deficiencies ; about 1 in 11 state survey teams nationwide were rated as below satisfactory by cms surveyors on the deficiency determination measure .

we found that comparative survey data may mask the true extent of understatement because cms's current protocol does not require regional offices to track in the federal monitoring survey database when state surveyors cite lower - than - appropriate scope and severity levels .

as we conducted our work , cms officials recognized this problem and in october 2007 began to experiment with a pilot program to measure understated scope and severity .

however , at the conclusion of the pilot , scheduled for fiscal year 2008 , cms may decide not to implement a validation question for all scope and severity differences .

we believe it is important to assess differences for understatement that occurs at the d through l levels — potential for more than minimal harm , actual harm , and immediate jeopardy .

we also found that cms was not effectively managing the federal monitoring survey database to ensure that regional offices were entering data in a timely and consistent fashion .

lack of accurate and reliable data hinders effective oversight .

for example , we found that the database was missing a considerable number of comparative surveys .

further , cms has not used the federal monitoring survey database to its full potential as an oversight tool .

for example , cms is not fully using data on comparative surveys to ensure that regional offices are implementing guidance intended to improve federal monitoring surveys .

although cms's survey and certification group assumed control of the database in january 2007 , headquarters staff often referred us to cms regional office staff to answer specific database questions , suggesting a lack of familiarity with the organization and content of the database .

in addition , agency officials told us that they do not plan to follow up on inconsistencies between comparative and observational survey results that could indicate weaknesses in how regional offices evaluate state surveyors' performance .

identifying and following up on such inconsistencies could help ensure database reliability and hold regional office officials accountable for their implementation of the federal monitoring survey program , a program required by statute .

to address weaknesses in cms's management of the federal monitoring survey database that also affect the agency's ability to effectively track understatement , we recommend that the administrator of cms take the following two actions: require regional offices to determine if there was understatement when state surveyors cite a deficiency at a lower scope and severity level than federal surveyors do and to track this information in the federal monitoring survey database .

establish quality controls to improve the accuracy and reliability of information entered into the federal monitoring survey database .

to address weaknesses that affect cms's ability to oversee regional office implementation of the federal monitoring survey program , we recommend that the administrator of cms take the following two actions: routinely examine comparative survey data and hold regional offices accountable for implementing cms guidance that is intended to ensure that comparative surveys more accurately capture the conditions at the time of the state survey .

regularly analyze and compare federal comparative and observational survey results .

in written comments on our draft report , hhs indicated that it fully endorsed and would implement our four recommendations intended to strengthen management and oversight of the federal monitoring survey program .

the comments generally outlined cms's implementation plan through 2009 and indicated that some steps , such as improved management of the federal monitoring survey database , are already under way .

hhs's comments are reproduced in appendix vi .

the majority of hhs's comments focused on its strategic approach to improving oversight: ( 1 ) ensuring that all nursing homes are surveyed at least once every 15 months , ( 2 ) improving surveyor understanding of federal quality requirements through improved guidance and training , ( 3 ) increasing the consistency of state surveys through the introduction of a new nursing home survey methodology , and ( 4 ) improving the use of data generated by federal monitoring surveys .

many of these strategies aim to address the underlying causes of understatement , the topic of a forthcoming gao report .

hhs also noted that limitations in the medicare survey and certification budget underscore the agency's need to target resources effectively to maximize results .

for example , hhs indicated that the implementation of the new survey methodology will be dependent on the level of funding in the overall survey and certification budget through fiscal year 2014 .

survey and certification funding is the subject of another forthcoming gao report .

two of hhs's observations merit further discussion .

first , hhs noted that understatement that arises from a lack of understanding or confusion about federal requirements would generally not be detected through federal monitoring surveys because both federal and state surveyors would be affected by the same limitation .

we believe that the consistency with which federal surveys have identified serious deficiencies missed by state surveyors from fiscal year 2002 through 2007 — about 15 percent , on average — suggests that federal surveyors have a better understanding of cms quality requirements than do state surveyors .

we have previously reported that the limited experience level of state surveyors because of the high turnover rate was a contributing factor to deficiency understatement .

second , hhs questioned our use of “one missed deficiency per survey” as a measure of understatement .

we believe that this standard is appropriate for serious deficiencies that result in harm or immediate jeopardy ( g through l level ) because the goal of state surveys should be to identify and require nursing homes to address all such deficiencies .

cms itself uses this standard during annual state performance reviews .

we also used this standard to describe the proportion of comparative surveys that identified missed deficiencies at the potential for more than minimal harm level ( d through f ) .

identifying and requiring nursing homes to correct such deficiencies is important because if uncorrected they have the potential to become more serious .

compared to missed serious deficiencies , we found that understatement of potential for more than minimal harm deficiencies was more widespread — about 70 percent of comparative surveys identified at least one state survey with such missed deficiencies .

the number of state surveys with missed deficiencies at the d through f level was greater than 40 percent in all but five states , and state surveys selected for comparative surveys failed to identify an average of 2.5 deficiencies in this range per survey .

in short , the magnitude of understatement at the potential for more than minimal harm level should be a cause for concern .

hhs also provided technical comments , which we incorporated as appropriate .

as arranged with your offices , unless you publicly announce its contents earlier , we plan no further distribution of this report until 30 days after its issue date .

at that time , we will send copies to the administrator of the centers for medicare & medicaid services and appropriate congressional committees .

we will also make copies available to others upon request .

in addition , the report will be available at no charge on gao's web site at http: / / www.gao.gov .

if you or your staffs have any questions about this report , please contact me at ( 202 ) 512-7114 or dickenj@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix vii .

in order to identify trends in the percentage of nursing homes cited with actual harm or immediate jeopardy deficiencies , we analyzed data from the centers for medicare & medicaid service's ( cms ) on - line survey , certification , and reporting system ( oscar ) database for fiscal years 2002 through 2007 ( see table 4 ) .

because homes must be surveyed at least every 15 months , with a required 12-month statewide average , it is possible that a home was surveyed more than once in any fiscal year .

to avoid double counting homes , we included only a home's most recent survey from each fiscal year .

because cms conducts a relatively small number of comparative surveys , it is not possible to compare the results of comparative surveys to the results of all state surveys .

in addition to the contact named above , walter ochinko , assistant director ; katherine nicole laubacher ; dan lee ; elizabeth t. morrison ; steve robblee ; karin wallestad ; and rachael wojnowicz made key contributions to this report .

nursing home reform: continued attention is needed to improve quality of care in small but significant share of homes .

gao - 07-794t .

washington , d.c.: may 2 , 2007 .

nursing homes: efforts to strengthen federal enforcement have not deterred some homes from repeatedly harming residents .

gao - 07-241 .

washington , d.c.: march 26 , 2007 .

nursing homes: despite increased oversight , challenges remain in ensuring high - quality care and resident safety .

gao - 06-117 .

washington , d.c.: december 28 , 2005 .

nursing home deaths: arkansas coroner referrals confirm weaknesses in state and federal oversight of quality of care .

gao - 05-78 .

washington , d.c.: november 12 , 2004 .

nursing home fire safety: recent fires highlight weaknesses in federal standards and oversight .

gao - 04-660 .

washington d.c.: july 16 , 2004 .

nursing home quality: prevalence of serious problems , while declining , reinforces importance of enhanced oversight .

gao - 03-561 .

washington , d.c.: july 15 , 2003 .

nursing homes: public reporting of quality indicators has merit , but national implementation is premature .

gao - 03-187 .

washington , d.c.: october 31 , 2002 .

nursing homes: quality of care more related to staffing than spending .

gao - 02-431r .

washington , d.c.: june 13 , 2002 .

nursing homes: more can be done to protect residents from abuse .

gao - 02-312 .

washington , d.c.: march 1 , 2002 .

nursing homes: federal efforts to monitor resident assessment data should complement state activities .

gao - 02-279 .

washington , d.c.: february 15 , 2002 .

nursing homes: sustained efforts are essential to realize potential of the quality initiatives .

gao / hehs - 00-197 .

washington , d.c.: september 28 , 2000 .

nursing home care: enhanced hcfa oversight of state programs would better ensure quality .

gao / hehs - 00-6 .

washington , d.c.: november 4 , 1999 .

nursing home oversight: industry examples do not demonstrate that regulatory actions were unreasonable .

gao / hehs - 99-154r .

washington , d.c.: august 13 , 1999 .

nursing homes: proposal to enhance oversight of poorly performing homes has merit .

gao / hehs - 99-157 .

washington , d.c.: june 30 , 1999 .

nursing homes: complaint investigation processes often inadequate to protect residents .

gao / hehs - 99-80 .

washington , d.c.: march 22 , 1999 .

nursing homes: additional steps needed to strengthen enforcement of federal quality standards .

gao / hehs - 99-46 .

washington , d.c.: march 18 , 1999 .

california nursing homes: care problems persist despite federal and state oversight .

gao / hehs - 98-202 .

washington , d.c.: july 27 , 1998 .

