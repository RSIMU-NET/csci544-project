we appreciate the opportunity to participate in the subcommittee's hearing on us - visit ( the united states visitor and immigrant status indicator technology ) , a multibillion - dollar program of the department of homeland security ( dhs ) that is intended to achieve a daunting set of goals: to enhance the security of our citizens and visitors and ensure the integrity of the u.s. immigration system , and at the same time to facilitate legitimate trade and travel and protect privacy .

to achieve these goals , us - visit is to record the entry into and exit from the united states of selected travelers , verify their identity , and determine their compliance with the terms of their admission and stay .

since fiscal year 2002 , the house and senate appropriations committees have provided valuable oversight and direction to dhs on us - visit by legislatively directing it to submit annual expenditure plans for committee approval .

this legislation also directed us to review these plans .

our reviews have produced four reports that , among other things , described dhs progress against legislatively mandated milestones and identified fundamental challenges that the department faced in delivering promised program capabilities and benefits on time and within cost .

for example , we reported in september 2003 that the program office did not have the human capital and acquisition process discipline needed to effectively manage the program .

in light of the challenges that we identified , we concluded that the program carries an appreciable level of risk , meaning that it must be managed effectively if it is to be successful .

managing us - visit effectively requires high levels of capability and expertise .

fundamentally , it entails being able to respond affirmatively to two basic questions .

first , are we doing the right thing ? .

to be sure that a program is doing the right thing , it needs to be justified by sufficient fact - based and verifiable analysis to show that the program as defined will properly fit within the larger homeland security operational and technological environments and that it will produce mission value commensurate with expected costs and risks .

the second question is , are we doing it the right way ? .

to be done the right way , a program needs to be executed in a rigorous and disciplined manner , which means that it needs to employ the necessary mix of people , processes , and tools to reasonably ensure that promised program capabilities and expected mission value are delivered on time and within budget .

beyond these two questions , effective program management also means that the program is held accountable for results , which involves measuring and disclosing performance relative to explicitly defined program goals , outcomes , and commitments .

over the last 4 years , our reports have provided recommendations to dhs to ensure that these questions are answered and used as the basis for informed decision making about us - visit .

they have also provided recommendations to promote dhs accountability for the program .

these recommendations have been aimed at helping the department to ensure that this program fulfills expectations: in other words , that the program is doing the right thing in the right way , and that it is holding itself accountable for doing so .

according to dhs , the recommendations have made us - visit a stronger program .

further , they concur with the need to implement them with due speed and diligence .

my statement will describe the status of us - visit and where the department now stands in implementing these recommendations and thus in addressing the challenges that it faces .

it is based on our aforementioned reports to the appropriations committees and our ongoing work for the house committee on homeland security .

all work on which this testimony is based was performed in accordance with generally accepted government auditing standards .

us - visit is a governmentwide program intended to enhance the security of u.s. citizens and visitors , facilitate legitimate travel and trade , ensure the integrity of the u.s. immigration system , and protect the privacy of our visitors .

the scope of the program includes the pre - entry , entry , status , and exit of hundreds of millions of foreign national travelers who enter and leave the united states at over 300 air , sea , and land ports of entry , as well as analytical capabilities spanning this overall process .

to achieve its goals , us - visit uses biometric information ( digital fingerscans and photographs ) to verify identity and screen persons against watch lists .

in many cases , the us - visit process begins overseas , at u.s. consular offices , which collect biometric information from applicants for visas , and check this information against a database of known criminals and suspected terrorists .

when a visitor arrives at a port of entry , the biometric information is used to verify that the visitor is the person who was issued the visa or other travel documents .

ultimately , visitors are to confirm their departure by having their visas or passports scanned and undergoing fingerscanning .

 ( currently , at a few pilot sites , departing visitors are asked to undergo these exit procedures. ) .

the exit confirmation is added to the visitor's travel records to demonstrate compliance with the terms of admission to the united states .

other key us - visit functions include ● collecting , maintaining , and sharing information on certain foreign nationals who enter and exit the united states ; identifying foreign nationals who ( 1 ) have overstayed or violated the terms of their admission ; ( 2 ) may be eligible to receive , extend , or adjust their immigration status ; or ( 3 ) should be apprehended or detained by law enforcement officials ; ● detecting fraudulent travel documents , verifying traveler identity , and determining traveler admissibility through the use of biometrics ; and ● facilitating information sharing and coordination within the immigration and border management community .

in july 2003 , dhs established a program office with responsibility for managing the acquisition , deployment , operation , and sustainment of the us - visit system and its associated supporting people ( eg , customs and border protection officers ) , processes ( eg , entry / exit policies and procedures ) , and facilities ( eg , inspection booths and lanes ) .

as of october 2005 , about $1.4 billion has been appropriated for the program , and according to program officials , about $962 million has been obligated to acquire , develop , deploy , operate , and maintain us - visit entry capabilities , and to test and evaluate exit capability options .

dhs plans to deliver us - visit capability in four increments , with increments 1 through 3 being interim , or temporary , solutions that fulfill legislative mandates to deploy an entry / exit system , and increment 4 being the implementation of a long - term vision that is to incorporate improved business processes , new technology , and information sharing to create an integrated border management system for the future .

in increments 1 through 3 , the program is building interfaces among existing ( “legacy” ) systems , enhancing the capabilities of these systems , and deploying these capabilities to air , sea , and land ports of entry .

these first three increments are to be largely acquired and implemented through existing system contracts and task orders .

in may 2004 , dhs awarded an indefinite - delivery / indefinite - quantity prime contract to accenture and its partners .

according to the contract , the prime contractor will help support the integration and consolidation of processes , functionality , and data , and it will develop a strategy to build on the technology and capabilities already available to produce the strategic solution , while also assisting the program office in leveraging existing systems and contractors in deploying the interim solutions .

increment 1 concentrates on establishing capabilities at air and sea ports of entry .

it is divided into two parts — 1a and 1b .

● increment 1a ( air and sea entry ) includes the electronic capture and matching of biographic and biometric information ( two digital index fingerscans and a digital photograph ) for selected foreign nationals , including those from visa waiver countries .

increment 1a was deployed on january 5 , 2004 , through the modification of pre - existing systems .

these modifications accommodated the collection and maintenance of additional data fields and established interfaces required to share data among dhs systems in support of entry processing at 115 airports and 14 seaports .

● increment 1b ( air and sea exit ) involves the testing of exit devices to collect biometric exit data for select foreign nationals .

three exit alternatives were pilot tested at 11 air and sea ports of entry .

these alternatives are as follows .

● kiosk — a self - service device ( including a touch screen interface , document scanner , finger scanner , digital camera , and receipt printer ) that captures a digital photograph and fingerprint and prints out an encoded receipt .

● mobile device — a hand - held device that is operated by a workstation attendant and includes a document scanner , finger scanner , digital camera , and receipt printer to capture a digital photograph and fingerprint .

● validator — a hand - held device that is used to capture a digital photograph and fingerprint , which are then matched to the photograph and fingerprint captured via the kiosk and encoded in the receipt .

increment 2 focuses primarily on extending us - visit to land ports of entry .

it is divided into three parts — 2a , 2b , and 2c .

● increment 2a ( air , sea , and land entry ) includes the capability to biometrically compare and authenticate valid machine - readable visas and other travel and entry documents at all ports of entry .

increment 2a was deployed on october 23 , 2005 , according to program officials .

it also includes the deployment by october 26 , 2006 , of the capability to read biometrically enabled passports from visa waiver countries .

● increment 2b ( land entry ) redesigned the increment 1 entry solution and expanded it to the 50 busiest land ports of entry .

the process for issuing entry / exit forms was redesigned to enable the electronic capture of biographic , biometric ( unless the traveler is exempt ) , and related travel documentation for arriving travelers .

this increment was deployed to the busiest 50 u.s. land border ports of entry on december 29 , 2004 .

before increment 2b , all information on the entry / exit forms was hand written .

the redesigned process provides for electronically capturing the biographic data on the entry / exit form .

in some cases , customs and border protection ( cbp ) officers enter the data electronically and then print the completed form .

● increment 2c ( land entry and exit ) is to provide the capability to automatically , passively , and remotely record the entry and exit of covered individuals using radio frequency ( rf ) technology tags at primary inspection and exit lanes .

this tag includes a unique id number that is to be embedded in each entry / exit form , thus associating a unique number with a us - visit record for the person holding that form .

one of dhs's goals in using this technology is to improve the ability to collect entry and exit information .

in august 2005 , the program office deployed the technology to three land ports of entry to verify the feasibility of using passive rf technology to record traveler entries and exits from the number embedded in the entry / exit form .

the results of this demonstration are to be reported in february 2006 .

increment 3 extended increment 2b ( land entry ) capabilities to 104 land ports of entry ; this increment was essentially completed as of december 19 , 2005 .

increment 4 is the strategic us - visit program capability , which program officials stated will likely consist of a further series of incremental releases or mission capability enhancements that will support business outcomes .

the program reports that it has worked with its prime contractor and partners to develop this overall vision for the immigration and border management enterprise .

all increments before increment 4 depend on the interfacing and integration of existing systems , including the following: ● the arrival and departure information system ( adis ) stores ● noncitizen traveler arrival and departure data received from air and sea carrier manifests , ● arrival data captured by cbp officers at air and sea ports of ● i - 94 issuance data captured by cbp officers at increment 2b land ● departure information captured at us - visit biometric departure pilot ( air and sea ) locations , ● pedestrian arrival information and pedestrian and vehicle departure information captured at increment 2c port of entry locations , and ● status update information provided by sevis and claims 3 ( described below ) .

adis provides record matching , query , and reporting functions .

● the passenger processing component of the treasury enforcement communications system ( tecs ) includes two systems: advance passenger information system ( apis ) , a system that captures arrival and departure manifest information provided by air and sea carriers , and the interagency border inspection system , a system that maintains lookout data and interfaces with other agencies' databases .

cbp officers use these data as part of the admission process .

the results of the admission decision are recorded in tecs and adis .

● the automated biometric identification system ( ident ) collects and stores biometric data about foreign visitors .

● the student and exchange visitor information system ( sevis ) and the computer linked application information management system ( claims 3 ) contain information on foreign students and foreign nationals who request benefits , such as change of status or extension of stay .

some of these systems , such as ident , are managed by the program office , while some systems are managed by other organizational entities within dhs .

for example , tecs is managed by cbp , sevis is managed by immigration and customs enforcement , claims 3 is under united states citizenship and immigration services , and adis is jointly managed by cbp and us - visit .

us - visit also interfaces with other , non - dhs systems for relevant purposes , including watch list updates and checks to determine whether a visa applicant has previously applied for a visa or currently has a valid u.s. visa .

in particular , us - visit receives biographic and biometric information from the department of state's consular consolidated database as part of the visa application process , and returns fingerscan information and watch list changes .

over the last 3 years , us - visit program officials and supporting contractor staff have worked to meet challenging legislative time frames , as well as a dhs - imposed requirement to use biometric identifiers .

under law , for example , dhs was to create an electronic entry and exit system to screen and monitor the stay of foreign nationals who enter and leave the united states and implement the system at ( 1 ) air and sea ports of entry by december 31 , 2003 , ( 2 ) the 50 highest - volume land ports of entry by december 31 , 2004 , and ( 3 ) the remaining ports of entry by december 31 , 2005 .

it was also to provide the means to collect arrival / departure data from biometrically enabled and machine - readable travel documents at all ports of entry .

to the program office's credit , it has largely met its obligations relative to an entry capability .

for example , on january 5 , 2004 , it deployed and began operating most aspects of its planned entry capability at 115 airports and 14 seaports , and added the remaining aspects in february 2005 .

during 2004 , it also deployed and began operating this entry capability in the secondary inspection areas of the 50 highest volume land ports of entry .

as of december 19 , 2005 , it had deployed and begun operating its entry capability at all but 1 of the remaining 104 land ports of entry .

the program has also been working to define feasible and cost - effective exit solutions , including technology feasibility testing at 3 land ports of entry and operational performance evaluations at 11 air and sea ports of entry .

moreover , the development and deployment of this entry capability has occurred during a period of considerable organizational change , starting with the creation of dhs from 23 separate agencies in early 2003 , followed by the establishment of a us - visit program office shortly thereafter — which was only about 5 months before it had to meet its first legislative milestone .

compounding these program challenges was the fact that the systems that were to be used in building and deploying an entry capability were managed and operated by a number of the separate agencies that had been merged to form the new department , each of which was governed by different policies , procedures , and standards .

as a result of the program's efforts to deploy and operate an entry capability , dhs reports that it has been able to apprehend and prevent the entry of hundreds of criminal aliens: as of march 2005 , dhs reported that more than 450 people with records of criminal or immigration violations have been prevented from entering .

for example , its biometric screening prevented the reentry of a convicted felon , previously deported , who was attempting to enter under an alias ; standard biographic record checks using only names and birth dates would have likely cleared the individual .

another potential consequence , although difficult to demonstrate , is the deterrent effect of having an operational entry capability .

although deterrence is not an expressly stated goal of the program , officials have cited it as a potential byproduct of having a publicized capability at the border to screen entry on the basis of identity verification and matching against watch lists of known and suspected terrorists .

accordingly , the deterrent potential of the knowledge that unwanted entry may be thwarted and the perpetrators caught is arguably a layer of security that should not be overlooked .

a prerequisite for prudent investment in programs is having reasonable assurance that a proposed course of action is the right thing to do , meaning that it properly fits within the larger context of an agency's strategic plans and related operational and technology environments , and that the program will produce benefits in excess of costs over its useful life .

we have made recommendations to dhs aimed at ensuring that this is in fact the case for us - visit , and the department has taken steps intended to address our recommendations .

these steps , however , have yet to produce sufficient analytical information to demonstrate that us - visit as defined is the right solution .

without this knowledge , investment in the program cannot be fully justified .

agency programs need to properly fit within a common strategic context or frame of reference governing key aspects of program operations — eg , what functions are to be performed by whom , when and where they are to be performed , what information is to be used to perform them , and what rules and standards will govern the application of technology to support them .

without a clear operational context for us - visit , the risk is increased that the program will not interoperate with related programs and thus not cost - effectively meet mission needs .

in september 2003 we reported that dhs had not defined key aspects of the larger homeland security environment in which us - visit would need to operate .

for example , certain policy and standards decisions had not been made , such as whether official travel documents would be required for all persons who enter and exit the country — including u.s. and canadian citizens — and how many fingerprints would be collected .

nonetheless , program officials were making assumptions and decisions at that time that , if they turned out to be inconsistent with subsequent policy or standards decisions , would require us - visit rework .

to minimize the impact of these changes , we recommended that dhs clarify the context in which us - visit is to operate .

about 28 months later , defining this operational context remains a work in progress .

for example , the program's relationships and dependencies with other closely allied initiatives and programs are still unclear .

according to the us - visit chief strategist , an immigration and border management strategic plan was drafted in march 2005 that shows how us - visit is aligned with dhs's organizational mission and that defines an overall vision for immigration and border management .

according to this official , the vision provides for an immigration and border management enterprise that unifies multiple internal departmental and other external stakeholders with common objectives , strategies , processes , and infrastructures .

as of december 2005 , however , we were told that this strategic plan has not been approved .

in addition , since the plan was drafted , dhs has reported that other relevant initiatives have been undertaken .

for example: ● the dhs security and prosperity partnership of north america is to , among other things , establish a common approach to securing the countries of north america — the united states , canada , and mexico — by , for example , implementing a border facilitation strategy to build capacity and improve the legitimate flow of people and cargo at our shared borders .

● the dhs secure border initiative is to implement a comprehensive approach to securing our borders and combating illegal immigration .

according to the chief strategist , portions of the strategic plan are being incorporated into these initiatives , but these initiatives and their relationships with us - visit are still being defined .

similarly , the mission and operational environment of us - visit are related to those of another major dhs program — the automated commercial environment ( ace ) , which is a new trade processing system that is planned to support the movement of legitimate imports and exports and to strengthen border security .

in addition , both us - visit and ace could potentially use common it infrastructures and services .

as we reported in february 2005 , the program office recognized these similarities , but managing the relationship between the two programs had not been a priority matter .

accordingly , we recommended that dhs give priority to understanding the relationships and dependencies between the us - visit and ace programs .

since our recommendation , the us - visit and ace managers have formed an integrated project team to , among other things , ensure that the two programs are programmatically and technically aligned .

program officials stated that the team has met three times since april 2005 and plans to meet on a quarterly basis going forward .

the team has discussed potential areas of focus and agreed to three areas: rf technology , program control , and data governance .

however , it does not have an approved charter , and it has not developed explicit plans or milestone dates for identifying the dependencies and relationships between the two programs .

it is important that dhs define the operational context for us - visit , as well as its relationships and dependencies with closely allied initiatives and such programs as ace .

the more time it takes to settle these issues , the more likely that extensive and expensive rework will be needed at a later date .

prudent investment also requires that an agency have reasonable assurance that a proposed program will produce mission value commensurate with expected costs and risks .

thus far , dhs has yet to develop an adequate basis for knowing that this is the case for its early us - visit increments .

without this knowledge , it cannot adequately ensure that these increments are justified .

assessments of costs and benefits are extremely important , because the decision to invest in any capability should be based on reliable analyses of return on investment .

according to omb guidance , individual increments of major systems are to be individually supported by analyses of benefits , cost , and risk .

in addition , omb guidance on the analysis needed to justify investments states that such analysis should meet certain criteria to be considered reasonable .

these criteria include , among other things , comparing alternatives on the basis of net present value and conducting uncertainty analyses of costs and benefits .

 ( dhs has also issued guidance on such economic analyses , which is consistent with that of omb. ) .

without reliable analyses , an organization cannot be reasonably assured that a proposed investment is a prudent and justified use of resources .

in september 2003 , we reported that the program had not assessed the costs and benefits of increment 1 .

accordingly , we recommended that dhs perform such assessments for future increments .

in february 2005 , we reported that although the program office had developed a cost - benefit analysis for increment 2b ( which provides the capability for electronic collection of traveler information at land ports of entry ) , it had again not justified the investment , because its treatment of both benefits and costs was unclear and insufficient .

further , we reported that the cost estimates on which the cost - benefit analysis was based were of questionable reliability , because effective cost - estimating practices were not followed .

accordingly , we recommended that dhs follow certain specified practices for estimating the costs of future increments .

since our february 2005 report , the program has developed a cost - benefit analysis for increment 1b ( which is to provide exit capabilities at air and sea ports of entry ) .

the latest version of this analysis , dated june 23 , 2005 , identifies potential costs and benefits for three exit solutions at air and sea ports of entry and provides a general rationale for the viability of the three alternatives described .

this latest analysis meets some but not all the omb criteria for economic analyses .

for example , it explains why the investment was needed , and it shows that at least two alternatives to the status quo were considered .

however , it does not include , for example , a complete uncertainty analysis for the three exit alternatives evaluated .

that is , it does not include a sensitivity analysis for the three alternatives , which is a major part of an uncertainly analysis .

 ( a sensitivity analysis is a quantitative assessment of the effect that a change in a given assumption — such as unit labor cost — will have on net present value. ) .

a complete analysis of uncertainty is important because it provides decision makers with a perspective on the potential variability of the cost and benefit estimates should the facts , circumstances , and assumptions change .

in addition , the quality of a cost - benefit analysis is dependent on the quality of the cost assessments on which it is based .

however , the cost estimate associated with the june 2005 cost - benefit analysis for the three exit solutions ( increment 1b ) did not meet key criteria for reliable cost estimating .

for example , it did not include a detailed work breakdown structure .

a work breakdown structure serves to organize and define the work to be performed , so that associated costs can be identified and estimated .

thus , it provides a reliable basis for ensuring that the estimates include all relevant costs .

program officials stated that they recognize the importance of developing reliable cost estimates and have initiated actions to more reliably estimate the costs of future increments .

for example , the program has chartered a cost analysis process action team , which is to develop , document , and implement a cost analysis policy , process , and plan for the program .

program officials also stated that they have hired additional contracting staff with cost - estimating experience .

strengthening the program's cost - estimating capability is extremely important .

the absence of reliable cost estimates impedes , among other things , both the development of reliable economic justification for program decisions and the effective measurement of performance .

program decisions and planning depend on adequate analyses and assessments of program impacts and options .

the department has begun to develop such analyses , but some of these , such as its analyses of the operational impact of increment 2b and of the options for its exit capability , do not yet provide an adequate basis for investment and deployment decisions .

we reported in may 2004 that the program had not assessed its workforce and facility needs for increment 2b ( which provides the capability for electronic collection of traveler information at land ports of entry ) .

because of this , we questioned the validity of the program's assumptions and plans concerning workforce and facilities , since the program lacked a basis for determining whether its assumptions were correct and thus whether its plans were adequate .

accordingly , we recommended that dhs assess the full impact of increment 2b on workforce levels and facilities at land ports of entry , including performing appropriate modeling exercises .

seven months later , the program office evaluated increment 2b operational performance , with the stated purpose of determining the effectiveness of increment 2b performance at the 50 busiest land ports of entry .

for this evaluation , the program office established a baseline for comparing the average times to issue and process entry / exit forms at 3 of these 50 ports of entry .

the program office then conducted two evaluations of the processing times at the three ports , first after increment 2b was deployed as a pilot , and next 3 months later , after it was deployed to all 50 ports of entry .

the evaluation results showed that the average processing times decreased for all three sites .

program officials concluded that these results supported their workforce and facilities planning assumptions that no additional staff was required to support deployment of increment 2b and that minimal modifications were required at the facilities .

however , the scope of the evaluations is not sufficient to satisfy the evaluations' stated purpose or our recommendation for assessing the full impact of 2b .

for example , the selection of the three sites , according to program officials , was based on a number of factors , including whether the sites already had sufficient staff to support the pilot .

selecting sites based on this factor could affect the results , and it presupposes that not all ports of entry have the staff needed to support 2b .

in addition , evaluation conditions were not always held constant: specifically , fewer workstations were used to process travelers in establishing the baseline processing times at two of the ports of entry than were used during the pilot evaluations .

moreover , cbp officials from a land port of entry that was not an evaluation site ( san ysidro ) told us that us - visit deployment has not reduced but actually lengthened processing times .

 ( san ysidro processes the highest volume of travelers of all land ports of entry. ) .

although these officials did not provide specific data to support their statement , their perception nevertheless raises questions about the potential impact of increment 2b on the 47 sites that were not evaluated .

similarly , in february 2005 , we reported that us - visit had not adequately planned for evaluating the alternatives for increment 1b ( which provides exit capabilities at air and sea ports of entry ) because the scope and timeline of its exit pilot evaluation were compressed .

accordingly , we recommended that dhs reassess plans for deploying an exit capability to ensure that the scope of the exit pilot provides for adequate evaluation of alternative solutions .

over the last 11 months , the program office has taken actions to expand the scope and time frames of the pilot .

for example , it increased the number of ports of entry in the pilot from 5 to 11 , and it also extended the time frame by about 7 months .

further , according to program officials , they were able to achieve the target sample sizes necessary to have a 95 percent confidence level in their results .

nevertheless , questions remain about whether the exit alternatives have been adequately evaluated to permit selection of the best exit solution for national deployment .

for example , one of the criteria against which the alternatives were evaluated was the rate of traveler compliance with us - visit exit policies ( that is , foreign travelers providing information as they exit the united states ) .

however , across the three alternatives , the average compliance with these policies was only 24 percent , which raises questions as to their effectiveness .

the evaluation report cites several reasons for the low compliance rate , including that compliance during the pilot was voluntary .

the report further concludes that national deployment of the exit solution will not meet the desired compliance rate unless the exit process incorporates an enforcement mechanism , such as not allowing persons to reenter the united states if they do not comply with the exit process .

although an enforcement mechanism might indeed improve compliance , program officials stated that no formal evaluation has been conducted of enforcement mechanisms or their possible effect on compliance .

the program director agreed that additional evaluation is needed to assess the impact of implementing potential enforcement mechanisms and plans to do such evaluation .

establishing effective program management capabilities is important to ensure that an organization is going about delivering a program in the right way .

accordingly , we have made recommendations to establish specific people and process management capabilities .

while dhs is making progress in implementing many of our recommendations in this area , this progress has often been slow .

one area in which dhs has made good progress is in implementing our recommendations to establish the human capital capabilities necessary to manage us - visit .

in september 2003 , we reported that the us - visit program had not fully staffed or adequately funded its program office or defined specific roles and responsibilities for program office staff .

our prior experience with major acquisitions like us - visit shows that to be successful , they need , among other things , to have adequate resources , and program staff need to understand what they are to do , how they relate to each other , and how they fit in their organization .

in addition , prior research and evaluations of organizations show that effective human capital management can help agencies establish and maintain the workforce they need to accomplish their missions .

accordingly , we recommended that dhs ensure that human capital and financial resources are provided to establish a fully functional and effective program office , and that the department define program office positions , roles , and responsibilities .

we also recommended that dhs develop and implement a human capital strategy for the program office that provides for staffing positions with individuals who have the appropriate knowledge , skills , and abilities .

dhs has implemented our recommendation that it define program office positions , roles , and responsibilities , and it has partially completed our two other people - related recommendations .

it has filled most of its planned government positions and is on the way to filling the rest , and it has filled all of its planned contractor positions .

however , the program completed a workforce analysis in february 2005 and requested additional positions based on the results .

securing these necessary resources will be a continuing challenge .

in addition , as we reported in february 2005 , the program office , working with the office of personnel management , developed a draft human capital plan that employed widely accepted human capital planning tools and principles ( for example , it included an action plan that identified activities , their proposed completion dates , and the office responsible for the action ) .

in addition , the program office had completed some of the activities in the plan .

since then , the program office has finalized the human capital plan , completed more activities , and formulated plans to complete others ( for example , according to the program office , it has completed an analysis of its workforce to determine diversity trends , retirement and attrition rates , and mission - critical and leadership competency gaps , and it has plans to complete an analysis of workforce data to maintain strategic focus on preserving the skills , knowledge , and leadership abilities required for the us - visit program's success ) .

program officials also said that the reason they have not completed several activities in the plan is that these activities are related to the department's new human capital initiative , maxhr .

because this initiative is to include the development of departmentwide competencies , program officials told us that it could potentially affect ongoing program activities related to competencies .

as a result , these officials said that they are coordinating these activities closely with the department as it develops and implements this new initiative , which is currently being reviewed by the dhs deputy secretary .

dhs's progress in implementing our human capital recommendations should help ensure that it has sufficient staff with the right skills and abilities to successfully execute the program .

having such staff has been and will be particularly important in light of the program's more limited progress to date in establishing program management process capabilities .

dhs's progress in establishing effective processes governing how program managers and staff are to perform their respective roles and responsibilities has generally been slow .

in our experience , weak process management controls typically result in programs falling short of expectations .

from september 2003 , we have made numerous recommendations aimed at enabling the program to strengthen its process controls in such areas as acquisition management , test management , risk management , configuration management , capacity management , security , privacy , and independent verification and validation ( iv&v ) .

dhs has not yet completed the implementation of any of our recommendations in these areas , with one exception .

it has ensured that the program office's iv&v contractor was independent of the products and processes that it was verifying and validating , as we recommended .

in july 2005 , the program office issued a new contract for iv&v services after following steps to ensure the contractor's independence ( for example , iv&v contract bidders were to be independent of the development and integration contractors and are prohibited from soliciting , proposing , or being awarded work for the program other than iv&v services ) .

if effectively implemented , these steps should adequately ensure that verification and validation activities are performed in an objective manner , and thus should provide valuable assistance to program managers and decision makers .

in the other management areas , dhs has partially completed or has only begun to address our recommendations , and more remains to be done .

for example , dhs has not completed the development and implementation of key acquisition controls .

we reported in september 2003 that the program office had not defined key acquisition management controls to support the acquisition of us - visit , increasing the risk that the program would not satisfy system requirements or meet benefit expectations on time and within budget .

accordingly , we recommended that dhs develop and implement a plan for satisfying key acquisition management controls in accordance with best practices .

the program office has recently taken steps to lay the foundation for establishing key acquisition management controls .

for example , it has developed a process improvement plan to define and implement these controls that includes a governance structure for overseeing improvement activities .

in addition , the program office has recently completed a self - assessment of its acquisition process maturity , and it plans to use the assessment results to establish a baseline of its acquisition process maturity as a benchmark for improvement .

according to program officials , the assessment included key process areas that are generally consistent with the process areas cited in our recommendation .

the program has ranked these process areas and plans to focus on those with highest priority .

 ( some of these high - priority process areas are also areas in which we have made recommendations , such as configuration management and risk management. ) .

the improvement plan is currently being updated to reflect the results of the baseline assessment and to include a work breakdown structure , process prioritization , and resource estimates .

according to a program official , the goal is to conduct a formal appraisal to assess the capability level of some or all of the high - priority process areas by october 2006 .

these recent steps provide a foundation for progress , but fully and effectively implementing key acquisition management controls takes considerable time , and dhs is still in the early stages of the process .

therefore , it is important that these improvement efforts stay on track .

until these controls are effectively implemented , us - visit will be at risk of not delivering promised capabilities on time and within budget .

another management area of high importance to a complex program like us - visit is test management .

the purpose of system testing is to identify and correct system defects before the system is deployed .

to be effective , testing activities should be planned and implemented in a structured and disciplined fashion .

among other things , this includes developing effective test plans to guide the testing activities and ensuring that test plans are developed and approved before test execution .

in this area also , dhs's progress responding to our recommendation has been limited .

we reported in may 2004 , and again in february 2005 , that system testing was not based on well - defined test plans , and thus the quality of testing being performed was at risk .

because dhs test plans were not sufficiently well - defined to be effective , we recommended that before testing begins , dhs develop and approve test plans that meet the criteria that relevant systems development guidance prescribes for effective test plans: namely , that they ( 1 ) specify the test environment ; ( 2 ) describe each test to be performed , including test controls , inputs , and expected outputs ; ( 3 ) define the test procedures to be followed in conducting the tests ; and ( 4 ) provide traceability between the test cases and the requirements to be verified by the testing .

about 20 months later , the quality of the system test plans , and thus system testing , is still a challenge .

to the program's credit , the test plans for the proof of concept for increment 2c , dated june 28 , 2005 ( which introduces rf technology to automatically record the entry and exit of covered individuals ) , satisfied part of our recommendation .

specifically , the test plan for this increment was approved on june 30 , 2005 , before testing began ( according to program officials , it began on july 5 , 2005 ) .

further , the test plan described , for example , the scope , complexity , and completeness of the test environment ; it described the tests to be performed , including a high - level description of controls , inputs , and outputs ; and it identified the test procedures to be performed .

however , the test plan did not adequately trace between test cases and the requirements to be verified by testing .

for example , about 70 percent of the requirements that we analyzed did not have specific references to test cases .

further , we identified traceability inconsistencies , such as one requirement that was mapped to over 50 test cases , even though none of the 50 cases referenced the requirement .

time and resource constraints were identified as the reasons that test plans have not been complete .

specifically , program officials stated that milestones do not permit existing testing / quality personnel the time required to adequately review testing documents .

according to these officials , even when the start of testing activities is delayed because , for example , requirements definition or product development takes longer than anticipated , testing milestones are not extended .

without complete test plans , the program does not have adequate assurance that the system is being fully tested , and thus unnecessarily assumes the risk of system defects not being detected and addressed before the system is deployed .

this means that the system may not perform as intended when deployed , and defects will not be addressed until late in the systems development cycle , when they are more difficult and time - consuming to fix .

this has in fact happened already: postdeployment system interface problems surfaced for increment 1 , and manual work - arounds had to be implemented after the system was deployed .

until process management weaknesses such as these are addressed , the program will continue to be overly dependent on the exceptional performance of individuals to produce results .

such dependence increases the risk of the us - visit program falling short of expectations .

to better ensure that us - visit and dhs meet expectations , we made recommendations related to measuring and disclosing progress against program commitments .

thus far , such performance and accountability mechanisms have yet to be fully established .

measurements of the operational performance of the system are necessary to ensure that the system adequately supports mission operations , and measurements of program progress and outcomes are important for demonstrating that the program is on track and is producing results .

without such measurements , program performance and accountability can suffer .

as we reported in september 2003 , the operational performance of initial system increments was largely dependent on the performance of existing systems that were to be interfaced to create these increments .

for example , we said that the performance of an increment would be constrained by the availability and downtime of the existing systems , some of which had known problems in these areas .

accordingly , we recommended that dhs define performance standards for each increment that are measurable and that reflect the limitations imposed by this reliance on existing systems .

in february 2005 , we reported that several technical performance standards for increments 1 and 2b had been defined , but that it was not clear that these standards reflected the limitations imposed by the reliance on existing systems .

since then , the program office has defined certain other technical performance standards for the next increment ( increment 2c , phase 1 ) , including standards for availability .

consistent with what we reported , the functional requirements document states that these performance standards are largely dependent upon those of the current systems , and for system availability , it sets an aggregated availability standard for increment 2c components .

however , the document does not contain sufficient information for a determination of whether these performance standards actually reflect the limitations imposed by reliance on existing systems .

unless the program defines performance standards that do this , it will be unable to identify and effectively address performance shortfalls .

similarly , as we observed in june 2003 , to permit meaningful program oversight , it is important that expenditure plans describe how well dhs is progressing against the commitments made in prior expenditure plans .

the expenditure plan for fiscal year 2005 ( the fourth us - visit expenditure plan ) does not describe progress against commitments made in the previous plans .

for example , according to the fiscal year 2004 plan , us - visit was to analyze , field test , and begin deploying alternative approaches for capturing biometrics during the exit process .

however , according to the fiscal year 2005 plan , us - visit was to expand its exit pilot sites during the summer and fall of 2004 , and it would not deploy the exit solution until fiscal year 2005 .

the plan does not explain the reason for this change from its previous commitment nor its potential impact .

nor does it describe the status of the exit pilot testing or deployment , such as whether the program has met its target schedule or whether the schedule has slipped .

additionally , the fiscal year 2004 plan stated that $45 million in fiscal year 2004 was to be used for exit activities .

however , in the fiscal year 2005 plan , the figure for exit activities was $73 million in fiscal year 2004 funds .

the plan does not highlight this difference or address the reason for the change in amounts .

also , although the fiscal year 2005 expenditure plan includes benefits stated in the fiscal year 2004 plan , it does not describe progress in addressing those benefits , even though in the earlier plan , us - visit stated that it was developing metrics for measuring the projected benefits , including baselines by which progress could be assessed .

the fiscal year 2005 plan again states that performance measures are under development .

figure 1 provides our analysis of the commitments made in the fiscal year 2003 and 2004 plans , compared with progress reported and planned in february 2005 .

the deployment of an exit capability , an important aspect of the program that was to result from the exit pilots shown in the figure , further illustrates missed commitments that need to be reflected in the next expenditure plan .

in the fiscal year 2005 expenditure plan , the program committed to deploying an exit capability to air and sea ports of entry by september 30 , 2005 .

although us - visit has completed its evaluation of exit solutions at 11 pilot sites ( 9 airports and 2 seaports ) , no decision has yet been made on when an exit capability will be deployed .

according to program officials , deployment to further sites would take at least 6 months from the time of the decision .

this means that the program office will not meet its commitment .

another accountability mechanism that we recommended in may 2004 is for the program to develop a plan , including explicit tasks and milestones , for implementing all our open recommendations , and report on progress , including reasons for delays , both to department leadership ( the dhs secretary and under secretary ) in periodic reports and to the congress in all future expenditure plans .

the department has taken action to address this recommendation , but the initial report does not disclose enough information for a complete assessment of progress .

the program office did assign responsibility to specific individuals for preparing the implementation plan , and it developed a report identifying the person responsible for each recommendation and summarizing progress .

this report was provided for the first time to the dhs deputy secretary on october 3 , 2005 , and the program office plans to forward subsequent reports every 6 months .

however , some of the report's progress descriptions are inconsistent with our assessment .

for example , the report states that the impact of increment 2b on workforce levels and facilities at land ports of entry has been fully assessed .

however , as mentioned earlier , evaluation conditions were not always held constant — that is , fewer workstations were used to process travelers in establishing the baseline processing times at two of the ports of entry than were used during the pilot evaluations .

in addition , the report does not specifically describe progress against most of our recommendations .

for example , we recommended that the program reassess plans for deploying an exit capability to ensure that the scope of the exit pilot provides for adequate evaluation of alternative solutions .

with regard to the exit evaluation , the report states that the program office has completed exit testing and has forwarded the exit evaluation report to the deputy secretary for a decision .

however , it does not state whether the program office had expanded the scope or time frames of the pilot .

in closing , i would emphasize that the program has met many of the demanding requirements in law for deployment of an entry - exit system , owing , in large part , to the hard work and dedication of the program office and its contractors , as well as the close oversight and direction of the house and senate appropriations committees .

nevertheless , core capabilities , such as exit , have yet to be established and implemented , and fundamental questions about the program's fit within the larger homeland security context and its return on investment remain unanswered .

moreover , the program is overdue in establishing the means to effectively manage the delivery of future capabilities .

the longer the program proceeds without these , the greater the risk that the program will not meet its commitments .

measuring and disclosing the extent to which these commitments are being met are also essential to holding the department accountable , and thus are an integral aspect of effective program management .

our recommendations provide a comprehensive framework for addressing each of these important areas and thus ensuring that the program as defined is the right solution , that delivery of this solution is being managed in the right way , and that accountability for both is in place .

we look forward to continuing to work constructively with the program to better ensure the program's success .

mr. chairman , this concludes my statement .

i would be happy to answer any questions that you or members of the committee may have at this time .

if you should have any questions about this testimony , please contact randolph c. hite at ( 202 ) 512-3439 or hiter@gao.gov .

other major contributors to this testimony included tonia brown , barbara collier , deborah davis , james houtz , scott pettis , and dan wexler .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

it may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

