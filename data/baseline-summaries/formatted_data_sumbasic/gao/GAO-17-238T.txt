i am pleased to be here today to discuss the progress of the u.s. census bureau's ( bureau ) preparations for the 2020 census .

as requested , my remarks will focus on ( 1 ) the preliminary results to date of the bureau's 2016 census test in los angeles ( l.a. ) county , california , and harris county , texas ; ( 2 ) the status of the bureau's test of address canvassing procedures in buncombe county , north carolina , and st. louis , missouri ; and ( 3 ) the lessons learned from the 2010 census that can be applied to the bureau's preparations for 2020 .

in his statement today , my colleague will discuss the bureau's approach to deliver an enterprise information technology initiative , and to ensure the integrity and security of systems and data in support of the 2020 census .

we anticipate issuing a report on the bureau's 2016 test early in the new year .

sufficient testing , while important to the success of any census , is even more critical for the bureau's preparations for 2020 .

to help control costs and maintain accuracy , the 2020 census design includes new procedures and technology that have not been used extensively in earlier decennials , if at all .

while these innovations show promise for a more cost - effective head count , they also introduce new risks .

as we have noted in our prior work , it will be important to thoroughly test the operations planned for 2020 to ensure they will ( 1 ) produce needed cost savings , ( 2 ) function in concert with other census operations , and ( 3 ) work at the scale needed for the national head count .

the bureau's failure to fully test some key operations prior to the 2010 census was a key factor that led us to designate that decennial as one of our high - risk areas .

a key objective of the 2016 census test in harris and l.a .

counties was to refine the methodology for nonresponse follow - up ( nrfu ) , where enumerators personally visit households that do not self - respond to the census .

nrfu is the largest and costliest of all census - taking activities because it is so labor intensive .

the bureau selected harris and l.a. counties as test sites for several reasons including language diversity , demographic diversity , high vacancy rates , and varying levels of internet usage .

there are around 225,000 housing units in each test area .

the bureau estimates that re - engineering its field procedures could save as much as $2.5 billion .

in conducting the 2016 address canvassing test , which began in august 2016 , the bureau is to measure the effectiveness of new procedures for building its address list .

buncombe county , north carolina , is a mix of urban , suburban , and rural territories while st. louis is a principal city .

accurate addresses and precise maps are critical for the census , in part because census data are used for congressional apportionment , redistricting , and allocations of federal aid to state and local governments .

in prior decades , the bureau employed field staff to walk almost every street in the nation as one of several operations to update the bureau's inventory of addresses and geography .

for 2020 , the bureau plans to target its traditional or “in - field” canvassing efforts to those areas most in need of updating such as those that have experienced rapid recent housing development and for which the bureau has no data sources capturing those changes .

the bureau will rely on “in - office” procedures to update the majority of addresses in the country .

these procedures include validating addresses through aerial imagery and by using data from the u.s .

postal service as well as from state , local , and tribal governments .

the bureau estimates it will save up to $1 billion with the successful implementation of this initiative .

my testimony is based on our ongoing reviews of the 2016 census test and address canvassing test .

for these studies , we reviewed bureau documents and preliminary data , interviewed local and headquarters bureau officials , and for the 2016 census test , made several site visits to los angeles and harris counties to observe nrfu procedures .

for the address canvassing test , we made site visits to buncombe county , north carolina and st. louis to observe in - field address canvassing procedures and to the bureau's national processing center in jeffersonville , indiana to observe in - office canvassing .

these observations are not generalizable .

on september 16 , 2016 , we shared the information included in this statement with the census bureau for its review .

on september 21 , 2016 , we met with bureau officials and they provided technical comments which we included , as appropriate .

my testimony is also based on our prior work on the bureau's preparations for 2020 , as well as our work on lessons learned from the conduct of the 2010 census .

for those studies , we reviewed bureau planning documents and test plans , interviewed bureau officials , and made site visits to observe how census operations were being implemented in the field .

the work on which this statement is based was conducted in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

with a cost of about $12.3 billion , the 2010 census was the most expensive population count in u.s. history , costing about 31 percent more than the $9.4 billion 2000 census ( in constant 2020 dollars ) .

some cost growth is to be expected because the population is growing and becoming more complex and difficult to count , which increases the bureau's workload .

however , the cost of counting each housing unit has escalated from about $16 in 1970 to $92 in 2010 ( in constant 2020 dollars ) , according to the bureau .

for the 2020 census , the bureau intends to limit its per - household cost to not more than that of the 2010 census , adjusted for inflation .

to achieve this goal , the bureau is significantly changing how it conducts the census , in part by re - engineering key census - taking methods and infrastructure .

the bureau's innovations include ( 1 ) using the internet as a self - response option ; ( 2 ) verifying most addresses using “in - office” procedures rather than costly field canvassing ; ( 3 ) re - engineering data collection methods ; and ( 4 ) in certain instances , replacing enumerator - collected data with administrative records ( information already provided to federal and state governments as they administer other programs ) .

the bureau's various initiatives have the potential to reduce costs .

in october 2015 , the bureau estimated that with its new approach it can conduct the 2020 census for a life - cycle cost of $12.5 billion , $5.2 billion less than if it were to repeat the design and methods of the 2010 census ( both in constant 2020 dollars ) .

however , in june 2016 , we reported that this $12.5 billion cost estimate was not reliable and did not adequately account for risk .

table 1 below shows the bureau's estimated cost savings it hopes to achieve in the following four innovation areas .

the 2016 test was the latest major test of nrfu in the bureau's testing program .

in 2014 , the bureau tested new methods for conducting nrfu in the maryland and washington , d.c. , area .

in 2015 , the bureau assessed nrfu operations , in maricopa county , arizona .

in 2018 , the bureau plans to conduct a final “end - to - end” test which is essentially a dress rehearsal for the actual decennial .

the bureau needs to finalize the census design by the end of fiscal year 2017 so that key activities can be included in the end - to - end test .

the bureau plans to conduct additional research through 2018 in order to further refine the design of the 2020 census , but recently had to alter its approach .

on october 18 , 2016 , the bureau decided to stop two field test operations planned for fiscal year 2017 in order to mitigate risks from funding uncertainty .

specifically , the bureau said it would stop all planned field activity , including local outreach and hiring , at its test sites in puerto rico , north and south dakota , and washington state .

the bureau will not carry out planned field tests of its mail - out strategy and follow up for non - response in puerto rico , or its door - to - door enumeration .

the bureau also cancelled plans to update its address list in the indian lands and surrounding areas in the three states .

however , the bureau will continue with other planned testing in fiscal year 2017 , such as those focusing on systems readiness and internet response .

further , the bureau said it would consider incorporating the cancelled field activities elements within the 2018 end - to - end test .

the bureau maintains that stopping the 2017 field test will help prioritize readiness for the 2018 end - to - end test , and mitigate risk .

nevertheless it also represents a lost opportunity to test , refine , and integrate operations and systems , and puts more pressure on the 2018 test to demonstrate that enumeration activities will function as needed for 2020 .

nrfu generally proceeded according to the bureau's operational plans .

however , our observations and the bureau's preliminary data at both test sites found that ( 1 ) there were a large number of non - interviews , and ( 2 ) enumerators had difficulty implementing new census - taking procedures .

the bureau's 2016 census test included a new field management structure that , among other things , included an enhanced operations control system supporting daily assignments of cases .

a cornerstone of the bureau's efforts to reduce the cost of nrfu is the automation of decision - making on how to manage the follow - up caseload .

unlike previous censuses and one prior test , enumerators in the 2016 census test did not have an assigned set of cases that they alone would work until completion .

instead , the bureau relied on an enhanced operational control system that was designed to provide daily assignments and street routing of non - response follow - up cases to enumerators in the most optimal and efficient way .

the bureau first tested this system in the 2015 census test .

the test also included streamlined procedures for making contact at large apartment buildings .

this was intended to reduce repeated attempts to contact property managers .

a key objective of the 2016 census test was to refine procedures for collecting nrfu data from households using mobile devices leased from a contractor .

in prior decennials , enumerators collected nrfu information using paper and pencil .

the bureau believes that replacing paper - based operations with automated case management and mobile devices for collecting interview data will provide a faster , more accurate , and more secure means of data collection in the 2020 census ( see figure 1 ) .

some test activities that we observed at both test sites included streamlined multi - unit contact procedures and interviews with a proxy respondent .

a proxy is someone who is a non - household member , at least 15 years old , and knowledgeable about the nrfu address .

at multi - unit structures such as apartment buildings , the enumerator is trained to first interview the property manager to find out which units were occupied and which were vacant on census day .

such interviews help to streamline nrfu by removing vacant units from an enumerator's workload .

they also help build a rapport with property managers by ensuring they know when enumerators are working in their building and can also help them gain access to locked buildings .

preliminary data at both test sites indicate that the bureau experienced a large number of non - interviews .

according to the bureau , non - interviews are cases where either no data or insufficient data were collected , in part because the cases reached the maximum number of six attempted visits without success or were not completed due to , for example , language barriers or dangerous situations .

while not necessarily a precursor to the 2020 non - interview rate , because of its relationship to the cost and quality of the count , it will be important for the bureau to better understand the factors contributing to it .

according to preliminary 2016 census test data , there were 19,721 nrfu cases coded as non - interviews in harris county , texas and 14,026 in los angeles county , california , or about 30 and 20 percent of the test workload respectively .

in such cases , the bureau may have to impute attributes of the household based on the demographic characteristics of surrounding housing units as well as administrative records .

bureau officials expect higher numbers of non - interviews during tests in part because , compared to the actual enumeration , the bureau conducts less outreach and promotion .

bureau officials hypothesized that another contributing factor could be related to nrfu methods used in the 2016 test compared to earlier decennials .

for the 2010 and earlier decennials , enumerators collected information during nrfu using pencil and paper .

enumerators may have visited a housing unit more than the 6 maximum allowable visits to obtain an interview but did not record all of their attempts , thus enabling them to achieve a higher completion rate .

for the 2020 census , and as tested in 2016 , the bureau plans to collect data using mobile devices leased from a contractor , and an automated case management system to manage each household visit .

the bureau believes that this approach will provide a faster , more accurate , and more secure means of data collection .

at the same time , the mobile device and automated case management system did not allow an enumerator to attempt to visit a housing unit more than once per day , reopen a closed case , or exceed the maximum allowable six attempts .

one factor we observed that may have contributed to the non - interview rate was that enumerators did not seem to uniformly understand nor follow procedures for completing interviews with proxy respondents .

according to the 2016 census test enumerator training manual , when an eligible respondent at the address cannot be located , the automated case management system on the mobile device will prompt the enumerator when to find a proxy to interview , such as when no one is home or the housing unit appears vacant .

in such circumstances , enumerators are to find a neighbor or landlord to interview .

however , in the course of our site visits , we observed that enumerators did not always follow these procedures .

for example , one enumerator , when prompted to find a proxy , looked to the left and then right and , finding no one , closed the case .

similarly , another enumerator ignored the prompt to find a proxy and explained that neighbors are usually not responsive or willing to provide information about the neighbor , and did not seek to find a proxy .

enumerators we interviewed did not seem to understand the importance of obtaining a successful proxy interview , and many appeared to have received little encouragement during training to put in the effort to find a proxy .

proxy data for occupied households are important to the success of the census as the alternative is a non - interview .

in 2010 , about one - fourth of the nrfu interviews for occupied housing units were conducted using proxy data .

we shared our observations with bureau officials who told us that they are aware that enumerator training for proxies needs to be revised to convey the importance of collecting proxy data when necessary .

converting non - interviews by collecting respondent or proxy data can improve interview completion rates , and ultimately the quality of census data .

the bureau told us it will continue to refine procedures for 2020 .

according to the bureau , its plans to automate the assignment of nrfu cases have the potential to deliver significant efficiency gains .

at the same time , refinements to certain enumeration procedures and better communication could produce additional efficiencies by enabling the bureau to be more responsive to situations enumerators encounter in the course of their follow - up work .

enumerators were unable to access recently closed incomplete cases .

under current procedures , if an enumerator is unable to make contact with a household member , the case management system closes that case and it is to be reattempted at a later date , perhaps by a different enumerator , assuming the enumerator has not exceeded six attempts .

decisions on when reattempts will be made — and by whom — are automated and not designed to be responsive to the immediate circumstances on the ground .

this is in contrast to earlier decennials when enumerators , using paper - based data collection procedures , had discretion and control over when to re - attempt cases in the area where they were working .

according to the bureau , leaving cases open for re - attempts can undermine the efficiency gains of automation when enumerators depart significantly from their optimized route , circling back needlessly to previously attempted cases rather than progressing through their scheduled workload .

during our test site observations , however , we preliminarily found how this approach could lead to inefficiencies in certain circumstances .

for example , we observed enumerators start their nrfu visits in the early afternoon as scheduled , when many people are out working or are otherwise away .

if no one answered the door , those cases were closed for the day and reassigned later .

however , if a household member returned while the enumerator was still around , the enumerator could not reopen the case and attempt an interview .

we saw this at both test site locations , typically in apartment buildings or at apartment - style gated communities , where enumerators had clear visibility to a large number of housing units and could easily see people arriving home .

bureau officials acknowledged that closing cases in this fashion represented a missed opportunity and plan to test greater flexibilities as part of the 2018 end - to - end test .

programming some flexibility into the mobile device — if accompanied with adequate training on how and when to use it — should permit completion of some interviews without having to deploy staff to the same case on subsequent days .

this in turn could reduce the cost of follow - up attempts and improve interview completion rates .

enumerators did not understand procedures for visits to property managers .

property managers are a key source of information on non - respondents when enumerators cannot find people at home .

they can also facilitate access to locked buildings .

further , developing a rapport with property managers has helped the nrfu process , such as when repeated access to a secured building or residential complex is needed on subsequent days by different enumerators .

in response to problems observed during the bureau's 2014 and 2015 census tests and complaints from property managers about multiple uncoordinated visits by enumerators , the bureau's 2016 census test introduced specific procedures to conduct initial visits to property managers in large multi - unit apartment buildings .

the procedures sought to identify up front which , if any , units needing follow - up at the location were vacant , eliminating the need for enumerators to collect this information from property managers with subsequent visits on a case - by - case basis .

according to bureau officials , the automated case management system was designed to allow for an enumerator to make up to three visits to property managers to remove vacant units .

according to the bureau , the 2016 census test demonstrated that vacant units could quickly be removed from the nrfu workload using these procedures in cases where a property manager was readily available ; however , in other cases the procedures caused confusion .

for example , whenever an initial visit was unsuccessful , all of the cases at that location — up until then collated into only one summary row of the enumerator's on - screen case list — would suddenly expand and appear as individual cases to be worked , sometimes adding several screens and dozens of cases to the length of the list , which enumerators we spoke with found confusing .

furthermore , without the knowledge of which units were vacant , enumerators may have unnecessarily made visits to these units and increased the cost and the time required to complete nrfu .

during debriefing sessions the bureau held , bureau enumerators and their supervisors identified training in these procedures as an area they felt needed greater attention in the future .

indeed , while training classes included a case study exercise on interviewing a property manager , this exercise in the enumerators training manual gives no warning to enumerators and does not refer to the procedures .

bureau officials said that they are pleased with the progress the test demonstrates they have made in automating case management at multi - unit locations a priority .

they added that they recognize the need to better integrate procedures in the training moving forward .

timing of return visits did not leverage information on respondent availability .

during our field visits , we encountered several instances where enumerators had been told by a respondent or otherwise learned that returning at a specific time on a later date would improve their chance of obtaining an interview from either a household respondent or a property manager .

but the bureau's 2016 census test and automated case management did not have an efficient way to leverage that information .

attempting contact at non - responding households at times respondents are expected to be available can increase the completion rate and reduce the need to return at a later date or rely on proxy interviews as a source of information .

the bureau's automated case management system assigned cases to 6- hour time windows after estimating hour - by - hour probabilities of when best to contact people .

the estimation relied on various administrative records , information from other bureau surveys that had successful contacts in the past , as well as area characteristics .

the 2016 census test did not have a way to change or update these estimates when cases were subsequently reassigned .

the goals of assigned time windows were intended to result in more productive visits and reduce costs .

when enumerators identified potentially better times to attempt a contact , they were instructed to key in this information into their mobile devices .

for example , one enumerator keyed in a mother's request to come back on thursday afternoon when her kids were in camp , while others keyed - in information like office hours and telephone contact numbers obtained from signs on the property they had seen for property managers .

however , according to the bureau , this updated information went unused , and we met enumerators who had been assigned to enumerate addresses at the same unproductive time after they had written notes documenting other better times to visit .

another enumerator reported visiting a property manager who complained that the enumerator was not honoring the manager's earlier request made during a prior enumeration attempt that an enumerator return during a specified time window .

such repeat visits can waste enumerator time ( and miles driven ) , and contribute to respondent burden or reduced data quality when respondents become annoyed and may become less cooperative .

we discussed our preliminary observation with managers at the test sites , who expressed frustration that the automated case management system did not allow them to record the locally - obtained data on when to contact people whom they found in enumerator notes in a way to affect future case assignment .

headquarters staff told us that while they have not fully evaluated this yet , they are concerned that providing local managers with too much flexibility to override the results of optimized case and time assignments would undermine the efficiency gains achievable by the automation .

they also explained that enumerators were to have been provided capability to record what day or what time of day for follow - up .

this information could have been used by the automated case management to better target the timing of future assignments .

however , they acknowledged that this procedure may not have been either fully implemented or explained during enumerator training .

bureau officials have said that this is another area they are planning to address .

the bureau has reengineered its approach to building its master address list for 2020 .

specifically , by relying on multiple sources of imagery and administrative data , the bureau anticipates constructing its address list with far less door - to - door field canvassing compared to previous censuses .

one major change the bureau is making consists of using in - office address canvassing – a two - phase process that systematically reviews small geographic areas nationwide , known as census blocks , to identify those that will not need to be canvassed in the field , as shown in figure 2 .

the bureau estimates that the two phases of in - office canvassing will result in roughly 25 percent of housing units requiring in - field canvassing , instead of canvassing nearly all housing units in the field as done previously .

with in - office address canvassing clerks compare current aerial imagery for a given block with imagery for that block dating to the time of the last decennial census in 2010 .

during this first phase , called interactive review , specially trained clerks identify whether a block appears to have experienced change in the number of housing units , flagging each block either as stable — free of population growth , decline , or uncertainty in what is happening in the imagery over time — or “active,” in which case it moves to the next phase .

addresses in stable blocks are not marked for in - field canvassing .

for blocks where change is detected or suspected , the bureau uses a second phase of in - office canvassing , known as active block resolution , to attempt to resolve the status of each address and housing unit in question within that block .

during this phase , clerks use aerial imagery , street imagery , and data from the u.s .

postal service , as well as from state , local , and tribal partners when reviewing blocks .

if a block can be fully resolved during this phase of in - office canvassing , the changes are recorded in the bureau's master address file .

if a block cannot be fully resolved during the second phase of in - office canvassing , then the entire block , or some portion of the block , is flagged for inclusion in the in - field canvassing operation .

in - office address canvassing began in september 2015 with plans for a first pass of the entire country to be completed by the end of fiscal year 2018 .

in - field canvassing for the 2020 census is scheduled to begin in august 2019 .

another major change the bureau is making for its re - engineered address canvassing is significantly expanding the role that state , local , and tribal partners can play throughout the decade in contributing to an accurate , more up - to - date address list .

through the geographic support systems initiative , begun in fiscal year 2011 , partner jurisdictions have been providing address and spatial data to the bureau to help validate and supplement the bureau's address list .

as of october 2016 , the bureau reported that it had received partner data covering 73 percent of all known housing units nationwide .

it added that the vast majority of the addresses in the files that the bureau had processed as of july 2015 have either been matched with existing addresses in its database , or added to the address list .

as with previous decennial censuses , as directed by congress , the bureau will also engage with state , local , and tribal partners through its local update of census addresses program in fiscal years 2018 and 2019 in order to ensure that jurisdictions have the ability to comment on the address list prior to enumeration .

the bureau plans to rely on the in - office part of address canvassing to validate a large part of the addresses added to the list during that program where data are available to permit it .

the bureau is testing its re - engineered address canvassing operation in two sites through december 2016 — in buncombe county , north carolina , and st. louis , missouri .

in - office canvassing for the test sites began at the bureau's national processing center in jeffersonville , indiana , in august 2016 .

the exercise will test the bureau's assumptions about the cost and effectiveness of the re - engineered approach , as well as the quality of in - office canvassing , field staff training , and the use of new collection geography in the field .

in addition to the 100 percent in - office canvassing the bureau plans for 2020 , the bureau will also canvass 100 percent of the test areas in the field so that it can compare results it obtains for blocks where it would not otherwise have gone door to door .

the bureau hired 262 in - field listers across both sites to conduct the door - to - door canvassing , also beginning in october with a relisting operation commencing in november .

although the innovations the bureau is planning with its reengineered address canvassing have the potential to reduce costs , they entail some risks that could affect the cost or quality of the address canvassing operation .

according to the bureau , these risks include: locating hidden housing units .

the bureau recognizes that certain kinds of dwellings are hard to identify and may not have been marked as housing units at the time of address list development and not included in any databases .

this could lead to their being missed and occupants not being counted in the census .

these units are referred to as hidden housing units and include such living arrangements as attics , basements , or garages converted into housing units .

according to the bureau , while in - field canvassing also has similar risks for missing these types of housing units , solely relying on the use of imagery to identify these units could lead to an incomplete address list .

monitoring change in the housing stock .

when the bureau determines during the first phase of in - office canvassing that a block has not experienced population change , the bureau plans to subject the block to later monitoring so that if later change is detected , the block can be reassigned for further review .

the bureau has developed the conditions or “triggers” for subjecting blocks to later monitoring , but has not yet determined how it will operationalize them .

according to the bureau , if the triggers that the bureau is developing for this process do not adequately detect recent change , then housing unit growth may be missed , and the resulting address list may not be up - to - date .

obtaining quality data .

for the bureau to adequately review enough blocks in - office – and therefore reduce field costs of door - to - door canvassing – the bureau needs to have data of sufficient quality to make reliable determinations about changes in housing units within those blocks .

according to the bureau , if it does not obtain sufficient satellite imagery ( covering areas with both current and prior census imagery ) or address and spatial data from state / local / tribal partners , then it may be forced to send more blocks than planned to in - field canvassing .

we have ongoing audit work examining the bureau's re - engineered address canvassing approach .

the justification of key cost and data quality assumptions , the approaches to mitigating key risks , and the bureau's adherence to timelines and canvassing schedules are all subjects of our ongoing work , which we plan to report on early next year .

the bureau goes to great lengths each decade to improve specific census - taking activities .

but these incremental modifications have not kept pace with societal changes that make the population increasingly difficult to locate and cost - effectively count .

this increasing difficulty and escalating costs led the bureau to re - engineer its approach for the 2020 census .

while preparations for 2020 are still underway , and with testing still occurring , the bureau's experience in planning for 2010 can enhance its readiness for 2020 .

for example , as the bureau continues its planning efforts for 2020 , our prior work indicates that it will be essential for it to address the following three lessons learned: ensure key census - taking activities are fully tested develop and manage on the basis of reliable cost estimates sustain workforce planning ensure key census - taking activities are fully tested .

the census is a large , complex operation comprised of thousands of moving parts , all of which must function in concert with one another to secure a cost - effective count .

while the census is under way , the tolerance for any breakdowns is quite small .

given this difficult operating environment , rigorous testing is a critical risk mitigation strategy because it provides information on the feasibility and performance of individual census - taking activities , their potential for achieving desired results , and the extent to which they are able to function together under full operational conditions .

given the new four innovation areas for the 2020 census , it will be imperative that the bureau have systems and operations in place for the 2018 end - to - end test that will take place in three locations , covering more than 700,000 housing units in total .

the 2018 test locations are: pierce county , washington ; providence county , rhode island ; and the bluefield - beckley - oak hill area of west virginia .

in our prior work on testing done for the 2010 census , we noted that a sound study design should include such components as: clearly stated objectives with accompanying performance measures ; research questions linked to test objectives and , as appropriate , a clear rationale for why sites were selected for field tests ; a thoroughly documented data collection strategy ; input from stakeholders and lessons learned considered in developing test objectives ; and a data analysis plan including , as appropriate , methods for determining the extent to which specific activities contribute to controlling costs and enhancing quality .

develop and manage on the basis of reliable cost estimates .

reliable cost estimates that appropriately account for risks facing an agency can help an agency manage large complex activities like the 2020 census , as well as help congress make funding decisions and provide oversight .

cost estimates are also necessary to inform decisions to fund one program over another , to develop annual budget requests , to determine what resources are needed , and to develop baselines for measuring performance .

the bureau has a history of unreliable cost estimation and resultant overruns .

for example , we placed the decennial census on our high risk list in 2008 in part due to weaknesses in the bureau's estimation of its 2010 census life - cycle cost .

recently , we reported in our review of the bureau's october 2015 life - cycle cost estimate that in order for the bureau to improve its ability to control the cost of the 2020 census , it will be critical for it to have better control over its cost estimation process .

while we found that the bureau has taken significant steps toward improving its capacity to produce reliable cost estimates , those efforts had not yet resulted in a reliable decennial cost estimate .

among the four broad characteristics of a reliable cost estimate — none of which the bureau fully met — the bureau reported it was focusing its attention on improving the documentation of the cost estimate , in order to help improve other characteristics as well .

while poor documentation affected our ability to assess the reliability of the bureau's cost estimate's other characteristics , we believe the problems we observed related to an absence of internal control procedures over the cost estimation process , which resulted in poor documentation .

furthermore , we found the bureau lacked guidance to control the cost estimation process .

investment in the planning documents to help control and support cost estimation early in the estimation cycle , such as with an operational plan , guidance on key steps and process flows , assignment of responsibilities , and job aids for staff can help institutionalize practices and ensure that otherwise disparate parties in the process operate consistently .

as we reported , taking steps to ensure its cost estimate is reliable would help improve decision - making , budget formulation , progress measurement , course correction when warranted , and accountability for results .

we made three recommendations including that the bureau take specific steps to ensure its cost estimate meets the characteristics of a high - quality estimate and improve control over how risk and uncertainty are accounted for in cost estimation , with which the department of commerce agreed .

bureau officials have stated that they plan to address the recommendations with their update of the 2020 census lifecycle cost estimate in december 2016 .

we plan to assess this cost estimate as soon as it is available .

sustain attention to workforce planning .

strategic workforce planning encourages agency managers and stakeholders to systematically consider what is to be done , when and how it will be done , what skills will be needed , and how to gauge progress and results .

sustained workforce planning can help the bureau stay on track for the 2020 census and help avoid past staffing problems .

for example , a bureau assessment of its experience with the 2010 census observed that areas such as the management of large programs and projects , cost estimation , and information technology ( it ) lacked staff with core skills and experience .

moreover , the bureau's experience with the 2010 census and prior enumerations has shown that not following leading practices in workforce planning can increase the risks of subsequent downstream operations , such as cost estimation .

in 2012 we reported that while the bureau's workforce planning efforts were generally consistent with such key leading practices as identifying current and future critical occupations , the bureau had not coordinated workforce planning efforts across its directorates for key occupations .

without a bureau - wide competency assessment , for instance , the bureau risked not having the necessary workforce in place to manage the multimillion dollar it investments for its 2020 operations .

we found the bureau also needed to address having inadequately trained cost estimating staff so that it could produce credible , comprehensive , and accurate cost estimates .

moreover , the bureau needed to devote greater attention to setting goals and monitoring progress for skills gaps — as well as engaging stakeholders in developing , communicating , and implementing its workforce plan — so that the bureau could identify and avoid possible workforce plan implementation barriers .

since that time , the bureau has taken actions in response to our recommendations to coordinate and set goals for its workforce planning .

for example , in september 2014 , the bureau drafted action plans to address the skills gaps that had been identified as part of a bureau - wide competency assessment .

the bureau has indicated that a 2020 directorate - wide workforce assessment report is in its final review stages and will include a comprehensive succession planning strategy .

these actions taken by the bureau to incorporate key leading workforce planning practices will help the bureau meet its objective of having a workforce matched with the demands of the 2020 census .

going forward , a sustained focus on workforce planning will be necessary to ensure the bureau will be in a position to hire the optimal mix of managers and technical experts to carry out a cost - effective census .

in summary , the key innovations the bureau plans for 2020 show promise for controlling costs and maintaining accuracy , although there are significant risks involved .

the bureau is aware of these risks , and robust testing can help manage them by assessing the feasibility of key activities , their capacity to deliver desired outcomes , and their ability to work in concert with one another under operational conditions .

while the bureau decided to stop key field testing planned for fiscal year 2017 in order to mitigate a funding risk , this decision may have consequences for elements of field operations not getting tested as a result , and , ultimately , for the 2020 census .

going forward , once the bureau has the test results , past experience has also shown the importance of refining operations as needed based on the results of the tests , incorporating lessons learned from 2010 as appropriate , and making needed changes to its design in time to be included in the bureau's end - to - end test scheduled for 2018 .

chairman meadows , ranking member connolly , and members of the subcommittee , this completes my prepared statement .

i would be pleased to respond to any questions that you may have .

if you have any questions on matters discussed in this statement , please contact robert goldenkoff at ( 202 ) 512-2757 or by e - mail at goldenkoffr@gao.gov .

other key contributors to this testimony include lisa pearson , assistant director ; mark abraham , peter beck ; devin braun ; jeff demarco ; robert gebhart ; emily hutz ; richard hung ; donna miller ; ty mitchell ; kayla robinson ; kathleen padulchick ; robert robinson , and timothy wexler .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

the published product may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

