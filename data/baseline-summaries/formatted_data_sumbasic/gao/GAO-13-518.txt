the federal government is one of the world's largest and most complex entities , with about $3.5 trillion in outlays in fiscal year 2012 funding a vast array of programs and operations .

it faces a number of significant fiscal , management , and performance challenges in responding to the diverse and increasingly complex issues it seeks to address .

addressing these challenges will require actions on multiple fronts .

for example , program structures that are outmoded , fragmented , overlapping , or duplicative and not up to the challenges of the times must be reformed or restructured .

since 2011 , our series of annual reports has identified 162 areas of potential duplication , overlap , or fragmentation as well as cost savings and revenue - enhancing opportunities .

in addition , weaknesses in management capacity , both government - wide and in individual agencies , undermine efficient and effective government .

the recent update to our high - risk list identified numerous opportunities to reduce costs and improve government performance .

moving forward , the federal government will need to make tough choices in setting priorities as well as reforming programs and management practices to better link resources to results .

in that regard , we have previously reported that the performance planning and reporting framework originally put into place by the government performance and results act of 1993 ( gpra ) , and significantly enhanced by the gpra modernization act of 2010 ( gprama or the act ) , provides important tools that can help inform congressional and executive branch decision making to address challenges the federal government faces .

for example , we recently reported on several issues that hinder the federal government's ability to address fragmentation , overlap , and duplication , including the need for improved and regular performance information , the absence of a comprehensive list of federal programs , and the lack of related funding information .

if effectively implemented , gprama could help address these issues as well as improve information sharing and coordination among federal agencies — both of which are needed to further address governance challenges related to fragmentation , overlap , and duplication .

gprama lays out a schedule for gradual implementation of its provisions during a period of interim implementation — from its enactment in january 2011 to february 2014 when a new planning and reporting cycle for federal agencies begins .

gprama also includes provisions requiring us to review implementation of the act at several critical junctures and provide recommendations to improve its implementation .

this report is the final in a series responding to the mandate to assess initial implementation of the act by june 2013 , and pulls together findings from our recent work related to the act , the results of our periodic survey of federal managers , and our related recent work on federal governance , performance , and coordination issues .

our specific objectives for this report were to assess the executive branch's ( 1 ) progress in implementing key provisions of the act and ( 2 ) effectiveness in using tools provided by the act to address key governance challenges the federal government faces .

to address these objectives , we reviewed gprama , related congressional documents and office of management and budget ( omb ) guidance , and our past and recent work related to managing for results and the act .

we also interviewed omb staff .

to determine the extent to which agencies are using performance information and several of the act's requirements to improve agency results , we surveyed a stratified random sample of 4,391 persons from a population of approximately 148,300 mid - level and upper - level civilian managers and supervisors ( general schedule levels 13 through 15 and career senior executive service ( ses ) , or equivalent ) working in the 24 executive branch agencies covered by the chief financial officers ( cfo ) act of 1990 , as amended .

the web - based survey was administered between november 2012 and february 2013 and is comparable to surveys we conducted in 1997 , 2000 , 2003 , and 2007 .

for this report , our focus is on comparing the 2013 survey results with those from the 1997 baseline survey and with the results of the 2007 survey , which is the most recent survey conducted before gprama was enacted in 2011 .

we noted the results from the other two surveys — 2000 and 2003 — when statistically significant trends compared to 2013 occurred .

for the 2013 survey , we received usable questionnaires from about 69 percent of the eligible sample .

the response rate across the 24 agencies ranged from 57 percent to 88 percent .

the overall survey results are generalizable to the population of managers as described above at each of the 24 agencies and government - wide .

concurrently with this report , we are issuing an electronic supplement that shows all of the aggregated responses to all survey items at the government - wide and individual agency levels .

to help determine the reliability and accuracy of the database elements used to draw our sample of federal managers for the 2013 survey , we checked the data for reasonableness and the presence of any obvious or potential errors in accuracy and completeness and reviewed our past analyses of the reliability of this database .

we believe the data used to draw our sample are sufficiently reliable for the purpose of this report .

appendix i provides additional information about our objectives , scope , and methodology .

we conducted this performance audit from august 2012 to june 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

gprama is a significant enhancement of gpra , which was the centerpiece of a statutory framework that congress put in place during the 1990s to help resolve long - standing management problems in the federal government and provide greater accountability for results .

gpra sought to focus federal agencies on performance by requiring agencies to develop long - term and annual goals — contained in strategic and annual performance plans — and measure and report on progress towards those goals on an annual basis .

in our past reviews of its implementation , we found that gpra provided a solid foundation to achieve greater results in the federal government , but several key governance challenges remained — particularly related to: addressing crosscutting issues ; ensuring performance information was useful and used by agency leadership and managers and the congress ; strengthening the alignment between individual performance and agency results as well as holding individuals and organizations responsible for achieving those results ; measuring performance for certain types of programs ; and providing timely , useful information about the results achieved by agencies .

to help address these and other challenges , gprama revises existing provisions and adds new requirements , including the following: cross - agency priority ( cap ) goals: omb is required to coordinate with agencies to establish federal government priority goals — otherwise referred to as cap goals — that include outcome - oriented goals covering a limited number of policy areas as well as goals for management improvements needed across the government .

the act also requires that omb — with agencies — develop annual federal government performance plans to , among other things , define the level of performance to be achieved toward the cap goals .

agency priority goals ( apgs ) : certain agencies are required to develop a limited number of apgs every 2 years .

both the agencies required to develop these goals and the number of goals to be developed are determined by omb .

these goals are to reflect the highest priorities of each selected agency , as identified by the head of the agency , and be informed by the cap goals as well as input from relevant congressional committees .

leadership positions: although most of these positions previously existed in government , they were created by executive orders , presidential memoranda , or omb guidance .

gprama established these roles in law , provided responsibilities for various aspects of performance improvement , and elevated some of them .

chief operating officer ( coo ) : the deputy agency head , or equivalent , is designated coo , with overall responsibility for improving agency management and performance .

performance improvement officer ( pio ) : agencies are required to designate a senior executive within the agency as pio , who reports directly to the coo and has responsibilities to assist the agency head and coo with performance management activities .

goal leader: for each cap goal , omb must identify a lead government official — referred to by omb as a goal leader — responsible for coordinating efforts to achieve each of the goals .

for agency performance goals , including apgs , agencies must also designate a goal leader , who is responsible for achieving the goal .

performance improvement council ( pic ) : originally created by a 2007 executive order , gprama establishes the pic in law and included additional responsibilities .

the pic is charged with assisting omb to improve the performance of the federal government and achieve the cap goals .

among its other responsibilities , the pic is to facilitate the exchange among agencies of useful performance improvement practices and work to resolve government - wide or crosscutting performance issues .

the pic is chaired by the deputy director for management at omb and includes agency pios from each of the 24 cfo act agencies as well as other pios and individuals designated by the chair .

quarterly performance reviews ( qpr ) : for each apg , agencies are required to conduct qprs to review progress towards the goals and develop strategies to improve performance , as needed .

these reviews are to be led by the agency head and coo and include the pio , relevant goal leaders , and other relevant parties both within and outside the agency .

performance.gov: omb is required to develop a single , government - wide performance website to communicate government - wide and agency performance information .

the website — implemented by omb as performance.gov — is required to make available information on apgs and cap goals , updated on a quarterly basis ; agency strategic plans , annual performance plans , and annual performance reports ; and an inventory of all federal programs .

performance management capacity: the office of personnel management ( opm ) is charged with three responsibilities under the act .

opm is to ( 1 ) in consultation with the pic , identify key skills and competencies needed by federal employees to carry out a variety of performance management activities ; ( 2 ) incorporate these skills and competencies into relevant position classifications ; and ( 3 ) work with agencies to incorporate these key skills into agency training .

since gprama's enactment in january 2011 , omb and agencies have taken a number of important steps to implement key provisions related to the act's planning and reporting requirements .

in february 2012 , omb identified 14 interim cap goals concurrent with the submission of the president's budget .

nine of the goals related to crosscutting policy areas and 5 covered management improvements .

in addition , at the same time , 24 agencies selected by omb developed 103 apgs for 2012 and 2013 , and omb published information about these goals as well as the cap goals on performance.gov , which omb considers to comprise the federal government performance plan .

in december 2012 , omb expanded the information available on the site by providing an update on fiscal year 2012 performance for both sets of goals , and in march 2013 , quarterly updates of the site began .

all 24 cfo act agencies are conducting qprs , according to our survey of pios at these agencies .

our 2013 survey indicates that approximately one - third ( 33 percent ) of federal managers across the government are at least somewhat familiar with the qprs .

these and related efforts were based on omb guidance on implementing the act issued in 2011 and 2012 .

as another positive development , omb and agencies have also put into place key aspects of the act's performance management leadership roles .

we recently reported that , at the agency level , all 24 cfo act agencies have assigned senior - level officials to the coo , pio , and goal leader roles .

furthermore , omb guidance directed agencies with pios who are political appointees or other officials with limited - term appointments to appoint a career senior executive to serve as deputy pio .

nearly all ( 22 ) of the cfo act agencies have assigned officials to the deputy pio role , according to our pio survey .

pios we surveyed reported that most performance management officials ( coos , pios , deputy pios and goal leaders ) had large involvement in four primary tasks that summarize the performance management responsibilities required by gprama: ( 1 ) strategic and performance planning and goal setting , ( 2 ) performance measurement and analysis , ( 3 ) communicating agency progress toward goals , and ( 4 ) agency quarterly performance reviews .

at the government - wide level , the pic has taken steps to meet its requirement to facilitate the exchange of useful practices and tips and tools to strengthen agency performance management .

for example , it established the goal setting working group to help agencies set their 2012 to 2013 apgs ; the internal agency reviews working group to share best practices for qprs ; and the business intelligence working group to share tools for data analytics .

pios we surveyed reported that , in general , they found the pic helpful and that there was strong agency participation in the pic and its working groups .

however , in april 2013 we reported that the pic has not routinely assessed its performance and recommended that omb work with the pic to conduct formal feedback on the pic's performance from member agencies on an ongoing basis ; and update the pic's strategic plan and review the pic's goals , measures , and strategies for achieving performance , and revise them if appropriate .

omb staff agreed with these recommendations .

in addition , opm has completed its work identifying key skills and competencies needed by performance management staff and incorporating those skills and competencies into relevant position classifications .

opm identified 15 competencies for performance management staff and published them in a january 2012 memorandum from the opm director .

it also identified relevant position classifications that are related to the competencies for performance management staff and worked with a pic working group to develop related guidance and tools for agencies .

furthermore , opm has taken steps to work with agencies to incorporate the key competencies into agency training .

however , we reported in april 2013 that these efforts have been broad - based and not informed by specific assessments of agency training needs .

we recommended that , in coordination with the pic and the chief learning officers council , opm ( 1 ) identify competency areas needing improvement within agencies , ( 2 ) identify agency training that focuses on needed performance management competencies , and ( 3 ) share information about available agency training on competency areas needing improvement .

opm agreed with these recommendations and reported that it will take actions to implement them .

many of the meaningful results that the federal government seeks to achieve , such as those related to protecting food and agriculture and providing homeland security , require the coordinated efforts of more than one federal agency , level of government , or sector .

however , agencies face a range of challenges and barriers when they attempt to work collaboratively .

the need for improved collaboration has been highlighted throughout our work over many years , in particular in two bodies of work .

first , our reports over the past 3 years identified more than 80 areas where opportunities exist for executive branch agencies or congress to reduce fragmentation , overlap , and duplication .

figure 1 defines and illustrates these terms .

we found that resolving many of these issues requires better collaboration among agencies .

second , collaboration and improved working relationships across agencies are fundamental to many of the issues that we have designated as high risk due to their vulnerabilities to fraud , waste , abuse , and mismanagement , or most in need of transformation .

for almost 2 decades we have reported on agencies' missed opportunities for improved collaboration through the effective implementation of gpra .

in our 1997 assessment of the status of the implementation of gpra , we reported that agencies faced challenges addressing crosscutting issues , which led to fragmentation and overlap .

again , we reported in 2004 — 10 years after the enactment of gpra — that there was still an inadequate focus on addressing issues that cut across federal agencies .

on a government - wide level , we reported that omb did not fully implement a government - wide performance plan , as was required by gpra .

additionally , few agency strategic and performance plans addressed crosscutting efforts and coordination .

at that time , almost half of federal managers in our 2003 survey reported that they coordinated program efforts to a great or very great extent with other internal or external organizations .

now , almost 20 years since gpra's passage , our work continues to demonstrate that the needed collaboration is not sufficiently widespread .

accordingly , in 2012 we developed a guide on key considerations for implementing collaborative mechanisms .

the results of our 2013 survey of federal managers show that the percentage of managers reporting that they use information obtained from performance measurement when coordinating program efforts with other internal or external organizations to a great or very great extent has not increased since 1997 .

based on this survey , an estimated 23 percent of the managers reported that they coordinated program efforts to a small extent or not at all .

the following three examples , among many , highlight the need for improved collaboration to help address crosscutting issues: food safety: one area that has been identified in both bodies of work is the fragmented nature of federal food safety oversight .

the u.s. food safety system is characterized by inconsistent oversight , ineffective coordination , and inefficient use of resources ; these characteristics have placed the system on our high - risk list since 2007 and in all three of our annual reports on fragmentation , overlap , and duplication .

we have reported that the u.s. department of agriculture ( usda ) and the food and drug administration ( fda ) , the two primary agencies responsible for food safety , have taken some steps to increase collaboration .

however , agencies have not developed a government - wide performance plan for food safety that includes results - oriented goals and performance measures , as we recommended when we put federal oversight of food safety on the high - risk list in january 2007 .

in the absence of this plan , we have reported cases of fragmentation , overlap , and duplication .

the 2010 nationwide recall of more than 500 million eggs because of salmonella contamination highlights a negative consequence of this fragmentation .

several agencies have different roles and responsibilities in the egg production system .

through the food safety working group , federal agencies have taken steps designed to increase collaboration in some areas that cross regulatory jurisdictions .

for example , both usda and fda set goals to reduce illness from salmonella within their own areas of egg safety jurisdiction by the end of 2011 and developed a memorandum of understanding on information sharing regarding egg safety .

while such actions are encouraging , without a government - wide performance plan for food safety , fragmentation , overlap , and duplication is likely to continue .

climate change: climate change is a complex , crosscutting issue that poses risks to many environmental and economic systems — including agriculture , infrastructure , ecosystems , and human health — and presents a significant financial risk to the federal government .

among other impacts , climate change could threaten coastal areas with rising sea levels , alter agricultural productivity , and increase the intensity and frequency of severe weather events such as floods , drought , and hurricanes .

weather - related events have cost the nation tens of billions of dollars in damages over the past decade .

for example , in 2012 , the administration requested $60.4 billion for superstorm sandy recovery efforts .

however , the federal government is not well positioned to address the fiscal exposure presented by climate change , partly because of the complex , crosscutting nature of the issue .

given these challenges and the nation's precarious fiscal condition , we added “limiting the federal government's fiscal exposure to climate change” to our high - risk list in 2013 .

in adding climate change to this list , we reported that the federal government would be better positioned to respond to the risks posed by climate change if federal efforts were more coordinated and directed toward common goals .

in october 2009 , we recommended that the appropriate entities within the executive office of the president , in consultation with relevant federal agencies , state and local governments , and key congressional committees of jurisdiction , develop a strategic plan to guide the nation's efforts to adapt to climate change , including the establishment of clear roles , responsibilities , and working relationships among federal , state , and local governments .

in written comments , the council on environmental quality generally agreed with the report's recommendations , noting that leadership and coordination is necessary within the federal government to ensure an effective and appropriate adaptation response and that such coordination would help to catalyze regional , state , and local activities .

some actions have subsequently been taken to improve the coordination of federal adaptation efforts , including the development of an interagency climate change adaptation task force .

federal disability programs: in june 2012 , we identified 45 programs in nine agencies that helped people with disabilities obtain or retain employment , reflecting a fragmented system of services and supports .

many of these programs overlapped in whom they served and the types of services they provided .

such fragmentation and overlap may frustrate and confuse program beneficiaries and limit the overall effectiveness of the federal effort .

having extensive coordination and overarching goals can help address program fragmentation .

although we identified promising coordination efforts among some programs , most reported not coordinating with each other , and some officials told us they lacked funding and staff time to pursue coordination .

coordination efforts can be enhanced when programs work toward a common goal ; however , the number and type of outcome measures used by the 45 programs varied greatly .

to improve coordination , efficiency , and effectiveness , we suggested that omb consider establishing government - wide goals for employment of people with disabilities .

consistent with this suggestion , omb officials stated that the domestic policy council began an internal review intended to improve the effectiveness of some disability programs through better coordination and alignment .

however , as we noted in our 2013 high - risk update , omb still needs to maintain and expand its role in improving coordination across programs — such as the 45 we identified — that support employment for those with disabilities , and ultimately work with all relevant agencies to develop measurable government - wide goals to spur further coordination and improved outcomes for those who are seeking to find and maintain employment .

on the other hand , we have recently highlighted progress that the executive branch and congress have made in addressing areas that we previously identified as being at risk of fragmentation , overlap , and duplication .

for example , the nation's surface transportation system is critical to the economy and affects the daily life of most americans .

however , in our 2011 annual report on fragmentation , overlap , and duplication , we reported that over the years federal surface transportation programs grew increasingly fragmented .

at the core of this fragmentation was the fact that federal goals and roles for the programs were unclear or conflicted with other federal priorities , programs lacked links to the performance of the transportation system or of the grantees , and programs did not use the best tools to target investments in transportation to the areas of greatest benefit .

accordingly , since 2004 , we have made several recommendations and matters for congressional consideration to address the need for a more goal - oriented approach to surface transportation , introduce greater performance and accountability for results , and break down modal stovepipes .

as we reported in february 2013 , there was progress in clarifying federal goals and roles and linking federal programs to performance when the moving ahead for progress in the 21st century act was enacted in july 2012 .

the act addressed fragmentation by eliminating or consolidating programs , and made progress in clarifying federal goals and roles and linking federal programs to performance to better ensure accountability for results .

the challenge of collaboration has also been highlighted in our reviews of related gprama requirements , such as those for cap goals , apgs , and qprs .

while agencies have implemented some of these provisions , these efforts have not included all of the relevant agency , program , and other contributors .

when agencies do not include all relevant contributors , they may miss important opportunities to work with others who are instrumental to achieving intended outcomes .

including all contributors is also a requirement of gprama .

at the government - wide level , omb is required to list all of the agencies , organizations , program activities , regulations , tax expenditures , policies , and other activities that contribute to each cap goal .

with relevant stakeholders , omb is required to review the progress of all contributors towards each goal on a quarterly basis .

at the agency level , agencies are required to identify the various federal organizations , programs , and activities — both within and external to the agency — that contribute to each goal , and for apgs , review progress on a quarterly basis with relevant stakeholders .

however , as shown in table 1 , we have found that agencies are not including all stakeholders as they implement gprama .

while we continue to see challenges to collaboration across federal agencies , as a positive development , our survey of federal managers shows that reported collaboration increases when individuals contribute to the cap goals , apgs , or qprs .

our 2013 survey data indicate that 58 percent of federal managers reported they were somewhat or very familiar with cap goals .

among these individuals , federal managers who viewed their programs as contributing to cap goals to a great or very great extent were more likely to report collaborating outside their program to a great or very great extent to help achieve cap goals , as figure 2 shows .

we saw a similar pattern in responses from managers who were familiar with the apgs and the extent to which their programs contributed to the apgs .

eighty - two percent of federal managers reported they were somewhat or very familiar with apgs .

among these individuals , those who viewed their programs as contributing to apgs to a great or very great extent were more likely to report collaborating outside their program to a great or very great extent to help achieve apgs , as figure 3 shows .

while the questions on our survey were designed to examine collaboration outside individual programs , they were not designed to distinguish between collaboration within or outside agency boundaries .

as discussed in table 1 , we found that collaboration was more common within agencies than between agencies .

this may be appropriate in some cases ; however , in other cases this might point to a need for broader inclusion of external stakeholders .

we found that more managers reported collaborating with officials external to their agency to a great or very great extent when they also reported that their programs were involved in qprs to a similar extent .

tax expenditures represent a significant federal investment .

if the department of the treasury ( treasury ) estimates are summed , an estimated $1 trillion in revenue was forgone from the 169 tax expenditures reported for fiscal year 2012 , nearly the same as discretionary spending that year .

for some tax expenditures , forgone revenue can be of the same magnitude or larger than related federal spending for some mission areas .

for example , in fiscal year 2010 , tax expenditures represented about 78 percent ( $132 billion ) of federal support for housing .

since 1994 , we have recommended greater scrutiny of tax expenditures , as periodic reviews could help determine how well specific tax expenditures work to achieve their goals and how their benefits and costs compare to those of spending programs with similar goals .

in november 2012 , we issued a guide that identifies criteria for assessing tax expenditures and provides questions for the congress to ask about a tax expenditure's effectiveness .

however , omb has not developed a framework for reviewing tax expenditure performance , as we recommended in june 1994 and again in september 2005 .

because omb has not yet established such a framework , little is known about how tax expenditures contribute to broad federal outcomes and how they are related to spending programs seeking the same or a similar outcome .

omb guidance has shown some progress in addressing how agencies should incorporate tax expenditures in strategic plans and annual performance plans and reports , as we first recommended in september 2005 .

gprama specifically requires omb to identify tax expenditures among the various federal activities that contribute to each cap goal , when applicable .

although the act does not explicitly require agencies to identify tax expenditures among the various federal programs and activities that contribute to their performance goals , omb's guidance directs agencies to do so for their apgs , which are a small subset of their performance goals .

however , our review of the apgs developed for 2012 to 2013 found that only one agency , for one of its apgs , identified two relevant tax expenditures .

we recently reported that omb was missing an opportunity to more broadly identify how tax expenditures contribute to each agency's overall performance .

even among the cap goals , omb and agencies are missing opportunities to identify tax expenditures as contributors .

in the original information on performance.gov in february 2012 , omb included tax expenditures as potential contributors for 5 of the 14 cap goals ( veteran career readiness , entrepreneurship and small businesses , energy efficiency , job training , and improper payments ) .

in the december 2012 and march 2013 updates to performance.gov , only two goals ( veteran career readiness and improper payments ) discussed two tax expenditures , which represent $2.7 billion or 0.3 percent of the $1 trillion sum across the tax expenditures listed by treasury .

tax expenditures were no longer mentioned as contributing to the entrepreneurship and small businesses , energy efficiency , and job training cap goals .

for example , under the energy efficiency cap goal , omb originally listed both spending programs and tax expenditures that contribute to the goal .

however , in the december 2012 update to performance.gov , omb had deleted all of the tax expenditures even though many of these tax expenditures remained unchanged .

in one case , omb deleted the credit for energy efficiency improvements to existing homes ( estimated at $780 million for fiscal year 2012 ) , but highlighted the department of energy's ( doe ) weatherization assistance spending program ( estimated at $68 million in obligations for fiscal year 2012 ) , even though both fund residential energy efficiency .

overall , we identified eight tax expenditures , totaling $2.4 billion in forgone revenue , which share the purpose of achieving energy efficiency , but are no longer identified as potential contributors .

when asked about these changes , omb staff shared that for the entrepreneurship and small business cap goal the goal leaders narrowed the focus of the goal , which resulted in an updated list of contributing programs and activities that no longer included tax expenditures .

for the energy efficiency and job training cap goals , omb staff told us that the exclusion of tax expenditures from the december 2012 and march 2013 updates was an oversight .

omb staff told us they planned to add the appropriate tax expenditures as contributors to those goals in the next quarterly update to performance.gov , which occurred in june 2013 .

however , none were added to the job training cap goal update , and as of june 19 , 2013 , the energy efficiency cap goal had not yet been updated .

however , these examples raise concerns as to whether omb previously ensured all relevant tax expenditures were identified as contributors to the 14 cap goals when they were published in february 2012 , especially since only 5 cap goals listed tax expenditures as contributors at that time .

we have previously reported that , as with spending programs , tax expenditures represent a substantial federal commitment to a wide range of mission areas .

given the lack of scrutiny tax expenditures receive compared to spending programs — especially absent a comprehensive framework for reviewing them — it is possible that additional tax expenditures should have been identified and included as contributors to one or more of the other 9 cap goals .

moreover , for the 2 cap goals where tax expenditures were listed as contributors and mistakenly removed , it is unclear if omb and the goal leaders assessed the contributions of those tax expenditures toward the cap goal efforts , since they were not listed in the december 2012 and march 2013 updates .

without information about which tax expenditures support these goals and measures of their performance , congress and other decision makers will not have the needed information to assess overall federal contributions towards desired results , and the costs and relative effectiveness associated with those contributions .

we have previously reported that data - driven decision making leads to better results .

moreover , we have reported that if agencies do not use performance measures and performance information to track progress toward goals , they may be at risk of failing to achieve their goals .

the textbox illustrates this problem in the high risk area of the department of defense's ( dod ) approach to business transformation .

dod is not regularly reviewing performance information to assess progress towards goals in transforming its business operations in 2005 , we identified dod's approach to business transformation as high - risk because dod had not established clear and specific management responsibility , accountability and control over its business transformation and it lacked a plan with specific goals , measures , and mechanisms to monitor progress .

we subsequently reported that dod made improvements to strengthen its management approach , but we also identified additional steps that are needed .

for example , dod has broadly outlined a performance management approach , and established governance structures , such as the defense business council , to help monitor progress in its business transformation efforts .

however , we found the council had not regularly reviewed performance data and when reviews did occur , it did not have sufficient information to assess progress .

to enhance dod's ability to set strategic direction for its business transformation efforts , better assess overall progress toward business transformation goals , and take any necessary corrective actions , we recommended in february 2013 that dod take a number of steps to improve its approach to performance management .

dod agreed with this recommendation and said it would continue to improve and institutionalize the council's operations .

in the first 4 months of 2013 alone , we issued numerous testimonies and reports that illustrate how performance management weaknesses can hinder agencies' abilities to achieve critical results .

this work also illustrates that the scope of these problems is widespread , affecting agencies such as dod , treasury , the departments of transportation ( dot ) , homeland security ( dhs ) , health and human services , housing and urban development ( hud ) , and state .

the impact of these weaknesses is far reaching as well: these agencies are responsible for performing functions that affect every aspect of americans' lives , from education , healthcare , and housing to national security and illicit drug use , as described in the textbox .

office of national drug control policy has established a performance monitoring system to address illicit drug use , but not yet reported on results the public health , social , and economic consequences of illicit drug use , coupled with the nation's constrained fiscal environment , highlight the need for federal programs to use resources efficiently and effectively to address this problem .

however , we reported in march 2013 that the office of national drug control policy and federal agencies have not made progress toward achieving most of the goals in the 2010 national drug control strategy , although they reported to be on track to implement most strategy action items in support of these goals .

in april 2012 , the office established the performance reporting system , a monitoring mechanism intended to provide specific , routine information on progress toward strategy goals and help identify factors for performance gaps and options for improvement .

we reported that this could help increase accountability for improving results and identify ways to bridge the gap that existed between the lack of progress toward the strategy's goals and the strong progress made on implementing the strategy's actions .

while this was promising , the office does not plan to report on results until later in 2013 , and until then , operational information is not available to evaluate its effectiveness .

gao , office of national drug control policy: office could better identify opportunities to increase program coordination , gao - 13-333 , ( washington , d.c.: mar .

26 , 2013 ) .

our prior work has shown that performance information can be used across a range of management functions to improve results , from setting program priorities and allocating resources to taking corrective action to solve program problems .

since our 2007 survey there was statistically significant improvement on two survey items related to use of performance information .

more managers reported in 2013 — after gprama's enactment and initial implementation — that they used performance information to a great or very great extent in developing program strategy and refining program performance measures .

however , the 2013 improvement on the refining program performance measures item followed an earlier decline and does not represent an improvement in comparison to our 1997 survey results .

while there was also a statistically significant change between 1997 and 2013 in the percentage of managers who reported to a great or very great extent that they used performance information in adopting new program approaches or changing work processes , the initial decline on this item occurred between our 1997 and 2000 surveys with no significant changes since then .

overall , our periodic surveys of federal managers since 1997 indicate that with the few exceptions described above , the use of performance information has not changed significantly at the government - wide level , as shown in figure 4 .

in addition , we introduced an item in the 2013 survey on streamlining programs , a performance management activity that can help address the overlap and duplication challenges and opportunities described earlier in this report .

less than half of federal managers ( 44 percent ) reported to a great or very great extent that they used performance information for “streamlining programs to reduce duplicative activities.” our prior work has identified practices that can promote the use of performance information for management decision making , such as leadership demonstrating commitment to using performance information , communicating performance information frequently and effectively , ensuring that performance information is useful , and building capacity to use performance information .

moreover , many of the requirements put in place by gprama reinforce the importance of these practices .

our past government - wide surveys of federal managers indicated that these key practices were not always being employed across various agencies .

our 2013 survey suggests that effectively adopting these practices continues to be a substantial weakness across the government as described below .

demonstrating leadership commitment: our prior work has shown that the demonstrated commitment of leadership and management to achieving results and using performance information can encourage the federal workforce to apply the principles of performance management .

gprama requires top leadership involvement in performance management , such as requiring agency leadership to routinely review performance information and progress toward apgs during the qprs .

however , results from our 2013 survey show almost no statistically significant changes in managers' perceptions of their leaders' and supervisors' attention and commitment to the use of performance information since our last survey in 2007 .

the only statistically significant change from 2007 to 2013 was a decline in the percentage of managers that agreed to a great or very great extent that their agencies' top leadership demonstrates a strong commitment to achieving results , from 67 percent to 60 percent .

moreover , less than two - thirds of managers agreed to a great or very great extent with other survey items related to leadership commitment and attention to performance information , as shown in figure 5 .

communicating performance information: our prior work showed that communicating performance information frequently and effectively throughout an agency can help managers to inform staff and other stakeholders of their commitment to achieve the agency's goals and to keep these goals in mind as they pursue their day - to - day activities .

frequently reporting progress toward achieving performance targets also allows managers to review the information in time to make improvements .

gprama includes requirements for communicating performance information , such as sharing performance information at least quarterly and directing agencies to update performance indicators on their websites at least annually .

however , there was no statistically significant change between 2007 and 2013 in the percentage of federal managers agreeing to a great or very great extent that agency managers at their level effectively communicate performance information on a routine basis ( 41 percent in 2013 and 43 percent in 2007 ) .

our analysis suggests that easy access to performance information is related to the effective communication of performance information .

of the 49 percent of federal managers who agreed to a great or very great extent that performance information is easily accessible to managers at their level , 62 percent also agreed that agency managers at their level effectively communicate performance information on a routine basis to a great or very great extent .

conversely , of the 19 percent that agreed to only a small or no extent that performance information is easily accessible to managers at their level , only 9 percent also agreed that agency managers at their level effectively communicate performance information on a routine basis to a great or very great extent .

ensuring performance information is useful: as we previously reported , to facilitate the use of performance information , agencies should ensure that information meets various users' needs for completeness , accuracy , consistency , timeliness , validity , and ease of use .

gprama introduced several requirements that could help to address these various dimensions of usefulness .

for example , agencies must disclose more information about the accuracy and validity of their performance data and actions to address limitations to the data .

without useful performance information , it is difficult to monitor agencies' progress toward critical goals , such as improving veterans' access to health care provided by the department of veterans affairs ( va ) , as illustrated in the textbox .

performance information on veterans' wait times for medical appointments was unreliable the veterans health administration ( vha ) , within the va , provided nearly 80 million outpatient medical appointments to veterans in fiscal year 2011 .

although access to timely medical appointments is important to ensuring veterans obtain needed care , long wait times and inadequate scheduling processes have been persistent problems .

vha is implementing a number of initiatives to improve veterans' access to medical appointments such as use of technology to interact with patients and provide care .

however , we testified in march 2013 that certain aspects of vha's policies and policy implementation contributed to unreliable performance information on veterans' wait times .

va concurred with our recommendations and identified actions planned or under way to address them .

gao , va health care: appointment scheduling oversight and wait time measures need improvement , gao - 13-372t ( washington , d.c.: mar .

14 , 2013 ) .

responses to four survey items on hindrances related to the usefulness of performance information indicate some limited improvement .

there was a statistically significant improvement between the 2007 and 2013 surveys on two of these four items ( shown as declines because they concern hindrances ) , but no significant change otherwise , as illustrated in figure 6 .

in addition , related survey items introduced after 1997 showed no significant change between 2007 and 2013 , with about 40 percent of managers agreeing to a great or very great extent that “agency managers at my level take steps to ensure that performance information is useful and appropriate” and 36 percent agreeing to the same extent that “i have sufficient information on the validity of the performance data i use to make decisions.” despite these limited improvements , the overall picture from the 2013 results — with about one - fifth to nearly one - third of managers reporting hindrances , as indicated in figure 6 , and less than half agreeing with most of the positive statements about the format , timeliness , and accessibility of their performance information in figure 7 — remains a major concern .

building capacity to use performance information: we have previously reported that building the capacity to use performance information is critical to using performance information in a meaningful fashion , and that inadequate staff expertise , among other factors , can hinder agencies from using performance information .

gprama lays out specific requirements for opm to identify skills and competencies for performance management functions , among other actions , which reinforce the importance of staff capacity to use performance information .

managers' survey responses and our recent work indicate areas of weakness in agencies' analysis and evaluation tools and staff's skills and competencies , both of which are critical components of performance management capacity .

about a third ( 36 percent ) of managers reported in 2013 that they agreed to a great or very great extent that their agencies have sufficient analytical tools for managers at their levels to collect , analyze , and use performance information .

furthermore , less than a third of managers reported that their agencies were investing resources to improve the use and quality of performance information .

thirty percent of managers reported that they agree to a great or very great extent that the programs they are involved with have sufficient staff with the knowledge and skills needed to analyze performance information .

additionally , our recent work found gaps in performance management competencies among agency staff .

although pios we surveyed at 24 agencies in 2012 for our april 2013 report on performance management leadership roles reported that their staff generally possessed core competencies identified by opm for performance management staff , certain competencies — performance measurement , information management , organization performance analysis , and planning and evaluating — were present to a lesser extent .

training is one way agencies can address a lack of staff capacity to use performance information , as illustrated in the sidebar .

between 1997 and 2013 , there was a statistically significant increase in the percentage of managers reporting that their agencies made training available in the past 3 years on most of the performance management tasks we asked about .

however , between 2007 and 2013 , there was either no significant change or a decline in the percentage of managers responding positively to the same items , as shown in figure 8 .

our prior work has indicated that effective data - driven reviews can serve as a leadership strategy , requiring leadership and other responsible parties to come together to review performance information and progress toward results and identify important opportunities to drive performance improvements .

according to our 2012 survey of pios at 24 agencies , the majority ( 21 of 24 ) reported that actionable opportunities for performance improvement are identified through the reviews at least half the time .

in addition , most officials we interviewed at doe , treasury , and the small business administration ( sba ) attributed improvements in performance and decision making to their qprs .

the textbox presents one such improvement described by officials at treasury .

treasury credits qprs with decision to stop minting $1 coins for circulation and saving u.s. government millions treasury's deputy secretary said that it was a performance review session with the u.s. mint that first led him to question the direction they had been taking with the $1 coin .

performance data he reviewed for the meeting indicated that the mint was producing 400 million new $1 coins annually , while the federal reserve already had 1.4 billion existing ones in storage .

digging deeper , he learned that the federal reserve had previously estimated that there were enough $1 coins to meet demand for more than a decade .

this estimate was based on the assumption that demand would remain at 2012 levels .

while our case studies and survey of pios indicated the benefits of qprs , our 2013 government - wide federal managers' survey indicated that the majority of federal managers are not familiar with the qprs at their agencies , although a greater percentage of senior executive service ( ses ) managers reported that they were familiar with the qprs , as shown in figure 9 .

our analysis suggests that , while familiarity with qprs may be somewhat limited government - wide , it is positively related to managers' perceptions of their leadership's demonstrated commitment to using performance information .

of the 12 percent of all federal managers who reported they were very familiar with qprs , 76 percent agreed that their top leadership demonstrates a strong commitment to using performance information to guide decision making to a great or very great extent .

in contrast , of the 66 percent who reported they were not familiar with qprs , 36 percent agreed to a great or very great extent with the same statement .

similarly , our analysis suggests that being the subject of a qpr is positively related to the extent to which managers view the qprs as being used to accomplish certain purposes to a great or very great extent .

for example , federal managers who reported that their programs have been the subject of a qpr to a great or very great extent were more likely to report that their agencies use qprs to identify problems or opportunities than those who reported that their programs have been the subject of a qpr to a moderate or small or no extent .

figure 10 shows this trend , along with a similar one for federal managers' ratings of agency leadership use of qprs to help achieve performance goals .

our analysis also suggests that being the subject of a qpr may be positively related to managers' perceptions of their agencies employment of key practices that we have previously reported can promote successful data - driven performance reviews .

for example , federal managers who reported that their programs have been the subject of a qpr to a great or very great extent were more likely to report that the reviews included key practices , such as leadership actively participating in reviews , than those who reported that their programs have been the subject of qprs to a moderate or small or no extent .

this trend and similar ones for other key practices are shown in figure 11 .

federal managers' responses to items about other key practices — holding qprs on a regular , routine basis and having a process for following up on qprs — were similarly related to the extent to which managers' programs were the subject of a qpr .

it is important for individuals to see a connection between their daily operations and results to help understand how individual performance can contribute to organizational success .

while our past work has shown that agencies have encountered challenges linking individual performance with broader organizational results , progress has been made over the last decade in establishing this linkage and holding individuals accountable for organizational results through performance management systems .

for example , while agencies have been required to hold senior executives accountable for their individual and organizational performance by linking performance expectations with gpra - required goals since 2000 , opm and omb have continued to reinforce the importance of this alignment in improvements in ses performance management .

most recently , in january 2012 , opm and omb released a government - wide performance appraisal system for senior executives that provides agencies with a standard framework for managing the performance of its executives .

while striving to provide greater clarity and equity in the development of performance standards and link to compensation , among other things , the directors of opm and omb stated that the new system is intended to provide agencies with the necessary flexibility and capability to customize the system in order to meet their needs .

as part of this framework , agencies are to identify expectations for the senior executives that focus on measurable outcomes from the strategic plan or other measurable outputs and outcomes clearly aligned to organizational goals and objectives .

in addition , the goals - engagement - accountability - results ( gear ) model , established in 2011 , focuses on aligning employee performance with organizational performance , creating a culture of engagement , and implementing accountability at all levels , among other things .

the gear model outlines a series of recommended actions for agencies to adopt in order to help improve employee and organizational performance .

we reported in september 2012 that doe's gear implementation plan includes aligning employee performance management with organizational performance management and developing training to support these goals , which along with initiating knowledge - sharing activities , will promote improvement of doe's organizational performance , according to doe officials .

we have ongoing work looking at gear implementation in the five pilot agencies and plan to issue the results of our work later in 2013 .

to further institutionalize individual accountability for achieving results , gprama established in law several mechanisms that help individuals and agencies see this connection and hold them accountable for their contributions to agency and government - wide goals .

as we recently reported , agency leaders should hold goal leaders and other responsible managers accountable for knowing the progress being made in achieving goals and , if progress is insufficient , understanding why and having a plan for improvement including improvements in the quality of the data to help ensure they are sufficient for decision making .

for example , pios are responsible for , among other things , assisting the agency head and coo in developing and using performance measures specifically for assessing individual performance in the agency .

qprs offer an opportunity for organizational performance to be assessed and responsible officials to be held accountable for addressing problems and identifying strategies for improvement .

as agencies implement the accountability provisions of gprama , they will need to ensure managers have decision - making authority commensurate with the responsibility to identify and address performance problems as they arise .

since our 1997 government - wide survey of federal managers , ses managers have reported improvements in accountability for agency goals and results and the decision - making authority to help achieve agency goals .

however , there has been a gap between ses managers' perceptions of their accountability for program performance as opposed to their decision - making authority since our initial survey in 1997 .

in 2013 , 80 percent of ses managers reported that they are held accountable for the results of the programs for which they are responsible to a great or very great extent , while 61 percent reported that they have the decision - making authority they need to help the agency achieve its strategic goals , a 19 percentage point difference .

see figure 12 .

using performance information in employee performance management helps individuals track their performance and progress toward achieving organizational goals and can help emphasize the importance of individual contributions to organizational success .

however , the percentage of federal managers reporting use of performance information in employee performance management to a great or very great extent has stagnated with no statistically significant change in reported use from 1997 to 2013 .

see figure 13 .

a fundamental element in an organization's efforts to manage for results is its ability to set meaningful goals for performance and to measure progress toward those goals .

in our 1996 executive guide , we underscored the importance of taking a balanced approach to setting goals and measuring performance .

if a balance across an organization's various priorities does not exist , the measures in place can overemphasize some goals and create skewed incentives .

this need for agencies to have a balanced set of performance measures was reinforced in gprama , which calls for agencies to develop a variety of measures , such as output , outcome , customer service , and efficiency , across program areas .

as we have previously reported , based on our government - wide federal managers surveys , federal managers reported a statistically significant increase in the presence of different types of performance measures for their programs to a great or very great extent following initial implementation of gpra .

despite this early progress in establishing a variety of performance measures , since our 2003 federal managers survey , there generally has been no statistically significant increase in the reported presence of these measures to a great or very great extent .

more recently , as illustrated in figure 14 , the only statistically significant increase between 2007 and 2013 is in the percentage of managers reporting the presence of quality measures .

we have further found over the years and through our more recent work that there has been uneven development of outcome - oriented performance measures across federal programs , even though agencies have been responsible for measuring program outcomes , among other things , since the passage of gpra in 1993 .

as demonstrated in the textbox , outcome - oriented performance measures help agencies determine if the program is achieving its intended purpose .

additionally , these performance measures are essential for assessing the vast number of results of federal efforts that span multiple agencies and organizations .

gao has reported on agency difficulties in developing and using outcome measures in may 2006 , we recommended that usda and dhs adopt meaningful performance measures for assessing the effectiveness of the agriculture quarantine inspection ( aqi ) program at intercepting foreign pests and disease on agricultural materials entering the country by all pathways and posing a risk to u.s. agriculture .

we reported in march 2013 that the federal emergency management agency has not yet established clear , objective , and quantifiable capability requirements and performance measures to identify capability gaps in a national preparedness assessment , as recommended in our march 2011 report .

we reported in april 2013 that the federal communications commission , dhs , dod , and department of commerce had taken a variety of actions to support the security of the nation's communications networks , including ones related to developing cyber policy and standards , securing internet infrastructure , sharing information , supporting national security and emergency preparedness , and promoting sector protection efforts .

gao , homeland security: management and coordination problems increase the vulnerability of u.s. agriculture to foreign pests and disease , gao - 06-644 ( washington , d.c.: may 19 , 2006 ) .

gao , homeland security: agriculture inspection program has made some improvements , but management challenges persist , gao - 12-885 ( washington , d.c.: sept. 27 , 2012 ) .

gao - 11-318sp .

gao , communications networks: outcome - based measures would assist dhs in assessing effectiveness of cybersecurity efforts , gao - 13-275 ( washington , d.c.: apr .

3 , 2013 ) .

our work over the last 20 years has identified difficulties agencies face in measuring performance across various program types , such as regulations and grants .

some commonly reported difficulties that cut across the various program types include: accounting for factors that are both outside of an agency's control and impact the results of a program ; developing appropriate performance measures , especially for programs without a clearly defined purpose or that require a long time period to achieve intended results ; and obtaining complete , timely , and accurate performance information of the program .

illustrative examples from our recent work that show how agencies have experienced difficulties in measuring program performance are provided in table 2 .

in our 2013 annual report on fragmentation , overlap , and duplication , we identified the need for improving the measurement of performance and results — including program evaluation — as a theme that cuts across our suggested actions to address fragmentation , overlap , and duplication in federal agencies .

while some agencies have faced difficulties in measuring program performance , some progress has been made in developing performance measures and using the resulting performance information to measure performance in the applicable program area .

for example: hud has made progress in measuring grant program performance .

as we reported in november 2011 , hud measured progress toward some green building goals by collecting energy consumption data for participating properties receiving grants or loans under its green retrofit program for multifamily housing before and after the properties are retrofitted and planned to use this data to calculate savings and evaluate effectiveness .

in january 2011 , we reported that the federal railroad administration ( fra ) has created a set of performance goals and measures that address important dimensions of program performance related to its regulatory safety activities .

in its proposed fiscal year 2011 budget , fra included specific safety goals to reduce the rate of train accidents caused by various factors , including human errors and track defects .

these goals were quantitative , with a targeted accident rate per every million train miles .

collecting such accident data equips fra with a clear way to measure whether or not those safety goals are met .

fra's budget request has also linked fra's performance goals and measures with dot's strategic goals .

moving forward , we will continue to examine the availability and use of performance measures across a variety of program types and update our work in this area .

given that we have found that agencies across the federal government have experienced similar difficulties in measuring the performance of different program types and have not made consistent progress in addressing them , a comprehensive examination of these difficulties is needed .

the pic could help facilitate this examination .

as discussed earlier , gprama requires the pic , in part , to resolve crosscutting performance issues and facilitate the exchange of practices that have led to performance improvements within specific programs or agencies or across agencies .

although measuring the performance of different program types is a significant and long - standing challenge , the pic has not yet addressed this issue in a systematic way , such as through a working group to identify common difficulties in developing and using performance measures to assess program performance and share best practices from instances in which agencies have overcome these difficulties .

without a comprehensive examination , it will be difficult for the pic and agencies to fully understand these measurement issues and develop a crosscutting approach to help address them , which will likely result in agencies experiencing difficulties in measuring program performance in the future .

according to our 2013 survey of federal managers , 34 percent reported that performance information is easily accessible to agency employees to a great or very great extent , while 17 percent reported that their agency's performance information is easily accessible to the public to a great or very great extent .

survey data also indicate that agencies are not communicating to their employees about contributions to cap goals or their progress toward achieving apgs .

in fact , of the 58 percent of federal managers who indicated they were familiar with cap goals , 22 percent reported that their agency has communicated to its employees on those goals to a great or very great extent .

of the 82 percent of federal managers who indicated familiarity with apgs , 40 percent reported that their agency has communicated on progress toward achieving them to great or very great extent .

we recently reported that performance.gov , as the central repository for federal government performance information , can assist in oversight and lead to a greater focus within government on the activities and efforts necessary to improve performance .

omb's stated goals for performance.gov include , among others , providing both a public view into government performance to support transparency as well as providing executive branch management capabilities to enhance senior leadership decision making .

according to omb staff , omb will maintain responsibility for the website , but going forward , the plans are that the effort will be driven more by the general services administration ( gsa ) and the pic , with gsa continuing to provide technological support .

for future development of performance.gov , omb , the pic , and gsa are working with federal agencies to develop the performance management line of business that , according to omb staff , will standardize the collection and reporting of performance information by agencies .

performance.gov has the potential to increase the accessibility of performance information for users both inside and outside the federal government .

an analysis of statements from omb and gsa staff , agency officials , and feedback we obtained from potential users , however , indicates that there are varying expectations regarding the primary uses of performance.gov .

for example , omb and gsa staff emphasized that they have viewed performance.gov as a tool for agencies to support cross - agency coordination and efforts to achieve agency goals .

consistent with this , omb staff said that performance.gov has been used to facilitate conversations between omb examiners and agency managers about progress on apgs .

while most officials we interviewed said that omb had collected feedback from the agencies in the development of performance.gov , officials from most of these agencies also said that performance.gov is not being used as a resource by agency leadership or other staff , as they have information sources tailored to meet their needs , and performance.gov does not contain critical indicators or the ability to display some visualizations used for internal agency performance reviews .

in addition , a performance management practitioner and other potential users of the website noted that the detailed , technical nature of performance.gov seemed primarily oriented toward a government rather than a public audience .

according to omb staff , the specific legal requirements of gprama have been the primary framework used to guide efforts to develop performance.gov thus far .

they noted that they have been focused on working to comply with these requirements by providing information on cap goals and apgs , and by establishing a phased development plan for the integration of additional information from agency strategic plans , performance plans , and performance reports .

omb and gsa staff members have said , however , that the leading practices for developing federal websites will be helpful in guiding the future development of performance.gov .

omb and gsa staff have also noted that as the phased development of performance.gov unfolds , they expect to use broader outreach to , and usability testing with , a wider audience , including members of the public , to make performance.gov more “public - facing” and “citizen - centric.” in accordance with this transition , we recommended in june 2013 that omb work with gsa and the pic to clarify the specific ways that intended audiences could use the information on performance.gov .

howto.gov , a leading source of best practices and guidance on the development of federal government websites , recommends identifying the purposes of a website , and the ways in which specific audiences could use a website to accomplish various tasks , and then structuring information and providing tools to help visitors quickly complete these tasks .

with greater clarity about the intended uses of performance.gov , omb and gsa should have sufficient direction to design performance.gov to make it a relevant and accessible source of information for a variety of potential users including those specified under gprama — members and committees of congress and the public .

in the same report , we also recommended that omb should work with gsa and the pic to systematically collect information on the needs of intended audiences and collect recommended performance metrics that help identify improvements to the website .

for example , howto.gov practices recommend that a website use consistent navigation .

although users we interviewed had mixed opinions on the organization and navigation of performance.gov , simplifying the website's navigation , adding an effective internal search engine , and providing an appropriate level of detail and information for intended audiences could increase the overall usability of performance.gov .

outreach and testing on the ease of navigation and searching would help omb systematically collect information on the needs of various audiences and how these could be addressed through performance.gov .

with performance goals and measures for the website , it would also be possible for the developers of performance.gov to identify the gap between current capabilities and what is needed to fulfill stated goals and to identify and set priorities for improvements .

omb staff agreed with these recommendations .

congressional support has played a critical role in sustaining interest in management improvement initiatives over time .

as we have previously reported , congress has served as an institutional champion for many government - wide management reform initiatives over the years , such as the cfo act and gpra in the 1990s and more recently gprama .

further , congress has often played an important role in performance improvement and management reforms at individual agencies .

congress has also provided a consistent focus on oversight and has reinforced important policies .

as we have previously reported , having pertinent and reliable performance information available is necessary for congress to adequately assess agencies' progress in making performance and management improvements and ensure accountability for results .

however , our work has found that the performance information that agencies provided to congress was not always useful for congressional decision making because the information was not clear , directly relevant , or sufficiently detailed .

as stated earlier , in order for performance information to be useful , it should meet the needs of different users — including congress — in terms of completeness , accuracy , consistency , timeliness , validity , and ease of use .

gpra required agencies to consult with congress and obtain the views of interested stakeholders as a part of developing their strategic plans .

however , according to the senate committee report that accompanied the bill that ultimately became gprama , agencies did not adequately consider the input of congress in developing strategic plans , often because the agencies waited until strategic plans were substantially drafted and reviewed within the executive branch before consulting with congress .

in doing so , agencies limited the opportunities for congress to provide input on their strategic plans and related goals , as well as the performance information that would be most useful for congressional oversight .

to help ensure agency performance information is useful for congressional decision making , gprama strengthens the consultation requirement .

the act requires agencies to consult at least once every two years with relevant appropriations , authorization and oversight committees , obtaining majority and minority views , when developing or updating strategic plans — which include apgs .

subsequently , agencies are to describe how congressional input was incorporated into those plans and goals .

similarly , omb is required to consult with relevant committees with broad jurisdiction at least once every two years when developing or updating cap goals , and describe how that input was incorporated into those goals .

at the request of congress , in june 2012 , we developed a guide to assist members of congress and their staffs in ensuring the consultations required under gprama are useful to the congress .

the guide outlines general approaches for successful consultations , including creating shared expectations and engaging the right people in the process at the right time .

the guide also provides key questions that members and congressional staff can ask as part of the consultation process to ensure that agency performance information reflects congressional priorities .

however , it is unclear if agencies incorporated congressional input on their updated strategic plans and apgs published in 2012 , and therefore if this information will be useful for congressional decision making .

in our recent review of apgs , we found that agencies reported engaging congress during the development of their strategic plans and goals to varying degrees , and only 1 of the 24 agencies we reviewed explained how congressional input was incorporated into its apgs , as required by gprama .

we recommended in april 2013 that omb ensure that agencies adhere to omb's guidance for website updates by providing a description of how input from congressional consultations was incorporated into each goal .

omb staff concurred with our recommendation .

in addition , our recent work indicated that the performance information provided on performance.gov also may not be meeting congressional needs .

we found that outreach from omb to congressional staff was limited , as were opportunities for staff to provide input on the development of performance.gov .

according to omb staff , they met several times with staff from the senate homeland security and governmental affairs committee , house oversight and government reform committee , and the senate budget committee to discuss the development of performance.gov , and used this outreach to identify several specific website modifications .

of the three congressional staff that we spoke to that said they had received briefings on the development of performance.gov , however , only one told us she had been consulted on website input .

in addition , since 2010 , omb staff has not held meetings on the development of performance.gov with staff from other committees in the house or senate that might use the website to inform their oversight of federal agencies .

as previously mentioned , we also found that omb has not articulated how various intended audiences , including congress , can use the site to accomplish specific tasks , such as supporting coordination and decision making to advance shared goals .

at the request of the congress , in december 2011 and june 2012 , we highlighted several instances in which congress has used agency performance information in various oversight and legislative activities , including ( 1 ) identifying issues that the federal government should address ; ( 2 ) measuring the federal government's progress toward addressing those issues ; and ( 3 ) identifying better strategies to address the issues when necessary .

for example , to help promote the use of e - filing of tax returns with the irs , congress used performance information to set clear expectations for agency performance , support oversight activities , and inform the development of additional legislation to help irs achieve its goals .

for further information , see the textbox .

congressional use of performance information to promote e - filing of tax returns congress sought to promote the use of e - filing , which allows taxpayers to receive refunds faster , is less prone to errors , and provides irs significant cost savings .

congress took the following actions to increase the use of e - filing:  setting expectations: as part of the internal revenue service restructuring and reform act of 1998 , congress established a performance goal of having 80 percent of individual tax returns e - filed by 2007 .

 oversight: congress monitored irs's progress in meeting the established goal for e - filings ; held 22 hearings related to irs filing seasons and e - filings ; and requested annual gao reports to congress on filing season performance , including e - filing .

 additional legislation: congress saw the need for further actions to help irs achieve the goal , and subsequently passed legislation to require tax return preparers who file more than 10 returns per year to do so electronically .

although irs did not meet the 80 percent e - filing target by 2007 ( 58 percent were e - filed that year ) , increased use of e - filing has substantially reduced irs's cost to process returns .

irs subsequently met this goal for individual tax returns as of the 2012 tax filing season , with 82 percent of individual returns e - filed .

irs has yet to reach the 80 percent e - file goal for some types of returns other than individual income tax returns .

see gao , 2012 tax filing: irs faces challenges providing service to taxpayers and could collect balances due more effectively , gao - 13-156 ( washington , d.c.: dec. 18 , 2012 ) .

moving forward , the federal government will need to make tough choices in setting priorities as well as reforming programs and management practices to address the pressing and complex economic , social , security , sustainability , and other issues the nation confronts .

gprama provides a number of tools that could help address these challenges .

since enactment in 2011 , the executive branch has taken a number of important steps to implement key provisions of the act , by developing interim cap goals and apgs , conducting quarterly reviews , assigning key performance management roles and responsibilities , and communicating results more frequently and transparently through performance.gov .

however , the executive branch needs to do more to fully implement and leverage the act's provisions to address these challenges .

our recent work reviewing federal performance issues and implementation of the act has pointed to several areas where improvements are needed and , accordingly , we recommended a number of actions .

in addition , examples from our past work along with the most recent results from our survey of federal managers show that the executive branch has made little progress addressing long - standing governance challenges related to improving coordination and collaboration to address crosscutting issues , using performance information to drive decision making , measuring the performance of certain types of federal programs , and engaging congress in a meaningful way in agency performance management efforts to ensure the resulting information is useful for congressional decision making .

of particular concern , omb has yet to develop a framework for reviewing the performance of tax expenditures , which represented approximately $1 trillion in forgone revenue in fiscal year 2012 .

in some areas , forgone revenue due to tax expenditures is nearly equal to or greater than spending for federal outlay programs .

since 1994 we have recommended omb take this action , and the act puts into place explicit requirements for the cap goals that omb identify related tax expenditures and measure their contributions to broader federal outcomes .

while early implementation of cap goals showed some promise , with tax expenditures being identified as contributing to 5 of the 14 goals , many of those tax expenditures were subsequently removed .

for example , our work shows that eight tax expenditures , representing about $2.4 billion in forgone revenue , should be listed as contributing to the energy efficiency cap goal .

the few tax expenditures that continue to be listed as contributors to a cap goal only represent about $2.7 billion in forgone revenue — approximately 0.3 percent of the total estimate of forgone revenue from tax expenditures .

while omb staff told us the removal of these tax expenditures was an oversight and that they will be added as contributors in the near future , it raises concerns as to whether omb previously ensured all relevant tax expenditures were identified as contributors to the 14 cap goals when they were published in february 2012 .

tax expenditures represent a substantial federal commitment to a wide range of mission areas , but do not receive the same scrutiny as spending programs .

therefore , it is possible that additional tax expenditures should have been identified and included as contributors to one or more of the other 9 cap goals .

moreover , for the 2 cap goals where tax expenditures were mistakenly removed , it is unclear if omb and the goal leaders assessed the contributions of those tax expenditures toward the cap goal efforts , since they were not listed in the december 2012 and march 2013 updates .

without information about which tax expenditures support these goals and measures of their performance , congress and other decision makers will not have the needed information to assess overall federal contributions towards desired results and the costs and relative effectiveness associated with those contributions .

omb took another promising action in 2012 by directing agencies to identify tax expenditures among the various federal programs and activities that contribute to their apgs — above and beyond what the act requires for all performance goals , which include apgs .

however , the 103 apgs developed for 2012 to 2013 at 24 agencies represent only a small subset of all performance goals across the government .

in addition , our review of the apgs for 2012 to 2013 found that only one agency , for one of its apgs , identified two relevant tax expenditures .

omb and agencies are missing important opportunities to more broadly identify how tax expenditures contribute to each agency's overall performance .

in addition to measuring the contributions of tax expenditures to their goals , our work has found that agencies have experienced common issues in measuring the performance of various other types of programs and have not made consistent progress in addressing them in the last 20 years .

as such , a comprehensive and concerted effort to address these long - standing difficulties needs to be taken .

with responsibilities to resolve crosscutting performance issues and facilitate the exchange of proven practices , the pic should lead such an assessment .

the pic has not yet addressed this issue in a systematic way , and without a comprehensive examination , it will be difficult for the pic and agencies to fully understand these measurement issues and develop a crosscutting strategy to address them .

that would likely result in agencies continuing to experience difficulties in measuring program performance in the future .

the pic's upcoming strategic planning effort provides a venue for developing an approach for tackling this issue by putting in place the necessary plans and accountability .

the pic's strategy should detail specific actors and actions to be made within set time frames to ensure that these persistent measurement challenges are adequately addressed .

to improve implementation of gprama and help address pressing governance issues , we make the following four recommendations .

to help ensure that the contributions made by tax expenditures toward the achievement of agency goals and broader federal outcomes are properly recognized , we recommend that the director of omb take the following three actions: revise relevant omb guidance to direct agencies to identify relevant tax expenditures among the list of federal contributors for each appropriate agency goal .

review whether all relevant tax expenditures that contribute to a cap goal have been identified , and as necessary , include any additional tax expenditures in the list of federal contributors for each goal .

assess the contributions relevant tax expenditures are making toward the achievement of each cap goal .

given the common , long - standing difficulties agencies continue to face in measuring the performance of various types of federal programs and activities — contracts , direct services , grants , regulations , research and development , and tax expenditures — we also recommend the director of omb work with the pic to develop a detailed approach to examine these difficulties across agencies , including identifying and sharing any promising practices from agencies that have overcome difficulties in measuring the performance of these program types .

this approach should include goals , planned actions , and deliverables along with specific time frames for their completion , as well as the identification of the parties responsible for each action and deliverable .

we provided a draft of this report for review and comment to the director of omb .

via e - mail , staff from omb's office of performance and personnel management agreed with the recommendations in this report .

the staff also provided technical comments , which we incorporated as appropriate .

we are sending copies of this report to the director of omb as well as interested congressional committees and other interested parties .

this report will also be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-6806 , or mihmj@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of our report .

key contributors to this report are listed in appendix iii .

the gpra modernization act of 2010 ( gprama ) lays out a schedule for gradual implementation of its provisions during a period of interim implementation — from its enactment in january 2011 to february 2014 when a new planning and reporting cycle begins .

gprama also includes provisions requiring us to review implementation of the act at several critical junctures and provide recommendations for improvements to its implementation .

this report is the final in a series responding to the mandate to assess initial implementation of the act by june 2013 , and pulls together findings from our recent work related to the act , the results of our periodic survey of federal managers , and our related recent work on federal performance and coordination issues .

our specific objectives for this report were to assess the executive branch's ( 1 ) progress in implementing the act and ( 2 ) effectiveness in using tools provided by the act to address challenges the federal government faces .

to address both objectives , we reviewed gprama , related congressional documents and office of management and budget ( omb ) guidance , and our past and recent work related to managing for results and the act .

we also interviewed omb staff .

in addition , to further address the second objective , we administered a web - based questionnaire on organizational performance and management issues to a stratified random sample of 4,391 persons from a population of approximately 148,300 mid - level and upper - level civilian managers and supervisors working in the 24 executive branch agencies covered by the chief financial officers ( cfo ) act of 1990 , as amended .

the survey results provided information about the extent to which key performance management practices are in place to help address challenges .

the sample was drawn from the office of personnel management's ( opm ) central personnel data file ( cpdf ) as of march 2012 , using file designators indicating performance of managerial and supervisory functions .

in reporting the questionnaire data , when we use the term “government - wide” and the phrases “across the government” or “overall” we are referring to these 24 cfo act executive branch agencies , and when we use the terms “federal managers” and “managers” we are referring to both managers and supervisors .

the questionnaire was designed to obtain the observations and perceptions of respondents on various aspects of results - oriented management topics such as the presence and use of performance measures , hindrances to measuring performance and using performance information , agency climate , and program evaluation use .

in addition , to address implementation of gprama , the questionnaire included a section requesting respondents' views on various provisions of gprama , such as cross - agency priority goals , agency priority goals , and quarterly performance reviews .

for the agency priority goal questions , we directed the federal managers from the nuclear regulatory commission to not answer these questions since omb did not require the agency to develop agency priority goals for 2012 to 2013 .

this survey is comparable to surveys we have conducted four times previously at the 24 cfo act agencies — 1997 , 2000 , 2003 , and 2007 .

the 1997 survey was conducted as part of the work we did in response to a gpra requirement that we report on implementation of the act .

the 2000 , 2003 , and 2007 surveys were designed to update the results from each of the previous surveys .

the 2007 survey also included a section requesting the respondent's view on omb's program assessment rating tool and the priority that should be placed on various potential improvements to it .

the 2000 and 2007 surveys , unlike the other two surveys , were designed to support analysis of the data at the department and agency level as well as government - wide .

for this report , we focus on comparing the 2013 survey results with those from the 1997 baseline survey ; and with the results of the 2007 survey , which is the most recent survey conducted before gprama was enacted in 2011 .

we noted the results from the other two surveys — 2000 and 2003 — when statistically significant trends compared to 2013 occurred .

similar to the four previous surveys , the sample was stratified by agency and by whether the manager or supervisor was a member of the senior executive service ( ses ) or non - ses .

the management levels covered general schedule ( gs ) or equivalent schedules at levels comparable to gs - 13 through gs - 15 and career ses or equivalent .

similar to our 2000 , 2003 , and 2007 surveys , we also incorporated managers or supervisors in other pay plans at levels generally equivalent to the gs - 13 through career ses levels into the population and the selected sample to ensure at least a 90 percent coverage of all mid - to upper - level managers and supervisors at the departments and agencies we surveyed .

most of the items on the questionnaire were closed - ended , meaning that depending on the particular item , respondents could choose one or more response categories or rate the strength of their perception on a 5-point extent scale ranging from “to no extent” at the low end of the scale to “to a very great extent” at the high end .

on most items , respondents also had an option of choosing the response category “no basis to judge / not applicable.” a few items had yes , no , or do not know options for respondents .

many of the items on the questionnaire were asked in our earlier surveys ; the sections of the questionnaire asking about gprama , program evaluations , and availability of performance information are new .

for these new questions , we conducted pretests with federal managers in several of the 24 cfo act agencies .

for the 2013 survey , based on feedback we obtained from our pretests with managers , we moved the placement of question 8 in the survey to accommodate the insertion of a new question .

in previous surveys , only those respondents who answered yes to question 5 — that they had performance measures available for their programs — were asked to answer question 8 — a series of items about the extent to which they used information obtained from performance measurement when participating in certain activities .

respondents answering “no” or “do not know” to question 5 could skip past the question 8 items .

for the 2013 survey , all respondents were asked to answer question 8 given the new question added .

to maintain the consistency and comparability with how we have previously analyzed and reported question 8 results , we applied the skip pattern used in prior surveys to question 8 by removing those individuals who did not answer yes to question 5 ( and in the past would have been directed to skip out of answering the question ) .

however , in the e - supplement we report the results as the federal managers answered the questionnaire , regardless of how they had answered question 5 .

to administer the survey , an e - mail was sent to managers in the sample that notified them of the survey's availability on the gao website and included instructions on how to access and complete the survey .

with the exception of the managers at the department of justice ( doj ) , which is discussed below , managers in the sample who did not respond to the initial notice were sent up to four subsequent e - mail reminders and follow - up phone calls asking them to participate in the survey .

in our prior surveys , we worked with opm to obtain the names of the managers and supervisors in our sample as selected through the cpdf .

however , since our last survey in 2007 , some agencies had requested from opm that the names of individuals within selected subcomponents be withheld from the cpdf .

we worked with officials at these agencies to attempt to gain access to these individuals to maintain continuity of the population of managers surveyed from previous years .

due to doj's national security concerns about providing identifying information ( eg , names , e - mail addresses , phone numbers ) of federal agents to us , we administered the current survey to all doj managers in our sample through a doj official .

to identify the sample of managers whose names were withheld from the cpdf , we provided doj with the last four digits of social security numbers , the subcomponent , duty location , and pay grade information .

to ensure that doj managers received the same survey administration process as the rest of the managers in our sample to the extent possible , we provided doj with copies of the notification , activation ( including the web link to our survey ) , and follow - up e - mails that managers at other agencies received from us .

doj administered the survey to its managers and conducted follow - up with the nonrespondents .

we administered the survey to all 24 agencies from november 2012 through february 2013 .

to help determine the reliability and accuracy of the cpdf data elements used to draw our sample of federal managers , we checked the data for reasonableness and the presence of any obvious or potential errors in accuracy and completeness .

for example , we identified cases where the managers' names were withheld and contacted opm to determine the reason and extent of this issue .

we also checked the names of the managers in our selected sample provided from opm with the applicable agency contacts to verify these managers were still employed with the agency in the role .

we noted discrepancies when they occurred and excluded them from our population of interest , as applicable .

we also reviewed our past analyses of the reliability of the cpdf data .

on the basis of these procedures , we believe the data we used from the cpdf are sufficiently reliable for the purpose of this report .

of the 4,391 managers selected for this survey , we found that 266 of the sampled managers had retired , separated , died , or otherwise left the agency or had some other reason that excluded them from the population of interest .

we received usable questionnaires from 2,762 sample respondents , or about 69 percent of the remaining eligible sample .

in addition , there were 29 persons that we were unable to locate and therefore unable to request that they participate in the survey .

the response rate across the 24 agencies ranged from 57 percent to 88 percent .

the overall survey results are generalizable to the population of managers as described above at each of the 24 agencies and government - wide .

the responses of each eligible sample member who provided a usable questionnaire were weighted in the analyses to account statistically for all members of the population .

all results are subject to some uncertainty or sampling error as well as nonsampling error .

because we followed a probability procedure based on random selections , our sample is only one of a large number of samples that we might have drawn .

since each sample could have provided different estimates , we express our confidence in the precision of our particular sample's results as a 95 percent confidence interval .

this is the interval that would contain the actual population value for 95 percent of the samples we could have drawn .

the percentage estimates presented in this report based on our sample for the 2013 survey have 95 percent confidence intervals within plus or minus 5 percentage points of the estimate itself , unless otherwise noted .

an online e - supplement shows the questions asked on the survey along with the percentage estimates and associated 95 percent confidence intervals for each item for each agency and government - wide .

because a complex survey design was used in the current survey as well as the four previous surveys , and different types of statistical analyses are being done , the magnitude of sampling error will vary across the particular surveys , groups , or items being compared due to differences in the underlying sample sizes , usable sample respondents , and associated variances of estimates .

for example , the 2000 and 2007 surveys were designed to produce agency - level estimates and had effective sample sizes of 2,510 and 2,943 , respectively .

however , the 1997 and 2003 surveys were designed to obtain government - wide estimates only , and their sample sizes were 905 and 503 , respectively .

consequently , in some instances , a difference of a certain magnitude may be statistically significant .

in other instances , depending on the nature of the comparison being made , a difference of equal or even greater magnitude may not achieve statistical significance .

we note in this report when we are 95 percent confident that the difference is statistically significant .

also , as part of any interpretation of observed shifts in individual agency responses between the 2013 and the 2000 surveys , it should be kept in mind that components of some agencies and all of the federal emergency management agency became part of the department of homeland security .

in addition to sampling errors , the practical difficulties of conducting any survey may also introduce other types of errors , commonly referred to as nonsampling errors .

for example , difficulties in how a particular question is interpreted , in the sources of information available to respondents , or in how the data were entered into a database or were analyzed can introduce unwanted variability into the survey results .

with this survey , we took a number of steps to minimize these nonsampling errors .

for example , our staff with subject matter expertise designed the questionnaire in collaboration with our survey specialists .

as noted earlier , the new questions added to the survey were pretested to ensure they were relevant and clearly stated .

when the data were analyzed , a second independent gao analyst independently verified the analysis programs to ensure the accuracy of the code and the appropriateness of the methods used for the computer - generated analysis .

since this was a web - based survey , respondents entered their answers directly into the electronic questionnaire , thereby eliminating the need to have the data keyed into a database , thus avoiding a source of data entry error .

we conducted this performance audit from august 2012 to june 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

status omb staff agreed with our recommendations .

clarify the ways that intended audiences could use the information on the performance.gov website to accomplish specific tasks and specify the design changes that would be required to facilitate that use ; seek to more systematically collect information on the needs of a broader audience , including through the use of customer satisfaction surveys and other approaches recommended by howto.gov ; and seek to ensure that all performance , search , and customer satisfaction metrics , consistent with leading practices outlined in howto.gov , are tracked for the website , and , where appropriate , create goals for those metrics to help identify and prioritize potential improvements to performance.gov .

omb staff agreed with our recommendations .

provide a definition of what constitutes “data of significant value ; ” direct agencies to develop and publish on performance.gov interim quarterly performance targets for their agency priority goal performance measures when the above definition applies ; direct agencies to provide and publish on performance.gov completion dates , both in the near - term and longer - term for their milestones ; and direct agencies to describe in their performance plans how the agency's performance goals — including priority goals — contribute to any of the cross - agency priority goals .

when such revisions are made , the director of omb should work with the pic to test and implement these provisions .

status omb staff agreed with our recommendations .

complete information about the organizations , program activities , regulations , policies , tax expenditures , and other activities — both within and external to the agency — that contribute to each goal ; and a description of how input from congressional consultations was incorporated into each goal .

to improve performance management staff capacity to support performance management in federal agencies , the director of opm should , in coordination with the pic and the chief learning officer council , work with agencies to: identify competency areas needing improvement within agencies ; identify agency training that focuses on needed performance management competencies ; and share information about available agency training on competency areas needing improvement .

opm agreed with our recommendations , and explained that it will work with agencies , and in particular with pios , to assess the competencies of the performance management workforce .

opm also stated that it will support the use of the pic's performance learning website to facilitate the identification and sharing of training related to competencies in need of improvement .

omb staff agreed with our recommendations .

conduct formal feedback on the performance of the pic from member agencies , on an ongoing basis ; and update its strategic plan and review the pic's goals , measures , and strategies for achieving performance , and revise them if appropriate .

to better leverage agency quarterly performance reviews as a mechanism to manage performance toward agency priority and other agency - level performance goals , the director of omb should — working with the pic and other relevant groups — identify and share promising practices to help agencies extend their quarterly performance reviews to include , as relevant , representatives from outside organizations that contribute to achieving their agency performance goals .

omb staff agreed with our recommendation .

summary of related recommendations the director of omb , in considering additional programs with the potential to contribute to the crosscutting goals , should review the additional departments , agencies , and programs that we have identified , and consider including them in the federal government performance plan , as appropriate .

status omb staff agreed with our recommendation .

in december 2012 and march 2013 , omb updated information on performance.gov on the cap goals .

omb included some of the agencies and programs we identified for select goals , but in other instances eliminated key contributors that were previously listed .

in addition to the above contact , elizabeth curda ( assistant director ) and benjamin t. licht supervised this review and the development of the resulting report .

tom beall , peter beck , mallory barg bulman , virginia chanley , laura miller craig , sara daleski , karin fangman , stuart kaufman , don kiggins , judith kordahl , jill lacey , janice latimer , adam miles , kathleen padulchick , mark ramage , daniel ramsey , marylynn sergent , megan taylor , sarah veale , kate hudson walker , and dan webb made significant contributions to this report .

pawnee davis , shannon finnegan , quindi franco , ellen grady , robert gebhart , tom james , donna miller , michael o'neill , robert robinson , and stephanie shipman also made key contributions .

