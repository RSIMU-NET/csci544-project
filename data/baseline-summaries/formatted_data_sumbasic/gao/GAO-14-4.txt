having reliable program data is an important factor in being able to effectively manage and evaluate a program .

our previous work on the workforce investment act of 1998 ( wia ) , however , has raised questions about the quality of data that states report to the u.s. department of labor ( dol ) on the number of individuals they serve .

wia , the centerpiece of the nation's employment and training system , established three separately funded programs — adult , dislocated worker , and youth — and created a comprehensive one - stop system , now known as the american job center network , for the delivery of many federally funded employment and training program services .

at this writing , the congress is considering proposals to reauthorize wia , which has been due for reauthorization since 2003 .

in our previous work , we found that the federal government's efforts to collect and report accurate , consistent wia program performance data from states were affected by ( 1 ) flexibility in federal guidance on collecting and reporting the data , ( 2 ) major changes to states' information systems that resulted in lost data and other issues , and ( 3 ) limited monitoring by the department of labor ( dol ) .

we also found that dol's wia data do not include information on all participants in the adult and dislocated worker programs and that the data were not comparable across states and local areas .

states were reporting inconsistent data on wia participants in the adult and dislocated worker programs because dol's guidance did not clarify how certain participants should be counted .

given the longstanding concerns about the quality of the data and in anticipation of wia's reauthorization , you asked us to examine the data on wia participants .

this report addresses the following questions: similarly , dol's office of inspector general found that 1 .

what factors have affected the ability to report consistent and complete data on participants in the wia adult and dislocated worker programs , and 2 .

what actions has dol taken to improve the quality of participant data ? .

gao - 07-1051t ; gao - 06-82 .

inspector general and representatives of two national workforce - related organizations .

to better understand the challenges faced by states in reporting data on these wia programs , we visited or telephoned dol's employment and training administration's ( eta ) six regional offices and a nongeneralizable sample of eight states .

within each state , we visited or contacted at least one comprehensive american job center — formerly known as a one - stop center — or a local workforce board .

we selected the states to provide diversity on the basis of: ( 1 ) geographic location , ( 2 ) total federal spending on the adult and dislocated worker programs in program year 2010 , ( 3 ) the extent of data issues identified by dol's data contractor in the fourth quarter of program year 2010 , ( 4 ) whether the state reported participants who received only core “self - service,” and ( 5 ) the number of local areas within the state .

we analyzed data for program year 2011 because they were the most recent full year of wiasrd data available when we conducted our review .

program year 2011 ran from july 1 2011 through june 30 2012. estimates for the number of , characteristics of , and services provided to participants whose information is recorded by dol as having been served by the wia adult or dislocated worker program .

however , we did not find those data to be reliable for other purposes such as making state - to - state comparisons because of variations in how states collect and report participant data for the wia adult and dislocated worker programs .

see appendix i for additional information on our scope and methodology .

we conducted this performance audit from august 2012 through november 2013 in accordance with generally accepted auditing standards .

those standards require that we plan and perform the audit work to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

wia requires states and local areas to bring together a number of federally funded employment and training programs into a comprehensive workforce investment system , the american job center network .

these programs — including the adult and dislocated worker programs — are known as mandatory partners , and must provide services through this network ( see tab .

1 ) .

the wia adult and dislocated worker programs are designed to provide quality employment and training services to assist eligible individuals to find and qualify for employment and to help employers find the skilled workers they need .

the adult program provides services to individuals over the age of 18 who are job seekers , although states and local areas must give priority of service to low - income individuals if funds are determined to be limited .

the dislocated worker program provides services to workers who have been or will be terminated or laid off from employment .

for fiscal year 2013 , congress appropriated over $1.9 billion for the adult and dislocated worker programs: $730 million for the adult program and $1.2 billion for the dislocated worker program .

dol's employment and training administration administers the wia adult and dislocated worker programs and oversees their implementation , which is carried out by states and local areas .

each state must have one or more designated local workforce investment area , and each local area must have at least one comprehensive american job center where job seekers can receive core services and access other programs and activities offered by the mandatory partners .

although each local area must have one comprehensive center , under wia , the mandatory partners have flexibility in the way they provide services through the american job center network , and can co - locate services on site or make referrals to external service providers or training , including to local community colleges .

wia provides three tiers , or levels , of service for adult and dislocated workers: ( 1 ) core , ( 2 ) intensive , and ( 3 ) training .

core services include basic services , such as job search or résumé - building assistance , and may be accessed with or without staff assistance .

intensive services include activities such as staff - assisted comprehensive assessment of a participant's skill levels and case management .

29 u.s.c .

§§ 2831 and 2864 ( c ) ( 2 ) .

training services include activities such as occupational skills or on - the - job training ( see fig .

1 ) .

service at one level and a determination that a participant is unable to obtain employment through that service are prerequisites for service at the next level , although wia does not specify the amount of time an individual must spend or the number of attempts that must be made to gain employment before moving to the next level .

job seekers who receive only core services that are self - service and informational in nature are not counted in the programs' performance measures , but dol requires that states count such individuals as program participants .

self - service and informational activities can be accessed either at an american job center or remotely , such as when a job seeker searches for employment over an internet connection to an american job center from a home computer .

as part of its oversight , dol collects program data from states , which are used to assess how well the adult and dislocated worker programs are working .

states must submit quarterly and annual performance reports to dol , in addition to uploading individual records on a quarterly basis to dol's national wiasrd database .

specifically , states must submit quarterly and supplemental monthly performance reports , a validated annual performance report at the end of each year , and quarterly wiasrd files for each reporting quarter for a program year .

the wiasrd files include demographic and characteristic information for participants in the wia adult and dislocated worker programs and information about services received through these wia programs , as well as through some other partner programs .

the process of collecting and reporting wia data involves all three levels of government .

more specifically , participant data are typically collected by staff at american job centers and entered into a state or local information system .

in some states , local staff may enter data directly into a statewide information system ; in other states , local areas may use their own individualized information systems to enter data from which they then must extract and compile for submission to the state .

after the data is submitted to the state agency , it is compiled and formatted for the various submissions to dol , including for quarterly wiasrd record layout submissions .

 ( see fig .

2 ) .

dol's guidance to states , in the form of training and employment guidance letters and training and employment notices , details how states should collect and report data on participants in the wia adult and dislocated worker programs .

however , the flexibility in the guidance dol provides to states makes it difficult for dol to provide consistent national data on participants in these programs .

the flexibility in the guidance stems from the flexibility inherent in wia , which allows states and local areas to tailor service delivery to their needs .

consequently , dol's guidance is designed to accommodate the different ways that states and local areas can deliver services through the american job center network , including decisions about whether to enroll participants in partner programs .

this flexibility , however , results in variations in how states and local areas report participant data , which makes it challenging for dol to aggregate wia data at the national level .

in particular , it has created inconsistencies among states in when a job seeker is counted as a participant in the wia adult or dislocated worker program .

in addition , dol's guidance is open to interpretation , allowing states to define and report some variables differently , further contributing to inconsistencies in the data that states report to dol on these programs .

for example , while dol requires states to report the type of training service provided to wia participants who receive such services , the agency's guidance only lists the six broad categories of training services states must report without defining or describing them in detail .

in accordance with government internal control standards , management is responsible for developing policies and procedures to achieve program objectives and clearly communicating these policies and procedures to facilitate understanding and consistent implementation .

the flexibility in dol's guidance on when states and local areas should count individuals as participants in the wia adult and dislocated worker programs has resulted in inconsistencies in the data reported on program participants .

wia allows for flexibility in the extent to which adult and dislocated worker program services are integrated with those from other programs .

integrate wia services with those from other partner programs so that job seekers have access to a coordinated system of employment and training services .

as a result , states' service delivery models differ in the extent of integration between wia services and other programs .

for example , state officials that we interviewed told us that they funded core services at their american job centers exclusively through wia , exclusively through a partner program , or through a blend of both wia and partner program funds .

according to officials from dol's national office , states and local areas are best positioned to determine the mix of services that will meet the needs of their job seekers .

however , depending on which service delivery model a state or local area selects , job seekers receiving the same types of services may be counted as wia participants at different points in time , or they may never be counted under the wia adult or dislocated worker program .

used in this context , integration can refer to the co - location of services at an american job center , or to integrated funding to provide any given service .

lower populations .

for example , according to the state officials we interviewed , utah's american job centers integrate wia adult program funding with funding for the wagner - peyser program to provide core services .

as a result , every job seeker aged 18 years or older who receives core services in utah is counted as a participant in both programs , as permitted under dol's guidance .

in comparison , state officials in california told us that the state typically funds core services exclusively through the wagner - peyser program and therefore counts all individuals accessing core services from an american job center as participants in the wagner - peyser program , but not as participants in the wia adult program or the dislocated worker program .

therefore , only job seekers who meet the eligibility criteria for the wia adult or dislocated worker program and receive intensive or training services funded by those programs are counted as wia participants .

because of this variability , the total counts of wia adult program participants and wia dislocated worker program participants represent different populations of job seekers in different states , depending on the service delivery model the state uses .

as a result of these differences , utah ranked 3rd out of 53 states in the total number of participants it served in the wia adult program in program year 2011 , even though it ranked 36th in overall population.the same time , california ranked 27th in the total number of participants served in the wia adult program , even though it was the most populous state ( see fig .

3 ) .

to improve the quality of data on participants in the wia adult or dislocated worker programs , dol has enhanced its oversight efforts and introduced new initiatives including having its data contractor produce quarterly reports on data issues , requiring states to validate their wia data on an annual basis , and engaging its regional offices in periodic reviews of case files from states .

however , the agency has not established a process to review the results of oversight to identify and resolve systemic issues with the quality of participant data from the wia adult and dislocated worker programs .

our past work has shown that the benefit of collecting performance information is only fully realized when this information is actually used by managers to make decisions oriented toward improving results .

dol has a contract with spra to correct and analyze wiasrd data and provide data files and reports on the accuracy of the data reported by states that are made available to the public via dol's website .

corrections spra makes to the state wiasrd data files may not be accurate , and may result in incorrect data for a state .

the publicly available data files that spra produces are released quarterly and include “data issues reports,” which identify issues or anomalies in the wia data submitted by each state to dol .

officials from dol's national office stated that the original intent of spra's analysis was to create the publicly available data files and not to report on data anomalies or errors , even though spra has always identified issues with the data while creating the publicly available files .

however , since about 2010 , when states started submitting quarterly wiasrd files instead of annual ones , reviewing the quality of the data and issuing the quarterly “data issues and anomalies report” has become standard practice under spra's contract , according to officials from dol's national office .

the agency's regional offices are supposed to provide the states with the published quarterly error reports and ask them to update any errors prior to their next quarterly wiasrd submission .

dol publishes spra's data files and reports on its website , and its regional offices are expected to share these reports with their states so that the states can correct any data issues in their subsequent quarterly submissions .

however , officials from dol's region 5 said that although they receive these reports from dol's national office , they have not had the chance to review them or comment on any of the errors for states in their region .

in addition , officials from dol's region 1 said that although these reports have always been available on dol's website , they only recently began receiving the reports in a user friendly format and that they only recently began providing feedback to spra on issues identified for the states in their region .

our analysis of spra's data issues reports suggests that some states may not be using spra's reports to improve the quality of their data on wia participants , which could be due to a lack of awareness of these reports .

for example , spra's data issue reports for the fourth quarters of both program years 2010 and 2011 identified some of the same issues , such as errors in the dates of service reported by the states .

this suggests that the states that made these errors in 2010 may not have reviewed these reports and used them to correct the data reported in the following year .

in addition , while officials from four states were aware of the spra reports , officials from four other states told us they either were not aware of these reports or that they began receiving these reports from the regions only recently , beginning with the final report for program year 2011 .

when asked , officials from dol's national office stated that they do not have a plan to systematically identify or address recurring errors noted in spra's reports .

government internal control standards note that , for oversight and monitoring to be effective , information should be recorded and communicated to management and others within the entity and external stakeholders , and this should be done within a time frame that enables them to carry out their internal control and other responsibilities .

officials added that they do not conduct formal oversight reviews or audits of spra's data analyses because they consider spra to be the “data experts” and , therefore , do not know what kind of oversight they could provide .

according to government standards for internal controls , agencies should ensure that ongoing monitoring occurs in the course of normal operations , which would include monitoring and oversight of contractors through regular management and supervisory activities .

these officials also said they believe any major data issues or obstacles would be uncovered by their internal data edit checks , which are run on all wiasard data submitted by the states prior to spra's review of the data .

gao / aimd - 00-21.3.1 .

correcting the data .

for example , officials from california explained that spra changed some of the numbers entered by local areas for wiasrd variable 325 — employment and training programs related to food stamps — to zeros because the numbers entered seemed too high .

according to the state officials , the numbers for that variable entered by the local areas were correct .

states , however , are generally not provided an opportunity to review and verify spra's changes before they are made , as they only receive copies of the data issues reports after they are published .

officials from both dol's national office and from some of the state workforce agencies noted that not all issues identified by spra represent actual errors and that some outliers on certain variables are acceptable .

dol requires each state to validate the data it collects and report on participants in the wia adult and dislocated worker programs on an annual basis , but the findings from these validation efforts have not been strategically used to identify systemic issues with or to improve the quality of the data on wia participants .

government standards for internal controls state that for oversight and monitoring to be effective , information should be communicated to management and others , along with the use of this information for program assessment , so that it can be used to carry out their internal control and other responsibilities .

each year , states are required to review a sample of wia participant records to determine whether the source documents match the information in the electronic records states use to collect and report data to dol in wiasrd .

dol requires states to validate the accuracy of the data they submit annually to ensure that decisions about wia policy and funding are made based on a true picture of the number of participants and program outcomes .

although dol has established a provisional 5 percent error rate threshold for states' validation of the variables , the agency does not have plans to tie the results of these validation efforts to dol's financial awards or penalties because , according to officials from dol's national office , the results of states' validation efforts were never intended to be used for enforcement purposes .

officials from dol's national office explained that , in their opinion , dol's regional offices should be using the states' validation efforts as a management tool to improve the quality of their data by identifying inaccurate or confusing variables to target the technical assistance they provide to states and local areas .

dol , however , does not know what effect state data validation efforts have had on the quality of participant data for the wia adult and dislocated worker programs .

in addition , our interviews with regional and state officials suggest that dol's regions and the states are not always using the results of these data validation efforts to improve data quality or target technical assistance .

during our interviews with regional and state officials , only those from region 3 and massachusetts described specific efforts to use the results of the state data validation efforts to improve data quality and direct technical assistance .

officials from dol region 3 noted that the region recently began requiring states to respond to findings from states' annual data validation efforts and to track error rates found in each quarterly submission .

similarly , officials from massachusetts said that they use the results of their data validation efforts to direct the technical assistance the state provides to local areas and to improve the quality of the state's wia data .

in contrast , officials from one state said that , although they receive information about errors associated with specific case files as they enter data from each file into dol's data validation system , they do not know how to retrieve their state - wide results from dol's database and they have not received any reports from dol documenting the nationwide results of the data validation efforts .

officials from dol's national office said that they were surprised by this , and that data element validation results are available to states through dol's reporting system .

moreover , our analyses of the results of dol's efforts to validate wiasrd variables for program years 2010 and 2011 suggest that dol's data validation efforts have not prevented high error rates on certain data elements for select variables — nationally , error rates for certain variables have remained well above the 5 percent threshold over both program years .

for example , in program year 2010 , across all states , about 16 percent of the files for the adult program for which the “date of program exit” variable was reviewed had errors , compared to around 14 percent in program year 2011 .

similarly , the nationwide error rate for “date of first staff - assisted core service” was above 7 percent in both program years for both the adult and the dislocated worker programs .

when asked , officials from dol's national office and two regional offices explained that variables containing dates frequently have high error rates due to discrepancies between the date reported and the date in the source documentation .

if a date , such as date of dislocation — the date a worker lost his or her job — in the hard copy document differs from the date in the electronic record , even by one day , the variable for that record “fails” the validation check .

moreover , officials from dol's national office and three regional offices stated that high error rates resulting from such discrepancies do not necessarily reflect any serious issues with the reported data — a participant would still be a dislocated worker whether , for example , the date of dislocation was june 20th or june 21st .

nonetheless , dol requires these dates to match precisely and errors noted in program year 2011 for these variables were still prevalent although similar errors were noted the previous year .

dol's required annual data validation efforts are resource - intensive and time - consuming both for dol regions and states , according to officials from dol's national office , two dol regional offices , and five states .

however , dol has not yet evaluated the process or determined its effect on data quality .

specifically , an official from one state workforce agency estimated the cost of its annual data validation efforts , including staff time , travel , and other expenses , to be about $200,000 .

officials in another state explained that they would like dol to reduce the required sample size for the required validation of the data elements in wiasrd in order to reduce the administrative burden on states .

in addition , in 2011 one dol regional office convened a workgroup of representatives from four states that analyzed the data validation procedures and provided recommendations to dol's national office for improvements to reduce the administrative burden on states .

these recommendations included considering using alternative sampling methods , revisiting the frequency and precision requirements of data validation , and issuing guidance to share “best practices” across states and local areas .

however , as of september 2013 , dol had not implemented the workgroup's recommendations , and the data validation process remains unchanged .

officials from dol's national office acknowledged the trade - off between monitoring data quality and minimizing the administrative burden on states .

they said that revising wiasrd's edit checks to allow states more flexibility may result in making the data validation process more efficient by , for example , permitting states to report a range of dates , if appropriate , for certain variables .

dol's regional offices review a sample of case files from states as part of their oversight of the quality of data for the wia adult and dislocated worker programs , but they have not used the results of these reviews to identify systemic issues with the quality of the data on wia participants .

according to officials from dol's national office , its regional offices are responsible for providing feedback to states based on these reviews , and it is not the national office's role to conduct any type of systemic review to identify cross - state data issues .

government standards for internal controls state that for oversight and monitoring to be effective , information should be communicated to management and others , along with the use of this information for program assessment , so that it can be used to carry out their internal control and other responsibilities .

in response to a recommendation from a prior gao report , dol began to require its regional offices to review a sample of case files to monitor states' annual data validation procedures .

in addition , over the past few years , to address concerns about the nationwide consistency of monitoring activities , dol has issued additional guidance to its regional offices on the process that should be used in reviewing the case files .

officials from all six of dol's regional offices reported using these materials when they design and conduct their reviews of the case files .

the review process begins when officials from dol's regions review a state's most recent data validation report and identify a subsample of participant case files from the most recent review by the state .

in addition to checking the data in the electronic records by comparing them to the source documentation , dol's regional staff assess whether the state followed the proper procedures in conducting its annual data validation efforts , according to officials from dol's national office .

the process concludes with a report outlining the dol regional office's findings , including non - compliance with statutory or regulatory requirements for collecting and reporting data on wia participants .

many of the reports also identify areas of concern , such as when states do not share their annual data validation results with local area staff from american job center partner programs , and identify promising practices observed during the reviews .

state officials have 45 days to respond to findings in the region's report and are also encouraged but are not required to respond to areas of concern detailed in the report .

in addition , officials from dol's national office noted that states with high error rates on select variables are encouraged to inform the regional offices of how they plan to reduce their error rates in the future .

officials from dol's national office said that , while they discuss the results of these reviews with regional officials and provide state - specific technical assistance as needed , they do not have a regular , formal process for analyzing the findings from these reviews by their regional offices , including determining whether similar findings and areas of concern were identified across states .

dol officials explained that , because the reviews are part of the regional offices' oversight of the states , they believe that the national office should not be involved in monitoring the results of the reviews or the way in which they are conducted .

as a result , dol does not have a systematic means of determining the importance of the findings , their prevalence , or their likely effect on the quality of the national data on participants in the wia adult and dislocated worker programs .

this limits dol's ability to respond to data issues that are systemic or widespread .

table 2 summarizes our analysis of the most prevalent issues identified during the most recent reviews for each of the 53 states and territories .

over the past few years , dol has issued additional guidance and provided technical assistance to states and local areas , including training and webinars , to clarify and explain the requirements for collecting and reporting data for the wia adult and dislocated worker programs .

however , some state officials said that dol's technical assistance is not always timely , and that dol could do more to facilitate the collection or sharing of promising data collection and reporting practices across regions and states .

for example , dol has provided general technical assistance on data reporting for the wia adult and dislocated worker programs to states , and officials from three of the eight states said that the assistance provided by dol's regional offices was useful in helping them address some of the challenges related to data reporting .

in particular , officials from dol's national office said that some regional offices issue quarterly performance letters to states that include program year performance data and any related analysis , in addition to hosting quarterly phone conferences with state performance specialists to discuss performance issues .

dol also sponsors the workforce3one website , which contains a variety of training and background materials related to data collection and reporting for wiasrd .

national and regional dol data specialists also said they hold biweekly meetings to discuss data issues .

in addition , dol officials from each region described regular communication they have with state officials to provide technical assistance in response to specific data reporting issues , and officials from five of the six regional offices described conference calls that they have hosted as opportunities for states to discuss challenges related to the quality of their data on wia participants .

furthermore , dol's national and regional offices have access to an internal data system , infospace , which allows them to retrieve and review publicly available wiasrd data by state and local area .

over the past few years , dol has also issued a number of training and employment guidance letters and training and employment notices related to data collection and reporting for wia .

in 2011 , dol developed and hosted a series of webinars for states and local areas , including one on data validation and data quality issues .

the materials from this session describe the approach dol uses to monitor the data and explore issues and findings across states .

they also highlight how data validation can be used to improve data systems and provide information on the guidance regional offices use to review states' case files .

while the webinar materials present information on some of the consistent findings across states — such as incorrect source documentation and exit dates — dol officials said that they have not provided any additional formal technical assistance to address these issues on a national level because of resource limitations .

moreover , they said it would be difficult for dol to provide such assistance without having first reviewed the results of its own monitoring efforts .

dol's webinar also noted that dol would establish a working group in the summer of 2011 to look into and possibly revise the source documentation requirements for the annual data validation process .

however , as of the summer of 2013 , dol officials said that this working group had not been established due to competing priorities and resource constraints .

officials from two states noted that dol's updates to its guidance for collecting and reporting the data are often not provided far enough in advance to be implemented by the time changes take effect .

for example , officials from california said that they often do not have enough lead time to properly implement new data elements or guidance when it is issued by dol .

according to state officials , the state generally has 1 month or less to change its automated system to meet deadlines , which is not enough time .

in addition , officials from georgia said the data validation reports they currently receive from dol are not timely since they are at least 3 months old by the time the state receives the reports .

some state officials also told us that they would benefit from learning how their peers are addressing challenges in reporting data on the wia programs .

officials from dol's national office , however , told us they do not currently facilitate the collection or sharing of promising data collection and reporting practices across regions or states , and have no plans to do so — because of competing resources , the agency's main focus is on service delivery rather than data collection .

best practices state that high - performing organizations continually assess performance and efforts to improve performance .

in particular , managers can use performance information to identify and share more effective processes and approaches .

in addition to its regular monitoring activities , dol has taken specific steps to improve the consistency of the wia data collected by states and local areas .

for example , the agency has developed an integrated data reporting system , which is being piloted in two states .

however , dol has not evaluated the results of the pilot program to determine whether it has had a positive effect on the quality of participant data for the wia adult and dislocated worker programs and , despite not having evaluated its effectiveness , plans to expand the program to additional states .

to standardize and streamline reporting across several of dol's workforce programs — the wagner - peyser program , the wia adult , dislocated worker and youth programs , veterans employment and training service , national emergency grants , and trade adjustment assistance programs — the agency has developed an integrated data reporting system , wispr .

two states , pennsylvania and texas , have been piloting wispr since 2007 to collect and report data on the wia adult and dislocated worker programs , and a third state — utah — plans to start piloting wispr in the fall of 2013 .

officials from dol's national office and from utah explained that one of wispr's key advantages over the current separate reporting systems for each program is that wispr has standardized variables that include all the required variables for each program .

improvement over their current system because future changes in dol's guidance for any of the workforce programs it administers — including the wia adult and dislocated worker programs — would be incorporated into a single system , facilitating implementation of these changes .

although dol's guidance for reporting data in wiasrd encourages states and local areas to provide integrated services through multiple programs , each program has its own reporting requirements , according to officials from dol's national office .

as a result , it is not possible to track individual job seekers who receive services from multiple programs across the workforce system , or to determine the proportion of resources provided by each program for a particular service , or to attribute participant outcomes to those programs .

the current record layout of wiasrd to match that of wispr .

dol officials told us they expect to implement the revised wiasrd record layout in the fall of 2013 .

however , as of august 2013 , they said it is not clear whether or when nationwide implementation of wispr will occur because this depends on the resources available to upgrade both federal and state information systems and the associated programming costs .

while wispr appears to offer advantages over the current reporting system that might make it a promising step forward , dol does not currently have plans to evaluate the results of the pilot program to determine whether it has had a positive effect on the completeness and consistency of participant data for the wia adult and dislocated worker programs before expanding the program to other states .

dol officials cited the agency's limited resources as the reason for not planning an evaluation of the wispr pilot program before expanding it to other states .

however , best practices note that evaluation can play a key role in program planning , management , and oversight by providing feedback to program managers , legislative and executive branch policy officials , and the public .

further , when pilot programs are designed to produce change — such as by allowing for more streamlined data collection and reporting — assessing the impact is essential for knowing if the pilot is meeting its goals .

without an evaluation of wispr , dol will not know if this data system has resulted in the collection of more accurate wia participant data when compared to wiasrd .

finally , dol administers two grant programs that states can use to improve their wia information systems: the workforce innovation fund and the workforce data quality initiative.fund is a competitive grant program that supports innovative approaches to the design and delivery of employment and training services .

although it is not targeted specifically at information systems , at least 3 of the 26 grants awarded by dol have been used for local initiatives to integrate their workforce data systems .

for example , one local area we visited in chicago received a workforce innovation fund grant that they plan to use to integrate the different data systems used by the workforce programs in their local area .

officials said that they hope the improvements will result in more data - driven decisions about service delivery , and that all employment and training programs in their local area will be able to share information electronically .

another grant program , dol's workforce data quality initiative , is also not specifically aimed at wia data reporting but may have positive incidental effects on wia data quality , according to dol officials .

the purpose of this initiative is to create a longitudinal database to chart individuals' progress through the education system and beyond to the labor market .

this effort would entail upgrades to state information systems that may resolve some data reporting issues currently attributed to limited technological capacities .

at this time , it is too early to know whether these grants will have a positive effect on the quality of wia participant data .

collecting and reporting consistent and complete data is important for program oversight and management and to evaluate the effectiveness of program activities and services , but it can be difficult when federal programs are carried out in partnership with states and local areas .

dol has taken steps to improve the quality of the data on wia's adult and dislocated worker programs .

however , the flexibilities in dol's guidance , reflective of those inherent in the programs' authorizing statute , which allows states flexibility in program design , along with limitations in state information systems , present challenges to dol in collecting and reporting consistent and complete data on a unique count nationwide of participants in the wia adult and dislocated worker programs .

without such data , policymakers , program officials , and other stakeholders have an incomplete picture of the number of adults and dislocated workers served , their characteristics , and the type and level of services received .

in addition , while dol engages in several types of oversight activities designed to ensure the accuracy of states' data on participants in the wia adult and dislocated worker programs , it does not consistently share the results of its oversight activities with states and local areas .

as a result , states and local areas are not always aware of potential data quality issues , and may miss opportunities to improve their data collection and reporting .

moreover , since 2007 , two states have been piloting a new information system that tracks program participants across several of dol's employment and training programs , but dol does not plan to evaluate its effects on the quality of the data collected on participants in the wia adult or dislocated worker or other programs before it expands the system to other states .

similarly , dol does not regularly collect and disseminate promising practices to states and local areas , which could facilitate the adoption of steps other states and local areas have taken to improve their data collection and reporting efforts .

while it may not be possible to achieve 100 percent precision and accuracy in the data reported on participants in a large , complex system like the workforce investment system , by not appropriately targeting their available resources and facilitating sharing of promising practices among states to continuously try to improve the quality of the data , dol misses an opportunity to identify and address longstanding , systemic issues .

1 .

to improve the consistency and completeness of national data on participants in the wia adult and dislocated worker programs , we recommend that the secretary of labor take additional steps to improve the uniformity of participant data reported by states .

these steps could include the following: a. providing additional guidance to states on data reporting , such as how core and intensive services should be recorded for wia participants who receive these services through partner programs ; and b. conducting an evaluation or review of wispr to determine if it has resulted in more complete and consistent data collection and reporting for participants in the wia adult and dislocated worker programs and placing a high priority on the implementation of wispr if it is shown to improve data consistency and completeness .

2 .

we also recommend that the secretary of labor promote a formal , continuous process for improving the quality of data on participants in the wia adult and dislocated worker programs through such measures as the following: a. consistently sharing the results of all oversight activities with states and local areas , including findings from validation of participant data ; b. reviewing the methods used for data validation , such as its scope and error rate threshold , to identify opportunities to increase efficiencies and accountability in the process .

this could include implementing , if appropriate , recommendations from the regions' review of data validation procedures ; c. evaluating data validation efforts to determine their effects on data quality , particularly on systemic errors , and providing targeted guidance and assistance to states and local areas to address such errors ; d. regularly monitoring social policy research associates' corrections and analyses of state wia participant data , sharing this information with states , and coordinating with states to ensure that any corrections are appropriate and accurate ; and e. collecting and disseminating promising practices to states and local areas on data collection and reporting on a regular basis .

we provided a draft of this report to officials at dol for their review and comment .

we received written comments from dol , which are reproduced in their entirety in appendix iii .

dol officials did not state whether they agreed or disagreed with our recommendations .

these officials acknowledged the importance of having reliable data to effectively manage and evaluate the wia adult and dislocated worker programs ; however , they commented that data reliability should be balanced with the flexibility wia gives to states and with dol's responsibility to prioritize use of its limited resources .

they stated that wia provides states and local areas with the flexibility to serve their customers in the way that best suits their particular needs .

dol officials also stated that the agency has invested significant resources in its workforce performance accountability system , especially for wia programs .

according to officials , the agency has a robust system in place to ensure data quality and reliability and has recently made several enhancements to the reporting system .

in their comments , dol officials detailed various efforts they plan to take to address our recommendations .

nonetheless , we believe that these efforts will not sufficiently address the specific data quality issues we identified and encourage dol to take more targeted steps as outlined in our recommendations .

in response to our first recommendation , dol officials said that they believe the agency's current guidance is clear but that they will continue to work with states to develop additional guidance , as necessary , such as forthcoming guidance on how to avoid duplication of services when co - enrolling participants across multiple partner programs .

however , it is important that any additional guidance also specify when to count job seekers as wia participants if they also receive services funded by partner programs .

we also encourage dol to develop additional guidance for the wiasrd variables noted in our report that are open to interpretation , such as “type of training,” to facilitate consistent reporting on participants in these programs .

dol officials also noted that an evaluation of wispr is subject to the agency's resource constraints , adding that the purpose of wispr was never explicitly to improve data quality .

as we stated in our report , however , wispr seeks , in part , to improve the consistency of wia data by standardizing reporting across the workforce system .

as such , it has the potential to improve data quality .

therefore , we encourage dol to evaluate the system in order to make an informed decision on how best to allocate finite agency resources going forward .

in response to our second recommendation , dol officials stated that they consistently share the results of the agency's oversight activities with states but acknowledged that more could be done to analyze the results of its activities to identify and share similar findings and areas of concern across multiple states .

dol officials added that they will work with the regional offices towards this goal .

with regard to the agency's data validation methods , officials said they regularly review these methods and solicit input from states on how to improve them .

specifically , dol pointed out that , as required by the paperwork reduction act , the office of management and budget reviews dol's data validation process every 3 years and solicits public comment before approving the methodology and authorizing data collection , and that their 2014 submission will reflect state input .

however , given the time - consuming nature of data validation , we believe the agency should take additional actions to review its current methods specifically with an eye toward making them more efficient and holding states accountable for their data validation results .

with regard to evaluating the effectiveness of its data validation efforts , dol officials said that the agency plans to consider the regional data validation workgroup's findings and recommendations from 2011 , explore ways to streamline the process , and examine the effect of data validation on error rates .

we commend dol's plans , but to adequately address the persistently high data error rates we found in our analysis , we believe it is necessary to go beyond evaluating the effectiveness of its data validation efforts and pinpoint the underlying cause of the errors so that they can be addressed .

officials also pointed out that the agency already monitors and shares the analyses of state data conducted by its contractor , social policy research associates ( spra ) .

they stated that spra's corrections of states' data have been publicly available with the data set from the inception of wia .

they also noted that since program year 2011 dol has provided spra's analyses and corrections to the states ( through eta regional offices ) on a quarterly basis for states to either correct or dispute .

they noted that this is a formal and recurring process , and that eta regional offices have begun to analyze state date wiasrd data on a regular basis as part of their annual review cycles .

however , we found that not all states are aware of or receive copies of spra's reports , and that some of the corrections spra makes to the state wiasrd data files may not be accurate .

furthermore , as noted in our report , dol officials told us that they do not conduct formal oversight reviews or audits of spra's data analyses .

in addition , dol officials reiterated that data collection and reporting are topics that are included in workforce3one , a point we noted in our report .

however , we maintain that dol could do more to facilitate the sharing of information across states , such as creating a forum through which states could learn how their peers are addressing challenges in data reporting for participants in the wia programs .

finally , dol provided technical comments , which we incorporated , as appropriate .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the appropriate congressional committees , the secretary of labor , and other interested parties .

in addition , the report will be available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions concerning this report , please contact me at ( 202 ) 512-7215 or moranr@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix iv .

our objectives were to determine: ( 1 ) what factors have affected the ability to report consistent and complete data on participants in the workforce investment act ( wia ) adult and dislocated worker programs , and ( 2 ) what actions has the department of labor ( dol ) taken to improve the quality of participant data .

to address our objectives , we reviewed applicable laws and regulations , as well as dol's guidance to states for collecting and reporting data on participants in the wia adult and dislocated worker programs .

we also interviewed officials from dol's employment and training administration , its office of inspector general , and its six regional offices .

in addition , we visited or telephoned a nongeneralizable sample of eight states .

within each state , we visited or contacted at least one american job center — formerly known as a one - stop center — or a local workforce board .

we also assessed the reliability of program year 2011 data from the workforce investment act standardized record data ( wiasrd ) system by testing the data electronically and interviewing knowledgeable agency officials and dol's data contractor .

we found the data in appendix ii to be sufficiently reliable for the purposes of providing estimates of the number of , characteristics of , and services provided to participants whose information is recorded by dol as having received services from either the wia adult program or the wia dislocated worker program .

the data are not reliable for other purposes , such as making state - to - state comparisons , because of variations in how states collect and report data on participants in the wia adult and dislocated worker programs .

we conducted these interviews between september 2012 and june 2013. with dol officials in regions 1 ( boston ) , 3 ( atlanta ) , and 5 ( chicago ) ; state and local workforce officials in california , georgia , illinois , massachusetts , and washington ; and american job center officials in maryland .

we conducted telephone interviews with dol officials in regions 2 ( philadelphia ) , 4 ( dallas ) , and 6 ( sacramento ) , and with state workforce officials in maryland , south dakota , and utah .

we nonstatistically selected these states to provide diversity on the basis of: ( 1 ) geographic location , ( 2 ) total federal spending on the adult and dislocated worker programs in program year 2010 , ( 3 ) the extent of data issues identified in the fourth quarter of program year 2010 , ( 4 ) whether the state reported participants who only received core self - services , and ( 5 ) the number of local areas within the state .

in each state , we obtained general information about the state's and the local area's implementation of the wia adult and dislocated worker programs and on any challenges they may have encountered in collecting and reporting data on program participants .

we also asked about actions dol has taken to improve the quality of the data on participants in the wia adult and dislocated worker programs .

we used semi - structured interviews for our regional , state , and local interviews .

because we interviewed officials from a nongeneralizable sample of eight states and selected local areas , we cannot generalize our findings beyond the data collected on those states and local areas .

to assess the reliability of dol's data in the wiasrd database for participants in the wia adult and dislocated worker programs , we ( 1 ) reviewed existing documentation related to the data sources , including reports issued by dol's office of inspector general ; ( 2 ) electronically tested the wiasrd data to identify potential problems with consistency , completeness , or accuracy ; and ( 3 ) interviewed dol's data contractor and knowledgeable agency officials to obtain information about the data .

our electronic testing consisted of identifying inconsistencies , outliers , missing values , and other errors .

more specifically , the electronic testing included assessing the reliability of data collected on the characteristics and the services participants in the wia adult and dislocated worker programs received in program year 2011 .

prior to testing the data , we combined 160 records that were overlapping or duplicative into 80 unique records and removed 19 records that had missing or erroneous participation dates .

a few variables , including data on a participant's dislocation date — the date a worker lost his or her job , and the occupational codes for participants who completed training , were found to not be sufficiently reliable for our purposes and were not included in our report .

in addition , we analyzed the publicly available wiasrd data file for program year 2011 , which was produced for dol by its data contractor , social policy research associates .

as part of our analysis , we reviewed the steps the data contractor took to correct the data and , to the extent possible , compared our data to the publicly available file .

in light of variations in how states collect and report participant data for the wia adult and dislocated worker programs and limitations in their information systems , the actual number of participants in these programs is unknown .

however , we were able to estimate the number of , characteristics of , and services provided to participants whose information is recorded by dol as having been served by the wia adult and dislocated worker programs using wiasrd data from program year 2011 .

to describe and assess dol's oversight and monitoring efforts , we reviewed technical assistance guides and material posted to workforce3one , including dol's core monitoring guides and data validation reporting system guidance .

we also interviewed officials from dol's employment and training administration national office and from all of dol's six regional offices .

in addition , we obtained and reviewed copies of dol's monitoring reports , including the results of dol's program year 2010 and 2011 annual data validation efforts and the most recent case file review for each state and territory .

to analyze the results of the annual data validation efforts , we calculated the average reported error rate for each variable across states .

we included in our analysis all variables on characteristics and services .

to analyze trends in the results of the case file reviews , we reviewed the findings and areas of concern identified in each review and categorized them to identify common issues present in multiple states .

we conducted this performance audit from august 2012 through november 2013 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit work to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

we reviewed the data collected by the department of labor ( dol ) in the workforce investment act standardized record data ( wiasrd ) system on the number of , characteristics of , and services provided to participants in the wia adult and dislocated worker programs in program year 2011 .

we found the data to be sufficiently reliable for the purposes of providing estimates of the number of , characteristics of , and services provided to , participants whose information is recorded by dol in wiasrd .

these estimates are presented in figures 4 through 9 .

in addition to the contact named above , meeta engle , assistant director ; theodore alexander ; jenn mcdonald ; and brian schwartz made key contributions to this report .

also contributing to this report were jessica botsford , david chrisinger , kathy leslie , mimi nguyen , carol patey , rhiannon patterson , catherine roark , jerry sandau , walter vance , and charles youman .

workforce investment act: local areas face challenges helping employers fill some types of skilled jobs .

gao - 14-19 .

washington d.c.: december , 2013 .

workforce investment act: additional actions would further improve the workforce system .

gao - 07-105it .

washington , d.c.: june 28 , 2007 .

workforce investment act: employers found one - stop centers useful in hiring low - skilled workers ; performance information could help gauge employer involvement .

gao - 07-167 .

washington , d.c.: december 22 , 2006 .

workforce investment act: labor and states have taken actions to improve data quality , but additional steps are needed , gao - 06-82 .

washington , d.c.: nov. 14 , 2005 .

workforce investment act: labor should consider alternative approaches to implement new performance and reporting requirements .

gao - 05-539 .

washington , d.c.: may 27 , 2005 .

workforce investment act: substantial funds are used for training , but little is known nationally about training outcomes .

gao - 05-650 .

washington , d.c.: june 29 , 2005 .

workforce investment act: labor actions can help states improve quality of performance outcome data and delivery of youth services .

gao - 04-308 .

washington , d.c.: february 23 , 2004 .

workforce investment act: states and local areas have developed strategies to assess performance , but labor could do more to help .

gao - 04-657 .

washington , d.c.: june 1 , 2004 .

workforce investment act: improvements needed in performance measures to provide a more accurate picture of wia's effectiveness .

gao - 02-275 .

washington , d.c.: february 1 , 2002 .

