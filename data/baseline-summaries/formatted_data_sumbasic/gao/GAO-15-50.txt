the department of veterans affairs' ( va ) disability compensation program provides cash benefits to veterans for disabling conditions incurred or aggravated while in military service .

in fiscal year 2013 , va paid $53.6 billion in disability compensation to 3.6 million veterans .

within va , the veterans benefits administration ( vba ) , which is charged with processing disability compensation claims , faces a backlog of claims , due in part to the recent wars in iraq and afghanistan and the increasing number of servicemembers leaving the military .

at the same time , vba set a goal of achieving 98 percent accuracy in fiscal year 2015 for compensation claim decisions , which are made by staff in 57 vba regional offices .

accurate claim decisions can help ensure that vba is paying disability benefits only to those entitled to such benefits , in the correct amounts .

meanwhile , consistent decisions help ensure that veterans' claims receive comparable treatment , regardless of which vba adjudicator or regional office processes the claim .

questions have been raised about recent changes in the calculation of vba's national accuracy rate , which is based on its national systematic technical accuracy review ( star ) , and whether such changes reflect reliable measures of accuracy and vba's commitment to serving veterans .

gao and va's office of inspector general ( oig ) have also previously reported on shortcomings in vba's quality assurance activities .

this report examines ( 1 ) the extent to which vba effectively measures and reports the accuracy of compensation claim decision - making , and ( 2 ) whether vba's other quality assurance activities are coordinated and effective .

to determine the extent to which vba effectively measures the accuracy of compensation claim decisions , we reviewed star guidance , reports , and data and interviewed cognizant staff .

we assessed vba's sampling methodology and analyzed star and other vba data on claims processed and reviewed from october 2012 through september 2013 .

we focused on the star process for reviewing disability compensation claims that were evaluated by vba .

we did not review quality assurance efforts involving pension claims or appealed cases .

to assess how vba reports accuracy , we reviewed relevant vba performance reports and compared vba practices with legal requirements for agency performance reporting and related gao work .

to determine whether vba's quality assurance activities are coordinated and effective , we reviewed vba quality assurance policies , reports and guidance to identify key quality assurance activities , and then examined each activity's function and process by reviewing relevant guidance and policy documents and interviewing central office officials .

we also interviewed vba officials from four regional offices to gain their perspectives on how quality assurance activities are implemented at the regional office level , as well as how information is shared among quality assurance activities.vba's quality assurance activities against its internal guidance and we compared standards for internal control in the federal government.reviewed vba's methods for designing and implementing its consistency studies against generally accepted practices in survey and questionnaire development .

we assessed the reliability of vba data used for all our analyses and determined that they were sufficiently reliable for the purposes of providing information on trends in claims decisions .

for additional details on our objectives , scope , and methodology , see appendix i .

we conducted this performance audit from september 2013 to november 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

va pays monthly disability compensation to veterans with service - connected disabilities ( i.e. , injuries or diseases incurred or aggravated while on active military duty ) according to the severity of the disability .

vba staff in 57 regional offices process disability compensation claims.these claims processors include veterans service representatives ( vsr ) who gather evidence needed to determine entitlement , and rating veterans service representatives ( rvsr ) who decide entitlement and the rating percentage .

veterans may claim more than one medical condition , and a rating percentage is assigned for each claimed medical condition , as well as for the claim overall.decided more than 1 million compensation claims .

in fiscal year 2013 , vba since fiscal year 1999 , vba has used star to measure the decisional accuracy of disability compensation claims .

through the star process , vba reviews a stratified random sample of completed claims , and certified reviewers use a checklist to assess specific aspects of each claim .

are randomly sampled each month and the data are used to produce estimates of the accuracy of all completed claims .

va reports national estimates of accuracy from its star reviews to congress and the public through its annual performance and accountability report and annual budget submission .

vba also produces regional office accuracy estimates , which it uses to manage the program .

regional office and national accuracy rates are reported in a publicly available performance database , the aspire dashboard .

the star review has two major components .

the benefit entitlement review assesses whether the correct steps were followed in addressing all issues in the claim , collecting appropriate evidence , and whether the resulting decision was correct , including effective dates and payment rates .

accuracy performance measures are calculated based on the results of the benefit entitlement review .

the star review also assesses whether claims processors appropriately documented the decision and notified claimants .

new issue - based measure .

by comparison , under the existing claim - based measure , the claim would be counted as 0 percent accurate unless the error did not affect benefits when considered in the context of the whole claim .

in march 2014 , vba reported a national estimate of issue - based accuracy in its fiscal year 2015 annual budget submission and plans to update this estimate in va's next performance and accountability report .

vba also produces issue - based estimates by regional office , and reports them in the aspire dashboard .

for fiscal year 2013 , the regional office claim - based accuracy rates ranged from an estimated 78.4 to 96.8 percent , and the issue - based accuracy rates ranged from an estimated 87.0 to 98.7 percent .

beyond star , vba has programs for conducting regional office quality reviews and for measuring the consistency of decisions .

in march 2012 , vba established quality review teams ( qrt ) with one at each regional office .

a qrt conducts individual quality reviews of claims processors' work for performance assessment purposes .

the qrt also conducts in - process reviews before claims are finalized to help prevent inaccurate decisions by identifying specific types of common errors .

such reviews also serve as learning experiences for staff members .

since fiscal year 2008 , vba has also conducted studies to assess the consistency of disability claims decisions across regional offices .

initially , this initiative used inter - rater reliability ( irr ) studies to assess the extent to which a cross - section of claims processors from all regional offices agree on an eligibility determination when reviewing the entire body of evidence from the same claim .

in 2013 , vba revised its approach and began using questionnaires as its primary means for assessing consistency .

a questionnaire includes a brief scenario on a specific medical condition for which claims processors must correctly answer several multiple - choice questions .

when calculating accuracy rates , vba does not always follow generally accepted statistical practices .

for example , vba does not weight the results of its star reviews to reflect its approach to selecting claims by regional office , which can affect the accuracy of estimates .

according to our analysis of vba data , weighting would have resulted in a small change to vba's nationwide claim - based accuracy rate for fiscal year 2013 — from 89.5 to 89.1 percent .

at the regional level , 29 of the 57 offices would have experienced a somewhat greater increase or decrease in their accuracy rates .

without taking weighting into consideration , regional office accuracy performance may be misleading and vba management may focus corrective action or positive recognition on the wrong offices .

for example , by taking weighting into account for the 57 regional offices in fiscal year 2013 , the reno regional office would have improved in relative accuracy by 12 places ( from 34th to 22nd place ) , whereas the los angeles office would have declined in relative accuracy by 10 places ( from 46th to 56th place ) ( see fig .

1 ) .

vba also does not calculate the confidence intervals associated with the accuracy estimates that it generates , which prevents a complete understanding of trends over time and comparisons among offices .

accuracy estimates for different regional offices , or for the same office over time , are considered statistically different from each other when their confidence intervals do not overlap .

as such , meaningful comparisons could be made on the basis of our analysis between , for example , fort harrison's estimated claim - based accuracy rate ( ranked #1 ) and new york's estimated claim - based accuracy rate ( ranked #36 ) because their confidence intervals did not overlap in fiscal year 2013 ( see fig .

2 ) .

conversely , comparisons between fort harrison's and milwaukee's or pittsburgh's estimated claim - based accuracy rates ( ranked #2 and #35 respectively ) — which had overlapping confidence intervals in fiscal year 2013 — require a statistical test to determine if their differences are statistically meaningful .

in effect , the claim - based accuracy rate of fort harrison and those of the regional offices with the next 34 highest reported accuracy rates may not be meaningfully different despite being ranked 1 through 35 of 57 .

similarly , according to agency officials , vba also does not calculate the confidence intervals associated with its newer issue - based accuracy estimates , which prevents meaningful comparisons between those estimates as well .

because vba produces issue - based estimates using the same sample drawn to produce claim - based estimates , it would have to take extra steps to calculate the associated confidence intervals.computing the confidence intervals associated with issue - based as with the claim - based accuracy estimates , not estimates limits vba's ability to monitor its regional offices' relative performance and its overall performance over time .

vba's approach to measuring accuracy is also inefficient because it reviews more claims than are statistically required to estimate accuracy .

vba randomly selects about 21 claims per month from each of its regional offices for star review , regardless of the offices' varying workloads and historical accuracy rates .

according to vba , this uniform approach allows the agency to achieve a desired level of precision of its accuracy estimates for each regional office .

however , accepted statistical practices would allow for fewer cases to be reviewed at regional offices where the number of claims processed has been relatively small or accuracy has been high .

according to our analysis of fiscal year 2013 regional office workload and accuracy results , vba could reduce the overall number of claims it reviews annually by about 39 percent ( over 5,000 claims ) and still achieve its desired precision for its regional office accuracy estimates .

more efficient sampling could allow vba to select fewer cases for review and free up limited resources for other important quality assurance activities , such as additional targeted accuracy reviews on specific types of error - prone or complex claims .

specifically , reviewing about 5,000 fewer claims could free up about 1,000 staff days because , according to vba officials , star staff review at least 5 claims per day .

calculating weighted estimates and confidence intervals , and adjusting sampling according to shifting workloads and accuracy rates , requires use of statistical methodology .

according to vba officials we interviewed , although star management used a statistician to help develop the way in which they measure accuracy , it currently does not use a statistician to , for example , weight star results and calculate confidence intervals for accuracy estimates .

further , vba officials said they did not consult a statistician when developing the new issue - based accuracy measure , but rather relied on the same sampling methodology and approach for estimating accuracy as for the claim - based measure .

we have previously reported that to be useful , performance information must meet users' needs for completeness , accuracy , consistency , and validity , among other factors .

in response to our draft july 2014 testimony based on preliminary work , vba officials stated they are exploring alternatives to their current methodology for estimating accuracy .

beyond not following generally accepted statistical practices , vba's star review systematically excludes certain claims , which may inflate accuracy rate estimates .

specifically , according to vba officials , when a claim moves from one regional office to another , because a veteran has moved or workloads are redistributed , the database vba uses to select claims for star review does not always reflect the office responsible for as a result , star staff making the final determination for the claim .

often select for review , then subsequently de - select , claims that have changed regional office jurisdiction .

of the 14,286 rating claims randomly selected initially by vba for review in fiscal year 2013 , about 10 percent were de - selected because of a change in jurisdiction and replaced with other randomly selected claims .

those de - selected claims are not eligible for star review for the regional office that was ultimately responsible for the claim , thereby causing an underrepresentation of these claims in the star sample .

such underrepresentation may inflate vba's reported accuracy rate because redistributed claims have historically had lower accuracy rates than non - redistributed claims .

in responding to our draft report , vba indicated it is revising its procedures to ensure that claims selected for star review are included in the accuracy rate of the responsible regional office regardless of whether a change of jurisdiction occurred .

federal agencies should report clear performance information to the congress and the public to ensure that the information is useful for decision making .

in prior work , we identified clarity as a key attribute to a successful performance measure , meaning that the measure is clearly stated and its associated methodology is identified .

measures that lack clarity may confuse or mislead users , and not provide a good picture of how well the agency is performing .

we have also reported on best practices in implementing related federal performance reporting requirements , such as those in the gpra modernization act of 2010 .

specifically , agencies must disclose information about the accuracy and validity of their performance information in their performance plans , including the sources for their data and actions to address any limitations .

vba's accuracy reporting lacks methodological details that would help users understand the distinction between its two accuracy measures and their associated limitations .

while vba's new issue - based measure provides some additional perspective on the quality of claim decisions to date , vba has not fully explained in its public reports how the issue - based and claim - based measures differ .

for example , the issue - based measure tends to be higher than the claim - based measure because the former allows for claims to be considered partially correct , whereas the claim - based measure does not .

according to vba officials , the issue - based estimate provides a better measure of quality because veterans' our analysis claims have increasingly included multiple medical issues.of star data confirms that as the number of issues per claim increases , the chance of at least one issue being decided incorrectly within a single claim increases because there are more opportunities for error ( see fig .

3 ) .

however , va did not report in its fiscal year 2015 budget request how these measures are calculated and why the issue - based measure might be higher than the claim - based measure .

va has also not reported these distinctions in its aspire dashboard .

vba also counts claims processing errors differently under its claim - based measure than it does under its issue - based measure but does not report these distinctions , which raises questions about the transparency and consistency of vba's accuracy measures .

for both measures , vba differentiates between benefit entitlement errors that may financially affect the veteran and other errors , such as documentation and administrative errors that do not financially affect the veteran .

for claim - based accuracy , vba counts errors that financially affect the veteran now , but does not count errors that may financially affect the veteran in the future , although it works to correct both types of errors .

for example , if one of several claimed medical conditions was rated incorrectly ( eg , 10 percent instead of 20 percent ) , but this error did not immediately affect the overall rating of the claim , vba would not consider the claim in error because it did not affect the benefits that the veteran would receive .

for the issue - based accuracy measure , however , vba would count this as an error even if the error did not immediately affect the veteran's benefits .

unlike claim - based accuracy , issue - based accuracy may also include errors that would never affect future payments .

for example , an incorrect effective date that is within the same month as the correct effective date does not affect benefits , but is counted as an error in vba's issue - based accuracy measure .

conversely , according to vba officials , this is not counted as an error in its claim - based measure .

according to our analysis of star data , up to 6.9 percent of reviewed claims in fiscal year 2013 had these types of errors ( i.e. , benefit entitlement errors that do not immediately and may never affect benefits ) , and if they were all counted as errors , vba's unweighted claim - based accuracy rate would have decreased by about 2 percent .

further , va has not explained in public reports that its accuracy measures are estimates that have distinct confidence intervals and limitations .

users should be aware of these confidence intervals to make meaningful comparisons , for example , between the two measures or over time for the same measure .

in terms of each accuracy measure's limitations , the claim - based measure does not provide a sense of the proportion of issues that the agency decides correctly because the measure counts an entire claim as incorrect if any error is found .

on the other hand , the issue - based measure does not provide a sense of the proportion of claims that the agency decides with no errors .

in addition to its star reviews , vba's quality assurance framework includes other complementary activities , which have been enhanced to help meet its goal of 98 percent accuracy in fiscal year 2015 .

specifically , vba ( 1 ) established quality review teams ( qrt ) in march 2012 in regional offices as a means of strengthening its focus on quality where claims are processed , and ( 2 ) enhanced efforts to assess the consistency of decisions .

although regional offices were previously responsible for assessing individual performance , qrts represent a departure from the past because qrt personnel are dedicated primarily to performing these and other local quality reviews .

in addition , vba requires qrt staff to pass a skills certification test annually — similar to vba requirements for star staff and in contrast to requirements for claims processors who must pass a test every 2 years .

in july 2013 , vba issued national guidance to ensure consistent qrt roles and practices across regional offices .

for example , it included guidance on selecting individual quality review claim samples and conducting additional reviews for claims processors who do not meet their accuracy goals .

in addition to conducting individual quality reviews , qrt personnel are charged with conducting in - process reviews of claims that are not yet finalized , looking for specific types of common errors .

quality reviewers are also responsible for providing feedback to claims processors on the results of their quality reviews , typically as reviews are completed , including formal feedback from the results of individual quality reviews and more informal feedback from the results of in - process reviews .

in addition , at the four offices we contacted , quality reviewers are available to answer questions and provide guidance to claims processors as needed .

vba's efforts to assess consistency of claims decisions have also expanded in recent years .

up until 2013 , vba largely relied on inter - rater reliability ( irr ) studies to assess consistency , which to date have been time consuming and resource intensive .

claims processors typically required about 4 hours to review an entire claim .

the process was administered by proctors in the regional offices and the results were hand - graded by national vba staff .

given the resources involved , irr studies have been typically limited to 300-500 ( about 25-30 percent ) claims processors , randomly selected from the regional offices .

in 2009 , vba expanded its consistency program to include questionnaires , which it now relies on more heavily to assess consistency .

the more streamlined consistency questionnaires require less staff time to complete because , in addition to a brief scenario on a specific condition , participants have 10 or fewer multiple - choice questions to answer .

the questionnaires are administered electronically through the va talent management system , removing the need to proctor or hand - grade the tests , which has allowed vba to significantly increase employee participation .

a recent consistency questionnaire was taken by about 3,000 claims processing employees — representing all employees responsible for rating claims .

further , vba now administers these studies more frequently , from about 3 to 24 per year .

according to vba officials , they plan to further expand the use of consistency studies from two questionnaires per month to six to eight per month , pending approval of additional quality assurance staff .

vba also has taken steps to coordinate its quality assurance efforts in several ways , such as systematically disseminating information on national accuracy and consistency results and trends to regional office management and qrts , which in turn share this information with claims processing staff .

with respect to star , in addition to receiving monthly updates on overall accuracy performance , regional offices receive quarterly reports with analyses of accuracy performance including information by error type .

qrt reviewers also participate in monthly conference calls with star staff during which they discuss error trend information .

while claims processing staff learn about errors they made on claims directly from star , managers or qrt members at each of the regional offices we contacted noted that they also share star trend data with claims processors during periodic training focused on star error trends .

with respect to consistency studies , regional offices receive national results ; regional office - specific results ; and , since february 2014 , individual staff results .

officials at each of the four regional offices we visited told us qrt staff share the results of consistency studies with staff and inform claims processors of the correct answers to the questions .

coordination also occurs when qrt personnel disseminate guidance and support regional office training based on error trends identified through star and other quality assurance activities .

two of the four offices we contacted cited instances where they have used consistency study results for training purposes .

at one office , the results from a consistency study were used to provide training on when to request an exam for certain conditions , such as tinnitus .

in general , at each of the four offices , officials told us that qrt reviewers conduct , or work with regional office training coordinators to conduct , periodic training forums for claims processors .

regional offices we contacted also supplement training with other communications informed by quality review results .

for example , qrts at three of the four regional offices we contacted produce periodic newsletters for regional office claims processors , which include guidance based on errors found in all types of reviews .

specifically , at one office , a newsletter was used to disseminate guidance on ensuring that a rating decision addresses all issues in a claim .

the need for this guidance was identified on the basis of star and local quality review results .

lastly , vba coordinates its quality assurance activities by using star results to guide other quality assurance efforts .

according to vba officials , the agency has used star data to identify error trends associated with specific medical issues , which in turn were used to target efforts to assess consistency of decision - making related to those issues .

recent examples are ( 1 ) the august 2013 irr study , which examined rating percentages and effective dates assigned for diabetes mellitus ( including peripheral neuropathy ) ; and ( 2 ) a february 2014 study on obtaining correct disability evaluations on certain musculoskeletal and respiratory conditions .

in addition , according to vba , the focus of in - process reviews performed by qrts has been guided by star error trend data .

vba established in - process reviews in march 2012 to help the qrts identify and prevent claim development errors related to medical examinations and opinions , which it described as the most common error type .

more recently , vba has added two more common error types — incorrect rating percentages and incorrect effective benefit dates — to its in - process review efforts .

vba officials stated that they may add other common error types based on future star error analyses .

while qrts reflect vba's increased focus on quality , during our site visits we identified shortcomings in qrt practices and implementation that could reduce their effectiveness .

specifically , we identified the following shortcomings: ( 1 ) the exclusion of claims processed during overtime to assess individual performance ; ( 2 ) the inability to correct errors identified before a claim is finalized in certain situations ; and ( 3 ) a lack of pre - testing of consistency questionnaires .

regarding the first shortcoming , we learned that three of the four offices we contacted had agreements with their local unions that prevented qrt personnel from reviewing claims processed during overtime to assess individual performance .

as a result , those regional offices were limited in their ability to address issues with the quality of work performed during overtime .

centrally , vba officials did not know which or how many regional offices excluded claims processed during overtime , or the extent to which excluding cases worked during overtime occurred nationally .

according to vba data , claims processed on overtime represented about 10 percent of rating - related claims completed nationally in fiscal year 2013 .

after we reported this finding , vba issued guidance in august 2014 to regional offices stipulating inclusion of claims processed on overtime , and that the regional offices work with their local unions to rescind any agreements that exclude such claims from review .

second , officials at four regional offices we contacted told us that they face a challenge in conducting individual quality and in - process reviews as expected because vba's veterans benefits management system lacks the capability to briefly pause the process and prevent claims from being completed while a review is still underway .

vba officials acknowledged that this was a problem for regional offices in completing reviews , based on anecdotal information from regional offices , but did not have information on the extent to which this occurred .

vba officials noted that reviews could be performed after a claim is completed ; however , if an error is found , the regional office might need to rework the claim and provide the veteran with a revised decision .

the officials also noted that vba is working toward modifying its veterans benefits management system to address this issue , but is at the initial planning stage of gathering requirements and could not provide a time frame for completion .

thirdly , although vba has developed a more streamlined approach to measuring consistency , vba officials told us that consistency questionnaires were developed and implemented without any pre - testing , which would have helped the agency determine whether the test questions were appropriate for field staff and were accurately measuring consistency .

pre - testing is a generally accepted practice in sound questionnaire development for examining the clarity of questions or the validity of the questionnaire results .

in the course of our review , vba quality assurance officials noted that they plan to begin pre - testing consistency questionnaires as a part of a new development process .

specifically , after each questionnaire has been developed , two to three quality assurance staff who have claims processing experience , but were not involved in the questionnaire's development , would be targeted to pre - test it .

quality assurance staff responsible for the consistency studies would then adjust the questionnaire if necessary before it is administered widely .

while initially slated to occur in july 2014 , vba quality assurance staff now anticipate pre - testing to begin in september 2014 .

beyond these implementation shortcomings , staff in each of the four offices we contacted said that several key supports were not sufficiently updated to help quality review staff and claims processors do their jobs efficiently and effectively .

staff at these offices consistently described persistent problems with central guidance , training , and data systems .

guidance: federal internal control standards highlight the need for pertinent information being captured and distributed in a form that allows people to perform their duties efficiently .

however , regional office quality review staff said they face challenges locating the most current guidance among all of the information they are provided .

managers or staff at each of the regional offices we contacted said that vba's policy manuals are outdated .

as a result , staff must search numerous sources of guidance to locate current policy , which is time - consuming and difficult .

this , in turn , could affect the accuracy with which they decide claims .

one office established a spreadsheet to consolidate guidance because the sources were not readily available to claims processors .

vba officials acknowledged that there are several ways it provides guidance to regional offices .

in addition to the existence of relevant regulations and vba's policy and procedures manual , vba provides guidance to claims processors through policy and procedures letters , monthly quality calls and notes from these calls , various bulletins , and training letters and other materials maintained on vba's intranet site .

while agreeing that having multiple sources of guidance could be confusing to staff , vba officials noted they face challenges in updating the policy manual and other available guidance materials to ensure that they are as current as possible .

after we reported on this issue , vba officials noted that they are considering streamlining the types of guidance provided .

they also plan to develop a system of consolidated links to guidance documents by alphabetized topic to help claims processors access the information more efficiently ; however , vba officials acknowledge that developing a single repository will be a challenging project and have not yet dedicated adequate resources for this effort .

training: staff in the offices we contacted also said that in some cases national training has not been updated to reflect the most current guidance , which in turn makes it difficult to provide claims processors with the information they need to avoid future errors .

for example , staff from one regional office noted that training modules on an error - prone issue — individual unemployability and related effective dates of benefits — had not been updated to reflect all new guidance , the sources of which included conference calls , guidance letters , and frequently asked questions compiled by vba's central office .

further , officials at regional offices we contacted expressed concern that vba limits their flexibility to update out - of - date course materials .

in response to these concerns , vba training officials explained that that they are continually updating national training to reflect new guidance , but how long it takes is a function of the extent of the policy change .

these officials noted that updating the individual unemployability training was particularly delayed because of numerous , unanticipated changes in policy and related guidance that resulted in their setting aside previously updated course materials and starting over .

vba training officials also explained that while vba does not allow changes to the contents of courses in its catalog , regional offices can propose courses for the catalog , based on their needs identified through quality reviews .

data systems: regional office quality review staff also told us that they are required to log errors into three systems or databases that do not “speak to one another” and two lack the capability to fully track errors trends , thereby limiting their ability to take corrective actions .

at the regional office level , quality assurance information is entered into three different databases or systems .

staff at each of the four offices we contacted said that the automated standardized performance elements nationwide system used for tracking individual accuracy for performance management purposes lacks functionality to create reports on error trends by claimed medical issue or reasons for specific types of errors .

as a result , three offices maintain separate spreadsheets to identify error trends related to individual accuracy .

regional office staff also noted that one of the two systems used to track in - process reviews does not help track error trends , for example , by employee , resulting in two offices maintaining additional spreadsheets to track this information .

at the national level , vba central office has made some improvements in reporting and now has the ability to analyze regional office information on errors by medical issue .

according to vba officials , they share this information with regional office managers and quality staff during training calls .

vba officials stated that a planned replacement for its automated standardized performance elements nationwide system would have addressed reporting limitations at the local level , but was halted .

as of september 2014 , vba did not have a timeframe for restarting the process for acquiring a new system .

finally , vba's efforts to evaluate the effectiveness of its quality assurance activities have been limited .

specifically , vba officials told us that although they have not seen an increase in the national accuracy rate in fiscal year 2014 , the number of errors related to claim development has declined , demonstrating the success of qrt reviews and training in targeting these errors .

also , vba identified 13 regional offices whose issue - based accuracy rates improved between the first and third quarters of fiscal year 2014 , attributing these improvements to actions taken by however , it was not clear quality assurance staff in fiscal year 2014.from the documentation vba provided whether and how it monitored the effectiveness of these actions for all regional offices .

with respect to consistency studies , vba also has not evaluated — and lacks plans to evaluate — the efficacy of using consistency questionnaires relative to the more resource - intensive irr studies .

according to a vba official , the consistency questionnaires have helped identify regional offices and individuals in need of further training on the basis of the percentage of incorrect answers , as well as the need for national training .

however , officials could not provide data or evaluations indicating that consistency questionnaires have improved accuracy rates in the areas studied .

vba officials noted that they are considering a new data system that would combine all local and national quality assurance data — including star , in - process reviews , and individual quality reviews — and allow for more robust analyses of root causes of errors .

specifically , they expect the system will show relationships across the results of various quality assurance reviews to determine employee competence with various aspects of claims processing .

according to vba officials , this system would also enable them to more easily evaluate the effectiveness of specific quality assurance efforts .

evaluation can help to determine the “value added” of the expenditure of federal resources or to learn how to improve performance — or both .

it can also play a key role in strategic planning and in program management , informing both program design and execution .

continuous monitoring also helps to ensure that progress is sustained over time .

however , vba officials indicated that this proposal is still in the conceptual phase and requires final approval for funding and resources .

vba's dual approach for measuring accuracy is designed to provide additional information to better target quality improvement efforts , but its methods and practices lack rigor and transparency , thereby undermining the usefulness and credibility of its measures .

by not leveraging a statistician or otherwise following statistical practices in developing accuracy estimates , vba is producing and relying on inaccurate estimates to make important internal management decisions .

similarly , by using a one - size sampling methodology , vba is unnecessarily expending limited resources that could be used elsewhere .

the systematic exclusion of redistributed claims and those moved between offices further calls into question the rigor of its accuracy estimates .

lastly , vba's reporting of its two accuracy metrics lacks sufficient transparency to help members of congress and other stakeholders fully understand the differences and limitations of each , and thus may undermine their trust in vba's reported performance .

vba has enhanced and coordinated other aspects of its quality assurance framework , but shortcomings in implementation and evaluation detract from their overall effectiveness .

for example , although vba is disseminating the results of national star reviews and consistency studies , and local qrts are using those results to focus related training or guidance to claims processing staff , until centralized guidance is consolidated and streamlined , staff lack ready access to information that will help them prevent errors .

moreover , absent adequate system capabilities to support local quality reviews , qrts are unable to stop incorrect decisions from being finalized , and may not be aware of error trends that could be mitigated through training or other corrective action .

finally , although some of its quality assurance activities are relatively new , vba lacks specific plans to evaluate their effectiveness and may miss opportunities to further improve or target these activities to more error - prone areas .

in general , unless vba takes steps to improve the rigor of all its quality assurance methods and practices , vba may find progress toward achieving its goal of 98 percent accuracy in fiscal year 2015 illusive — especially in the face of challenging workloads , limited resources , and expectations of timely claim decisions .

to help improve the quality of vba's disability compensation claim decisions , we recommend that the secretary of veterans affairs direct the under secretary for benefits to: leverage appropriate expertise to help vba do each of the following: weight its accuracy estimates to reflect the sample design for determine and report the confidence intervals associated with its reported accuracy estimates ; and re - examine its approach to calculating the regional office sample size for star .

take steps to ensure that redistributed claims and those moved between regional offices are not underrepresented in the star sample .

increase transparency in explaining how the claim - based and issue - based accuracy rates are calculated as well as their key limitations when publicly reporting these metrics .

review the multiple sources of policy guidance vba provides to determine ways to consolidate them or otherwise improve their availability and accessibility for use by staff in regional offices .

take steps to ensure that any future upgrades to local data systems allow qrts to pause the claims process when errors are detected and enable qrts to better track error trends .

take additional steps to evaluate the effectiveness of quality assurance activities to identify opportunities to improve or better target these activities .

we provided a draft of this report to va for review and comment , and its written comments are reproduced as appendix iii in this report .

va generally agreed with our conclusions and concurred with all of our recommendations .

the agency outlined how it plans to address our recommendations as follows: regarding our recommendations to leverage appropriate expertise to improve its measurement and reporting of accuracy , va stated that a vba statistician has begun developing a revised sampling methodology that takes into consideration output and claims processing accuracy at each regional office to determine sample sizes .

vba also plans to appropriately weight accuracy estimates and calculate the margins of error based on the revised sampling methodology .

vba intends to report results based on this new methodology beginning in march 2015 .

regarding our recommendation to take steps to ensure that redistributed claims and those moved between regional offices are not underrepresented in the star sample , va stated that vba's revised sampling methodology will be based on the office completing the claim , and that no claims will be excluded from samples due to changes in jurisdiction .

vba intends to implement this revised sampling methodology by the end of march 2015 .

regarding our recommendation to increase transparency in explaining how the claim - based and issue - based accuracy rates are calculated , va stated that vba will describe its sampling , assessment criteria , calculation , and reporting methodologies for claim and issue - level accuracy as part of future performance documents and public reports .

vba anticipates implementing this recommendation by the end of march 2015 .

regarding our recommendation to review the multiple sources of policy guidance vba provides to regional office staff , va stated that in september 2014 , vba began improving the availability and accessibility of policy guidance , as well as consolidating references to this guidance .

vba anticipates completing this project by the end of april 2015 .

regarding our recommendation to take steps to ensure that any future upgrades to local data systems allow qrts to pause the claims process when errors are detected and enable qrts to better track error trends , va stated that vba is designing a new database that will incorporate all types of quality reviews ( i.e. , regional office reviews , star , and consistency studies ) and provide vba with more data analysis capabilities .

although va did not outline specific steps vba plans to take to upgrade local data systems so that qrts may pause the claims process , vba plans to implement this recommendation by the end of june 2015 .

regarding our recommendation to take additional steps to evaluate the effectiveness of quality assurance activities to identify opportunities to improve or better target these activities , va stated that vba's new database will enable vba to do so by the end of june 2015 .

va also provided technical comments , which we incorporated as appropriate .

we are sending copies of this report to the appropriate congressional committees and the secretary of veterans affairs .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-7215 or bertonid@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix iv .

the objectives of this report were to examine ( 1 ) the extent to which the veterans benefits administration ( vba ) effectively measures and reports the accuracy of compensation claim decision - making , and ( 2 ) whether vba's other quality assurance activities are coordinated and effective .

to assess vba's measurement and reporting of the accuracy of compensation claim decision - making , we focused on the star process for reviewing disability compensation claims that vba identifies as rating - related — that is , requiring a decision on the claimant's eligibility for benefits and the monthly benefit amount .

we did not review quality assurance over disability compensation claims that did not involve a rating , including adjustments for additional dependents .

we also did not review quality assurance efforts involving appealed cases , aspects of which fall under the board of veterans' appeals .

finally , we did not review pension claims , which represent a small portion of vba's disability benefits workload , because vba is reviewing its approach to the accuracy assessment of pension claims .

to determine the extent to which star appropriately reflects the accuracy of claims , we reviewed vba policy manuals , the star checklist , and other tools used in vba's star review .

we interviewed vba and office of inspector general ( oig ) officials to learn whether there are claim types that are omitted from star review and , if so , the reasons for these omissions .

to determine how errors are identified and counted under star , we examined the ways in which the checklist and other star procedures are used to quantify errors .

we visited vba's office in nashville , tennessee , where the star reviews are conducted to observe the review process and program methodology in action .

we reviewed checklists used to assess accuracy of claims and identified information vba uses on the basis of these checklists to calculate accuracy rates .

to assess the extent to which vba uses generally accepted statistical practices to generate accuracy rates , we analyzed vba data on claims processed and reviewed from october 2012 through september 2013 .

in analyzing star data , we calculated the weighted claim - based annual accuracy rate for each regional office and nationwide .

we then calculated the 95 percent confidence intervals associated with these estimated accuracy rates .

we applied a statistical sample size formula suitable for use in a stratified random sample and analyzed the differences this approach produced compared to vba's sample size estimation methodology for regional offices .

we assessed the reliability of vba's star data by performing electronic data testing , reviewing related documentation , and interviewing knowledgeable agency officials .

we also assessed the reliability of vba's claim processing data by interviewing knowledgeable agency officials about the data .

to electronically assess the reliability of the star data , we tested for duplicate benefit records , tested the claim disposition date field to ensure we only analyzed star claims from fiscal year 2013 , checked the benefit claim end product code to ensure we only included benefit claims with end product codes eligible for inclusion in the star accuracy sample , checked for missing data in key analysis variables , and examined the range of values in key variables to check for outliers .

we determined that the data were sufficiently reliable for our purposes .

to assess how vba reports accuracy , we identified and reviewed relevant vba performance reports , such as va's performance and accountability report and aspire dashboard data .

we also interviewed vba officials about the rationale for creating the issue - based accuracy measure , and the agency's plans for reporting its performance on accuracy and consistency .

we compared vba practices with legal requirements for agency performance reporting such as the gpra modernization act of 2010 and related gao work ( eg , gao , managing for results: gpra modernization act implementation provides important opportunities to address government challenges , gao - 11-617t , washington , d.c.: may 10 , 2011 ) .

to determine whether vba's quality assurance activities are coordinated and effective , we reviewed vba quality assurance policies , reports , and guidance to identify key quality assurance activities .

based on this review , we focused on quality review teams ( qrt ) , which are located in each regional office and responsible for local quality assurance , as well as on vba's consistency program that is administered by vba's centralized quality assurance staff .

we then examined each activity's function and process by reviewing relevant guidance and policy documents and interviewing central office officials .

specifically: we reviewed vba policy and procedure documents for quality review teams ( qrt ) to learn the purposes of , and the information generated by , these efforts .

in addition , we interviewed vba central office and regional office officials to gather their perspectives on any redundancy or gaps between quality assurance efforts .

we compared the functions of and information yielded by quality assurance components with the framework laid out in vba's quality assurance program plan , as well as standards for internal control in the federal government ( see gao , standards for internal control in the federal government , gao / aimd - 00-21.3.1 , washington , d.c. : november 1999 ) .

in addition , we interviewed vba regional office officials to learn about processes qrts follow and how these procedures may vary across regional offices .

we also reviewed and compared vba criteria for qrt staff , star reviewer , and claims processor certification .

we reviewed documents and interviewed vba officials to learn more about the recent changes to the agency's approach to assessing consistency .

more specifically , we explored the rationale for the change from using inter - rater reliability ( irr ) studies to using consistency questionnaires .

we assessed the development and implementation of the recent consistency questionnaires by , for example , examining vba's consideration of pre - testing the instruments using generally accepted survey procedures , and how pre - testing may affect the resulting measures of consistency .

finally , to further determine how consistency questionnaires are complementary with other quality assurance efforts , we reviewed vba's process for determining topics for consistency questionnaires .

specifically , we asked about the methods used to select and prioritize topics , including the extent to which officials use findings from qrts and star .

to further determine what and how information is shared among quality assurance components and how this coordination helps to identify problem areas , we interviewed vba regional office officials to gather their perspectives on how information is shared from star , qrt , consistency studies , and regional office compliance visits and how that information - sharing could be improved .

we interviewed officials at the regional level to gain their perspectives on coordination and effectiveness of all of vba's quality assurance activities .

at each office , we spoke with service center managers and quality assurance staff , as well as representatives of local veteran service organizations .

the regional offices were selected to reflect a range of characteristics related to: ( 1 ) geography ( at least one regional office in each of va's four areas ) , ( 2 ) number of claims processed annually , ( 3 ) claim - based accuracy rates , and ( 4 ) issue - based accuracy rates .

we did not identify specific quality assurance pilots or initiatives being tested in regional offices .

we selected 4 of vba's 57 regional offices for review .

we visited the oakland and newark regional offices and conducted telephone interviews with nashville and waco regional office staff .

table 1 provides information about the regional offices we selected to visit .

this appendix provides additional technical details on ratio estimation for producing issue - based accuracy rates , as well as the audit work we did to re - estimate the regional office systematic technical accuracy review ( star ) sample sizes using a formula for stratified random probability samples .

because star is designed to sample claims and produce an estimate of the claim - based accuracy rate and because the number of medical issues per claim varies , ratio estimation should be used to develop issue - based accuracy rates .

furthermore , during their review of sampled claims , star reviewers may find that one or more inferred issues were missed or , conversely , that the review process included one or more issues inappropriately .

thus , the star sample of claims must be used to estimate both the total number of issues as well as the number of issues that were processed correctly .

with respect to star , ratio estimation takes the form shown below .

in the formula , the subscript i represents the regional office , the subscript j represents the month of the fiscal year , jin , represents the monthly sample size for regional office i in month j , jiw , represents the stratum sampling weight for regional office i in month j , kjia , number of issues adjudicated correctly on claim k in month j and regional office i and represents the total number of issues on claim k in kjim , month j and regional office i .

the ability to calculate a ratio estimate and its associated confidence interval are available in most statistical software applications .

each month the veterans benefits administration ( vba ) selects a random sample of benefit claims within each va regional office to review under the star program .

the measure of interest is the estimated percent of claims that were processed correctly by vba regional office staff .

the sample size formula used by vba to derive the number of claims to select in each vba regional office is shown below .

in the formula , z = the quantile from the normal distribution for the desired level of confidence .

the desired margin of sampling error is denoted by e. the assumed percent of accuracy in the population is denoted by p , and q is defined as q = ( 1 – p ) .

for their calculations , vba uses the following values: .

when these values are plugged into the equation , n = 246 .

this is vba's target annual sample size for each va regional office .

with 57 regional offices , this translates into 14,022 claims selected nationally per fiscal year in the star sample .

on a monthly basis , when divided by 12 , 246 / 12 = 20.5 which rounds up to 21 .

thus , vba's monthly sample size for each regional office is 21 claims .

by definition , the sample frame for each month is the set of veteran benefit claims completed by the regional office within the previous month .

the standard statistical formula for the sample size calculation with a stratified random sample is shown below .

we applied this formula to determine an annual total sample size for a regional office in the coming fiscal year using observed monthly accuracy rates and monthly number of claims completed from the previous fiscal year .

 .

in turn , this initial sample size is adjusted with the finite population correction factor .

the formula for the adjusted sample size is shown below .

in addition to the contact named above , michele grgich ( assistant director ) , dana hopings ( analyst - in - charge ) , carl barden , james bennett , david chrisinger , alexander galuten , joel green , avani locke , vernette shaw , almeta spencer , walter vance , and greg whitney made key contributions to this report .

