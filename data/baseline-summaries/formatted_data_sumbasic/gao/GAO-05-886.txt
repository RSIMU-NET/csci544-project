between 2002 and 2012 an estimated 850,000 jobs will open in the construction industry , but experts predict that there will not be enough skilled workers to fill them .

the national registered apprenticeships system , administered by the office of apprenticeship training , employer and labor services ( oatels ) within the department of labor , has an important role in the development of this skilled workforce .

with a budget of $21 million , oatels promulgates standards to safeguard the welfare of apprentices and registers apprenticeship programs that meet those standards , which include requirements for related instruction , on - the - job training , and equal employment opportunity for apprentices .

oatels also oversees apprenticeship programs to ensure that they provide quality training for apprentices , as many as 480,000 of whom may be enrolled at any one time .

labor , through oatels , directly registers and oversees programs in 23 states .

it has granted 27 other states , the district of columbia , and 3 territories authority to register and oversee their own programs , and ensures programs comply with federal standards and meet additional state standards .

in these states , referred to here as council - monitored states , oatels reviews the activities of the apprenticeship councils that are responsible for ensuring programs in their state comply with federal labor standards and equal opportunity protections .

while labor and apprenticeship councils provide oversight , recent studies have shown that a significant number of construction apprentices are not completing their programs and that construction programs sponsored by employers without union participation have lower completion rates and wages for apprentices .

in addition , some have raised concerns that the failure to complete programs could be indicative of poor program quality .

the anticipated shortage of skilled construction workers has heightened concerns about the relationship between program outcomes and program quality , the prospect for expanding the supply of skilled workers through apprenticeships , and labor's oversight of these programs .

in view of these concerns , you asked us to review the extent of federal oversight of apprenticeship programs in general and compare apprenticeship outcomes in the construction industry by type of program sponsorship .

specifically , we assessed ( 1 ) the extent to which the u.s. department of labor monitors the operations and outcomes of registered apprenticeship programs in the states where it has direct oversight , ( 2 ) its oversight activities for council - monitored states , and ( 3 ) the outcomes for construction apprentices in programs sponsored jointly by employers and unions in relation to those sponsored by employers alone .

to obtain national information on labor's monitoring and oversight activities , we surveyed all state directors of apprenticeship training programs through electronic questionnaires posted on the world wide web .

we excluded the three territories — guam , puerto rico , and the virgin islands — from our analyses because the few programs they had were atypical .

we also visited four states , both federal ( texas ) and council - monitored ( california , new york , and washington ) , that had large numbers of construction apprentices ( from about 52,000 to 6,500 ) .

in these states , we talked to knowledgeable officials , private - sector experts and stakeholders , including employer and labor union sponsors of apprenticeship programs .

in some cases , we visited apprentice training facilities .

to determine completion rates , times to completion , and wage rates for apprentices , we analyzed data in labor's apprenticeship database for the fiscal years 1994 through 2004 .

in calculating completion rates , we constructed five cohorts based on when apprentices enrolled in a program — 1994 , 1995 , 1996 , 1997 , or 1998 — and established their completion status 6 years after they enrolled .

these analyses included data on programs in 23 states where labor has direct oversight and programs in 8 council - monitored states .

in addition , we obtained comparable data on construction programs from 10 council - monitored states that have large numbers of construction apprentices and were able to provide this information .

the 41 states for which we had some type of data accounted for an estimated 92 percent of all construction apprentices .

we also interviewed labor officials and other knowledgeable parties .

 ( see app .

i. ) .

we conducted our work between august of 2004 and july 2005 in accordance with generally accepted government auditing standards .

although apprenticeship programs in the united states are largely private systems that are paid for largely by program sponsors , the national apprenticeship act of 1937 authorizes and directs the secretary of labor to formulate and promote labor standards that safeguard the welfare of apprentices .

the responsibility for formulating and promoting these standards resides with oatels .

oatels had a staff of about 176 full - time equivalencies and an annual appropriation of about $21 million in 2004 .

in addition , because of budgetary constraints , oatels officials do not expect resources to increase .

at the national level , oatels can register and deregister apprenticeship programs ( i.e. , give or take away federal recognition ) , issue nationally recognized , portable certificates to individuals who have completed registered programs , plan appropriate outreach activities targeted to attract women and minorities , and promote new apprenticeship programs to meet workforce needs .

in addition to this national role , oatels directly oversees individual apprenticeship programs in 23 states .

in these states , the director for the state's apprenticeship system and other program staff are federal employees who monitor individual apprenticeship programs for quality and their provision of equal opportunity .

labor can give authority to states to oversee their own apprenticeship programs if the state meets certain requirements .

labor has given this authority to 27 states , the district of columbia , and three territories .

in these states , which we refer to as council - monitored , the federal government is not responsible for monitoring individual apprenticeship programs ; instead , the state is .

it does so through state apprenticeship councils .

oatels does , however , conduct two types of reviews to determine how well the state fulfills its responsibilities .

quality reviews determine , in part , conformance with prescribed federal requirements concerning state apprenticeship laws , state council composition , and program registration , cancellation and deregistration provisions .

equal employment opportunity ( eeo ) reviews assess the conformity of state eeo plans , affirmative action activities , record - keeping procedures , and other activities with federal eeo regulations .

in addition to these reviews , oatels may also provide state agencies with federal staff to assist in day - to - day operations .

the number and type of construction apprenticeship programs are distributed differently across federally - and council - monitored states .

council - monitored states not only have more programs , but these programs are more likely to be jointly sponsored by employers and unions than sponsored by employers alone .

on average , a construction apprenticeship program in federally - monitored states trains about 17 apprentices and in council - monitored states trains about 20 .

beyond this average , it's important to note that there can be great variation among programs , with some having over 400 participants and others 1 or 2 .

figure 1 identifies states where programs are federally - and council - monitored .

both the federal and council - monitored states collect data on the individual programs they oversee .

labor maintains a large database called the registered apprenticeship information system ( rais ) and collects information about individual programs , apprentices , and sponsors for apprenticeships in the 23 states where it has direct oversight and in 8 council - monitored states that have chosen to report into this system .

the other council - monitored states , 20 in total , maintain their own data and collect various pieces of information on apprenticeship systems .

labor does collect aggregate data on apprentices and programs from these states .

in all states , individuals can enter the construction trades without completing formal apprenticeship programs , but many construction workers , particularly those working in highly skilled occupations that require extensive training , such as the electrical , carpentry , and plumbing trades , receive their training though registered apprenticeship programs .

to complete their programs , apprentices must meet requirements for on - the - job training and classroom instruction that must meet the minimum standards for the trade as recognized by labor or the state apprenticeship council .

programs in some trades , for example , commercial electricity , may take 5 years to complete but programs to train laborers may only take a year .

beginning apprentices' wages generally start at about 40 percent of the wage of someone certified in a particular trade and rise to about 90 percent of that wage near completion .

apprentices' contracts with their program sponsors specify a schedule of wage increases .

although oatels is responsible for overseeing thousands of apprenticeship programs in the states where it has direct oversight , it reviews few of these programs each year .

also , while its apprenticeship database collects much information about individual participants and programs , labor hasn't used these data to systematically generate program performance indicators such as completion rates .

as a result , it lacks information that would allow it to identify poorly performing programs and adjust its oversight accordingly .

furthermore , despite many technical upgrades , labor's database hasn't provided information that meets the needs of federal apprenticeship directors or the needs of other stakeholders .

oatels has reviewed very few of the apprenticeship programs in the states where it has direct oversight .

federal apprenticeship directors in these states reported they conducted 379 quality reviews in 2004 , covering only about 4 percent of the programs under their watch .

these reviews are done to determine , for example , whether sponsors have provided related instruction and on - the - job training hours in accordance with the standards for the program and whether wages reflected actual time in the program .

the number of reviews conducted varied across states .

on average , 22 quality reviews per state were conducted , but one director reported conducting as many as 67 reviews while another reported conducting no reviews at all .

in addition , programs in council - monitored states were almost twice as likely as programs in federally - monitored states to have been reviewed within 3 years .

 ( see fig .

2. ) .

several federal officials said over the past several years they had placed primary emphasis on registering new programs and recruiting more apprentices , particularly in nontraditional areas such as childcare and health .

in addition , they told us it was not possible to do more reviews in part because of limited staff .

in addition to having fewer reviews , apprenticeships in federally - monitored states had fewer staff dedicated to monitoring activities than council - monitored states .

in 2004 , each staff person in a federally monitored state was responsible , on average , for about 2,000 apprentices , according to federal program directors ; to put this in context , case loads of monitors in federally - monitored states were almost twice as large as those in council - monitored states .

in federally - monitored states , on average there were about 2.5 staff to monitor programs , less than one - third the average in council - monitored states .

labor's practice of assigning federal staff to monitor programs in 18 of the council - monitored states rather than to programs in federally - monitored states compounded differences in staff resources .

directors in council - monitored states reported that at least two federal employees , on average , monitored programs in their jurisdiction .

as important as the number of staff , is how they spent their time .

about a half of the staff in federally - monitored states spent 40 percent or more of their time in the field performing monitoring , oversight , and providing related technical assistance , according to federal program directors whereas one - half of the staff in council - monitored states spent about 70 percent or more in the field .

although labor collects information to compute completion rates and track participants who do not complete programs in the time expected , it does not use these data to focus its oversight efforts on programs with poor performance .

during a site visit in a federally - monitored state , a monitor showed us how she computed cancellation rates by hand for apprentices in programs that she felt were not doing an adequate job of training apprentices to see if her hypotheses were correct .

in the absence of performance information , directors and staff in federally - monitored states reported that a variety of factors dictated which programs to review .

these included size , newness , location , date of the last review , sponsor's cooperativeness , as well as the location of staff resources .

in addition to not using program data to target reviews , labor has not collected and consistently entered into its database information about why apprentices cancel out of programs , although its database was designed to include such information and having it could help target reviews .

officials told us that voluntary cancellation or transfers to another program were at times associated with program quality , while other nonvoluntary reasons , such as illness or military service , were not .

currently , recording the reason for an apprentice's cancellation in the database is an optional field .

we found that no reason was recorded for 60 percent of the cancellations and the remaining 40 percent did not effectively capture the reasons for leaving .

of the 18 reasons entered , the most common reasons were “unknown,” “voluntarily quit,” “unsatisfactory performance,” “discharged / released,” and “cancelled with the occupation,” some of which did not provide useful information to target reviews .

also , other entries were close duplicates of one another , such as “left for related employment” and “left for other employment.” labor also treats as optional data entries for its equal employment opportunity reviews: including the date of the last review , compliance status , status of corrective actions , and other information that would improve the efficiency of managing reviews .

as a result , such data were available for about 5 percent of programs in labor's database in fiscal year 2004 .

without this information , it is more difficult to determine when programs had their last eeo review and to readily identify programs with known problems .

despite many technical upgrades , labor's database hasn't provided information that meets the needs of its federal directors or the needs of other stakeholders .

while acknowledging that labor's database has been updated and improved , 22 out of the 23 directors of apprenticeship programs and their monitoring staff have expressed dissatisfaction with the present system .

one complained of “daily” changes to the data fields without being informed of “why or when they will change.” expressing the desire to select and sort data on any field and generate unique reports in context with all available data , another concluded , “in short , we need a lot of flexibility with database reports that we don't have at this time.” many federal apprenticeship directors made recommendations for improving the database .

in general , what state directors wanted most was a system that was stable , user friendly , and that would allow them to produce customized reports to better oversee the apprenticeship programs in their states .

the list below shows those potential improvements endorsed by more than half of the state apprenticeship directors: increase the timeliness of notifications to state and regional offices for changes to rais ( eg , provide for more frequent communication ) , ( 22 of 23 surveyed states ) .

simplify instruction and procedures for producing reports ( 18 of 23 surveyed states ) .

allow production of customized state and regional reports by type of industry ( 18 of 23 surveyed states ) .

allow production of customized state and regional reports by sponsor type ( 17 of 23 ) and occupational type ( 17 of 23 surveyed states ) .

improve the frequency of rais training ( 17 of 23 surveyed states ) .

improve the quality of rais training ( 16 of 23 surveyed states ) .

simplify instructions and procedures for inputting and updating data ( 16 of 23 surveyed states ) .

increase available coding options to explain why apprentices leave the program ( 14 of 23 surveyed states ) .

allow production of customized state and regional reports by sex of apprentice and race of apprentice ( 14 of 23 surveyed states ) .

oatels has recently purchased software that enables users to extract data from labor's databases in order to produce customized reports .

purchased originally for the secretary of labor's use , labor information technology and oatels officials said they foresaw the software's utility for many programs and therefore decided to purchase licenses for apprenticeship field staff .

however , oatels has not necessarily taken steps to ensure field staff will be able to make optimal use of the software .

about half the directors in federally - monitored states did not know the software was available or what it was .

although the software was demonstrated at a directors' meeting in 2004 , several couldn't recall the demonstration and others were not in attendance .

moreover , two of the directors lacked basic hardware , such as a high - speed cable needed to support the software .

in fact , one director told us he was working from his home because his office didn't have such basics as a cable hook - up for his computer .

even if such obstacles are surmounted , the new system may not meet the staffs' data needs .

two directors who were already attempting to use the software reported to us that it did not allow them to select information using factors that would be most useful to them , such as state - level data on apprenticeship programs .

in addition , labor could or would not supply us with formal documentation describing its plans to implement the software or its vision of how the software would be used by its staff .

labor also reported that because of budget constraints and the easy use of the new software , it had no plans to provide training .

without such plans , labor's commitment to the full implementation and future financing of the program is questionable .

labor has infrequently reviewed states to which it has delegated oversight responsibility .

this includes both quality reviews and eeo reviews to assure that these states are in compliance with federal rules for overseeing apprenticeship programs and also adhering to equal employment opportunity requirements .

moreover , states that have been reviewed in recent years reported that they had little utility for helping them manage their programs , in part , because of the little feedback they received .

in terms of providing information to congress and others , labor does not collect from these states information that is readily available on apprenticeships by occupation or industry , even for occupations where shortages of skilled workers are anticipated .

agency records indicate that labor conducted only three quality and eeo reviews of council - monitored states in calendar years 2002 and 2003 , and none in 2004 but has scheduled seven for 2005 .

state apprenticeship directors confirmed that reviews are infrequent .

twelve of the 27 directors in council - monitored states reported that oatels had conducted reviews of their programs less frequently than once every 3 years and several responded that reviews had not taken place in the last 9 to 12 years .

an additional five directors reported their states had never been reviewed or that they were unaware if such reviews had taken place .

the remaining 10 reported reviews took place in their states at least once every 3 years .

 ( see fig .

3. ) .

while neither statute nor regulation specifies the frequency with which oatels should conduct such reviews , they constitute an important mechanism for ensuring that state laws conform to requirements necessary for labor's recognition of a state's registered apprenticeship program .

state directors reported that the quality reviews and the eeo reviews had limited utility for helping them manage their programs .

for example , only about half of them reported that the quality reviews were at least moderately useful for helping them determine their compliance with federal regulation .

 ( see fig .

4. ) .

results were similar for the eeo reviews .

 ( see fig .

5. ) .

for example , slightly less than half of state directors reported that eeo reviews were at least moderately useful in helping them determine their compliance with federal eeo regulations .

some directors said reviews would be more useful if they focused on reviewing program - related activities in the state .

eight of the directors suggested that labor focus more on state and local conditions and the performance of apprenticeship programs instead of focusing only on whether council - monitored states comply with federal standards .

for example , one director reported the feedback he received on eeo activities was unrelated to the racial composition of the state .

also , some suggested reviews could provide opportunities for federal officials to provide assistance and share knowledge about strategies that other states have found useful .

while directors had a number of ideas for improving the usefulness of quality and eeo reviews , many noted that labor provided limited or no feedback as part of the review process .

for example , one said his state agency received a brief letter from labor stating only that the state was in compliance with federal regulations .

two others said their agencies received no documentation that a review had in fact been conducted , even though in one of these cases the state had made requests for the review findings .

officials in one state said feedback from their last review was positive and indicated no problems , but a few years later , oatels took steps to get their state apprenticeship council derecognized with no prior notice or subsequent review .

labor collects aggregate counts of apprentices for most council - monitored states and has not developed strategies to collect more detailed information that would allow for a description of apprenticeships at the national level , even for those where shortages of skilled workers are anticipated .

of the 28 council - monitored states , 20 have their own data system and do not report data to labor's apprenticeship database .

these 20 states represent about 68 percent of the nation's apprentices .

labor and council - monitored states have differing opinions about why there are separate data systems .

labor officials told us that , as they were developing their database , they conducted outreach to council - monitored states .

officials from these states say otherwise .

they also said that participating in labor's database would be an onerous process or that labor's system did not meet their state's information needs and , therefore , they had invested the time and money to develop their own systems .

because many of these systems are not compatible with labor's , the agency collects only total counts of apprentices and programs from these 20 states , which it uses for its official reports .

while incompatible data systems may suggest that it would be difficult or costly to obtain more than aggregate counts , in collecting data for this report , we found many of the council - monitored states — including 10 with large numbers of apprentices — were both willing and capable of providing us data on apprentices by industry and by occupation as well as information on completion rates , completion times , and some wage data for occupations that we had specified .

in fact , one state reported that it had designed its apprenticeship database to collect all information required by labor's database and had offered to report these data to labor electronically — but labor had not taken steps to accept this offer .

nevertheless , as one director pointed out , having a unified data picture is central to oatels' oversight as well as its promotional activities and , as many agree , such a system would promote the health of the registered apprenticeship system .

construction apprentices in programs sponsored jointly by employers and unions ( joint programs ) generally completed at a higher rate and in greater numbers than those enrolled in programs sponsored by employers alone ( non - joint programs ) .

more importantly , despite growth in construction program enrollment , there has been a decline over time in completion rates for both types of programs .

completion rates declined from 59 percent for apprentices enrolling in 1994 to 37 percent for apprentices enrolling in 1998 .

it is difficult to know what factors underlie this trend because , as noted earlier , labor does not systematically record information about why apprentices leave programs .

apprentices who completed programs within 6 years tended to finish earlier than expected .

in addition , wages for joint apprentices were generally higher at the start and upon completion of their programs .

data received from 10 council - monitored states that do not report to labor's database generally mirrored these findings .

completion rates were generally higher for apprentices in joint programs than for those in non - joint programs .

of the apprentices who entered programs between 1994 and 1998 , about 47 percent of apprentices in joint programs and 30 percent of apprentices in non - joint programs completed their apprenticeships by 2004 .

for five consecutive classes ( 1994-1998 ) of apprentices in labor's database , completion rates calculated after 6 years , were higher for joint programs , as shown in figure 6 .

the data we received from 10 additional states that do not report into labor's database showed similar trends , with joint apprentices having higher completion rates .

for complete data that we received from these 10 states , see appendix ii .

for the programs in labor's database , this higher completion rate for joint apprenticeship programs was true for all but 1 of the 15 largest individual trades which collectively account for 93 percent of active apprentices in construction .

 ( see fig .

7. ) .

it should be noted that among the trades , themselves , there were substantial variations in completion rates , often due to the nature of work environment and other constraints , according to federal and state officials .

for example , roofing programs , which have low completion rates , face unpredictable weather and seasonal work flows .

officials said that joint programs have higher completion rates because they are more established and better funded .

for some joint programs , these additional resources stem in part from union members paying a small portion of their paychecks into a general training fund that is used to help defray some of the training costs for apprentices .

in addition , they suggested that , because unions tend to have a network of affiliates spread across an area , they are more likely to find work for participating apprentices in other areas when work is slow in a particular area .

local union chapters often have portability agreements with one another other , which help to facilitate such transfers .

officials also said these programs provide mentoring and other social supports .

enrollments in construction apprenticeship programs more than doubled from 1994 to 1998 , increasing from 20,670 construction apprentices to 47,487 .

 ( see fig .

8. ) .

meanwhile , completion rates declined from 59 percent for the class of 1994 to 37 percent for the class of 1998 .

this decline for these cohorts held for both joint and non - joint programs .

 ( see fig .

9. ) .

completion rates for joint apprentices dropped from nearly 63 percent to 42 percent , and from 46 percent to 26 percent for non - joint apprentices .

this trend was consistent across different occupations as well , with most experiencing declines .

because labor does not systematically record the explanations that apprentices offer for canceling out of programs , it is difficult to determine what may lie behind this downward trend .

labor suggested that some apprentices may choose to acquire just enough training to make them marketable in the construction industry in lieu of completing a program and achieving journey status .

while we cannot confirm this hypothesis , we did find that those apprentices who did cancel chose to do so after receiving over a year of training .

joint apprentices cancelled after 92 weeks on average and non - joint apprentices cancelled after 85 weeks on average .

other reasons offered included a decline in work ethic , the emphasis placed by high schools on preparing students for college and the corresponding under - emphasis on preparation for the trades , and a lack of work in the construction industry .

we cannot verify the extent to which unemployment played a role influencing outcomes , but , according to the bureau of labor statistics , the unemployment rate for construction increased overall from 6.2 percent to 8.4 percent between 2000 to 2004 , despite the predictions of future worker shortages in construction .

those apprentices who completed construction programs within 6 years tended to finish earlier than they were expected to , with apprentices in non - joint programs finishing a bit sooner than their joint counterparts .

on average , joint apprentices completed their programs 12 weeks early and non - joint apprentices completed 35 weeks early .

this trend was similar across the largest trades in terms of enrollment as shown in table 1 below .

this may be due to the willingness of program sponsors to grant apprentices credit for previous work or classroom experience that was directly related to their apprenticeship requirements .

apprentices in joint construction programs were paid higher wages at the start of their apprenticeships and were scheduled to receive higher wages upon completion of their programs .

in 2004 , the first year in which labor collected information on starting wages , apprentices in joint programs earned $12.28 per hour while non - joint apprentices earned $9.90 at the start of their apprenticeships .

these differences in wages were more pronounced at the journey level , that is , upon completion , with apprentices in joint programs scheduled to earn journey - level wages of $24.19 as compared with $17.85 for those in non - joint programs .

as shown in figure 10 , joint apprentices generally earned higher wages across the 15 trades with the largest numbers of construction apprentices .

there were three trades — carpenter , structural steel worker , and cement mason — for which starting wages were higher for non - joint apprentices .

for journey - level wages there was only one trade for which wages were higher for non - joint apprentices — that of millwright .

officials we spoke with commonly attributed this distinction in wages to the bargaining process associated with joint programs .

data from the 10 additional states ( outside labor's database ) whose data we examined showed a similar pattern — with joint apprentices earning higher wages .

 ( see app .

ii. ) .

as a small program with finite resources tasked with an important mission , it is incumbent on labor's apprenticeship office to leverage the tools at its disposal to carry out its oversight , all the more so during a period of tight budgets .

labor's responsibility for assuring that registered apprenticeship programs meet appropriate standards is no small charge , given the thousands of programs in operation today .

in terms of the programs it directly monitors , labor has not made optimal use of the information it collects to target resources .

the failure to do so limits the agency's ability to target its oversight activities to address and remedy areas where there may be significant need , particularly the construction trades where completion rates are declining .

underscoring this point is the fact that apprenticeship directors in federally - monitored states cannot get easy access to the data in the form of customized reports .

irrespective of distinctions between apprentice outcomes for joint and non - joint programs , without better use of its data , labor is still not in a position to assess programs on their individual merits .

given the relatively limited number of staff available for field visits , by not using the program data it has , labor misses opportunities to more efficiently use its staff .

with regard to states with council - monitored apprenticeship programs , labor's oversight practices do not necessarily ensure that those states' activities comply with federal standards for oversight because the apprenticeship office has only sporadically assessed their operations .

moreover , to the extent that the federal office does not provide useful feedback to the states when it does conduct reviews , states may lose opportunities to improve programs under their jurisdiction .

finally , because labor does not seek much information beyond aggregate numbers from a majority of council - monitored states , policymakers lose an opportunity to gain perspective and insight for aligning workforce training with national needs , specifically for key occupations within construction that are likely to be faced with shortages of skilled workers in the near future .

we recommend that the secretary of labor take steps to ( 1 ) better utilize information in labor's database , such as indicators of program performance , for management oversight , particularly for apprenticeship programs in occupations with expected future labor shortages ; ( 2 ) develop a cost - effective strategy for collecting data from council - monitored states ; ( 3 ) conduct labor's reviews of apprenticeship activities in states that regulate their own programs on a regular basis to ensure that state activities are in accord with labor's requirements for recognition of apprenticeship programs ; and ( 4 ) offer substantive feedback to states from its reviews .

we provided a draft of this report to the department of labor for review and comment .

labor provided written comments on the draft report that are reproduced in appendix v. labor concurred with our recommendations and has already taken steps to obtain data on apprenticeships from some council - monitored states and to regularly review activities in these states .

further , labor stated it plans to use the data to better target the performance of the apprenticeship programs that oatels directly registers and oversees , and to provide improved feedback to states that register and oversee their own apprenticeship programs .

unless you publicly announce its contents earlier , we plan no further distribution of this report until 14 days after the date of this letter .

at that time , we will send copies of this report to the secretary of labor and other interested parties .

we will also make copies available to others upon request .

in addition , the report will be available at no charge on gao's web site at http: / / www.gao.gov .

please contact me on 512-7215 or nilsens@gao.gov if you or your staff have any questions about this report .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix vi .

our objectives were to determine ( 1 ) the extent to which the u.s. department of labor monitors the operations and outcomes of registered apprenticeship programs in the states where it has direct oversight , ( 2 ) its oversight activities for council - monitored states , and ( 3 ) outcomes for construction apprentices in programs sponsored jointly by employers and unions in relation to those sponsored by employers alone .

to carry out these objectives , we surveyed oatels officials in charge of apprenticeship programs in 23 federally monitored states and state apprenticeship directors in 28 states , including the district of columbia , where state apprenticeship councils oversee programs .

we used two surveys — one for federally - monitored states and one for council - monitored states — to obtain national information on oatels' monitoring and oversight activities .

we focused only on apprentices in the civilian sector of the economy and did not include military or prison - based programs .

we asked questions designed to determine the amount of resources devoted to oversight , the frequency of oversight activities , and the outcomes from these activities .

the surveys were conducted using self - administered electronic questionnaires posted on the world wide web .

we pretested our surveys with a total of five federally - monitored and council - monitored state officials to determine if the surveys were understandable and if the information was feasible to collect .

we then refined the questionnaire as appropriate .

we sent e - mail notifications to all federally - monitored and council - monitored state officials on january 5 , 2005 .

we then sent each potential respondent a unique password and username by e - mail on january 13 , 2005 , to ensure that only members of the target population could participate in the appropriate survey .

to encourage respondents to complete the surveys , we sent e - mail messages to prompt each nonrespondent approximately 1½ weeks after the initial e - mail message and a final e - mail reminder on february 7 , 2005 .

we also called nonrespondents to encourage them to complete the survey .

we closed the surveys on march 18 , 2005 .

we received responses from all 23 federally - monitored and 27 of 28 council - monitored state officials including the district of columbia .

 ( see table 2. ) .

copies of the surveys are provided in appendices iii and iv .

to examine the outcomes for apprentices in the construction industry , we analyzed data from labor's rais database .

in calculating completion rates , we constructed five cohorts based on when they enrolled in their programs ; we had cohorts for fiscal years 1994 , 1995 , 1996 , 1997 , and 1998 .

we then considered the status of these cohorts 6 years after they enrolled to determine if they had completed , cancelled , or remained in training .

our analysis of wage data focused on data collected in fiscal year 2004 , the first full year that labor began collecting such information .

we assessed the reliability of the rais database by reviewing relevant information on the database , interviewing relevant oatels officials , and conducting our own testing of the database .

this testing included examining the completeness of the data , performing data reliability checks , and assessing the internal controls of the data .

based on this information and our analysis , we determined that these data were sufficiently reliable for the purposes of our report .

because labor's rais database does not contain data from all states , we supplemented these data with data from 10 council - monitored states that do not report to this database .

we selected these states based on the number of apprentices they had and whether their data were in an electronic format that would facilitate extracting and sending these data to us .

we submitted a data request that asked for selected information on enrollment , completion , and wages for the 10 largest apprenticeship occupations to these states and received data from all of them .

we determined that these data were reliable for our purposes .

we did not combine these data with those from rais ; we used them as a means of comparison .

to learn more about the oversight of apprenticeship programs and their outcomes , we conducted site visits to four states — new york , california , texas , and washington .

these states represented both federal and council - monitored states and had large numbers ( from a high of about 52,000 to a low of 6,500 ) of construction apprentices .

on these site visits , we interviewed relevant federal and state officials along with joint and non - joint program sponsors .

we also toured facilities in two states where certain apprentices are trained .

throughout the engagement we interviewed relevant labor officials and experts that have researched apprenticeship programs and reviewed relevant past reports and evaluations of these programs .

we conducted our review from august 2004 through july 2005 in accordance with generally accepted government auditing standards .

california reported no structural steel worker non - joint programs .

new york reported no completers for pipe fitter , structural steel worker , painter , and operating engineer non - joint programs .

oregon reported no non - joint apprenticeship programs are registered in the state .

22 q6 .

in your opinion , would the following updates or modifications improve registered apprenticeship information system's ( rais ) usefulness to your state ? .

23 q8 .

did your state use wia governor's 15% state set - aside funds to support new and / or established apprenticeship programs in ffy 2004 ? .

23 q9 .

were wia state set - aside funds used to support new and / or established apprenticeship programs in your state in ffy 2004 to do any of the following ? .

q11 .

for which of the following reasons did your state not use wia set - aside funds to support apprenticeship programs in ffy 2004 ? .

17 17 q13 .

were wia funding sources other than state set - aside funds used in your state to support new and / or established apprenticeship programs in ffy 2004 ? .

q14 .

other than state set - aside funds , which of the following wia funding sources were used to support new and / or established apprenticeship programs in ffy 2004 ? .

q16 .

did your state establish linkages between wia state unit and the state apprenticeship unit in ffy 2004 for any of the following purposes ? .

22 q19 .

how often does your unit conduct formalized quality reviews of individual apprenticeship programs that address on - the - job training , related instruction , and / or program operations in your state ? .

more than twice a year q21 .

approximately how many quality reviews did your unit conduct in ffy 2004 ? .

 ( click in the box and then enter up to a 4-digit whole number only. ) .

little or no extent ( please specify in question 24. ) .

little or no extent ( please specify in question 24. ) .

q26 .

how often does your unit conduct formalized equal employment opportunity ( eeo ) reviews of individual apprenticeship programs ? .

more than twice a year q28 .

approximately how many eeo reviews did your unit conduct in ffy 2004 ? .

 ( click in the box and then enter up to a 4-digit whole number only. ) .

23 q29 .

to what extent , if at all , did your state find the ffy 2004 eeo reviews useful for the following purposes ? .

little or no extent ( please specify in question 31. ) .

q33 .

did your state have procedures or policies for recording complaints filed in ffy 2004 that were elevated to the level of the state or regional oatels office ? .

q34a2 .

check if actual , estimate , or do not know or cannot estimate q34b1 .

how many complaints concerned termination in ffy 2004 ? .

q34b2 .

check if actual , estimate , or do not know or cannot estimate q34c1 .

how many complaints concerned discrimination in ffy 2004 ? .

q34c2 .

check if actual , estimate , or do not know or cannot estimate 18 q34d1 .

how many complaints concerned wages in ffy 2004 ? .

q34d2 .

check if actual , estimate , or do not know or cannot estimate q34e1 .

how many complaints concerned related instruction in ffy 2004 ? .

q34e2 .

check if actual , estimate , or do not know or cannot estimate 18 q34f1 .

how many complaints concerned on - the - job training in ffy 2004 ? .

q34f2 .

check if actual , estimate , or do not know or cannot estimate q34g1 .

how many complaints concerned other issues in ffy 2004 ? .

27 q6 .

during state fy 2004 , how many full - time equivalency ( fte ) apprenticeship training staff were employed by the bat agency in your state to monitor and oversee apprenticeship programs in your state ? .

q8 .

how often does your oatels conduct sac 29 / 29 review ( review of labor standards for registration of apprenticeship programs ) in your state ? .

more than twice a year q10 .

to what extent did your state find oatels' most recent sac 29 / 29 review ( review of labor standards for registration of apprenticeship programs ) useful for the following purposes in your state ? .

q15 .

how often does oatels conduct sac 29 / 30 review ( review of equal employment opportunity in apprenticeship and training ) in your state ? .

more than twice a year q17 .

to what extent , if at all , did your state find oatels' most recent sac 29 / 30 review ( equal employment opportunity in apprenticeship and training ) useful for the following purposes ? .

q21 .

does your state presently use oatels' registered apprenticeship information system ( rais ) to register apprentices and to track apprentice and program information ? .

27 q23 .

does you state plan or intend to use rais to register apprentices and track apprenticeship and program information in the future ? .

q26 .

did your state use the wia governor's 15% state set - aside funds to support new and / or established apprenticeship programs in state fy 2004 ? .

q27 .

were wia state set - aside funds used to support new and / or established apprenticeship programs in your state in state fy 2004 to do any of the following ? .

5 q29 .

for which of the following reasons did your state not use wia set - aside funds to support apprenticeship programs in state fy 2004 ? .

22 q31 .

were wia funding sources other than state set - aside funds used in your state to support new and / or established apprenticeship programs in state fy 2004 ? .

q32 .

other than state set - aside funds , which of the following wia funding sources were used to support new and / or established apprenticeship programs in state fy 2004 ? .

3 q34 .

did your state establish linkages between wia and the state apprenticeship unit in state fy 2004 for any of the following purposes ? .

q37 .

did your state have a mechanism for conducting formalized reviews of apprenticeship programs that address on - the - job training , related instruction , and / or program operations in state fy 2004 ? .

q38 .

which of the following components - - on - the - job training , related instruction , and / or program operations - - were included in these reviews ? .

25 q40 .

how often does your state conduct formalized reviews of individual apprenticeship programs that address on - the - job training , related instruction , and / or program operations ? .

q42 .

does your state have a mechanism for conducting formalized equal employment opportunity ( eeo ) reviews of individual apprenticeship programs ? .

q43 .

how often does your state conduct formalized equal employment opportunity ( eeo ) reviews of individual apprenticeship programs ? .

more than twice a year q45 .

did your state have procedures or policies for recording complaints filed in state fy 2004 that were elevated to the level of state apprenticeship agencies ? .

q46a1 .

in your state , how many total complaints were referred to state officials in state fy 2004 ? .

q46a2 .

check if actual , estimate , or do not know or cannot estimate 22 q46b1 .

how many complaints concerned termination in state fy 2004 ? .

q46b2 .

check if actual , estimate , or do not know or cannot estimate q46c1 .

how many complaints concerned discrimination in state fy 2004 ? .

q46c2 .

check if actual , estimate , or do not know or cannot estimate q46d1 .

how many complaints concerned wages in state fy 2004 ? .

q46d2 .

check if actual , estimate , or do not know or cannot estimate q46e1 .

how many complaints concerned related instruction in state fy 2004 ? .

q46e2 .

check if actual , estimate , or do not know or cannot estimate q46f1 .

how many complaints concerned on - the - job training in state fy 2004 ? .

q46f2 .

check if actual , estimate , or do not know or cannot estimate 22 q46g1 .

how many complaints concerned other issues in state fy 2004 ? .

patrick dibattista , assistant director , scott heacock , linda w. stokes , and kathleen d. white managed all aspects of the assignment .

the following individuals made significant contributions to this report: susan bernstein , jessica botsford , richard burkard , cathy hurley , and jean mcsween .

workforce investment act: substantial funds are used for training , but little is known nationally about training outcomes .

gao - 05-650 .

washington , d.c.: june 2005 .

public community colleges and technical schools: most schools use both credit and noncredit programs for workforce development .

gao - 05-4 .

washington , d.c.: october 2004 .

registered apprenticeships: labor could do more to expand to other occupations .

gao - 01-940 .

washington , d.c.: september 2001 .

youth training .

pemd - 94-32r .

washington , d.c.: september 1994 .

apprenticeship training: administration , use , and equal opportunity .

hrd - 92-43 .

washington , d.c.: march 1992 .

