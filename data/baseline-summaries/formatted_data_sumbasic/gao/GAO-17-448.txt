the federal government's demand for information technology ( it ) is ever increasing .

in recent years , as federal agencies have modernized their operations , put more of their services online , and improved their information security profiles , their need for computing power and data storage resources has grown .

accordingly , this growing demand has led to a dramatic rise in the number of federal data centers and a corresponding increase in operational costs .

in response , the office of management and budget's ( omb ) federal chief information officer ( cio ) launched the federal data center consolidation initiative ( fdcci ) in 2010 to reduce the growing number of centers .

congress has also recognized the importance of reforming the government - wide management of it , and in december 2014 , federal information technology acquisition reform provisions ( commonly referred to as fitara ) were enacted as a part of the carl levin and howard p. ‘buck' mckeon national defense authorization act for fiscal year 2015 .

the law includes specific requirements related to federal data center optimization including , for example , that omb is to establish metrics to measure data center optimization progress ( to include server efficiency ) .

pursuant to fitara , in august 2016 , the federal cio issued a memorandum that announced the data center optimization initiative ( dcoi ) as a successor effort to fdcci .

according to omb , this new initiative supersedes and builds on the results of fdcci , and is also intended to improve the performance of federal data centers in areas such as facility utilization and power usage .

among other things , dcoi requires 24 federal departments and agencies ( agencies ) to develop plans and report on strategies ( referred to as dcoi strategic plans ) to consolidate inefficient infrastructure , optimize existing facilities , improve security posture , and achieve cost savings .

over the past several years , we have reported and testified that , while data center consolidation and optimization could potentially save the federal government billions of dollars , weaknesses exist in the execution and oversight of these efforts .

for example , in march 2016 , we reported that 22 agencies had collectively made limited progress against omb's fiscal year 2015 data center optimization performance metrics .

as a result , we recommended that these agencies take action to improve optimization progress .

most agencies agreed with our recommendations or had no comments .

given the importance of the optimization initiative , this report responds to the committees' request that we review federal agencies' data center optimization progress .

the specific objectives of this review were to ( 1 ) assess agencies' progress against omb's data center optimization targets , ( 2 ) identify agencies' notable optimization successes and challenges , and ( 3 ) evaluate the extent to which agencies are able to effectively measure server utilization .

to address the first objective , we analyzed 24 dcoi agencies' february 2017 data center optimization progress information from the it dashboard — an omb public website that provides information on federal agencies' major it investments .

we then compared the agencies' optimization progress information against omb's fiscal year 2018 optimization targets , as documented in its august 2016 memorandum .

we also reviewed the 24 agencies' dcoi strategic plans , as of april 2017 , to obtain information regarding their fiscal years 2017 and 2018 plans to meet or not meet omb's optimization targets .

to address the second objective , we reviewed the 24 agencies' dcoi strategic plans to identify successes and challenges encountered by agencies in optimizing their data centers .

we also interviewed cognizant officials at the 24 agencies in order to gather additional information about their data center optimization successes and challenges .

we then categorized the agency - reported successes and challenges to determine the ones encountered most often .

for the third objective , we analyzed the 24 agencies' february 2017 data center inventory information to determine the extent to which the agencies reported the implementation of automated monitoring tools at their data centers to measure server utilization , as well as the reported server utilization percentages at those centers .

we also reviewed agencies' dcoi strategic plans , fitara implementation milestone information , and other planning documentation provided by agencies ( such as project charters and project plans ) to determine the extent to which agencies documented plans to implement automated monitoring tools at all their data centers by the end of fiscal year 2018 , as required by omb's august 2016 memorandum .

see appendix i for a more detailed discussion of our objectives , scope , and methodology .

we conducted this performance audit from july 2016 to august 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the federal government's increasing demand for it has led to an increase in the number of federal data centers and a corresponding increase in operational costs .

according to omb , the federal government reported 432 data centers in 1998 , 2,094 in july 2010 , and 9,995 in august 2016 .

operating such a large number of centers has been and continues to be a significant cost to the federal government , including costs for hardware , software , real estate , and cooling .

for example , in 2007 , the environmental protection agency ( epa ) estimated that the electricity costs to operate federal servers and data centers across the government were about $450 million annually .

according to the department of energy ( energy ) , a typical data center has 100 to 200 times the energy use intensity of a commercial building .

in 2009 , omb reported that server utilization rates as low as 5 percent across the federal government's estimated 150,000 servers were a factor driving the need to establish a coordinated , government - wide effort to improve the efficiency , performance , and environmental footprint of federal data center activities .

concerned about the size of the federal data center inventory and the potential to improve the efficiency , performance , and the environmental footprint of federal data center activities , omb , under the direction of the federal cio , established fdcci in february 2010 .

this initiative's four high - level goals were to promote the use of “green it” by reducing the overall energy and real estate footprint of government data centers ; reduce the cost of data center hardware , software , and operations ; increase the overall it security posture of the government ; and shift it investments to more efficient computing platforms and technologies .

as part of the initiative , omb required the 24 agencies to identify a data center consolidation program manager to lead the agency's consolidation efforts .

in addition , agencies were required to submit an asset inventory baseline and other documents that would result in a plan for consolidating their data centers .

the asset inventory baseline was to contain detailed information on each data center and identify the consolidation approach to be taken for each one .

it would serve as the foundation for developing the final data center consolidation plan .

the data center consolidation plan would serve as a technical road map and approach for achieving the targets for infrastructure utilization , energy efficiency , and cost efficiency .

in october 2010 , omb reported that all of the agencies had submitted an inventory and plan .

omb also clarified the definition of a data center and noted that , for the purposes of fdcci , a data center is defined as any room used for the purpose of processing or storing data that is larger than 500 square feet and meets stringent availability requirements .

under this definition , omb reported that agencies had identified 2,094 data centers as of july 2010 .

“…a data center is…a closet , room , floor , or building for the storage , management , and dissemination of data and information and computer systems and associated components , such as database , application , and storage systems and data stores [excluding facilities exclusively devoted to communications and network equipment ( eg , telephone exchanges and telecommunications rooms ) ] .

a data center generally includes redundant or backup power supplies , redundant data communications connections , environmental controls…and special security devices housed in leased , owned , collocated , or stand - alone facilities.” under the new definition , omb estimated that there were a total of 3,133 federal data centers in december 2011 , and its goal was to consolidate approximately 40 percent , or 1,253 data centers , for a savings of approximately $3 billion by the end of 2015 .

see figure 1 for an example of an image of data center server racks at the social security administration's ( ssa ) national support center .

in march 2012 , omb launched the portfoliostat initiative , which requires agencies to conduct an annual agency - wide it portfolio review to , among other things , reduce commodity it spending and demonstrate how its it investments align with the agency's mission and business functions .

portfoliostat is designed to assist agencies in assessing the current maturity of their it portfolio management process , make decisions on eliminating duplication , and move to shared solutions in order to maximize the return on it investments across the portfolio .

subsequently , in march 2013 , omb issued a memorandum that documented the integration of fdcci with portfoliostat and stated that agencies should focus on an enterprise - wide approach to address commodity it ( including data centers ) in a comprehensive manner .

the memorandum also discussed consolidating previously collected it - related plans , reports , and data submissions .

for example , agencies were no longer required to submit the data center consolidation plans previously required in 2012 .

however , omb required agencies to update their data center inventories and report on consolidation progress at the end of every quarter .

omb's 2013 memorandum also increased the focus on optimizing the performance of federal data centers .

specifically , omb stated that , to more effectively measure the efficiency of an agency's data center assets , agencies would also be measured by the extent to which their primary data centers were optimized for total cost of ownership by incorporating metrics for data center energy , facility , labor , and storage , among other things .

subsequently , in may 2014 , omb issued memorandum m - 14-08 , which established a set of data center optimization metrics to measure agency progress .

in addition , omb established target values that agencies were expected to achieve by the end of fiscal year 2015 .

recognizing the importance of reforming the government - wide management of it , congress enacted fitara in december 2014 .

among other things , the law includes a number of requirements related to federal data center consolidation and optimization: agencies shall submit to omb a comprehensive inventory of the data centers owned , operated , or maintained by or on behalf of the agency .

agencies shall submit a multi - year strategy to achieve the consolidation and optimization of the agency's data centers no later than the end of fiscal year 2016 .

this strategy should include , for example , performance metrics that are consistent with the government - wide data center consolidation and optimization metrics .

on a quarterly basis , agencies shall report to omb's administrator of the office of electronic government on progress towards meeting government - wide data center consolidation and optimization metrics .

omb's administrator of the office of electronic government shall establish metrics applicable to the consolidation and optimization of data centers ( including server efficiency ) , ensure that agencies' progress toward meeting government - wide data center consolidation and optimization metrics is made publicly available , review agencies' inventories and strategies to determine whether they are comprehensive and complete , and monitor the implementation of each agency's strategy .

not later than december 19 , 2015 , omb's administrator of the office of electronic government shall develop and make publicly available , a goal , broken down by year , for the amount of planned cost savings and optimization improvements achieved through fdcci and , for each year thereafter through october 1 , 2018 , compare reported cost savings and optimization improvements against those goals .

the law's data center consolidation and optimization provisions expire on october 1 , 2018 .

in june 2015 , omb memorandum m - 15-14 provided guidance for implementing fitara and related it management practices .

omb's guidance includes several actions that agencies are to take to establish a basic set of roles and responsibilities ( referred to as the “common baseline” ) for cios and other senior agency officials that are needed to implement the authorities described in the law .

for example , agencies are to conduct a self - assessment to identify where they conform to the common baseline and where they deviate .

omb guidance also requires agencies to annually update their self - assessments and report their progress in reaching fitara implementation milestones .

in august 2016 , omb issued a memorandum that established dcoi and included guidance on how to implement the data center consolidation and optimization provisions of fitara .

among other things , the guidance requires agencies to consolidate inefficient infrastructure , optimize existing facilities , improve their security posture , and achieve cost savings .

for example , agencies are required to maintain a complete inventory of all data center facilities owned , operated , or maintained by or on behalf of the agencies and measure progress toward defined optimization performance metrics on a quarterly basis as part of their data center inventory submissions .

omb's august 2016 memorandum also revised the definition of a physical data center to include any room with at least one server that provides services ( such as testing and development ) .

further , omb's guidance directed agencies to categorize their data centers as either a tiered data center or a non - tiered data center .

omb guidance defines a tiered data center as one that uses each of the following: a separate physical space for it infrastructure , an uninterruptible power supply , a dedicated cooling system or zone , and a backup power generator for a prolonged power outage .

according to omb , all other data centers shall be considered non - tiered .

regarding data center optimization planning , the memorandum directs agencies to develop dcoi strategic plans that define their data center strategies for fiscal years 2016 through 2018 .

among other things , this strategy is to include a timeline for agency consolidation and optimization activities with an emphasis on cost savings and optimization performance benchmarks the agency can achieve between fiscal years 2016 and 2018 .

for example , agencies are required to establish planned data center optimization milestones and report on progress toward achieving those milestones in their strategic plans .

omb required agencies to publicly post the plans to their agency - owned digital strategy websites by september 30 , 2016 , and to post subsequent strategic plan updates by april 14 , 2017 , and april 13 , 2018 .

omb also directed agencies to update their publicly available fitara implementation milestone information to identify , at a minimum , five milestones per fiscal year to be achieved through dcoi .

according to omb , the dcoi milestones are expected to be updated quarterly as progress is achieved and are to be reviewed in quarterly meetings with omb staff .

further , the memorandum states that omb will report government - wide and agency - specific progress on the it dashboard — a public website that provides detailed information on major it investments .

according to omb , this progress information is to include planned and achieved data center closures , consolidation - related costs savings , and data center optimization performance information .

in this regard , omb began including data center consolidation and optimization progress information on the dashboard in august 2016 .

moreover , omb guidance includes a series of performance metrics in the areas of data center closures , cost savings , and optimization progress .

data center closures: agencies are expected to close at least 25 percent of tiered data centers government - wide , excluding those approved as inter - agency shared services providers , by the end of fiscal year 2018 .

further , agencies are to close at least 60 percent of non - tiered data centers government - wide by the end of fiscal year 2018 .

omb's guidance further notes that , in the long term , all agencies should continually strive to close all non - tiered data centers , noting that server rooms and closets pose security risks and management challenges and are an inefficient use of resources .

cost savings: agencies are expected to reduce government - wide annual costs attributable to physical data centers by at least 25 percent , resulting in savings of at least $2.7 billion , by the end of fiscal year 2018 .

data center optimization: agencies are expected to measure progress against a series of new data center performance metrics in the areas of server utilization , energy metering , power usage , facility utilization , and virtualization .

further , omb's guidance establishes target values for each metric that agencies are to achieve by fiscal year 2018 .

to improve the measurement of data center optimization progress , omb's memorandum directs agencies to replace the manual collection and reporting of systems , software , and hardware inventory housed within data centers with automated monitoring , inventory , and management tools ( eg , data center infrastructure management ) by the end of fiscal year 2018 .

according to omb , these data center tools ( henceforth referred to as “automated monitoring tools” ) are to provide the capability to , at a minimum , measure progress toward server utilization and virtualization metrics .

while implementation of automated monitoring tools is not required to be completed until the end of fiscal year 2018 , the memorandum strongly encourages agencies to implement them throughout their data centers immediately .

while omb is primarily responsible for dcoi , its august 2016 memorandum designated the general services administration's ( gsa ) office of government - wide policy as a managing partner of the federal government data center line of business and data center shared services .

more specifically , omb's memorandum states that this office is responsible for , among other things , providing guidance on technology advancements , innovation , cybersecurity , and best practices to data center providers and consumers of data center services .

further , the memorandum states that the office is responsible for assisting with creating and maintaining an inventory of acquisition tools and products related to data center optimization , including procurement vehicles for the acquisition of automated monitoring tools .

from july 2011 through may 2017 , we issued a number of reports and testified on agency efforts to consolidate and optimize federal data centers and achieve cost savings .

for example , in september 2014 , we reported that , while agencies had made progress on their consolidation efforts , the total number of data centers reported by agencies had continued to grow since 2011 as a result of omb's expanded definition and improved inventory reporting .

more specifically , we determined that agencies had collectively reported 9,658 data centers in their inventories — an increase of about 6,500 compared to omb's previous estimate from december 2011 .

we noted that agencies had plans to close about 3,700 data centers by september 2015 .

we also reported that 19 of the 24 fdcci agencies had collectively reported achieving an estimated $1.1 billion in cost savings for fiscal years 2011 through 2013 , and that , by 2017 , that figure was estimated to rise to about $5.3 billion .

however , we pointed out that planned savings may be higher because 6 agencies — the departments of health and human services ( hhs ) , interior ( interior ) , justice ( justice ) , and labor ( labor ) , gsa , and the national aeronautics and space administration ( nasa ) — that reported closing as many as 67 data centers had also reported limited or no savings .

in addition , our 2014 report noted that 11 of the 21 agencies with planned cost savings had underreported their fiscal years 2012 through 2015 figures to omb by approximately $2.2 billion .

while several agencies noted communication issues as the reason for underreporting , others did not provide a reason .

we concluded that , until agencies fully report their savings , the $5.3 billion in total savings would be understated .

further , we reported that omb's may 2014 data center optimization metrics did not address server utilization , even though omb reported this to be as low as 5 percent across the federal government in 2009 .

we noted that , without this metric , omb may lack important information on agencies' progress .

as a result , we recommended that it implement a metric for server utilization and assist six agencies in reporting their consolidation cost savings ; we also recommended that agencies fully report their consolidation cost savings .

omb and the agencies to which we made recommendations generally agreed with them .

omb subsequently established a metric to measure agencies' server utilization progress in its august 2016 memorandum .

in march 2016 , we reported that agencies had continued to make progress in their data center consolidation efforts .

specifically , we noted that agencies had reported closing 3,125 of the 10,584 total data centers as of november 2015 .

we further noted that 19 of the 24 agencies had reported achieving an estimated $2.8 billion in cost savings and avoidances from their data center consolidation and optimization effort for fiscal years 2011 through 2015 .

agencies were also planning an additional $5.4 billion in cost savings and avoidances , for a total of approximately $8.2 billion , through fiscal year 2019 .

however , we noted that planned savings may be higher because 10 agencies that reported planned closures from fiscal years 2016 through 2018 had not fully developed their cost savings goals for these fiscal years .

in addition , we reported that 22 agencies had made limited progress against omb's fiscal year 2015 data center optimization performance metrics , such as the utilization of data center facilities .

accordingly , we recommended that the agencies take actions to complete their cost savings targets and improve optimization progress .

most agencies agreed with the recommendations or had no comments .

finally , in may 2017 , we reported that agencies continued to consolidate their data centers , including closing 4,388 of the 9,995 total data centers as of august 2016 .

figure 2 provides a summary of the total number of data centers and closures reported from 1998 through august 2016 .

however , we pointed out that agency progress in achieving savings had slowed and planned goals had been reduced .

specifically , 18 of the 24 agencies had reported achieving an estimated $2.3 billion in cost savings and avoidances from their data center consolidation and optimization efforts from the start of fiscal year 2012 to august 2016 , which was about $451 million less than the total amount of achieved cost savings and avoidances that agencies reported to us in november 2015 .

in addition , agencies' total planned cost savings of about $633 million were more than $3.4 billion less compared to the amounts that agencies reported to us in november 2015 , and more than $2.1 billion less than omb's fiscal year 2018 cost savings goal of $2.7 billion .

our may 2017 report also identified weaknesses in agencies' dcoi strategic plans .

of the 23 agencies that submitted their strategic plans at the time of our review , 7 — the departments of agriculture ( agriculture ) , education ( education ) , homeland security ( dhs ) , and housing and urban development ( hud ) ; gsa ; the national science foundation ( nsf ) ; and the office of personnel management ( opm ) — had addressed all five required elements of a strategic plan , as identified by omb ( such as providing information related to data center closures and cost savings metrics ) .

the remaining 16 agencies either partially met or did not meet the requirements .

we also pointed out that there were inconsistencies in the reporting of cost savings in the strategic plans of 11 agencies .

we concluded that , until agencies address the weaknesses in their dcoi strategic plans , they may be challenged in implementing the data center consolidation and optimization provisions of fitara .

accordingly , we recommended that omb improve its oversight of agencies' dcoi strategic plans and their reporting of cost savings and avoidances .

we also recommended that 17 agencies complete the missing elements in their strategic plans and that 11 agencies ensure the reporting of consistent cost savings and avoidance information to omb .

twelve agencies agreed with our recommendations , 2 disagreed , and 11 did not state whether they agreed or disagreed .

the 2 agencies that disagreed — hud and the nuclear regulatory commission ( nrc ) — asserted that they had submitted complete strategic plans .

after further review , we agreed that hud had provided a complete plan and removed our recommendation .

however , we determined that nrc's plan was still incomplete and maintained that our recommendation was appropriate .

as mentioned earlier , fitara required omb to establish metrics to measure the optimization of data centers , including server efficiency , and ensure that agencies' progress toward meeting the metrics is made publicly available .

pursuant to fitara , omb's august 2016 memorandum established a set of five data center optimization metrics intended to measure agency's progress in the areas of server utilization and automated monitoring , energy metering , power usage effectiveness , facility utilization , and virtualization .

according to omb , the server utilization and automated monitoring metric applies to agency - owned tiered and non - tiered data centers , while the four remaining metrics apply to agency - owned tiered centers only .

omb's memorandum also established a target value for each of the five metrics , which agencies are expected to achieve by the end of fiscal year 2018 .

omb measures agencies' progress against the optimization targets using the agencies' quarterly data center inventory submission and publicly reports this progress information on its dashboard .

table 1 provides a description of the data center optimization metrics and target values that agencies are expected to achieve by the end of fiscal year 2018 .

as of february 2017 , 22 of the 24 dcoi agencies reported limited progress against omb's fiscal year 2018 data center optimization targets on the dashboard .

the remaining 2 agencies — education and hud — reported that they did not have any agency - owned data centers in their inventory and , therefore , did not have a basis to measure and report optimization progress .

with regard to the data center optimization targets , the most progress was reported for the power usage effectiveness and virtualization metrics , with 5 agencies reporting that they had met omb's targets .

however , 2 agencies or less reported meeting the target for energy metering , facility utilization , and server utilization and automated monitoring .

figure 3 summarizes the 24 agencies' progress in meeting each optimization target , as of february 2017 .

following the figure is a more detailed discussion of the progress of each of the 24 agencies .

among the 24 agencies , ssa and epa reported the most progress by meeting three targets , 20 reported meeting one or none of the targets , and the remaining 2 agencies did not have a basis to report on progress because they did not have any agency - owned data centers .

of the 22 agencies reporting progress information , 9 were not able to report progress against either the server utilization metric or power usage effectiveness metric , or both , because they lacked the required monitoring tools to measure progress in these areas .

omb began requiring the implementation of these monitoring tools in august 2016 ; however , as of february 2017 , these 9 agencies were not yet reporting implementation of the tools at any of their data centers .

this issue is discussed in greater detailed later in this report .

table 2 lists the agencies that met or did not meet each omb target .

agencies' limited progress against omb's optimization targets is due , in part , to them not fully addressing our prior recommendations in this area .

as noted earlier , in march 2016 , we reported on weaknesses in agencies' data center optimization efforts , including that 22 agencies did not meet omb's fiscal year 2015 optimization targets .

we noted that this was partially due to the agencies facing challenges in optimizing their data centers , including their decentralized organizational structures that made consolidation and optimization difficult and competing priorities for resources .

in addition , consolidating certain data centers was problematic because the volume or type of information involved required the data center to be close in proximity to the users .

accordingly , we recommended that the agencies take action to improve optimization progress , to include addressing any identified challenges .

most agencies agreed with our recommendations or had no comments .

in response to our recommendation , 19 of the 22 agencies submitted corrective action plans to us that described steps they intended to take to improve their data center optimization efforts .

among these steps were developing internal scorecards to track and report on optimization progress , including progress at their component agencies , and launching more aggressive efforts to optimize data centers using virtualization and cloud computing solutions .

while 2 of the 22 agencies — education and hud — are no longer subject to omb's optimization metrics based on omb's august 2016 memorandum and their current data center inventory , none of the remaining 20 agencies had fully addressed our recommendation as of may 2017 .

the importance of overcoming optimization challenges and addressing our prior recommendations is critical to the ability of agencies to implement the data center optimization provisions of fitara and achieve omb's fiscal year 2018 optimization targets .

going forward , it will be important for the 19 agencies that have established corrective action plans to continue to execute them and monitor the impact of actions completed on their optimization progress .

until agencies fully implement our prior recommendations to address their challenges and improve optimization progress , they may be hindered in implementing the data optimization provisions of fitara and omb guidance intended to increase operational efficiency and achieve cost savings .

further , omb may be challenged in demonstrating that dcoi is meeting its established objectives .

in addition to reporting current optimization progress on the dashboard , omb requires agencies' dcoi strategic plans to include , among other things , planned performance levels for fiscal years 2017 and 2018 for each optimization metric .

however , according to the 24 agencies' dcoi strategic plan information as of april 2017 , most are not planning to meet omb's optimization targets by the end of fiscal year 2018 .

more specifically , of the 24 agencies , 5 — the department of commerce ( commerce ) , epa , nsf , the small business administration ( sba ) , and the u.s. agency for international development ( usaid ) — reported plans to fully meet their applicable targets by the end of fiscal year 2018 ; 13 reported plans to meet some , but not all , of the targets ; 4 reported that they do not plan to meet any targets ; and 2 do not have a basis to report planned optimization milestones because they do not report having any agency - owned data centers .

figure 4 summarizes agencies' progress in meeting omb's optimization targets as of february 2017 , and planned progress to be achieved by september 2017 and september 2018 , as of april 2017 .

agencies' reported plans to meet the optimization targets also vary by metric .

specifically , about half of the 22 agencies reported plans to meet the facility utilization and virtualization metrics by the end of fiscal year 2018 , while less than half are planning to meet the server utilization and automated monitoring , energy metering , and power usage effectiveness metrics .

further , agencies reported that they plan to make the least amount of progress in meeting the target for power usage effectiveness .

figure 5 provides a summary , by optimization metric , of agencies' current progress in meeting the targets as of february 2017 , and planned progress to be achieved by september 2017 and september 2018 , as of april 2017 .

the limited progress made by agencies in optimizing their data centers , combined with the lack of established plans to improve progress , makes it unclear whether agencies will be able to achieve omb's optimization targets by the end of fiscal year 2018 .

considering that omb is expecting at least $2.7 billion in cost savings from agencies' optimization efforts , the ability of agencies to meet the optimization targets will be critical to meeting this savings goal .

however , with less than 2 years remaining until omb's fiscal year 2018 dcoi optimization target deadline and the expiration of the data center consolidation and optimization provisions of fitara in october 2018 , only five agencies are planning to meet all of their applicable targets .

with the majority of agencies not planning to meet the optimization targets , there is an increased likelihood that agencies will need more time beyond 2018 to continue to implement their optimization efforts .

extending the data center consolidation and optimization provision of fitara beyond the current october 2018 horizon could provide agencies with additional time to realize the benefits of optimization , including cost savings .

the 24 dcoi agencies reported successes in optimizing their data centers — notably , the benefits of key technologies , such as virtualizing systems to improve performance , and increased energy efficiency .

however , agencies also reported operational , technical , and financial challenges related to , for example , improving the utilization of their data center facilities , measuring server utilization , and obtaining funding within their agency for optimization efforts .

it will be important for agencies to take action to address their identified challenges — as we previously recommended — in order to improve data center optimization progress .

agencies reported a variety of successes in optimizing data centers .

specifically , the 24 agencies reported a total of 23 areas of success .

eight areas of successes were identified by three or more agencies , with the most reported successes for an area being identified by 17 agencies .

the two most reported areas of success — implementing virtualization technologies and migrating it applications and services to cloud computing solutions — were similar to the top reported success in achieving consolidation cost savings that we identified in 2014 ( i.e. , focusing on virtualization and cloud services as consolidation solutions ) .

agencies are also continuing to report successes in other areas that we highlighted in 2014 , including improved energy efficiency , standardized technology , and improved data center inventory reporting .

table 3 details the reported areas of success , as well as the number of related agencies .

the most common areas of success are further discussed after the table .

seventeen agencies reported that implementing virtualization technologies ( i.e. , running multiple , software - based machines with different operating systems on the same physical machine ) has proven successful in optimizing their data centers .

for example , officials from commerce's office of the cio stated that the department had made the most notable optimization progress in virtualizing all non - high performance computing servers , including approximately 11,700 operating systems ( as of october 2016 ) .

additionally , officials from labor's office of the cio noted that virtualization had helped the department create a highly efficient , lower cost , common operating environment suitable for hosting mission - critical applications and services .

the officials added that the department expects to significantly increase its migration activity and closures in fiscal years 2017 and 2018 by leveraging the portability of this highly virtualized environment .

as another example , officials from gsa's it office stated that the agency has achieved success in retiring older physical systems and shifting to newer , virtualized technologies .

the officials stated that these actions have contributed to greater flexibility , stability , and redundancy in the agency's it capabilities .

further , officials from nrc's office of the cio stated that their agency had virtualized 72 percent of its servers , which allowed the agency to significantly reduce the amount of old , outdated , and energy - inefficient equipment .

thirteen other agencies also stated that implementing virtualization technologies had led to successes in optimizing their data centers .

thirteen agencies reported that migrating it applications and services to cloud computing solutions had led to successes in optimizing their data centers .

for example , officials from hhs's office of the cio stated that one of the department's offices had realized substantial value with the use of cloud - provided solutions , including reducing the cost of data center services by approximately 15 percent compared to government and on - premises data centers .

additionally , officials from nsf's office of information and resource management stated that the agency successfully reduced and streamlined its it footprint through a number of different efforts , such as migration of applications , e - mail , and instant messaging to cloud providers ; networking technology standardization ; and server and storage consolidation .

as another example , officials from usaid's office of the cio stated that in 2011 the agency transformed and migrated its primary data center to a private infrastructure cloud provider , thereby eliminating physical infrastructure issues ( eg , power , heating , ventilation , air conditioning , and physical security issues ) .

the officials added that the cloud solution provided the data center infrastructure , network access , connectivity , and other services needed to ensure the delivery of critical business services .

further , officials from interior's office of the cio stated that the department had migrated 70,000 users off of 14 legacy e - mail systems to a single department - wide cloud - based e - mail communications and collaboration system .

nine other agencies also stated that migrating to cloud computing solutions led to successes in optimizing their data centers .

their reported successes ranged from migrating e - mail applications to the cloud solutions to responding more timely to shifts in user demand .

five agencies reported that increasing their energy efficiency had led to success in optimizing their data centers .

for example , officials from the department of state's ( state ) bureau of information resource management noted that the department has had success in deploying modular data centers that utilize energy - efficient power systems and other optimized operating features that help to reduce the department's carbon footprint .

further , a program manager from the ssa's office of hardware engineering stated that the agency had improved its energy efficiency and reduced its carbon footprint through various initiatives including , among other things , rainwater reclamation , improved monitoring of it equipment power usage , energy - efficient lighting , and the use of solar panels .

figure 6 shows the use of solar panels at the ssa's national support center .

additionally , officials from epa's office of environmental information stated that the agency had success in improving energy efficiency through the purchase of energy efficient it equipment and by including energy metering in data center facilities planning and buildout to assist with validating energy optimization metrics .

the officials also noted that the agency had increased the operating temperature in some data centers as well as used alternate methods of cooling ( eg , outdoor air to cool its data centers ) , which helped the agency improve its energy efficiency .

officials from commerce and hhs further stated that increasing their energy efficiency by , for example , purchasing energy - efficient equipment and deploying power monitoring equipment , had led to successes in optimizing their data centers .

agencies also reported facing a variety of challenges in optimizing their data centers .

specifically , the 24 dcoi agencies identified a total of 27 types of challenges across three areas: operational , technical , and financial .

the highest number of challenges were reported in the operational and technical areas , which included improving data center facility utilization and measuring and reporting on server utilization .

certain challenges reported were similar to those described to us by agencies in 2016 , including those related to competing priorities for labor resources and closing data centers that provide mission critical applications that require proximity to users .

agencies also continued to report operational , technical , and financial challenges that were similar to those described to us in 2014 , including gathering data from component agencies , determining power usage information , and obtaining funding from within their agency .

for example , in 2014 , six agencies noted that gathering data from component agencies was an operational challenge to achieving consolidation cost savings ; however , only two agencies are now reporting that as a challenge in optimizing their data centers .

agencies also cited many new challenges that are specific to optimizing their data centers , such as incorporating enterprise - wide efficiencies when data centers are owned and managed by multiple organizations and the significant upfront costs required to purchase data center monitoring tools .

table 4 details the reported challenges in optimizing data centers , as well as the number of related agencies .

the most common challenges are further discussed after the table .

agencies reported the most operational challenges in the following areas: improving data center facility utilization ; competing priorities for labor resources with other agency it efforts ; shifting definitions of a data center and changes to data center optimization requirements ; and incorporating enterprise - wide efficiencies when data centers are owned and managed by multiple organizations .

improving data center facility utilization: nine agencies cited this challenge .

for example , officials from the department of veterans affairs' ( va ) infrastructure operations stated that increasing virtualization generally reduces the number of active server racks in the space and , therefore , decreases facility utilization .

the officials added that , for smaller rooms that are part of a larger , agency - owned , multi - functional facility , reducing the size of the room is most often not an economical decision , as it does not lead to energy savings or reduced facility costs but , instead , moves the recurring cost of the space from it to other functions .

officials from dhs , interior , labor , and nrc also reported that their increased use of virtualization has negatively impacted their ability to increase facility utilization .

as another example of a challenge in improving facility utilization , officials from commerce's office of the cio stated that the national oceanic and atmospheric administration's weather field office data centers contain systems that are proprietary and connect to local weather sensing instruments or satellite communication equipment .

the officials said that most of these data centers are averaging only 50 percent facility utilization and have no plans to increase , but are difficult to close because they contain systems designed specifically for the agency's mission .

officials from agriculture , gsa , nasa , and the department of the treasury ( treasury ) also cited challenges in improving facility utilization .

competing priorities for labor resources with other agency it efforts: six agencies cited this challenge .

for example , officials from commerce's office of the cio stated the census bureau is ramping up for a very large program — the 2020 decennial census — while also working to optimize its data centers .

this has led to challenges in implementing data center infrastructure management tools and replacing old power distribution units with new ones .

as another example , officials from epa's office of environmental information noted that it personnel are primarily focused on day - to - day operations and maintenance activities and , therefore , resources normally used to support data center activities are periodically pulled away to address more immediate operational activities ( such as cybersecurity initiatives ) .

in addition , sba's cio stated that the biggest challenge faced by the agency is a lack of labor resources , which has historically been due to a focus on mission priorities instead of data center improvements .

officials from gsa , labor , and transportation also stated that completing priorities for labor resources has been a challenge to optimizing their data centers .

shifting definition of a data center and changes to data center optimization requirements: five agencies cited this challenge .

for example , officials from interior's office of the cio stated that significant changes outlined in omb's august 2016 memorandum and previously issued guidance related to the definitions of a data center and optimization metrics presented challenges in maintaining inventories , measuring progress , and assessing cost savings and avoidances .

as another example , officials from energy's office of the cio stated that energy's unique computing environments , which support scientific research , facility and plant operations , power management , and mission - specific computing , makes aligning with omb's data center definition difficult .

in addition , officials from dhs's office of the cio stated that omb's recent changes to the data center optimization metrics , including the focus on agency - owned data centers , greatly impacted the department's ability to report on optimization progress .

more specifically , the officials stated that omb's prior optimization metrics focused on the department's three core data centers ( i.e. , primary consolidation points ) ; however , under omb's new metrics , the department's core data centers are no longer applicable to the metrics because they are not agency - owned .

the officials added that this negatively impacted the department's ability to report optimization progress related to power usage effectiveness .

officials from gsa and nrc also cited challenges related to the change in the definition of a data center and data center optimization requirements .

incorporating enterprise - wide efficiencies for data centers owned and managed by multiple organizations: five agencies identified this challenge .

for example , officials from nasa's office of the cio stated that , historically , the agency's data centers have been owned and managed by multiple organizations , including contractors , which has made it challenging to incorporate enterprise - enabled efficiencies ( i.e. , common procurements , implementation of standard hardware , software , and management tools ) .

the officials also mentioned that the extensive use of data centers collocated within multi - use buildings , with shared electrical and mechanical infrastructure , has resulted in the agency not realizing the magnitude of savings that would be attributed to the closure of stand - alone data center facilities .

as another example , officials in energy's office of the cio stated that the implementation of optimization solutions in data centers that are mission and research specific , or have unique operational and environmental requirements , has presented operational challenges .

in addition , officials from justice's office of the cio stated that implementing enterprise solutions across a large and traditionally federated organization has been challenging .

officials from dhs and labor also cited challenges with improving optimization at data centers that are owned and managed by multiple organizations .

agencies reported the most technical challenges in the following areas: measuring and reporting on server utilization progress , a lack of electricity metering to determine power usage information , and poor network connectivity and low bandwidth at field locations constraining consolidation and optimization efforts .

measuring and reporting on server utilization progress: nine agencies cited this challenge .

for example , officials from va's infrastructure operations cited challenges with the complexity of programming the tools needed to collect the data to measure server utilization .

in particular , the officials noted issues in delineating what data should be collected to determine server “busy” and “idle” times ( eg , computer processing unit usage , power consumption , or other data ) and what unit of time to associate with the data collection ( i.e. , seconds , minutes , hours , etc. ) .

in order to be able to report on the server utilization metric .

as another example , officials from justice's office of the cio stated that optimizing the server utilization of department data centers that are consolidation points will be extremely difficult because the environments are going through significant changes as they receive servers from other locations .

in addition , officials from treasury's office of the cio stated that , while the department's servers have the ability to measure and monitor processing usage , most data centers do not have the ability to centrally aggregate and report on that data .

officials from agriculture , the department of defense ( defense ) , labor , nasa , opm , and treasury also cited challenges in measuring and reporting on server utilization progress .

lack of electricity metering to determine power usage information: seven agencies identified this challenge .

for example , officials from commerce's office of the cio stated that many of the department's data centers are small and lack separate power metering .

the officials added that , rather than adding power monitoring to each small data center , the department needs to conduct further research to evaluate whether consolidation of these unmetered data centers into a few larger well - maintained data centers is more cost effective .

as another example , officials from labor's office of the cio stated that a vast majority of the department's data centers are in modified office spaces that also serve other purposes , such as accommodating the storage of legacy it assets and providing a workspace for it support personnel , which has made the installation of power metering challenging .

further , officials from va's infrastructure operations stated that the department's individual data centers are largely unique , thus requiring detailed engineering to determine how to retrofit energy metering solutions to provide the data necessary for energy usage optimization , particularly without incurring critical it system downtime .

the officials added that the majority of the department's data centers are not stand - alone data centers , but rather , are rooms within a medical center facility or other multi - purpose facility that were not constructed to facilitate power metering .

va officials stated that these challenges made measuring power usage effectiveness extremely complicated , time - consuming , and costly .

agriculture , labor , opm , and sba also mentioned challenges related to the lack of electricity metering to determine power usage information .

poor network connectivity and low bandwidth at field locations constrains consolidation and optimization efforts: five agencies cited this challenge .

for example , officials from interior's office of the cio stated that numerous remote field offices within the department experience poor network connectivity and low bandwidth to support running remotely - hosted applications .

the officials added that the risk of reduced service levels at these remote locations is frequently cited as a constraint on consolidation and a challenge to improving optimization progress .

as another example , transportation's office of the cio noted challenges with consolidating field site servers because the telecommunication bandwidth to the field sites is lacking .

officials from hhs , labor , and sba also cited concerns about connectivity performance issues as a challenge to consolidation and optimization of data centers at their field office locations .

agencies reported three financial challenges in the following areas: obtaining the funding within their agency for optimization efforts , the upfront costs required to purchase the monitoring tools needed to measure optimization progress , and determining the resulting cost savings and avoidances .

obtaining the funding within their agency for optimization efforts: ten agencies cited this challenge .

for example , officials from opm's office of the cio stated that while the agency's base budget includes ongoing operations and maintenance funding for the agency's existing data centers , the availability of financial resources during fiscal years 2017 and 2018 would be one of the most significant challenges to improving data center optimization performance , and satisfying dcoi requirements .

further , officials from justice's office of the cio stated that financial constraints may limit the funding available for migration of component infrastructure to cloud computing services or the department's core enterprise facilities , which could delay or prevent optimization .

as another example , officials from defense's office of the cio stated that resource constraints to support application and system rationalization , re - engineering , and migration , forced many component agencies to focus on physical relocations of systems , which limit data center optimization opportunities and savings .

officials from commerce , dhs , energy , hhs , labor , sba , and transportation also cited challenges in obtaining the funding within their agency for optimization efforts .

significant upfront costs required to purchase the monitoring tools needed to measure optimization progress: eight agencies cited this challenge .

for example , officials from treasury's office of the cio stated that the department is currently in the process of evaluating how to most effectively meet data center power metering requirements without incurring significant expenditures .

the officials stated that several of their larger data centers are in older , multi - use buildings and share a cooling infrastructure with the entire building .

the officials added that measuring the energy consumed by the portions of the building dedicated to hosting it equipment would require meters to be installed within just those spaces dedicated to it , which is a significant cost that is being evaluated relative to other mission - oriented investments .

as another example , officials from interior's office of the cio stated that the investment for purchasing data center optimization tools would require a reallocation of funds from the department's fiscal years 2017 and 2018 budgets and would have an adverse effect on meeting other higher priority requirements , such as cybersecurity requirements .

further , the officials stated that purchasing and deploying energy metering tools in the department's smaller data centers would result in a negative return on investment .

in addition , officials from va's infrastructure operations stated that the department's data centers are largely unique and require detailed engineering to determine how to retrofit metering solutions to provide data necessary for energy usage optimization , which has not yet been funded .

officials from agriculture , commerce , defense , gsa , and state also cited significant upfront costs of data center monitoring tools as a challenge .

determining the resulting cost savings and avoidances from consolidation and optimization efforts: five agencies identified this challenge .

for example , officials from nasa's office of the cio stated that due to their extensive use of data centers collocated within multi - use buildings , with shared electrical and mechanical infrastructure , the agency has not realized the magnitude of savings that would be attributed to the closure of stand - alone data center facilities .

the officials added that , in most instances , the closed data center spaces have been locally repurposed for non - it use .

as another example , officials from agriculture's office of the cio stated that it can be difficult to determine facility costs and the resulting cost savings and avoidances .

the officials noted that data centers located within government owned or leased buildings usually do not pay for electricity , heating and air conditioning expenses , or lease and facility upkeep costs , which can present challenges in calculating any cost savings and avoidances from optimization .

officials from gsa , interior , and treasury also cited challenges in determining the resulting cost savings and avoidances from their consolidation and optimization efforts .

addressing these optimization challenges and others — as we previously recommended in 2016 — is increasingly important in light of fitara's requirements , which direct agencies to establish a multi - year strategic plan to improve data center optimization progress .

until agencies address these challenges , they could be hindered in the implementation of their data center optimization strategic plans and in making initiative - wide progress against omb's optimization targets .

as noted earlier , fitara required omb to establish data center consolidation and optimization metrics , including a metric specific to measuring server efficiency ; it also required agencies to report on progress in meeting the metrics .

pursuant to fitara , omb's august 2016 memorandum required agencies to measure and report on server utilization progress , including the number of agency - owned data centers fully equipped with automated monitoring tools and their server utilization percentages .

to effectively measure progress against this metric , omb's memorandum also directed agencies to immediately begin replacing the manual collection and reporting of systems , software , and hardware inventory housed within agency - owned data centers with automated monitoring tools and to complete this effort no later than the end of fiscal year 2018 .

agencies are required to report progress in implementing automated monitoring tools and server utilization averages at each data center as part of their quarterly data center inventory reporting to omb .

finally , standards for internal control emphasize the need for federal agencies to establish plans to help ensure goals and objectives can be met , including compliance with applicable laws and regulations .

as of february 2017 , 4 of the 22 agencies reporting agency - owned data centers in their inventory — nasa , nsf , ssa , and usaid — reported that they had implemented automated monitoring tools at all of their data centers .

further , 10 reported that they had implemented automated monitoring tools at between 1 and 57 percent of their centers , and 8 had not yet begun to report the implementation of these tools .

in total , the 22 agencies reported that automated tools were implemented at 123 ( or about 3 percent ) of the 4,528 total agency - owned data centers , while the remaining 4,405 ( or about 97 percent ) of these data centers were not reported as having these tools implemented .

table 5 provides a listing of the number and related percentage of agency - owned data centers reported by agencies as having automated monitoring tools implemented .

of the 123 data centers reported as having automated monitoring tools implemented , 59 were identified as tiered data centers and 64 as non - tiered data centers .

figure 7 summarizes the number of agency - owned data centers reported with automated monitoring tools installed , including the number of tiered and non - tiered centers .

the limited implementation of automated monitoring tools resulted in incomplete information on server utilization percentages .

as noted earlier , omb's it dashboard is used to publicly report on agencies' progress in measuring server utilization .

this progress information is obtained from agencies' quarterly data center inventory submissions , which are required to include detailed data on the server utilization averages of each tiered and non - tiered data center .

based on agencies' february 2017 data center inventory data , 4 of the 22 agencies reported a server utilization average for all of their monitored tiered and non - tiered data centers , 10 reported server utilization averages at a portion of their centers , and 8 did not report this information .

ssa reported the highest server utilization average of 100 percent at its one agency - owned tiered data center , while gsa reported the lowest percentage of 9 percent across its 31 agency - owned tiered and non - tiered centers with automated monitoring tools installed .

according to our analysis of agencies' inventory data , the average server utilization across all 123 data centers with automated monitoring tools installed was about 28 percent , which is approximately 37 percent below omb's fiscal year 2018 goal of 65 percent or higher .

figure 8 shows the agency - reported server utilization averages for the 4 agencies that reported this information at all their data centers and the 10 agencies that reported this information at a portion of their centers , as well as the percentage of their agency - owned data centers with automated monitoring tools installed .

for the 18 agencies that did not report server utilization average information at all their data centers , none fully documented plans to implement the automated monitoring tools required to measure this information at all their agency - owned tiered and non - tiered centers by the end of fiscal year 2018 .

more specifically , our analysis of agencies' dcoi strategic plans , fitara implementation milestones , and other documentation ( such as project plans and charters ) showed that 6 of the 18 agencies — agriculture , energy , epa , gsa , state , and va — partially documented plans because they addressed implementing automated monitoring tools for only a portion of their data centers .

however , these agencies did not address implementing such tools at all tiered and non - tiered agency - owned data centers , as required by omb .

the remaining 12 agencies did not document plans to implement automated monitoring tools .

table 5 provides an assessment of agencies' documented plans to implement data center automated monitoring tools .

the 18 agencies provided a variety of reasons regarding why they had not established a plan to implement automated monitoring tools at all agency - owned data centers .

for example , officials at six agencies ( defense , dhs , epa , gsa , labor , and justice ) stated that they were in the process of establishing a plan to implement automated monitoring tools , but had not yet completed it .

as another example , agency officials from state's bureau of information resource management and nrc's office of the cio noted that they were still evaluating options for purchasing and deploying these tools .

further , officials from opm's office of the cio and transportation's office of the cio stated that they were still determining the extent to which their data centers had automated monitoring tools installed .

lastly , officials from commerce's office of the cio stated the department had no specific plans to invest in automated monitoring tools .

the lack of detailed plans to implement automated monitoring tools at all agency - owned data centers is also due , in part , to omb not having established a formal requirement to document such plans .

although omb's august 2016 memorandum required agencies to submit a dcoi strategic plan by september 30 , 2016 , and to update it by april 14 , 2017 , these plans were not required to include detailed information describing how the agency was planning to meet omb's requirement to implement automated monitoring tools at all agency - owned tiered and non - tiered centers .

recognizing this issue , omb staff from the office of the federal cio stated that they have been advising agencies to include these more detailed plans and milestones for implementing data center automated monitoring tools as part of their publicly available fitara implementation milestones .

however , omb has not established a formal requirement in its data center guidance or fitara implementation guidance provided to agencies .

as mentioned previously , our analysis of agency's fitara implementation milestones showed that most agencies were not aware of omb's request to include this information .

until omb requires agencies to include detailed plans to implement automated monitoring tools in their fitara implementation milestones , agencies may continue to lack a roadmap to meet a key dcoi goal .

further , until agencies complete their plans , they may be challenged in implementing the tools needed to effectively measure server utilization — a data center optimization area highlighted in fitara , and that we previously reported as being critical to improving the efficiency , performance , and environmental footprint of federal data center activities .

with the august 2016 launch of dcoi , omb took a considerable step forward in providing guidance for the implementation of the data center consolidation and optimization requirements of fitara and increasing the oversight of agencies' efforts to optimize their data centers .

omb's fiscal year 2018 optimization targets provide clear and transparent goals for agencies' optimization efforts ; however , agencies reported limited progress against those targets .

additionally , although agencies' dcoi strategic plans provide a mechanism for agencies to report planned fiscal years 2017 and 2018 milestones toward achieving omb's optimization targets , most agencies reported that they are not planning to meet omb's targets by the end of fiscal year 2018 .

considering that omb established a dcoi - wide savings goal of $2.7 billion , the ability of agencies to meet the optimization targets will be critical to achieving these savings .

extending the time frame for the agencies to meet the required data center consolidation and optimization provisions of fitara beyond october 2018 could provide agencies with additional time to achieve the benefits of optimization .

in addition , agencies' implementation of our prior recommendations to address optimization challenges and improve progress could help ensure that they are better positioned to meet key dcoi goals .

as a result of omb's increased focus on data center optimization beginning in 2013 and its more recent efforts to launch dcoi , agencies have reported noteworthy successes in optimizing their data centers — particularly in leveraging virtualization and cloud computing as a means to optimize their data centers .

these constructive experiences indicate that dcoi is moving in the right direction .

however , as agencies work toward achieving omb's fiscal year 2018 optimization targets , many are reporting challenges related to improving data center facility utilization , measuring and reporting on server utilization progress , and obtaining the funding within their agency for optimization efforts .

such a dynamic environment reinforces the need for agencies to address their identified challenges — as we previously recommended — in order to improve data center optimization progress .

omb's efforts to establish a metric to measure server utilization as part of its august 2016 memorandum were consistent with our 2014 recommendation and an important step toward ensuring that agency computing resources are being used more efficiently .

additionally , omb's requirement that agencies implement automated monitoring tools at their data centers by the end of fiscal year 2018 will help to ensure that they have the necessary foundation in place to effectively measure and report on server utilization progress .

however , with agencies collectively reporting that these tools are only installed at about 3 percent of the total data centers and with 18 agencies lacking complete plans to implement these tools at their remaining data centers , significant work remains toward meeting omb's requirement .

the lack of a formal omb requirement to establish detailed plans in this area and report them to omb further increases the likelihood that agencies will continue to lack them .

in the absence of such a requirement and completed plans , agencies will be missing an important roadmap for implementing the automated monitoring tools needed to measure server utilization — an area that both we and omb have reported as critical to improving the efficiency , performance , and environmental footprint of federal data center activities .

moreover , with automated monitoring tools not required by omb to be fully implemented by agencies until the end of fiscal year 2018 , extending the time frame of fitara's data center consolidation and optimization provisions could also better ensure that server utilization is effectively measured and reported beyond fiscal year 2018 , after the necessary monitoring tools are implemented .

as most agencies lack plans to meet omb's data center optimization targets by the end of fiscal year 2018 , it is increasingly likely that these agencies will require additional time to achieve the data center consolidation and optimization goals required by fitara and omb guidance .

in order to provide agencies with additional time to meet omb's data center optimization targets and achieve the related cost savings , congress should consider extending the time frame for the data center consolidation and optimization provisions of fitara beyond their current expiration date of october 1 , 2018 .

to better ensure that agencies complete important dcoi planning documentation and that the initiative improves governmental efficiency and achieves intended cost savings , we are recommending that the director of omb direct the federal cio to formally document a requirement for agencies to include plans , as part of existing omb reporting mechanisms , to implement automated monitoring tools at their agency - owned data centers .

we are also recommending that the secretaries of agriculture , commerce , defense , homeland security , energy , hhs , interior , labor , state , transportation , treasury , and va ; the attorney general of the united states ; the administrators of epa , gsa , and sba ; the director of opm ; and the chairman of nrc take action to , within existing omb reporting mechanisms , complete plans describing how the agency will achieve omb's requirement to implement automated monitoring tools at all agency - owned data centers by the end of fiscal year 2018 .

we received comments on a draft of this report from omb and the 24 agencies that we reviewed .

of the 19 agencies to which we made recommendations , 10 agencies agreed with our recommendations , 3 ( defense , interior , and opm ) partially agreed , and 6 ( including omb ) did not state whether they agreed or disagreed .

in addition , 6 agencies to which we did not make recommendations stated that they had no comments .

multiple agencies also provided technical comments , which we have incorporated as appropriate .

the following discusses the comments from each agency to which we made a recommendation .

in an e - mail received on july 7 , 2017 , a staff member from omb's office of general counsel stated that the agency had no comments on the draft report .

the staff member did not state whether the agency agreed or disagreed with our recommendation .

in an e - mail received on june 26 , 2017 , a senior advisor in the department of agriculture's office of the cio did not state whether the department agreed or disagreed with our recommendation , but noted that the department understands that automated monitoring of server utilization and virtualization is critical to accurate data center performance and cost savings reporting .

in written comments , commerce stated that it agreed with our recommendation and described actions planned to implement it .

specifically , the department noted that , as part of its effort to consolidate , define , and establish a plan to deploy an enterprise - wide automated monitoring tool , it has identified two component agencies that will offer a data center infrastructure management tool as a service .

the department added that this approach will allow it to monitor and report cost savings and avoidances more efficiently .

commerce's comments are reprinted in appendix ii .

in written comments , defense stated that it partially agreed with our recommendation .

specifically , the department stated that it recognizes the value of data center infrastructure management capabilities in realizing dcoi objectives and will endeavor to implement the capabilities as quickly as possible .

however , the department noted that it will be unable to complete the implementation of data center infrastructure management capabilities by the end of fiscal year 2018 , as we recommended .

as obstacles to meeting this deadline , the department cited procurement regulations , resource challenges , the budget cycle , and remaining work to resolve the population of installation processing nodes , but did not offer further details .

our report specifically recognizes the challenges cited by agencies in the implementation of automated monitoring tools ( i.e. , data center infrastructure management capabilities ) , and notes the importance of detailed plans to overcome these challenges .

given the department's own acknowledgment of facing implementation obstacles , a plan describing how it will implement these important monitoring tools could help overcome the challenges identified .

therefore , we continue to believe our recommendation is warranted .

defense's comments are reprinted in appendix iii .

in written comments , energy stated that the department concurred with our recommendation and described planned actions to implement it .

specifically , the department stated that it established plans to implement automated monitoring tools at its 78 department - owned tiered data centers and plans to evaluate whether its 68 department - owned non - tiered data centers should be consolidated or closed .

for the non - tiered centers slated to remain open , the department stated that it expects to complete plans describing how it will automate server utilization by september 2019 .

energy's comments are reprinted in appendix iv .

in written comments , hhs stated that the department concurred with our recommendation and described planned actions to implement it .

specifically , the department stated that hhs will direct its operating and staff divisions to acquire and install automated monitoring tools in all agency - owned data centers by the close of fiscal year 2018 .

hhs's comments are reprinted in appendix v. in written comments , dhs stated that the department concurred with our recommendation and described planned actions to implement it .

specifically , the department stated that it is continually reviewing optimization alternatives , including evaluating the option to move to a cloud deployment model over the next few years .

the department further noted that it does not expect to achieve the optimum solution in agency - owned tiered data centers by the end of fiscal year 2018 , as we recommended , but agreed with our suggestion that the dcoi time frame be reconsidered .

in addition , dhs stated that it expects to have an optimization plan that includes , among other things , resource requirements and a schedule to achieve monitoring compliance for agency - owned tiered data centers by april 2018 .

dhs's comments are reprinted in appendix vi .

in written comments , interior stated that the department partially concurred with our recommendation .

specifically , the department stated that it is committed to completing its plan on schedule , but that its ability to meet omb's requirement to implement automated monitoring tools at all department - owned data centers by the end of fiscal year 2018 , as we recommended , will depend on many factors and variables , including the availability of funding and other resources .

because of the potential for improved efficiency and cost savings from data center optimization , as discussed in this report , we believe the department should devote the necessary resources to ensure that automated monitoring tools are installed at all department - owned data centers by the end of fiscal year 2018 , as required by omb .

therefore , in our view , the recommendation continues to be warranted .

interior's comments are reprinted in appendix vii .

in an e - mail received on july 13 , 2017 , a justice audit liaison stated that the department concurred with our recommendation .

in written comments , labor stated that the department accepted our recommendation and will incorporate pertinent information in its next data center consolidation and optimization strategic plan due in april 2018 .

labor's comments are reprinted in appendix viii .

in written comments , state indicated that the department agreed with our recommendation and described completed and planned actions to address it .

specifically , the department stated that it performed an analysis of tools , including shared services and commercial - off - the - shelf products .

the department also stated that it is developing an acquisition strategy based on its research and is recommending that a commercially available product would be the best solution to meet monitoring requirements .

further , the department noted that additional budgetary resources may be required to support an enterprise - wide roll - out of automated server monitoring across all tiered data centers , which may not be available until fiscal year 2019 or later .

as discussed in detail in this report , data center optimization holds the potential for improved efficiency and cost savings .

consequently , we encourage the department to devote the necessary resources to ensure that automated monitoring tools are installed at all department - owned data centers by the end of fiscal year 2018 , as required by omb .

state's comments are reprinted in appendix ix .

in an e - mail received on july 3 , 2017 , a deputy director in transportation's audit relations and program improvement office stated that the department concurred with our recommendation .

in an e - mail received on july 20 , 2017 , an audit liaison in treasury's office of the cio stated that the department had no comments on the draft report , and did not state whether the agency agreed or disagreed with our recommendation .

in written comments , va stated that it concurred with our recommendation and noted that it is developing a plan to fully comply with omb's requirement to implement automated monitoring tools at all agency - owned data centers by the end of fiscal year 2018 .

the department added that it expects to complete this plan by november 2017 .

va's comments are reprinted in appendix x .

in written comments , epa did not state whether the agency agreed or disagreed with our recommendation , but described planned actions to implement it .

specifically , the agency detailed plans to address omb's requirements , such as leveraging epa's current investment in a network monitoring tool and the intent to procure and deploy a data center infrastructure management tool by the end of fiscal year 2018 .

however , epa also noted that budget cuts may delay the agency's efforts to fully implement the requirements of dcoi .

as noted earlier , because of the potential efficiency and savings from data center optimization , we believe epa should devote the necessary resources to ensure that automated monitoring tools are installed at all department - owned data centers by the end of fiscal year 2018 , as required by omb .

epa's written comments are reprinted in appendix xi .

in written comments , gsa stated that it agreed with our recommendation and that it plans to install automated monitoring tools by the end of fiscal year 2018 .

gsa's comments are reprinted in appendix xii .

in written comments , nrc stated that it was in general agreement with our findings .

the agency did not state whether it agreed or disagreed with our recommendation , but described actions planned to address it .

specifically , the agency stated that it plans to install automated monitoring tools in all of its tiered data centers .

the agency added that it is planning to close its non - tiered data centers .

nrc's comments are reprinted in appendix xiii .

in written comments , opm stated that the agency partially concurred with our recommendation .

specifically , the agency stated that it plans to consolidate its remaining data centers into two main locations by the end of fiscal year 2018 .

opm further stated that this consolidation will obviate the need to implement automated monitoring tools at the data centers that are closing .

finally , the agency noted that it is implementing automated monitoring tools at the designated core data centers .

we encourage opm's efforts to continue to consolidate its data centers .

however , as mentioned in its comments , opm's automated monitoring tools have not yet been installed at the agency's core data centers .

completing a plan describing how the agency will meet omb's requirement to implement automated monitoring tools at these centers , as we recommended , could better ensure that this important effort is completed .

therefore , we believe our recommendation is still warranted .

opm's comments are reprinted in appendix xiv .

in an e - mail received on july 13 , 2017 , a program manager in sba's office of congressional and legislative affairs stated that the agency had no comments on the draft report , and did not state whether the agency agreed or disagreed with our recommendation .

in addition to the aforementioned comments , six agencies to which we did not make recommendations provided the following responses: in an e - mail received on june 23 , 2017 , a policy analyst in education's office of the secretary / executive secretariat stated that the department had no comments on the draft report .

in written comments , hud stated that the department had no comments on the draft report .

hud's comments are reprinted in appendix xv .

in an e - mail received on july 14 , 2017 , a nasa audit liaison stated that the agency had no comments on the draft report .

in an e - mail received on july 17 , 2017 , a nsf audit liaison stated that the agency had no comments on the draft report .

in written comments , ssa stated that the agency had no comments on the draft report .

ssa's comments are reprinted in appendix xvi .

in an e - mail received on july 12 , 2017 , an audit liaison in usaid's bureau for management stated that the agency had no comments on the draft report .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 22 days from the report date .

at that time , we will send copies to interested congressional committees , the director of omb , secretaries and agency heads of the departments and agencies addressed in this report , and other interested parties .

in addition , the report will be available at no charge on gao's website at http: / / www.gao.gov .

if you or your staffs have any questions on the matters discussed in this report , please contact me at ( 202 ) 512-9286 or pownerd@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix xvii .

our objectives were to ( 1 ) assess agencies' progress against the office of management and budget's ( omb ) data center optimization targets , ( 2 ) identify agencies' notable optimization successes and challenges , and ( 3 ) evaluate the extent to which agencies are able to effectively measure server utilization .

to assess agencies' progress against omb's data center optimization targets , we analyzed the february 2017 data center optimization progress information of the 24 department and agencies ( agencies ) that participate in omb's data center optimization initiative ( dcoi ) .

this progress information was obtained from the information technology ( it ) dashboard — an omb public website that provides information on federal agencies' major it investments .

we then compared the agencies' optimization progress information against omb's fiscal year 2018 optimization targets , as documented in its august 2016 memorandum .

although omb's memorandum establishes a single optimization target value for the server utilization and automated monitoring metric , the dashboard displays agencies' progress for tiered and non - tiered data centers separately .

to report consistently with omb's implementation memorandum , we combined the progress information for tiered and non - tiered data centers into a single assessment in this report .

we also reviewed the 24 agencies' dcoi strategic plans , as of april 2017 , to obtain information regarding their fiscal years 2017 and 2018 plans to meet or not meet omb's optimization targets .

this documentation included agencies' strategic plan information publicly posted on agency - owned digital strategy websites , and additional agency - provided documentation of their data center consolidation and optimization strategic plans .

to assess the reliability of agencies' optimization progress information on omb's it dashboard , we reviewed the information for errors or missing data , such as progress information that was not available for certain metrics .

we also compared agencies' optimization progress information across multiple reporting quarters to identify any inconsistencies in agencies progress .

we discussed with omb staff any discrepancies or potential errors identified to determine the causes or request additional information .

in addition , we interviewed omb officials to obtain additional information regarding the steps taken to ensure the reliability of and validate the optimization data on the dashboard .

we determined that the data were sufficiently reliable to report on agencies' optimization progress .

to assess the reliability of the dcoi strategic plans , we reviewed agencies' documentation to identify any missing data or errors .

we also compared the planned data center optimization milestones in agencies' documentation against current optimization progress information obtained from the dashboard .

in addition , we reviewed agency chief information officer statements attesting to the completeness of their dcoi strategic plan information .

moreover , we obtained written responses from agency officials regarding the steps taken to ensure the accuracy and reliability of their strategic plan .

we discussed with agency officials any discrepancies or potential errors identified during our reviews of their strategic plan to determine the causes or request additional information .

as a result of these efforts , we determined that the agencies' strategic plan information was sufficiently reliable for reporting on plans to meet or not meet omb's fiscal year 2018 optimization targets .

to address the second objective , we reviewed the 24 agencies dcoi strategic plans to identify successes and challenges encountered by agencies in optimizing their data centers .

we also interviewed cognizant officials at the 24 agencies in order to gather additional information about their data center optimization successes and challenges .

we then categorized the agency - reported successes and challenges to determine the ones encountered most often .

to evaluate the extent to which selected agencies are able to effectively measure server utilization , we analyzed the 24 agencies' february 2017 data center inventory information .

we reviewed the inventory information to determine the extent to which the agencies reported the implementation of automated monitoring tools at their data centers to measure server utilization , as well as the reported server utilization percentages at those centers .

to determine whether agencies had established detailed plans to meet omb's m - 16-19 requirement to implement automated monitoring tools at all agency - owned data centers by the end of fiscal year 2018 , we reviewed agencies dcoi strategic plans , publicly available milestone information for implementing the december 2014 it acquisition reform law , and other planning documentation provided by agencies ( such as project charters and project plans ) .

we reviewed this documentation to determine the extent to which agencies documented plans to implement automated monitoring tools at all their agency - owned data centers by the end of fiscal year 2018 , as required by omb .

to assess the reliability of the agencies' data center inventories , we checked for missing data and other errors , such as anomalous server utilization percentage information .

we also compared agencies' reported use of automated monitoring tools at their data centers across multiple reporting quarters to identify any inconsistencies in agencies' progress .

we discussed with agency officials any discrepancies or potential errors identified to determine the causes or request additional information .

further , we obtained written responses from agency officials regarding actions taken to ensure the reliability of their inventory data .

we determined that the agencies' data were sufficiently reliable to report on agencies' progress in implementing automated monitoring tools to measure server utilization .

we conducted this performance audit from july 2016 to august 2017 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact named above , individuals making contributions to this report included dave hinchman ( assistant director ) , jon ticehurst ( assistant director ) , chris businsky , rebecca eyler , linda kochersberger , and jonathan wall .

