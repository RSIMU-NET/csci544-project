as greater numbers of foreign - born persons enter , live , and work in the united states , policymakers and the general public increasingly place high priority on issues involving immigrants .

because separate policies , laws , and programs apply to different immigration statuses , valid and reliable information is needed for populations defined by immigration status .

however , government statistics generally do not include such information .

the information most difficult to obtain concerns the size , characteristics , costs , and contributions of the population referred to in this report as undocumented or currently undocumented .

such information is needed because , for example , large numbers of undocumented persons arrive each year , and the census bureau has realized that information on the size of the undocumented population would help estimate the size of the total u.s. population , especially for years between decennial censuses .

more generally , information about the undocumented population — and about changes in that population — can contribute to policy - related planning and evaluation efforts .

as you know , in 1998 , we devised an approach to surveying foreign - born respondents about their immigration status .

this self - report , personal - interview approach groups answers so that no respondent is ever asked whether he , she , or anyone else is undocumented .

in fact , no individual respondent is ever categorized as undocumented .

logically , however , grouped answers data can provide indirect estimates of the undocumented population .

generally , grouped answers questions on immigration status would be asked as part of a larger survey that includes direct questions on demographic characteristics and employment and might include questions on school attendance , use of medical facilities , and so forth ; some surveys also ask specific questions that can help estimate taxes paid .

potentially , combining the answers to such questions with grouped answers data can provide further information on the characteristics , costs , and contributions of the undocumented population .

we reported the first results of preliminary tests of the grouped answers approach , primarily with hispanic farmworkers , in 1998 and 1999 ; the majority of the preliminary test interviews were fielded by aguirre international of burlingame , california .

we also recommended that the immigration and naturalization service ( ins ) and the census bureau further develop and test the method .

in response , the census bureau contracted for a test as part of the 2004 general social survey ( gss ) , which is fielded by the national opinion research center ( norc ) at the university of chicago , with “core funding” provided by a grant from the national science foundation ( nsf ) .

the census bureau's analysis of the 2004 gss data became available in 2006 .

in this report , we respond to your request that we review the ongoing development of the grouped answers approach and related issues .

we address four questions: ( 1 ) is the grouped answers approach “acceptable” for use in a national survey of the foreign - born population ? .

 ( 2 ) what kinds of further research are or may be needed , based on the results of tests conducted thus far and expert opinion ? .

 ( 3 ) how large a survey is needed to provide “reasonably precise” estimates of the undocumented population , using grouped answers data ? .

 ( 4 ) are there appropriate ongoing surveys in which the grouped answers question series might eventually be inserted ( thus avoiding the costs of fielding a new survey ) ? .

to answer these questions , we consulted private sector experts in immigration issues and studies , including immigrant advocates , immigration researchers , and others ; consulted an independent statistical expert , dr. alan zaslavsky , and other experts in statistics and surveys ; reanalyzed the data from the 2004 gss test and subjected both our analysis and the census bureau's analysis to review by the independent statistical expert ; performed test calculations , using specific assumptions ; and identified ongoing surveys that might be candidates for piggybacking the grouped answers question series , gathered documents on those surveys , and met with officials and staff at the federal agencies that conduct or sponsor them .

we also met with other relevant federal agencies .

appendix i describes our methodology and the scope of our work in more detail .

we conducted our work in accordance with generally accepted government auditing standards between july 2005 and september 2006 .

survey questions about sensitive topics carry a “threat” for some respondents , because they fear that a truthful answer could result in some degree of negative consequence ( at a minimum , social disapproval ) .

the grouped answers approach is designed to reduce this threat when asking about immigration status .

three key points about the grouped answers approach are that 1. no respondent is ever asked whether he or she , or anyone else , is 2. two pieces of information are separately provided by two subsamples of respondents ( completely different people — no one is shown both immigration status cards ) ; and 3. taking the two pieces of information together — like two different pieces of a puzzle — allows indirect estimation of the undocumented population , but no individual respondent ( and no piece of data on an individual respondent ) is ever categorized as undocumented .

we discuss each point in some detail .

1 .

no respondent is ever asked whether he or she is in the undocumented category .

unlike questions that ask respondents to choose among specific answer categories , the grouped answers approach combines answer categories in sets or “boxes,” as shown in figure 1 .

box b includes the sensitive answer category - — currently “undocumented” — along with other categories that are nonsensitive .

each respondent is asked to “pick the box” — box a , box b , or box c — that contains the specific answer category that applies to him or her .

respondents are told , in effect: if the specific category that applies to you is in box b , we don't want to know which one it is , because right now we are focusing on box a categories .

by using the boxes , the interview avoids “zeroing in” on the sensitive answer .

the specific categories shown in the boxes in figure 1 are grouped so that one would expect many respondents who are here legally , as well as those who are undocumented , to choose box b , and there is virtually no possibility of anyone deducing which specific category within box b applies to any individual respondent .

2 .

two pieces of information are provided separately by two subsamples of respondents ( no one is shown both immigration status cards ) .

respondents are divided into two subsamples , based on randomization procedures or rotation ( alternation ) procedures conducted outside the interview process .

 ( for example , a rotation procedure might specify that within an interviewing area , every other household will be designated as subsample 1 or subsample 2. ) .

this “split sample” procedure has been used routinely for many surveys over the years .

as applied to the grouped answers approach , the two subsamples are shown alternative flash cards .

immigration status card 1 , described above , represents one way to group immigration statuses in three boxes .

a second immigration status flash card ( immigration status card 2 , shown in figure 2 ) groups the same statuses differently .

the alternative immigration - status cards can be thought of as “mirror images” in that the two nonsensitive legal statuses in box a of card 1 appear in box b of card 2 and the two nonsensitive legal statuses in box b of card 1 appear in box a of card 2 .

however , the undocumented status always appears in box b. interviewers ask survey respondents in subsample 1 about immigration status with respect to card 1 .

they ask survey respondents in subsample 2 ( completely different persons ) about immigration status with respect to card 2 .

each respondent is shown one and only one immigration - status flash card .

there are no highly unusual or complicated interviewing procedures .

because the two subsamples of respondents are drawn randomly or by rotation , each subsample represents the foreign - born population and , if sufficiently large , can provide “reasonably precise” estimates of the percentages of the foreign - born population in the boxes on one of the alternative cards .

incidentally , a respondent picking a box that does not include the sensitive answer — for example , a respondent picking box a or box c in figure 1 — can be asked follow - up questions that pinpoint the specific answer category that applies to him or her .

thus , direct information is obtained on all legal immigration statuses .

the data on some of the legal categories can be compared to administrative data to check the reasonableness of responses .

additionally , these data provide estimates of legal statuses , which are useful when , for example , policymakers review legislation on the numbers of foreign - born persons who may be admitted to this country under specific legal status programs .

3 .

no individual respondent is ever categorized as undocumented , but indirect estimates of the undocumented population can be made .

using two slightly different pieces of information provided by the two different subsamples allows indirect estimation of the size of the currently undocumented population — by simple subtraction .

the only difference between box b of card 1 and box a of card 2 is the inclusion of the currently “undocumented” category in box b of card 1 .

figure 3 shows both cards together for easy comparison .

thus , the percentage of the foreign - born population who are currently undocumented can be estimated as follows: start with the percentage of subsample 1 respondents who report that they are in box b of card 1 ( hypothetical figure: 62 percent of subsample 1 ) .

subtract from this the percentage of subsample 2 who say they are in box a on card 2 ( hypothetical figure: 33 percent of subsample 2 ) .

observe the difference ( 29 percent , based on the hypothetical figures ) ; this represents an estimate of the percentage of the foreign - born population who are undocumented .

alternatively , a “mirror - image” estimate could be calculated , using box b of card 2 and box a of card 1 .

to estimate the numerical size of the undocumented population , a grouped answers estimate of the percentage of the foreign - born who are undocumented would be combined with a census figure .

for example , the 2000 census counted 31 million foreign - born , and the census bureau issued an updated estimate of 35.7 million for 2005 .

the procedure would be to simply multiply the percent undocumented ( based on the grouped answers data and the subtraction procedure ) by a census count or an updated estimate for the year in question .

these procedures ensure that no respondents — and no data on any specific respondent — are ever separated out or categorized as undocumented , not even during the analytic process of making indirect , group - level estimates .

to further ensure reduction of “question threat,” the grouped answers question series begins with flash cards that ask about nonsensitive topics and familiarize respondents with the 3-box approach .

for each nonsensitive - topic card , interviewers ask the respondent which box applies to him or her , saying: if it's box b , we do not want to know which specific category applies to you .

in this way , most respondents should understand the grouped answers approach before seeing the immigration - status card .

to help ensure accurate responses , respondents who choose box a can be asked a series of clarifying questions .

 ( no follow - up questions are addressed to anyone choosing box b. ) .

the questions for box a respondents are designed to prompt them to , essentially , reclassify themselves in box b , if that is appropriate .

the grouped answers question series can potentially be applied in a large - scale general population survey , where the questions on immigration status would be added for the foreign - born respondents — provided that an appropriate survey can be identified .

if a new survey of the general foreign - born population were planned , it would involve selecting a general sample of households and then screening out the households that do not include one or more foreign - born persons .

finally , we note that while the initial version of the grouped answers approach involved three alternative flash cards ( and was termed the “three - card method” ) , we recently devised the version described here , which uses two cards rather than three .

the two - card method is simpler , is easier to understand , and provides more precise estimates .

all cards are alike in that they feature three boxes in which specific answer categories are grouped .

generally , grouped answers questions on immigration status would be asked as part of a larger survey that includes direct questions on demographic characteristics and employment and might include questions on school attendance , use of medical facilities , and so forth ; some surveys also ask specific questions that can help estimate taxes paid .

potentially , combining the answers to such questions with grouped answers data can be used to provide further information on the characteristics , costs , and contributions of the undocumented population .

for example , the numbers of undocumented persons in major subgroups — such as demographic or employment status subgroups — can be estimated , provided that the sample of foreign - born persons interviewed is sufficiently large .

grouped answers data collected from adult respondents can also be used to estimate the number of children in various immigration statuses , including undocumented — provided that an additional question is asked .

additionally , when combined with separate quantitative data ( for example , data on program costs per individual ) , grouped answers data can be used to estimate quantitative information ( such as program costs ) for the undocumented population as a whole — or , again , depending on sample size , for specific subgroups .

the procedures for deriving these more complex indirect estimates are described in appendix ii .

no grouped answers respondent is ever categorized as undocumented .

the foreign - born population of the united states is large and growing — as is the undocumented population within it .

congressional policymakers , the u.s. commission on immigration reform , and the national research council's ( nrc ) committee on national statistics have indicated a need for statistical information on the undocumented population , including its size , characteristics , costs , and contributions .

the census bureau estimates that as of 2005 , foreign - born residents ( both legally present and undocumented ) numbered 35.7 million and accounted for at least one - tenth of all persons residing in each of 15 states and the district of columbia .

these figures represent substantial increases over the prior 15 years .

for example , in 1990 the foreign - born population totaled fewer than 20 million ; only 3 states had a population more than one - tenth foreign - born .

one result is that as the department of labor has testified , foreign - born workers now constitute almost 15 percent of the u.s. labor force , and the numbers of such workers are growing .

a new paper from the department of homeland security ( dhs ) puts the “unauthorized” immigrant population at 10.5 million as of january 2005 and indicates that if recent trends continued , the figure for january 2006 would be 11 million .

the pew hispanic center's indirect estimate of the undocumented population as of 2006 is 11.5 million to 12 million .

these estimates represent roughly one - third of the entire foreign - born population .

dhs has variously estimated the size of the undocumented population as of january 2000 as 7 million and 8.5 million .

government and other estimates for 1990 numbered only 3.5 million .

these various indirect estimates of the undocumented population are based on the “residual method.” residual estimation ( 1 ) starts with a census count or survey estimate of the number of foreign - born residents who have not become u.s. citizens and ( 2 ) subtracts out estimated numbers of legally present individuals in various categories , based on administrative data and assumptions ( because censuses and surveys do not ask about legal status ) .

the remainder , or residual , represents an indirect estimate of the size of the undocumented population .

to illustrate the role of administrative data and assumptions , residual estimates draw on counts of the number of new green cards issued each year .

but they also require assumptions to account for emigration and deaths among those who received green cards in earlier years .

a recent dhs paper providing residual estimates of the undocumented population includes ranges of estimates based on alternative assumptions made for two key components .

for example , “by lowering or raising the emigration rates 20 percent .

 .

 .

the estimated unauthorized immigrant population would range from 10.0 million to 11.0 million.” the dhs paper also lists assumptions that were not subjected to alternative specifications .

we believe the dhs paper represents an advance because , up to now , analysts producing residual estimates have generally not made public statements regarding the precision of the estimates .

 ( some critics have , however , indicated that residual estimates are likely to lack precision. ) .

while the residual approach has been used to profile the undocumented population on two characteristics — age and country of birth — it is limited with respect to estimating ( 1 ) current geographic location and ( 2 ) current employment and benefit use .

the reason is that current characteristics of legally present persons are not maintained in administrative records ; analysts must therefore rely largely on assumptions .

in contrast , the grouped answers method does allow for the possibility of estimating current characteristics based on current self - reports .

during the mid - 1990s , the u.s. commission on immigration reform determined that better statistical “information on legal status and type of immigrant crucial” to assessing immigration policy .

indeed , the commission called for a variety of improvements in estimates of the costs and benefits associated with undocumented immigration .

nrc's committee on national statistics further emphasized the need for better information on costs , especially state and local costs .

 ( if successfully fielded , the grouped answers method might help provide general information on such costs — and , potentially , specific information for large states such as california .

sample size limitations would be likely to prohibit separate analyses for specific local areas , small states , and states with low percentages of foreign - born or undocumented. ) .

over the years , we have received numerous congressional requests related to estimating costs associated with the undocumented population .

recent census bureau research and conferences reflect the realization that undocumented immigration is a key component of current population growth and that there is a resultant need for information on this group .

additionally , some of the immigrant advocates we interviewed expressed an interest in being able to better describe the contributions of the undocumented population .

various national surveys ask foreign - born respondents to provide information about themselves and , in some cases , other persons in their households .

while such surveys provide a wealth of information on a wide variety of areas , including some sensitive topics , national surveys generally do not ask about current immigration status — with the exception of a question on u.s. citizenship , which is included in several surveys .

as we reported earlier , it is believed that direct questions on immigration status “are very sensitive , and negative reactions to them could affect the accuracy of responses to other questions on survey.” two surveys that have asked respondents directly about immigration status for several years are the national agricultural workers survey ( naws ) , an ongoing annual cross - sectional self - report survey of farmworkers , fielded by aguirre international , a private sector firm under contract to the department of labor , since 1988 , and the survey of income and program participation ( sipp ) , a longitudinal panel survey of the general population , conducted by the census bureau , which has asked immigration status questions since 1996 .

of the two , sipp is the more relevant , because its immigration status questions have been administered to a sample of the general foreign - born population .

sipp has asked an adult respondent - informant from each household to provide information about himself or herself and about others in his or her household , including which immigration - status category applied to each person when he or she came to this country .

answers are facilitated by a flash card that lists major legal immigration statuses ( see fig .

4 ) .

a further question asks whether each person obtained a green card after arriving in this country .

the sipp questions come close to asking about — but do not actually allow an estimate of — the number of foreign - born u.s. residents who are currently undocumented .

according to the census bureau , sipp is now scheduled to be “reengineered,” but the full outlines of the revised effort have not been set .

in the middle to late 1990s , the grouped answers question series was subjected to preliminary development and testing with hispanic respondents , including interviews with farmworkers conducted by aguirre international , under contract to gao .

in these tests , every respondent picked a box .

however , these interviews were not conducted under conditions of a typical large - scale survey in which interviewers initiate contact with respondents in their homes .

to further test respondents' acceptance of the grouped answers approach , the census bureau created a question module with 3-box flash cards and contracted for it to be added to the 2004 gss .

when presenting the survey to respondents , interviewers explained that norc of the university of chicago fielded the gss survey , with “core funding” from an nsf grant .

the census bureau's question module included cards from the three - card version of the grouped answers approach — which features only one immigration status category in box a .

the cards used were the two training cards shown in figures 5 and 6 and the immigration status card shown in figure 7. the “overwhelming majority of foreign - born respondents” picked a box on the immigration status card without — according to interviewers — any objection , hesitation , or periods of silence ; while some interviewers did not give a judgment or were confused about rating respondents' understanding , about 80 percent of respondents were coded as understanding and about 10 percent as not ; and some respondents' comments , written in by interviewers , indicated that although the gss is a “personal interview” survey , telephone interviews had been substituted , in some cases , and this meant that respondents could not see the cards — making the use of the 3-box format difficult .

the census bureau's paper highlighted various limitations of the 2004 gss test , including ( 1 ) testing only one immigration status card , ( 2 ) underrepresenting hispanics , and ( 3 ) in some instances interviewing over the telephone ( instead of in person ) , so that respondents did not see the flash cards .

the acceptability of the grouped answers approach appears to be high , when implemented in surveys fielded by a university or private sector organization .

many immigration experts , including advocates , accepted the grouped answers approach , although some conditioned their acceptance on a quality implementation in a survey fielded by a university or other private sector organization .

an independent statistical expert believed that the grouped answers approach would be generally usable with survey respondents .

some of the researchers and advocates we contacted were extremely enthusiastic about the potential for new data .

no one objected to statistical , policy - relevant information being developed on the size , characteristics , costs , and contributions of the undocumented population .

overall , the immigration experts we contacted ( listed in appendix i , table 5 ) accepted the grouped - answers question approach — although advocates sometimes conditioned their acceptance on , for example , the questions being asked in a survey fielded by a university or private sector organization — with data protections built in .

many also offered suggestions for maximizing cooperation by foreign - born respondents or ideas about how advocacy organizations might help .

some advocates indicated that a key condition of their support would be that ( 1 ) the grouped answers question on immigration status be asked by a university or private sector organization and ( 2 ) identifiable data ( that is , respondents' answers linked to personal identifiers ) be maintained by that organization .

two advocate organizations specifically stated that they “could not endorse,” or implied they would not support , the grouped answers approach , assuming the data were collected and maintained by , in one case , the census bureau and , in the other case , the government .

many other immigration experts and advocates preferred that grouped answers data on immigration status be collected by a university or other reputable private sector organization pledged to protect the data .

the immigration advocates said that private sector fielding of a grouped answers survey and protection of such data from nonstatistical uses that might harm immigrants were key issues because some foreign - born persons are from countries with repressive regimes and thus have more fear of ( less trust in ) government than the typical u.s. - born person .

despite current law protecting individual data from disclosure , some persons believe that information collected by a government agency such as the census bureau is routinely shared ( or that in some circumstances it might be shared ) across government agencies .

further , one advocate pointed out that the congress could change the current law , eliminating that protection .

 ( although the grouped answers approach does not identify anyone as undocumented , it does provide some information regarding each respondent's immigration status. ) .

extremely large - scale data collections — notably , the american community survey ( acs ) — can yield estimates for areas small enough that if the data were publicly available , they could be used for nonstatistical , nonpolicy purposes .

some advocates referred to the world war ii use of census data to identify the areas where specific numbers of persons of japanese origin or descent resided .

they also pointed out that census bureau data on ethnicity — including counts of arab americans — are publicly available by zip code .

 ( the census bureau , unlike other government agencies and private sector survey organizations , is associated with extremely large - scale data collections , and some persons may not fully differentiate census bureau data collection efforts of different sizes. ) .

hostility to or lack of trust in the census bureau might result in potentially lower response rates for foreign - born persons , based on the world war ii experience of the japanese or a more recent incident in which census bureau staff helped a dhs enforcement unit access publicly available data on ethnicity by zip code .

51 , dhs stated that it did not use these data and had not requested the information by zip code .

the census bureau clarified its position on providing help to others requesting publicly available data .

various advocates saw the issues listed above as linked to their own acceptance , as well as to respondent acceptance , of a survey .

linking these issues to respondent acceptance of a survey was , in some cases , echoed by other immigration experts we consulted .

some immigrant advocates and other immigration experts counseled us that if there were an increase in enforcement efforts in the interior of the united states ( as opposed to border - crossing areas ) , foreign - born respondents' acceptance of the grouped answers questions would be likely to decrease — at least , if the questions were asked in a survey fielded by the government .

see samia el - badry and david a. swanson , “providing special census tabulations to government security agencies in the united states: the case of arab - americans,” paper presented at the 25th international population conference of the international union for the scientific study of population , tours , france , july 18 – 23 , 2005 .

one advocate was particularly concerned about the possibility that lower respondent cooperation might have resulted from these incidents and , if so , might have led to underrepresentation of these communities in census bureau data .

additionally , one advocate questioned whether local estimates of the undocumented might , in future , facilitate possible efforts to base apportionment on population counts that do not include undocumented residents .

we note that most large - scale personal - interview surveys do not include sufficient numbers of foreign - born respondents to allow indirect grouped answers estimates of undocumented persons for small geographic areas , such as zip codes .

sector organization with government funding .

in some cases , we specifically referred to one or both of the following surveys , which ( 1 ) have been conducted for many years without inappropriate data disclosures and ( 2 ) ask direct sensitive questions: the national survey on drug use and health ( nsduh ) , fielded by rti international under a contract from hhs's substance abuse and mental health services administration ( samhsa ) , and the national agricultural workers survey ( naws ) , fielded by aguirre international , under a contract from the department of labor .

the advocates' response was generally to accept the concept of government funding of a university's or private sector survey organization's field work , provided that appropriate protections of the data were built into the funding agreement .

gao's contract with aguirre international for early testing of the grouped answers approach with farmworker respondents specified that data on respondents' answers would be “stripped of person - identifiers and related information.” additionally , the gss “core funding” grant with nsf and its contractual arrangements with sponsors of question modules — such as the grouped - answers question insert contracted for by the census bureau — do not involve the transfer of any data other than publicly available data , stripped of identifiers , and limited so as to avoid the possibility of “deductive disclosure” with respect to respondent identities or local areas .

various advocates said that their acceptance was also contingent on factors such as 1. high - quality data , including coverage of persons who have limited english proficiency , with special attempts to reach those who are linguistically isolated ( that is , members of households in which no one 14 or older speaks english “very well” ) and to overcome other potential barriers ( such as cultural differences ) ; 2. appropriate presentation of the survey , including an appropriate explanation of its purpose and how respondents were selected for interview ; and 3. transparency — that is , keeping the immigrant community informed about or involved in the development and progress of the survey .

one advocate specifically said that her organization's support would be contingent on both ( 1 ) the development of more information on respondent acceptance within the asian community — particularly among asians who have limited english proficiency or are linguistically isolated — and ( 2 ) a survey implementation that is planned to adequately communicate with asian respondents , including those who are linguistically isolated or have little education .

although one - fourth of the 2004 gss test respondents were asian , the test was conducted in english ( allowing help from bilingual household members ) , and no other tests have included linguistically isolated asians .

advocates and other experts made several suggestions for maximizing respondent cooperation with a survey using the grouped answers question series — that is , maximizing response rates for such a survey as well as maximizing authentic participation .

advocates suggested that the survey ( 1 ) avoid taking names or social security numbers , ( 2 ) hire interviewers who speak the respondents' home - country language , ( 3 ) let respondents know why the questions are being asked and how their households came to be selected , ( 4 ) conduct public relations efforts , ( 5 ) obtain the support of opinion leaders , ( 6 ) select a survey group from a well - known and trusted university to collect the data , and ( 7 ) ask respondents about their contributions to the american economy through , for example , working and paying taxes .

additionally , survey experts suggested using audio – computer assisted self interview ( audio - casi ) , carefully explaining to respondents how anonymity of response is paying respondents $25 or $30 for participating in the interview .

survey experts viewed these elements as key ways of boosting response rates or encouraging authentic responses to sensitive questions .

for example , naws , which uses respondent incentives , achieves extremely high response rates within cooperating farms — 97 percent in 2002 , with a $20 payment to farmworkers selected .

some immigrant advocates also offered suggestions for how their organizations or other advocates might help the effort to develop and field the grouped answers approach , including 1. providing contacts at local organizations to help with arrangements for 2. developing or reviewing box a follow - up questions , and 3. serving on an advisory board with other representatives from immigrant communities .

as we report above , the census bureau's recent analysis of the 2004 gss grouped answers data concluded that the “overwhelming majority of foreign - born respondents” picked a box without objection , hesitation , or silence .

the census bureau reported , more specifically , that roughly 90 percent ( 216 of 237 respondents ) chose a box , 4 gave other answers , and 17 refused to answer or said “don't know.” our subsequent analysis excluded 19 of the 237 respondents in the census bureau analysis because 4 were not foreign - born ( for example , 1 had been born abroad to parents who had , by the time he was born , become naturalized u.s. citizens ) ; 1 was not classifiable as either foreign - born or not foreign - born ( because he did not know whether his parents were born in the united states ) ; 4 others were known to have been interviewed on the telephone , based on written - in interviewers' comments recorded in the computer file ( for example , one wrote that the respondent could not see the cards because the interview was on the telephone ) ; and 10 others were subsequently found to have been interviewed on the telephone , based on a special gss hand check of the interview forms for respondents who had refused or said “don't know,” which was carried out in response to our request .

as a result , in our analysis we found that only 6 personally interviewed foreign - born gss respondents refused or said “don't know.” one of the 6 was an 18-year - old mexican who told the interviewer that he did not know whether or not he was a legal immigrant .

additionally , we found that the 4 respondents who gave “other answers” had provided usable information ( for example , one called out that he had a student visa ) and thus could be recoded into an appropriate box .

the test confirms the general usability of the with subjects similar to the target population for its potential large - scale use — that is , foreign - born members of the general population .

out of about 218 respondents meeting eligibility criteria and who were most likely administered the cards in person ( possibly including a few who had telephone interviews but responded without problems ) , only 9 did not respond by checking one of the 3 boxes .

of these , 3 provided verbal information that allowed coding of a box , and 6 declined to answer the question altogether .

furthermore , several of these raised similar difficulties with other 3-box questions on nonsensitive topics ( type of house where born , mode of transportation to enter united states ) , suggesting that the difficulties with the question format were at least in part related to the format and not to the particular content of the answers .

thus , indications were that there would not be a systematic bias due to respondents whose immigration status is more sensitive being unwilling to address the 3-box format .

dr. zaslavsky emphasized the importance of minimizing or completely avoiding telephone interviews when using the grouped answers approach — or , alternatively , providing advance copies of the cards to respondents before interviewing over the telephone .

 ( dr. zaslavsky's written review is presented in full in appendix iii. ) .

the findings on respondent acceptance — that is , the gss test — raised some unanswered questions about acceptance that experts said should be addressed .

additionally , the experts said that one or more tests of response validity are needed to determine whether respondents “pick the correct box” versus systematically avoiding box b .

four issues should be addressed in future field tests: ( a ) equivalent acceptability of all forms of the response card , ( b ) usability with special populations including those with low literacy , the linguistically isolated , and concentrated immigrant populations , ( c ) methods that avoid telephone interviews , or reduce bias and nonresponse due to use of the telephone , ( d ) use of follow - up questions to improve the accuracy of box choices .

as the independent expert explained with respect to point ( b ) , gss undercoverage of the foreign - born population occurred at least in part because interviews were conducted only in english , although household members could help respondents with limited english .

various colleagues and experts we talked with supported points ( a ) through ( d ) .

we further note that points ( a ) and ( c ) were covered or touched on in the census bureau's paper reporting its analysis of the 2004 gss data .

in our discussions with census bureau staff , they also mentioned that further tests of acceptance should include ( d ) follow - up questions for box a respondents .

additionally , some advocates and an immigration researcher suggested improving the cards , which might minimize the potential for “don't know” or inaccurate answers .

a survey expert suggested using focus groups to further explore respondent perceptions of the cards — and to potentially improve them .

earlier testing covered a key portion of the populations ( hispanic farmworkers ) cited in ( b ) above , was conducted in spanish , and included box a follow - up questions as recommended in ( d ) above .

in those interviews , every respondent picked a box .

however , 1 .

no language other than spanish or english has been used in testing ; thus , as one immigrant advocate pointed out , no testing has focused on linguistically isolated asians ( those living in households in which no adult member speaks english ) .

2 .

the interviews with hispanic farmworkers were not conducted under typical conditions of a household survey .

3 .

only one immigration status card was tested with hispanic farmworkers and in the gss .

therefore , we agree that the acceptance - testing issues the experts raised should be considered in assessing the grouped answers approach .

several experts told us that tests of respondent accuracy — or at least respondents' intent to respond accurately — should be conducted .

these experts emphasized that grouped answers data would not be useful if substantial numbers of respondents were to systematically avoid picking box b ( that is , to not pick the box with the undocumented category ) .

however , one immigration study expert believed that if a response validity study involved lengthy delays , fielding a grouped answers survey should proceed in advance of a validity study .

we agree with the experts' position that tests are needed to determine whether respondents systematically avoid box b ( even after box a follow - up check questions ) .

tests of response validity would ideally be conducted with the methods of encouraging truthful answers that experts mentioned , such as ( 1 ) explaining why the survey is being conducted , how the respondent was selected , and how the anonymity of answers is ensured , and ( 2 ) using audio - casi and , if appropriate , paying respondents for participating in the interview .

and , as the census bureau pointed out , such a study should include the full grouped answers question series , including follow - up questions , and it should test both card 1 and card 2 .

even if small numbers of respondents were to respond inaccurately , it would be helpful to estimate this and adjust for any resulting bias .

we discussed various approaches to conducting validity studies with immigration experts , including immigrant advocates , and with agencies conducting surveys .

in reviewing these approaches , we found that response validity tests vary according to whether they are conducted before , during , or after a survey is fielded .

before a large - scale survey is conducted .

the grouped answers question series could be asked of a special sample of respondents for whom the answers are known , in advance , by study investigators on an individual - respondent basis .

such knowledge might be based , for example , on information that recent applicants for green cards have submitted to dhs .

“firewalls” could be used to prevent survey information from being given to dhs .

we discussed this approach with dhs ; however , experts criticized a dhs - based validity study on both methodological and public relations grounds .

an alternative source of data on individuals' immigration statuses might avoid these problems , but no alternative source has yet been identified .

before or as part of a large - scale survey .

in either situation ( that is , in a presurvey study or as part of a survey ) , respondents could be asked if they would be willing to participate in special validity - test activities in return for a payment of , say , $25 or $30 for each activity .

later , after interviewing had been completed in a given location — not as part of the interview process — a sample of respondents who chose box a ( that is , those who claimed to be here legally ) could be asked to participate in a focus group in which respondents would discuss how they felt answering the grouped answers questions when the interviewer came to their house and , also , could possibly be asked to fill out a “secret ballot” indicating whether they had answered authentically in the earlier home interview ; give permission for a record check and provide information that could subsequently be used in a record check ( for example , their name , date of birth , and social security number ) and permission to check these data with the social security administration ; or show his or her documentation ( for example , green card ) to a documents expert .

these checks would logically be focused on box a respondents , for most of whom such checks would be less threatening .

we believe that it is reasonable to assume that most respondents who chose box b picked the correct box .

further , because the survey interview states that there are no more questions on immigration if the respondent picks box b , pursuing follow - up validity checks might be deemed inappropriate for box b respondents .

after data are collected .

with a large - scale survey , it would be possible to conduct comparative analyses after the data were collected .

we provide three examples.1 .

grouped answers estimates of the percentage undocumented could be compared for ( a ) all foreign - born versus ( b ) high - risk groups , such as those who arrived in the united states within the past 5 or 10 years .

the expectation would be that with valid responses , a higher estimate of the percentage undocumented would be obtained for those who arrived more recently — because , for example , persons who had arrived recently were not here during the amnesty in the late 1980s .

2 .

comparisons could be made of ( a ) box a estimates of specific legal statuses and the approximate dates received — notably , the numbers of persons claiming to have received valid green cards in 1990 or more recently — with ( b ) publicly available dhs reports of the numbers of green cards issued from 1990 to the survey date .

3 .

analysts could compare ( a ) grouped answers estimates of the number undocumented overall to ( b ) estimates of total undocumented obtained by the residual method .

wherever possible , card 1 and card 2 should be tested separately for accuracy of response .

the advantage of conducting a validity study in advance of a survey is that if significant problems surface , adjustments in the approach can be made .

or if the problems are substantial and cannot be easily corrected — and if the anticipated survey were to be fielded mostly or only to collect grouped answers data — then that survey could be postponed or canceled .

however , the results of validity tests conducted during or after a survey can be used to interpret the data and , potentially , to adjust estimates if it appears that , for example , 5 to 10 percent of undocumented respondents had erroneously claimed to be in box a of card 1 .

as one expert noted , conducting an advance study does not preclude conducting a subsequent study during or after the survey .

although several factors are involved , and it is not possible to guarantee a specific level of precision in advance , we estimate that roughly 6,000 foreign - born respondents , or more , would be needed for a grouped answers survey .

as we explain below , this is based on ( 1 ) a precision requirement ( that is , a 95 percent confidence interval consisting of plus or minus 3 percentage points ) , ( 2 ) assumptions about the sampling design of the survey in which the questions are asked , and ( 3 ) the assumption that approximately 30 percent of the foreign - born population is currently undocumented .

an indirect grouped answers estimate of the undocumented population generally requires interviews with more foreign - born respondents than a corresponding hypothetical direct estimate would — assuming it were possible to ask such questions directly in a major national survey .

one key reason is that the main sample of foreign - born respondents must be divided into two subsamples .

half the respondents answer each immigration status card .

on this basis alone , one would have to double the sample size required for a direct estimate based on a question asked of all respondents .

further , the estimate of undocumented , which is achieved by subtraction , combines two separate estimates , each characterized by some degree of uncertainty .

determining the number of respondents required for a “reasonably precise” estimate of the percentage of the foreign - born population who are undocumented involves three key factors: 1. specification of a precision level — that is , choice of a 90 percent or 95 percent confidence level and an interval defined by plus or minus 2 , 3 , or 4 percentage points ; 2. information on ( or assumptions about ) the sampling design for the main survey and for subsamples 1 and 2 ; and 3. to the extent possible , consideration of the likely distribution of the foreign - born population across immigration status categories , including the various legal categories and the undocumented category .

with respect to the first factor involved in determining sample size , some agencies — for example , the census bureau and the bureau of labor statistics ( bls ) — use the 90 percent confidence level .

other agencies use the 95 percent level .

with respect to the second factor , the sampling design of a large - scale , nationally representative , personal - interview survey is based on probabilistic area sampling rather than simple random sampling of individuals .

this often reduces the precision of estimates ( relative to simple random sampling ) .

the reason is that persons selected for interview are clustered in a limited number of areas or neighborhoods ( and residents of a particular neighborhood may tend to be similar ) .

it is possible that the design for selecting subsamples 1 and 2 could increase precision ; however , it is not possible to predict by how much .

with respect to the third factor , existing residual estimates point to a fairly even 3-way split between three main categories — undocumented , u.s. citizen , and legal permanent resident .

however , there is some uncertainty associated with these estimates , the distribution may vary across subgroups , and the percentages may change in future .

therefore , a range of distributions is relevant .

taking each of these factors into account ( to the extent possible ) and using conservative assumptions , we estimated the approximate numbers of respondents required for indirect estimates of the undocumented population that are “reasonably precise.” table 1 shows required sample sizes for the 90 percent confidence level , table 2 for the 95 percent level , with precision at plus or minus 2 , 3 , and 4 percentage points .

in estimating these required sample sizes , we made conservative assumptions and specified a range of possibilities for the distribution with respect to the undocumented category .

to identify a single , rough figure for the sample size needed for reasonably precise estimates , we focused on 1. the 95 percent level , which is more certain and , we believe , preferable ; 2. the 30 percent column , because a current residual estimate of the undocumented population is in this range ; and 3. the middle row ( for plus or minus 3 percentage points ) , which is a midpoint within the area of “reasonable precision” as defined above .

with this focus , we estimate that roughly 6,000 or more respondents would be required .

high - risk subgroups — subgroups with higher percentages of undocumented ( such as adults 18 to 44 and persons who arrived in the united states within the past 10 years ) — would require fewer respondents for the same level of precision , as illustrated in the tables' middle and right columns .

for example , if about 70 percent of a subgroup were undocumented , a survey with about 3,500 respondents in that subgroup would produce an estimate of the percentage of the subgroup that is undocumented , correct to within approximately plus or minus 3 percentage points at the 95 percent confidence level .

low precision could obtain for smaller subgroups in which there are relatively few undocumented persons ( for example , 10 percent or less ) , particularly if — as assumed in tables 1 and 2 — there is an even split of legally present foreign - born persons across the box a categories of immigration status cards 1 and 2 .

the independent statistician we consulted indicated that if more than one grouped answers survey is conducted , combining data across two or more surveys could help provide larger numbers of respondents for subgroup analysis .

for example , if a large - scale survey were conducted annually , analysts could combine 2 or 3 years of data to obtain more precise estimates .

 ( one caveat is that combining data from multiple survey years reduces the time - specificity associated with the resulting estimate. ) .

finally , we note that to estimate the numerical size of the undocumented population , a grouped answers estimate of the percentage of the foreign - born who are undocumented would be combined with a census count of the foreign - born or an updated estimate .

for example , the 2000 census counted 31 million foreign - born persons , and the census bureau later issued an updated estimate of 35.7 million for 2005 .

the specific procedure would be to multiply the percentage undocumented ( based on the grouped answers data and the subtraction procedure ) by a census count or an updated estimate of the foreign - born population for the year in question .

the precision of the resulting estimate of the numerical size of the undocumented population would be affected by ( 1 ) the precision of the grouped answers percentage estimate , which is closely related to sample size , as described above , and ( 2 ) any bias in the census count or updated estimate of the foreign - born population .

the precision of the grouped answers percentage is taken into account by using a percentage range ( for example , the estimate plus or minus 3 percentage points ) when multiplying .

although the amount of bias in a census count or updated estimate is unknown , we believe that any such bias would have a proportional impact on the calculated numerical estimate of the undocumented population .

to illustrate the proportional impact , we assume that a census count for total foreign - born is 5 percent too low .

using that count in the multiplication process would cause the resulting estimate of the size of the undocumented population to be 5 percent lower than it should be .

the situation is analogous for subgroups .

overall , it seems clear that reasonably precise grouped answers estimates of the undocumented population and its characteristics require large - scale data collection efforts but not impossibly large ones .

a low - cost field strategy would be to insert the new question series in an existing , nationally representative , large - scale survey — that is , to pose the grouped answers questions to the foreign - born respondents already being interviewed .

however , based on our review of on - going large - scale surveys , the insertion strategy does not seem feasible .

specifically , we identified four potentially relevant surveys but none met criteria based on the grouped answers design and other criteria based on immigrant advocates' concerns .

the dollar costs associated with inserting a grouped answers module are difficult to calculate in advance because many factors are involved .

however , to suggest the “ball park” within which the cost of a grouped answers insert might be categorized , if an insertion were possible , we present the following two examples .

the gss test , in which a grouped answers question module was inserted , cost approximately $100 per interview ( more than 200 interviews were conducted ) .

on average , the question series took 3.25 minutes .

logically , per - interview costs are likely to be higher in relatively small surveys than in larger surveys with thousands of foreign - born respondents .

for the much larger current population survey ( cps ) , with interviews covering native - born and foreign - born persons in more than 50,000 households , the census bureau and bls told us that “an average 10-minute supplement cost $500,000 in 2005.” this implies $10 per interview at the 50,000 level , but per - interview costs might be higher when the question series applied to only a portion of the respondents .

additional costs might apply for flash cards and foreign - language interviews .

bls noted that still other costs would apply for advance testing and subsequent analyses requested by the customer .

a more costly option would be to ask the grouped answers question series in a follow - back survey of foreign - born respondents identified in interviewing for an existing survey .

 ( in - person self - report interviews can cost $400 to $600 each. ) .

more costly still would be the development of a new , personal - interview survey of a representative sample of the foreign - born population devoted to migration issues ; the main reason is that there would be additional costs in “screening out” households without foreign - born persons .

we identified four potentially relevant ongoing large - scale surveys .

all have prerequisites and processes for accepting ( or not accepting ) new questions .

we also developed six criteria for assessing the appropriateness of each survey as a potential vehicle for fielding the grouped answers approach .

three criteria are based on design requirements , and three are based on the views of immigrant advocates .

we found that no ongoing large - scale survey met all criteria .

we identified four nationally representative , ongoing large - scale surveys in which respondents are or could be personally interviewed .

three of these conduct most or all interviews in person: 1. the current population survey ( cps ) , sponsored by bls and the census bureau and fielded by census ; 2. the national health interview survey ( nhis ) , sponsored by the national center for health statistics ( nchs ) and fielded by the census bureau ; and 3. the national survey on drug use and health ( nsduh ) , sponsored by samhsa and fielded by rti international , a private sector contractor .

the fourth survey is the american community survey ( acs ) , a much larger survey fielded by the census bureau and using “mixed mode” data collection .

the majority of the data are based on mailed questionnaires or telephone interviews , with the remaining data based on personal interviews .

in addition , there is one personal - interview follow - back survey that uses the acs frame and data to draw its sample .

other follow - back surveys might eventually be possible .

for any of these four surveys , inserting a new question or set of questions ( or fielding a “follow - back” survey based on respondents' answers in the main survey ) requires approvals by the office of management and budget ( omb ) , the agencies that sponsor or field the surveys , and in cases in which data are collected by a private sector organization , the organization's institutional review board .

the prerequisites for an ongoing survey's accepting new questions typically include low anticipated item nonresponse , pretesting and pilot testing ( including debriefing of respondents and interviewers ) that indicate a minimum of problems , review by stakeholders to determine acceptability , and tests that indicate no effect on either survey response rates or answers to the main survey's existing questions .

another prerequisite would be the expectation of response validity .

additionally , multiple agencies mentioned a need for prior “cognitive interviewing,” compatibility with existing items ( so that there is no need to change existing items ) , and no significant increase in “respondent burden” ( by , for example , substantially lengthening the interview ) .

agencies sponsoring or conducting large - scale surveys varied on the perceived relevance of immigration to the main topic of their survey .

for example , bls noted that some of its customers would be interested in data on immigration status by employment status ( among the foreign - born ) , and the census bureau has indicated the relevance of undocumented immigration to population estimation .

but some other agencies saw little relevance to the large - scale surveys they sponsored or conducted .

resistance to including a grouped answers question series might occur where an agency perceives little or no benefit to its survey or its customers .

additionally , one agency raised the issue of informed consent , which we discuss in appendix v .

based on the design of the grouped answers approach , as tested to date , two criteria for an appropriate survey are ( 1 ) personal interviews in which respondents can view the 3-box cards and ( 2 ) a self - report format in which questions ask the respondents about their own status ( rather than asking one adult member of a household to report information on others ) .

a third criterion is that the host survey not include highly sensitive direct questions that could affect foreign - born respondents' acceptance of the grouped answers questions .

we based these criteria on the results of the gss test , our knowledge of the grouped answers approach , and general logic .

as shown in table 3 , one of the surveys we reviewed ( the cps ) does not meet the self - report criterion ; that is , it accepts proxy responses .

two other surveys ( the nhis and nsduh ) do not meet the criterion of an absence of highly sensitive questions , since they include questions on hiv status ( nhis ) and the use of illegal drugs ( nsduh ) .

conducting a follow - back survey based on acs would meet all three criteria.1 .

are the data gathered in personal interviews ? .

yes .

mostly , for in - person waves ; 16% of foreign - born interviewed by telephone , in the in - person waves .

3 .

are direct questions not highly sensitive ? .

yes , not highly sensitive .

yes .

mostly ; 17% of foreign - born sample adults interviewed by telephone .

no .

there are direct questions on hiv , other stds .

national survey of drug use and health ( nsduh ) yes .

all interviewed in person .

no .

an adult respondent reports on self and provides proxy responses for others in his or her household .

in - person data for 6,744 households with 1 or more foreign - born members ( 2006 ) .

yes .

for some questions , but not all , 4,829 foreign - born adults self - report ( 2004 ) .

yes .

7,364 foreign - born age 12 and older and 4,934 foreign - born age 18+ self - report ( 2004 ) .

yes .

a follow - back could specify self - report only .

 ( acs data include both self - report data and proxy data in which one member of a household provides responses for others. ) .

no .

there are direct questions on respondent's use and sale of drugs like marijuana and cocaine .

yes , not highly sensitive .

yes .

a follow - back could specify personal interviews only .

 ( acs is mixed mode , mostly mail. ) .

the views of immigrant advocates , which were echoed by some other experts , suggested three additional criteria for a candidate “host” survey: 1. data collection by a university or private sector organization , 2. no request for the respondent's name or social security number , and 3. protection from possible release of grouped answers survey data for small geographic areas ( to guard against estimates of the undocumented for such areas ) .

the experts based their views on ( 1 ) methodological grounds ( foreign - born respondents would be more likely to cooperate , and to respond truthfully , if all or some of these criteria were met ) and ( 2 ) concerns about privacy protections at the individual or group levels .

these criteria are potentially important , in part because the success of a self - report approach hinges on the cooperation of individual immigrants and , most likely , also on the support of opinion leaders in immigrant communities .

with respect to the first criterion above , we note that with the exception of initial gao pretests , all tests of the grouped answers approach have involved data collection by a university or private sector organization .

without further tests , we do not know whether acceptance would be equally high in a government - fielded survey .

as shown in table 4 , an acs follow - back would potentially not meet any of the three criteria based on immigrant advocates' views .

only one survey ( nsduh ) met all three criteria based on immigrant advocates' views — and because of its sensitive questions on drug use , that survey did not meet the design - based table 3 criteria .

1 .

does a nongovernment organization conduct field work ? .

2 .

are interviews anonymous ( that is , no names or social security numbers are taken ) ? .

3 .

is sample too small for reliable small - area estimates of undocumented ? yes .

no .

no .

the census bureau conducts field work.no .

the census bureau conducts field work.yes .

no .

takes names .

no .

takes both names and social security numbers .

yes .

yes .

yes .

yes .

no .

only the census bureau can conduct field work .

no .

takes names in the initial survey , and a follow - back would be based on knowing each person's identity .

potentially , no .

a follow - back might be extremely large .

 ( also , small - area releases are not prohibited by law or policy. ) .

in conclusion , we did not find a large - scale survey that would be an appropriate vehicle for “piggybacking” the grouped answers question series .

for more than a decade , the congress has recognized the need to obtain reliable information on the immigration status of foreign - born persons living in the united states — particularly , information on the undocumented population — to inform decisions about changing immigration law and policy , evaluate such changes and their effects , and administer relevant federal programs .

until now , reliable data on the undocumented population have seemed impossible to collect .

because of the “question threat” associated with directly asking about immigration status , the conventional wisdom was that foreign - born respondents in a large - scale national survey would not accept such questions — or would not answer them authentically .

using the grouped answers approach to ask about immigration status seems promising because it reduces question threat and is statistically logical .

additionally , this report has established that the grouped answers approach is acceptable to most foreign - born respondents tested ( thus far ) in surveys fielded by private sector organizations ; it is also acceptable — with some conditions , such as private sector fielding of the survey — to the immigrant advocates and other experts we consulted .

a variety of research designs are available to help check whether respondents choose ( or intend to choose ) the correct box .

the grouped answers approach requires a fairly large number of personal interviews with foreign - born persons ( we estimate 6,000 ) to achieve reasonably precise indirect estimates of the undocumented population overall and within high - risk subgroups .

however , the most cost - efficient method of fielding a grouped answers question series — piggybacking on an existing survey — does not seem feasible .

rather , fielding the grouped answers approach would require a new survey focused on the foreign - born .

this raises two new questions about “next steps” — and the answers depend , in large part , on policymaker judgments , as described below .

question 1: are the costs of a new survey justified by information needs ? .

dhs stated ( in its comments on a draft of this report ) that the “information on immigration status and the characteristics of those immigrants potentially available through this method would be useful for evaluating immigration programs and policies.” the census bureau has indicated that information on the undocumented would help estimate the total population in intercensal years .

and an expert reviewer emphasized that a new survey of the foreign - born would be likely to help estimate the total population .

additionally , policymakers might deem a new survey of the foreign - born to be desirable for other reasons than obtaining grouped answers data .

notably , an immigration expert who reviewed a draft of this report pointed out that a survey focused on the foreign - born might provide more in - depth , higher - quality data on that population than existing surveys that cover both the u.s. - born and foreign born populations .

for example , more general surveys , such as the acs and cps ( 1 ) ask a more limited set of migration questions than is possible in a survey focused on the foreign - born , ( 2 ) are not designed with a primary goal of maximizing participation by the foreign - born ( for example , are not conducted by private sector organizations ) , and ( 3 ) as dhs pointed out in comments on a draft of this report , may not be designed to cover persons who are only temporarily linked to sampled households , because such persons may have arrived only recently in the united states and are temporarily staying with relatives .

a new survey aimed at obtaining grouped answers data on immigration status would require roughly 6,000 ( or more ) personal , self - report interviews with foreign - born adults .

other in - person , self - report interviews in large - scale surveys have cost $400 to $600 each .

a major additional cost would be obtaining a representative sample of foreign - born persons ; this would likely require a much larger survey of the general population in which “mini - interviews” would screen for households with one or more foreign - born individuals .

we did not study the likely costs of such a data collection or options for reducing costs .

however , survey costs can be estimated ( based on , for example , the experience of survey organizations ) , and policymakers can , in future , weigh those costs against the information need — keeping in mind the results of research on the grouped answers approach , to date , and experts' opinions on research needed .

question 2: what further tests of the grouped answers method , if any , should be conducted before planning and fielding a new survey ? .

on one hand , advance testing could assess response validity ( that is , whether respondents pick — or intend to pick — the correct box ) before committing funds for a survey and in time to allow adjustments to the question series ; further delineate respondent acceptance and explore the impact on acceptance of factors such as government funding — or funding by a particular agency — in order to inform decisions about whether or how to conduct a survey ; and as suggested in dhs's comments on a draft of this report , help determine the cost of a full - scale survey .

on the other hand , extensive advance testing would likely delay the survey - - and may not be needed because response validity could be assessed — and respondent acceptance could be further delineated — concurrently with or subsequent to the survey rather than in advance , the need for advance testing of response validity would be lessened if policymakers see a need for more or better survey data on the foreign - born additional to the need for grouped answers data on immigration status ( see discussion in question 1 , above ) ; the value of advance testing would be lessened if changes in immigration law and policy occurred between the time of an advance test and the main survey , because such changes could affect the context in which the survey questions are asked and , hence , change the operant levels of acceptance and validity ; and survey costs can be estimated — albeit more roughly — on the basis of the experience of survey organizations .

given the arguments for and against advance testing , it seems appropriate for these to be weighed by policymakers .

we provided a draft of this report to and received comments from the department of commerce , the department of homeland security , and the department of health and human services ( see appendices vii , viii , and ix , respectively ) .

the office of management and budget provided only technical comments , and the department of labor did not comment .

the census bureau agreed with the report's discussion of the grouped answers method , including its strengths and limitations ; the census bureau - gss evaluation , including the conclusions of the independent consultant ( alan zaslavsky ) ; and the need for a “validity study” to determine whether the grouped answers method can “generate accurate estimates” of the undocumented population .

the census bureau also provided technical comments , which we used to clarify the report , as appropriate .

the department of homeland security stated that the kinds of information that the grouped answers approach would provide , if successfully implemented , would be useful for evaluating immigration programs and policies .

dhs further called for pilot testing by gao to assess the reliability of data collection and to help estimate the costs of an eventual survey .

as we indicate in the “observations” section of this report , two key decisions for policymakers concern whether to invest in a new survey and whether substantial testing is required in advance of planning and fielding a survey .

we believe that depending on the answers to these questions , another issue — one we cannot address in this report — would concern identifying the most appropriate agency for conducting or overseeing ( 1 ) tests of the grouped answers and ( 2 ) an eventual survey of the foreign - born population .

however , we believe that conducting or overseeing such tests or surveys is a management responsibility and , accordingly , is not consistent with gao's role or authorities .

dhs made other technical comments which we incorporated in the report where appropriate .

the department of health and human services ( hhs ) agreed that the nsduh would not be an appropriate vehicle for a grouped answers question series .

commenting on a draft of this report , hhs said that the report should include more information on variance calculations and on “mirror - image” estimates .

therefore , we ( 1 ) added a footnote illustrating the variance costs of a grouped answers estimate relative to a corresponding direct estimate and ( 2 ) developed appendix vi , which gives the formula for calculating the variance of a grouped answers estimate and discusses “mirror image” estimates .

additionally , hhs said that interviewers should more accurately communicate with respondents when presenting the three - box cards .

we believe that the text of appendix v on informed consent , based on our earlier discussions with privacy experts at the census bureau , deals with this issue appropriately .

as we state in appendix v , it would be possible to explain to respondents that “there will be other interviews in which other respondents will be asked about some of the box b categories or statuses.” finally , hhs made other , technical comments , which we incorporated in the report , as appropriate .

the office of management and budget provided technical comments .

in addition , our discussions with omb prompted us to re - order some of the points in the “observations” section of the report .

the department of labor informed us that it had no substantive or technical comments on the draft of the report .

we are sending copies of this report to the director of the census bureau , secretary of homeland security , secretary of health and human services , secretary of labor , director of the office of management and budget , and to others who are interested .

we will also provide copies to others on request .

in addition , the report will be available at no charge on gao's web site at http: / / www.gao.gov .

if you or your staff have any questions regarding this report , please call me at ( 202 ) 512-2700 .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

other key contributors to this assignment were judith a. droitcour , assistant director , eric m. larson , and penny pickett .

statistical support was provided by sid schwartz , mark ramage , and anna maria ortiz .

to gain insight into the acceptability of the grouped answers approach , we discussed the approach with numerous experts in immigration studies and immigration issues , including immigrant advocates .

table 5 lists the experts we met with and their organizations .

to ensure that we identified immigration experts from varied perspectives , we consulted demetrios g. papademetriou , who is among the immigration experts listed in table 5 , and michael s. teitelbaum , vice president of the alfred j. sloan foundation .

with respect to immigrant advocates , we sought to include advocates who represented ( 1 ) immigrants in general , without respect to ethnicity ; ( 2 ) hispanic immigrants , as these are the largest group of foreign - born residents ; ( 3 ) asian american immigrants , as these are also a large group ; and ( 4 ) arab american immigrants , as these have been the target of interior ( that is , nonborder ) enforcement efforts in recent years .

to determine what the 2004 general social survey ( gss ) test indicated about the acceptability of grouped answers questions to foreign - born respondents and its “generally usability” in large - scale surveys , we obtained the census bureau's report of its analysis of those data , and we assessed the reliability of the gss data through a comparison of answers to interrelated questions .

then we submitted the census bureau's report of its analysis to dr. alan zaslavsky , an independent expert , for review ; developed our own analysis of the gss data and submitted our paper describing that analysis to the same expert ; and summarized the expert's conclusions and appended his report and the census bureau's report ( reproduced in appendixes iii and iv ) , as well summarizing our conclusions .

we used these procedures to ensure independence , given that the gss test was based on our earlier recommendation that the census bureau and the department of homeland security ( dhs ) test the grouped answers approach .

to describe additional research that might be needed , we outlined the grouped answers approach and reviewed the main conclusions of the gss test in meetings with the immigration experts listed in table 5 and with private sector statisticians .

additionally , we discussed the approach with various federal officials and staff at agencies responsible for fielding large - scale surveys .

to assess the precision of indirect estimates , we addressed questions to dr. zaslavsky , developed illustrative tables showing hypothetical calculations under specified assumptions , and subjected those tables to review .

to identify and describe candidate surveys for piggybacking the grouped answers question series , we set minimum criteria for consideration ( nationally representative , mainly or only in - person interviews , and data on at least 50,000 persons overall , including native - born and foreign - born ) .

then we identified surveys that met those criteria , collected documents concerning the surveys , and interviewed officials and staff at federal agencies that sponsored or conducted those surveys .

we also talked with experts in immigration about additional key criteria for selecting an appropriate survey .

the scope of our work had several limitations .

we did not attempt to collect new data from foreign - born respondents in a survey , focus group , or other format .

we did not assess census or survey coverage of the foreign - born or undocumented populations .

we did not assess nonresponse rates among foreign - born or undocumented persons selected for interview .

we did not review alternative methods of obtaining estimates of the undocumented .

while we consulted a number of private sector experts and sought to include a range of perspectives , other experts may have other views .

finally , we do not know to what extent the broad range of persons who compose immigrant communities share the views of the immigrant advocates we spoke with .

logically , grouped answers data can be used to estimate subgroups of the undocumented population , using the following procedures: 1. isolate survey data for ( a ) the subsample 1 respondents who are in the desired subgroup , based on a demographic or other question asked in the survey ( for example , if the survey included a question on each respondent's employment , data could be isolated for foreign - born who are employed ) , and ( b ) subsample 2 respondents in that subgroup ; 2. calculate ( a ) the percentage of the subsample 1 subgroup respondents who are in each box of immigration status card 1 and ( b ) the percentage of subsample 2 subgroup respondents who are in each box of immigration status card 2 ; and 3. carry out the subtraction procedure ( percentage in box b , card 1 , minus percentage in box a , card 2 ) , thus estimating the percentage of the subgroup who are undocumented .

the resulting percentage can be multiplied by a census count or an updated estimate of the foreign - born persons who are in the subgroup ( for example , multiply the estimate of the percentage of employed foreign - born who are undocumented by the census count or updated estimate of the number of employed foreign - born ) .

these steps can be repeated to indirectly estimate the size of the undocumented population within various subgroups defined by activity , demographics , and other characteristics ( such as those with or without health insurance ) that are asked about in the survey .

without an extremely large survey , it would be difficult or impossible to derive reliable estimates for subgroups with few foreign - born persons or few undocumented persons .

ongoing surveys conducted annually have sometimes combined 2 or 3 years of data in order to provide more reliable estimates of low - prevalence groups ; however , there is a loss of time - specificity .

program cost data are sometimes available on an average per - person basis , and surveys sometimes ask about benefit use .

in such cases , the total costs of a program associated with a certain group can be estimated .

program costs associated with the undocumented population might be estimated by either ( 1 ) multiplying the estimated numbers of undocumented persons receiving benefits by average program costs or ( 2 ) performing the following procedures: 1 .

isolate survey data for all foreign - born subsample 1 respondents who said they were in box b of card 1 and estimate each individual respondent's program cost .

then aggregate the individual costs to estimate the total program cost ( potentially , millions or billions of dollars ) associated with the population of foreign - born persons defined by the group of immigration statuses in box b , card 1 .

2 .

isolate data for all foreign - born subsample 2 respondents who said they were in box a of card 2 and , as above , estimate each individual respondent's program costs , aggregating these to estimate the total program costs associated with the population of foreign - born persons defined by the immigration statuses in box a , card 2 ( again , potentially millions or billions of dollars ) .

3 .

because the only difference between the immigration statuses in box b , card 1 , and box a , card 2 , is the inclusion of the undocumented status in box b , card 1 , start with the total program cost estimate for all box b , card 1 , respondents and subtract the corresponding cost estimate for box a , card 2 , respondents .

the result of the subtraction procedure represents an indirect estimate of program costs associated with the undocumented population .

a more precise cost estimate can be obtained by calculating an additional “mirror image” cost estimate — this time , starting with costs estimated for respondents in box b of card 2 and subtracting costs associated with respondents in box a of card 1 .

the two “mirror image” estimates could then be averaged .

the key limitations on such procedures are sample size and the representation of key subgroups — for example , foreign - born respondents residing in small states and local areas .

thus , for example , it is possible that state - level costs associated with undocumented persons might be estimated with reasonable precision for a large state or city with many foreign - born persons and a relatively high percentage of undocumented ( potentially , california or new york city ) but not for many smaller states or areas , unless very large samples ( or samples focused on selected areas of interest ) were drawn .

further work could explore the ways that complex analyses could be conducted to help delineate costs .

contributions can be conceptualized as contributions to the economy through work or , potentially , through taxes paid .

such contributions might be estimated by combining grouped answers data with other survey questions to estimate relevant subgroups , such as employed undocumented persons .

in complex analyses , these data could potentially be combined with other data to help estimate taxes paid .

logically , other quantitative estimates might be obtained through procedures similar to those outlined above for estimating program costs .

for example , the numbers of children in various immigration statuses might be estimated by asking an adult respondent how many foreign - born children ( or how many foreign - born school - age children ) reside in the household and then — using the 3-box card assigned to the adult respondent — asking how many of these children are in box a , box b , and box c. we note that , thus far , testing has not asked respondents to report children's immigration status with the grouped answers approach .

if subsamples 1 and 2 are sufficiently large , it might also be possible to estimate the portion of the undocumented population represented by “overstays” who were legally admitted to this country for a specific authorized period of time but remained here after that period expired ( without a timely application for extension of stay or change of status ) and currently undocumented persons who are applicants for legal status and are waiting for dhs to approve ( or disapprove ) their application .

to estimate overstays would require a separate question on whether the respondent had entered the country on a temporary visa .

to estimate undocumented persons with pending applications would require a separate question concerning pending applications for any form of legal status ( including , for example , applications for u.s. citizenship as well as applications for legal permanent resident status and other legal statuses ) .

the precision of such estimates would depend on factors such as sample size , the percentages of foreign - born who came in on temporary visas or who have pending applications of some kind , and the numbers of undocumented persons within these groups .

appropriately informing each respondent about what information he or she is being asked to provide is a key issue .

on one hand , the grouped answers approach logically conveys to each respondent exactly what he or she is being asked to reveal about himself or herself ; no one we spoke with suggested otherwise .

on the other hand , the grouped answers question series does not indicate that the respondent is being asked to participate in an effort that will result in estimates of all immigration statuses .

therefore , a statement is needed to convey this information .

officials and staff at the national center for health statistics ( nchs ) were particularly concerned about this issue and believed that failing to adequately address informed consent issues could be considered unethical .

privacy protection specialists at the census bureau said that an introductory statement before the first immigration - related question might be phrased , “the next questions are geared to helping us know more about immigration and the role that it plays in american life.” when each respondent is shown the 3-box training cards , it would be possible to explain to him or her that — while the survey does not ask , and does not want to know , the specifics of which box b category applies to him or her — there will be other interviews in which other respondents will be asked about some of the box b categories or statuses .

just before showing each respondent the immigration status card , it should be stated — and , in fact , interviewers stated in the test with hispanic farmworkers — that “using the boxes allows us to obtain the information we need , without asking you to give us information that you might not want to.” further: “because we're using the boxes , we won't ‘zero in' on anything somebody might not want to tell us.” it may also be possible to explain that the study's goal is to allow researchers to broadly estimate all categories or statuses on the card for the population of immigrants — but to indicate that this will be done without ever asking questions that “zero in” on something that some respondents might not want to disclose in an interview .

neither the estimation method ( that is , the two cards ) nor the specific policy relevance of immigration - status estimates would have to be described to all respondents .

however , interviewer statements should be provided for responding to respondents who have doubts or questions .

the statistical expression and variance of a grouped answers estimate is as follows , with the starting point being the percentage or proportion of subsample 1 who are in box b , card 1 , and the procedure being to subtract from this the proportion of subsample 2 who are in box a , card 2 ( with cards and boxes as defined as in figure 3 ) :grouped answers estimate = p. where p = the proportion of subsample 1 in box b , card 1 p ) = [ ( pq ) + ( p / n = the proportion of subsample 1 not in box b , card 1 q = 1 – p = numbers of respondents in subsamples 1 and 2 , respectively .

the immigration status cards in figure 3 are designed so that boxes a and b include all major immigration statuses .

this design ensures that , on each card , the box b categories apply to the largest possible number of legally present respondents .

in designing the cards this way , we reasoned that this should reduce the question threat associated with choosing box b .

as a result , few respondents are expected to choose box c ( “some other category not in box a or box b” ) .

for example , in the 2004 gss test , only one foreign - born respondent of more than 200 chose box c. therefore , we believe that for purposes of illustrative variance calculations , it is reasonable to assume that no one chooses box c. under this assumption , the two mirror - image estimates of the percentage of the foreign - born who are undocumented would necessarily be exactly the same , as explained below .

for simplicity , the discussion in this appendix assumes simple random sampling , for both the main sample and the selection of the two subsamples .

the alternative , mirror - image estimate can then be defined as follows: as indicated above , q are defined in terms of p and p = ( 1 – q ) – ( 1 – q = q in other words , under the assumption that no one chooses box c , the mirror - image estimates of the percentage undocumented are , by definition , identical .

thus , no precision gain follows from combining them .

no additional information is provided by a second , mirror - image estimate .

in contrast , quantitative indirect estimates are based on a combination of ( 1 ) grouped answers data and ( 2 ) additional , separate quantitative data or estimates ( for example , per - person estimates of emergency - visit costs based on respondent reports of number of emergency room visits in the past year and other information from hospitals on per - visit costs ) .

if the quantitative data are tallied or totaled for individuals in each box of each card , the result is four different figures , none of which can be derived from the others .

 ( there are different respondents in each box , and each would have separately reported how many emergency room visits , for example , he or she made in the past year. ) .

thus , for quantitative estimates of this type , calculating two independent mirror - image estimates , and averaging them , may yield a more precise result .

nancy r. kingsbury , ( 202 ) 512-2700 or kingsburyn@gao.gov .

key gao staff contributing to this report include judith a. droitcour , eric m. larson , and penny pickett .

statistical support was provided by sid schwartz , mark ramage , and anna maria ortiz .

bird , ronald .

statement of ronald bird , chief economist , office of the assistant secretary for policy , u.s. department of labor , before the committee on the judiciary , u.s. senate , july 5 , 2006 .

boruch , robert , and joe s. cecil .

assuring the confidentiality of social research data .

philadelphia: university of pennsylvania press , 1979 .

camarota , steven a. , and jeffrey capizzano .

“assessing the quality of data collected on the foreign born: an evaluation of the american community survey ( acs ) : pilot and full study findings,” immigration studies white papers , sabre systems inc. , april 2004. http: / / www.sabresys.com / whitepapers / cis_whitepaper.pdf ( sept. 6 , 2006 ) .

costanzo , joseph , and others , “evaluating components of international migration: the residual foreign - born,” population division working paper 61 , u.s. census bureau , washington , d.c. , june 2002 , p. 22 .

droitcour , judith a. , and eric m. larson , “an innovative technique for asking sensitive questions: the three - card method,” bulletin de mèthodologie sociologique , 75 ( july 2002 ) : 5 – 23 .

el - badry , samia , and david a. swanson , “providing special census tabulations to government security agencies in the united states: the case of arab - americans,” paper presented at the 25th international population conference of the international union for the scientific study of population , tours , france , july 18 – 23 , 2005 .

hill , kenneth .

“estimates of legal and unauthorized foreign - born population for the united states and selected states based on census 2000.” presentation at the u.s. census bureau conference , immigration statistics: methodology and data quality , alexandria , virginia , february 13 – 14 , 2006 .

hoefer , michael , nancy rytina , and christopher campbell .

estimates of the unauthorized immigrant population residing in the united states: january 2005 .

washington , d.c.: department of homeland security , office of immigration statistics , august 2006 .

gao .

undocumented aliens: questions persist about their impact on hospitals' uncompensated care costs , gao - 04-472 .

washington , d.c.: may 21 , 2004 .

gao .

illegal alien schoolchildren: issues in estimating state - by - state costs , gao - 04-733 .

washington , d.c.: june 23 , 2004 .

gao .

overstay tracking: a key component of homeland security and a layered defense , gao - 04-82 .

washington , d.c.: may 21 , 2004 .

gao .

record linkage and privacy: issues in creating new federal research and statistical information .

gao - 01-126sp .

washington , d.c.: april 2001 .

gao .

survey methodology: an innovative technique for estimating sensitive survey items , gao / ggd - 00-30 .

washington , d.c.: november 1999 .

gao .

immigration statistics: information gaps , quality issues limit utility of federal data to policymakers , gao / ggd - 98-164 .

washington , d.c.: july 31 , 1998 .

greenberg , bernard g. , and others .

“the unrelated questions randomized response model: theoretical framework.” journal of the american statistical association , 64 ( 1969 ) : 520 – 39 .

kincannon , charles louis , “procedures for providing assistance to requestors for special data products known as special tabulations and extracts,” memorandum to associate directors , division chiefs , bureau of the census , washington , d.c. , august 26 , 2004 .

locander , william , and others .

“an investigation of interview method , threat , and response distortion.” journal of the american statistical association , 71 ( 1976 ) : 269 – 75 .

national research council , committee on national statistics , local fiscal effects of illegal immigration: report of a workshop .

washington , d.c.: national academy press , 1996 .

passel , jeffrey s. “the size and characteristics of the unauthorized migrant population in the u.s.: estimates based on the march 2005 current population survey.” research report .

washington , d.c.: pew hispanic center , march 7 , 2006 .

passel , jeffrey s. , rebecca l. clark , and michael fix .

“naturalization and other current issues in u.s. immigration: intersections of data and policy,” in proceedings of the social statistics section of the american statistical association: 1997 .

alexandria , va.: american statistical association , 1997 .

robinson , j. gregory .

“memorandum for donna kostanich.” dssd a.c.e .

revision ii memorandum series no .

pp - 36 .

washington , d.c.: u.s. bureau of the census , december 31 , 2002 .

rytina , nancy f. estimates of the legal permanent resident population and population eligible to naturalize in 2004 .

washington , d.c.: department of homeland security , office of immigration statistics , february 2006 .

schryock , henry s. , and jacob s. siegel and associates .

the methods and materials of demography .

washington , d.c.: u.s. government printing office , 1980 .

siegel , jacob s. , and david a. swanson .

the methods and materials of demography , 2nd ed .

san diego , calif.: elsevier academic press , 2004 .

u.s. census bureau , “the u.s. census bureau's intercensal population estimates and projections program: basic underlying principles,” paper distributed by the census bureau at its conference on population estimates: meeting user needs , alexandria , virginia , july 19 , 2006 .

u.s. commission on immigration reform .

u.s. immigration policy: restoring credibility: 1994 report to congress .

washington , d.c.: u.s. government printing office , 1994 .

u.s. immigration and naturalization service , office of policy and planning .

estimates of the unauthorized immigrant population residing in the united states: 1990 to 2000 .

washington , d.c.: january 2003 .

u.s. department of labor , findings from the national agricultural workers survey ( naws ) 2000 – 2002: a demographic and employment profile of united states farm workers .

research report 9 .

washington , d.c.: march 2005 .

warner , stanley .

“randomized response: a survey technique for eliminating evasive answer bias.” journal of the american statistical association , 60 ( 1995 ) : 63 – 69 .

warren , robert , and jeffrey s. passel .

“a count of the uncountable: estimates of undocumented aliens counted in the 1980 census.” demography , 24:3 ( 1987 ) : 375 – 93 .

