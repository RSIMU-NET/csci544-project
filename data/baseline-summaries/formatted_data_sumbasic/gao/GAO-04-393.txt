computer software has increasingly become a critical component for department of defense ( dod ) weapon systems .

the development of complex software represents a potential leap forward in operational capability for any number of dod defense acquisitions — from stabilizing a weapon to providing all of the key functions needed in an avionics system .

technological advancements have even made it possible for software to perform functions once handled by hardware .

as the demand for complex software grows , the need for discipline while developing and delivering software also increases .

in recent years , dod has attributed significant cost and schedule overruns of software - intensive systems to difficulties in developing and delivering software .

dod estimates that it spends about 40 percent of its research , development , test , and evaluation budget on software — $21 billion for fiscal year 2003 .

furthermore , dod and industry experience indicates that about $8 billion ( 40 percent ) of that amount may be spent on reworking software because of quality - related issues .

we previously reported that dod did not have effective and consistent corporate or software processes for software acquisitions , has had difficulty in implementing disciplined processes developed by industry experts , and some components had no software acquisition programs focused on improving processes and practices .

we recommended that dod correct these deficiencies by developing software process improvement programs .

in december 2002 congress required the secretaries of each military service and the head of those defense agencies that manage major defense software - intensive acquisition programs to develop process improvement programs for software acquisitions .

subsequently , the senate committee on armed services requested that we ( 1 ) identify the best practices and knowledge - based metrics used by leading companies to develop software , ( 2 ) analyze the causes of poor outcomes of selected dod software - intensive acquisition programs , and ( 3 ) evaluate dod's efforts to develop software process improvement programs and assess how those efforts compare with leading companies' practices to improve software acquisition processes .

dod's major weapon systems rely more heavily on software to achieve their performance characteristics than ever before .

according to information in a 2000 defense science board report , in the last 40 years , functionality provided by software for aircraft , for example , has increased from about 10 percent in the early 1960s for the f - 4 to 80 percent for the f / a - 22 , which is currently under development .

the reasons for this are simple: performance requirements for weapon systems have become increasingly demanding , and breakthroughs in software capability have led to a greater reliance on software to provide more capability when hardware limitations are reached .

along with this , dod's practice of expecting leaps in capability has placed extreme reliance on software development in most acquisitions .

as dod moves to more complex acquisitions — such as the integration of multiple systems in a single “system of systems” — understanding and addressing software development issues have become even more critical for dod in order to control cost and deliver systems on time .

we have issued a series of reports on the knowledge that leading commercial firms gain and use to manage and control the acquisition and development costs of their products .

leading firms attain knowledge early in the development process about the technology they plan to incorporate and ensure that resources match requirements .

they make sure the design is mature before approving production and have production processes under control before production begins .

implicit in this approach to product development is the successful development of software .

software is rapidly becoming a significant , if not the most significant , part of dod's acquisitions .

for example , software enables a missile to recognize a target ; on some weapon systems , functionality as basic as flight is no longer possible without sophisticated software .

in addition to successful commercial practices and other significant resources that have proven effective for managing software acquisition and development , dod has at its disposal numerous reports and recommendations by industry experts to transform dod's software development process .

this community of experts includes independent engineering teams , senior advisors on dod's defense science board , and carnegie mellon university's software engineering institute .

although they have offered detailed guidance , dod's software - intensive weapon system acquisitions remain plagued by cost overruns , schedule delays , and failure to meet performance goals .

dod is an acquisition organization — that is , it acquires major weapon systems and manages the overall acquisition process as well as the contractors who are tasked with developing the systems and associated software .

the more managers know about software development processes and metrics , the better equipped they are to acquire software .

on dod's weapon system programs , the software development process is a part of the larger weapon system acquisition process .

software development has similar phases and — in the case of new systems — occurs in parallel with hardware development until software and hardware components are integrated .

the following describes the four phases common to all software development: determining requirements: software development begins with performance requirements for the component or for the fully integrated product .

ideally , a team of system and software engineers , users , acquirers or their representatives analyzes the overall requirements — operational characteristics , user interfaces , speed , maneuverability , survivability , and usability — and translates them into specific requirements , allocating some to software and others to hardware .

in more mature organizations , before making a commitment to develop a component or product , the software developer validates that the requirements allocated to software are realistic , valid , testable , and supportable .

management approves the requirements before the design phase begins .

systems engineering , a comprehensive technical management tool , provides the knowledge necessary to translate the acquirer's requirements into specific capabilities .

with systems engineering knowledge in hand , the acquirer and the developer can work together to close gaps between expectations and available resources — well before a program is started .

some gaps can be resolved by the developer's investments , while others can be closed by finding technical or design alternatives .

remaining gaps — capabilities the developer does not have or cannot get without increasing the price and timing of the product beyond what the acquirer will accept — must be resolved through trade - offs and negotiation .

the basic steps in systems engineering include the following: defining what the acquirer wants , how the final product is to be used , what the operating environment will be , and what the performance characteristics are ; turning the requirements into a set of specific functions that the system must perform ; and identifying the technical and design solutions needed to meet the required functions .

completion of these steps leads to a product design .

establishing a stable design: the software development team develops a design that meets the software's desired functions .

numerous activities and documents typically are necessary to demonstrate that all of the software requirements are incorporated into a preliminary design and that functionality can be fully tested .

the developer may construct a prototype for the acquirer to test the understanding of the requirements during the design phase .

if management approves the preliminary design , the developer refines the design and managers conduct a critical design review before giving approval for the coding phase to begin .

manufacturing code: software code translates requirements and a detailed design into an executable series of instructions .

in more mature software development organizations , developers are required to follow strict coding practices .

these include ensuring that the code is reviewed by knowledgeable peers addresses requirements specified in the final design and follows strict configuration control procedures to ensure that no “secret code” is put in the system and generally follows coding documentation guidelines that enable software engineers other than the coder to understand and maintain the software .

testing to validate that software meets requirements: to ensure that the design is ready for coding , testing activities start during the design phase and then continue through the coding phase .

the testing of code is an important and critical phase and results in a series of quality - assurance tasks that seek to discover and remove defects that would hinder the software's performance .

completing these tasks requires the testers to coordinate with various stakeholders , such as the quality assurance group , to define test criteria that sufficiently test the approved software requirements .

significant resources are available to dod for improving its software acquisition outcomes .

among these is carnegie mellon university's software engineering institute , a federally funded research and development center .

the software engineering institute has identified specific processes and practices that have proven successful in fostering quality software development .

the institute has constructed models for developing and acquiring software , developing and implementing software process improvement programs , and integrating hardware and software into a weapon system .

to help organizations meet cost , schedule , and performance goals , the institute has issued guidance for adopting its models .

the commercial firms we visited and dod , both of which use the institute's models , consider them to be an industry standard .

the institute created the models to provide general guidance for software development and acquisition activities that programs can tailor to meet their needs .

these models can also be used to assess an organization's capability for developing or acquiring software .

the software capability maturity model® , for example , focuses on improving software development processes .

the model rates software maturity according to five levels of maturity: initial: the software process is characterized as ad hoc .

success depends on individual effort .

repeatable: the basic process is in place to track cost , schedule , and functionality .

some aspects of the process can be applied to projects with similar applications .

defined: there is a standardized software process for the organization .

all projects use some approved version of this process to develop and maintain software .

managed: the organization uses and collects detailed data to manage and evaluate progress and quality .

optimizing: quantitative feedback about performance and innovative ideas and technologies contribute to continuous process improvement .

in addition , the institute has created a model specifically for software acquisition .

this model follows the same five principles as the previous model but emphasizes acquisition issues and the needs of individuals and groups who are planning and managing software acquisition activities .

a third model focuses on the integration of hardware and software and has a heavier emphasis in systems engineering .

 ( see appendix ii for a description of the three models. ) .

despite acknowledgment of significant problems and access to extensive resources , dod's problems with software acquisition have continued .

in 2000 the defense science board's task force on defense software reviewed selected dod software - intensive systems and found that the programs lacked a well thought out , disciplined program management plan and software development process .

the programs lacked meaningful cost , schedule , and requirements baselines , making it difficult to track progress .

these findings are echoed by the work of dod's tri - service assessment initiative , an independent group that evaluates army , air force , and department of navy programs' software management processes and offers guidance for developing software in a disciplined manner .

the tri - service initiative found that three of the leading causes of problems in software - intensive systems are process capability , requirements management , and organizational management .

a 1999 study performed by the standish group , an organization that researches risk , cost , and investment return for information technology investments , found that about one - third of software development programs — commercial or military — resulted in cancellation .

furthermore , in a series of studies completed through the 1990s , the group , found that the average cost overrun was 189 percent ; the average schedule overrun was 222 percent of the original estimate ; and , on average , only 61 percent of the projects were delivered with originally specified features or functions .

to address its problems with weapon acquisition , including software - intensive weapon systems , dod recently revised its requirements generation and acquisition policies to incorporate a more evolutionary framework and improve its ability to deliver more capability to the acquirer faster .

leading software companies we visited have been successful at software development largely because they establish a manageable product development environment , disciplined processes , and strong metrics to manage program outcomes .

key characteristics of a successful environment include evolutionary product development and continuous improvement of development capabilities so outcomes are more predictable .

within this environment , these companies use a structured management review process , and at the end of each of four key development phases — requirements , design , coding , and testing — the companies conduct reviews so that the development team does not progress to the next phase unless it attains a certain level of knowledge .

a great deal of management attention is placed on the requirements - setting phase because missing , vague , or changing requirements tend to be a major cause of poor software development outcomes .

finally , leading developers we visited track cost and schedule outcomes with the help of a critical management tool , called earned value , a key indicator , or metric , for identifying and mitigating risk .

in addition to earned value , developers use metrics for the size of a project , requirements , tests , defects , and quality to assess software development progress and to identify potential areas of improvement .

developers share this information with acquirers , who use the data to assess the risk software development has on overall product development and to make informed decisions about acquisitions .

figure 1 shows that a manageable environment , disciplined processes , and useful metrics are used together to form an effective process for software development .

three leading companies we visited — general motors powertrain unit motorola global software group ( gsg ) ; and teradata , a division of national cash register corporation ( ncr ) — made a concerted effort to establish an environment that lowers risk and increases the chances of successful software development outcomes .

this environment focuses on producing what is possible by establishing evolutionary product development while adhering to well - understood , well - defined , manageable requirements and encouraging continuous improvement of development processes .

the environment enables leading companies to effectively compete in markets where delivery times are paramount and the acquirer expects reasonable prices and can go elsewhere with its business if not satisfied .

over time , these leading companies have learned that an evolutionary process emphasizing knowledge and quality enables successful outcomes .

in comparison , an environment that allows too many risks , unknowns , and immature processes into product development can have poor outcomes .

in high - risk , low - technology maturity environments , developers find themselves forcing software to meet unrealistic expectations .

officials at each of the companies we visited said that evolutionary product development is one of the fundamental elements of a manageable environment .

evolutionary development reduces risk because it allows software to be developed in small , manageable increments , with the availability of the complete software package coming later in the development life cycle .

the general motors powertrain unit , which manufactures engines and transmissions , follows an evolutionary approach that calls for four to eight releases of the software product line each year .

this approach offers many benefits , including allowing the software teams to restrict the size of projects to make them more manageable and to reduce risk .

in addition , only well - defined requirements are included in the scope of the work , allowing the software teams to make improvements to previous releases .

these leading companies consider continuous improvement to be an important part of their environment and culture , and most have implemented one of the software engineering institute's capability maturity models® .

they have found that ad - hoc processes make it impossible to gain a clear understanding of when and how defects occur and make it difficult to fix processes so that the same defects can be avoided in the future .

motorola gsg officials told us it is not enough to hire talented software developers to achieve successful outcomes .

rather , companies must establish the right environment and use disciplined processes to help developers work efficiently and then target their recruiting efforts toward staff who can work in a process - oriented environment .

this is not an easy task .

companies must be willing to invest time and money to develop new processes , collect meaningful data on a consistent basis , and train employees to follow the processes and interpret the data .

in addition , management must display a strong commitment toward implementing the improved processes .

within a low - risk , continuous improvement environment , leading companies we visited use a very structured , gated software development process that requires teams to obtain knowledge about the maturity of their software projects at key points in time .

they plan , manage , and track activities for requirements , design , coding , and testing and rely heavily on such activities as configuration management , peer reviews , and quality assurance to help ensure the quality of their software .

they also identify areas of risk and take actions to control the risks .

developers pay particular attention to the requirements - setting process because requirements are the foundation of a development effort .

if requirements are not well defined or if there are too many changes , the result is additional , sometimes unmanageable risk .

figure 2 is a general depiction of the process used by the companies we visited to manage software development .

there are four development phases: determining requirements , establishing a stable design , manufacturing code , and testing to validate that the software meets the requirements and to detect errors .

within each phase are key activities that must take place and knowledge , or information , that must be attained to pass a review and move to the next phase of development .

in addition to the four software development phases , these companies consider quality assurance , configuration management , measurement , and analysis to be integral parts of their software development activities .

these activities assist developers in adequately managing software projects and collectively give the developer and the acquirer a level of confidence that the software is being developed within cost , schedule , performance , and quality targets .

for example , configuration management allows developers to maintain a historical perspective of each software version change , keep a record of the comments made about the changes , and verify the resolution of defects .

quality assurance activities are typically focused on detecting and resolving defects .

however , some companies , like motorola gsg , may assign responsibility for detecting and resolving defects to the project team and focus their quality assurance activities on evaluating whether project - associated work products adhere to the applicable process standards and procedures .

in this case , quality assurance activities would also include ensuring that when the project teams do not comply with processes , these instances are identified , reported , and resolved at the appropriate level .

officials at each company we visited told us that the earlier defects are found and fixed , the less costly it is to the organization .

if the defects are not found in the phase in which they occur , the cost to correct them grows in subsequent phases to the point where it could cost the company a significant amount of money to fix the problem once the software is fielded than if it had been corrected earlier .

senior managers at software development and acquisition companies we visited expect requirements to be managed and controlled before design work begins and virtually all lower - level design elements to be adequately defined before the start of coding .

without adequate definition and validation of requirements and design , software engineers could be coding to an incorrect design , resulting in missing functionality or errors .

motorola gsg , a communications company , and teradata , a division of ncr that specializes in database technology , estimate that about 95 percent of their requirements are set by the end of the requirements phase and 98 percent by the end of the design phase .

officials view managing requirements as the most critical development task to ensure successful software outcomes .

they said that many software problems , often referred to as defects , could be traced to missing , vague , or changing requirements .

although company officials stated that some requirements - related defects are inevitable , such as those that arise when requirements are not sufficiently detailed , they said significant time and effort are necessary to elicit and document all requirements and determine the appropriate sequence for meeting these requirements .

nevertheless , mature organizations take time to conduct the various activities to sufficiently document and validate requirements before proceeding to preliminary design .

leading software developers told us they typically devote about 20 to 30 percent of their software development time to requirements - setting activities .

doing so ensures that developers will be able to provide managers with key knowledge at the requirements review gate and show that requirements have been properly vetted with the acquirer and that they are achievable and well written .

activities they complete are highlighted below .

establish integrated project teams: representatives from all acquirer and developer stakeholder groups use sound systems engineering techniques to establish software requirements .

categorize requirements: acquirer and software team develop a comprehensive list of requirements and then categorize them on the basis of how critical they are to the product's performance .

negotiate requirements: software team develops resource and schedule estimates on the basis of system engineering knowledge and past projects of similar size and scope .

the software team then advises the acquirer which requirements may have to be delayed or sacrificed on the basis of resource and schedule goals .

agree to requirements baseline: software team and acquirer agree to a requirements baseline that details the software requirements , including cost , schedule , performance , and quality goals the software team is expected to achieve .

develop more detailed software requirements: using systems engineering , software team breaks the requirements into lower - level requirements , discusses the requirements with the acquirer , and formally documents the more detailed requirements .

perform quality check: organization performs quality checks on requirements - related documents , such as the functional requirements document , to ensure that requirements are written clearly and all of the acquirer's requirements have been adequately addressed .

company officials stress that to develop effective software requirements , the acquirer and developer must work closely together and have open and honest discussions about what can and cannot be done within desired time frames .

motorola gsg officials , for example , emphasize the importance of a written requirements baseline agreement with the acquirer to solidify software requirements and then strict adherence to requirements agreed to in order to avoid cost and schedule growth .

they also perform detailed quality reviews to detect requirements problems early and to avoid costly rework in later stages .

once developers establish requirements , they must also effectively manage the number and timing of requirements changes .

each developer we visited acknowledged that requirements could change at any point .

however , officials told us that they aggressively manage requirements changes to make sure that they are reasonable and do not have a detrimental impact on project outcomes .

for example , before making changes , they analyze the potential impact on cost , schedule , and performance and negotiate with the acquirer about whether the changes should be made within the ongoing project or in a future release .

the negotiation usually involves preparing an impact report for review by the acquirer or a governing board .

teradata , a division of ncr , goes further by limiting the number of changes it will make during the development cycle .

a stable design ensures that all requirements are addressed and that components and interfaces are defined .

a motorola gsg official stated that at least 90 percent of the company's software designs are stable before coding and suggested that developers that do not effectively manage the design phase could spend as much as 40 percent of a project's resources on rework activities .

leading companies complete a series of activities to stabilize their design and assure management that the software team is ready to advance to the next stage of development .

these activities include , among other things , defining the overall functions and structure of the software on the basis of established requirements ; selecting a system design ; and developing the detailed system design specifications , which are sometimes referred to as the low - level design .

typically , software teams will have two management reviews during this phase of development .

a preliminary design review is used to examine the design rationale and design assumptions to ensure that the resulting software systems will meet the stated requirements .

particular attention is given to high - priority aspects of the system , such as performance , security , maintainability , and system recovery .

user manuals and software test plans may also be examined at this time .

a critical design review is conducted once the detailed design of the software system has been completed .

the purpose of this review is to examine all design features to determine if they meet the acquirer's requirements .

throughout this phase companies typically perform peer reviews of design documents to detect errors and may also construct prototypes for the acquirers to test their understanding of the requirements .

during the coding phase , software developers translate the requirements and design into a series of software steps that will control the system .

according to company officials , well - written , achievable requirements , as well as very detailed designs , greatly enhance a software developer's ability to create software with relatively few defects .

additional processes that are critical to the success of this phase include peer reviews , coding standards , frequent unit testing , access to a library of pre - coded and tested functionality , and use of programming languages that enable the software engineer to document the code to facilitate understanding at a later time .

for example , the leading companies we visited rely heavily on previously developed software to reduce development time , costs , and testing .

according to company officials , it is not uncommon for them to reuse 70 percent of previously developed software on a new project .

general motors powertrain officials emphasized that reuse is a top consideration for their projects and they have developed a software product line that teams use to complete requirements , design , and coding activities .

over the past few years , they have also re - engineered some of their electronic modules to allow for greater standardization of components within and across their powertrain portfolio .

this has greatly enhanced their ability to reuse software .

testing is then performed to uncover defects or gaps in the code .

leading software companies we visited develop test plans after requirements are stable and take steps to ensure that there are one or more tests for each requirement .

through testing , teams assess the quality of the software to make it as defect - free as possible .

for motorola gsg , the software team is in control of all of the coding , testing , and quality - assurance activities .

officials stated that teams have access to online training and rely on libraries of previously used and tested code .

they use peer reviews and inspections extensively during the requirements , design , and coding phases , for all software documents and test software and hardware components together to identify any integration problems that must be corrected .

leading developers we visited commonly use seven major types of metrics — cost , schedule , size , requirements , tests , defects and quality — to gauge a project's progress and identify areas for improvement .

acquirers use some of these same metrics to assess whether the developer will be able to deliver the software within cost , schedule , performance , and quality parameters .

we found that leading developers are relentless in their efforts to collect metrics to improve project outcomes and processes .

the importance of metrics to these companies cannot be overemphasized .

motorola gsg and teradata , a division of ncr , measure key aspects of software development for individual projects from the usual cost and schedule goals to process - improvement - type metrics that track the number and type of defects within each software development phase .

they also have goals and metrics for companywide initiatives , such as cost - reduction efforts and customer satisfaction .

equally important , they have emphasized the critical nature of measuring processes , collecting metrics , and using them to analyze performance into their workforce through training .

table 1 provides an overview of the seven categories of metrics used by the leading developers we visited , examples of their specific metrics , and how the companies use the metrics to manage their projects .

company officials cautioned that a variety of metrics could be used to satisfy each category listed in table 1 and that no one set of specific metrics would necessarily apply to all companies .

rather , companies tailor metrics from each category to fit their own needs .

leading developers we visited use metrics from each category above to actively oversee their projects and continuously assess their processes and projects to identify opportunities for improvement .

motorola gsg , for example , uses a standard set of metrics to enable project managers , as well as other levels of management , to assess the status of their individual software projects , staff productivity , requirements volatility , cost and schedule estimation accuracy , and the effectiveness of their quality assurance processes .

management also uses the information to compare similar projects within a software center or across the company to identify trends and areas that can be improved .

they are particularly interested in tracking the number of defects by software development phase , the amount of rework associated with correcting the defect , and the amount of project resources spent to ensure quality .

for example , data from one project show that developers were able to find and correct 92 percent of their problems during the phase in which they occurred .

the other 8 percent were corrected by the end of the system test phase , resulting in only 1 percent of total project resources being spent to correct defects .

motorola gsg uses an earned value management system to track the actual amount of time and effort it spends on project activities versus what it estimated for the projects .

the earned value system , when properly implemented , provides developers and acquirers with early warnings of problems that could significantly affect the software project's cost and schedule .

for example , according to private industry research , once a project is over 15 percent complete , developers will be unable to make up any overruns incurred to that point and the overruns will be even greater once the project is finished .

this is often because project planning typically underestimates the time and effort required to implement planned tasks .

motorola gsg uses a project time - tracking system to record the time spent on project activities attributed to the cost of quality and cost of poor quality metrics .

the cost of quality metric tracks the amount of time and money spent on such activities as formal quality reviews , testing , defect prevention , and rework to ensure a reliable product .

if more resources were expended on these activities than expected , motorola gsg would identify the reasons for this occurrence and improve its processes to try to prevent overruns from happening again .

the cost of poor quality is also a concern to motorola gsg because it quantifies the amount of rework that was necessary to address any product nonconformance , such as defects before ( internal failure ) and after ( external failure ) releasing the software product to the acquirer .

according to company officials , the cost of poor quality is a direct reflection of the effectiveness of a company's software development processes .

generally speaking , poor processes lead to greater rework and a higher cost of poor quality , while better processes lead to a small amount of rework and a low cost of poor quality .

motorola gsg officials stated they have been able to hold the cost of poor quality ( rework ) to less than 5 percent for its projects by identifying when defects occur and then looking for improvements in their processes to try to prevent them from happening again .

acquirers also need the types of metrics presented in table 1 to plan , manage , and track overall product development .

these types of metrics allow acquirers to make their own assessments of the status of the software development project , where the software project is headed , the potential risk that software presents to overall product development , and if the developer's processes are effective in terms of reducing cost and schedule and improving quality .

the earned value management system could provide acquirers with key information for calculating cost and schedule variations and also determining how much effort will be needed to complete a project on time when a project is behind schedule .

if acquirers determine that software is likely to be late or over cost at completion , they then have the option to move some of the software requirements to a later development effort or allow the software development team more time to complete the project .

in our reviews of five major dod software - intensive weapon system acquisitions , we found mixed results .

when dod managers had a smaller , more evolutionary product with manageable requirements , used disciplined development process with gated reviews , and collected and used metrics to manage software development progress — such as the tactical tomahawk and the f / a - 18-c / d programs — they delivered their product with less cost increase and less schedule delay .

when dod managers had expectations of developing revolutionary capabilities and did not use structured management reviews or collect and use metrics for software development — such as the f / a - 22 , sbirs , and comanche programs — they experienced significant cost growth and schedule delays .

table 2 illustrates how an evolutionary environment , effective process management , and use of meaningful metrics correlate with cost and schedule outcomes experienced by each program .

the tactical tomahawk and f / a - 18 c / d programs were developed in an evolutionary environment , engaged in extensive work on requirements , controlled requirements' changes , collected and used detailed metrics to track development progress , and had less cost and schedule increase than the other programs we reviewed .

the navy's tactical tomahawk missile will provide ships and submarines with enhanced capability to attack targets on land .

new features include improved anti - jamming global positioning system , in - flight retargeting , and the ability to transmit battle damage imagery .

tomahawk program developers had disciplined development processes and used extensive peer reviews to discover defects and provided the acquirer with insight at each stage in development: requirements , design , code and test .

they were responsible for collecting and reporting data on a monthly basis , relying on metrics — cost , schedule , effort , size , requirements , testing , and defects that are similar to those used by leading commercial firms .

the program office managed the acquisition based on the trends found in these metrics .

the f / a - 18 c / d is a navy attack fighter aircraft that has been deployed for a number of years .

periodically , the navy upgrades the flight software to incorporate new features , add the capability to fire new munitions , and correct deficiencies discovered since the last upgrade .

working in an evolutionary environment , f / a - 18 c / d program officials recognized that the success of the software upgrade to incorporate additional performance into the flight operations software depended on extensive requirements analysis before program start and firm control as requirements changed throughout development .

this analysis ensured that the effort needed to meet requirements was well understood at the beginning of development , thus limiting the amount of redesign .

proposals for new requirements or changes to requirements after the program began were analyzed for cost , schedule , and performance impact .

as with the tomahawk program , fa - 18 developers adhered to disciplined development processes , used extensive peer reviews to discover defects , and collected meaningful metrics to track progress .

the f / a - 22 , sbirs , and comanche are complex programs that attempted to achieve quantum leaps in performance requiring extensive use of software rather than follow an evolutionary approach to software development .

they all initially lacked controls over requirements , software processes , and metrics , causing major program upheavals .

they encountered significant requirements changes , schedule slips , and cost increases because software defects were not discovered until later stages of the programs .

each of these programs has been restructured to incorporate requirements management controls , more - defined software development processes , and additional metrics .

the air force's f / a - 22 , originally planned to be an air dominance aircraft , will also have air - to - ground attack capability .

it is expected to have advanced features , such as stealth characteristics , to make it less detectable to adversaries and capable of high speeds for long ranges .

the f / a - 22's avionics are designed to greatly improve pilots' awareness of the situation surrounding them .

early in the development process for the f / a - 22 , we reported that the program's planned strategy for software development and acquisition was generally sound .

we cited the air force's plans to collect software costs and other software metrics to measure progress as examples of this sound strategy .

at that time , we endorsed the program's plans to be event - rather than schedule - driven .

however , as early as 1994 , many features of this sound strategy were not being followed .

delayed software deliveries contributed to cost increases and schedule delays .

requirements and design changes accounted for 37 percent of the critical problem reports leading to avionics shutdowns in the f / a - 22 , according to program office reports .

program officials and contractor personnel agreed that requirements volatility had been a problem ; however , they were unable to provide any specific measure of requirements changes because they had not tracked the overall growth in software requirements since the first 3 years of the program .

according to lockheed martin officials , the avionics system software is made up of 84 computer software configuration items , each of which accounts for a specific avionics function , such as the interaction between the pilot and the aircraft .

in our discussion with contractor and program personnel , they stated that disciplined processes in requirements control , design , testing , and configuration management were not uniformly followed because of cost and schedule pressures .

the f / a - 22 software strategy also called for the collection of software metrics to measure costs .

program and contractor officials were unable to provide metrics for sufficient management visibility over the overall progress of the software .

the contractor stated that the air force did not compile metrics from lower levels into major segments such as avionics .

the air force's sbirs satellites are being developed to replace dod's older missile - warning satellites .

in addition to missile warning and missile defense missions , the satellites will perform technical intelligence and battlespace characterization missions .

since the program was initiated in 1996 , sbirs has faced cost , scheduling , and technology problems .

we have reported that sbirs has experienced serious software design problems .

officials from lockheed martin , the prime contractor , stated that the program had uncontrolled requirements growth as well as overly optimistic expectations about reusing software from a previous program .

program and contractor officials agreed that deficient systems engineering and the scarcity of personnel in software engineering disciplines contributed to ineffective control and to not understanding how much of the previous software could be reused .

these officials also stated that neither the program office nor the contractor had a change management control process in place to analyze change requests .

a thorough analysis late in the program revealed that very little of the software could be reused .

furthermore , because of a deficiency in resources devoted to systems engineering , the total requirements for the system were not adequately defined .

a report from an independent review team stated that more robust systems engineering could have precluded some of the problems .

the report concluded that problems with the first sbirs increment were primarily due to problems with software development and poor program execution .

peer reviews and engineering review boards were in place to monitor development , but , for reasons ranging from schedule pressures to reduced staffing , these decision bodies were ineffective .

sbirs contractor officials stated that they collected data on additions to requirements and on the number of lines of code , but because there were no restrictions on accepting new requirements and no control limits to the size of code , the metrics were not used to manage the project on a daily basis .

the army's comanche is a multi - mission helicopter intended to perform tactical armed reconnaissance .

it is designed to operate in adverse weather across a wide spectrum of threat environments and provide improved speed , agility , reliability , maintainability , and low observability over existing helicopters .

since the program's first cost estimate , originally approved in 1985 , the research and development cost for comanche has almost quadrupled , and the time to obtain an initial capability has increased from 9 to over 21 years .

several studies have identified software development as a problem area and highlighted requirements volatility and inadequate requirements analysis as having a large impact on the program .

the lack of a disciplined process for comanche's software acquisition was also cited as a reason for program shortfalls ; however , the exact percentage of cost growth attributed to software is not known because the program office lacked adequate visibility into the software development process and , therefore , has little historical data on software .

comanche officials stated that initially they did not require a uniform set of metrics from the contractor .

they said they received earned value information from the contractor , but it combined software and hardware development data .

all three programs have been restructured and have instituted changes to bring more knowledge into the programs .

for example , f / a - 22 program officials report that their contractors have teamed with divisions within their companies that have more disciplined processes and they are reporting fewer problems with the avionics software .

sbirs program officials stated that they have instituted more controls over requirements changes , requiring analysis and approval at higher levels .

comanche officials reported that the program office has quarterly software reviews to focus attention on software development progress with the contractor and has adopted an incremental , block development strategy for software development .

program officials stated that they have asked for more - detailed metrics by which to manage the programs .

as a result of congressional requirements to initiate improvement plans and revisions to requirements and acquisition policies , dod , the military services and mda have created a more conducive environment for software acquisition and development .

however , additional steps must be taken .

we have found that leading software acquirers and developers we visited create disciplined software development processes and collect useful metrics for management oversight .

these practices have proven to be a significant factor in their ability to achieve successful outcomes .

dod , the services , and mda still lack controls in these areas that would put acquisition program managers in a better position to achieve successful program outcomes .

the plans that the services and mda have begun in response to congressional direction have varying levels of detail and are at various stages of approval within the organizations .

the army , for example , has completed and has begun to implement its plan .

the plan includes using pilot programs to provide information on metrics , and the army expects to team with the software engineering institute to identify training needs and continuous improvement .

mda has prepared a detailed draft that includes forming a baseline assessment of each missile defense element and making recommendations to the program office for each element to adopt improvement processes .

mda expects the elements to begin work once the baseline assessment is complete .

the navy's response includes teaming with the software engineering institute to identify a course of action , including a training program for acquisition professionals and identifying software acquisition requirements and management initiatives .

the air force has called for a working group to begin in march 2004 to baseline air force practices and to suggest a course of action .

these efforts establish an environment of change for the services and provide a platform upon which to make additional improvements .

furthermore , they make explicit to software an evolutionary approach to systems development and acquisition that dod included in the recently revised requirements generation and acquisition policies .

however , the services' and mda's planning does not include practices we found at leading commercial firms that enable those firms to have successful outcomes .

furthermore , the plans do not incorporate controls that would ensure that the plans now being formulated are incorporated into acquisition practice .

the plans could be strengthened by adding specific criteria to ensure that requirements' baselines based on systems engineering are documented and agreed to by both the acquirer and developer before a program's initiation and that cost / benefit analyses are required when new requirements are proposed ; software developers and acquirers make efforts to continually improve gated reviews and deliverables are integrated into the development developers collect and analyze metrics , including earned value to obtain knowledge about development progress and to manage risk .

army , navy , air force , and mda officials said they have high - level support for improving software acquisition and for the plans they are developing , and the army and mda stated that they had included funding for software improvements in their budgets .

officials at the leading companies we visited emphasized that strong management support is needed to ensure success with process improvements .

although dod has embraced an evolutionary approach in its acquisition policy , dod has not yet incorporated a requirement specific to software process improvement into the policy .

furthermore , dod has not said how it will require individual program offices to follow the guidance once the services and mda establish full - fledged programs to improve software development processes .

apart from the software acquisition improvement plans , dod has taken some initiatives to strengthen software acquisition and development as well as address repeated performance shortfalls attributed to software .

since 1999 the tri - service initiative has conducted detailed assessments of software - intensive programs to identity and mitigate software risks .

the initiative has assessed about 50 programs spanning all military branches .

while the results of individual initiatives are confidential to their programs , an overview shows three of the main causes of critical program performance problems: ( 1 ) the ability of the programs to establish and adhere to processes to meet program needs , ( 2 ) requirements management , and ( 3 ) organizational management .

process capability was a problem in 91 percent of case studies while problems with requirements management and organizational management were identified as problems 87 percent of the time .

these findings are consistent with our discussions with leading companies about significant problem areas for software development management .

this kind of information could prove useful to the military services and agencies as they plan for improving software acquisition .

dod has begun another initiative to strengthen the role that systems engineering plays in weapons system development as well as in software development .

according to dod officials , this initiative will include provisions for gated reviews of systems engineering baselines on an event - driven basis .

furthermore , the officials stated that they were working to incorporate the new systems engineering directives into acquisition policy .

dod has tasked a source selection criteria working group with clarifying policy regarding source selection criteria for software - intensive systems , and another working group is creating a clearinghouse for best practices .

the source selection criteria working group is discussing the application of software product maturity measures , and the software intensive systems office is developing a proposal for a centralized clearinghouse of software best practices , but these initiatives are not complete .

to provide a better method of estimating the cost of software , dod added a requirement to its acquisition policy to report such information as type of project , size , effort , schedule , and quality data to the cost analysis improvement group .

dod policy requires the software resource data report for major defense programs for any software development element with a projected software effort greater than $25 million .

organizations we visited that have established a strong , consistent , evolutionary environment and practices for setting product requirements , maintaining a disciplined development process , and using metrics to oversee development progress achieve favorable cost , schedule , and quality outcomes for software projects .

these practices limit development efforts to what can be managed and result in decisions throughout the development process that are based on knowledge obtained through systems engineering that is sufficient to adequately gauge risks .

the organizations we visited made business decisions to invest time and resources in achieving high process maturity levels to improve these practices .

for the most part , in the programs reviewed , dod garnered poor results from its software acquisition process because it has not employed consistent practices in these areas .

much as we have found in dod's overall acquisition management process , the decisions to begin programs and to make significant investments throughout development are made without matching requirements to available resources and without demanding sufficient knowledge at key points .

the acquisition programs we reviewed that used evolutionary environments , disciplined processes , and managed by metrics were more successful , and the programs that did not use these practices were less successful .

dod has attempted to improve acquisition outcomes by establishing a framework for an evolutionary environment in its requirements generation and acquisition policies that develops manageable increments of capability .

this is a positive step .

however , dod's policies do not contain the controls needed to ensure individual programs will adhere to disciplined requirements and development processes , nor do they include the metrics needed to do so .

as dod works to finalize its software process improvement plans , it has the opportunity to put in place those practices that have proven successful in achieving improved outcomes for software - intensive systems .

in moving into a more complex , “system of systems” acquisition environment , much more will be demanded from software .

the need for consistent practices and processes for managing software development and acquisition will become paramount if dod is to deliver capabilities as promised .

we have previously made recommendations to dod to adopt certain specific practices developed by the software engineering institute .

as dod changes the way it manages software intensive systems , it must take steps to ensure better acquisition outcomes .

we recommend the secretary of defense take the following four actions: to assure dod appropriately sets and manages requirements , we recommend that dod document that software requirements are achievable based on knowledge obtained from systems engineering prior to beginning development and that dod and the contractor have a mutual understanding of the software requirements .

furthermore , we recommend that trade - off analyses be performed , supported by systems engineering analysis , considering performance , cost , and schedule impacts of major changes to software requirements .

to ensure dod acquisitions are managed to a disciplined process , acquirers should develop a list of systems engineering deliverables ( including software ) , tailored to the program characteristics , and based on the results of systems engineering activities that software developers are required to provide at the appropriate stages of the system development phases of requirements , design , fabrication / coding , integration , and testing .

to ensure dod has the knowledge it needs to oversee software - intensive acquisitions , we recommend that acquirers require software contractors to collect and report metrics related to cost , schedule , size , requirements , tests , defects , and quality to program offices on a monthly basis and before program milestones and that acquirers should ensure that contractors have an earned value management system that reports cost and schedule information at a level of work that provides information specific to software development .

these practices should be included and enforced with controls and incentives in dod's acquisitions policy , software acquisition improvement plans and development contracts .

dod provided us with written comments on a draft of this report .

the department concurred with two of the recommendations , subject to our incorporating some minor revisions .

since the suggested revisions did not materially change the intent of the recommendations , we revised them .

for two other recommendations , the department partially concurred .

the department agreed that the report provides useful insight for improving the software acquisition process and is consistent with its efforts to improve the process as it continues to implement section 804 of the fiscal year 2003 national defense authorization act .

it also agreed to take the report's findings into account as it monitors the process for continuous improvement and to apply our recommendations as further guidance to its component services and agencies .

the department further noted that the techniques highlighted in the report should not be seen as a panacea .

we agree .

our report provides evidence that acquisitions can succeed if they take place in an evolutionary environment rather than an environment that requires complex solutions for a single quantum leap in software capabilities .

to augment an evolutionary environment , requirements must be carefully managed and existing systems and software engineering knowledge must be taken into account , the development processes must be disciplined and transparent to decision makers , and key metrics must be gathered and used to support decisions .

we disagree with the department's observation that the report “plays down significant challenges associated with acquisition of complex defense systems .…” to the contrary , our report highlights those challenges as inherent to acquisitions that proceed with limited knowledge about how to achieve quantum leaps in capability in a single acquisition .

our comparison of two successful evolutionary programs ( tactical tomahawk and f / a - 18 c / d , both categorized as major defense acquisition programs ) with three revolutionary programs ( f / a - 22 , sbirs , and comanche ) shows different outcomes in terms of cost , schedule , and delivery of equipment to the warfighter .

dod's rationale for providing programs with data less frequently than we recommended in our third recommendation suggested that data did not create knowledge and that knowledgeable software professionals are needed to interpret data .

we agree that both knowledgeable people and data are needed , but those professionals must have data to interpret .

we found that initially the f / a - 22 , sbirs , and comanche programs had knowledgeable staff but little data to analyze .

dod indicated that it was already addressing software acquisition in policy in response to the fourth recommendation and cited multiple sections of dod directive 5000.1 as evidence .

we do not agree that the current policy puts adequate controls in place to improve software practices to a level achieved by leading commercial companies .

dod is silent about including incentives in contracts for improving software processes .

the department's comments are printed in appendix i .

to determine the best practices commercial companies use to manage software development and acquisition , we first conducted general literature searches .

from these literature searches and discussions with experts , we identified numerous companies that follow structured and mature processes for software development and acquisition .

we visited the following commercial companies: computer sciences corporation ( csc ) develops individual business solutions for commercial and government markets worldwide .

the company is specialized in management and information technology consulting , systems consulting and integration , operations support , and information services outsourcing .

in 2003 , the company generated revenues of $11.3 billion .

we visited csc's federal sector office in moorestown , new jersey , and discussed its practices for developing and acquiring commercial and federal software .

the federal sector unit has achieved a level 5 capability maturity model rating .

diebold , incorporated manufactures self - service products , such as automated teller machines , electronic and physical security products , and software and integrated systems .

in 2002 the company reported revenues of $1.9 billion .

we visited the company's headquarters in north canton , ohio , and discussed the process it uses to develop software for automated teller systems .

general motors , the world's largest vehicle manufacturer , designs , builds , and markets cars and trucks worldwide .

in 2002 the company reported total net sales of $186.7 billion .

we spoke with representatives from the powertrain group to discuss the processes used to develop and acquire electronic controls .

motorola gsg provides integrated communications and embedded electronic solutions , such as wireless phones , two - way radio products , and internet - access products to consumers , network operators , commercial , government , and industrial customers .

in 2002 the company reported net sales of $26.7 billion .

we visited its global software group offices in montreal , canada , and discussed the company's software and product development processes .

the global software group has achieved a level 5 capability maturity model rating .

ncr offers solutions for data warehousing , retail store automation , and financial self - services .

in 2002 the company reported sales totaling approximately $5.6 billion .

we visited the teradata data warehousing group office in san diego , california , and discussed the software development process for the company's teradata database software .

the teradata unit has achieved a level 4 capability maturity model rating .

software acquisition covers myriad activities and processes from planning and solicitation , to transition , to the support of a developed product .

in fact , the software engineering institute's capability maturity models ( cmm ) ® for software acquisition and development delineate more than a dozen different processes of this nature and offer principles governing the goals , activities , necessary resources and organizations , measurements , and validation of each process .

this report does not attempt to judge software acquisitions against all of those processes .

instead , our scope targets practices in three critical management areas we identified as problem areas from our previous work on weapon systems acquisitions and through discussions with leading companies .

we limited our focus to ways to develop an environment that encourages continual improvement ; improve the management of software development processes , including software requirements ; and metrics to improve overall weapon system acquisition outcomes .

in doing so , we borrowed criteria from each cmm® that offered a road map for continuous improvement in each of those specific areas .

at each of the five companies , we conducted structured interviews with representatives to gather uniform and consistent information about the practices , processes , and metrics that each company uses to manage software development and software acquisition .

during meetings with representatives , we obtained a detailed description of the practices and processes they use to develop software within cost and schedule and ensure quality .

we also consistently used a structured data collection instrument to collect metrics from the companies on their software projects .

we met with company directors , software engineers , project managers , configuration managers , and quality assurance personnel .

our report highlights several best practices in software development and acquisition on the basis of our fieldwork .

as such , they are not intended to describe all practices or suggest that commercial companies are without flaws .

representatives from the commercial companies we visited told us that their practices have evolved over many years and that they continue to be improved on the basis of lessons learned and new ideas and information .

this is not to say that the application and use of these practices have always been consistent or without error or that they subscribe to a single model for their practices and processes .

however , they strongly suggested that the probability of success in developing and acquiring software is greatly enhanced by the use of these practices and processes .

we also selected five dod weapon systems: rah - 66 comanche , f / a - 22 , f / a - 18 c / d , sbirs , and tactical tomahawk .

these systems are at various stages of development .

we compared the practices , processes , and metrics the programs were using to manage software development and acquisition with the best practices commercial companies use .

to identify the current policy , processes , and acquisition practices used in software development , for each program we visited , we conducted structured interviews with representatives from the program office and prime contractors boeing sikorsky for comanche ; lockheed martin , marietta , georgia , for f / a - 22 ; and lockheed martin , boulder , colorado , for sbirs .

we also used a data collection instrument to determine which metrics program offices were collecting .

we selected air force , army , and navy programs because they all manage major defense acquisition programs .

we also obtained the responses to date that the services and mda have prepared in response to section 804 of the bob stump national defense authorization act for fiscal year 2003 .

the legislation states that the secretary of each military service and the head of each defense agency that manages a major defense acquisition program with a substantial software component shall establish a program to improve the software acquisition processes of that military service or defense agency .

to determine how dod responded to congress's requirement , we met with dod officials from the tri - service assessment initiative and the software intensive systems office and the staff responsible for developing the process improvement plans for the air force , army , department of the navy , and mda .

we also met with officials from the office of the under secretary of defense ( acquisition , technology and logistics ) concerning systems engineering initiatives and officials from the office of the assistant secretary of defense ( networks and information integration ) concerning the software improvement plans .

because the plans are in varying stages of completeness , we did not evaluate to what degree the military services and mda have complied with section 804 .

to determine whether the responses so far would help improve dod's software acquisition , we evaluated the responses on the basis of the information we obtained from leading organizations concerning environment , disciplined processes , and collection of meaningful metrics .

we conducted our review between march 2003 and february 2004 in accordance with generally accepted government auditing standards .

we are sending copies of this report to the secretary of defense ; the secretaries of the air force , army , and navy ; the director of the missile defense agency ; and the director of the office of management and budget .

we will also provide copies to others on request .

in addition , the report will be available at no charge on the gao web site at http: / / www.gao.gov .

please contact me at ( 202 ) 512-4841 if you have any questions concerning this report .

other key contributors to this report were cheryl andrew , beverly breen , lily chin , ivy hubler , carol mebane , mike sullivan , sameena nooruddin , marie penny ahearn , madhav panwar , and randy zounes .

the capability maturity model for software ( sw - cmm ) ® describes the principles and practices underlying software process maturity and is intended to help software organizations improve the maturity of their software process in terms of an evolutionary path organized into five maturity levels .

except for level 1 , each maturity level is decomposed into several key process areas that indicate the areas that an organization should focus on to improve its software process .

table 3 describes the characteristics of each level of process maturity and the applicable key process areas .

the software acquisition capability maturity model ( sa - cmm ) ® is a model for benchmarking and improving the software acquisition process .

the model follows the same architecture as sw - cmm® but with a unique emphasis on acquisition issues and the needs of individuals and groups who are planning and managing software acquisition efforts .

each maturity level indicates an acquisition process capability and has several key process areas .

each area has goals and common features and organizational practices intended to institutionalize common practice .

in 1997 a team led by dod , in conjunction with software engineering institute , government , and industry , concentrated on developing an integrated framework for maturity models and associated products .

the result was the capability maturity model integration ( cmmi ) ® , which is intended to provide guidance for improving an organization's processes and the ability to manage the development , acquisition , and maintenance of products and services while reducing the redundancy and inconsistency caused by using stand - alone models .

cmmi® combines earlier models from software engineering institute and the electronic industries alliance into a single model for use by organizations pursuing enterprise - wide process improvement .

ultimately , cmmi® is to replace the models that have been its starting point .

many integrated models consist of disciplines selected according to individual business needs .

models can include systems engineering , software engineering , integrated product and process development , and supplier sourcing .

there are also two representations of each cmmi® model: staged and continuous .

a representation reflects the organization , use , and presentation of model elements .

table 5 shows the cmmi® model for staged groupings .

 ( 1 ) the secretary of each military department shall establish a program to improve the software acquisition processes of that military department .

 ( 2 ) the head of each defense agency that manages a major defense acquisition program with a substantial software component shall establish a program to improve the software acquisition processes of that defense agency .

 ( 3 ) the programs required by this subsection shall be established not later than 120 days after the date of the enactment of this act .

 ( b ) program requirements. — a program to improve software acquisition processes under this section shall , at a minimum , include the following: ( 1 ) a documented process for software acquisition planning , requirements development and management , project management and oversight , and risk management .

 ( 2 ) efforts to develop appropriate metrics for performance measurement and continual process improvement .

 ( 3 ) a process to ensure that key program personnel have an appropriate level of experience or training in software acquisition .

 ( 4 ) a process to ensure that each military department and defense agency implements and adheres to established processes and requirements relating to the acquisition of software .

 ( c ) department of defense guidance — the assistant secretary of defense for command , control , communications , and intelligence , in consultation with the under secretary of defense for acquisition , technology , and logistics , shall — ( 1 ) prescribe uniformly applicable guidance for the administration of all of the programs established under subsection ( a ) and take such actions as are necessary to ensure that the military departments and defense agencies comply with the guidance ; and ( 2 ) assist the secretaries of the military departments and the heads of the defense agencies to carry out such programs effectively by — ( a ) ensuring that the criteria applicable to the selection of sources provides added emphasis on past performance of potential sources , as well as on the maturity of the software products offered by the potential sources ; and ( b ) identifying , and serving as a clearinghouse for information regarding , best practices in software development and acquisition in both the public and private sectors .

 ( d ) definitions — in this section: ( 1 ) the term “defense agency” has the meaning given the term in section 101 ( a ) ( 11 ) of title 10 , united states code .

 ( 2 ) the term “major defense acquisition program” has the meaning given such term in section 139 ( a ) ( 2 ) ( b ) of title 10 , united states code .

defense acquisitions: dod's revised policy emphasizes best practices , but more controls are needed .

gao - 04-53 .

washington , d.c.: november 10 , 2003 .

best practices: setting requirements differently could reduce weapon systems' total ownership costs .

gao - 03-57 .

washington , d.c.: february 11 , 2003 .

best practices: capturing design and manufacturing knowledge early improves acquisition outcomes .

gao - 02-701 .

washington , d.c.: july 15 , 2002 .

defense acquisitions: dod faces challenges in implementing best practices .

gao - 02-469t .

washington , d.c.: february 27 , 2002 .

dod information technology: software and systems process improvement programs vary in use of best practices .

gao - 01-116 .

washington , d.c.: march 30 , 2001 .

best practices: better matching of needs and resources will lead to better weapon system outcomes .

gao - 01-288 .

washington , d.c.: march 8 , 2001 .

best practices: a more constructive test approach is key to better weapon system outcomes .

gao / nsiad - 00-199 .

washington , d.c.: july 31 , 2000 .

defense acquisition: employing best practices can shape better weapon system decisions .

gao / t - nsiad - 00-137 .

washington , d.c.: april 26 , 2000 .

best practices: dod training can do more to help weapon system program implement best practices .

gao / nsiad - 99-206 .

washington , d.c.: august 16 , 1999 .

best practices: better management of technology development can improve weapon system outcomes .

gao / nsiad - 99-162 .

washington , d.c.: july 30 , 1999 .

defense acquisitions: best commercial practices can improve program outcomes .

gao / t - nsiad - 99-116 .

washington , d.c.: march 17 , 1999 .

defense acquisition: improved program outcomes are possible .

gao / t - nsiad - 98-123 .

washington , d.c.: march 17 , 1998 .

best practices: dod can help suppliers contribute more to weapon system programs .

gao / nsiad - 98-87 .

washington , d.c.: march 17 , 1998 .

best practices: successful application to weapon acquisition requires changes in dod's environment .

gao / nsiad - 98-56 .

washington , d.c.: february 24 , 1998 .

best practices: commercial quality assurance practices offer improvements for dod .

gao / nsiad - 96-162 .

washington , d.c.: august 26 , 1996 .

