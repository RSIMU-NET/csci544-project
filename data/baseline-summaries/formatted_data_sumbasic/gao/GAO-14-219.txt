in response to the recent serious recession , congress enacted the american recovery and reinvestment act of 2009 ( recovery act ) to , among other purposes , promote economic recovery , make investments , and minimize and avoid reductions in state and local government services .

a significant component of the recovery act was grants for use in states and localities .

as of the end of october 2013 , the department of the treasury had awarded approximately $219 billion of recovery act funds in the form of grants .

these grants covered a broad range of areas including education , transportation , infrastructure , energy , the environment , health care , and housing .

the importance of spending recovery act funds quickly was highlighted by the president's goal of spending 70 percent of the funds by september 30 , 2010 .

you asked us to examine grant management lessons learned resulting from the recovery act and to provide examples of what worked well , as well as what challenges were experienced by federal , state , and local governments .

to better understand grant management lessons learned resulting from the recovery act , we focused on two key issues involving grant implementation — accountability and transparency — where congress and the administration placed unprecedented emphasis when they crafted the recovery act .

specifically , this report identifies and provides examples of good practices employed and the challenges faced in meeting the recovery act's accountability and transparency requirements by select federal , state , and local agencies implementing grant programs funded by the recovery act .

additionally , in september 2013 , we issued a related report examining federal efforts to increase the transparency of federal data and identifying lessons learned from operating existing data systems that could contribute to these efforts .

to accomplish our objectives , we conducted a detailed literature review to identify relevant prior work by us and others regarding recovery act challenges and lessons learned .

we then interviewed federal , state , and local officials involved in the implementation of the recovery act and obtained supporting documentation .

the federal entities that we contacted with broad jurisdiction for the recovery act were the recovery implementation office , the office of management and budget ( omb ) , and the recovery accountability and transparency board ( recovery board ) .

we developed criteria to select a subset of four federal agencies , three state governments , and two local governments .

we then contacted these entities in order to obtain a more in - depth understanding of their experiences with grant programs funded by the recovery act as well as to identify examples of challenges and good practices .

our selection criteria included factors such as the nature , type , and value of the grants handled by the organization ; whether the grants involved were already well - established , greatly increased in size , or entirely new ; and the extent to which the organizations were identified in our previous work or in the broader literature .

the federal agencies we selected were the departments of education , energy , transportation , and housing and urban development .

we deemed medicaid out of scope for the purposes of this review .

although it was the largest grant program funded by the recovery act , it is primarily an entitlement and is subject to specific rules that are not typical of program grants .

the state and local governments we selected included california , georgia , and massachusetts , as well as new york , new york and denver , colorado .

these three states are part of a core group of 16 states and the district of columbia that we selected for our series of bimonthly reviews of how recovery act funds were being used by recipients .

the recovery act required that we conduct these bimonthly reviews of how these funds were used by selected states and localities .

this report also fulfills this requirement in that we examined the use of recovery act funds in the previously mentioned states and cities .

to obtain a broader state perspective , we interviewed officials from the state recovery act coordinators' network , which included key state officials responsible for implementing the recovery act from several states .

for additional context , we supplemented these interviews by meeting with officials from state and local advocacy organizations such as the national association of state auditors and comptrollers ; the national association of state budget officers ; and the national association of counties .

we reviewed and synthesized the information provided by these officials , as well as previously issued work regarding challenges and good practices that relate to our two key themes , and we developed descriptive examples .

we also reviewed and applied criteria established by howto.gov , a source of guidance and leading practices for government websites , to recovery.gov and state and local recovery websites .

a full description of our objectives , scope , and methodology is provided in appendix i .

we conducted this performance audit from december 2012 to january 2014 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the stated purposes of the recovery act are to: preserve and create jobs and promote economic recovery ; assist those most impacted by the recession ; provide investments needed to increase economic efficiency by spurring technological advances in science and health ; invest in transportation , environmental protection , and other infrastructure that will provide long - term economic benefits ; and stabilize state and local government budgets , in order to minimize and avoid reductions in essential services and counterproductive state and local tax increases .

while many recovery act projects focused on immediately jumpstarting the economy , some projects — such as those involving investments in technology , infrastructure , and the environment — are expected to contribute to economic growth for many years .

the recovery act established the recovery accountability and transparency board ( recovery board ) to provide additional monitoring and oversight .

the board was originally scheduled to terminate operations by september 30 , 2013 , but its mission has been extended until september 30 , 2015 , to provide oversight and monitoring of assistance provided in response to hurricane sandy , which hit the northeast in october 2012.in figure 1 displays selected events related to the recovery act and its requirements .

the congressional budget office ( cbo ) initially estimated the cost of the recovery act to be approximately $787 billion ; however , cbo's most recent estimate projects that the recovery act will cost approximately $830 billion over the 2009-2019 time period .

as of october 31 , 2013 , the federal government provided a total of approximately $812 billion related to recovery act activities .

this includes funding to 28 federal agencies that were distributed to states , localities , and other entities ; individuals through a combination of tax benefits and cuts ; entitlements ; and loans , contracts , and grants .

see figure 2 for an overview of recovery act spending by category and program .

although medicaid was the single largest recovery act grant program , we did not include it in our review because it is primarily an entitlement program and subject to specific rules that are not typical of program grants .

accordingly , we included the recovery act funds directed to medicaid in the entitlement category , rather than the grant category , in figure 2 .

emphasizing the importance of spending recovery act funds quickly , the president established a goal that by september 30 , 2010 , 70 percent of recovery act funding should be spent ( that is , both obligated and outlayed ) .

therefore , agencies had approximately 19 months to spend almost three - quarters of their recovery funds .

grants have played a key role in providing recovery act funds to recipients , with approximately $219 billion being awarded for use in states and localities through a wide variety of federal grant programs .

with the intent of disbursing funds quickly to create and retain jobs and stabilize state and local budgets , a large majority of recovery act grant funding went to states and localities within 3 years of the law's enactment .

recipients reported receiving approximately 88 percent of their grant awards by the end of the 2nd quarter of calendar year 2013 .

state and local spending was as follows: fiscal year 2009: spending totaled approximately $53 billion in actual outlays .

fiscal year 2010: spending was at its highest level with approximately $112 billion in actual outlays .

fiscal year 2011: spending decreased from its peak , with approximately $69 billion in actual outlays .

the 28 federal agencies that received recovery funds developed specific plans for spending the money .

the agencies then awarded grants and contracts to state governments or , in some cases , directly to schools , hospitals , or other entities .

omb guidance directed these federal agencies to file weekly financial reports detailing how the money was being distributed .

recipients of the funds , in turn , were required by the recovery act to file quarterly reports on how they were spending the recovery act funds that they received .

recovery act grants provided to states and localities covered a broad range of areas such as transportation , energy , and housing .

education programs were the largest recipients of recovery act grant awards .

of the education programs funded in the recovery act , the largest in terms of funding was the newly created state fiscal stabilization fund ( sfsf ) program , which provided assistance to state governments to stabilize their budgets by minimizing budgetary cuts in education and other essential government services , such as public safety .

the recovery act appropriated $53.6 billion for the sfsf program.shows , grants represent over one - quarter of recovery act funding .

out of that category , funding received in the program areas of education , transportation , and energy and environment amount to approximately $137 billion , or 70 percent , of recovery act grant spending to date .

as figure 2 ( above ) .

the recovery act called for a large amount of federal funds to be spent ( that is , obligated and outlayed ) in a short period of time — approximately 19 months — by the end of september 30 , 2010 .

to assure the public that their tax dollars were being spent efficiently and effectively , the recovery act placed increased emphasis on accountability and transparency through enhanced reporting , auditing , and evaluation requirements for users of recovery act funds .

the recovery act delineated some of these increased accountability and transparency responsibilities to existing organizations and entities as well as newly - created ones .

see table 1 for details regarding the primary accountability and oversight responsibilities of key organizations involved in implementing the recovery act .

under the recovery act , accountability for timely and effective implementation of the law was a shared responsibility that included agencies involved in directly implementing the law as well as the external oversight community .

on the operational side , among the practices that facilitated accountability were ( 1 ) strong support by top leaders , ( 2 ) centrally - situated collaborative governance structures , and ( 3 ) the regular and systematic use of data to support management reviews .

we have previously reported on the importance of having the active support of top leadership when undertaking large and complex activities .

this was the case in the implementation of the recovery act where , at the federal level , the president and vice president made clear that effective recovery act implementation was a high priority for them .

the president assigned overall management responsibility for the recovery act to the vice president and appointed a former omb deputy director to head the newly - created recovery implementation office with direct reporting responsibilities to both him and the vice president .

the former head of the recovery implementation office told us that his position gave him access to top leadership in the administration .

this official said he participated in daily morning staff meetings with the white house senior staff , briefing them on any issues related to the recovery act .

he briefed the president directly approximately once a month .

in addition , he typically met with the vice president's staff on a daily basis after the president's staff meeting .

he also met with the vice president directly every 1 to 2 weeks .

finally , he frequently interacted with the head of omb and sometimes also sat in on his staff meetings .

in each of these roles he had direct access to , and support from , the highest levels of government .

the former head of the recovery implementation office stated this was key to his ability to ensure cooperation and coordination with other federal departments during the recovery act .

for example , he told us that senior government leaders knew that his office had the authority of the president and vice president behind it , and if they did not do what was requested , they would have to explain their reasoning to senior white house officials .

this awareness of the recovery implementation office's line of authority helped to ensure that federal officials coordinated and cooperated with the office .

in turn , the involvement and engagement of top leaders at individual federal agencies was facilitated by omb guidance that required each agency to identify a senior accountable official — generally at the deputy secretary or subcabinet level — to be responsible for recovery planning , implementation , and performance activities within the agency.senior agency leaders were regularly involved with overseeing and reporting on recovery act efforts .

at the state level , several governors demonstrated top leadership support by establishing specific positions , offices , or both that were responsible for state recovery efforts .

for example , the governor of massachusetts created the massachusetts recovery and reinvestment office as a temporary program management office for the specific task of overseeing recovery activities .

the former director of the office stated that he reported directly to , and drew his authority from , the governor .

the governor also elevated the office to the rank of a senior level office .

this action increased the office's visibility and gave it a seat at the governor's weekly cabinet meetings , where its director would regularly report on the status of recovery act projects .

in addition , no state recovery act program could be approved without the director's consent .

the former director told us that the success of the office was attributable to the direct line of authority it had with the governor of massachusetts .

in fiscal year 2012 , massachusetts' office of commonwealth performance , accountability , and transparency was created , in part , as a direct result according to massachusetts' state officials , this of the recovery act .

office is the state's attempt to take lessons from the state's experience with the massachusetts recovery and reinvestment office and apply them post recovery act .

mass .

gen. laws ch .

7 , § 4a ( e ) .

and to run competitions in a manner consistent with their individual statutes , regulations , and agency practices .

on the other hand , there was also centralization of oversight as demonstrated by the direct involvement of high - level officials such as the vice president , cabinet secretaries , and senior accountable officials in federal agencies receiving recovery act funding , as well as centrally - placed policy and oversight organizations such as omb and the recovery board .

this combination of a centralized and decentralized approach to managing the implementation of the recovery act represented a new method of managing grant oversight , one which simultaneously recognized the importance of collaboration while increasing the role of the center .

officials in the recovery implementation office employed a collaborative , facilitative approach , while also leveraging the authority of the vice president to facilitate the participation of stakeholders .

the office functioned as a convener and problem - solver that engaged with a wide range of federal , state and local partners .

this approach was embodied in the objectives identified by the vice president when the office was established .

these objectives included the expectation that office staff respond to requests and questions within 24 hours , cut across bureaucratic silos by reaching out to a variety of partners , and always be accessible .

toward this end , the office adopted the role of an “outcome broker,” working closely with partners across organizational silos at all levels of government in order to foster implementation of the recovery another role of the recovery implementation act and achieve results .

office was to closely monitor recovery act spending .

one way it did so was to monitor grants to ensure that they were consistent with the objectives identified by the vice president .

a second way the office monitored spending was to review weekly financial reports on agency obligations and expenditures for programs receiving recovery act funds and to meet with the agencies on a regular basis .

for more information on the concept of an “outcome broker” , please see frank digiammarino , can government work like open table ? .

innovation in the collaborative era ( 2012 ) , accessed january 22 , 2014 , http: / / www.scribd.com / doc / 115361546 / can - government - work - like - opentable .

omb sought to facilitate effective implementation of the recovery act by working to establish and strengthen relationships with state and local governments that would ultimately implement the programs on the ground .

this was done in two ways: ( 1 ) by soliciting feedback from state and local partners when formulating and revising rules and policies governing the implementation of recovery act programs and ( 2 ) by developing its capacity to respond to questions from the many states and localities that would be implementing those rules and policies .

a senior omb official directly involved in this work told us the office had to move out of its traditional role as mainly a policy - making organization to adopt a more interactive and service - oriented approach .

under this approach , key activities involved engaging with and obtaining feedback from states and localities as well as providing technical support to these groups so that they could meet the recovery act's numerous reporting requirements .

for example , to obtain feedback from state and local partners when developing key recovery act policies , omb became actively involved in weekly conference calls that included a diverse group of federal , state , and local organizations .

starting in the spring of 2009 , regular participants in these calls included omb ; gao ; the national association of state auditors , comptrollers and treasurers ; the national governors' association ; the national association of state budget officers ; the recovery board ; the national association of counties ; the national association of state chief information officers ; and the national association of state purchasing officers .

these weekly calls were scheduled after several of these organizations wrote to omb and gao to express their strong interest in coordinating on reporting and compliance aspects of the recovery act .

an important outcome of this regular information exchange was to make omb aware of the need to clarify certain reporting requirements .

the recovery act required federal agencies to make information publicly available on the estimate of the number of jobs created and number of jobs retained as a result of activities funded by the act .

our previous recovery act work in the states raised the issue that some local officials needed clarification regarding definitions when reporting on job data .

the local partners participating in these calls were able to corroborate what we reported and provide omb with specific information about what additional guidance was needed .

to obtain information to further guide refinements to the recovery implementation process , at the end of 2009 , omb officials said they ( 1 ) interviewed and surveyed numerous stakeholders including governors and state and local recipients , and ( 2 ) worked with gao to identify best practices .

based on these efforts , omb subsequently revised its guidance , which focused on lessons learned around enhancing recipient reporting and compliance .

to improve technical support provided to state and local governments implementing the recovery act , omb worked with the recovery board to establish an assistance center based on an “incident command” model .

one omb official likened this approach to an extension of a traditional response model used during natural disasters , where the country's economic condition during the great recession was the “incident” and the recovery act was the intervention to be rolled out through many partners .

to help implement this approach , omb worked with officials from the department of agriculture who offered the services of one of their national emergency management teams to help set up and coordinate this effort .

given the large number of state and local governments that needed to be supported , omb requested that each agency with grant programs receiving recovery act funds contribute personnel to support the center .

according to omb officials , from september to mid - december of 2009 , the center responded to approximately 35,000 questions from states and localities .

under the recovery act , some agencies used new data - driven approaches to inform how they managed programs , and some of those new approaches become institutionalized at the agencies post - recovery .

while the government performance and results act ( gpra ) modernization act of 2010 ( gprama ) laid out requirements for data - driven quarterly performance reviews , several recovery act efforts aided agencies in implementing those requirements .

for example , in february 2013 we found that the department of energy ( doe ) built on its recovery act - related performance reviews and established quarterly performance reviews , called business quarterly reviews , in 2011 .

another control doe implemented for large dollar projects was a “stage - gate” process , which did not allow the funds to be disbursed all at one time .

it required the recipient to meet certain metrics before receiving additional funding at certain levels .

doe office of inspector general ( oig ) officials believed this stage - gate approach was an effective internal control tool .

post - recovery , doe has institutionalized both the business quarterly reviews and stage - gate processes .

as part of the department of housing and urban development's ( hud ) implementation of the recovery act , the agency piloted a new approach to data management and accountability called hudstat .

hud's recovery act team collected data about the status of projects and progress towards financial goals .

armed with this information , hud leaders could identify and neutralize spending delays across the agency's 80 field and regional offices .

in some cases , a senior hud official would make a phone call to a mayor or a governor to stress the need to spend funds quickly .

in other cases , staff would refocus on regions where progress was slow and would work with grantees to move more quickly to promote economic growth .

after the recovery act , and in accordance with gprama requirements , hud continued to use hudstat to share data and resources across the agency .

the recovery act contained increased accountability requirements in the areas of reporting , audits , and evaluations to help ensure that tax dollars were being spent efficiently and effectively .

at the same time , the act provided aggressive timelines — approximately 19 months — for the distribution of funds .

the combination of these two factors placed high expectations on federal , state , and local governments and led to increased coordination both vertically across levels of government and horizontally within the same level of government to share information and work towards common goals .

organizations involved in overseeing and implementing grants funded by the recovery act made use of both new and established networks to share information .

shortly after the recovery act was signed into law , our then acting comptroller general and the chair of the council of the inspectors general on integrity and efficiency hosted a coordination meeting with the oigs or their representatives from 17 federal agencies to discuss an approach to coordination and information sharing going forward .

we also worked with state and local auditors and their associations to facilitate regular conference calls to discuss recovery act issues with a broad community of interested parties .

participants included the association of government accountants ; the association of local government auditors ; the national association of state auditors , comptrollers , and treasurers ; the recovery board ; and federal oigs .

another active venue for information sharing was the national intergovernmental audit forum ( niaf ) .

the niaf , led during this period by our then acting comptroller general , is an association that has existed for over three decades as a means for federal , state , and local audit executives to discuss issues of common interest and enhance accountability .

niaf's may 2009 meeting brought together these executives and others including omb , to update them on the recovery act and provide another opportunity to discuss emerging issues and challenges .

in addition , several intergovernmental audit forum meetings were scheduled at the regional level across the country and sought to do the same .

this regional coordination and information sharing directly contributed to our recovery act work in the states .

for example , our western regional director made a presentation at the pacific northwest audit forum regarding our efforts to coordinate with state and local officials in conducting recovery act oversight .

in conjunction with that forum and at other related forums , she regularly met with the principals of state and local audit entities to coordinate oversight of recovery act spending .

officials from new york city also played a role in creating networks to share information .

believing that large cities were probably facing similar issues and challenges , recovery officials in new york city established the american recovery and reinvestment act big city network ( bcn ) to serve as a peer exchange group and facilitate information sharing among large municipalities across the country .

the group was composed of over 20 large cities with geographical diversity , such as los angeles , philadelphia , phoenix , and seattle , that received a significant amount of federal stimulus funding .

the former head of the bcn told us that the organization held frequent teleconferences and used this collaboration to elevate issues unique to large cities with omb , the white house's recovery implementation office , and the recovery board .

for example , bcn informally surveyed its members in january 2010 concerning each grant and associated funds they received .

from this survey , bcn officials assembled a list of cross - jurisdictional issues reflecting the perspectives and experiences of large cities and shared them with the white house , omb , and the recovery board .

likewise , omb , the recovery implementation office , and the recovery board used bcn as a vehicle for getting information out to its partners on the ground .

similarly , at the state level , a network was established where state recovery act coordinators shared information and lessons learned on a weekly basis .

this state - level network also discussed ongoing recovery act policy and operational issues with the white house , omb , and the recovery board to ensure successful implementation .

federal officials joined the state calls on a regular basis .

both bcn and the state network proved to be especially helpful in fostering intergovernmental communications .

for example , the former head of the bcn stated that in response to a senate committee request in 2012 , new york city leveraged both bcn and the state recovery act coordinators' network to inform the current discussion on the digital accountability and transparency act , proposed legislation which seeks to improve grant transparency through increased reporting .

cities and states mobilized quickly and came together on key consensus principles for congress' consideration .

under the tight time frames set for implementation of the recovery act , federal agencies needed to work together to accomplish their goals .

for example , hud and doe shared a goal of weatherizing low - income households through long - term energy efficiency improvements .

to get the projects under way as quickly as possible , they worked together to ensure that homeowners met income standards .

before recovery act implementation , both doe and hud conducted their own independent income verifications .

in may of 2009 , doe and hud entered into a memorandum of understanding that eliminated the need for separate doe income verification for people whose incomes had already been verified by hud .

according to doe officials , this collaboration helped projects move faster , reduced the cost and administrative burden of duplicative verifications , and helped doe weatherize numerous homes under the recovery act through 2013 .

doe officials reported that between fiscal years 2010 and 2013 , the joint effort helped weatherize approximately 1.7 million housing units , the majority of which were low - income .

this policy of sharing low - income verifications for weatherizing homes has continued post - recovery act .

at the state level , massachusetts is an example where officials developed new ways of working together to achieve recovery act goals .

for example , massachusetts state officials established the stimulus oversight and prevention ( stop ) fraud task force in 2009 to fulfill the recovery act's goal of preventing fraud , waste , and abuse of recovery act funds .

this task force included the state oig's office , the attorney general's office , and the state auditor .

over the next 2 years , the group met bimonthly to discuss fraud prevention and collaborated with several federal agencies including the department of justice , the federal bureau of investigation , and hud .

the group also brought in federal oigs including doe and education , the state comptroller's office , and the massachusetts recovery and reinvestment office to discuss our report findings and omb guidance .

according to officials from the massachusetts attorney general's office , the task force improved communication and furthered efforts to avoid overlap .

faced with the short time frames and accelerated roll out of recovery act funds , both the oversight community and agencies adjusted their oversight approach and innovated to foster accountability for recovery act funds at the federal and state agency levels .

these organizations became more engaged in up - front analysis and monitoring of programs under the recovery act and their reviews were often issued before money was spent .

these practices included ( 1 ) assessing and planning for risks up front ; ( 2 ) reviewing programs before and while they were being funded rather than waiting until after programs were implemented ; ( 3 ) communicating findings quickly through informal processes as opposed to regular full reports ; and ( 4 ) using advanced data analytics .

at the federal level , several agency oigs conducted up - front risk planning to proactively prepare for the influx of recovery act funds .

for example , the department of transportation's ( dot ) oig instituted a three - phase risk assessment process for dot programs that received recovery act funds .

the oig first identified existing program risks based on past reports ; it next assessed what the department was doing to address those risks ; and it then conducted the audit work .

dot's oig is continuing to use this three - phase scan approach for its work on hurricane sandy .

at the department of education , when the oig realized that education's discretionary grant budget would increase from a typical allotment of $60 billion annually to over $100 billion under the recovery act , officials put aside their initial work plan and developed a new one which focused on the recovery act .

toward this end , the oig conducted up - front risk assessments by looking at its prior work to identify persistent implementation issues going back to fiscal year 2003 .

the oig then issued a 2009 capping report that summarized these issues .

this report and additional risk assessments on recovery act - specific issues guided the oig's internal control audits that focused on the use of funds , cash management , subrecipient monitoring , and data quality for recovery act education programs .

shortly after the recovery act was signed , doe's oig reviewed the challenges the agency would need to address to effectively manage the unprecedented level of funding and to meet the goals of the recovery act .

the resulting report was based on a body of work by the oig to improve operations and management practices .

the oig identified specific risks that they discovered during past reviews and investigations .

the oig also suggested actions that should be considered during recovery act planning and program execution to help reduce the likelihood that these historical problems would recur .

further , the oig described the department's initial efforts to identify risks and to develop strategies to satisfy the recovery act's goals and objectives .

in addition , the report outlined the oig's planned oversight approach which adopted a risk - based strategy that included , among other things , early evaluations of internal controls and assessments of performance outcomes .

at hud , regional offices conducted front - end risk assessments of programs that would be receiving recovery act funds .

the hud oig considered these risk assessments when preparing its work plan and carrying out audits .

the office also conducted capacity reviews for programs that field offices had identified as having known issues .

the purpose of these capacity reviews was to enable the office to actively address and work to resolve known issues before recovery act funds were distributed to programs .

at the state level , audit organizations also adjusted their usual approaches when planning and conducting reviews of grant programs that received recovery act funds .

several state auditors conducted extra audit work of state programs up front in an effort to identify risks and inform their work moving forward .

for example , the office of the california state auditor conducted “readiness reviews” that highlighted known vulnerabilities in programs receiving recovery act money .

the office used the information coming out of these reviews to identify specific issues to focus on in future work as well as to inform the oversight committees of the state legislature and other state officials involved in recovery act oversight and implementation .

as a result of one such review that focused on doe's weatherization assistance program , the state auditor was able to identify key implementation issues that needed attention at a joint meeting of state and federal officials organized by the governor's recovery act task force .

the readiness review identified specific areas where the program needed to improve and informed the frequency with which state auditors would go back to program officials to check on progress .

according to the california state auditor , among the benefits of this approach was the feedback it provided to state agencies on their level of readiness as well as the detailed information given to both the state legislature and the governor's recovery act task force on the agency's progress .

the use of readiness reviews has continued post - recovery act .

most recently , the office employed the approach in 2013 as it prepared to audit the implementation of the affordable care act in california .

the recovery act's short time frames prompted the oversight community to carry out some of its reviews in “real time” as recovery funds were being rolled out , as opposed to the traditional approach of reviewing a program after implementation .

under this approach , members of the oversight community looked for ways to inform program officials of challenges and needed improvements much earlier in the process .

for example , as described previously in table 1 , the recovery act specified several roles for us , including conducting bimonthly reviews of selected states' and localities' use of funds made available under the act .

we subsequently selected a core group of 16 states and the district of columbia to follow over the next few years to provide an ongoing longitudinal analysis of the use of funds provided in conjunction with the recovery act .

the recovery act also assigned us a range of responsibilities to help promote accountability and transparency .

some were recurring requirements such as providing bimonthly reviews of the use of funds made available under various provisions of the recovery act by selected states and localities and reviews of quarterly reports on job creation and job retention as reported by recovery act fund recipients .

other requirements included targeted studies in several areas such as small business lending , education , and trade adjustment assistance .

in total , we issued approximately 125 reports on , or related to , the recovery act resulting in more than 65 documented accomplishments .

the interest in obtaining “real time” feedback concerning recovery act implementation was not limited to the oversight community .

for example , dot's federal highway administration ( fhwa ) established national review teams ( nrt ) within 3 months of the recovery act's passage to help assist its division offices attain the greater level of accountability and transparency called for under the recovery act .

as we previously reported , the nrts were composed of fhwa staff — separated from the rest of fhwa — to act as a neutral third party to conduct oversight .

the mission of the nrts was to conduct quick reviews of fhwa programs and assess processes and compliance with federal requirements in six key risk areas: ( 1 ) preliminary plans , specifications , and estimates ; ( 2 ) contract administration ; ( 3 ) quality assurance of construction materials ; ( 4 ) local public agencies ; ( 5 ) disadvantaged business enterprises ; and ( 6 ) eligibility for payments .

as a review progressed , the nrt discussed findings with division office and state transportation staff .

according to fhwa officials , independent reviews had several benefits: a consistent , comparative perspective on the oversight regularly conducted by division offices , and the collection of information at the national level on both best practices and recurring trouble spots across fhwa division offices ; additional “boots on the ground” for project - level oversight and increased awareness of federal oversight activity among states , metropolitan planning organizations , and other transportation organizations receiving recovery act funds ; and an independent outside voice to examine recovery act projects and point out problems , keeping the partnering relationship between the division offices and the state dots intact .

division offices and state officials with whom we spoke responded positively to the nrt reviews .

the nrt was viewed as a success for fhwa and it has since added independent reviews based largely on the nrt model to provide independent corporate level review of projects and programs in addition to providing other support services .

the rapid pace at which recovery act funds were being distributed also prompted audit organizations to communicate their findings earlier in the audit process .

for example , dot's oig issued periodic advisories within the agency rather than waiting until an audit was completed to share its findings .

according to oig staff , these advisories informed the department of issues or concerns shortly after they were discovered , thereby permitting program staff to take corrective action much more quickly .

in our first report on our bimonthly reviews of the use of recovery act funds by selected states and localities , we determined that the single audit process needed adjustment to provide the necessary level of focus and accountability over recovery act funds in a timelier manner than the current schedule .

subsequently , we recommended that the director of omb adjust the single audit process to provide for review of the design of internal controls during 2009 over programs to receive recovery act funding , before significant expenditures in 2010 .

in response , in october 2009 omb implemented the single audit internal control project — a collaborative effort between 16 volunteer states receiving recovery act funds , their auditors , and the federal government — to achieve more timely communication of internal control deficiencies for higher - risk recovery act programs .

the project encouraged auditors to identify and communicate significant deficiencies and material weaknesses in internal controls over compliance for selected major recovery act programs 3 months sooner than the 9-month time frame required under statute .

the project allowed program management officials at an audited agency to expedite corrective action and help mitigate the risk of improper recovery act expenditures .

in may 2010 , we reported that the project met some of its objectives and was helpful in identifying critical areas where further omb actions were needed to improve the single audit process over recovery act funding .

auditors at the local level also communicated their findings early .

for example , the denver city auditor's office adopted new practices to provide more timely information on recovery act programs to the mayor and other key officials , particularly on issues affecting compliance with recovery act reporting requirements .

using a tiered notification process , the auditor's office would initially notify the appropriate city department informally through e - mail or a similar means of potential issues they were finding during an on - going audit .

the auditor's office would revisit the issues later and , if the office determined the issue had not been addressed , it would then formally communicate any substantive issue on a real - time basis through an “audit alert.” these alerts were typically brief documents and went to the affected departments as well as directly to the mayor's work group that oversaw the city's recovery act implementation .

if appropriate action was still not forthcoming , the city auditor might issue a public alert or maybe a full public audit report .

according to a senior city audit official , the alerts were beneficial because the city auditor did not have to conduct a full audit to communicate risks and findings to decision makers , allowing them to more quickly address problems .

the city auditor issued its first audit alert in october 2009 and subsequently issued another one in february 2010 when problems from the first one had not been addressed .

after the second alert , the city administration corrected the identified problems .

to further increase accountability under the recovery act , the recovery board utilized innovative data analytics in carrying out its oversight responsibilities .

data analytics is a term typically used to describe a variety of techniques that can be used to analyze and interpret data to , among other things , help identify and reduce fraud , waste , and abuse .

specifically , predictive analytic technologies can be used to identify potential fraud and errors before payments are made , while other techniques , such as data - mining and data - matching of multiple databases , can identify fraud or improper payments that have already been awarded , thus assisting agencies in recovering these dollars .

in october 2009 , the recovery board established an innovative center to analyze the use of recovery act funds by employing data analytics ( see figure 3 ) .

the recovery operations center ( roc ) served as a centralized location for analyzing recovery act funds and their recipients through the use of such predictive analytic technologies .

according to recovery board staff , the results of these approaches provided the oig community and other oversight authorities with information they could use to focus limited resources on cities , regions , and high - risk government programs where historical data and current trends suggested the likelihood of future risk .

roc analysts would cross - reference lists of grant recipients or sub - recipients against a variety of databases to look for risk indicators such as criminal convictions , lawsuits , tax liens , bankruptcies , risky financial deals , or suspension / debarment proceedings .

one tool used to do this is link analysis , which assists the analyst in making connections by visually representing investigative findings .

link analysis charts visually depict how individuals and companies are connected , what awards an entity has received , and how these actors may be linked to any derogatory information obtained from the databases described above .

such tools , when combined with enhanced geographic information system capabilities , enable roc analysts to conduct geospatial analysis by displaying data from multiple datasets on maps to help them make linkages and discover potential problems .

for example , the roc helped a federal agency investigate possible contract fraud related to over - billing on multiple contracts .

roc analysts found 99 recipient awards made to a single company totaling over $12 million .

in another example , the roc helped to investigate allegations of false claims and major fraud against the united states .

roc analysts found officers of one company were also executives of more than 15 other companies , many of which were located at the same address , and collectively received millions in recovery act funds .

more recently , the roc has been used to track funds and help reduce fraud , waste , and abuse related to the tens of billions of dollars that have been awarded to states and communities to assist in their recovery after hurricane sandy hit in october 2012 .

recovery board staff have sought to leverage the expertise they have developed in analyzing financial spending and identifying potential fraud and high - risk indicators based on their experience with the recovery act .

figure 3 .

an analyst working in the recovery board's recovery operations center and a sample output of one of roc's link analysis tools .

to assure the public that their tax dollars were being spent efficiently and effectively , the recovery act called for increased oversight and accountability of those funds by oversight and program entities at the federal , state , and local levels .

this increased emphasis on oversight and accountability presented challenges for those entities stemming from ( 1 ) a lack of financial resources to conduct oversight at the state and local levels , ( 2 ) human capital issues , and ( 3 ) the accelerated roll out of recovery act funds .

officials with whom we spoke in several states expressed concerns that the recovery act did not provide funding to state oversight entities , although it placed additional federal requirements on them to provide proper accounting and to ensure transparency .

federal agency oig offices received a significant amount to conduct oversight of recovery act funds — ranging anywhere from $1 million to $48.25 million distributed to more than 28 agencies .

in contrast , states and localities relied on their existing budgets and human capital resources ( and , in some cases , supplemented by a small percentage of administrative funds ) to carry out their additional oversight activities .

due to fiscal constraints , states reported significant declines in the number of management and oversight staff — limiting states' ability to ensure proper implementation and management of recovery act funds .

with oversight capacity already strained in many states , the situation was further exacerbated by increased workloads resulting from implementation of new or expanded grant programs funded by the recovery act .

for example , massachusetts officials explained that the state oversight community faced budget cuts of about 10 percent .

according to officials from the oig and the state auditor's office , their budgets are almost entirely composed of salaries , and any cuts in funding resulted in fewer staff available to conduct oversight .

as a result of the cuts , the inspector general stated that his department did not have the resources to conduct any additional oversight related to recovery act funds .

further , the massachusetts state auditor described how his department had to furlough staff for 6 days in fiscal year 2009 .

in recognition of this situation and reflective of the state's desire to pursue fraud in the recovery act program , for state fiscal years 2009 through 2012 , the massachusetts recovery and reinvestment office allocated funds from the state's central administration account to the attorney general , state auditor , and oig offices to ensure that oversight would take place .

the california state auditor also cited the lack of federal funding for state and local oversight as a challenge to ensuring accountability in the implementation of the recovery act .

in a 2009 testimony to the california state budget committee , the state auditor said that her office would need to conduct an additional 14 audits based on an initial analysis of the estimated stimulus funds that california would receive .

furthermore , the programs that the office was auditing at the time received additional funds , which potentially increased the workload and cost to audit those programs as well .

finally , new requirements created by the recovery act for existing programs also impacted the state audit office's efforts .

the california state auditor noted that given the additional responsibilities her office faced due to the influx of stimulus funds , any budget cuts would adversely affect the office's ability to conduct audits .

in another example , colorado's state auditor reported that state oversight capacity was limited during recovery act implementation , noting that the department of health care policy and financing had three controllers in 4 years and the state legislature's joint budget committee cut field audit staff for the department of human services in half .

in addition , the colorado dot's deputy controller position was vacant , as was the department of personnel & administration's internal auditor position .

colorado officials noted that these actions were , in part , due to administrative cuts during a past economic downturn in an attempt to maintain program delivery levels .

the president's goal for quickly spending recovery act funds created a large spike in spending for a number of programs in the 28 agencies receiving recovery act funds .

the act also created a number of new programs — requiring agencies to move quickly .

as a result , under the recovery act's accelerated rollout requirements , some federal agencies and states faced oversight challenges .

for example , dot and states faced numerous challenges in implementing the recovery act's maintenance - of - effort oversight mechanism due to the accelerated rollout of funds .

the recovery act contains maintenance of effort provisions designed to prevent recipients , such as state dots , public housing agencies , and private companies , from substituting planned spending for a given program with recovery act funds .

that is , the provisions ensured that the increased federal spending would supplement rather than replace state , local , or private spending .

the maintenance - of - effort provision for dot in the recovery act required the governor of each state to certify that the state would maintain its planned level of transportation spending from february 17 , 2009 , through september 30 , 2010 .

twenty - one states did not meet their certified planned spending levels , and a january 2011 preliminary dot report found that some of these states were unclear on what constituted “state funding” .

dot also found some of the states were unclear about how well dot guidance on calculating planned expenditures would work in the many different contexts in which it would have to operate .

as a result , many problems came to light only after dot had issued initial guidance and states had submitted their first certifications .

dot issued guidance seven times during the first year after the act was signed to clarify how states were to calculate their planned or actual expenditures for their maintenance - of - effort certifications .

further , many states did not have an existing means to identify planned transportation expenditures for a specific period , and their financial and accounting systems did not capture that data .

therefore , according to dot and some state officials , a more narrowly focused requirement applying only to programs administered by state dots or to programs that typically receive state funding could have helped address the maintenance - of - effort challenges .

dot and state officials told us that while the maintenance - of - effort requirement can be useful for ensuring continued investment in transportation , allowing more flexibility for differences in states and programs , and adjustments for unexpected changes to states' economic conditions , should be considered for future provisions .

at doe , the department initially encountered some challenges with fully developing a management and accountability infrastructure because of the large amount of recovery act funding it received in a short period of time .

according to an official in the doe oig's office , this was especially true with the new energy efficiency conservation block grant program.this official told us that some states and localities also did not have the infrastructure in place ( including the necessary training ) to manage the large amount of additional federal funding .

further , doe required recipients' weatherization plans to address how the respective state's current and expanded workforce ( employees and contractors ) would be trained .

in may 2010 , according to doe , the agency was in the process of developing national standards for weatherization certification and accreditation .

doe estimated that developing the standards would take about 2 years — a time frame that did not match the accelerated timing of the recovery act's funds' distribution .

several years after the recovery act was implemented , doe reported that it had completed certain milestones toward developing national standards for weatherization , training , certification , and accreditation , but was still working to finalize other elements such as its national certification program .

in an april 2009 memorandum , omb directed agencies to follow leading practices for federal website development and management , such as those listed on howto.gov , a website managed by the federal web managers council and the general services administration.makes available a list of the “top 10 best practices” for federal websites as a resource to improve how agencies communicate and interact with howto.gov customers and provide services.state and city recovery websites , demonstrated several of these leading practices including establishing a clear purpose of the website , using social networking tools to garner interest in the website , tailoring websites to meet audience needs , and obtaining stakeholder input when designing the website .

in addition , we found that some websites enabled place - based performance reporting .

consistent with leading practices for the development of federal websites on howto.gov , recovery.gov and selected state recovery websites clearly identify for the user the purposes of the site and the ways it can be used to accomplish tasks efficiently .

according to howto.gov , this is important because people often visit government websites with a specific task in mind , and if it is not easy to find the information quickly that they need to complete that task , they will leave the site .

recovery.gov contains an entire page that outlines what users can do on the site , including how to use the raw data available through the website ; report waste , fraud , and abuse ; or find job and grant opportunities .

further , recovery.gov has a “get started” page with an overview of the information on the site including recovery act goals , the recovery board's mission , what information is not available on the website , and what users can do on the website .

similarly , massachusetts' recovery website has tabs on its homepage that link to information on how to use the website to track recovery act jobs , spending , vendors , and the impact of recovery act dollars in the state .

for example , the “track jobs” page informs users how they can track jobs created and retained in their community and provides a user guide to assist them in their query .

another leading practice for federal websites includes the use of social networking tools .

according to howto.gov , social media is transforming how government engages with citizens , allowing agencies to share information and deliver services more quickly and effectively than ever before .

recovery.gov and selected state and local recovery websites use social networking tools to garner interest in their websites .

these websites integrated web 2.0 technologies to help people share and use the information they provide .

for example , to develop web - based communities of interest , recovery.gov has a dedicated social media web page that has links to recovery's presence on various social - networking tools such as facebook , twitter , youtube , and flickr .

recovery.gov's social media page enables users to ( 1 ) download a recovery application for iphones and for ipads with a mapping feature showing how recovery act funds were being spent , ( 2 ) sign up for a recovery.gov month - in - review email , and ( 3 ) sign up to receive recovery rss web feeds .

finally , recovery.gov also has a blog , written by recovery board staff , with a stated purpose to further a dialogue on transparency and accountability in government , as well as to provide a forum for thoughts , comments , and suggestions from the public .

new york city also made use of social networking to communicate information regarding recovery act implementation through the use of a tumblr blog .

city officials used this blog to communicate stories and examples to its residents about how it was using recovery act funds and the impact of those investments .

city officials said the blog allowed them to get behind full - time equivalent numbers and dollar expenditures so that people could better understand how the recovery act was helping them tackle problems where they work and live .

for example , the blog described one project that had no net increase in jobs but still made a valuable difference for the city because recovery act funds were used to repair 300,000 potholes and move to zero diesel fuel emissions for city vehicles .

organizing a website according to the needs of its audience is also a key leading practice for federal websites since an agency's goal is to build the right website for the people who need it and serve them effectively by learning as much as possible about the website's customers and what they do .

recovery.gov has dedicated pages for different audiences that compile and organize relevant resources according to their needs and interests .

on its home page , recovery.gov has a tab which provides links to pages designed with specific users in mind such as citizens , the press , and grant recipients .

there are also links to pages on neighborhood recovery act projects , information on the recovery board , and other information users are looking for .

for example , grant recipients have a dedicated page that provides resources such as reporting timelines , user guides , a service / help desk , recipient reporting information , and a recipient awards map .

 ( see figure 4. ) .

on recovery.gov's “developer center” web page , users can access data reported by recipients of recovery awards through the recovery application program interface ( api ) and the mapping api .

users can also find widgets providing data summaries by state , county , congressional district , or zip code as reported by recipients .

the web page also has a tool for users to build customized charts and graphs displaying information such as funds awarded and received by state , agencies by number of awards , and spending categories by funds awarded .

the state of massachusetts also tailored its recovery act website to meet its audience's needs .

prior to its implementation of the recovery act's transparency provisions , massachusetts had little experience with electronic reporting and disclosure of federal contracts , grants , and loans .

the massrecovery website provided weekly citizen updates and testimonials of how spending has benefited lives .

the citizens' update web page provides a summary of where the state's recovery act dollars are going , where jobs are being created and retained , and information on beneficiaries of funds received .

in december 2009 , masspirg , an independent consumer research group , issued a brief pointing to the strengths of the massachusetts recovery website including the ability of the citizens' update web page to show money spent and jobs created and retained in easy - to - read pie charts and tables ; a summary of funds distributed through the state ; and an interactive state map of recovery act spending .

further , in january 2010 , good jobs first , a national policy resource center , reviewed and evaluated states' recovery act websites .

the organization ranked massachusetts' recovery website on its top 10 list citing such beneficial features as the site's comprehensive search engine , data download capability , and information on five key recovery act project elements — description , dollar amount , recipient name , status , and the text of the award .

leading website practices also recommend that developers obtain stakeholder input when designing federal websites by engaging potential users through focus groups and other outreach ; regularly conducting usability tests to gather insight into navigation , the organization of content , and the ease with which different types of users can complete specific tasks ; and collecting and analyzing performance , customer satisfaction , and other metrics .

according to leading website practices , these efforts are important for collecting and analyzing information about audiences , their needs , and how they are using , or want to use , the website .

the developers of recovery.gov followed this leading practice by using input from user forums , focus groups , and usability testing with interested citizens to collect feedback and recommendations , which then inform the development of the website from its initial stages .

for example , teaming with omb and the national academy of public administration , the developers of recovery.gov hosted a week - long electronic town hall meeting at the end of april 2009 entitled “recovery dialogue on information technology solutions.” over 500 citizens , information technology specialists , and website development experts registered for the event and submitted numerous ideas .

recovery.gov adopted some of the ideas right away and included others in the re - launched version of the website in september 2009 .

these changes included a standardized reporting system for recipients , a greater use of maps , and a feedback section for users .

additionally , in october 2009 , recovery.gov developers conducted remote usability testing with 72 users , where the developers received suggested changes , some of which they later implemented .

further , in 2012 , significant changes were made to recovery.gov based on user feedback on the website .

these changes included creating a recipient and agency data page , agency profiles , and a new recipient projects map with a series of dropdown menus and checkboxes that enable users to filter data so they can see it in a targeted fashion ( for example , by state , agency , or category ) .

for websites covering numerous projects at various locations , a place - based geographic information system can be a useful tool .

according to the white house's digital government strategy , the federal government needs to be customer - centric when designing digital service platforms such as websites .

in other words , agencies need to be responsive to customers' needs by making it easy to find and share electronic information and accomplish important tasks .

from the beginning , recipient reported data on recovery.gov was geo - coded in a way that made it possible for users to find awards and track the progress of projects on a block - by - block basis .

the presentation of information on recovery.gov and on many state websites generally targeted individual citizens who were not experts in data analysis .

the format and content of data prioritized mapping capabilities and invited people to enter their zip code and locate projects in their immediate area .

for example , figure 5 shows the map a user sees if zip code 30318 in georgia is entered into this web page .

from this map , the user can click on any of the dots that represent recovery projects to find out information such as the project recipient name , award amount , project description , number of jobs created , and completion status .

additional information available to users includes the amount of funds received by recipients as well as the overall distribution of grants by funding categories for that area .

states and localities also utilized mapping features on their recovery websites .

for example , in new york city , recovery officials launched a recovery act website , the nycstat stimulus tracker , as an interactive , comprehensive reporting tool .

the federal government's website , recovery.gov , served as the design inspiration and , according to a senior city official , stimulus tracker was one of the first publicly - accessible websites to report recovery act data for a local jurisdiction .

city recovery officials were able to develop and launch new york city's stimulus website more quickly than other locations — approximately 6 weeks from start to completion — because they were able to leverage a previously implemented information technology platform to support citywide performance reporting .

stimulus tracker allowed the public to explore several levels deeper than what was at recovery.gov , which reported at the funding award level .

for example , stimulus tracker broke down each award into several projects , each of which had its own dashboard page that displayed information such as ( 1 ) the status of the project , ( 2 ) the percentage of total funds spent , ( 3 ) start date and spending deadlines , and ( 4 ) the number of jobs created or retained .

visitors to the site could drill into a record of every payment made with stimulus funds through the additional feature “payment tracker” and every contract to carry out stimulus - funded work through “contract tracker.” stimulus tracker also offered an interactive map for site visitors who were interested in knowing how stimulus dollars were allocated geographically and where specific projects were located .

this information was layered on top of the city's existing online map portal .

it included such items as the locations of schools , libraries , hospitals , and subways , as well as online property , building , statistics , and census information .

as new york city's existing online map portal could already be navigated either by entering a specific address or simply using zoom and scroll tools , city recovery act officials were able to build on this application and include a city mapping tool for recovery act funds where the public could find any project with a discrete location .

see figure 6 for a screen shot of new york city's mapping tool depicting the city's recovery act projects .

the recovery act requires recipients to report on their use of funding and agencies that provide those funds to make the reports publicly available .

the recovery act's recipient reporting requirements apply only to nonfederal recipients of funding , including all entities other than individuals receiving recovery act funds directly from the federal government such as state and local governments , private companies , educational institutions , nonprofits , and other private organizations .

as required by section 1512 ( c ) of the recovery act , recipients were to submit quarterly reports that included the total amount of recovery act funds received , the amount of funds expended or obligated to projects or activities , and a detailed list of those projects or activities .

for each project or activity , the detailed list was to include the project's name , description , and an evaluation of its completion status .

also , the recipient reports were to include detailed information on any subcontracts or subgrants as required by the federal funding accountability and transparency act of 2006 .

for example , recipient reports are required to also include details on sub - awards and other payments .

with the recovery act's enhanced reporting requirements on spending , agencies and recipients faced several challenges .

many agencies and state and local partners were limited in their capacity to meet the enhanced reporting requirements due to a lack of knowledge and expertise .

others struggled with the burden of double reporting when they had to report to federal systems tracking recovery dollars as well as to agency systems because , in some cases , agencies required more data to manage their programs .

finally , some had trouble reporting data for certain projects within the operational limitations of place - based data mapping systems .

capacity to meet reporting requirements .

many state and local partners were limited in their capacity to meet spending reporting requirements because they lacked knowledge and expertise .

using a centralized mechanism like federalreporting.gov to capture recipient reporting information was a new process that recipients and agencies had to learn .

we have previously reported on the questions raised by state officials regarding the reporting capacities of some local organizations , particularly small rural entities , boards , or commissions , and private entities not used to doing business with the federal government .

in addition , some state officials said that the recovery act's requirement that recipients report on the use of funds within 10 days after a quarter ends was a challenge because some sub - recipients were unable to send them the needed data on time .

officials at several agencies suggested that if federalreporting.gov had allowed certain key award and identifying data fields to be pre - populated each quarter , it would have likely resulted in fewer data errors for agencies to address and eased the reporting burden on recipients .

in our september 2013 report and testimony on federal data transparency , we concluded that the transparency envisioned under the recovery act for tracking spending was unprecedented for the federal government , requiring the development of a system that could track billions of dollars disbursed to thousands of recipients .

such a system needed to be operational quickly to enable posting of spending information rapidly for a variety of programs .

however , because agency systems did not collect spending data in a consistent manner , the most expedient approach for recovery act reporting was to collect data directly from fund recipients .

recipients had the additional burden of having to provide this information and when the data had to be entered manually , it could impact the accuracy of the data .

thus , in september 2013 we recommended that the director of omb , in collaboration with members of the government accountability and transparency board , develop a plan to implement comprehensive transparency reform , including a long - term timeline and requirements for data standards , such as establishing a uniform award identification system across the federal government .

earlier this year , the recovery board noted that agencies and oigs also experienced difficulties adapting to the more frequent reporting ( every quarter ) and more detailed reporting ( eg , jobs created or individual project activities ) required of most government grant recipients .

agency officials acknowledged spending considerable staff hours training recipients , providing technical assistance to them , verifying and validating their data , and following up with them when issues arose .

despite efforts to streamline and enhance existing review protocols , agencies still needed skilled people to review and process applications for awards .

although agencies and oigs credited outreach to recipients for reducing noncompliance with reporting requirements , the amount of staffing resources it took to conduct that outreach was significant .

double reporting .

we have previously noted that recipients of recovery act funds were required to report similar information to both agency reporting systems and federalreporting.gov .

several federal agency and state government officials we spoke with also mentioned that reporting to federalreporting.gov resulted in double reporting for their agency and grantees as several of them deemed their existing internal systems superior and therefore would end up reporting to both .

for example , at hud , program offices were unable to abandon their established reporting systems because the agency's systems collected data necessary to support hud's grants management and oversight processes .

hud officials told us that requiring grantees to report using two systems resulted in double reporting of data and proved burdensome to recipients and to hud staff who spent many hours correcting inaccurate entries .

at dot , officials preferred using the agency's own data because it was more detailed and was reported monthly — more frequently than the recovery.gov data .

in a focus group involving state transportation officials , several echoed the redundancy of reporting systems .

these officials indicated that having to report to three systems — the internal state system , dot's system , and federalreporting.gov — increased their agencies' burden .

as we reported in our previously mentioned september 2013 report and testimony on federal data transparency efforts , the lack of consistent data and standards and commonality in how data elements are defined places undue burden on federal fund recipients .

this can result in them having to report the same information multiple times via disparate reporting platforms .

procedures for reporting on the use of federal funds , it directed recipients of covered funds to use a series of standardized data elements .

further , rather than report to multiple government entities , each with its own disparate reporting requirements , all recipients of recovery act funds were required to centrally report into the recovery board's inbound reporting website , federalreporting.gov .

gao - 13-871t and gao - 13-758 .

the geospatial reporting presentation format on the website .

for example , according to recovery board officials , the website only allowed one location to be reported per project even though some projects spanned multiple locations .

therefore , if a dot highway project crossed multiple zip codes , only one location of performance could be reported .

further , certain locations were difficult to map such as rural roads , post office boxes , county level data , and consultant contractors who worked out of their homes .

the other major performance measure required under the recovery act focused on the estimate of the number of jobs created or number of jobs retained as a result of funding provided by the act .

in addition to the previously described reporting on funds spent and activities , recipients were required in their quarterly reports to estimate the number of jobs created or retained by that project or activity .

omb issued clarifying guidance for recipient reporting in june 2009 and recipients began reporting on jobs starting in october 2009 .

among other things , the guidance clarified that recipients of recovery act funds were to report only on jobs directly created or retained by recovery act - funded projects , activities , and contracts .

recipients were not expected to report on the employment impact on materials suppliers ( “indirect” jobs ) or on the local community .

recipients had 10 days after the end of each calendar quarter to report .

omb's guidance also provided additional instruction on calculating the number of jobs created or retained by recovery act funding on a full - time equivalent ( fte ) basis .

recipients faced several challenges meeting these requirements .

they had difficulty accurately defining ftes , as various recipients interpreted and applied the fte guidance from omb differently .

further , many recipients struggled to meet reporting deadlines as they had little time to gather , analyze , and pass on information to the federal government at the end of each fiscal quarter .

definitional challenges and discrepancies in reporting ftes .

under omb guidance , jobs created or retained were to be expressed as ftes .

in our november 2009 report we found that recipients reported data inconsistently even though omb and federal agencies provided significant guidance and training .

specifically , we found that while fte calculations should allow for different types of jobs — part time , full time or temporary — to be aggregated , differing interpretations of the fte guidance compromised the recipients' ability to aggregate the data .

for example , in california , two higher education systems calculated ftes differently .

one chose to use a 2-month period as the basis for the fte performance period .

the other chose to use a year as the basis .

the result was almost a three - to - one difference in the number of ftes reported for each university system in the first reporting period .

although the department of education provided alternative methods for calculating an fte , in neither case did the guidance explicitly state the period of performance of the fte .

we recommended that omb clarify the definition of fte jobs and encourage federal agencies to provide or improve program - specific guidance for recipients .

further , we recommended that omb be more explicit that jobs created or retained are to be reported as hours worked and paid for by the recovery act .

in general , omb and agencies acted upon our recipient reporting - related recommendations and later reporting periods indicated significant improvements in fte calculations .

omb's guidance changed the original formula and consequently , agencies had to rush to educate recipients about the changes .

agencies spent extra time and resources that quarter reviewing and validating recipient data to reduce errors .

in some cases , agencies communicated daily with recipients via phone or e - mail to ensure their report submissions were accurate .

capacity of recipients to meet deadlines .

the requirement to regularly report on jobs created and retained further strained the capacity of some recipients .

recipients only had 10 days after the end of each fiscal quarter to determine this information and pass it on to the federal government.reporting should have been extended by 1 to 2 weeks so they were not rushing to input data .

one of these officials said she was directed by other state officials to put in “the best data you have , even if it's not correct…and go back and correct it later.” city officials also reported concerns with the quick turn - around time for reporting .

for example , one city official stated that , in order to meet reporting deadlines , it was necessary had to enter data manually , which created additional work .

the recovery board accepted these post - correction actions as it extended the quality assurance period to provide more time for agencies to review reports and recipients to make corrections in federalreporting.gov .

as a result , recipients could change their reports up to about 2 weeks before the start of the next reporting period .

the administration required agencies receiving recovery act funds to submit performance plans that identified additional measures on a program - by - program basis .

consistent with existing gpra requirements for agencies to set outcome - oriented performance goals and measures , omb's initial recovery act implementation guidance required federal agencies to ensure that program goals were achieved .

omb required agencies to measure specific program outcomes , supported by corresponding quantifiable output measures , and improved results on broader economic indicators .

agencies typically resorted to existing measures in their grant programs' performance plans .

this information is reported by agency and by program within each agency , as opposed to government - wide .

while recovery.gov provided a template for facilitating the reporting of this information , the level of detail and specificity of outcomes varied greatly for some of the agencies we reviewed , making it difficult to determine the extent to which some were making progress toward their goals and demonstrating results .

see omb memorandum m - 09-10 ( 2009 ) .

this information was to be provided by all agencies receiving recovery act funds , covering each grant program using these funds , in the agencies' “recovery program plans” submitted to omb .

initially due on may 1 , 2009 , the plans were to be updated by the agencies as needed and were to be published on recovery.gov as well as agency websites .

these plans included information on each recovery act program's objectives , activities , delivery schedule , accountability plan , monitoring plan , and program performance measures .

for example , education's performance plan described the agency's accountability mechanisms , the type and scope of project activities , and specific program performance measures .

with the exception of the number of jobs created or retained , education's plan stated the agency was primarily using existing established agency performance measures that applied to both recovery and non - recovery funds .

for example to measure the success of one type of education grant fund ( specifically , title i of the elementary and secondary education act of 1965 , as amended ) which the recovery act made available to local educational agencies , education used existing agency performance measures , such as the percentage of economically disadvantaged students in grades 3 to 8 scoring at the proficient or advanced levels on state reading and mathematics assessments .

on the other hand , dot filled out the templates to report on its 12 programs , and its performance measures were generally less specific and outcome oriented .

for example , dot's capital assistance for high speed rail corridors and intercity passenger rail service performance plan metrics included whether interim guidance was published within time frames , the number of applicants received for the program , and the number of grants awarded for the program .

further , as we previously reported , dot released a series of performance plans in may 2009 to measure the impact of recovery act transportation programs , but these plans generally did not contain an extensive discussion of the specific goals and measures to assess the impact of recovery act projects .

for example , while the plan for the highway program contained a section on anticipated results , three of its five measures were the percent of funds obligated and expended and the number of projects under construction .

the fourth measure was the percentage of vehicle miles traveled on pavement on the national highway system rated in good condition , but the plan said that goals for improvement with recovery act funds were yet to be determined .

the fifth goal was number of miles of roadway improved , and dot's plan reported that even with the addition of recovery act funds , the new target would remain the same as previously planned .

as a result , we recommended in may 2010 that dot ensure that the results of these projects were assessed and a determination made about whether these investments produced long - term benefits .

dot did not implement our recommendation .

created in response to the recent serious recession , the recovery act represents a significant financial investment in improving the economy .

grant programs were a key mechanism for distributing this support .

by increasing accountability and transparency requirements while at the same time setting aggressive timelines for the distribution of funds , the recovery act created high expectations as well as uncertainty and risk for federal , state , and local governments responsible for implementing the law .

faced with these challenges , some of these organizations looked beyond their usual way of doing business and adjusted their usual practices to help ensure the accountability and transparency of recovery act funds .

the oversight community adopted a faster and more flexible approach to how they conducted and reported on their audits and reviews so that their findings could inform programs of needed corrections before all recovery funds were expended .

they leveraged technology by using advanced data analytics to reduce fraud and to create easily accessible internet resources that greatly improved the public's access to , and ability to make use of , data about grants funded by the recovery act .

these and other experiences , as well as the challenges identified in this report , provide potentially valuable lessons for the future .

underlying many of these lessons is the importance of increased coordination and collaboration , both vertically — transcending federal , state , and local levels of government — and horizontally — across organizational silos within the federal community — to share information and work towards common goals .

one question that remains unresolved is the extent to which good practices developed in response to the recovery act's special challenges and conditions can ultimately be incorporated in everyday practice for managing and overseeing grants .

some of the practices we found , such as the use of the recovery operations center and state readiness reviews , have been able to make this transition .

others , such as some of the information sharing networks established during the recovery act , have had more difficulty in doing so .

proposals under consideration by congress and the administration to extend recovery act requirements for spending transparency to all federal grants suggest that this has been the case for tracking dollars .

still to be seen is whether it will be possible to provide this type of government - wide transparency to other measures of performance , such as grant outcomes .

we provided a draft of this report to the secretaries of the departments of education , energy , housing and urban development , and transportation ; and to the director of the office of management and budget .

we also provided drafts of the examples included in this report to cognizant officials from the relevant state and local agencies to verify accuracy and completeness , and we made technical changes and clarifications where appropriate .

the agencies generally agreed with our findings and provided technical comments which were incorporated in the report .

we are sending copies of this report to other interested congressional committees ; the secretaries of the departments of education , health and human services , housing and urban development , and transportation ; and the director of the office of management and budget .

in addition , the report will be available on our web site at http: / / www.gao.gov .

if you or your staff have any questions regarding this report , please contact me at ( 202 ) 512-6806 or by email at czerwinskis@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix i .

to better understand grant management lessons resulting from the american recovery and reinvestment act of 2009 ( recovery act ) , we focused on two key issues involving grant implementation during the recovery act: accountability and transparency .

specifically , this report identifies and provides examples of good practices employed and the challenges faced by select federal , state , and local agencies implementing grant programs funded by the recovery act , in the areas of accountability and transparency .

to obtain a broad view of lessons learned during the implementation of grants funded by the recovery act , we conducted a detailed literature review of relevant reports describing lessons learned from implementing grants funded by the recovery act from gao ; federal and state inspectors general ; federal agencies ; state and local governments ; accountability boards ; state and local government advocacy organizations ; think tanks ; and academia .

we developed selection criteria to identify relevant federal agencies and state and local governments to obtain their views related to the implementation of grant programs funded by the recovery act .

we then selected four federal agencies , three states , and two localities based on the extent to which they had information related to our focus areas of accountability and transparency ; information from our colleagues , subject matter experts , and academics ; and citations in the literature .

to capture a diverse mix of recovery act grants and identify potential good practices and challenges , we selected a variety of grants — some that had their funding structures already well established , others that had their funding greatly increased as a result of the recovery act , as well as new programs .

although medicaid was the largest grant program funded by the recovery act , we deemed it out of scope for the purposes of this review since it is primarily an entitlement and subject to specific rules that are not typical of program grants .

further , medicare and unemployment insurance were not included in the recipient reports we examined .

to obtain illustrative examples of the good practices employed and the challenges faced during the implementation of grants funded by the recovery act related to accountability and transparency , we conducted interviews with a wide range of officials and experts .

we interviewed cognizant officials and obtained supporting documentation from government - wide oversight entities at the federal level including the recovery implementation office , office of management and budget , and the recovery accountability and transparency board .

in addition , we interviewed and obtained supporting documentation from select federal agency officials from the departments of education ; energy ; housing and urban development ; and transportation ; and their respective inspectors general .

at the state level , we interviewed and obtained supporting documentation from agency and audit officials from the states of california , georgia , and massachusetts .

to get a broader state perspective , we also interviewed officials from the state recovery act coordinators' network , which included key state officials involved in implementing the recovery act from several states .

interviewed officials from denver , colorado and new york , new york .

the states represented in the state recovery act coordinators' network meeting were arizona , arkansas , delaware , florida , maryland , massachusetts , michigan , minnesota , missouri , nebraska , nevada , oregon , rhode island , tennessee , texas , utah , and wisconsin .

association of state budget officers , and the national association of counties .

we obtained additional information on lessons learned related to the recovery act from officials representing the government accountability and transparency board , sunlight foundation , council of government relations , national council of non - profits , center for effective government , the federal demonstration project , and national association of state chief information officers .

in addition , we conducted seven focus groups representing a range of federal fund recipients .

focus groups included: ( 1 ) state comptrollers ; ( 2 ) state education and transportation officials ; and ( 3 ) local government officials from both large and small municipalities .

each focus group had between four and eight participants who were recruited from randomized member lists provided by the recipient associations we interviewed .

lastly , we reviewed and synthesized information provided in previously issued reports related to the recovery act that included the following sources: our previous work ; inspectors general from the departments of education , energy , housing and urban development , and transportation ; the recovery accountability and transparency board ; the white house ; and various non - governmental sources including the ibm center for the business of government .

in addition , we reviewed and applied criteria established by howto.gov , a source of guidance and leading practices for government websites , to recovery.gov and state and local recovery websites .

the scope of our work did not include independent evaluation or verification of the effectiveness of the examples we identified .

we also did not attempt to assess the prevalence of the practices or challenges we cite either within or across levels of government .

therefore , entities other than those cited for a particular practice may or may not have employed the same or similar practice , and it is not possible to generalize how prevalent the practices and challenges may be across all recovery act grants .

we conducted this performance audit from december 2012 through january 2014 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact named above , peter del toro , assistant director ; mark abraham ; and jyoti gupta made significant contributions to this report .

also contributing to this report were tom beall , robert gebhart , jacob henderson , donna miller , robert robinson , beverly ross , and andrew j. stephens .

