the department of homeland security ( dhs ) invests extensively in acquisition programs to help execute its many critical missions .

dhs and its underlying components are acquiring systems to help reduce the probability of a terrorist attack , protect against infectious diseases , mitigate natural hazards , secure air and land borders , and execute a wide variety of other operations .

in fiscal year 2014 , dhs reported it planned to spend approximately $10.7 billion on its major acquisition programs , including acquisition , planning , maintenance , and investment support costs .

in 2011 , dhs told congress that it planned to invest a total of $167 billion in its major acquisition programs .

however , dhs officials were unable to verify this number or provide an update , during the course of this review , since the agency lacks key cost information for its programs .

we have highlighted dhs acquisition management issues on our high - risk list since 2005 and made numerous recommendations to in recent years , dhs has improve acquisition management practices.taken steps to improve acquisition management by dedicating additional resources to oversight and documenting major acquisition decisions in a more transparent and consistent manner .

however , many of our recommendations have not yet been implemented , including that dhs ensure all major acquisition programs fully comply with dhs acquisition policy .

within dhs , the office of program accountability and risk management ( parm ) is the lead body responsible for overseeing the acquisition process and assessing the status of acquisition programs , although other dhs offices also have oversight roles .

nearly all of dhs's program management offices are located within 13 department organizations , including components such as the transportation security administration , u.s. coast guard , and u.s. customs and border protection .

you requested that we review dhs's oversight of its major acquisition programs .

this review focuses on parm's day - to - day program oversight , rather than oversight at key points in the acquisition life cycle as defined in policy , such as acquisition decision events that can occur years apart .

we have previously reviewed the key points in the acquisition life cycle and have found that dhs's acquisition policy reflects many key program management practices .

specifically , this report addresses ( 1 ) steps dhs has taken to improve oversight and gaps that exist , if any , and ( 2 ) whether the data parm provides to dhs and congressional decision makers to carry out their oversight responsibilities are accurate and up - to - date .

to conduct our work , we identified organizations within dhs , in addition to parm , that are responsible for oversight of major acquisitions and determined their roles and responsibilities by analyzing dhs policies and procedures , reviewing organizational charts , and interviewing policy , budget , and acquisition oversight officials at the headquarters level .

to determine how parm coordinates with the components to conduct oversight , we selected nine dhs components with responsibility for at least one level 1 acquisition — a program with a reported life - cycle cost estimate exceeding $1 billion — and interviewed their component acquisition executives ( cae ) or designees .

we reviewed component - specific policies and procedures and charters for program governance groups , as well as other relevant documentation .

we also selected a non - generalizable sample of one major acquisition program from each of the nine components to collect examples , from program office officials , of parm's oversight and coordination activities .

we selected as our case study programs those that included a variety of characteristics , such as parm identification as high visibility for oversight purposes , high and low “risk scores” as reported by parm , information technology ( it ) and non - it programs , and a range of life - cycle cost estimates .

for the nine case studies , we reviewed relevant documentation , such as acquisition decision memorandums , and interviewed program officials .

we selected the following programs as case studies: national protection and programs directorate — next generation office of the chief information officer ( ocio ) — national capital science and technology directorate — national bio and agro - defense transportation security administration — technology infrastructure u.s .

citizenship and immigration services — verification u.s. coast guard — fast response cutter u. s. customs and border protection — strategic air and marine u.s. immigration and customs enforcement — electronic health in addition , we collected program data for each of the nine case study programs from the information system that parm uses to track program performance , the next generation periodic reporting system ( nprs ) .

we assessed the data reliability of nprs by comparing this data to the information contained in the comprehensive acquisition status report , a report to congress , and noting discrepancies between the system data and the issued data .

based on the discrepancies we found , we evaluated the effectiveness of the acquisition report as a tool for dhs management and congressional oversight .

we determined that the nprs data were not sufficiently reliable for our purposes ; however , we present the data for illustrative purposes only .

see appendix i for a more complete description of our scope and methodology .

we conducted this performance audit from march 2014 to march 2015 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

dhs invests in major acquisition programs to develop capabilities intended to improve its ability to execute its mission .

dhs policy defines acquisition programs as follows: level 1 major acquisition programs are expected to cost $1 billion or more over their life cycles .

level 2 major acquisition programs are expected to cost at least $300 million over their life cycles .

special interest programs , without regard to the established dollar thresholds , are designated as level 1 or level 2 programs .

for example , a program may be raised to a higher acquisition level if its importance to dhs's strategic and performance plans is disproportionate to its size or it has high executive visibility .

level 3 programs are those with a life - cycle cost estimate less than $300 million and are considered non - major .

dhs's acquisition management directive 102-01 ( md 102 ) and dhs instruction manual 102-01-001 ( guidebook ) , which includes 12 appendices , establish the framework for the department's policies and processes for managing these acquisition programs .

md 102 establishes that dhs's chief acquisition officer — the under secretary for management ( usm ) — is responsible for the management and oversight of the department's acquisition policies and procedures .

the deputy secretary , usm , and cae are the acquisition decision authorities for dhs's acquisition programs , depending on the level .

the acquisition decision authority is responsible for reviewing and approving the movement of dhs's major acquisition programs through four phases of the acquisition life cycle at a series of five acquisition decision events .

these acquisition decision events , which can be more than one year apart , provide the acquisition decision authority an opportunity to assess whether a major program is ready to proceed through the life - cycle phases .

following are the four phases of the acquisition life cycle , as established in dhs acquisition policy: 1 .

need: department officials identify that there is a need , consistent with dhs's strategic plan , justifying an investment in a new capability and the establishment of an acquisition program to produce that capability ; 2 .

analyze / select: a designated program manager reviews alternative approaches to meeting the need and recommends a best option to the acquisition decision authority ; 3 .

obtain: the program manager develops , tests , and evaluates the selected option .

during this phase , programs may proceed through acquisition decision event 2b , which focuses on the cost , schedule , and performance parameters ; and acquisition decision event 2c , which focuses on low rate initial production ; and 4 .

produce / deploy / support: dhs delivers the new capability to its operators , and maintains the capability until it is retired .

this phase includes sustainment , which begins when a capability has been fielded for operational use ; sustainment involves the supportability of fielded systems through disposal , including maintenance .

figure 1 depicts the four phases of the acquisition life cycle and the associated acquisition decision events .

an important aspect of these acquisition decision events is the review and approval of key acquisition documents critical to establishing the need for a major program , its operational requirements , an acquisition baseline , and testing and support plans .

examples of key dhs acquisition documents include: a life - cycle cost estimate , which provides an exhaustive and structured accounting of all resources and associated cost elements required to develop , produce , deploy , and sustain a program ; and an acquisition program baseline , which establishes a program's critical baseline cost , schedule , and performance parameters .

we are also conducting a separate review that assesses the extent to which select dhs major acquisition programs are on track to meet their cost estimates , schedules , and capability requirements .

parm is designated by md 102 as the lead body responsible for overseeing the acquisition process of major acquisition programs .

parm was established in october 2011 to develop and update program management policies and practices , oversee the acquisition workforce , and collect program performance data .

parm is led by an executive director who reports directly to the usm .

in addition to its role of overseeing major acquisitions , parm provides support and assistance to caes and program managers at each of dhs's 13 components during the acquisition process .

within these components , caes are responsible for establishing acquisition processes and overseeing the execution of their respective portfolios .

also within the components , program management offices are responsible for planning and executing dhs's individual programs within cost , schedule , and performance goals and preparing required acquisition documents for acquisition decision events , which help facilitate the governance process .

table 1 lists elements at the headquarters , component , and program level that contribute to oversight of dhs major acquisition programs .

the fiscal year 2012 dhs appropriations act required the usm to submit a comprehensive acquisition status report ( casr ) with the president's budget proposal for fiscal year 2013 , and an associated conference report contained the specific information to be included in the casr .

the requirement for the casr has been continued in subsequent appropriations acts , and dhs is currently working on the next iteration of the casr , assuming dhs will again be required to produce this report .

the legislation required dhs to provide to congressional appropriations committees programmatic data and evaluative information , such as a program's current acquisition phase , life - cycle cost , and a rating of cost , schedule , and technical risks .

dhs is to include this information for each major acquisition on the master acquisition oversight list ( maol ) — a list of dhs acquisitions that is broken down into categories defining the differing oversight requirements across programs .

the legislation established the following casr requirements for major acquisition programs: 1 .

a narrative description including current gaps and shortfalls , the capabilities to be fielded , and the number of planned increments and / or units ; 2 .

acquisition review board status of each acquisition , including the current acquisition phase , the date of the last review , and a listing of the required documents that have been reviewed and / or approved ; 3 .

the most current approved acquisition program baseline , including project schedules and events ; 4 .

a comparison of the original and current acquisition program baseline , and the current estimate ; 5 .

whether or not an independent verification and validation has been implemented , with an explanation for the decision and a summary of any findings ; 6 .

a rating of cost risk , schedule risk , and technical risk associated with the program , including narrative descriptions and mitigation actions ; 7 .

contract status , including earned value management data , as 8 .

a life - cycle cost of the acquisition , and time basis for the estimate ; 9 .

a planned procurement schedule , including the best estimate of the annual cost and increments / units to be procured annually ; 10 .

a table delineated by appropriation that provides the actual or estimated appropriations , obligations , unobligated authority , and planned expenditures ; 11 .

the reason for any significant changes from the previous casr in acquisition quantity , cost , or schedule ; 12 .

key events or milestones from the prior fiscal year ; and 13 .

key events or milestones for the current fiscal year .

although dhs has taken steps to improve oversight of major acquisition programs , such as clarifying the role of the caes , it lacks written guidance for a consistent approach to oversight .

specifically , there is no guidance to define the roles and responsibilities of parm and other dhs headquarters organizations in providing day - to - day support and oversight to programs during the acquisition process .

parm started conducting monthly high visibility meetings to discuss programs that require immediate or additional management attention .

parm also maintains a list of programs subject to oversight , the maol .

the process for creating this list has fluctuated over time ; parm recently made revisions to the maol and plans to make further changes to it in the future .

finally , dhs has not established a structure for overseeing the costs of 42 programs in sustainment whose acquisition documentation requirements were waived by the usm in 2013 .

sustainment costs can account for more than 80 percent of total costs , and all but one of these programs lack an approved cost estimate .

while dhs has made progress in defining and documenting roles and responsibilities in the oversight of major acquisitions , such as issuing guidance describing the roles of caes , the roles and responsibilities of parm and other dhs headquarters organizations are not clear .

without defined roles and responsibilities , dhs cannot ensure it is providing the appropriate level of oversight or receiving the right information to conduct oversight .

parm has made efforts to expand its oversight and support roles through its component leads , parm's liaisons to the components ; however , roles and responsibilities for these positions are not defined .

in addition , there was no guidance to define the differences in the role of parm and ocio - enterprise business management office ( ebmo ) in the oversight of major it acquisitions , and we found potential overlap in the roles of these entities .

figure 2 illustrates parm's interactions with dhs headquarters , component , and program - level offices and officials with acquisition oversight responsibility .

some of these interactions are set forth in policy while others are not .

parm provides ongoing oversight and support to programs in a number of ways , such as consulting with program officials to prepare required documents prior to an acquisition review board and providing training to components on various aspects of program management .

one of parm's key mechanisms for providing day - to - day oversight and support to programs between acquisition decision events is through its staff of 10 component leads , but their roles and responsibilities are not defined in dhs acquisition policy .

according to parm officials , the component leads provide day - to - day oversight and support to acquisition programs for a specific component and are intended to be a key source of communication and coordination between parm and the programs .

in turn , component leads provide program information to parm's executive director , which may be used in high visibility meetings with the usm .

parm component leads told us they interact directly with the caes and program offices to ensure that programs are adhering to the acquisition process , along with meeting acquisition milestones and reporting requirements .

while parm's component leads play an important role in the coordination with components , their roles and responsibilities are not defined in dhs acquisition policy .

we found that their involvement and relationships with components varies significantly .

for example , parm's component lead for u.s .

citizenship and immigration services is involved in the day - to - day management of programs .

this component lead regularly attends component and program - level meetings and organizes training workshops to educate component and program - level staff .

in another example , the parm component lead for the national protection and programs directorate provided additional guidance and attention to the directorate's programs while the acting cae was learning his role .

in contrast , a u.s. coast guard official told us that while there is informal , almost daily communication , their component lead does not have direct access to program level data and relies on the input of the cae to schedule and prioritize department - level acquisition milestone meetings .

such differences in the parm component leads' involvement with programs may be appropriate depending on the type of program or experience of component and program office staff ; however , without defined roles and responsibilities , parm cannot ensure it is providing the appropriate level of oversight or receiving the right information to conduct oversight .

gao , auditing and financial management: standards for internal control in the federal government , gao / aimd - 00-21.3.1 ( washington , d.c.: nov. 1 , 1999 ) .

leads are not defined in dhs acquisition policy and it is a challenge that they are trying to determine how to address .

further , while parm is the lead office responsible for overseeing all major acquisition programs , we found confusion among component officials related to parm's role in it acquisitions , where ocio - ebmo also has oversight responsibility .

of the 72 level 1 and level 2 acquisition or service programs listed on the 2014 maol , 57 are designated as it programs .

per the dhs acquisition policy , the ocio is responsible for establishing it policies and procedures and ensuring that approved it acquisitions comply with technical requirements and departmental management processes , such as agile development , which calls for producing software in small , short increments .

within ocio , ebmo has been given primary responsibility for ensuring that the department's it investments align with its missions and objectives .

however , while dhs acquisition policy outlines responsibilities for parm and ocio , there is no guidance that defines how the role of parm differs from the role of ebmo in the oversight of it acquisition programs .

gao , auditing and financial management: framework for assessing the acquisition function at federal agencies , gao - 05-218g ( washington , d.c.: sept.1 , 2005 ) .

the oversight of major acquisitions could improve coordination , limit overlap of responsibilities , and reduce duplicative efforts at the component level .

in september 2014 , the usm issued a policy memorandum clarifying the responsibilities of the caes , who have an important role in acquisition oversight .

to strengthen acquisition oversight within the department , the usm intends to standardize these officials' acquisition authorities and experience levels .

the memo also sets forth oversight responsibilities of the caes , particularly for the level 3 programs for which they are the acquisition decision authority .

the memorandum additionally clarifies that for the purposes of acquisition oversight , program managers report to their cae and the caes report to the usm .

this clarification is useful , as caes we spoke with prior to the issuance of the memorandum noted differences in the roles and responsibilities of the caes across components .

for example , at u.s. immigration and customs enforcement , it was the component ocio , rather than the cae , who was responsible for the execution of acquisitions , and program managers reported directly to the component ocio .

at the u.s. coast guard , the cae is currently the vice commandant , who oversees all of the component's operations and mission support functions , including human resources , budget , and acquisitions .

within mission support is the assistant commandant for acquisitions , who has more direct oversight of the u.s. coast guard's acquisition programs .

given the new requirements for cae experience levels , parm's executive director anticipates that there may be changes in cae assignments for at least one component .

the memo directs parm to create and provide executive - level acquisition training to the caes .

the memorandum further outlines the caes' responsibilities for complementing parm's oversight activities , such as responding in a timely manner to requests for information .

as of march 2014 , parm began working with caes to hold monthly forums to discuss topics such as the maol , staffing plans , and the casr .

parm established monthly high visibility meetings to discuss programs that require immediate or additional management attention .

in addition , to identify programs for which parm has oversight responsibility , parm maintains a list of dhs's acquisition programs on the maol , which is broken down into categories that describe each program's reporting characteristics .

however , dhs has not established a structure for overseeing the costs of 42 programs in sustainment whose acquisition documentation requirements were waived by the usm in 2013 .

sustainment costs can account for more than 80 percent of total costs , and all but one of these programs lack an approved cost estimate .

parm's executive director established high visibility meetings in december 2013 to discuss any acquisition programs that require more immediate attention from dhs management .

parm's executive director uses these meetings as a management tool .

he identifies the programs to be discussed in consultation with component leads .

parm's executive director told us that the purpose of these meetings is to make sure that senior leadership — including the usm , chief financial officer , chief information officer , chief readiness support officer , chief procurement officer , and general counsel — have a common understanding of the acquisition programs' status and key issues .

according to parm officials , the high visibility meetings have provided better focus through greater senior level involvement and led to a reinvigoration of preparation for acquisition review boards .

as of november 2014 , 33 programs have been discussed in the high visibility meetings .

parm officials put programs on the meeting agenda based on a variety of considerations: programs with an upcoming acquisition review board meeting , programs with concerns or issues , and programs that parm is monitoring closely .

officials told us that the last two categories may include programs under gao or inspector general review , programs involved in a bid protest , and programs that have experienced schedule slips or a cost increase .

for example , parm officials told us about a program that changed its acquisition strategy to incorporate information technology , but did not involve the chief information officer .

parm included this program in a high visibility meeting to ensure that officials were informed of the change in strategy and were involved as appropriate .

in another case , parm officials told us that they used high visibility meetings to raise early awareness about concerns with a program , which resulted in multiple follow - on meetings among high level headquarters and component officials .

the usm directed the component to pause the program and issued an acquisition decision memorandum that described the path forward .

dhs acquisition policy provides the overall structure for acquisition management that programs are required to follow .

the policy requires parm to create a list of major acquisition programs , the maol , a document approved by the usm .

parm uses the maol to identify programs for which it has oversight responsibility and to determine which programs they include in the casr , an annual report to congress .

in 2014 , parm updated and expanded the maol by listing programs in six categories that detail the characteristics of programs .

five categories specifically address acquisition programs ( see table 2 ) .

in addition , there is one category for a non - acquisition activity that is required to submit an office of management and budget business case .

parm officials stated that they updated the list to more clearly incorporate input of all headquarters organizations , thereby making it a more useful oversight tool .

the list has evolved over time as more headquarters organizations have added programs to the maol .

parm officials have drafted updates to dhs acquisition policy that include a section on requirements for the maol .

specifically , the planned updates will include which headquarters organizations will be involved in the development of the list , and establish a process for removing programs .

parm officials also told us they recently began a process for updating the list more regularly .

the updates also provide additional information about the development and use of the maol .

the draft updates describe the process for determining whether or not a program belongs on the maol , which follows a decision tree .

parm officials said that the new process for developing the maol more effectively coordinates and tracks the input from other dhs headquarters organizations , like ebmo and the office of the chief financial officer , as well as caes .

the draft updates also describe justifications for removal from the maol .

for example , a program might be removed if it is merged with another program , or if it is no longer considered special interest — meaning that a program was elevated to a higher acquisition level without regard to dollar threshold .

officials were unsure when the draft updates would be approved by dhs management .

in addition to the draft policy updates , parm officials told us that they recently instituted a governing board of officials who will determine changes to the maol on a quarterly basis , given its potential to provide important information to department decision makers .

parm officials told us that the next maol , expected in february 2015 , will use the new process described in draft guidance .

dhs does not have a structure in place for overseeing the costs of 42 programs whose acquisition documentation requirements were waived this waiver through a memorandum issued by the usm in may 2013.covered certain programs in sustainment , meaning that these acquisition programs have been developed and delivered and they are being operated and maintained through the disposal phase .

because these programs were in sustainment when md 102 was instituted in 2008 , the usm determined that it would be cost prohibitive and inefficient to recreate documentation for previous phases .

however , we found that only one of the 42 waived programs has an approved life - cycle cost estimate , which would include acquisition costs as well as the costs to operate and maintain the system once it is in sustainment .

parm officials could not provide us estimates of the value of the sustainment programs .

parm's executive director stated that these programs should produce operations and maintenance cost estimates .

these estimates would account for the remainder of their life cycles through disposal , but the programs are not currently required to do so , given the 2013 waiver .

further , in the 2014 maol , parm included seven additional programs in sustainment and also noted that documentation was waived for these programs .

the 42 programs in sustainment from the usm's memorandum and the seven programs listed on the maol are listed in appendix ii .

the office of management and budget stated in 2014 that the sustainment phase can account for more than 80 percent of program life - cycle costs , which demonstrates the need for oversight of these programs' costs .

we have previously reported that cost estimates are necessary to support decisions about program funding , develop annual budget requests , and evaluate resource requirements .

furthermore , the management of a cost estimate involves continually updating the estimate with actual data as they become available , revising the estimate to reflect changes , and analyzing differences between the estimated and actual costs .

without knowing the operations and maintenance cost estimates for these programs , dhs will not be able to fully plan for and manage funding requirements across its major acquisition programs .

the 2013 waiver did not define which dhs office is responsible for oversight of the sustainment programs .

caes are responsible for level 3 programs and parm officials stated that this also applies to programs in sustainment .

a parm official further told us it is difficult to know who is responsible for oversight of level 1 and level 2 programs in sustainment .

parm officials expressed concerns about the lack of oversight of these programs .

specifically , officials noted dhs may decide , on a case - by - case basis , which organization should most appropriately provide oversight to programs in sustainment , which may include more than one office .

parm's fiscal year 2014 casr , a report mandated by congress , provided the status of 82 dhs major acquisition programs but contained data that were inaccurate and out - of - date .

parm primarily drew information for the casr from nprs , dhs's official system of record for acquisition program reporting .

however , data issues — including inconsistent participation among the programs responsible for entering data — have led to inaccurate information in nprs .

for example , our analysis found discrepancies between the casr and nprs for life - cycle cost estimate data even after efforts to update or fix the data inaccuracies through an extensive adjudication process .

therefore , it was unclear whether congressional casr recipients received accurate program information .

parm officials have acknowledged ongoing issues with the data reported in both nprs and the casr , and noted that they are working to improve the data quality .

officials stated that information in the casr did not provide a complete picture of program life - cycle costs , which was the result of both incorrect data that programs had reported and limitations in using the nprs system .

further , component and program officials have also stated that the casr did not accurately reflect program risks .

finally , dhs provided insufficient information to address certain casr reporting requirements .

for example , the casr did not include annual planned procurement schedules containing estimates of the units and / or increments for each program , although it was required to do so .

for the nine programs in our review , we found that program offices did not consistently enter and verify their data in nprs .

dhs established nprs as the system of record for acquisition program reporting in 2008 , and in 2012 the usm issued a memorandum to caes stating that programs should make every effort to ensure that their data in nprs is complete , accurate , and valid on a monthly basis .

according to the memorandum , nprs was intended to be a key tool for acquisition program management , and help provide the capability to efficiently assess the department's acquisition portfolio .

dhs components have the responsibility to ensure that their respective programs enter the data in nprs as required , and caes are required to ensure that the data is validated and submitted in timely manner .

however , we found that this was not done consistently for the nine major acquisition programs in our review , which are overseen by nine different dhs components .

we examined nprs data for the nine programs at two key points: september 2013 , the closing date for data for fiscal year 2013 , and march 2014 , the date when parm issued its fiscal year 2014 casr , which was based on fiscal year 2013 program data .

we found a number of problems with the data .

for example , as of september 2013 , three programs we reviewed did not enter expenditure data , the amount the programs actually spent , in nprs for fiscal year 2013 as required , and two of these programs did not enter historical expenditure data at all .

when we compared programs' entries of expenditure data over time , we found additional discrepancies .

as an example , the u.s. coast guard's fast response cutter program's expenditure entries in nprs increased by more than $340 million from september 2013 to march 2014 , even though both of these entries were supposed to reflect fiscal year 2013 expenditures .

a u.s. coast guard official stated that this increase was due to a correction in the program's reported expenditures , to account for all funds spent in fiscal year 2013 regardless of when those funds were received .

the official noted that the program's entry from september 2013 reflected only funds received in fiscal year 2013 .

however , the reason for this change was not documented in nprs .

in another example , the u.s .

citizenship and immigration service's verification modernization program's entries for total historical expenditures through fiscal year 2012 decreased by almost $240 million when comparing these data from september 2013 and march 2014 .

figure 3 shows the differences in reported expenditure data in nprs for the fast response cutter and verification modernization programs .

large nprs discrepancies such as these call into question the reliability of the underlying data and whether dhs management has the information it needs to provide oversight of major acquisition programs .

parm officials have acknowledged ongoing issues with the data reported in nprs and noted that they are working to improve its quality .

for example , parm provides a working group to the components to express their views on the nprs system and its processes .

however , parm officials stated they do not have a mechanism to hold the programs accountable for updating their data .

component and program officials told us that they do not use nprs for program management — even though that was one intended purpose of the system — because the system is difficult to use and does not meet their needs .

for example , the ocio national capital region infrastructure operations program manager stated that his program does not work with nprs .

for both september 2013 and march 2014 , nprs data fields for this program that were to be used to populate the fiscal year 2014 casr , such as the program description and last acquisition review board date , were blank .

component and program officials also stated that they use other internal tools , such as spreadsheets , presentations , or project software for program management purposes and to maintain current information .

parm has not undertaken an effort to ascertain the root causes of why program managers are not populating nprs as required .

as we have previously reported , to be useful , performance information must meet users' needs for completeness , accuracy , consistency , timeliness , validity , and ease of use .

unless dhs program managers consider nprs to be a useful tool for their own program management purposes , as intended , the problems we found with inaccurate data are likely to persist .

to further understand the reasons for program data inaccuracies in the fiscal year 2014 casr , we analyzed the steps that parm undertakes as part of an extensive adjudication process with the components regarding the underlying nprs data .

we found that parm's adjudication process did not rectify key inaccuracies in the fiscal year 2014 casr , specifically regarding programs' life - cycle cost estimates .

as a result , congress may not have received accurate program information .

prior to its release , parm conducts an extenstive adjudication process for the casr information , including reviews with program and various dhs headquarters offices , in order to identify and address potential data inconsistencies between the sources and draft report .

this process began in october after the close of the fiscal year and ended when the report was published in march .

we reviewed nprs data from march 2014 , the date when parm issued its fiscal year 2014 casr ( which is comprised of fiscal year 2013 program data ) to compare these data to what was presented to congress in the casr .

figure 4 shows select elements of the casr development and adjudication process , along with our assessment of those elements .

the fiscal year 2014 casr reported on a total of 82 major acquisition programs .

for four of the nine major acquisition programs in our review , we found discrepancies between the casr and nprs for life - cycle cost estimate data after the adjudication process , which should have reconciled such inconsistencies .

as an example of these discrepancies , both across nprs and between nprs and the casr , life - cycle cost estimates for two programs differed even though the estimates were associated with the same source and date .

another program , the electronic health record system , had three different life - cycle values ranging from approximately $60 million to $80 million , a difference of over 35 percent , with two of those values presented in the casr .

our analysis of the data inconsistencies indicated that it was unclear whether congressional casr recipients received accurate program cost information because there was no way to confirm which estimate was correct or what the different estimates represented .

parm officials stated that they are changing their process for the development of the next casr , which they expect to issue with the president's fiscal year 2016 budget submission , in an effort to more effectively match their reported data to nprs .

table 3 highlights discrepancies between the casr and nprs for life - cycle cost estimate data for the four programs that we reviewed .

further , parm may have incorrectly included or excluded certain programs in the casr based on dhs's incomplete information on program life - cycle costs .

as we reported in 2014 , unreliable cost estimates have been an enduring challenge for dhs .

parm included level 1 and 2 programs from the maol in the casr , as required , using program life - cycle costs to determine program status .

however , parm officials acknowledged that some programs' acquisition category levels were incorrect in the casr , and due to the lack of dhs approved life - cycle cost estimates , they would not know the scope of this issue .

for example , the casr included program life - cycle cost estimate figures , but did not indicate who approved these estimates ( i.e. , if they were approved at the component or department level ) , or if anyone approved the estimates at all .

because these cost figures may not accurately reflect the actual life - cycle costs , programs may have been inappropriately included or excluded from the casr and ultimately not receive the appropriate level of congressional oversight .

we also found areas where additional explanation in the casr would have been helpful .

for example , parm listed the electronic health record system program in the casr as a level 2 program , while its reported life - cycle cost estimate of approximately $70 million would designate it a level 3 program .

parm is not required to include level 3 programs in the casr .

electronic health record system officials explained that the program was listed as level 2 because dhs management designated it as a “special interest” program in the maol , which did make it eligible for inclusion in the casr , but parm did not include this rationale in the casr .

in addition , program officials stated that the inflexibility of nprs may prevent the department from providing accurate program information in the casr .

for example , officials from the national protection and programs directorate's next generation network - priority service noted difficulties in accurately reporting data on their program's increments in nprs .

the officials stated that the program has multiple increments , each with its own set of acquisition decision events .

however , the program reported one overall life - cycle cost estimate in nprs , even though it has estimates for each increment , because the system does not allow for the inclusion of multiple estimates .

officials ultimately provided explanatory comments in nprs that noted the increment 1 estimate included only acquisition costs while not specifying who approved the estimate , and that parm approved the increment 2 estimate in july 2013 .

because these incremental estimates were at different stages in their development , combining them into a single estimate in nprs , which parm ultimately reported in the casr , did not provide congress with an accurate picture of the program's costs .

of the 13 casr reporting requirements , dhs provided insufficient information for in - depth oversight for four of them , and in one case , dhs did not comply with a reporting requirement .

the first reporting requirement was a rating of cost risk , schedule risk , and technical risk associated with the program .

parm fulfilled this requirement by reporting programs' top - five cost , schedule , and technical risks , instead of separate ratings for each .

however , this reporting was inconsistent .

programs submitted these risks through dhs's investment management system , but this system can contain more than five risks .

as a result , program officials stated that they did not know how parm selected their top - five risks for inclusion in the casr .

for example , the strategic air and marine program listed nine risks in the system , but parm only reported two risks in the casr .

further , the risk reporting in this section varied across the programs in our review .

for example: the verification modernization program had five risks , all of which were technical .

the technology infrastructure modernization program used four of its own risk categories , which do not track to the required cost , schedule , and technical risks: reliability of systems ; dependencies and interoperability between this investment and others ; security ; and business .

the inconsistent risk reporting in this section prevents congress from making cost , schedule , and performance comparisons across dhs programs .

in addition , as part of a separate requirement for independent verification and validation , parm evaluated the overall risk of each program , assigned each a numerical risk score , and published these scores in the casr .

parm officials computed these risk scores using a set of weighted criteria .

however , component and program officials told us that they did not know how parm evaluated the risk scores for their respective programs .

parm , component , and program officials have acknowledged that the casr did not accurately reflect the cost , schedule , and performance risks associated with the programs .

parm officials were unable to provide us with the supporting data used to generate the scores because they did not store this information in nprs .

as a result , we were unable assess how parm computed these scores or determine the extent to which parm's evaluation accurately reflected program risks .

due to parm's inability to provide us with supporting data , we reviewed the science and technology directorate's national bio and agro - defense facility program's risk assessment in the casr and found it lacked details that could be useful to congress and dhs management .

parm gave the program a high risk score , in part , due to the lack of dhs approval for the program's acquisition documents .

a program official stated , however , that the documents could not go forward for dhs approval due to the program's lack of funding .

the casr did not contain any clarifying explanation for the documents not being approved .

further complicating the issue , the program's nprs data in september 2013 conflicts with its casr entry , and showed program documents approved by dhs as early as 2009 .

discrepancies such as this call into question the value of the information dhs is providing to congress in the casr .

to gain more visibility into the reasons for these inconsistencies , we reviewed the source documents for the national bio and agro - defense facility program , provided to us by parm , and found that the approval dates for five out of six documents do not match what was listed in either nprs or the casr .

table 4 compares the national bio and agro - defense facility program's reported document status according to nprs as of september 2013 and the casr issued in march 2014 , and the source documents provided by parm .

in another example , in parm's risk assessment of the federal emergency management agency's risk mapping , assessment and planning program , the casr stated that the program was covered by the usm's waiver of acquisition documents requirements and thus did not include certain program data .

however , an examination of nprs showed that , according to the system , the program had key documents , including a mission needs statement and an acquisition program baseline approved by dhs , which parm did not list in the casr and which could have provided further information to decision makers .

a second casr reporting requirement was a program's planned procurement schedule , including an estimate of the quantity to be procured annually until completion .

parm did not comply with this requirement .

instead , parm provided the top - five contracts by dollar value for each program , but these entries did not include procurement quantity information for the programs .

some programs did report total procurement quantities , but did not link these units to a schedule .

parm officials noted that certain programs are not well - suited for reporting procurement quantities , such as it programs .

however , in such cases , the casr should explain why no procurement quantities were listed .

a third requirement was the reason for any significant changes in a program's acquisition cost , quantity , or schedule from the prior annual casr .

parm officials interpreted these changes to only be those that resulted in the submission of a new acquisition program baseline .

according to dhs acquisition policy , programs need to submit new baselines when they breach defined cost , schedule , and performance parameters defined in their original baseline .

however , programs can experience cost , quantity , or schedule changes that do not require a new baseline .

for example , the national bio and agro - defense facility program experienced a delay in its construction schedule .

while this program's baseline remains in place , the construction delay could impact on - time delivery of the facility and is an example of a significant change that could be reported in this section .

in addition , the casr included 38 programs without an approved acquisition program baseline ; according to parm's guidance , the casr would not include any cost , schedule , or performance changes for these programs .

by defining programs' significant changes as those that resulted in new baselines , parm eliminated the need to report on any cost , schedule , or performance changes for almost half of the programs in the casr , thereby limiting the information available to congress .

finally , we found that parm did not include certain key program events in the casr , such as acquisition decision events or full operating capability schedules .

such data , in addition to the acquisition program baseline approval dates that parm currently reports , would have provided congress with more robust information about the program status .

table 5 lists these four casr requirements and our assessment of the information reported .

effective , on - going oversight of dhs's broad portfolio of programs is essential to ensure that programs are accountable for their performance and that congress and dhs decision makers receive useful , accurate , and up - to - date information .

dhs has improved aspects of its acquisition management in recent years , including dedicating additional resources to acquisition oversight and clarifying the roles of caes .

dhs could further enhance its oversight efforts by providing written roles and responsibilities to oversight officials within parm and among headquarters organizations .

furthermore , a consistent , defined approach to oversight could limit overlap of responsibilities and give dhs more insight into whether its acquisition programs are executing according to cost , schedule , and performance goals .

likewise , as dhs acquisition programs move into the sustainment phase , their costs continue to require monitoring .

the usm's waiving of documentation requirements for the 42 programs in sustainment in 2013 resulted in a lack of oversight of costs for these programs .

as of yet , no dhs office has been designated to take over monitoring those programs' operations and maintenance costs .

without an identified oversight body , dhs lacks insight into those programs' performance and the execution of their funding , which could potentially be billions of dollars .

this is particularly of concern given that only one program had an approved cost estimate at the time of the waiver .

finally , dhs has not effectively communicated program status to congress through the casr because it has provided out - of - date and inaccurate information .

programs do not consistently report their own data in nprs , and components are not validating the information .

although parm's adjudication process may address some data issues , data are not corrected in the source systems before being published in the casr .

further , while parm has some flexibility in the implementation of the casr reporting requirements , in one case the requirement was not met .

in other cases , such as parm's assessment of program risks , there are opportunities for more transparency and clarity in the information being transmitted to congress .

holding programs accountable for maintaining their cost , schedule , and performance data , and presenting contextual information would help make the casr a more effective instrument for dhs and congressional oversight .

in order to help ensure consistent , effective oversight of dhs's acquisition programs , we recommend the secretary of dhs take the following five actions: direct parm to develop written guidance that defines roles and responsibilities of its component leads .

direct the usm to: develop written guidance to clarify roles and responsibilities of parm and ocio - ebmo for conducting oversight of major acquisition programs .

produce operations and maintenance cost estimates for programs in sustainment and establish responsibility for tracking sustainment programs' adherence to those estimates .

determine mechanisms to hold programs accountable for entering data in nprs consistently and accurately and to hold caes accountable for validating the information .

also , evaluate the root causes of why programs are not using nprs as intended .

to make the casr more useful , starting with the report reflecting fiscal year 2015 program data , adjust the casr to do the following: report an individual rating for each program's cost , schedule , report a best estimate of procurement quantities or indicate why this is not applicable , as appropriate ; report all programs' significant changes in acquisition cost , quantity , or schedule from the previous casr report by determining a means to account for programs that lack acquisition program baselines ; report major program events that are included in acquisition program baselines , such as scheduled acquisition decision events ; and report the level at which the program's life - cycle cost estimate was approved .

we provided a draft of this product to dhs for comment .

in its written comments , reproduced in appendix iii , dhs concurred with all five of our recommendations and provided plans of action and estimated completion dates for four of them .

regarding the remaining recommendation , that the secretary of dhs direct parm to develop written guidance that defines roles and responsibilities for component leads , dhs provided evidence that is has complied with the recommendation , and we agree .

specifically , dhs provided a component lead handbook , signed on february 13 , 2015 , while our report was out for comment , that provides oversight roles and responsibilities and other guidance to parm component leads in their job to oversee component programs .

dhs also provided technical comments that we incorporated into the report as appropriate .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the secretary of dhs .

in addition , the report will be available at no charge on gao's website at http: / / www.gao.gov .

if you or your staff have questions about this report , please contact me at ( 202 ) 512-4841 or mackinm@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iv .

the objective of this review was to assess the department of homeland security's ( dhs ) oversight of its major acquisition programs .

specifically , this review focused on dhs's office of program accountability and risk management ( parm ) and its day - to - day program oversight , rather than the oversight it conducts at key points in the acquisition life cycle as defined in policy .

we assessed ( 1 ) steps dhs has taken to improve oversight and what gaps , if any , exist and ( 2 ) whether the data parm provides to dhs and congressional decision makers to carry out their oversight responsibilities on program cost , schedule , and performance are accurate and up - to - date .

to answer these questions , we identified organizations within dhs , in addition to parm , that are responsible for oversight of major acquisitions and determined their roles and responsibilities by analyzing dhs policies and procedures , reviewing organizational charts , and interviewing policy , budget , and acquisition oversight officials at the headquarters level .

specifically , we reviewed dhs acquisition management directive 102-01 ( md 102 ) and its associated guidebook — dhs instruction manual 102-01- 001 — and the guidebook's 12 appendices .

we reviewed draft updates to dhs acquisition policy , as well as draft updates to departmental instructions , such as agile development and delivery for information technology and the systems engineering life cycle guidebook .

we also reviewed dhs acquisition memorandums , including the secretary's april 2014 unity of effort memorandum ; the office of the chief procurement officer's strategic plan ; information technology ( it ) policies and guidance , such as dhs directive 102-04 on it portfolio management and the office of the chief information officer ( ocio ) portfolio governance concept of operations .

at the department level , we interviewed officials from parm , ocio – enterprise business management office ( ebmo ) , office of the chief procurement officer , office of policy , and office of the chief financial officer – office of program analysis and evaluation and cost analysis division .

in addition , we reviewed relevant gao and dhs inspector general reports to provide context for all of our objectives .

to address our first objective , we selected nine dhs components with responsibility for at least one level 1 acquisition — a program with a reported life - cycle cost estimate exceeding $1 billion — and interviewed their component acquisition executives ( cae ) or designees .

we reviewed component - specific policies and procedures and charters for program governance groups , as well as other relevant documentation .

the 2014 master acquisition oversight list ( maol ) identifies level 1 acquisition programs for the following nine components: federal emergency management agency national protection and programs directorate ocio science and technology directorate transportation security administration u.s .

citizenship and immigration services u.s. coast guard u. s. customs and border protection u.s. immigration and customs enforcement to collect examples of parm's oversight and coordination activities at the program level , we selected a non - generalizable sample of major acquisition programs from each of the nine components .

table 6 lists the nine programs we selected as case studies .

we selected programs that were included in the fiscal year 2014 comprehensive acquisition status report ( casr ) , which parm submitted to the house and senate appropriations committees to provide information on dhs major acquisition programs .

to the extent possible , we chose programs that have been identified as having “concerns / issues” or as being “monitored closely” in parm's high visibility meetings , which include dhs senior leadership .

in order to assess acquisition oversight across the spectrum of dhs programs , we selected case study programs with a variety of characteristics .

we chose a mix of level 1 and level 2 programs , as defined in the fiscal year 2014 casr , and included both it and non - it programs .

one of our nine case study programs , the electronic health record system , was classified as a level 2 program in the fiscal year 2014 casr , but listed as a level 3 program on the 2014 maol .

we chose this program in order to examine the reasons for the change and to determine the extent to which oversight varies for major and non - major acquisition programs .

another factor used to select the case studies was program risk , as measured by casr risk scores .

risk scores are included in the casr's independent verification and validation section and are derived from parm's rating of program risk using a standard set of criteria .

we chose programs to include a mix of both high and low casr risk scores .

for these case studies , we reviewed relevant program documentation , such as acquisition decision memorandums , and interviewed program officials .

for the second objective , we collected and reviewed data from dhs's official system of record for its acquisition programs , the next generation periodic reporting system ( nprs ) , and compared that data to the fiscal year 2014 casr .

all major programs on dhs's maol are required to report in nprs .

parm then uses the program data in nprs to help generate its casr .

in order to assess the data reliability of nprs , we reviewed select acquisition program data from nprs and compared this data to the information contained in the casr .

specifically , we used nprs reports for each of the nine case study programs from the end of fiscal year 2013 , when parm pulled the program data from the system to begin generating the fiscal year 2014 casr .

we then compared the data from those reports to the issued casr , as well as to the nprs program reports from march 2014 — the date that parm released the casr .

the comparison of those three sets of information allowed us to note discrepancies , including missing data or outliers , between the system data and the issued data , as well as if corrections were made to the system data following the release of the report .

we assessed various data elements from the nprs program reports that are used to generate the information contained in the casr .

we reviewed data across a range of tabs contained in the nprs program reports such as general information , acquisition review board history , program status , budget and funding , acquisition program baseline milestones , risk , and key documents .

for each of the nine case study programs , we assessed reports from the end of fiscal year 2013 , as well as march 2014 , for a total of eighteen program reports .

in addition , we reviewed documents , such as the nprs user manual and policies related to data entry , and interviewed agency officials responsible for inputting and reviewing the nprs data .

we determined that the nprs data were not sufficiently reliable for our purposes ; however , we present the data for illustrative purposes only .

for example , for certain programs in our review , current and historical expenditure data was missing .

another example from our analysis showed differences in the life - cycle cost estimates for certain programs in nprs compared to those reported in the casr .

while the under secretary for management ( usm ) issued a memorandum that programs are to update their nprs data monthly , parm officials recognized that this does not happen consistently , and they acknowledged that there are data accuracy issues with nprs .

in addition , when officials made updates or changes to program - reported information due to the pending release of the casr , the programs were responsible for entering these updates or changes into nprs .

our analysis confirmed that certain programs in our review did not update nprs after going through the casr reporting process .

in order to evaluate the effectiveness of nprs and the casr as tools for dhs management and congressional oversight , we first reviewed the department of homeland security appropriations act , 2014 , which established the provision for the usm to submit the casr with the president's budget proposal for fiscal year 2015 .

in addition , we reviewed conference report 112-331 for the consolidated appropriations act , 2012 , which contained the information requirements for inclusion in the casr .

we then compared the data from nprs for the nine case study programs to that presented in the fiscal year 2014 casr to determine discrepancies between the two for certain data elements .

we further compared the casr information to parm policies and procedures , such as the maol and md 102 .

in order to review the casr's independent verification and validation requirement , we asked parm officials for supporting documentation for how they generated their independent verification and validation evaluations , but they were unable to provide the documentation because they did not store it in nprs .

finally , we assessed the information the casr either did or did not provide compared to its congressional reporting requirements .

we conducted this assessment based on the casr's congressional reporting requirements , dhs policies , and acquisition practices .

we conducted this performance audit from march 2014 to march 2015 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

table 7 below identifies 42 acquisition programs for which the department of homeland security's ( dhs ) under secretary for management waived documentation requirements in a may 2013 memorandum .

these programs were already in sustainment prior to 2008 , meaning that they were in the last phase of their acquisition life cycle , when dhs issued md 102 .

programs in sustainment have been developed and delivered to their respective components for operation and maintenance through disposal .

the memorandum stated that it would be cost prohibitive and inefficient for these programs to recreate the documentation called for under the directive for their previous acquisition life - cycle phases .

table 8 below identifies seven additional major acquisition programs in sustainment for which dhs waived documentation requirements on the 2014 master acquisition oversight list .

the master acquisition oversight list stated that having programs provide documents for their previous acquisition life - cycle phases would be costly and provide no positive performance impact for systems already delivered .

in addition to the contact named above , katherine trimble , assistant director ; leigh ann haydon , analyst - in - charge ; stephen v. marchesani ; alexis olson ; sarah marie martin ; and daniel hilger made key contributions to this report .

peter w. anderson , jean l. mcsween , ozzy trevino , and alyssa weir also provided assistance .

