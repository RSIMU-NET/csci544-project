in fall 2003 , the federal head start program initiated a nationwide skills test of over 400,000 4- and 5-year - old children .

this test , called the head start national reporting system ( nrs ) , is intended to meet a long - standing need for systematic information on how well specific head start grantees are helping children learn .

head start is designed to promote school readiness and healthy development among poor preschool children and provides services to nearly 1 million children , generally between the ages of 3 and 5 , through nearly 1700 grantees .

these grantees or their delegates provide services at about 19,000 head start centers nationally , with each grantee having from 1 to over 100 centers .

for nearly a decade the head start bureau ( hsb ) and the u.s. department of health and human services ( hhs ) have been engaged in promoting accountability and moving toward a results - oriented evaluation of head start .

the nrs builds on this work .

the nrs was developed in response to president bush's april 2002 announcement of the “good start , grow smart” early childhood initiative that directed hhs to develop a national accountability system to ensure that every head start grantee will assess the progress made by children in early literacy , language , and numeracy skills .

head start teachers , or others trained as nrs assessors , administer the nrs to children individually in the fall and spring of the head start year .

the nrs begins with a game of “simon says,” lasts about 15 minutes , and includes four sub - tests designed to screen for understanding of spoken english and to assess skills in recognizing letters , vocabulary , and early math .

during the test , an assessor sits across from a child at a table and asks scripted questions of the child , and the child responds by verbally identifying or pointing to pictures , numbers , or letters that are contained in a 3-ring binder .

the assessor marks the child's responses on a computer - readable scoring sheet .

while all of the children are given at least the portion of the english - language assessment that screens for understanding of spoken english , children whose primary language is spanish are also assessed using a spanish version of the nrs .

children who speak both english and spanish are given both versions of the nrs and scores from both tests are reported separately .

although other evaluations of children's skills and head start performance exist , the nrs differs from them in its scale , type , and purpose .

the nrs is a standardized test intended for all prekindergarten head start children .

it represents the first time that hsb will use children's performance on a standardized test to measure how well specific head start grantees are helping children progress .

many in the head start community and beyond agree that it is a laudable goal to look at head start at the national and grantee levels to determine whether head start achieves its stated objectives .

however , there have been significant concerns about whether the nrs , as currently composed , is the right way to accomplish this goal .

given the importance hsb places on measuring head start performance and the concerns about the nrs , we examined ( 1 ) what information the nrs is designed to provide , ( 2 ) how hsb has responded to implementation issues raised by the head start grantees and experts during the first year of nrs implementation , and what issues remain to be addressed , and ( 3 ) whether the nrs provides hsb with the quality of information it needs to meet its purposes .

to answer these questions , we collected and analyzed information from multiple sources .

to determine what information the nrs is designed to provide , we interviewed representatives from hsb , its contractors , and early childhood professional organizations and we reviewed documents chronicling the steps hsb took in developing the nrs .

to examine how hsb responded to implementation issues raised by head start grantees and experts during the first year of nrs implementation and what issues remain to be addressed , we interviewed representatives from hsb and randomly sampled head start grantees and delegates from the population of all head start grantees and delegates during the 2003-2004 school year .

we received responses from 80 percent of the grantees and delegates we surveyed .

we also visited 12 head start grantees in 5 states ( colorado , maryland , massachusetts , rhode island , and virginia ) , to interview staff who conducted the assessments and to observe them administering the nrs to children .

the states and grantees chosen for site visits were judgmentally selected to include a range of enrollment sizes , types of program , rural and urban locations , and linguistic populations .

finally , to examine whether the nrs provides hsb with the quality of information it needs to meet its goals , we reviewed the professionally accepted standards for test development , interviewed all of the members of the technical work group — a team of experts convened to assist hsb and its contractors in the design and implementation of the nrs — and consulted with individuals recommended by the national academy of sciences as experts in the areas of test design and the educational testing of spanish - speaking and bilingual children .

these independent experts reviewed documents provided by hsb and its contractors pertaining to the adequacy and appropriateness of the assessment .

see appendix i for additional information on our scope and methodology .

we conducted our work between may 2004 and february 2005 in accordance with generally accepted government auditing standards .

established in 1965 , head start is a federally funded early childhood development program that served over 900,000 children at a cost of $6.8 billion in 2004 .

head start offers low - income children a broad range of services , including educational , medical , dental , mental health , nutritional , and social services .

children enrolled in head start are generally between the ages of 3 and 5 and come from varying ethnic and racial backgrounds .

head start is administered by hsb within acf .

hsb awards head start grants directly to local grantees .

grantees may develop or adopt their own curricula and practices within federal guidelines .

grantees may contract with other organizations — called delegate agencies — to run all or part of their local head start programs .

each grantee or delegate agency may have one or more centers , each containing one or more classrooms .

in this report , the term “grantee” is used to refer to both grantees and delegate agencies .

figure 1 provides information on the numbers of head start grantees , delegate agencies , centers and classrooms .

since the inception of head start , questions have been raised about the effectiveness of the program .

in 1998 , we reported that head start lacked objective information on performance of individual grantees and congress enacted legislation requiring hsb to establish specific educational standards applicable to all head start programs and allowed development of local assessments to measure whether the standards are met .

hsb implemented this legislation by developing the child outcomes framework to guide head start grantees in their ongoing assessment of the progress of children .

the framework covers a broad range of child skill and development areas and incorporates each of the legislatively mandated goals , such as that children “use and understand an increasingly complex and varied vocabulary” and “identify at least 10 letters of the alphabet.” since 2000 , hsb has required every head start grantee to include each of the areas in the framework in the child assessments that each grantee adopts and implements .

the eight broad areas included in the framework are language development , literacy , mathematics , science , creative arts , social and emotional development , approaches to learning , and physical health and development .

grantees are permitted to determine how to assess children's progress in these areas .

these assessments are to align with the grantee's curriculum ; as a result the specific assessments vary across the grantees .

the assessments occur 3 times each year and generally involve observing the children during normal classroom activities .

the results of the assessments are used for the purposes of individual program improvement and instructional support and are not aggregated across grantees or systematically shared with federal officials .

the nrs , prompted by the april 2002 announcement of president bush's good start , grow smart initiative , builds on the 1998 legislation by requiring all head start programs to implement the same assessment , twice a year , to all 4- and 5-year - old head start participants who will attend kindergarten the following year .

when president bush announced this initiative in april 2002 , it called for full implementation in fall 2003 ; as a result the nrs was developed and preparations for implementation occurred within an 18-month period .

see figure 2 .

shortly after the president announced this initiative , hsb hired a contractor to assist it in developing and implementing the nrs .

the contractor , working closely with hsb , was responsible for the design and field testing of the nrs , including developing training materials to support national implementation of the reporting system by grantees .

hsb also worked with the technical work group and others throughout implementation of the nrs .

the technical work group includes 16 experts in such areas as child development , educational testing , and bilingual education .

they advised hsb on the selection of assessments , the appropriateness of the assessments in addressing the mandated indicators , the technical merit of the assessments , and the overall design of the nrs .

while the technical work group members offered advice , the group members were not always in agreement with each other and hsb was not obligated to act on any of the advice it received .

a list of the technical work group members and their professional affiliations is included in appendix i .

through focus groups , teleconferences , and various correspondences , hsb officials communicated to head start grantees the purpose of the nrs and their plans for administering the assessment .

focus groups and discussions were held with various interested parties , including head start managers and directors and experts from universities and the public sector , on issues ranging from strengths and limitations of various assessment tools to strategies for assessing non - english speaking children .

hsb also received input through a 60-day public comment period , from mid - april to june 2003 .

another contractor developed a computer - based reporting system ( cbrs ) for the nrs .

local head start staff use the cbrs to enter descriptive information about their grantees , centers , classrooms , teachers , and children , as shown in table 1 , as well as to keep track of which children have been assessed .

hsb analyzes the descriptive information from the cbrs in conjunction with the child assessment data to develop reports on the progress of specific subgroups of children .

for example , hsb can report separately on the average scores of children enrolled in part - day programs and those enrolled in full - day programs .

hsb , with assistance from the contractors , worked to ensure local staff received adequate training on administering the assessment and using the cbrs , and provided guidance on how to obtain consent from parents .

training and certification of all assessors was required so that all assessors would administer the nrs in the same way .

two - and - a - half day training sessions were held at eight sites throughout the u.s. and puerto rico during july and august 2003 .

roughly 2,800 individuals completed the training , of which 484 were certified in both english and spanish .

in turn , these certified trainers held training sessions locally to train and certify additional staff who would be able to administer assessments .

the development of educational tests is a science in itself , to which university departments , professional organizations , and private companies are devoted .

among the most important concepts in test development are validity and reliability .

validity refers to whether the test results mean what they are expected to mean and whether evidence supports the intended interpretations of test scores for a particular purpose .

reliability refers to whether or not a test yields consistent results .

validity and reliability are not properties of tests ; rather , they are characteristics of the results obtained using the tests .

for example , even if a test designed for 4th graders were shown to produce meaningful measures of their understanding of geometry , this wouldn't necessarily mean that it would do so when administered to 2nd or 6th graders or with a change in directions allowing use of a compass and ruler .

test developers typically implement “pilot” tests that represent the actual testing population and conditions and they use data from the pilot to evaluate the reliability and validity of a test .

this process generally takes more than 1 year , especially if the test is designed to measure changes in performance .

in the remainder of the report , we will discuss how the focus of the nrs was determined and the assessment was developed , hsb's response to problems in initial implementation as well as some implementation issues that remain unaddressed , and the extent to which the assessment meets the professional and technical standards to support specific purposes identified by hsb .

the nrs assesses vocabulary , letter recognition , simple math skills , and screens for understanding of spoken english .

as initially conceived by hsb , the nrs was to gauge the progress of head start children in 13 congressionally mandated indicators of learning .

however , time constraints and technical matters precluded hsb from assessing children on all of the indicators and led hsb to consider , and eventually adopt , portions of other assessments for use in the nrs .

the 18 months from announcing the good start , grow smart initiative , of which the nrs is a part , to implementing the assessment was not enough time for hsb to develop a completely new assessment .

therefore , hsb , with the advice of its contractor and the technical work group , chose to borrow material from existing assessments .

concerns raised by technical work group members and the contractor about the length and complexity of the assessment and the technical adequacy of individual components eventually led to limiting the areas assessed in the nrs , from 13 skills to 6 .

the six legislatively mandated skills that hsb targeted included whether children in head start: use increasingly complex and varied spoken vocabulary ; understand increasingly complex and varied vocabulary ; identify at least 10 letters of the alphabet ; know numbers and simple math operations , such as addition and subtraction ; for non - english speaking children , demonstrate progress in listening to and understanding english ; and for non - english speaking children , show progress in speaking english .

in april and may of 2003 an assessment that included 5 components covering the 6 skills was field tested with 36 head start programs to examine the basic adequacy of the nrs , as well as the method for training assessors , and the use of the cbrs .

the field test also included a spanish version of the nrs .

based on the field test , one component – - phonological awareness , or one's ability to hear , identify , and manipulate sounds – - was eliminated .

while this component examined an area that experts have linked to prevention of reading difficulties , the test used to assess it was problematic .

hsb moved forward with the other components of the nrs .

the four components of the nrs each measure one or more of the six legislatively - mandated indicators .

the four components that comprise the nrs are from the following tests: oral language development scale ( olds ) of the pre - language assessment scale 2000 ( pre - las 2000 ) , third edition of the peabody picture vocabulary test ( ppvt - iii ) , head start quality research centers ( qrc ) letter - naming exercise , and early childhood longitudinal study of a kindergarten cohort ( ecls - k ) math assessment .

some or all of each test was previously used for other studies , and the ppvt and letter naming were previously used in studies of head start children .

three of the four tests were modified from their original version , as shown in table 2 .

figures 3 and 4 are examples from the letter naming and early math skills components of the nrs .

figure 5 is an example of the type of item used in the vocabulary ( ppvt ) component of the nrs .

here are some letters of the alphabet .

gesture with a circular motion at letters and say: point to all the letters that you know and tell me the name of each one .

go slowly and show me which letter you're naming .

indicate only correctly named letters on answer sheet .

when child stops naming letters , say: look carefully at all of them .

do you know any more ? .

keep asking until child doesn't know any more .

