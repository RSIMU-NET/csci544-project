the cost of the decennial census has steadily increased over the past several decades , with enumeration costs rising from about $16 per household in 1970 to around $92 in 2010 ( all in constant 2020 dollars ) .

the census bureau ( bureau ) estimates that overall decennial costs will increase by over $3 billion from the 2010 census to $15.6 billion in 2020 ( in current decennial time frame costs ) .

during this period of increasing costs , the percentage of households self - responding to mailed census questionnaires has declined from 78 percent in 1970 to 63 percent in 2010 .

the bureau anticipates that the self - response rate will further decline to roughly 60 percent in 2020 , in part because , as the bureau has noted , the population is overloaded with requests for information and has become increasingly concerned about sharing information .

when a household does not initially respond to the census , the bureau attempts to enumerate the residents through non - response follow - up ( nrfu ) , an operation where enumerators personally visit to count the household .

nrfu is labor intensive and is the largest and costliest operation that the bureau undertakes .

another enumeration operation happening at about the same time is group quarters , when the bureau counts residents of group facilities ( such as skilled nursing facilities and correctional facilities ) .

the bureau planned its 2018 census test in providence county , rhode island , to rehearse most of the operations , systems , and procedures that it will implement during the 2020 census .

previously , the bureau conducted operational tests from 2013 through 2017 , as well as multiple small - scale tests designed to demonstrate specific functionalities ( such as submitting census data over the internet ) .

the 2018 test is the last opportunity for the bureau to demonstrate readiness for its major operations in 2020 and to apply lessons learned from prior tests .

you asked us to review implementation of nrfu testing during the 2018 census test as well as the bureau's overall readiness for peak operations , which cover the actual enumeration of residents .

this report examines ( 1 ) the implementation of peak operations during the 2018 census test at the providence county , rhode island , site ; and ( 2 ) the extent to which implementation issues raised in prior 2020 census tests have been addressed and what actions the bureau could take to address these issues .

to address both of these research objectives , we visited the test site in rhode island to observe implementation of the peak operations being tested between may and august 2018 .

these visits included nongeneralizable observations of door - to - door field enumeration and office clerical work , as well as interviews with local managers .

we also observed debrief sessions held with multiple levels of the census field workforce after the operations .

from each of these visits , we documented observations and provided feedback to bureau managers in near real time so that the bureau could mitigate and adapt to issues raised by the test's implementation in a timely manner .

implementation issues are a natural part of the testing environment and are what testing is intended to uncover .

we also discussed any mitigation or evaluation strategies developed in response to our observations with the cognizant bureau headquarters officials .

in addition to our fieldwork , we collected real - time production data on the tested operations .

these data included tallies of case outcomes , transactional case activity by enumerators , and hours worked by bureau employees .

after testing the case tallies and distributions and interviewing cognizant officials , we determined that these data were sufficiently reliable for our reporting purposes .

we also received daily progress reports from the bureau throughout the test , and we reviewed bureau test - planning documentation and our work from prior tests to examine how , if at all , the bureau planned to address prior implementation issues .

we conducted this performance audit from april 2018 to december 2018 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

nrfu is a field - based operation that the bureau administers following the self - response period so that it can ( 1 ) determine the occupancy status of individual non - responsive housing units and ( 2 ) enumerate them .

in most instances , the bureau typically allows up to six enumeration attempts for each nonresponsive housing unit , or case .

if the bureau is unable to enumerate the housing unit in the field , it may have to impute attributes of the household based on the demographic characteristics of surrounding housing units as well as administrative records .

within the test site in providence county , rhode island , the bureau set up an area census office to administer field operations .

figure 1 provides an overview of the managerial hierarchy of the area census office .

the area census office manager oversees day - to - day operations within the office and acts as a liaison with the bureau's new york regional census center , which is a bureau regional office with jurisdiction over the providence area census office .

census field managers are to monitor operational progress and performance indicators to understand any areas of concern and shift resources as needed within the test site .

census field supervisors are to act as front - line supervisors for individual performance and payroll processes and receive procedural questions from enumerators , who conduct the count .

the bureau has another operation — group quarters — to enumerate those living or staying in a group facility that provides housing or services .

such facilities can include skilled nursing facilities , college and university student housing , and correctional facilities .

within the group quarters enumeration , the bureau also enumerates places such as soup kitchens , homeless shelters , and other service - based enumeration facilities .

prior to group quarters enumeration in the field , the bureau attempts to establish the facilities' approximate population count and preferred enumeration method through the advance contact operation .

these facilities can choose among methods including paper listing , where the facility provides a roster of residents as of census day to the bureau , and in - person enumeration , where a team of enumerators count residents .

for the 2020 cycle , the bureau is also adding an “eresponse” option , tested on a small scale in 2016 , whereby facility administrators can electronically submit enumeration data at a date of their choosing within operational time frames .

the bureau's testing of the peak operations that we observed during the 2018 census test was intended to test collection of census data from those either not responding themselves via paper , telephone , or over the internet or those living in group quarters .

prior to the start of nrfu during the 2018 test , roughly 45 percent of anticipated housing units in the test area of providence county , rhode island , self - responded , leaving more than 140,000 remaining housing units to be attempted by nrfu itself , which took place between may 9 and july 31 , 2018 .

the bureau conducted a test of its group quarters enumeration from july 25 through august 24 , 2018 , including service - based enumeration .

both portions of group quarters fieldwork were preceded by the advance contact activity .

dates for the peak operations we observed during the 2018 test are listed in table 1 .

the bureau's operational plans for this phase of the fieldwork for the 2018 test incorporated two innovation areas that the bureau hopes will produce savings for 2020 .

reengineered field operations .

for most of nrfu during the 2018 test , the bureau relied on automated data collection methods , including a system - based , automated process for assigning work to enumerators , a smartphone - based application for collecting enumeration data in the field , and system - generated supervisory alerts .

use of administrative records .

to help reduce costly nrfu visits during the 2018 test , the bureau reviewed and , where appropriate , applied administrative records — information already provided to the government as it administers other programs , such as social security , the selective service , or the special supplemental nutrition program for women , infants , and children — to determine the occupancy status of housing units and thus remove vacant housing units from the nrfu workload , as well as to provide population counts of households not responding .

the bureau also tested multiple operational features for the first time this decennial cycle under full census - like production conditions in 2018: nrfu closeout .

during the 2018 test , the bureau tested how best to relax certain business rules and enumeration procedures late in the nrfu operation so that it can enumerate persistently non - responsive housing units .

examples of procedural modifications include increasing the maximum allowable number of enumeration attempts for each housing unit and manually assigning cases to the highest - performing enumerators .

office - based group quarters advance contact .

in the 2010 census , the bureau sent enumerator crews in person to each facility in advance of enumeration to establish the facility's preferred method of enumeration and to obtain an approximate population count .

in the 2018 census test , the bureau implemented a new method for 2020 that instead involved clerical staff contacting facilities by telephone and updating the group quarters address list and enumeration information remotely to reduce expenses associated with field visits for its enumerator crews .

the bureau began the last phase of nrfu data collection in the 2018 test without having yet determined the procedures it would use for that critical phase .

bureau planning documentation from february 2018 described a late - operation “closeout” phase of nrfu that would attempt to resolve cases that had not yet responded .

however , we found that the bureau had not determined the procedural modifications this phase would involve , either in terms of rules enumerators followed or business rules for how cases were to be assigned .

by late may , nearly 3 weeks into the operation , the bureau issued a set of closeout procedures to census areas where most cases had either been completed or where at least four of the six allowable enumeration attempt day assignments had been made .

the bureau also placed a priority on having high - performing enumerators — in terms of their ability to complete cases — available to work these cases during this phase of the nrfu testing .

table 2 summarizes the chronology for when the bureau implemented and documented procedural changes governing the transition from early to late - nrfu data collection , as well as the nature of those changes .

in late june 2018 , the bureau began testing the third phase of nrfu data collection , what it referred to as the “final attempt” phase , with officials citing a high incidence of non - interviews during prior phases as the reason .

however , the bureau had also begun this phase's data collection before it had established the procedural modifications it would be using .

the modifications were intended to further increase the chances of enumerators completing cases in the field , such as by removing the limit on the number of attempts enumerators could make at each remaining case before nrfu ended .

standards for internal control in the federal government states that agencies should implement control activities by , for example , documenting policies .

however , the bureau did not determine procedures for the final attempt phase until after testing for this phase of nrfu had begun .

enumerators and census field supervisors thus began working closeout and final attempt cases without a standardized set of test procedures .

without determining the procedural changes the bureau would be testing — or the business rules guiding when to make those changes — the bureau was not well positioned to collect data to assess the alternatives it used during the test to inform planning for 2020 .

bureau officials shared with us that they believed their automated case assignment approach is most effective during initial data collection but that it is less effective at targeting the toughest cases to resolve late in nrfu data collection .

yet , in part because the bureau had not established when the transition from automated to manual case management would occur — or the business rules for determining when — some of the highest - performing enumerators were unavailable to receive assignments when the bureau needed to begin the final attempt phase , according to the area census office manager .

by not establishing the scope and timing of procedural changes for late - nrfu data collection in 2020 , the bureau may not be in a position to efficiently shift from its automated assignment approach to a manual one at the right time and position its most effective enumerators to receive assignments when needed .

in november 2018 , the bureau provided a draft contact strategy for nrfu in 2020 that included an outline of a multi - phase strategy for late - nrfu data collection .

by including multiple phases of ( 1 ) shifting away from a fully - automated case assignment process and ( 2 ) relaxing management controls to complete as much casework as possible in areas with continued high non - response rates , this strategy appears to follow what the bureau ultimately implemented during the 2018 test .

it will be important , however , for the bureau to determine the business rules for procedural changes and their timing in advance so that it can maximize the value of nrfu in reducing the number of housing units that have to be imputed for the 2020 census .

census field supervisors were not integrated into casework management .

as described in the bureau's training and operational planning documents , census field supervisors were to be the primary points of contact in fielding and addressing enumerator questions .

census field managers — the next step above census field supervisors — were to focus their efforts on monitoring progress in completing the caseload , reviewing cases flagged by enumerators as problematic in one of a small number of pre - defined ways ( eg , dangerous addresses ) , and resolving significant performance issues .

among field supervisors' key responsibilities , according to the bureau's plan for nrfu , were providing guidance to help enumerators understand procedural matters and to offer coaching and problem - solving support to enumerators who may need it .

they also led enumerator training prior to the beginning of nrfu and generally were to train their specific team of enumerators .

however , census field managers and enumerators indicated that census field supervisors were often not the primary actors involved in fielding and addressing enumerator questions .

instead , enumerators and census field managers reported having direct contact with each other over procedural questions .

moreover , seven of the nine enumerators participating in the bureau's operational debrief focus group who responded said they thought finding someone who could answer their questions was either difficult or very difficult .

we found that census field supervisors went underutilized in part because the bureau did not recruit and position them to assume front - line supervising and coaching responsibilities .

as outlined in training documentation , the bureau vested supervisory review authority ( for special cases , such as resident refusals and language barrier issues ) within census field managers , the area census office manager , clerks , and office operations supervisors instead of census field supervisors .

additionally , as part of the bureau's reengineered field operations for 2020 , census field supervisors are given automated tools to monitor enumerators , and enumerators we observed told us that they generally did not interact in person with their supervisors apart from training .

we believe that the combination of these factors resulted in census field supervisors having limited exposure to nrfu casework and any problematic situations enumerators might encounter .

officials also told us that the bureau did not screen census field supervisors for their supervisory or coaching skillsets , though officials noted that this has been the practice in prior censuses , too .

rather , they hired census field supervisors based on their scores on the online enumerator training and because they reported an interest in supervising .

additionally , census field supervisors lacked access to certain data streams from the test that could have helped them answer or troubleshoot enumerator questions .

according to two census field managers , the bureau did not regularly share consolidated records of procedural changes with census field supervisors .

information technology ( it ) and census field managers also noted that the bureau did not share or compare observations between the census field supervisor hotline and the decennial it hotline , even though enumerators could potentially call either or both with technical or procedural questions .

as a result , without sharing how best to respond to similar questions across support lines , enumerators could receive different answers for related questions depending on which hotline they contacted .

standards for internal control in the federal government states that agency management should demonstrate a commitment to recruit , develop , and retain competent individuals .

management should establish expectations for competence in key roles and should consider the level of assigned responsibility and delegated authority when establishing expectations .

yet , the role the bureau envisioned census field supervisors having was not aligned with the authority supervisors were given , the skills for which the bureau hired them , or the access to information that they had for the 2018 test .

when we raised this issue related to using census field supervisors , bureau officials agreed and cited feedback they had received that census field managers felt inundated with the combination of the volume of supervisory review cases that flowed to them and with troubleshooting day - to - day enumerator questions .

in october 2018 , the bureau provided documentation to us proposing a set of questions that they could use in screening applicants for the census field supervisor position to identify supervisory skills .

officials also said they were still evaluating options for granting census field supervisors more supervisory review authority .

as the bureau continues to learn from the 2018 test as part of its planning for 2020 , it will be important to align census field supervisor roles with their authorities , skills , and information flows so that the bureau does not underutilize a key portion of its field management chain .

doing so could also lessen the operational burden on higher - level census field managers .

enumerators did not receive training to address mid - operation issues .

prior to the start of 2018 nrfu testing , the bureau trained enumerators with a series of online training modules and assessments and one full day of in - person training facilitated by census field supervisors .

the training included modules on data stewardship requirements , payroll responsibilities , and procedural directions for conducting respondent interviews .

however , officials acknowledged that when the bureau implemented its closeout and final attempt phases of nrfu , it did not provide standardized training to enumerators on the rollout of procedural changes .

five enumerators we observed during these stages said they relied on informal communications from their census field supervisors or census field managers for guidance .

the initial practice had been for enumerators to receive daily assignments and follow pre - specified case sequencing and routing based on the bureau's automated system .

during the final attempt phase , enumerators were given discretion over the sequencing , routing , and number of attempts to make for cases that could be manually assigned , yet they were not given standardized training on how to handle this shift .

during our field observations , some enumerators we spoke with said they were uncertain about core procedures .

for example , enumerators were not consistently aware that they had some discretion in large multi - unit settings to deviate from the assigned sequence of their cases provided by the automated system .

enumerators we observed and spoke to were also not always clear on how to flag within their field enumeration application the commonly occurring cases with confusing address markings and numberings .

for example , enumerators had the option of selecting a case outcome of “missing unit designation,” but they were not always sure whether this selection would capture the nuances of what they were seeing on the ground or how it differed from other selection options .

standards for control in the federal government states that agencies should demonstrate a commitment to competence by , for example , tailoring training based on employee needs and helping personnel adapt to an evolving environment .

targeted informational training would help the bureau ensure that staff understand mid - operation procedural changes , and the training could be an opportunity for the bureau to address commonly - observed and persistent implementation issues that may be arising .

by developing brief , targeted mid - operation training , either as formal modules , guidance , or other standardized job aids , such as “frequently asked questions” worksheets , the bureau could better position itself to react nimbly to enumerator feedback .

we have previously reported challenges the bureau faces with its field work in other locations , such as connecting to the internet during testing of address canvassing in rural west virginia in 2017 and dealing with language barriers and other circumstances in unincorporated communities in southern texas or with migrant and seasonal farmworkers in southern california during the 2000 census .

all challenges are not universal to all locations .

given that some of the enumeration challenges enumerators encountered in 2018 nrfu testing might not occur everywhere , and that some other areas of the country will have their own types of challenges , locally - or regionally - specific training or guidance may better address some needs .

by relying solely on pre - nrfu training , the bureau risks having little opportunity to course - correct with enumerators who may not have absorbed all of the training and are experiencing difficulty completing interviews or not collecting quality data .

we observed and discussed with bureau officials in real time several other implementation issues that occurred during the 2018 test .

bureau officials acknowledged these issues and , as of september 2018 , were assessing them and developing mitigation strategies as part of their test evaluation process .

these issues include: training certification .

census field managers estimated that roughly 100 enumerators were unable to transmit their final test scores because the bureau's online learning management system had an erroneous setting .

according to bureau officials , this problem delayed the start of unsupervised work for these otherwise - qualified enumerators by an average of 2 days per enumerator and resulted in the attrition of some who were able to quickly find other work .

bureau officials told us they have fixed the system setting and are considering an alternative means to certify training , such as by having the option of trainees taking and verifying their final assessment as part of their final capstone day of classroom training .

according to bureau officials , development of this backup strategy will begin in december 2018 .

assigning cases manually in batches .

during the 2018 test , the bureau's automated case management system was not configured for non - headquarters staff to manually assign multiple cases to an enumerator at once .

rather , according to officials , census field managers were faced with having to manually assign thousands of cases individually during latter stages of nrfu .

according to field management , this problem presented an unexpected burden on them , delayed assignments of the hardest - to - count cases , and contributed to high - performing enumerators not receiving work timely and in some cases for days in a row .

officials told us that , as a work - around , the bureau shifted responsibility for assigning cases to a headquarters official with access rights in the system to assign large numbers of cases at once .

bureau officials acknowledge the unsustainability of this work - around if needed at a national level and the importance of resolving this before the 2020 census .

as of october 2018 , bureau officials showed us system screenshots of how census field managers would be able to manually assign batches of cases and indicated that this functionality would be ready for the 2020 census .

monitoring operational progress .

the bureau's reporting on its progress in completing the nrfu casework for the 2018 test emphasized a process - oriented measure that overstated the extent to which the nrfu efforts were resulting in completed workload .

in planning documentation , the bureau listed the outcomes of interview attempts that it considered complete and thus not in need of further enumeration assignments .

these outcomes — such as a full interview of the household or confirmation of a housing unit being vacant or nonexistent — would also result directly in reduction in the number of incomplete cases needing to have some of their missing data imputed by the bureau later .

yet the daily bureau progress report and “dashboard” the bureau provided us for the 2018 test , which decennial leadership also identified as their primary monitoring report , did not reflect these pre - planned definitions of completed workload .

rather , as officials acknowledged , it included cases that the bureau had unsuccessfully attempted to enumerate the maximum number of allowable times for the initial phase of nrfu being tested , even though those cases could still — and did — receive additional attempts during later phases of nrfu .

officials noted that the measure reported could be helpful during early stages of the operation in determining whether enough employees had been hired , or whether case assignments were being worked quickly enough .

figure 2 demonstrates the gap that arose during 2018 nrfu test implementation between the reported progress measure and the number of cases actually being completed .

the totals reflected in the bureau's reported measure include those that either have to be re - worked in the field during the final attempt phase as discussed or have their data imputed after fieldwork had ended .

by contrast , an outcome - based measure of operational progress , like the one the bureau designed , would capture only those cases where the bureau had completed enumeration of the nonresponding housing units and thus be a more accurate representation of the operation's status .

bureau officials acknowledged the need to maintain measures that focus on process as well as outcomes — such as avoiding having to impute data for cases after field work — when measuring progress completing nrfu .

they said that managers in the field and in bureau headquarters had access to alternative measures and reports that more closely identified outcomes .

the officials noted that the reporting mechanism expected to be used in 2020 was not fully available in time for the beginning of nrfu testing in 2018 , so the reporting format and measures will likely differ .

in addition , in october 2018 , the bureau provided a draft dashboard for 2020 that included greater detail on the number of cases that could still require work to enumerate .

such detail could help assist with determining when to transition to the final - attempt phase of the operation to address cases without sufficient information yet collected .

integrating key systems settings .

at the beginning of nrfu test implementation , the bureau's case assignment and case sequencing systems were operating as if they were on time zones 4 hours apart .

bureau officials said that this resulted in enumerators receiving mismatched case assignment times , which hampered early nrfu production , and census field supervisors having to process erroneous “work not started” supervisory alerts .

bureau officials said they addressed the problem within the first week of the operation and that they would ensure that future updates and key settings would be coordinated across systems .

tracking employees and equipment .

the bureau used two different sets of employee identification numbers to track their payroll status and use of bureau - issued equipment ( eg , smart phones ) , respectively , without cross - walking them .

according to census field managers , this resulted in extra work when trying to monitor changes in enumerators' employment statuses and whether enumerators had returned their equipment to the bureau .

the managers noted that office staff had to spend extra time comparing different lists of staff , while one manager developed a spreadsheet listing all staff by their two different identification numbers .

bureau officials said they considered this a priority issue to be resolved during final systems development for 2020 and had already developed a fix within their case management system so that the cross - walk between the two systems would be integrated within their management system .

this would eliminate the need for manually reconciling the differing identification numbers .

having more enumerators work weekends .

until the latter stages of 2018 nrfu testing , the bureau assigned cases to enumerators based on the alignment of the bureau's estimated probability of finding respondents at home at certain times and enumerator - reported work availability .

bureau officials told us that saturdays are generally one of the best days to find a household member home to respond to the census .

however , during the test , our analysis showed that saturdays had the second - fewest number of enumerators assigned to cases of any day of the week .

bureau officials said that they would review whether the incentive structure for working on saturdays should be altered and that they would examine ways to ensure that more enumerators are working on those days .

this includes exploring the feasibility of hiring and assigning work to applicants who may only want to work weekends and being clearer with enumerators about what the expected peak enumeration hours are .

increasing electronic completion rates for group quarters .

the bureau hopes to reduce field costs for group quarters ( such as skilled nursing homes , college and university student housing , and correctional facilities ) by , for the first time , encouraging facilities to self - enumerate electronically , when possible .

as previously discussed , clerical staff first establish facility enumeration preferences during group quarters advance contact , and enumeration ( either in person or otherwise ) takes place afterward .

during the 2018 test , the bureau reported that only 25 of the 75 facilities that selected the “eresponse” enumeration option during advance contact submitted responses by the enumeration deadline .

as of september 2018 , bureau officials said they were still evaluating potential causes of the low response rate by group quarters facilities but noted that issues with the required format for the submission of response files may have prevented some submissions .

bureau officials also acknowledged the need to conduct more active follow - up with these facilities during the eresponse period to ensure a full and accurate count of group quarters facilities .

we reported to the bureau during the 2015 census test that information enumerators were typing into their case notes did not appear to be systematically used by their managers .

we also reported that , during the 2016 census test , the bureau was not reviewing case notes written by enumerators providing respondent information on better times - of - day for future nrfu visits to their housing unit , and enumerators did not always have this note - taking feature available .

during the 2018 test , enumerators were trained to take notes and , when appropriate , identify special cases that would later require supervisory review .

we also observed that enumerators appeared to be consulting case notes from prior enumerator visits when planning nrfu visits to the same housing unit .

enumerators can use markings within their automated interview instrument to describe certain types of cases ( eg , hearing barriers and dangerous situations ) , which the automated system would then route to receive supervisory review .

enumerators could select other case outcomes that the automated system would apply predetermined business rules to either reassign the cases ( eg , refusal , no one home ) or treat them as completed ( verified vacant or not a housing unit ) .

however , we identified multiple scenarios in which enumerators had described cases in their case notes but for which the enumerators had not selected the corresponding case flag for the situation that would have resulted automatically in a supervisory review .

one census field manager described discovering several dozen cases that had been inactive where enumerators had written case notes describing language barriers encountered but had not specifically marked the flag within the device for “language barrier.” because these cases thus were not triggered for supervisory review , they were eligible to be reassigned by the bureau's standard automated system .

as a result , the bureau was not controlling for the requisite language skills in assigning the cases for subsequent enumeration attempts .

the bureau's use of automated systems to apply business rules to efficiently manage field casework for 2020 — including identifying which cases receive supervisory review — relies critically on field staff understanding how to reflect what they are seeing on the ground within the choices provided to them with which to flag cases in their interview device .

the bureau's use of remote management as part of reengineered field operations also relies on enumerators knowing when and how to report issues to their supervisors .

we observed multiple field scenarios that called these conditions into question , however .

for example , enumerators we observed during nrfu told us that they indicated address listing issues in their case notes , such as if the unit designation was missing or incorrectly marked .

yet , these enumerators did not know how to flag such cases in their interview instrument to trigger supervisory review .

according to bureau officials , this type of address listing issue turned out to be a broadly experienced challenge within the test area .

additionally , during group quarters , an enumerator we observed received supplemental information about the number of residents at a neighboring facility after that facility had been enumerated .

the enumerator made note of this discrepancy and included the original facility's identifying information but was uncertain about how , if at all , to alert the supervisor about the discrepancy .

moreover , we saw little evidence that census field supervisors or managers were systematically reviewing case notes for the purpose of identifying either cases not being marked properly or for which the selected flags may not have been fully describing the case characteristics .

for example , a census field manager confirmed that case notes recorded at group quarters facilities that were enumerated would not be reviewed during clerical processing , leaving the possibility — such as we observed — that if enumerators relied on case notes to communicate information about the accuracy of data collected , it would not be acted on .

bureau officials told us that reviewing all case notes could require more staff time than budgeted for , and changing the automation process to selectively present unflagged cases for supervisory review could necessitate requirements changes to systems whose development is already pressed for time .

standards for internal control in the federal government states that agencies should use quality information by , for example , processing reliable information to help it make informed decisions .

bureau enumerators can record useful local knowledge about their cases with their choice of case type flags and within their descriptive case notes .

while the bureau has anticipated a broad range of types of cases for enumerators to select from when documenting their casework , enumerators we observed did not uniformly understand those options , and the descriptors did not fully anticipate what enumerators were encountering .

improving training and guidance to field staff on the intended use of case notes and on alternative ways to communicate their concerns about cases , such as flags for different types of cases , can help ensure the bureau has reliable data on the cases during its field operations relying on automated interviewing instruments .

during the 2015 census test , we reported that certain technical and procedural problems that enumerators were encountering in the field were going unreported and that enumerators did not always know who to contact for assistance .

we further noted that the bureau was not systematically assessing or tracking the extent of these issues during testing , and we recommended that it enable such capture of information by training enumerators on where to record issues and whom to contact .

the bureau agreed with our recommendation .

during the 2018 test , the bureau had both an information technology ( it ) hotline and a census - field - supervisor hotline established for technical and procedural questions , respectively .

yet , enumerators we observed told us they did not always report to their support lines the technical issues that they were easily able to resolve by , for example , turning their devices on and off to reset .

this lack of reporting kept the bureau from getting information on commonly - occurring challenges that might be useful real - time feedback in the testing environment .

moreover , a bureau it manager noted that the bureau does not formally review and share observations and troubleshooting notes from it hotline and census field supervisor hotline calls .

because enumerators may call either or both hotlines when having difficulty operating their bureau - issued smart phone , operators of these hotlines could be unaware of the prevalence of or solutions to a given problem if the bureau does not monitor troubleshooting information across the two operational silos .

for the bureau to be informed on any additional training needs or other operational decisions for 2020 , it will need to continue to expand its efforts in collecting information on enumerator - reported problems per our 2015 recommendation .

depending on the size of a group quarters facility ( eg , skilled nursing facility , college and university student housing ) , the bureau can use varying sizes of enumerator crews to conduct an onsite count .

during the 2010 census , we observed overstaffing during the service - based enumeration ( eg , homeless shelters and soup kitchens ) portion of group quarters .

while determining staffing levels at these facilities can be challenging , such overstaffing can lead to poor productivity and unnecessarily high labor costs .

we recommended that the bureau determine and address the factors that led to this overstaffing prior to 2020 .

the bureau agreed with our recommendation .

however , the bureau has faced challenges determining the right staffing ratios in light of complications with the advance contact phase of group quarters .

as previously noted , the bureau used this phase to establish facilities' enumeration method preferences .

for the 2018 test , most group quarters facilities selected the facility - provided paper listing and the eresponse enumeration options .

therefore , the bureau allocated a large share of its enumerator and census field supervisor workforce in the test area to the 44 known service - based enumeration facilities , which were restricted in terms of the enumeration options they could select and tended to select in - person enumeration .

however , only 11 of these facilities responded to initial inquiries , so the bureau had less work than anticipated for its enumerator crews .

at multiple sites we observed in the test area , enumerators appeared either idle or underutilized .

moreover , several of the group quarters facilities we observed had changed their initial choice of enumeration method on the day of enumeration .

enumerator crews thus ran the risk of either being overstaffed ( in the case of switching to a facility - provided paper listing ) or understaffed ( in the case of switching to an in - person enumeration ) .

the bureau's advance contact activities have a potential benefit — if the bureau can get accurate information on the method of enumeration and approximate population within a facility ahead of time , bureau managers and enumerator crews can more proactively allocate resources and prepare for the count .

bureau officials said they are still assessing outcomes of advance contact to see if these gains were realized and may have completed the assessment by as early as january 2019 .

doing so will help the bureau determine appropriate staffing sizes and thus address our prior recommendation .

according to preliminary data from the 2018 census test , the bureau experienced similarly high rates of cases coded as non - interviews as it did during its last major field test of nrfu in 2016 .

non - interviews are cases where enumerators collect no data or insufficient data from households either because enumerators made the maximum number of visits without a successful interview , or because of special circumstances like language barriers or dangerous situations .

when this happens , the bureau may have to impute the census data for the case , such as whether the housing unit is vacant or not , the population counts of the households , or demographic characteristics of their residents .

in january 2017 , we reported that , during the 2016 census test , the bureau incurred what it considered high non - interview rates ( 31 and 22 percent across the two test sites , respectively , as the bureau preliminarily reported at the time ) , and we recommended that the bureau determine the causes of these rates .

using the same method to calculate the rate of non - interviews for the test as in 2016 , the 2018 census test had similarly high non - interview rates — 33 percent of all nrfu cases .

bureau officials said they are still examining causes of these elevated non - interview rates and whether final attempts helped to mitigate the non - interview rate and will report out on what they learn as part of their comprehensive assessment of the test , planned for december 2018 .

a draft of the bureau's revised contact strategy for nrfu , provided in november 2018 , indicates that as part of enumerator training in 2020 the bureau will need to incorporate messaging that emphasizes the importance of obtaining sufficient data from interview attempts .

officials noted that any interim lessons learned from this assessment process would inform updates to the field enumeration contact strategies for 2020 .

enumerators are directed to try and complete a nrfu case by interviewing a proxy for a household respondent , like a neighbor , after multiple failed attempts have been made to contact someone in the household for that case .

we previously observed in the 2016 census test that enumerators did not seem to understand the procedures for conducting these interviews and , as a result , underutilized the interviewing method .

in our january 2017 report , we therefore recommended that , as part of determining the causes of its non - interview rate , the bureau revise and test any needed changes to proxy procedures and associated training .

the bureau agreed with our recommendation and subsequently developed automated supervisory performance alerts for census field supervisors and census field managers that would inform them when an enumerator was not following prompts to conduct proxy interviews for eligible cases .

however , in implementing proxy interview procedures for the 2018 census test , the bureau experienced a technical glitch resulting in some confusion among some enumerators and their supervisors about related procedures .

early in nrfu data collection for the test , a programming error within the field enumeration application was prompting enumerators to make more than the allowable three attempts to interview a proxy respondent .

the bureau reported promptly implementing a technical fix to this issue ; yet , enumerators we observed reported receiving varying guidance from their supervisors on whether to abide by the erroneous prompts .

while some of these enumerators appeared to understand the importance of attempting proxy interviews , some did not appear to understand bureau guidance that enumerators should make no more than three attempts to interview a proxy respondent , and some appeared conditioned to follow the erroneous prompts .

proxy interviews can be a substantial portion of completed interviews during the census .

in 2018 nrfu testing , interviews of proxy respondents accounted for 27 percent of all successful interview - based enumerations of occupied housing units — compared to 24 percent during the 2010 census and 9 percent during the 2016 census test .

given the role that proxy interviews play in completing census data collection , it will be important for the bureau to fully implement our recommendation so that enumerators are properly pursuing and conducting these interviews .

initial visits to property managers of multi - unit residences can help the bureau identify vacant and occupied housing units before sending enumerators to individual units within the facilities .

we have previously reported that property managers can also be a helpful source of information on respondents who are not at home , thereby making subsequent follow - up visits to individual units more productive .

during the 2016 census test , we observed that enumerators were uncertain of how to handle individual cases within a multi - unit once they were unsuccessful in contacting a property manager initially .

as a result , we recommended in january 2017 that the bureau revise and test procedural and training modifications as needed to aid enumerators and their supervisors in these cases .

the bureau agreed with this recommendation and indicated that the evaluations of the 2018 test would inform its strategies for 2020 .

however , we observed a similar issue during the 2018 census test in that enumerators were unclear on what , if any , proxies to attempt if they were unsuccessful in finding the listed property manager .

additionally , we observed multiple enumerators leave voicemails with their contact information — not a central number — for the listed property manager , but it was unclear how these voicemails would produce a successful interview because , later , the automated system could reassign other enumerators to visit the manager .

when we raised this concern with bureau officials , they acknowledged that they need to continue to refine procedures for handling initial property manager visits for 2020 .

previously , during the 2016 census test , we observed that enumerators were unable to re - open closed non - interview cases even if they happened upon the respondent in question soon after and nearby .

we noted this inefficiency , since these cases would get re - assigned later , and in january 2017 , we recommended that the bureau revise and test procedures that would grant flexibility to enumerators to access cases in these circumstances .

the bureau agreed with our recommendation .

for the 2018 census test , the bureau provided a list in the field enumeration application of the cases that had been worked by the enumerator that day but that had not been submitted for processing or reassignment .

training for enumerators described this enumeration option , and enumerators were authorized to access these cases when needed , but not all enumerators we observed were consistently aware of how to do so .

enumerators we spoke with cited uncertainty over how to access these cases and whether enumerators were allowed to do so as considerations .

continuing to review the procedures and guidance to enumerators on this flexibility for completing interviews , consistent with our prior recommendation , will help the bureau make better use of it in 2020 .

as we reported in 2017 , the bureau previously modified how it would treat some of the households that did not respond to the 2020 census and that the bureau's use of administrative records had determined to be not occupied .

the bureau's earlier testing had determined that the bureau should require two — instead of just one — notices from the united states postal service that mail could not be delivered to these households before removing their addresses from the nrfu workload .

after we provided a draft of this report to the department of commerce to obtain agency comments , bureau officials provided us with findings from an evaluation of the 2018 census test .

in the evaluation , bureau officials observed that there were households for which they had received multiple notices from the united states postal service that mail was undeliverable but that bureau enumerators recorded as occupied .

while bureau officials believe , based on their follow - up research , that these addresses may likely be vacant or not housing units , they are concerned about possible undercounting from not enumerating people who may be at these addresses .

as of november 2018 , the bureau was considering adding one physical visit for each of these cases .

bureau officials said they are continuing to analyze these evaluation results and expect to document and include changes within its final operational plan for the 2020 census due in january 2019 .

the 2018 census test offered the bureau its last opportunity to test key procedures , management approaches , and systems under decennial - like conditions prior to the 2020 census .

as the bureau studies the results of its nrfu and group quarters testing to inform 2020 , it will be important that it address key program management issues that arose during implementation of the test .

namely , by not establishing the intended procedural changes for late - nrfu data collection ahead of time , the bureau risked not getting the most out of nrfu to minimize the number of housing units having to have their information imputed by the bureau later .

additionally , by not aligning the skills , responsibilities , and information flows for census field supervisors , the bureau limited their role in support of enumerators within the reengineered field operation .

the bureau also lacks mid - operation training or guidance , which , if implemented in a targeted , localized manner , could further help enumerators navigate procedural modifications and any commonly - encountered problems when enumerating .

finally , without enumerators understanding how to use case notes and flags for various types of cases in their enumeration device and to report enumeration challenges to supervisors and managers , the bureau may be unaware of field work issues that could affect the efficiency of its operations and the quality of its data .

we provided near real - time feedback to the bureau across a range of test implementation issues .

some , such as those related to staffing ratios for the group quarters operation , build on long - standing implementation issues that , if addressed , can contribute to the efficiency and effectiveness of 2020 field operations .

others , like not having nrfu progress measures that provide true indications of completed workload , are issues specific to this test that the bureau is assessing as part of its 2018 census test evaluations .

it will be important for the bureau to prioritize its mitigation strategies for these implementation issues so that it can maximize readiness for the 2020 census .

we are making four recommendations to the department of commerce and the census bureau: the secretary of commerce should ensure that the director of the census bureau determines in advance of non - response follow - up what the procedural changes will be for the last phases of its data collection and what the business rules will be for determining when to begin those phases , which cases to assign , and how to assign them .

 ( recommendation 1 ) the secretary of commerce should ensure that the director of the census bureau identifies and implements changes to align census field supervisor screening , authorities , and information flows to allow greater use of the census field supervisor position to provide supervisory support to enumerators .

 ( recommendation 2 ) the secretary of commerce should ensure that the director of the census bureau enables area census offices to prepare targeted , mid - operation training or guidance as needed to address procedural changes or implementation issues encountered locally during non - response follow - up .

 ( recommendation 3 ) the secretary of commerce should ensure that the director of the census bureau improves training and guidance to field staff on the intended use of case notes and flags , as well as on alternative ways to alert supervisors and managers when case characteristics are not readily captured by those flags .

 ( recommendation 4 ) .

we provided a draft of this report to the secretary of commerce .

in its written comments , reproduced in appendix ii , the department of commerce agreed with our findings and recommendations and said it would develop an action plan to address them .

the census bureau also provided technical comments and an update on their evaluation of the test , which we incorporated as appropriate .

we are sending copies of this report to the secretary of commerce , the undersecretary of economic affairs , the acting director of the u.s. census bureau , and the appropriate congressional committees .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report please contact me at ( 202 ) 512-2757 or goldenkoffr@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix iii .

this report examines ( 1 ) how peak field operations were implemented during the 2018 census test ; and ( 2 ) the extent to which implementation issues raised in prior 2020 census tests have been addressed , and what actions the census bureau ( bureau ) is taking to address them .

to address these objectives , we reviewed 2018 census test and 2020 census operational planning and training documentation .

we also reviewed our prior reports and documentation on prior census testing operations .

non - response follow - up ( nrfu ) operations took place from may 8 through july 31 , 2018 , while group quarters took place from july 25 , 2018 through august 24 , 2018 , with the service - based enumeration portion taking place july 25 , 2018 through july 27 , 2018 .

to review the bureau's test implementation and mitigation strategies for previously - identified implementation issues for peak operations , we visited providence , rhode island , multiple times between may and august 2018 to observe enumerators , census field supervisors , and management operations .

nrfu visits took place between mid - may and late - july 2018 , while we also conducted two iterations of visits of group quarters in late july and early - august 2018 .

these multiple iterations both across and within operations enabled us to see how , if at all , implementation of procedures varied over time .

it also enabled us to get direct feedback from bureau field managers on how various phases of test operations were proceeding .

these visits consisted of non - generalizable observations of field enumeration and office clerical work , as well as interviews with local managers .

for each of these visits , we developed data collection instruments to structure our interviews and to cover topics that were pertinent to the given phase of the operation we were observing .

we also observed debrief sessions with multiple levels of the bureau's field workforce following the field work .

to translate our observations into actionable feedback for the bureau , we shared high - level observations in near real - time to bureau headquarters management overseeing the operations so that the bureau could mitigate and adapt to known issues in a timely manner .

we also discussed any mitigation or evaluation strategies developed in response to our observations with the cognizant bureau headquarters officials .

for objective two specifically , we reviewed bureau test planning documentation and our work from prior tests to examine how , if at all , the bureau planned to address known implementation issues .

to gain insight into how implementation was proceeding when we were not directly observing test implementation , we received daily management progress reports from the bureau throughout the nrfu operation testing that included information on the total number of nrfu cases , the final outcomes of each case , and the number of cases that the bureau reported as completed for each day of the nrfu operation .

we also received periodic management reports that summarized high level outcomes of both the nrfu and group quarters workload .

to fully understand the source of the bureau's daily progress reports , we requested and received all transactional data collected during nrfu production .

we reconciled case totals and outcomes with the final numbers in the nrfu progress reports and then used these data to analyze the bureau's progress during nrfu production .

we also received and analyzed bureau payroll data on enumerator hours worked during nrfu operations .

specifically , we assessed the number of enumerators working each day , the number of enumerator' hours paid each day , and the days of the week that were worked the most by enumerators .

we found the bureau's transactional and payroll data sources to be sufficiently reliable for our reporting purposes .

we conducted this performance audit from april to december of 2018 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact named above , ty mitchell ( assistant director ) , devin braun , karen cassidy , joseph fread , robert gebhart , krista loose , kathleen padulchick , lisa pearson , kayla robinson , robert robinson , and cynthia saunders made significant contributions to this report .

