nursing homes play an important role in the health care system of the united states .

more than 40 percent of elderly americans will use a nursing home at some time in their lives .

such facilities provide skilled nursing , therapy , or supportive care to older individuals who do not need the intensive medical care provided by hospitals , but for whom receiving care at home is not feasible .

under the medicare and medicaid programs , nursing homes were expected to receive $58 billion in 2001 , with a federal share of approximately $38 billion .

nursing homes that participate in these programs are required to periodically assess the care needs of residents in order to develop an appropriate plan of care .

such resident assessment data are known as the minimum data set ( mds ) .

the federal government contracts with states to periodically inspect or survey nursing homes , and state surveyors use mds data to help assess the quality of resident care.medicare and some state medicaid programs also use mds data to adjust nursing home payments to account for variation in resident care needs .

thus , the accuracy of mds data has implications for the identification of quality problems and the level of nursing home payments .

mds accuracy is one of many areas that state surveyors are expected to examine during periodic nursing home surveys .

federal guidance for state surveyors regarding the accuracy of mds assessments focuses on whether appropriate personnel completed or coordinated the assessments and whether there are any indications that the assessments were falsified .

this guidance also instructs surveyors to conduct a check of specific mds items to ensure that the resident's condition is appropriately characterized .

concerns exist , however , that state surveyors already have too many tasks and that , as a result , the survey process may not adequately address mds accuracy .

in addition , our prior work on nursing home quality issues has identified weaknesses in the survey process that raise questions about the thoroughness and consistency of state surveys .

in response to your request , we assessed ( 1 ) how states monitor the accuracy of mds data compiled by nursing homes through review programs separate from their standard nursing home survey process , ( 2 ) how states attempt to improve the data's accuracy where there are indications of problems , and ( 3 ) how the federal government ensures the accuracy of mds data .

we surveyed the 50 states and the district of columbia to determine whether states had a separate mds review program — distinct from any mds oversight that might occur during the periodic nursing home surveys performed by all states .

we then conducted structured interviews with officials in 10 of the 11 states that indicated they had separate mds review programs .

we also interviewed staff from the centers for medicare and medicaid services ( cms ) , an agency within the department of health and human services ( hhs ) that manages the medicare and medicaid programs , who were responsible for developing the agency's mds review program .

in addition , we reviewed regulations , literature , and other documents relating to mds data .

we performed our work from december 2000 through january 2002 in accordance with generally accepted government auditing standards .

the nation's 17,000 nursing homes play an essential role in our health care system , providing services to 1.6 million elderly and disabled persons who are temporarily or permanently unable to care for themselves but who do not require the level of care furnished in an acute care hospital .

depending on the identified needs of each resident , as determined through mds assessments , nursing homes provide a variety of services , including nursing and custodial care , physical , occupational , and speech therapy , and medical social services .

the majority of nursing home residents have their care paid for by medicaid , a joint federal - state program for certain low - income individuals .

almost all nursing homes serve medicaid residents , while more than 14,000 nursing homes are also medicare - certified .

medicare , the federal health care program for elderly and disabled americans , pays for posthospital nursing home stays if a beneficiary needs skilled nursing or rehabilitative services .

medicare - covered skilled nursing home days account for approximately 9 percent of total nursing home days .

medicare beneficiaries tend to have shorter nursing home stays and receive more rehabilitation services than individuals covered by medicaid .

since 1991 , nursing homes have been required to develop a plan of care for each resident based on the periodic collection of mds data .

the mds contains individual assessment items covering 17 areas , such as mood and behavior , physical functioning , and skin conditions .

mds assessments of each resident are conducted in the first 14 days after admission and are used to develop a care plan .

a range of professionals , including nurses , attending physicians , social workers , activities professionals , and occupational , speech , and physical therapists , complete designated parts of the mds .

assessing a resident's condition in certain areas requires observation , often over a period of days .

for example , nursing staff must assess the degree of resident assistance needed during the previous 7 days — none , supervised , limited , extensive , or total dependence — to carry out the activities of daily living ( adl ) , such as using a toilet , eating , or dressing .

to obtain this information , staff completing the mds assessments are required to communicate with direct care staff , such as nursing assistants or activities aides , who have worked with the resident over different time periods .

these staff have first - hand knowledge of the resident and will often be the primary and most reliable source of information regarding resident performance of different activities .

while a registered nurse is required to verify that the mds assessment is complete , each professional staff member who contributed to the assessment must sign and attest to the accuracy of his or her portion of the assessment .

mds data are also submitted by nursing homes to states and cms for use in the nursing home survey process and to serve as the basis for adjusting payments .

cms contracts with states to periodically survey nursing homes to review the quality of care and assure that the services delivered meet the residents' assessed needs .

in fiscal year 2001 , the federal government spent about $278 million on the nursing home survey process .

effective july 1999 , the agency instructed states to begin using quality indicators derived from mds data to review the care provided to a nursing home's residents before state surveyors actually visit the home to conduct a survey .

quality indicators are essentially numeric warning signs of potential care problems , such as greater - than - expected instances of weight loss , dehydration , or pressure sores among a nursing home's residents .

they are used to rank a facility in 24 areas compared with other nursing homes in a state .

in addition , by using the quality indicators before the on - site visit to select a preliminary sample of residents to review , surveyors should be better prepared to identify potential care problems .

in addition to quality oversight , some state medicaid programs and medicare use mds data to adjust nursing home payments to reflect the expected resource needs of their residents .

such payment systems are commonly known as “case - mix” reimbursement systems .

because not all residents require the same amount of care , the rate paid for each resident is adjusted using a classification system that groups residents based on their expected costs of care .

facilities use mds data to assign residents to case - mix categories or groups that are defined according to clinical condition , functional status , and expected use of services .

in medicare , these case - mix groups are known as resource utilization groups .

each case - mix group represents beneficiaries who have similar nursing and therapy needs .

as of january 2001 , 18 states had introduced such payment systems for their medicaid programs .

as directed by the congress , hcfa in 1998 implemented a prospective payment system ( pps ) for skilled nursing facilities ( snf ) — nursing homes that are certified to serve medicare beneficiaries .

the snf pps also uses mds data to adjust nursing home payments .

states and cms use the term “accuracy reviews” to describe efforts that help ensure mds assessments accurately reflect residents' conditions .

review activities can be performed on - site — that is , at the nursing home — or off - site .

on - site reviews generally consist of documentation reviews to determine whether the resident's medical record supports the mds assessment completed by the facility .

if the mds assessment is recent , the review may also include direct observation of the resident and interviews with nursing home staff who have recently evaluated or treated the resident .

while documentation reviews may also be conducted outside of the nursing home , other off - site reviews of mds data include examining trends across facilities .

for example , off - site review activities could involve the examination of monthly reports showing the distribution of residents' case - mix categories across different facilities in a state .

similarly , off - site reviews could also involve an examination of particular mds elements , such as the distribution of adls within and across nursing homes to identify aberrant or inconsistent patterns that may indicate the need for further investigation .

off - site and on - site reviews may also be combined as a way of leveraging limited resources to conduct mds accuracy activities .

eleven states conduct separate mds accuracy reviews apart from their standard nursing home survey process .

ten of these states' reviews were in operation as of january 2001 .

an additional 7 states reported that they intend to initiate similar accuracy reviews .

all 18 of these states either currently use an mds - based medicaid payment system or plan to implement such a system .

the remaining 33 states have no plans to implement separate mds review programs and currently rely on their periodic nursing home surveys for mds oversight .

in all but one of the states with separate mds review programs operating as of january 2001 , accuracy reviews entail periodic on - site visits to nursing homes .

the reviews focus on whether a sample of mds assessments completed by the facility is supported by residents' medical records .

if the mds assessments reviewed are recent enough that residents are still in the facility and their health status has not changed , the on - site review may also be supplemented with interviews of nursing home staff familiar with the residents , as well as observations of the residents themselves , to validate the record review .

about half of these states also conduct off - site data analyses in which reviewers look for significant changes or outliers , such as facilities with unexplained large shifts in the distribution of residents across case - mix categories over a short period .

officials primarily attributed the errors found during their on - site reviews to differences in clinical interpretation and mistakes , such as a misunderstanding of mds definitions .

a few of these states have been able to show some recoupments of medicaid payments since the implementation of their on - site review programs .

of the 50 states and the district of columbia , only 11 conduct accuracy reviews of mds data that are separate from the state's nursing home survey process .

 ( see table 1. ) .

these 11 states provide care to approximately 22 percent of the nation's nursing home residents and all but one have an mds - based payment system ( virginia began conducting mds accuracy reviews in april 2001 in anticipation of adopting such a payment system in 2002 ) .

seven additional states plan to initiate separate mds reviews — three currently have an mds - based payment system and four are planning to implement such a payment system .

officials in the 10 states with separate , longer standing mds review programs said that the primary reason for implementing reviews was to ensure the accuracy of the mds data used in their payment systems .

several of these states also indicated that the use of mds data in generating quality indicators was another important consideration .

vermont officials , in particular , emphasized the link to quality of care , noting that the state had created its own mds - based quality indicators prior to hcfa's requirement to use quality indicators in nursing home surveys .

a state official told us it was critical that the mds data be accurate because vermont was making this information available to the public as well as using it internally as a normal part of the nursing home survey process .

to varying degrees , three major factors influenced the decision of 33 states not to establish separate mds review programs .

first , the majority — 28 states — do not have mds - based medicaid payment systems .

second , some states cited the cost of conducting separate reviews .

kansas , for example , reported a lack of funding and staff resources as the reason for halting a brief period of on - site visits in 1996 as a follow - up to nursing home surveys .

arkansas as well reported insufficient staff for conducting a separate review of mds data .

finally , officials in about one - third of the states without separate mds reviews volunteered that they had some assurance of the accuracy of mds data either because of training programs for persons responsible for completing mds assessments or because of the nursing home survey process .

for example , missouri operates a state funded quality improvement project in which nurses with mds training visit facilities to assist staff with the mds process and use of quality indicator reports .

north carolina also reported that its quarterly training sessions provide mds training to approximately 800 providers a year .

regarding standard surveys , connecticut and maryland reported that their nursing home survey teams reviewed mds assessments to determine if they were completed correctly and if the assessment data matched surveyor observations of the resident .

in connecticut , surveyors may also review a sample of facility mds assessments for possible errors whenever they identify aberrant or questionable data on the quality indicator reports .

officials in the 10 states with separate , longer standing mds review programs generally said that the survey process itself does not detect mds accuracy issues as effectively as separate mds review programs .

some noted that nursing home surveyors do not have time to thoroughly review mds accuracy and often review a smaller sample size than mds reviewers .

the surveyors' primary focus , they indicated , was on quality of care and resident outcomes — not accuracy of mds data .

for example , surveyors would look at whether the resident needed therapy and whether it was provided .

in contrast , the mds reviewer would calculate the total number of occupational , speech , and physical therapy minutes to ensure that the resident was placed in the appropriate case - mix category .

officials in iowa similarly noted that surveyors do not usually cite mds accuracy as a specific concern unless there are egregious mds errors , again , because the focus of the survey process is on quality of care .

nine of the 10 states with separate , longer standing mds accuracy review programs use on - site reviews to test the accuracy of mds data , generally visiting all or a significant portion of facilities in the state at least annually , if not more frequently .

 ( see app .

i for a summary of state on - site review programs. ) .

due to a lack of staff , one state — west virginia — limits its mds reviews to off - site analysis of facility - specific monthly data .

most of these states have been operating their mds review programs for 7 years or longer and developed them within a year of implementing an mds - based payment system .

three of the nine states arrive at the facility unannounced while the other six provide advanced notice ranging from 48 hours to 2 weeks .

the sample of facility mds assessments reviewed by each state varies considerably .

assessment sample sizes generally range from 10 to 40 percent of a nursing home's total residents but some states select a specific number of residents , not a percentage , and a few specifically target residents in particular case - mix categories .

for example , indiana selects a sample of 40 percent — or no less than 25 residents — across all major case - mix categories , while ohio's sample can be based on a particular case - mix category , such as residents classified as “clinically complex.” iowa officials told us that its reviewers select at least 25 percent of a facility's residents , with a minimum of 5 residents , while pennsylvania chooses 15 residents from each facility , regardless of case - mix category or facility size .

some states expand the resident sample when differences between the mds assessment and supporting documentation reach a certain threshold .

for example , if the on - site review for the initial sample in iowa finds that 25 percent or more of the mds assessments have errors , a supplemental random sample is selected for review .

while a few states limit their sample to medicaid residents only , most select assessments to review from the entire nursing home's population .

on - site reviews generally involve a comparison of the documentation in the resident's medical record to the mds assessment prepared by the facility .

generally , the on - site process also allows reviewers to interview nursing home staff and to directly observe residents , permitting a better understanding of the documentation in a resident's medical record and clarifying any discrepancies that may exist .

staff interviews and resident observations can enhance the reviewer's understanding of the resident's condition and allow a more thorough mds review than one relying primarily on documentation .

however , as the interval between the facility's mds assessment and the on - site review increases , staff interviews and resident observations become less reliable and more difficult to conduct .

for example , staff knowledge of a particular patient may fade over time , the patient's health status may change , or the patient may be discharged from the facility .

pennsylvania officials , who reported reviewing assessments that were 6 to 12 months old , told us that the state's mds reviews tended to identify whether the nursing home had adequate documentation .

reviewing such old assessments tends to focus the review process on the adequacy of the documentation rather than on whether the mds assessment was accurate .

four of the nine states review assessments between 30 and 90 days old , a process that likely increases the value of interviews and observation .

the combination of interviews and observations can be valuable , but limiting reviews to only recent mds assessments and providing homes advance notice may undermine the effectiveness of on - site reviews .

under such circumstances , facilities have an opportunity to focus on the accuracy of their recent assessments , particularly if the nursing home knows when their reviews will occur , instead of adopting facility - wide practices that increase the accuracy of all mds assessments .

based on their on - site reviews , officials in the nine states identified seven areas as having a high potential for mds errors , with two areas most often identified as being among the highest potential for error: ( 1 ) mood and behavior and ( 2 ) nursing rehabilitation and restorative care .

 ( see fig .

1. ) .

assessments of resident mood and behavior are used to calculate quality indicators and , along with nursing rehabilitation and restorative care , are often important in determining nursing home payments .

cms indicated that several of the mds elements cited in figure 1 were also identified by a cms contractor as areas of concern .

officials in most states with separate on - site review programs told us that errors discovered during their on - site reviews often resulted from differences in clinical interpretation or mistakes , such as a misunderstanding of mds definitions by those responsible for completing mds assessments .

officials in only four of the nine states were able to tell us whether the errors identified in their mds reviews on average resulted in a case - mix category that was too high or too low .

two of these states reported roughly equal numbers of mds errors that inappropriately placed a resident in either a higher or lower case - mix category ; a third indicated that errors more often resulted in higher payments ; and a fourth found that errors typically resulted in payments that were too low .

none of the nine states track whether quality indicator data were affected by mds errors .

two of the 10 states with mds review programs were able to tell us the amount of medicaid recoupments resulting from inaccurate mds assessments .

from state fiscal years 1994 through 1997 , south dakota officials reported that the state had recouped about $360,000 as a result of recalculating nursing home payments after mds reviews .

west virginia received $1 million in 1999 related to mds errors for physical therapy discovered during a 1995 on - site review at a nursing home .

officials in five additional states told us that they recalculate nursing home payments when mds errors are found , but could not provide the amount recovered .

of the 10 states with longer standing mds review programs , four use off - site analyses to supplement their on - site reviews , while one state relies on off - site analyses exclusively .

both maine and washington examine mds data off - site to monitor changes by facility in the mix of residents across case - mix categories .

such changes may help identify aberrant or inconsistent patterns that may indicate the need for further investigation .

ohio , a state with approximately 1,000 facilities — more than any other state that conducts mds reviews — analyzes data off - site to identify facilities with increased medicaid payments and changes in case - mix categories to select the approximately 20 percent of facilities visited each year .

west virginia has eliminated its on - site reviews and now focuses solely on analyzing monthly reports for its 141 facilities — for example , significant changes in case - mix categories or adls across consecutive mds assessments .

in addition to informally sharing results of off - site reviews with the state nursing home surveyors , west virginia is trying to formalize a process in which off - site reviews could trigger additional on - site or off - site documentation reviews .

officials in the nine states with on - site review programs consistently cited three features of their review programs that strengthened the ability of nursing home staff to complete accurate mds assessments and thus decrease errors: ( 1 ) the actual presence of reviewers , ( 2 ) provider education , and ( 3 ) remedies that include corrective action plans and financial penalties .

on - site reviews , for example , underscore the state's interest in mds accuracy and provide an opportunity to train and coach those who are responsible for completing mds assessments .

similarly , the errors discovered during on - site reviews guide the development of more formal training sessions that are offered by the state outside of the nursing home .

requiring nursing homes to prepare corrective action plans and imposing financial penalties signal the importance of mds accuracy to facilities and are tools to improve the accuracy of the mds data .

as a result of these efforts , some states have been able to show a notable decrease in their overall error rates .

most of the nine states view on - site visits and training as interrelated elements that form the foundation of their mds review programs .

state officials said that nursing homes pay more attention to properly documenting and completing the mds assessments because reviewers visit the facilities regularly .

on - site visits also allow reviewers to discuss mds documentation issues or requirements with staff , providing an opportunity for informal mds training .

for example , indiana officials told us that 2 to 3 hours of education are a routine part of each facility's mds review .

noting the high staff turnover rates in nursing homes , many states reported that frequent training for the staff responsible for completing mds assessments is critical .

officials in seven of the nine states with on - site reviews told us that high staff turnover was one of the top three factors contributing to mds errors in their states .

in addition , many of the reasons cited for mds errors — such as a misunderstanding of mds definitions and other mistakes — reinforce the need for training .

states with on - site reviews use the process to guide provider education activities — both on - site and off - site .

for example , during pennsylvania's annual mds reviews of all nursing homes , state reviewers determine the types of training needed .

according to state officials , the state uses the results of these reviews to shape and provide facility - specific training , if it is needed , within a month of the review and subsequently conducts a follow - up visit to see if the facility is improving in these areas .

they indicated that all 685 homes visited during 2000 , the first year of this approach , were provided with some type of training .

to improve mds accuracy , several states also provide voluntary training opportunities outside of the nursing home .

maine , iowa , indiana , and south dakota , for example , provide mds training regularly throughout the state , rotating the location of the training by region so that it is accessible to staff from all facilities .

while states generally emphasized on - site reviews and training as the primary ways to improve the accuracy of the mds data , some reported that they have also instituted certain remedies , such as corrective action plans and financial penalties .

indiana and pennsylvania , for example , require facilities to submit a corrective action plan detailing how the facility will address errors identified during an on - site review .

two states — maine and indiana — impose financial penalties .

maine has instituted financial penalties for recurring serious errors , collecting approximately $390,000 since late 1995 .

maine also requires facilities with any mds errors that result in a case - mix category change to complete and submit a corrected mds assessment for the resident .

while indiana imposes financial penalties , it does not view them as the primary tool for improving mds accuracy .

rather , officials attributed a decrease in mds errors to the education of providers and the on - site presence of reviewers .

other remedies cited by states include conducting more frequent on - site mds reviews and referring suspected cases of fraud to their state's medicaid fraud control unit .

five of the nine states that conduct on - site mds reviews told us that their efforts have resulted in a notable decrease in mds errors across all facilities since the implementation of their review programs .

 ( see table 2. ) .

south dakota officials , for example , reported that the percentage of assessments with mds errors across facilities had decreased from approximately 85 percent to 10 percent since the implementation of the state's mds review program in 1993 .

similarly , indiana reported a decrease in the statewide average error rate from 75 percent to 30 percent of assessments in 1 year's time .

four states could not provide these data .

in calculating these decreases , three of the five states — indiana , maine , and south dakota — define mds errors as an unsupported mds assessment that caused the case - mix category to be inaccurate .

iowa's definition , however , includes mds elements that are not supported by medical record documentation , observation , or interviews , regardless of whether the mds error changed the case - mix category .

similarly , while pennsylvania does not limit errors to those that changed the case - mix category , the state defines errors as a subset of mds elements that are not supported by the medical record .

following implementation of medicare's mds - based payment system in 1998 , hcfa began building the foundation for its own separate review program — distinct from state efforts — to help ensure the accuracy of mds data .

in the course of developing and testing accuracy review approaches , its contractor found widespread mds errors that resulted in a change in medicare payment categories for 67 percent of the resident assessments sampled .

in september 2001 , cms awarded a new contract to implement a nationwide mds review program over a 2- to 3-year period .

despite the benefits of on - site reviews , as demonstrated by states with separate review programs , the current plan involves conducting on - site reviews in fewer than 200 of the nation's 17,000 nursing homes each year .

in addition , the contractor's combined on - site and off - site reviews to evaluate mds accuracy will involve only about 1 percent of the approximately 14.7 million mds assessments expected to be prepared in 2001 .

in contrast , states that conduct separate on - site mds reviews typically visit all or a significant portion of their nursing homes and generally examine from 10 to 40 percent of assessments .

while cms' approach may yield some broad sense of the accuracy of mds assessments on an aggregate level , it may be insufficient to help ensure the accuracy of mds assessments in most of the nation's nursing homes .

at present , it does not appear that cms plans to leverage the considerable resources already devoted to state nursing home surveys and states' separate mds review programs that together entail a routine on - site presence in all nursing homes nationwide .

nor does it plan to more systematically evaluate the performance of state survey agencies regarding mds accuracy through its own federal comparative surveys .

finally , cms is not requiring nursing homes to provide documentation for the full mds assessment , which could undermine the efficacy of its mds reviews .

in september 1998 , hcfa contracted with abt associates to develop and test various on - site and off - site approaches for verifying and improving the accuracy of mds data .

two of the approaches resembled state on - site mds reviews and the off - site documentation reviews performed by cms contractors that review medicare claims .

another approach used off - site data analysis to target facilities for on - site review .

to determine the effectiveness of the approaches tested in identifying mds inaccuracies , abt compared the errors found under each approach to those found in its “reference standard” — independent assessments performed by mds - trained nurses hired by abt for approximately 600 residents in 30 facilities in three states .

abt found errors in every facility , with little variation in the percentage of assessments with errors across facilities .

on average , the errors found affected case - mix categories in 67 percent of the sampled medicare assessments .

abt concluded that the errors did not result in systematic overpayments or underpayments to facilities even though there were more errors that placed residents in too high as opposed to too low a case - mix category .

abt did not determine , however , the extent to which errors affected quality indicators .

due to the prevalence of errors , abt recommended a review program that included periodically visiting all facilities during the program's first several years .

recognizing the expense of visiting every facility , however , abt also recommended eventually transitioning to the use of off - site mechanisms to target facilities and specific assessments for on - site review .

abt also made recommendations to address the underlying causes of mds errors: simplifying the mds assessment tool , clarifying certain mds definitions ( particularly for adls ) , and improving mds training for facilities .

building on the work of abt associates , in the summer of 2000 , the agency began formulating its own distinct nationwide review program to address long - term mds monitoring needs .

the agency developed a request for proposal for mds data assessment and verification activities and sought proposals from its 12 program safeguard contractors .

on september 28 , 2001 , cms awarded a 3-year contract for approximately $26 million to computer sciences corporation .

the contract calls for the initiation of on - site and off - site reviews by late spring 2002 , but the full scope of mds review activities will not be underway until the second year of the contract .

 ( see table 3. ) .

despite this broad approach , the contractor is not specifically tasked with assessing the adequacy of each state's mds reviews .

instead , it is required to develop a strategy for coordinating its review activities with other state and federal oversight , such as the selection of facilities and the timing of visits , to avoid unnecessary overlap with routine nursing home surveys or states' separate mds review programs .

this approach does not appear to build on the benefits of on - site visits that are already occurring as part of state review activities .

rather , the contract specifies independent federal on - site and off - site reviews of roughly 1 percent of the approximately 14.7 million mds assessments expected to be prepared in 2001 — 80,000 during the first contract year and 130,000 per year thereafter .

the contractor , however , tentatively recommended that the majority of reviews , about 90 percent , be conducted off - site .

according to cms , these off - site reviews could include a range of activities , such as the off - site targeting approaches developed by abt or medical record reviews similar to those conducted by cms contractors for purposes of reviewing medicare claims .

in addition , the contractor is expected to conduct a range of off - site data analyses that could include a large number of mds assessments .

the remaining 10 percent of mds assessments — representing fewer than 200 of the nation's 17,000 nursing homes — would be reviewed on - site each year .

this limited on - site presence is inconsistent with abt's earlier recommendation regarding the benefits of on - site reviews in detecting accuracy problems , and with the view of almost all of the states with separate mds review programs that an on - site presence at a significant number of their nursing homes is central to their review efforts .

while cms' approach may yield some broad sense of the accuracy of mds assessments on an aggregate level , it appears to be insufficient to provide confidence about the accuracy of mds assessments in the vast bulk of nursing homes nationwide .

given the substantial resources invested in on - site nursing home visits associated with standard surveys or states' separate mds review programs , cms' mds review program could view states' routine presence as the cornerstone of its program and instead focus its efforts on ensuring the adequacy of state reviews .

cms could build on its established federal monitoring survey process for nursing home oversight .

the agency is required by statute to annually resurvey at least 5 percent of all nursing homes that participate in medicare and medicaid .

one of the ways cms accomplishes this requirement is by conducting nursing home comparative surveys to independently assess the states' performance in their nursing home survey process .

during a comparative survey , a federal team independently surveys a nursing home recently inspected by a state in order to compare and contrast the results .

these federal comparative surveys have been found to be most effective when completed in close proximity to the state survey and involve the same sample of nursing home residents to the maximum extent possible .

abt also attempted to review recently completed mds assessments .

finally , a potential issue that could undermine the efficacy of the federal mds accuracy reviews involves the level of documentation required to support an mds assessment .

cms requires specific documentation for some mds elements , but officials said that the mds itself — which can simply consist of checking off boxes or selecting multiple choice answers on the assessment form — generally constitutes support for the assessment without any additional documentation .

cms officials consider the mds assessment form to have equal weight with the other components of the medical record , such as physician notes and documentation of services provided .

as a result , cms asserts that the assessment must be consistent with , but need not duplicate , the medical record .

in contrast , most of the nine states with separate on - site review programs require that support for each mds element that they review be independently documented in the medical record .

state officials told us that certain mds elements , such as adls , are important to thoroughly document because they require observation of many activities by different nursing home staff over several days .

as a result , some of these states require the use of separate flow charts or tables to better document adls .

similarly , some states require documentation for short - term memory loss rather than accepting a nursing home's assertion that a resident has this condition .

cms' training manual describes several appropriate tests for identifying memory loss , such as having a resident describe a recent event .

in one of its december 2000 reports , the hhs oig recommended that nursing homes be required to establish an “audit trail” to support certain mds elements .

hcfa disagreed , noting that it does not expect all information in the mds to be duplicated elsewhere in the medical record .

however , given the uses of mds data , especially in adjusting nursing home payments and producing quality indicators , documenting the basis for the mds assessments in the medical record is critical to assessing their accuracy .

in complying with federal nursing home participation and quality requirements , about 17,000 nursing homes were expected to produce almost 15 million mds assessments during 2001 on behalf of their residents .

this substantial investment of nursing home staff time contributes to multiple functions , including establishing patient care plans , assisting with quality oversight , and setting nursing home payments that account for variation in resident care needs .

while some states , particularly those with mds - based medicaid payment systems , stated that ensuring mds accuracy requires establishing a separate mds review program , many others rely on standard nursing home surveys to assess the data's accuracy .

flexibility in designing accuracy review programs that fit specific state needs , however , should not preclude achieving the important goal of ensuring accountability across state programs .

it is cms' responsibility to consistently ensure that states are fulfilling statutory requirements to accurately assess and provide for the care needs of nursing home residents .

the level of federal financial support for state mds accuracy activities is already substantial .

the federal government pays up to 75 percent of the cost of separate state mds review activities and in fiscal year 2001 contributed $278 million toward the cost of the state nursing home survey process , which is intended in part to review mds accuracy .

instead of establishing a distinct but limited federal review program , reorienting the thrust of its review program in order to complement ongoing state mds accuracy efforts could prove to be a more efficient and effective means to achieve cms' stated goals .

such a shift in focus should include ( 1 ) taking full advantage of the periodic on - site visits already conducted at every nursing home nationwide through the routine state survey process , ( 2 ) ensuring that the federal mds review process is designed and sufficient to consistently assess the performance of all states' reviews for mds accuracy , and ( 3 ) providing additional guidance , training , and other technical guidance to states as needed to facilitate their efforts .

with its established federal monitoring system for nursing home surveys — especially the comparative survey process — that helps assess state performance in conducting the nursing home survey process , cms has a ready mechanism in place that it can use to systematically assess state performance for this important task .

finally , to help improve the effectiveness of mds review activities , cms should take steps to ensure that each mds assessment is adequately supported in the medical record .

with the goal of complementing and leveraging the considerable federal and state resources already devoted to nursing home surveys and to separate mds accuracy review programs , we recommend that the administrator of cms review the adequacy of current state efforts to ensure the accuracy of mds data , and provide , where necessary , additional guidance , training , and technical assistance ; monitor the adequacy of state mds accuracy activities on an ongoing basis , such as through the use of the established federal comparative survey process ; and provide guidance to state agencies and nursing homes that sufficient evidentiary documentation to support the full mds assessment be included in residents' medical records .

we provided a draft of this report to cms and the 10 states with separate mds accuracy programs for their review and comment .

 ( see app .

ii for cms' comments. ) .

cms agreed with the importance of assessing and monitoring the adequacy of state mds accuracy efforts .

cms also recognized that the mds affects reimbursement and care planning and that it is essential that the assessment data reflect the resident's health status so that the resident may receive the appropriate quality care and that providers are appropriately reimbursed .

however , cms' comments did not indicate that it planned to implement our recommendations and reorient its mds review program .

rather , cms' comments suggested that its current efforts provide adequate oversight of state activities and complement state efforts .

while cms stated that it currently evaluates , assesses , and monitors the accuracy of the mds through the nursing home survey process , it also acknowledged the wide variation in the adequacy of current state accuracy review efforts .

our work in the 10 states with separate mds review programs raised serious questions about the thoroughness and adequacy of the nursing home survey process for reviewing mds accuracy .

officials in many of these states said that the survey process itself does not detect mds accuracy issues as effectively as separate mds review programs .

surveyors , we were told , do not have time to thoroughly review mds accuracy and their focus is on quality of care and resident outcomes , not accuracy of mds data .

in response to our recommendations on assessing and monitoring the adequacy of each state's mds reviews , cms commented that it would consider adding a new standard to the state performance expectations that the agency initiated in october 2000 .

cms indicated that the state agency performance review program would result in a more comprehensive assessment of state activities related to mds accuracy than could be obtained through the comparative survey process .

cms also outlined planned analytic activities — such as a review of existing state and private sector mds review methodologies and instruments , ongoing communications with states to share the knowledge gained , and comprehensive analyses of mds data to identify systemic accuracy problems within states as well as across states — that it believes will help to evaluate state performance .

we agree that some of cms' proposed analytic activities could provide useful feedback to states on problem areas at the provider , state , region , and national levels .

similarly , the addition of mds accuracy activities to its state performance standards for nursing home surveys , which cms is considering , has merit .

while cms plans to consider adding a new standard to its state agency performance review program , the agency has a mechanism in place — the comparative survey process — that it could readily use to systematically assess state performance .

however , cms apparently does not intend to do so .

based on our discussions with agency officials , it does not appear that cms' approach will yield a consistent evaluation of each state's performance .

we continue to believe that assessment and routine monitoring of each state's efforts should be the cornerstone of cms' review program .

as we previously noted , the agency's proposed on - site and off - site reviews of mds assessments are too limited to systematically assess mds accuracy in each state and would consume resources that could be devoted to complementing and overseeing ongoing state activities .

a comprehensive review of the adequacy of state mds accuracy activities , particularly in those states without a separate review program , is essential to establish a baseline and to allow cms to more efficiently target additional guidance , training , or technical assistance that it acknowledged is necessary .

cms did not agree with our recommendation that it should provide guidance to states regarding adequate documentation in the medical record for each mds assessment .

cms stated that requiring documentation of all mds items places an unnecessary burden on facilities .

skilled reviewers , it stated , should be able to assess the accuracy of completed mds assessments through a combination of medical record review , observation , and interviews .

cms further stated that requiring duplicative documentation might result in documentation that is manufactured and of questionable accuracy .

of course , the potential for manufactured data could also be an issue with the mds , when supporting documentation is absent or limited .

without adequate documentation , it is unclear whether the nursing home staff sufficiently observed the resident to determine his or her care needs or merely checked off a box on the assessment form .

we continue to believe , as do most of the states with separate mds review programs , that requiring documentation for the full mds assessment is necessary to ensure the accuracy of mds data .

in our view , however , this documentation need not be duplicative of that which is already in the medical record but rather demonstrative of the basis for the higher - level summary judgments about a resident's condition .

some states have already developed tools to accomplish this and in commenting on a draft of this report , two states said that cms should establish documentation requirements for responses on the mds .

in addition , the discrepancies cited by the hhs oig in its studies stemmed from inconsistencies between mds assessments and documentation in residents' medical records .

the oig acknowledged that the results of its analyses were limited by the information available in the medical record — for example , when a facility mds assessment was based on resident observation , the facility may not have documented these observations in the medical record .

the importance of adequate documentation is further reinforced by the fact that using interviews and observation to validate mds assessments may often not be possible , particularly for residents who have been discharged from the nursing home before an mds accuracy review .

given the importance of mds data in adjusting nursing home payments and guiding resident care , documenting the basis for the mds assessment — in a way that can be independently validated — is critical to achieving its intended purposes .

cms provided additional clarifying information that we incorporated as appropriate .

in addition , the states that commented on the draft report generally concurred with our findings and provided technical comments that we incorporated as appropriate .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we will not distribute it until 30 days after its date .

at that time , we will send copies to the administrator of cms ; appropriate congressional committees ; and other interested parties .

we will also make copies available to others upon request .

if you or your staff have any questions , please call me at ( 202 ) 512-7114 or walter ochinko at ( 202 ) 512-7157 .

major contributors to this report include carol carter , laura sutton elsberg , leslie gordon , and sandra gove .

average time lapse between facility mds and state review 90 days 1998 ( payment ) 1998 ( reviews ) state reviews most recent mds assessment 1993 ( payment ) 1994 ( reviews ) minimum of 10 assessments per facility 1988 ( payment ) 1992 ( reviews ) at least 20 percent of residents in facility 1993 ( payment ) 1994 ( reviews ) year state began: mds - based payment system mds reviews 1996 ( payment ) 1994 ( reviews ) frequency of on - site reviews ( all facilities unless otherwise noted ) average time lapse between facility mds and state review 6-12 months 1993 ( payment ) 1993 ( reviews ) at least 25 percent of residents in facility 1992 ( payment ) 1992 ( reviews ) mds never older than 90 days 1998 ( payment ) 1998 ( reviews ) annually ( staff also conduct quarterly quality review audits ) yes ( effective 10 / 1 / 01 ) the types of mds errors that commonly reoccur relate to misapplication of mds definitions , and may in large part be due to facility staff turnover .

in commenting on a draft of this report , officials told us that these errors are consistent with those found in other states with mds - based payment systems .

state plans to publish the results of mds accuracy reviews on a web page to prevent simple but recurring errors virginia is not included because of the newness of its mds review program ( began operating in april 2001 ) .

we have included the nine other states with longer standing on - site review programs .

this column reflects the frequency of initial reviews for each facility .

some states conduct follow - up reviews more frequently for facilities where problems have been identified .

we asked states to select from the following categories: more important , equally important , and less important .

indiana officials added the following language to characterize mds errors: an error occurs when the audit findings are different from the facility's transmitted mds data and those differences result in a different case - mix category .

