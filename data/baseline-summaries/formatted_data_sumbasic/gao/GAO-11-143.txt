the department of energy's ( doe ) office of environmental management ( em ) is responsible for one of the world's largest environmental cleanup programs , the treatment and disposal of radioactive and hazardous waste created as a by - product of producing nuclear weapons and energy research .

the largest component of the cleanup mission is the treatment and disposal of millions of gallons of highly radioactive waste stored in aging and leak - prone underground tanks .

in addition , radioactive and hazardous contamination has migrated through the soil into the groundwater , posing a significant threat to human health and the environment .

em spends about $6 billion annually to clean up its sites .

as of february 2010 , doe estimated that the overall cost to complete the entire cleanup mission will be between $275 billion and $329 billion .

two doe sites — the hanford site in southeastern washington state and the savannah river site ( srs ) in south carolina — account for more than one - half of these annual costs and about 60 percent of the total projected cost of the overall cleanup of nuclear waste at doe sites .

as with nearly all of doe's missions , the majority of the work at these two sites is performed by private firms under contract with doe .

one tool em uses to help decide how to clean up this radioactive and hazardous waste is computer simulation modeling — hereafter referred to as computer models — where the behavior of physical and biogeochemical processes are described through the use of mathematical formulas .

for example , computer models may be used to simulate a process such as the transport of contamination through the soil and groundwater or to predict how long it will take to empty waste tanks in a certain sequence .

the results from these models often contribute to the basis for cleanup decisions that can cost hundreds of millions of dollars to implement .

the set of processes used to ensure the quality of computer software and models — known as “quality assurance” — has been a concern in the past .

in 2000 and again in 2002 , the defense nuclear facilities safety board raised concerns that doe did not have adequate controls to ensure the reliability of software used in nuclear facilities .

the board noted that many systems used to maintain safety in nuclear or hazardous facilities , such as ventilation system controls , rely on the smooth operation of software to prevent accidents .

another concern regarding software and modeling was raised at hanford in 2006 , when a doe headquarters review team found that the absence of quality assurance oversight activities and the lack of formal data validation and verification led to data inaccuracies in modeling used to support the development of an environmental impact statement .

these problems prompted doe to undertake a new modeling effort , delaying the environmental impact statement .

in response to your request , this report ( 1 ) describes how em uses computer models in cleanup decisions ; ( 2 ) evaluates how em ensures the quality of its computer models ; and , ( 3 ) assesses em's overall strategy for managing its computer models .

to address these objectives , we gathered and reviewed information on the types of cleanup decisions doe has made at hanford and srs .

for each site , we selected examples of three types of decisions that were representative of major decisions doe has made at these sites between 2002 and 2010 — ( 1 ) decisions made under environmental statutes , including the comprehensive environmental response , compensation , and liability act of 1980 , as amended ( cercla ) — which addresses specific environmental remediation solutions for a cleanup site — and the national environmental policy act ( nepa ) , as amended — under which doe evaluates the impacts to human health and the environment of proposed cleanup strategies and possible alternatives ; ( 2 ) performance assessments under doe orders governing radioactive waste management ; and ( 3 ) budgeting and planning decisions for liquid tank waste treatment and disposal .

we then selected , based on input from em officials , the main models that were used to support these decisions at the two sites .

we obtained and reviewed documentation on the computer models used and decisions made , and interviewed officials from doe headquarters to determine how the models were used in these decisions .

we analyzed this information to determine how the results of computer models were used in making cleanup decisions and the importance of the results .

we also obtained and reviewed documentation showing the standards the models were required to meet , as well as doe , contractor , and other quality assurance assessments indicating whether these standards were met .

we also interviewed officials from the environmental protection agency ( epa ) , the national research council , the defense nuclear facilities safety board , and other organizations about existing standards for the use and implementation of computer modeling software and modeling coordination strategies .

we visited both hanford and srs and spoke with em officials and contractor staff at both locations to better understand the use of models in planning and cleanup decisions , as well as em oversight of the models .

we focused our review on model standards and the use of models in decisions , not on the quality of the models themselves or of their output .

we conducted this performance audit from october 2009 to february 2011 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

since the 1940s , doe and its predecessors have operated a nationwide complex of facilities used to research , design , and manufacture nuclear weapons and related technologies .

the environmental legacy of nuclear weapons production at dozens of these sites across the united states includes contaminated buildings , soil , water resources , and large volumes of radioactive and hazardous wastes that require treatment , storage , and disposal .

the two sites that account for the majority of the costs of the cleanup effort — hanford and srs — were established in the 1940s and 1950s , respectively , to produce plutonium and other nuclear materials needed to manufacture nuclear weapons .

em manages cleanup projects at these and other sites that involve multiple activities to treat and dispose of a wide variety of radioactive and hazardous wastes .

under federal and state laws , em must clean up radioactive and hazardous substances in accordance with specified standards and regulatory requirements .

em carries out its cleanup activities under the requirements of federal environmental laws that include , among others , cercla and nepa .

cercla requires em to evaluate the nature and extent of contamination at the sites and determine what cleanup remedies , if any , are necessary to protect human health and the environment into the future .

under nepa , em must prepare an environmental impact statement that assesses the environmental effects for a proposed agency action , all reasonable alternatives , and the no - action alternative .

under both the cercla and nepa processes , em analyzes proposed remedial action alternatives according to established criteria , invites and considers public comment , and prepares a record of decision that documents the selected agency action .

if the cleanup method selected under cercla or nepa will result in disposal of waste at an on - site disposal facility , em is then required , under doe's radioactive waste management order — doe order 435.1 — to ensure that waste management activities at each disposal facility are designed , constructed , and operated in a manner that protects workers , the public , and the environment .

em does this by completing a “performance assessment” of the selected cleanup method .

to guide the implementation of selected cleanup methods , em and its contractors may prepare a “system plan” that provides the basis for scheduling cleanup operations and preparing budget requests .

for example , both hanford and srs have prepared system plans for treating and disposing of liquid radioactive waste stored in aging and leak - prone underground tanks .

em officials at doe headquarters and field offices oversee cleanup activities at the sites , but the work itself is carried out primarily by private firms contracting with doe .

em applies different approaches to managing cleanup activities , depending on the type and extent of contamination and state and / or federal requirements with which it needs to comply .

in addition , doe has agreements with state and federal regulators , known as federal facility agreements , to clean up the hanford and srs sites .

the agreements lay out legally binding milestones for completing major steps in the waste treatment and cleanup process .

epa officials , as well as officials with environmental agencies in the states where em sites are located , enforce applicable federal and state environmental laws and oversee and advise em on its cleanup efforts .

one tool em uses in support of cleanup decision analyses is computer modeling .

although the computer models used across em sites vary , they have certain common characteristics .

in general , computer models are based on mathematical formulas that are intended to reflect physical , biogeochemical , mechanical , or thermal processes in simplified ways .

for example , a computer model can simulate the movement of contamination through the soil and groundwater or simulate the transfer of high - level radioactive waste from underground storage tanks to facilities where the waste will be treated .

appendix ii details the key computer models used in the cleanup decisions we reviewed at hanford and srs .

em uses computer models to provide critical information for its decision - making process .

first , computer models provide information that em uses to analyze the effectiveness of alternative actions to clean up radioactive waste .

second , once a cleanup strategy has been selected , computer modeling provides information that em needs to assess the performance of the selected cleanup strategy in reducing risks to human health and the environment .

third , em uses computer models to simulate operations in the cleanup process , providing the basis for planning cleanup efforts and for making annual budget requests .

em's decision making for its cleanup efforts is based on meeting federal and state requirements ; input from state , local , and regional stakeholders ; and other considerations , including the costs of cleanup actions .

computer models provide critical information that em needs to assess compliance with regulatory requirements when seeking to identify and select alternatives for cleaning up radioactive and hazardous wastes , as well as contaminated soil and groundwater at its sites .

em's cleanup decisions are guided by several federal and state environmental laws , including cercla and nepa , which both set forth processes related to cleanup decisions .

in the case of cercla , em determines the nature and extent of the contamination , assesses various cleanup alternatives , and selects the best alternatives according to evaluation criteria that include , among other things , protection of human health and the environment , ease of implementing the alternative , state and community acceptance , and cost .

to accomplish these steps , em uses computer modeling to , among other things , simulate the movement of contaminants through soil and groundwater over many years assuming no cleanup action is taken .

projected contamination levels , migration pathways , and contamination travel timelines are provided by simulations and are evaluated to determine whether regulatory standards will likely be exceeded in the future .

if action is needed , then modeling simulations may be conducted for a number of different cleanup alternatives .

for example , em used modeling to assess contamination and the potential effectiveness of various cleanup strategies at srs's c - area burning / rubble pit .

used during the 1960s as a trash pit to dispose of organic solvents , waste oils , paper , plastics , and rubble , srs burned the contents of the pit periodically to reduce its volume .

eventually , srs used the pit for the disposal of inert rubble , finally covering it with two feet of soil in the early 1980s .

however , the disposal of these materials and periodic burning resulted in hazardous substance contamination of the surrounding soil and groundwater .

between 1999 and 2004 , em implemented several actions to clean up the majority of the area's contamination .

following these actions , em used computer models to simulate the movement of the remaining contamination through the soil and groundwater over the next 1,000 years .

information provided by this modeling helped em to identify the remaining risks to human health and the environment and to identify actions to clean up the remaining contamination .

using this information , in conjunction with other criteria such as additional site data , input from federal and state regulators and the public , and the availability of an appropriate cleanup technology , em selected a final cleanup remedy .

this remedy , which is ongoing and combines several different cleanup technologies , was estimated in 2008 to cost , in present - worth dollars , about $1.9 million over a 70-year period .

in implementing cercla , doe focuses on discrete facilities or areas within a site that are being remediated , making limited assessments of cumulative impacts .

by contrast , under nepa , em generally prepares environmental impact statements that assess the environmental impacts — including cumulative impacts — of a proposed cleanup action , all reasonable alternatives , and taking no action .

for example , the environmental impact statement for closing underground liquid radioactive waste tanks at hanford — which , as of november 2010 was still in draft form — includes an analysis of the potential environmental impact of various options for treating and disposing of about 55 million gallons of mixed radioactive and hazardous waste and closing 149 underground radioactive waste tanks .

the draft environmental impact statement includes an analysis of 11 tank waste treatment and closure alternatives , including a no - action alternative .

these alternatives range in cost from about $3 billion to nearly $252 billion , excluding the costs associated with the final disposal of the treated waste .

in the draft environmental impact statement , em used computer models to simulate the movement of contamination through soil and groundwater over a period of 10,000 years for each of the cleanup alternatives .

as with cercla modeling , the results of the computer models were used to estimate the remaining risks to human health and the environment following the completion of each cleanup alternative and these risks were then compared with requirements .

the results of these models will be used along with other information such as input from regulators and the public and the costs of each alternative when em selects the alternative it will eventually implement .

after a particular cleanup alternative is selected , em also uses computer modeling to demonstrate that the cleanup activity will result in reduced future contamination levels that meet regulatory requirements .

if the cleanup method selected under cercla or nepa will result in disposal of waste at an on - site disposal facility , em is then required , under doe's radioactive waste management order — doe order 435.1 — to ensure that waste management activities at each disposal facility are designed , constructed , and operated in a manner that protects workers , the public , and the environment .

to meet the requirements of the order , em completes a “performance assessment” of the selected cleanup method .

under the order , this performance assessment is to document that the disposal facility is designed , constructed , and operated in a manner that protects workers , the public , and the environment .

the performance assessment also is to project the release of contamination into the soil and groundwater from a site after cleanup and must include calculations of potential chemical doses to members of the public in the future .

for example , in march 2010 , srs issued a performance assessment of a cleanup and closure strategy for a group of 20 underground liquid radioactive waste tanks , known as the f - tank farm .

the performance assessment evaluated closing the underground waste tanks and filling them with a cement - like substance called grout — the alternative selected following completion of srs's 2002 environmental impact statement .

computer modeling was used extensively to prepare this performance assessment .

specifically , computer modeling was performed using two different types of models .

the first computer model was used to perform human health and environmental risk calculations and to calculate radiation doses that could be compared to the maximum level allowed by federal and state requirements .

the second model was used to analyze sensitivities and uncertainties in the results of the first model .

em also uses computer models for lifecycle planning , scheduling , and budgeting for its cleanup activities .

computer models provide important information that em and its contractors use to develop system plans that outline the schedules for cleanup activities at em sites .

outputs from computer models and databases are used to create tables , charts , and schedules that are published in the system plans and inform annual budget requests for cleanup activities .

for example , at hanford , a computer model known as the hanford tank waste operations simulator is designed to track the retrieval and treatment of over 55 million gallons of radioactive waste held in underground storage tanks .

according to the most recent hanford tank waste system plan , which was issued in november 2010 , the model projects the chemical and radiological characteristics of batches of waste that are to be sent to a $12.2 billion waste treatment plant that is being built at hanford to treat this waste .

the model also provides scheduling information the contractor uses to project near - and long - term costs and schedules .

similarly , srs uses a computer model known as spaceman plus™ to support the site's liquid waste system plan , which was issued in january 2010 .

for example , project work schedules for srs's tank waste program are guided by this model .

the model also simulates how the tank farms integrate with waste processing facilities and tracks the movement of waste throughout the liquid waste system .

output from the model was used to provide tables and schedules found in the appendixes of srs's system plan that details the specific cleanup activities that are to be accomplished .

these tables and schedules are used as part of the basis for determining the costs of completing those activities .

this information , in turn , allows doe and its contractors to generate annual budget requests .

although em uses general departmental quality assurance policies and standards that apply to computer models and relies on contractors to implement specific procedures that reflect these policies and standards , these policies and standards do not specifically provide guidance on ensuring the quality of the computer models used in cleanup decisions .

moreover , em officials have not regularly performed periodic quality assurance assessments , as required by doe policy to oversee contractors' development and use of cleanup models and the models' associated software .

in addition , doe and others have identified quality assurance problems .

for example , the state of washington has cited flaws in a model em uses to analyze soil and groundwater contamination and has told em that it will no longer accept the use of this model for chemical exposure analysis at hanford .

doe addresses quality through various departmental policies and industry standards ; however these policies and standards do not specifically provide guidance on ensuring the quality of the computer models used in cleanup decisions .

specifically , doe's primary quality assurance policy — doe order 414.1c — provides general requirements em and its contractors must meet to ensure all work at the cleanup sites is carried out correctly and effectively , including the development and use of computer models .

these requirements include developing a quality assurance program , training staff how to check the quality of their work , and providing for independent assessments of quality .

a manual accompanying this order describes acceptable , nonmandatory methods for specifically ensuring quality of “safety software.” safety software is described in the manual as software used to design , manage , or support nuclear facilities .

however , the manual is less clear on how to assure quality in computer models .

furthermore , it does not clearly address the use of computer software not considered as safety software , such as those used by computer models that support doe's cleanup decisions .

doe's quality assurance order also requires contractors to select and comply with an appropriate set of industry standards for all work , including computer modeling .

one common set of standards was developed by the american society of mechanical engineers and provides the requirements necessary to ensure safety in nuclear facilities , including the development and validation of computer models and software that is used to design and operate such facilities .

initially , the american society of mechanical engineers standards were not mandatory for computer models and software used for cleanup decisions , many of which are considered nonsafety software .

these standards were but one of many standards that contractors could choose to use .

however , as of november 2008 , em made the american society of mechanical engineers standards mandatory for all cleanup activities , including modeling .

em's contractors are to implement doe's quality assurance requirements using specific policies and procedures they develop .

the specifics of implementation vary from contractor to contractor .

in the case of computer software quality , a contractor is to include procedures for testing and validating the software , ensuring changes to software are properly documented , and correcting any errors .

em allows its contractors to take a “graded approach” to quality procedures for computer software , which means the contractor may adjust the rigor of the quality procedures to match the importance of the software to overall operations .

according to documents we reviewed , computer software that controls systems in a nuclear facility , for example , would require more rigorous quality procedures than an administrative payroll system , as any failure in the software controlling a nuclear facility could result in potentially hazardous consequences to workers , the public , and / or the environment .

em is to oversee its contractors' implementation of quality standards for computer models by performing periodic quality assurance assessments , according to doe's quality assurance order .

these quality assurance assessments are intended to ensure that computer models meet doe and accepted industry quality standards .

in our review of eight cleanup decisions at hanford and srs , we found em had conducted only three quality assurance assessments that addressed quality standards for the models used in those decisions .

for example , for three of the four decisions we reviewed at srs , doe officials at srs could not provide quality assurance assessments that specifically addressed whether the models used in those decision processes met doe's quality assurance requirements .

doe officials at srs provided three general quality assurance assessments , but these quality assurance assessments did not specifically look at the cleanup models .

in contrast , the models for a march 2010 performance assessment selecting a cleanup strategy to close underground liquid waste tanks at srs did receive a quality assurance assessment by a doe headquarters group established to review performance assessment decisions .

in particular , as part of the review , among other things , the doe group conducted a quality assurance assessment that evaluated the quality of the computer models used in the performance assessment and the degree to which the models complied with doe requirements and industry standards .

a doe quality assurance official at srs noted that the site relies primarily on its contractors to perform quality assurance assessments of computer models and their associated software .

similarly , in our review of four cleanup decisions at hanford , we found that em had performed assessments that addressed quality standards for the models used in those decisions in only two cases .

in fact , one quality assurance assessment was only undertaken after a contractor discovered data quality errors in 2005 in a computer model used to support a prior environmental impact statement at hanford .

according to a doe quality assurance manager at hanford , his office conducts quality assurance assessments primarily on those computer models and the associated software for which the failure would result in significant safety consequences to workers , the public , and / or the environment .

concerns have been raised by doe and others that em does not have complete assurance of the quality of the models .

for example: citing a number of flaws in a model doe uses to analyze soil and groundwater contamination at hanford , the washington state department of ecology told doe in february 2010 that it would no longer accept the use of this model for chemical exposure analysis at hanford .

for example , ecology cited previous concerns that the model was not robust enough to capture complexities of the movement of contamination through the subsurface soil .

we found that doe had conducted no specific quality assurance reviews on the model and its associated software .

em headquarters officials conducted two technical reviews in 2009 of planning models used for tank waste operations at hanford and srs .

the review of the hanford planning model found that the model has limited ability to sufficiently predict the composition of the contaminated waste as it is prepared for the treatment processes .

the review team cautioned that this limitation raised a significant risk that , when actual waste treatment operations started at the site , the waste may not meet the acceptance requirements for processing by hanford's treatment facility .

in addition , the review of srs's planning model found that , although the data the model provided on tank waste operations were reasonable , the model did not have the ability to optimize operating scenarios , which hampered the site's long - term planning abilities .

a march 2010 independent review commissioned by a hanford citizen's group raised concerns about a model used in the preparation of a draft environmental impact statement of alternatives for closing hanford's waste tanks .

these concerns , based on reviewing the draft statement , included insufficient documentation of the quality assurance processes followed for the model and that modeling uncertainties were inadequately quantified .

the review concluded that the environmental impact statement was insufficiently precise to be used to make a cleanup decision .

where doe has conducted quality assurance assessments , it has found that contractors did not always implement quality requirements consistently .

furthermore , in their own internal reviews , contractors have noted problems with the implementation of quality assurance requirements .

problems noted in doe's and contractors' quality assurance assessments include: inadequate documentation .

a 2007 software quality review conducted by doe at hanford found implementation problems , including inadequate documentation and improper training for personnel in quality procedures .

at srs , two general software quality assurance reviews performed by doe in 2004 found that while contractors generally met quality requirements , documentation was sometimes lacking or improperly prepared .

a similar 2007 doe review at srs found a good software quality program overall , but listed a number of deficiencies including inadequate software plans and procedures .

not following correct procedures .

a 2007 doe review of a hanford contractor's software quality assurance program found , among other things , that not all contractor personnel fully understood software quality requirements .

the report stated that , although software quality assurance training had been provided , personnel did not follow procedures in managing , maintaining , and overseeing software quality .

for example , the report cited an example of a spreadsheet in which data input cells were not properly locked , in violation of procedures .

in addition , the report noted that software documentation was not periodically updated , as required , because staff did not fully understand the procedures .

incorrect quality assurance grading .

in some cases , contractors did not always correctly determine the level of rigor needed to ensure the quality of computer models and their associated software .

for example , a 2007 internal contractor review at hanford found that 23 of 138 software codes registered in a central repository were incorrectly designated as nonsafety software , when in fact they should have been considered safety software .

as a result , the quality assurance procedures appropriate for a given level of risk may not have always been applied .

although em has recently begun some efforts to promote consistency in the use of models across its various sites , these efforts are still in early stages and , to date , some have had limited involvement of modeling officials at the sites and federal , state , and local stakeholders who are affected by decisions made using the output of computer models .

in addition , these efforts are not part of a comprehensive , coordinated effort to improve the management of computer models across em .

in the absence of such a strategy , em also does not have overarching guidance promoting consistency in modeling management , development , and use across em's sites .

em has begun some efforts to improve the use of computer models across its various sites .

for example , em , in fiscal year 2010 , began developing a set of state - of - the - art computer models to support soil and groundwater cleanup across the nuclear weapons complex .

according to em officials and documentation they provided , this initiative , called the advanced simulation capability for environmental management , will allow em to provide more sophisticated analysis of soil and groundwater contamination for cleanup decisions .

although the initiative's director told us that the goal is to encourage all sites to use these models for all of their soil and groundwater analysis , he noted that there are no plans to make using these models mandatory .

moreover , srs has created a forum for improving consistency in groundwater computer modeling performed at the site .

according to the charter document , the forum , called the groundwater modeling consistency team , was formed in 2006 following the discovery of inconsistencies in the data used in groundwater computer modeling conducted at hanford in support of the preparation of an environmental impact statement under nepa .

the group , which is made up of doe and contractor officials , reviews software codes , model inputs , and model assumptions to promote sitewide consistency in the management of computer models .

although these efforts may help improve em's use of computer models , they are largely still in early stages .

in addition , according to em officials , some of these efforts have , to date , had limited involvement of modeling officials at em's sites and of federal , state , and local stakeholders who are affected by decisions made using the output of computer models .

furthermore , they are not part of a comprehensive , coordinated effort to improve the consistency of computer models and reduce duplication across em's various sites .

for example , we found that different models are used to perform similar functions not only between em sites , but also within sites .

at srs , one contractor uses a set of models to perform soil and groundwater analyses when evaluating the potential effectiveness of cleanup alternatives under cercla and nepa , while another contractor uses a different set of models to perform similar analyses for performance assessments under doe's radioactive waste management order .

each contractor has its own set of procedures for developing and using each computer model .

officials from both contractors told us that they use different models because state and federal regulators have only approved the use of certain models for specific types of cleanup decisions .

issues with consistency and duplication of effort in the use of computer models have also been noted by others .

for example , a february 2010 doe review noted that five major doe sites use 28 different models to analyze groundwater and subsurface contamination when preparing performance assessments under doe's radioactive waste management order .

doe officials told us that past modeling practices have resulted in conflicting assumptions and data sets , as well as different approaches to uncertainty analyses .

in addition , a september 2009 doe technical review of the hanford tank waste modeling system raised concerns that two models at hanford that share data use different assumptions that could lead to inconsistencies between the two .

as a result , the hanford waste treatment system plan , which is based on the output of one of these models , may not reflect the most current information .

in contrast , other federal agencies and doe offices have taken steps to improve consistency and reduce duplication as part of a comprehensive , coordinated strategy to manage the use of computer models .

for example , epa organized a center for regulatory environmental modeling in 2000 as part of a centralized effort to bring consistency to model development , evaluation , and usage across the agency .

the center brings together senior managers , modelers , and scientists from across the agency to address modeling issues .

among its tasks are to help the agency ( 1 ) establish and implement criteria so that model - based decisions satisfy regulatory requirements ; ( 2 ) implement best management practices to use models consistently and appropriately ; ( 3 ) facilitate information exchange among model developers and users so models can be continuously improved ; and ( 4 ) prepare for the next generation of environmental models .

according to a doe official , em does not have a central coordination point similar to epa's .

within doe , the office of nuclear energy recently established an initiative — the nuclear energy modeling and simulation energy innovation hub — that provides a centralized forum for nuclear energy modelers .

according to the director of the office of nuclear energy's office of advanced modeling and simulation , the hub will provide a more centrally coordinated effort to bring together modeling and simulation expertise to address issues associated with the next generation of nuclear reactors .

similar comprehensive , coordinated efforts are lacking within em and , as a result , em may be losing opportunities to improve the quality of its models , reduce duplication , keep abreast of emerging computer modeling and cleanup technologies , and share lessons learned across em's sites .

the need for specific guidance for ensuring the careful management of computer models used in decision making is not new .

as early as 1976 , we reported on the government's use of computer models and found that the lack of guidance contributed to ineffective and inefficient use of computer models .

we noted that guidance should define the problem to be solved , specify the assumptions and limitations of the model , and provide methods to test whether the model reasonably describes the physical system it is modeling .

more recently , a 2007 national research council study of modeling at epa laid out guidelines to improve environmental regulatory computer modeling .

the study noted that adoption of a comprehensive strategy for evaluating and refining epa's models could help the agency add credibility to decisions based on modeling results .

it also noted several key principles to follow for model development , evaluation , and selection .

moreover , the study recommended that peer review be considered as an important tool for improving model quality .

according to the study , a peer review should entail not only an evaluation of the model and its output , but also a review of the model's origin and its history .

the study also made recommendations on quantifying and communicating uncertainty in model results to better communicate a model's limitations to stakeholders affected by decisions made using the results of computer models .

epa has taken action to develop specific guidance , issuing a guide in 2009 addressing the management , development , and use of computer modeling used in making environmental regulatory decisions .

in this guidance , epa developed a set of recommended best practices to help mode lers effectively use computer models .

the guidance defines the role of computer models in the public policy process , discusses appropriate ways of dealing with uncertainty , establishes criteria for peer review , and addresses quality assurance procedures for computer modeling .

even within doe , another office outside of em has recognized the need for specific guidance for managing computer models .

specifically , doe's office of civilian radioactive waste management specified in its quality assurance requirements several requirements for computer models .

these requirements included clearly defining the model's objective , documenting alternative models that could be used and the rationales for not using them , and discussed a model's limitations and uncertainties .

in addition , the office specified in its requirements that , among other things , a computer model receive a technical review through a peer review or publication in a professional journal .

although the importance of comprehensive guidelines for managing computer models is well established , according to its officials , em does not have such overarching guidance .

as previously discussed , em does have a manual accompanying its quality assurance order that describes acceptable methods for specifically ensuring the quality of safety software .

however , the manual does not generally address models used in cleanup decisions .

em also has guidance addressing the management of computer models used in conducting performance assessments under its radioactive waste management order .

specifically , a doe headquarters group that is charged with reviewing decisions made under this order — the low - level waste disposal facility federal review group — has developed a manual that contains guidance on , for example , ensuring that input data to computer models are described and are traceable to sources derived from , among other things , field data from the site and referenced literature that is applicable to the site .

however , this guidance does not apply to computer models used to analyze the potential effectiveness of cleanup alternatives under cercla or nepa or to computer models used for planning , scheduling , and budgeting purposes .

as a result , computer models developed at various doe sites do not have consistent criteria to define the role of the model in the decision - making process , consistent ways of dealing with uncertainties and a model's limitations , and mechanisms to ensure computer model quality , such as quality assurance assessments and peer review .

em's computer models provide critical information that is needed to make significant decisions about how to clean up the radioactive and hazardous legacy waste across the country .

however , em's oversight of the quality of these models and its management of the development , evaluation , and use of the models has not always been commensurate with the models' importance .

because the decisions em makes must protect human health and the environment for thousands of years into the future , it is critical that the models on which em bases its decisions are of the highest quality possible .

in addition , because these cleanup efforts will take decades and cost billions of dollars , it is also important that models used for planning , scheduling , and budgeting purposes provide the most accurate data possible for em and congress to make informed decisions on cleanup activities .

em's failure to fully oversee its contractors' implementation of quality assurance procedures has led to a reduced level of confidence that the models reasonably represent the conditions they are meant to simulate .

in several cases , we found necessary quality assurance reviews were not conducted .

in others , reviews found that quality assurance procedures were inadequately implemented .

because existing quality assurance requirements that are applied to em's computer models have not been adequately implemented and , in some cases , are insufficiently understood by its contractors , em and its contractors do not have an effective mechanism to provide the public and other em stakeholders with assurance of a model's quality .

to its credit , em is beginning to undertake efforts to improve the consistency of models across the nuclear weapons complex .

however , some of these efforts are still in their infancy , and it remains to be seen whether any improvements in em's management of its models will result .

we recognize that every site has its unique conditions and challenges and that a one - size - fits - all approach to modeling would not be appropriate .

nevertheless , there is room for additional consistency in model development and implementation , as well as a mechanism for sharing lessons learned among doe's various sites .

for a number of years , other federal agencies and offices within doe have recognized the importance of a comprehensive guidance for managing computer models .

without a comprehensive strategy and modeling guidance , em may miss opportunities to improve the quality of computer models , promote consistency , reduce duplication across doe sites , and share lessons learned .

to help em increase confidence in the quality of information provided to the public and its stakeholders resulting from the use of computer modeling , we recommend the secretary of energy take the following three actions: clarify specific quality assurance requirements for computer models used in environmental cleanup decisions , including to analyze the potential effectiveness of cleanup alternatives , assess the performance of selected cleanup activities , and assist in planning and budgeting cleanup activities .

ensure that the models are assessed for compliance with these requirements .

develop a comprehensive strategy and guidance for the management of computer models to promote consistency , reduce duplication , and ensure sharing of lessons learned .

we provided a draft of this report to doe for its review and comment .

in its written comments , doe agreed with our recommendations and stated that modeling is an important component of management analysis and decision making for the department .

doe noted that it is committed to continuous improvement in model development and application and commented that our recommendations will strengthen its modeling efforts .

doe stated in its comments that it disagreed with the draft report's assertion that its directives and standards fall short for the development and management of computer models .

doe commented that its quality assurance directives apply directly to the development , coding , and validation of safety and nonsafety computer models used in cleanup decisions and that em has interpreted and applied these directives and accompanying standards to develop its quality program .

we agree with doe , and our draft report noted , that doe addresses quality through various departmental policies and industry standards .

however , these directives do not provide specific guidance to em on assuring quality of the cleanup models themselves , guidance that other agencies and offices within doe have developed .

in particular , doe's primary quality assurance policy — doe order 414.1c — addresses general standards that em and its contractors must meet to ensure all work at its sites is carried out effectively , but is vague on the specific steps that must be followed to ensure the quality of models used in cleanup decisions .

in addition , as our draft report noted , a manual accompanying this order describes acceptable , nonmandatory methods for specifically ensuring quality of safety software .

however , the manual is less clear on the use of computer software not considered as safety software , such as those used by computer models that support doe's cleanup decisions .

our recommendation that doe clarify the specific quality assurance requirements for computer models used in environmental cleanup decisions is intended to address these problems .

doe's comments also provided additional information on the department's oversight of computer models , initiatives it is undertaking to improve its modeling efforts , and the specific steps it plans to take to address our recommendations .

doe also provided technical comments that we incorporated in the report as appropriate .

doe's written comments are presented in appendix iii .

as agreed with your office , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies of this report to the appropriate congressional committees ; the secretary of energy ; the director , office of management and budget ; and other interested parties .

in addition , the report will be available at no charge on the gao web site at http: / / www.gao.gov .

if you or your staffs have any questions regarding this report , please contact me at ( 202 ) 512-3841 or aloisee@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix iv .

to determine how the department of energy's ( doe ) office of environmental management ( em ) uses computer modeling in cleanup decisions , we focused on cleanup decisions em has made at its hanford site in washington state and savannah river site ( srs ) in south carolina because together these two sites account for more than one - half of em's annual cleanup spending and approximately 60 percent of the total estimated cost of approximately $275 billion to $329 billion to clean up the entire nuclear weapons complex .

we focused our review on decisions made in two major areas that represent the largest and most significant elements of the cleanup program at these two sites .

the first is cleanup of radioactive and hazardous waste stored in underground tanks , which doe has determined poses the most significant environmental safety and health threat in the cleanup program .

doe estimates cleaning up tank waste at the sites will cost between $87 billion and $117 billion , making it the largest cost element of em's cleanup program .

second , both sites have significant contamination to soil and groundwater , which doe estimates will cost more than $12 billion to remediate .

for each site , we selected three types of decisions that were representative of major decisions made at these sites between 2002 and 2010 — ( 1 ) decisions made under environmental statutes , including the comprehensive environmental response , compensation , and liability act of 1980 , as amended ( cercla ) — which addresses specific environmental remediation solutions for a cleanup site — and the national environmental policy act , as amended ( nepa ) — under which doe evaluates the impacts to human health and the environment of proposed cleanup strategies and possible alternatives ; ( 2 ) performance assessments under doe orders governing radioactive waste management ; and ( 3 ) cleanup budgeting and planning decisions .

we reviewed publicly available information from regulators and interviewed doe officials and contractor staff to identify the most recent decisions for each of the three types of decisions selected for review at each site .

we reviewed these decisions to identify the most recent decision that included the use of computer modeling .

we then selected , based on input by em officials , the main models used to support these decisions at the two sites .

we visited both hanford and srs and spoke with both em officials and contractor staff there to better understand the use of models in planning and cleanup decisions and doe's oversight of the models .

we obtained demonstrations of these models , as well as information on how they were used in decision making .

we obtained and reviewed the decision documents , as well as modeling studies , notes of meetings between doe and its regulators to develop models , and other documentation showing how the models were used in decisions .

we interviewed officials from doe headquarters and the two sites , as well as contractor staff , to determine how the models work and how they were used in these decisions .

we analyzed this information to determine how the results of computer models were used in making cleanup decisions , the importance of modeling in the selection of a cleanup strategy , and other factors that contributed to the selection of a cleanup strategy .

to evaluate how em determines the quality of the computer models used in cleanup decision making , we obtained and reviewed documentation showing the standards the models were required to meet .

we gathered documentation on doe standards , as well as policies and procedures from contractors overseeing the models .

we discussed computer model and software standards with em officials from em's sites , contractors at the sites , and headquarters officials .

we also interviewed officials from the defense nuclear facilities safety board , the national research council , the environmental protection agency , and the washington state department of ecology about existing standards for the use and implementation of computer modeling and its associated software .

we analyzed em policies and contractor procedures to determine what quality assurance standards exist to address the quality of computer models .

we also requested from em and its contractors all assessments that were conducted on computer models used in the decisions we were reviewing , indicating whether quality standards were met .

in general , the assessments we reviewed were largely conducted by the contractors , regulators , or external sources , such as consultants .

these reviews ranged from contractor - performed assessments of the implementation of quality standards for software , to federal and state regulator comments on the modeling output used to develop alternatives in a regulatory package , to an outside consultant - performed review on the appropriateness of modeling for selecting a preferred alternative from an environmental impact statement prepared under nepa .

we analyzed these assessments to understand the level of oversight em provided to assure model and software quality , as well as the extent to which contractors were implementing quality procedures .

to address em's overall strategy for managing computer models that are used in cleanup decisions , we interviewed doe officials from headquarters and from each site .

we also interviewed officials from the environmental protection agency , national research council , doe's office of nuclear energy , and doe's office of civilian radioactive waste management about the implementation of computer modeling guidance and modeling coordination strategies .

we reviewed modeling guidance from these organizations , as well as from the office of management and budget .

we focused our review on model quality assurance standards and the use of models in decision making , not on the quality of the models themselves or of their output .

we conducted this performance audit from october 2009 to february 2011 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the individual named above , ryan t. coles , assistant director ; ivelisse aviles ; mark braza ; dan feehan ; nancy kintner - meyer ; jonathan kucskar ; mehrzad nadji ; kathryn pedalino ; thomas c. perry ; and benjamin shouse made key contributions to this report .

nuclear waste: actions needed to address persistent concerns with efforts to close underground radioactive waste tanks at doe's savannah river site .

gao - 10-816 .

washington , d.c.: september 14 , 2010 .

recovery act: most doe cleanup projects appear to be meeting cost and schedule targets , but assessing impact of spending remains a challenge .

gao - 10-784 .

washington , d.c.: july 29 , 2010 .

department of energy: actions needed to develop high - quality cost estimates for construction and environmental cleanup projects .

gao - 10-199 .

washington , d.c.: january 14 , 2010 .

nuclear waste: uncertainties and questions about costs and risks persist with doe's tank waste cleanup strategy at hanford .

gao - 09-913 .

washington , d.c.: september 30 , 2009 .

department of energy: contract and project management concerns at the national nuclear security administration and office of environmental management .

gao - 09-406t .

washington , d.c.: march 4 , 2009 .

nuclear waste: doe lacks critical information needed to assess its tank management strategy at hanford .

gao - 08-793 .

washington , d.c.: june 30 , 2008 .

hanford waste treatment plant: department of energy needs to strengthen controls over contractor payments and project assets .

gao - 07-888 .

washington , d.c.: july 20 , 2007 .

nuclear waste: doe should reassess whether the bulk vitrification demonstration project at its hanford site is still needed to treat radioactive waste .

gao - 07-762 .

washington , d.c.: june 12 , 2007 .

hanford waste treatment plant: contractor and doe management problems have led to higher costs , construction delays , and safety concerns .

gao - 06-602t .

washington , d.c.: april 6 , 2006 .

nuclear waste: absence of key management reforms on hanford's cleanup project adds to challenges of achieving cost and schedule goals .

gao - 04-611 .

washington , d.c.: june 9 , 2004 .

nuclear waste: challenges to achieving potential savings in doe's high - level waste cleanup program .

gao - 03-593 .

washington , d.c.: june 17 , 2003 .

nuclear waste: department of energy's hanford tank waste project — schedule , cost , and management issues .

gao - rced - 99-13 .

washington , d.c.: october 8 , 1998 .

