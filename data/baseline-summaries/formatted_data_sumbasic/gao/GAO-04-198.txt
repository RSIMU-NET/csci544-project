to enhance public safety and bring criminals to justice , it is important for law enforcement officials to benefit from the latest advances in science and technology .

the mission of the office of science and technology ( ost ) , within the department of justice's national institute of justice ( nij ) , is to improve the safety and effectiveness of technology used by federal , state , and local law enforcement , corrections , and other public safety agencies .

ost awards funds to research and develop more effective technology and improve access to technology in a wide range of areas .

for example , ost funds programs in the areas of crime prevention technologies , investigative and forensic sciences , and electronic crime .

examples of products resulting from ost's programs include a guide on school safety , an evaluation of police protective gear , a prototype for ground - penetrating radar , and a report on gunshot residue detection and interpretation .

to support ost's programs , congress has significantly increased its funding , from $13.2 million in fiscal year 1995 to $204.2 million in fiscal year 2003 ( in constant 2002 dollars ) .

in response to your interest about whether ost's programs are achieving their intended results , we reviewed certain aspects of ost's operations .

specifically , this report assesses ( 1 ) the growth in ost's budgetary resources , from fiscal year 1995 to fiscal year 2003 , and changes in ost's program responsibilities ; ( 2 ) what types of products ost delivers and the methods used to deliver these products to public safety agencies ; and ( 3 ) how well ost's efforts to measure the success of its programs in achieving intended results meet applicable requirements .

to address our objectives , we collected and analyzed relevant data and reports and interviewed ost officials and nij officials , including nij executive staff and the assistant nij director for ost , division chiefs , and managers .

we also collected data and interviewed officials at ost technology centers in rockville , maryland ; and el segundo and san diego , california .

appendix i contains detailed information on the scope and methodology we used for this assessment .

we conducted this engagement in accordance with generally accepted government auditing standards .

the office of science and technology ( ost ) was created in fiscal year 1995 following a long history of science and technology efforts within the national institute of justice ( nij ) .

nij is a component of the office of justice programs ( ojp ) , a justice agency that , among other things , provides assistance to state , tribal , and local governments .

in establishing ost's objectives and allocating funds for ost's programs , the nij director considers the priorities of many stakeholders , including the president , congress , justice , and state and local law enforcement and public safety agencies .

in november 2002 , congress established ost and its mission and duties in statute as part of the homeland security act of 2002 ( the act ) .

the act specified ost's mission “to serve as the national focal point for work on law enforcement technology ; and to carry out programs that , through the provision of equipment , training , and technical assistance , improve the safety and effectiveness of law enforcement technology and improve access to such technology by federal , state , and local law enforcement agencies.” the act defined the term “law enforcement technology” to include “investigative and forensic technologies , corrections technologies , and technologies that support the judicial process.” the act also specified ost's duties to include the following , among others: establishing and maintaining advisory groups to assess federal , state , and establishing and maintaining performance standards , and testing , evaluating , certifying , validating , and marketing products that conform to those standards ; carrying out research , development , testing , evaluation , and cost - benefit analysis of certain technologies ; and developing and disseminating technical assistance and training materials .

ost's operations have multiple levels of internal organization and multiple kinds of external partners .

 ( for a more detailed description of ost's operations , see app .

v. ) ost's multiple levels of organization include a washington , d.c. , office and a network of 10 technology centers that provide technical assistance to ost's customers around the country .

to fulfill its mission , ost also collaborates with entities such as the departments of defense and energy and public and private laboratories to take advantage of established technical expertise and resources .

nij has three main types of awards for funding ost's programs: grants , interagency agreements , and cooperative agreements .

grants are generally awarded annually by nij to state and local agencies or private organizations for a specific product and amount .

interagency agreements are used by nij for creating partnerships with federal agencies .

cooperative agreements are a type of nij grant to nonfederal entities that prescribes a higher level of monitoring and federal involvement .

nij also uses memorandums of understanding ( mou ) to coordinate programs and projects between agencies .

the mous specify the roles , responsibilities , and funding amounts to be provided by participating agencies .

through nij , ost can provide supplemental funding to interagency and cooperative agreements that may be used to contract for special projects .

ost awards are administered by managers at its washington , d.c. , office who have final oversight and management responsibility .

these managers may delegate some responsibility to another federal r&d agency receiving the award .

in march 2003 , 21 managers were responsible for overseeing 336 active awards totaling $636 million .

guidance has been established for measuring the performance of government operations .

to assist justice to follow the government performance and results act of 1993 ( gpra ) , ost establishes goals and develops performance measures to track its progress .

in addition , in may 2002 , the white house office of management and budget ( omb ) and office of science and technology policy issued a memorandum setting forth r&d investment criteria that departments and agencies should implement .

the investment criteria require an explanation of why the investment is important , how funds will be allocated to ensure quality , and how well the investment is performing .

according to the memorandum , program managers must define appropriate outcome measures , and milestones that can be used to track progress toward goals and assess whether funding should be enhanced or redirected .

the memorandum encourages federal r&d agencies to make the processes they use to satisfy gpra consistent with these criteria .

ost's budgetary resources have grown and the range of program responsibilities has changed .

budgetary resources for ost increased significantly , from $13.2 million in fiscal year 1995 to $204.2 million in fiscal year 2003 ( in constant 2002 dollars ) , totaling over $1 billion .

this increase can be attributed to the introduction of new allocations and large increases for existing ones .

the nij director decides how to allocate certain appropriated funds to the various nij components , including ost .

about $749.7 million , or 72 percent , of ost's total budgetary resources was either directed to specific recipients or projects by public law , subject to congressional committee report guidance designating specific recipients or projects , or directed from the reimbursements from other justice and federal agencies in exchange for ost managing their projects .

corresponding with the designation of spending for specific recipients and projects , the range of ost's programs changed , from primarily law enforcement and corrections to include broader public safety technology r&d , such as for improving school safety and combating terrorism .

ost's budgetary resources include both funding received via justice appropriations accounts as well as reimbursements from other justice and federal agencies .

first , ost receives funding via three appropriations accounts enacted in the appropriations law for the justice department .

from these appropriations accounts , ojp allocates amounts to nij .

the nij director suballocates part of the nij funds for ost programs .

in addition , ost receives reimbursements from other justice and federal agencies in exchange for ost's management of specific projects of those agencies , such as ballistic imaging evaluation for the fbi .

table 1 lists nij allocations from the justice appropriations accounts that go toward funding ost programs .

ost's budgetary resources almost quadrupled from fiscal year 1995 to 1996 , increased 70 percent from fiscal year 1999 to 2000 , and increased 63 percent from fiscal year 2001 to 2002 .

while resources decreased 24 percent from fiscal year 2002 to 2003 , ost's fiscal year 2003 level still represents a 157 percent increase over the fiscal year 1999 level .

our analysis of ost's yearly budgetary resources from fiscal year 1995 to fiscal year 2003 showed that the overall increase can be attributed to the introduction of new nij allocations and large increases for existing ones .

the nij allocations that contributed to the overall increase in ost's budgetary resources are most notably the crime lab improvement program , dna backlog reduction , safe schools technology r&d , and counterterrorism r&d allocations .

table 2 shows figures for all years in constant 2002 dollars .

all dollar figures used in this narrative are in constant 2002 dollars , except as noted otherwise .

fiscal years 1995-1996: the $39.4 million ( 298 percent ) increase from $13.2 million to $52.6 million primarily came from two nij allocations totaling $35.4 million .

local law enforcement block grant ( llebg ) initiated with $22.2 million .

reimbursement of funds increased by $13.2 million ( 471 percent ) from $2.8 million to $16.0 million .

fiscal years 1999-2000: the $55.6 million ( 70 percent ) increase from $79.5 million to $135.1 million primarily came from three nij allocations totaling $51.7 million .

dna backlog reduction initiated with $15.6 million .

safe schools technology r&d allocation initiated with $15.6 million .

counterterrorism r&d increased by $20.5 million ( 193 percent ) from $10.6 million to $31.1 million .

fiscal years 2001-2002: the $103.4 million ( 63 percent ) increase from $164.6 million to $268.0 million primarily came from three nij allocations totaling $95.3 million .

reimbursement of funds increased by $55.6 million ( 209 percent ) from $26.6 million to $82.2 million .

dna backlog reduction increased by $24.3 million ( 227 percent ) from $10.7 million to $35 million .

crime lab improvement program increased by $15.4 million ( 79 percent ) from $19.6 million to $35 million .

to be consistent with the report narrative and to show trends , figures in table 2 are in constant 2002 dollars .

a table with the figures in current dollars can be found in appendix ii .

ost had a $63.8 million ( 24 percent ) decrease in total budgetary resources from fiscal years 2002 to 2003 , largely attributed to its not receiving fiscal year 2003 counterterrorism r&d resources , which totaled $45.3 million in fiscal year 2002 .

according to ost , its counterterrorism resources were transferred to the department of homeland security's office of domestic preparedness .

there was also a $26.2 million decrease in the reimbursement of funds from other agencies .

however , ost's fiscal year 2003 level still represents a 157 percent increase from fiscal year 1999 .

the range of ost's program responsibilities has changed over the years from primarily law enforcement and corrections to include broader public safety technology r&d .

this has happened as more and more of ost's budgetary resources were directed to be spent on specific recipients and projects .

appropriated funds , for example , are sometimes designated for specific recipients or projects in public law .

in addition , guidance on the spending of appropriated funds may be provided through congressional committee reports .

of the more than $1 billion ( in constant 2002 dollars ) that ost programs received from fiscal years 1995 to 2003 , $532.6 million , or 51 percent , was designated for specific recipients and projects in public law or subject to guidance in committee reports designating specific recipients or projects .

of the $532.6 million , $249.8 million was designated in public law for specific recipients or projects while $282.8 million was specified in committee report guidance for specific recipients or projects .

in addition to the $532.6 million designated in public law for specific recipients or projects or subject to guidance in committee reports for specific recipients or projects , another $217.1 million was reimbursements from other justice and federal agencies in exchange for ost's management of specific projects of those agencies .

thus , the total spending either directed for specific recipients and projects through public law , subject to committee report guidance designating specific recipients or projects , or received as reimbursements , amounts to $749.7 million , or 72 percent , of ost's total budgetary resources .

the range of ost's program responsibilities has changed to include such areas as school safety and counterterrorism .

in fiscal year 1999 , a safe schools initiative program was established pursuant to conference committee report guidance with $10 million directing nij to develop school safety technologies .

in another example , ost's counterterrorism r&d program , initially funded by public law in fiscal year 1997 , received $147.3 million through fiscal year 2002 , $96.6 million of which was specified in conference report guidance for three recipients from fiscal years 2000 to 2002 — oklahoma city national memorial institute for the prevention of terrorism ( $37.8 million ) , dartmouth college's institute for security technology studies ( $51.8 million ) , and the new york university's center for catastrophe preparedness and response ( $7 million ) .

ost's program responsibilities have also changed to expand the focus on investigative and forensic sciences .

our review of ost's budgetary resources for fiscal years 1995 through 2003 shows that budgetary resources for investigative and forensic sciences equals at least $342.1 million in constant fiscal year 2002 dollars , or about one - third , of its $1 billion in budgetary resources , as shown in table 3 .

the proportion of investigative and forensic sciences annual funding to total ost funding rose from 6 percent ( $800,000 ) in fiscal year 1995 to 52 percent ( $106.0 million ) in fiscal year 2003 .

ost delivers many products , which we categorized into three groups , and uses various methods to deliver them .

these three groups are ( 1 ) information dissemination and technical assistance ; ( 2 ) the application , evaluation , and demonstration of existing and new technologies for field users ; and ( 3 ) technology r&d .

according to ost , as of april 2003 , it had delivered 945 products since its inception .

furthermore , ost identified an additional 500 products expected from ongoing awards .

figure 2 shows our distribution of ost's delivered products by group .

we recognize , as ost officials told us , that the groups overlap and there is not a clean division between them .

for example , while reports are associated with information dissemination , they may also result from the technology r&d group .

ost has reviewed our classification of products and agrees that it is generally accurate .

because classification of some products is based on a judgment call , the proportions of products in each group should be considered approximations .

the following examples , while not exhaustive , indicate the wide range of ost's products .

reports on topics such as analysis of dna typing data , linguistic methods for determining document authorship , a pepper spray projectile and disperser , and gunshot residue detection and interpretation .

prototypes of products including ground - penetrating radar , ballistics matching using 3-dimensional images of bullets and cartridge cases , and an optical recognition system to identify and track stolen vehicles .

evaluations of technology including prison telemedicine networks , police vehicles , and protective gear .

guides on topics such as electronic crime scene investigation , use of security technologies in schools , and antennas for radio communications .

for a more detailed description of ost's products and further examples , see appendix iii .

information dissemination and technical assistance represents about 63 percent of ost's delivered products .

ost provides information to its customers in a variety of ways .

for example , ost provides guidance to r&d laboratories on the needs of public safety practitioners .

to public safety practitioners , ost recommends certain public safety practices , tools , and technologies .

through its office of law enforcement standards , ost develops performance standards to ensure that commercially available public safety equipment , such as handheld and walk - through metal detectors , meets minimum performance requirements .

ost also helps its customers enhance their technical capacities by providing them with training and technical assistance through its crime lab improvement program ( which also provides supplies and equipment ) , dna backlog reduction program , and network of technology centers .

ost also uses the r&d expertise and experience of already established laboratories and other r&d organizations to provide additional guidance for managing specialized technology projects .

further , ost helps its customers receive surplus federal equipment by acting as their liaison to the equipment transfer program of the department of defense .

for example , equipment transferred ranges from armored vehicles to boots and uniforms .

in addition , ost sponsors conferences , workshops , and forums that bring together its customers , technologists , and policymakers .

for example , it sponsors the mock prison riot , an annual event demonstrating emerging technologies in riot training scenarios held at the former west virginia penitentiary in moundsville , west virginia .

this event brings together corrections officers and vendors for technology showcases and training exercises .

also , ost sponsors the innovative technologies for community corrections annual conference , among others .

another ost product group is the application , evaluation , and demonstration of new and existing technologies , which represents about 20 percent of ost's delivered products .

some of ost's programs apply existing technology solutions in new ways to assist public safety operations .

examples of the application of new and existing technologies include developing methods for the collection and analysis of chemical trace evidence left from explosives and a handheld computer device provided to bomb technicians in order to access bomb data at the scene of incidents .

in addition , ost tests commercially available products through nij - certified laboratories to determine whether they are in accordance with national performance standards .

examples of products evaluated against standards include body armor , handcuffs , and semiautomatic pistols .

ost's evaluations also include conducting field tests to compare different commercially available products of the same type to allow users to select the product that best suits their needs .

ost also demonstrates technology resulting from r&d directly to its customers through ost - sponsored events .

for example , the critical incident response technology seminar , formerly known as the operation america , demonstrates live - fire simulation for bomb technicians .

the annual mock prison riot demonstrates emerging technologies for use by corrections officers and tactical team members .

about 17 percent of ost's delivered products were related to technology r&d , which involves the development of prototype devices , among other efforts .

according to ost , r&d in its early stages includes development of prototypes and demonstration that a principle can be proven .

applied r&d , which also involves the development of prototypes , includes technologies that are made available to public safety agencies , generally through ost - assisted commercialization .

examples of products resulting from ost's applied r&d range from a bomb threat training simulator , facial recognition technology for internet - based gang tracking , to a personal alarm and location monitoring system for corrections officers .

according to ost , r&d in its early stages begins with testing technology concepts , exploring solutions , and deciding whether continued development is warranted .

if ost decides to support product development and if it has available funds , it awards funding to develop , demonstrate , and evaluate an experimental prototype , which is then further developed into an initial engineering prototype , and then demonstrated and evaluated .

if the prototype proves successful , ost demonstrates a “near commercial” model to its customers for their evaluation .

while ost does not directly commercialize the results of its technology r&d , it does provide prototypes to local users for field - testing and assists in linking prototypes with potential commercial developers .

ost officials believe it would be a conflict of interest and therefore inappropriate for them to promote one vendor or technology over another or try to dictate what equipment their customers should purchase .

ost's role in commercialization is to bring technologies and potential manufacturers together so that the manufacturers can determine the feasibility of commercializing the technologies .

ost delivers its products to its customers through a variety of methods .

 ( we recognize that products are sometimes delivery methods .

for example , a publication can be both a product resulting from research and a method of information dissemination. ) .

besides publications , ost's methods for delivering information and technical assistance include mass mailings ; downloadable material from its web site ; panels , boards , and working groups ; training , support , and presentations ; and programs to enhance the capacity of public safety agencies .

ost also delivers its products related to application , evaluation , and demonstration through various means .

for example , private industry provides new and existing technologies to ost ; in turn , ost informs its customers of the results of using these technologies in new ways .

ost publishes user guides and the test results of its evaluations of commercially available equipment ( both standards - based and comparison - based ) .

seeking to further educate its customers , ost demonstrates new technology at technology fairs , providing “hands on” opportunities to use it .

for its r&d products , ost may test “near commercial” prototypes in particular settings .

for example , ost may install in a police agency a prototype technology that facilitates communications among public safety agencies and across jurisdictions .

if the technology is effective , the police agency may incorporate the technology directly into its operations , before the technology has become a commercial product .

ost's efforts to measure its performance results , including the usefulness and effectiveness of its products , do not fully meet applicable requirements .

to help justice comply with the government performance and results act of 1993 ( gpra ) , ost establishes goals and develops performance measures to track its progress .

gpra , which mandates performance measurements by federal agencies , requires , among other things , that each agency measure or assess relevant outputs and outcomes of each program activity .

according to gpra , the office of management and budget ( omb ) , and gao , outcomes assess actual results as compared with the intended results or consequences that occur from carrying out a program or activity .

outputs count the goods and services produced by a program or organization .

intermediate measures can be used to show progress to achieving intended results .

subsequent omb and committee report guidance on gpra , and previous gao reports recognize that output measures can provide important information in managing programs .

however , committee report guidance emphasizes using outcome measures to aid policy makers because such measures are key to assessing intended results .

the performance measures that ost has developed do not measure results .

according to the nij director , the assistant attorney general ( aag ) in april 2002 issued a memorandum requiring nij , including ost , to develop outcome measures for fiscal year 2004 .

in august 2002 , the nij director responded by stating that ost had indeed developed outcome measures for its programs .

in its fiscal year 2004 performance plan , ost established goals for 11 of its initiatives and developed 42 measures for assessing the achievement of those goals .

however , based on our review of ost's performance plan , omb guidance on gpra , and gao definitions of outcome , output , and intermediate measures , we determined that of the 42 measures , none were outcome - oriented , 28 were output - oriented , and 14 were intermediate .

see table 4 for gao's determination of the measures and appendix vi for further details of our results .

according to justice officials , r&d activities present measurement challenges because outcomes are difficult or costly to measure .

as the nij director pointed out , a may 2002 , white house omb and office of science and technology policy memorandum concluded that agencies should not have the same expectations for measuring the results of basic r&d as they do for applied r&d .

according to nij , relatively little of ost's work is basic r&d .

as shown earlier , most of ost's products are related to information dissemination and technical assistance and the application , evaluation , and demonstration of existing and new technologies for field users .

we recognize that ost's task in relation to measuring the results of even non - basic research is complex in part because of the wide array of activities it sponsors , and because of inherently difficult measurement challenges involved in assessing the types of programs it undertakes .

for example , programs that are intended to deter crime face measurement issues in assessing the extent to which something ( crime ) does not happen .

nevertheless , improvement in measurement of program results is important to help ost ensure it is doing all that is possible to achieve its goals .

it is worth noting that an outcome measure in relation to one ost program was discussed by the nij director in a may 2002 statement to congress .

in this statement , the director provided an example of an outcome from the convicted offender dna backlog reduction program .

the director stated that as a direct result of the program , approximately 400,000 convicted offender samples and almost 11,000 cases with no suspect were analyzed .

according to the nij director , as of may 14 , 2002 , more than 900 “hits” had been made on the fbi's combined dna index system ( codis ) database as a direct result of the program , that is , 900 cases previously unsolved had been reopened .

this information indicates how the program is achieving its intended results in addressing unsolved cases .

although this example seems to be a credible outcome measure , it is not included in ost's fiscal year 2004 performance plans .

ost efforts to measure information dissemination effectiveness have been limited .

one of the purposes of gpra is to improve federal program effectiveness and public accountability by promoting a new focus on results , service quality , and customer satisfaction .

surveys to gauge customer satisfaction represent one step toward finding out whether customers have received information and whether they deem it of value .

however , these surveys have limitations in determining the extent to which the information has been acted upon and resulted in intended improvements .

thus , surveys such as these are more likely to be intermediate measures ( did information get transferred ? ) .

than outcome measures ( did information get transferred , acted upon , and achieve a result ? ) .

in 1998 , nij initiated an effort to report the results of surveys to measure the satisfaction of participants at all conferences , workshops , and seminar series .

ost reported on the “grantee level of satisfaction with nij conferences” for fiscal years 1998-2000 .

however , in the fiscal years 2001- 2004 gpra performance plans , ost discontinued tracking the surveys because ojp and nij had ceased tracking these data as a performance measure .

in fiscal year 2001 , ost attempted to evaluate the effectiveness and value of its techbeat newsletter .

the survey sample of 5,500 was taken from a distribution of major readership groups on techbeat's mailing list of 20,674 .

according to ost , the response rate for the survey was too low to produce statistically valid results: only 124 completed or substantially completed responses were collected .

the surveyors also experienced a very low return on follow - up phone queries .

according to the study , the primary reason for the exceedingly low response rate was that so many individuals on the mailing list had either changed jobs or were completely unfamiliar with techbeat .

given these results , ost is trying to improve the management and distribution of techbeat .

in fiscal year 2001 , ost attempted to launch another effort to measure program results , service quality , and customer satisfaction , but funding for the effort was not provided .

ost requested funding for an evaluation to measure the success of its outreach efforts , including those by its technology centers .

the evaluation was to determine customer satisfaction with its strategies for outreach and communication and with its products .

specifically , ost planned to measure user satisfaction of the content , format , and delivery mechanisms of its efforts , such as technology information and assistance .

in fiscal years 1998 and 1999 , ost funded eight outside studies of some of its science and technology initiatives ( see table 5 ) .

our review of these studies showed that seven of the eight studies focused on management and organizational processes , and one was outcome - oriented .

management and process evaluations can be useful tools for examining how a program is operating and can offer insights into best practices .

they do not assess whether a program is achieving its intended results .

the homeland security act of 2002 requires nij to transmit to congress by late november 2003 a report assessing the effectiveness of ost's existing system of technology centers and to identify the number of centers necessary to meet the technology needs of federal , state , and local law enforcement in the united states .

according to nij , in response to the homeland security act requirement , it has initiated a study to assess the impact and effectiveness of the technology center system and how it can be enhanced to meet the evolving science and technology research and technology needs of the state and local public safety community .

nij also stated that the report would address the functions that the technology center system must provide to transfer nij's research and development results to practice in the criminal justice system .

nij and ost have failed to provide us with information detailing the methodology of the study , so we cannot comment on the likelihood that this study will produce the information sought by congress .

additionally , according to ojp , the technology centers are in the process of developing outcome measures to demonstrate the impact of their activities .

according to nij , ojp has implemented additional performance measures developed in may 2003 that will apply to nij , including ost .

however , ojp said it would defer implementing the measures related to the technology centers until the results of the technology center study are known and nij has a chance to take action , if warranted .

we acknowledge that measuring results using outcome measures is difficult , and may be especially so in relation to some of the types of activities undertaken by ost .

indeed , given the types and wide range of program goals for ost efforts — solving old crimes , saving lives , and reducing property loss — it may be the case that for some programs intermediate measures represent the best feasible measure of results .

we note that approximately 63 percent of ost's products fall into the category of information dissemination and technical assistance , aimed at informing customers and ultimately encouraging adoption of research results that lead to increased efficiency and effectiveness .

there are strategies available that have been used by other federal agencies to take steps toward assessing the effectiveness of information dissemination and technical assistance efforts .

for example , a recent gao report outlines various strategies to assess media campaigns and informational seminars , including immediate post workshop surveys and follow - up surveys and the use of logic models to define measures of a program's progress toward intended results and long - term goals .

given the wide range of its products , ost has the potential to significantly improve the technological capabilities of federal , state , and local public safety agencies .

however , the lack of information about the results of program efforts , or the assessment of progress toward goals , means that little is known about their effectiveness .

while developing outcome measurements in many research - related programs is extremely difficult , there are various performance measurement strategies that other federal programs have used for assessing information dissemination , technical assistance and other r&d activities that might be applied to ost's programs .

it is important to develop outcome measurements where feasible , or intermediate measurements where appropriate , to assist congress , ost and nij management , and ost's customers to better assess whether investment in ost's programs is paying off with improved law enforcement and public safety technology .

to help ensure that ost does all that is possible to measure its progress in achieving goals through outcome - oriented measures , we recommend that the attorney general instruct the director of nij to reassess the measures ost uses to evaluate its progress toward achieving its goals and to better focus on outcome measures to assess results where possible .

in those cases where measuring outcome is , after careful consideration , deemed infeasible , we recommend developing appropriate intermediate measures that will help to discern program effectiveness .

we provided a copy of a draft of this report to the attorney general of the united states for review and comment .

in an october 30 , 2003 , letter , the assistant attorney general ( aag ) for ojp commented on the draft .

her comments are summarized below and presented in their entirety in appendix vii .

ojp also provided technical comments , which have been incorporated into this report where appropriate .

in the aag's written response , the justice department concurred with our recommendation that nij reassess the measures ost uses to assess program outcomes .

in response to our recommendation , the aag reported that she has directed the nij director , to reassess nij's performance measures for ost and to refine them , where possible , in order to focus them more toward measuring outcomes .

while the aag agreed with our recommendation , she also made several other comments .

first , she commented that developing numerical outcome measures like those urged by gao is a particular challenge for r&d activities .

as stated in our report , we recognize that measuring results using outcome measures is difficult and may be especially so in relation to some of the types of activities undertaken by ost .

our reference to a numerical measure is meant only as an example of how one of ost's program activities can be linked to intended results .

we believe that further consideration of measures , both quantitative and qualitative , could improve the assessment of results for r&d as well as other ost programs .

our report also notes that relatively little of ost's work is r&d .

the majority of ost's products are in the category of information dissemination and technical assistance .

second , the aag noted that gao did not reach any conclusions in its discussion of ost's growth in budgetary resources , changes in program responsibilities , management of programs , and delivery of its products .

the aag noted that justice believed that ost's record is outstanding .

neither ost nor we can determine whether ost's efforts in these areas are successful or otherwise , given that ost has not developed measures to assess their outcomes .

therefore , it is not possible to draw conclusions .

third , the aag indicated that gao did not discuss in detail that over one - half of ost's funds were designated by congress for specific recipients and projects .

she noted that gao missed an opportunity to inform the requester of the impact of congress' recent decisions regarding ost .

we reported that 51 percent of ost's budgetary resources were designated for specific recipients and projects in public law or subject to guidance in committee reports .

as agreed with your office , unless you publicly announce its contents earlier , we plan no further distribution of this report until 10 days from its issue date .

at that time , we will send copies of the report to the attorney general , appropriate congressional committees and other interested parties .

we will also make copies available to others upon request .

in addition , the report will be available at no charge on gao's web site at http: / / www.gao.gov .

major contributors to this report are listed in appendix viii .

if you or your staff have any questions concerning this report , contact me on ( 202 ) 512-8777 .

to answer our objectives , we interviewed national institute of justice ( nij ) and office of science and technology ( ost ) officials and collected documents at ost's office in washington , d.c. , and at three of ost's technology centers — the national center in rockville , maryland ; west center in el segundo , california ; and border research and technology center in san diego , california .

we selected the rockville center because of its proximity to washington , d.c. , and the other two centers because of their locations and particular areas of technology and technical concentrations .

we also interviewed a small group of ost's customers — federal , state , and local law enforcement , and corrections and public safety officials — who were selected by officials at the el segundo and san diego centers .

in addition , we analyzed information that is available on the national institute of justice's public web site .

to determine ost's budgetary resources and amounts from fiscal year 1995 to fiscal year 2003 and the changes in ost program responsibilities , we reviewed nij and ost budget documents , interviewed officials in ost's technology management and the ojp's office of budget and management services , and reviewed pertinent appropriations laws and committee reports covering that period .

to determine the amount of ost budgetary resources that were directed to specific recipients and projects , we compared ost's budget documents that listed individual recipients and projects with the public laws and reports .

we defined directed spending as spending for specific recipients and projects designated in appropriations laws or subject to congressional committee report guidance designating specific recipients or projects .

we did not determine the amount of reimbursable projects designated in public laws or specified in committee reports because those projects were not originally allocated to ost .

instead , we considered all the reimbursable projects to be specific projects for which ost was directed pursuant to its agreements with other agencies on spending its reimbursable funds .

to determine the changes in ost's program responsibilities , we analyzed the year - to - year changes in its budget and program scope .

to determine the amount of ost's budgetary resources used for investigative and forensic sciences for fiscal years 1995-2003 , we compared ost's portfolio description and nij's definition of forensic sciences with the individual budget program and project items listed in ost's budget documents for each fiscal year .

however , while we recognize that ost's technology centers and their technical partners include investigative and forensic sciences in their provision of technical assistance , we did not attempt to determine the amount of center funds associated with investigative and forensic sciences because the budget documents we received from ost did not break out such amounts within the funding awarded to the centers .

therefore , our determination that $342.1 million of ost's total funding supported investigative and forensic sciences did not include such amounts .

to determine the amounts of funding awarded to the technology centers , we analyzed databases on all of the products ost has produced through april 2003 and the associated grants , interagency agreements , and cooperative agreements and their amounts .

to determine the composition of ost's products and how ost delivers the products to its customers , we analyzed ost documents and a database of all the products associated with its past and ongoing awards , from inception through april 2003 , that were delivered or anticipated to be delivered .

while the database included the award amounts associated with the products , it was not possible to reliably associate the award amounts for each product or type of product because multiple types of products could result from individual awards .

we also conducted interviews with the parties mentioned above .

for the budget and product data that ost provided us , we assessed the reliability of these data by examining relevant fields for missing data , conducting range checks to identify any potentially erroneous outliers and inspecting a subset of selected data elements that were common to two or more data sets .

in addition , we independently verified selected budget data back to appropriations legislation and committee reports .

in conducting our analyses , we identified some potential data errors or reliability problems .

when this occurred , we contacted agency officials to address and resolve these matters .

however , we did not verify the budget or product data back to source materials .

overall , we determined that budget or product data provided to us is adequate for the descriptive purposes it is used in this report .

we examined ost's efforts to measure performance by interviewing officials on this matter at ojp , nij , and ost in the washington , d.c. , office along with officials and staff at the technology centers , and current and previous advisory council officials .

we also reviewed related agency documents , such as the ojp mission statement and performance plans ; nij strategic planning documents and website pages , annual performance plans and performance reports , and gpra documents ; policies and procedures , department of justice memoranda , ost internal planning and reporting documents , program descriptions and documentation , and other related documents .

as part of our examination , we reviewed ost's fiscal year 1997 to 2004 goals and measures as presented in ost's gpra performance plans .

we focused our review on ost's fiscal year 2004 performance plan and measures .

as part of our review of these goals and measures , we made a determination as to whether the performance measure was output , outcome , or intermediate - oriented .

to make this determination about the types of performance measures contained in ost's performance plans , we compared the measures used in the plans with the requirements of gpra , accompanying committee report , omb's guidance on performance measurement challenges ( circular a - 11 ) , justice's guidance to its components for preparing performance measures , and previous gao work on gpra .

also included in our examination of ost performance measurement efforts were studies prepared by external parties under grants from ost that reviewed selected ost initiatives such as portfolio areas , projects , and programs .

in response to our request for all of ost's efforts to assess its programs , ost provided eight outside studies funded from fiscal years 1998 to 1999 .

for example , the pymatuning group , inc. , conducted an “assessment of the national law enforcement and corrections technology center ( nlectc ) program,” which described the operations of the ost's regional technology centers network .

we reviewed all eight of the outside studies for performance information on the ost initiatives being examined in the report .

we examined the studies to determine whether they provided information that would be considered consistent with an outcome - oriented evaluation as defined by our criteria .

the scope of this review was limited to ost , and therefore we cannot compare ost's efforts to measure the performance of its programs or the amount of funding directed to specific recipients and projects with the efforts and funding of any other federal r&d agencies .

we performed our audit work from september 2002 to september 2003 in washington , d.c. , and other cited locations in accordance with generally accepted government auditing standards .

while we divided ost's products into three groups for our reporting purposes , ost divides them into 10 categories .

 ( see table 7 for gao's 3 groupings of ost's 10 categories. ) .

in regrouping ost's 10 categories , we recognized , as ost officials told us , that the 10 categories overlap and there is not a clean division between them .

we also recognized that many of ost's products could also be considered a delivery method .

for example , publications , such as the techbeat newsletter , are ost products that can also represent a method of delivery for ost technology information .

ost has reviewed our classification of products and agrees that it is generally accurate .

ost has organized its individual projects to develop , improve , and implement technology for public safety agencies into nine portfolio areas .

as of april 2003 , these portfolio areas included critical incident technology , for first responders and investigators protecting the public in the event of critical incidents such as natural disasters , industrial accidents , or terrorist acts ; communications interoperability and information sharing , enhancing communication among public safety agencies through wired links , wireless radios , and information networks , even when disparate systems are involved ; electronic crime , supporting computer forensic laboratories , publishing guides for handling electronic evidence , and developing computer forensic tools ; investigative and forensic sciences , funding at the state and local levels for dna - typing of convicted offenders and use of dna - typing in the investigation of unsolved cases , and developing tools for forensic casework ; crime prevention technologies , including contraband detectors , sensors and surveillance systems , and biometric technologies ; protective systems technologies , including body armor ; “smart” handguns , which fire only upon recognition of , for example , a certain handprint or password ; puncture resistant gloves ; better handcuffs ; better concealed weapon detection ; and personnel tracking and location technologies ; less - than - lethal technologies , developing alternatives to lethal force , including technologies involving electrical or chemical effects , light barriers , vehicle stopping , and blunt trauma , and evaluating and modeling the effects of these technologies ; learning technologies , developing technology tools for agencies to use in training their personnel , including use of the internet , cd - roms , and video - based and interactive simulations ; and standards and testing , ensuring that the equipment public safety agencies buy is safe , dependable , and effective .

as with other federal agencies , ost's operations involve multiple levels of internal organization and multiple kinds of external partners .

ost's multiple levels of organization include a washington , d.c. , office that manages its technology programs and a network of technology centers around the country that provide technical assistance to ost's regional customers .

ost also collaborates with other r&d entities , such as those in the departments of defense and energy and public and private laboratories , by forming technical partnerships in order to leverage already established technical expertise and resources to support their program efforts .

another aspect of ost's complex operations is the need to determine ost's own priorities and the priorities of its customers , which involves washington and regional center staff collaborating formally and informally with a myriad of federal , state , and local officials , as well as with one another .

ost's multiple levels of organization include a washington , d.c. , office and technology centers , as well as technical partnerships with government , public and private r&d and public safety organizations .

as of september 2003 , ost's washington office consisted of 25 full - time - equivalent justice staff divided into three divisions and under the assistant nij director for ost .

responsibility for managing these programs is divided among the three divisions .

 ( see figure 3 for ost's organizational structure. ) .

research and technology development division manages electronic crime ( including cybercrime ) , critical incidents and counterterrorism , communications interoperability and information sharing , crime prevention , learning technology tools , less - than - lethal technologies , standards development , school safety , and corrections technologies .

investigative and forensic sciences division manages dna - related r&d and other investigative and forensic sciences , such as fingerprint analysis , and includes the crime laboratory improvement program projects , dna backlog reduction projects , and dna research and development projects .

technology assistance division , through the technology center network , provides training and technical advice to , and identifies technologies for , ost's customers , and oversees ost's network of 10 technology centers ( see figure 4 ) .

the technology centers are another source of technical advice for ost's customers .

ost's network of 10 technology centers provides technical assistance , among other things , to ost's customers .

from fiscal year 1995 to fiscal year 2003 ( as of july 2003 ) , funding support for the centers totaled $171.7 million .

 ( see table 8 for funding by center. ) .

the technology centers comprise six regional centers and four specialty centers .

while the regional centers assist ost's customers by region — northwest , west , rocky mountain , northeast , southeast , and national — they are expected to coordinate and collaborate among one another regardless of where the resources and capabilities are located .

each of these 6 centers works with a regional advisory council comprising state and local law enforcement , corrections , and public safety representatives .

as described below , the four specialty centers provide specialized expertise and services .

the office of law enforcement standards tests commercially available equipment and develops minimum performance standards for such equipment .

the office of law enforcement technology commercialization , inc. , assists inventors and developers , among others , in commercializing technologies .

the border research and technology center aids in the development of technologies for agencies concerned with law enforcement at the northern and southern borders .

the rural law enforcement technology center aids rural and small - community law enforcement and corrections agencies .

in addition to forming divisions and technology centers , ost has also formed partnerships with governmental , public and private r&d organizations , agencies , and working groups .

according to ost officials , an advantage of these partnerships is that ost can leverage the expertise and resources of already established r&d facilities without having to create their own .

these partners have included corporations , such as georgia tech research corporation and l - 3 communications , analytics corporation ; state and local agencies , such as the houston police department and the washington metropolitan area transit authority ; academic institutions , such as the university of virginia and syracuse other federal government agencies , such as the department of defense's army training and doctrine command , and the department of transportation's federal aviation administration ; and foreign government organizations , such as the royal canadian mounted police , the united kingdom police scientific development branch , and the government of israel .

each of ost's technology centers is affiliated with one or more of ost's technical partners .

these technical partners are awarded funding in exchange for providing staff and facilities to the technology centers .

table 9 lists ost's partners and their affiliations , and funding they received to support the centers through june of fiscal year 2003 .

to determine its program priorities , ost collaborates with its many customers and partners .

staff at both ost's washington , d.c. , office and its technology centers are involved in helping ost to set program priorities .

the staff report the results of their collaboration through formal meetings , periodic reports , and informal communication .

input is exchanged continually between ost's customers and staff and within its multiple levels of organization .

using their input , the nij director determines ost's program priorities .

 ( see figure 5 for the stakeholders , partners , and customers that contribute to the setting of ost's priorities. ) .

ost's three divisions collaborate with other u.s. government agencies , the research and professional communities , and its technology centers to solicit input for setting priorities .

also , the divisions work with public safety practitioners at the state and local levels by , for example , meeting with grantees and assessing their needs .

the investigative and forensic sciences division collaborates with , and receives input from , researchers , academia , and the forensic laboratory community to help set program priorities .

it also collaborates with , for example , the fbi and the interagency technical support working group .

the research and technology development division receives input through its collaboration with other federal agencies , such as the fbi , drug enforcement administration , u.s. secret service , and white house office of national drug control policy .

the division also participates in interagency working groups , such as for school safety and the technical support working group .

through these collaborations , ost can develop and share technologies used by both its customers and other agencies .

for example , ost works with the department of defense to conduct less - than - lethal weapons r&d for law enforcement .

the technology assistance division is primarily responsible for receiving input from ost's technology centers .

the centers solicit input from customers through their outreach efforts , such as technical assistance , e - mail exchanges , and telephone calls .

the centers are also required to use ost's web - based reporting system to record information on their customers' requests for technical assistance .

the centers are also required to submit monthly reports on their activities and finances .

ost's technology centers solicit input from the national and regional advisory councils that ost created to determine and advocate for the particular needs of its customers .

members of the national advisory council are selected by the technology centers and represent federal , state , and local public safety agencies , as well as international criminal justice organizations .

among its duties , this national advisory council identifies the present and future equipment and technology needs of ost's customers and reviews the programs of the technology centers .

in addition , the national advisory council recommends ( 1 ) ways to improve the technology centers' programs' relevance to the needs of the centers' customers and ( 2 ) broad priorities for the technology center network and ost that are consistent with the needs of their customers .

each technology center has a regional advisory council .

the regional advisory councils consist of a cross - section of law enforcement and other public safety officials who represent the interests of state and local officials .

the regional advisory councils solicit input from the state and local agencies serviced in their regions , advise and support their respective center directors on their customers' problems and needs , and advocate for resource support and improvements required by their customers .

through this method of sharing information , ost can better understand the needs of its customers .

for example , ost's regional councils can represent the unique needs of their customers that the national advisory council or the technology centers might not be aware of .

reduce dna backlog and support a functioning , active system , which can solve old crimes and prevent new ones from occurring .

1 .

number of labs demonstrating improved access to external capabilities and increased lab capabilities .

2 .

number of samples ( 1 ) analyzed using the selected dna markers that are required by the fbi's national combined dna index system ( codis ) database , and ( 2 ) made available for codis .

3 .

number of states that have experienced an increase in the number of samples they have contributed to the national database .

reduce dna backlog and support a functioning , active system , which can solve old crimes and prevent new ones from occurring .

4 .

number of dna samples from cases where there is no known suspect .

improve quality , timeliness , and credibility of forensic science services .

5 .

number of forensic labs with improved analytic and technological resources .

improve the ability of public safety responders , including law enforcement and corrections officers , to deal with critical incidents , save lives , and reduce property loss .

6 .

number of technology demonstrations and test indicators that describe the goods and services produced .

7 .

number of prototype technologies developed .

8 .

number of guides , standards , and assessments in progress .

9 .

number of guides , standards , and assessments completed .

10 .

number of technologies introduced in law enforcement and corrections agencies .

develop faster and more powerful tools and techniques for the analysis of dna evidence .

these new tools and techniques will result in more crimes prevented and solved and more perpetrators brought to justice .

11 .

number of projects researching new forensic dna markers .

12 .

number of development / validation studies for forensic dna techniques .

13 .

number of computer programs developed for forensic dna analysis .

14 .

number of prototypes and tools for forensic dna analysis .

assist in applying technology to reduce the vulnerability of critical infrastructure ; detect weapons and other contraband ; improve technologies to locate and differentiate between individuals in structures ; leverage information technology to enhance the responder community's ability to anticipate and deal with critical incidents ; identify and respond to terrorist attacks involving chemical , biological , and other unconventional weapons ; and develop needed standards .

15 .

number of technology demonstrations and tests .

16 .

number of prototype technologies developed .

17 .

number of guides , standards , and assessments in progress .

18 .

number of guides , standards , and assessments completed .

19 .

number of technologies introduced in law enforcement and corrections agencies .

20 .

number of technology demonstrations .

assist school administrators and law enforcement in creating a safer and more productive learning environment .

safe , effective , appropriate , and affordable technologies can affect the perception and reality of safe schools .

21 .

number of conferences and forums .

22 .

number of school safety technology products .

provide immediate results in solving more crimes , bringing to justice more criminals , and improving administration of justice through the presentation of strong , reliable forensic evidence at trial .

forensic services .

24 .

number of capacity - building forensic r&d and validation projects funded .

25 .

number of forensic technology training tools developed and distributed .

26 .

number of labs providing continuing education or advanced training to crime analysts .

27 .

number of crime labs with increased capacity for implementation of new forensic capabilities ( including dna analysis ) .

28 .

number of capacity - building forensic r&d and validation projects completed and impacting crime labs .

29 .

number of labs establishing new forensic capabilities .

30 .

number of labs expanding current forensic capabilities .

31 .

number of labs experiencing a reduction in time needed for evidence analysis .

32 .

number of labs experiencing a reduction in backlogged evidentiary sample analysis .

help the public safety community make informed decisions about products being marketed for public safety personnel .

33 .

number of methods for examining evidentiary materials developed .

34 .

number of standards for equipment and operating procedures developed .

35 .

law enforcement technology deliverables ( standards , product performance evaluations , product guides ) .

develop a firearm that could save the lives of law enforcement officers and members of the public that they encounter while performing their duties .

36 .

successful demonstration of prototype recognition system for smart gun .

37 .

failure mode analysis for prototype recognition system for smart gun .

38 .

incorporation and demonstration of recognition system into firearm ( where applicable ) .

39 .

identification of appropriate biometric solutions for recognition system ( where applicable ) .

help state and local law enforcement , corrections , and public safety personnel do their jobs more safely and efficiently , thereby leading to greater administrative efficiencies , more crimes solved , and more lives saved .

40 .

number of technology information documents distributed .

41 .

number of practitioners trained through the crime mapping program .

42 .

savings to criminal justice agencies through the dod's section 1033 military surplus program .

section 1033 of the national defense authorization act for fiscal year 1997 authorizes dod to transfer excess military property to federal and state agencies to support law enforcement activities including counterdrug and counterterrorism activities .

in addition to those named above , the following individuals contributed to this report: samuel l. hinojosa , debra l. picozzi , katherine m. davis , richard hung , geoffrey r. hamilton , denise m. fantone , kristeen mclain , elizabeth h. curda , rebecka derr , thomas m. beall , and leo m. barbour .

