the department of defense ( dod ) is one of the largest and most complex organizations in the world .

to meet its mission to protect the security of our nation and to deter war , it relies heavily on the use of information technology ( it ) and information systems to support warfighters .

in this regard , according to dod's it investment portfolio for fiscal year 2017 , the department spent approximately $33.4 billion for it investments .

of this amount , approximately $2.5 billion was spent on major automated information system ( mais ) programs , which include business and non - business information systems that help the department sustain its key operations in communications and command and control , and provide it with access to information to organize , plan , and monitor mission operations .

a dod it investment that falls within one of the following categories is designated as a mais program when: ( 1 ) program costs in any single year exceed $40 million , ( 2 ) total program acquisition costs exceed $165 million , or ( 3 ) total life - cycle costs exceed $520 million .

the secretary of defense could also use discretion to designate a program as a mais program if it did not meet these cost thresholds .

the national defense authorization act for fiscal year 2012 includes a provision that we select , assess , and report on dod mais programs annually through march 2018 .

gao satisfied the statutory mandate by submitting a draft of the report to congressional committees on march 29 , 2018 .

this final version of the report is the sixth and last report in the series of annual mandated assessments .

our specific objectives for this review were to ( 1 ) assess dod's policy for the management and oversight of mais programs ; ( 2 ) describe the extent to which selected mais programs have changed their planned cost and schedule estimates and met performance targets ; and ( 3 ) assess the extent to which selected mais programs have used leading it acquisition practices , including requirements and risk management .

to address the first objective , we assessed dod's memorandums and policies for managing mais programs .

to evaluate dod's approach in managing and overseeing mais programs , we identified leading it management practices in gao's information technology investment management guide and compared dod's policies to those practices .

we also interviewed an acquisition official responsible for the department's plan to update its policies for administering how mais programs are to be managed and monitored .

to address the second objective , we used dod's official list of 34 mais programs , as of april 18 , 2017 , to establish a basis for selecting programs .

from this list , we identified those mais programs based on our criteria that programs must be unclassified and have a first acquisition program baseline that could be used as a reference point for evaluating cost , schedule , and technical performance characteristics .

based on these criteria , we selected 15 of the 34 mais programs for our review .

we then compared each program's cost ( in then - year dollars ) and schedule estimates established in the first acquisition baseline to the latest total life - cycle cost and schedule estimates .

in addition , to determine whether system performance targets were met , we identified nine mais programs that had conducted performance tests .

we then compared each program's initial and most recent baseline performance targets .

to address the third objective , we selected three programs that had not been included in our last assessment , while seeking to ensure that we had representation from at least one military service and at least one defense agency .

using these criteria , we selected the navy's consolidated afloat networks and enterprise services ; defense logistics agency's defense agencies initiative , increment 2 ; and defense health agency's department of defense healthcare management system modernization .

we then identified requirements and risk management practices in the software engineering institute's capability maturity model® integration for acquisition ( cmmi® - acq ) and assessed each of the three programs against these criteria .

specifically , regarding risk management practices , we analyzed each program's key documents , such as the risk register logs , risk management plans , and other artifacts , and compared them to the leading practices .

regarding requirements management , we compared requirements documents , such as the requirements management plan , traceability matrix , and procedural tools to the leading practices .

we also conducted follow - up interviews with project officials regarding the management practices of each program .

to assess the reliability of the data we used to support the findings in this report , we corroborated program office responses with relevant program documentation and interviews with agency officials .

we determined that the data were sufficiently reliable for our reporting purposes .

since we selected a nonprobability sample of mais programs , the results of our analysis are not generalizable to all mais programs .

see appendix i for a more detailed discussion of our objectives , scope , and methodology .

we conducted this performance audit from april 2017 to may 2018 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

dod's organizational structure includes the office of the secretary of defense , the joint chiefs of staff , the military departments , numerous defense agencies and field activities , and various unified combatant commands that contribute to the oversight of dod's acquisition programs .

prior to february 2018 , the former under secretary of defense for acquisition , technology , and logistics also served as the principal acquisition official of the department and was the acquisition advisor to the secretary of defense .

the former under secretary also served as the defense acquisition executive and was the official responsible for supervising the acquisition of mais programs .

the former under secretary's authority included directing the military services and defense agencies on acquisition matters and making milestone decisions for mais and other programs .

this official also had policy and procedural authority for the defense acquisition system , which establishes the steps that dod programs generally take to plan , design , acquire , deploy , operate , and maintain the department's information systems .

however , as of february 2018 , the department changed the way it conducts business and operations with the statutory elimination of the office of the under secretary of defense for acquisition , technology , and logistics .

the statute contains a provision that required dod to establish a new office of the under secretary of defense for research and engineering to be responsible for driving innovation and acceleration of the advancement of warfighting capability .

in addition , a new office of the under secretary of defense for acquisition and sustainment was created to focus on delivering proven technology more quickly .

the creation of these offices within the department is intended to shift the principal focus of the office of the secretary of defense from a role of program oversight to that of directing major department investments .

further , the statutory creation of a chief management officer to replace the former deputy chief management officer is intended to improve the quality and productivity of the department's business operations .

in january 2015 , dod updated its guidelines that outline the framework for mais programs .

this framework consists of six models for acquiring and deploying a program , including two hybrid models that each describe how a program may be structured based on the type of product being acquired ( eg , software - intensive programs and hardware - intensive programs ) .

a generic acquisition model that shows all of the program life - cycle phases and key decision points is depicted in figure 1 and described below .

materiel solution analysis: refine the initial system solution ( concept ) and create a strategy for acquiring the solution .

a decision — referred to as milestone a — is made at the end of this phase to authorize entry into the technology maturation and risk reduction phase .

technology maturation and risk: determine the preferred technology solution and validate that it is affordable , satisfies program requirements , and has acceptable technical risk .

a decision — referred to as milestone b — is made at the end of this phase to authorize entry of the program into the engineering and manufacturing development phase and award development contracts .

an acquisition program baseline is first established at the milestone b decision point .

a program's first acquisition program baseline contains the original life - cycle cost estimate ( which includes acquisition and operations and maintenance costs ) , the schedule estimate ( which consists of major milestones and decision points ) , and performance parameters that were approved for that program by the milestone decision authority .

the first baseline is established after the program has refined user requirements and identified the most appropriate technology solution that demonstrates that it can meet users' needs .

engineering and manufacturing development: develop a system and demonstrate through testing that the system meets all program requirements .

a decision — referred to as milestone c — is made during this phase to authorize entry of the system into the production and deployment phase or into limited deployment in support of operational testing .

production and deployment: achieve an operational capability that meets program requirements , as verified through independent operational tests and evaluation , and implement the system at all applicable locations .

operations and support: operationally sustain the system in the most cost - effective manner over its life cycle .

we have developed and identified leading practices for governing it investments to help guide organizations to better manage and oversee their projects .

gao's information technology investment management guide states that good performance data and stakeholder oversight are elements that can lead to positive outcomes , such as helping to ensure a project is keeping to its initial cost , schedule , and performance goals .

the guide also states that projects should be reviewed at regular intervals to monitor performance so that stakeholders can be aware of and review any differences between actual outcomes and goals .

in addition , we and other entities , such as the software engineering institute at carnegie mellon university , have identified leading practices to help guide organizations to effectively plan and manage their acquisitions of major it systems .

our prior reviews have shown that proper implementation of such practices can significantly increase the likelihood of delivering promised system capabilities on time and within budget .

these practices include , but are not limited to: requirements management: requirements establish what the system is to do , how well it is to do it , and how it is to interact with other systems .

appropriate requirements management involves eliciting and developing customer and stakeholder requirements , and analyzing them to ensure that they will meet users' needs and expectations .

it also consists of validating requirements as the system is being developed to ensure that the final systems to be deployed will perform as intended in an operational environment .

risk management: risk management is a process for anticipating problems and developing plans to take appropriate steps to mitigate risks and minimize their impact on program commitments .

it involves identifying and documenting risks , categorizing them based on their estimated impact , prioritizing them , developing risk mitigation strategies , and tracking progress in executing the strategies .

according to gao's information technology investment management guide , leading practices for managing it projects include: instituting the investment board , which is the process for creating and defining the membership , guiding policies , operations , roles , responsibilities , and authorities within the organization ; identifying decision authorities for making important acquisition decisions ; providing oversight whereby the organization monitors each project on its performance progress ( eg , establishing and tracking baseline estimates on cost and schedule goals , and thresholds to identify high risk on cost and schedule ) ; and capturing and providing performance information about a particular investment ( project ) to decision makers at regular intervals ( eg , quarterly and annually ) .

to align mais programs with the functions they perform , dod recently made changes in how it characterizes its mais programs and , as a result , different programs must follow different management policies .

specifically , in april 2017 , dod identified 10 of 34 total mais programs as business programs and the director , acquisition resources and analysis announced that these programs would adhere to dod's instruction 5000.75 policy for management and oversight .

further , in november 2017 , the former under secretary of defense for acquisition , technology , and logistics announced that non - business mais programs would adhere to dod's instruction 5000.02 policy for management and oversight .

however , the policies used for mais business programs are not consistent in their adherence to leading it management practices .

for example , while the policy for non - business mais programs is consistent in its adherence to all four of the leading it management practices , the policy for mais business programs is consistent in its adherence to only two of the four practices .

table 1 shows our analysis of dod's policies for non - business mais programs and mais business program and their adherence to the leading it management practices .

as shown in the table , dod's policy for non - business mais programs adheres to all four leading it management practices .

for example , the policy requires non - business mais programs to report the status of each program's cost , schedule , and technical performance information quarterly and annually .

the policy also designates specific decision makers who are responsible for monitoring and overseeing the progress of non - business system mais programs .

further , the policy requires each program to establish and report their initial baseline estimates and current estimates on cost and schedule so their performance can be tracked and monitored .

in addition , to identify when programs may be at risk of significant cost or schedule increases , the policy requires programs to predetermine cost and schedule threshold estimates as an early warning indicator on when programs reach the point where they are at increased risk .

in contrast , dod's policy for mais business programs policy only adheres to two of the four practices .

specifically , the policy adheres to the practice of instituting an investment board with processes for creating and defining the membership , policies , operations , roles , responsibilities , and authorities within the organization .

in addition , the policy identifies decision authorities for making important executive - level acquisition decisions .

however , the policy does not specify the establishment of initial and current baseline estimates on cost and schedule , and does not specify the reporting of threshold cost and schedule estimates to identify the point when programs may be at high risk .

in addition , the policy does not adhere to leading practices requiring the periodic ( quarterly and annual ) reporting of performance information to stakeholders .

to help address the need for improved guidance , the former under secretary of defense for acquisition , technology and logistics established a cross - functional team that is to examine the future of non - business mais programs and mais business programs from a policy , organization , management , and reporting perspective .

the team was expected to provide its recommendations to the under secretary of defense for acquisition and sustainment by march 15 , 2018 .

however , because no final decisions had been made by the under secretary as of that date , it is unclear what specific actions the department will take regarding its policy recommendations , among other recommendations , to improve the management of non - business mais programs and mais business programs .

until dod updates its policy for mais business programs to adhere to leading practices on the establishment of baseline estimates on cost and schedule to include threshold estimates on cost and schedule to identify when programs may be at high risk , stakeholders may not have the information they need to manage and oversee mais business programs .

further , unless the department updates its policy for mais business programs to adhere to the leading practice for periodically ( quarterly and annually ) reporting essential performance information , stakeholders may not have the information they need to make informed decisions for managing and overseeing mais business programs .

all of the 15 selected mais programs had either increased or decreased their planned cost estimates , and 10 of them had delays in their planned schedule estimates when comparing the first acquisition program baseline to the most recent acquisition program baseline estimates .

the changes in the cost estimates ranged from a decrease of $1.6 billion ( - 41 percent ) to an increase of $1.5 billion ( 163 percent ) , and slippages in the schedule estimates ranged from a delay of 5 years to a delay of 5 months .

further , 9 of the 15 selected programs had conducted testing in which we could report on the number of performance targets met for each program .

of those 9 , 6 programs reported that they had met all of their performance targets .

the remaining 3 programs reported that they met several but not all performance targets .

the following table shows the extent of changes in planned cost and schedule estimates for the selected mais programs since the first baseline estimate , as well as the number of performance targets met .

all 15 selected mais programs had experienced increases or decreases in their planned cost estimates when comparing the initial , or first , baseline estimate to the current estimate .

specifically , 10 programs had decreases in their cost estimates that ranged from $1.2 million ( less than - 1 percent ) for the defense agencies initiative , increment 2 program to $1.6 billion ( - 41 percent ) for the air force's base information transport infrastructure wired program .

program officials reported that reductions in planned cost estimates were due to changes in program scope .

specifically , the reasons for reduction in cost include: program scope changes .

officials for the air force's joint space operations center mission system increment 2 program reported that its 12 percent cost decrease was due to a reduction in its estimate for operations and support that was changed from 20 years to 10 years .

officials for the defense information systems agency's global combat support system – joint increment 8 program reported that its 20 percent cost decrease was due to a reduction in the program's scope for the number of development hours required to meet the logistics and operational needs .

in addition , officials for the defense information systems agency's teleport generation 3 program reported that its 22 percent cost decrease was due to a revised scope in terms of what is needed at the milestone c decision point for low rate production .

design reconfiguration .

officials for the air force's base information transport infrastructure wired program reported that its 41 percent cost decrease was due to a reduction in the program's scope when they changed from a base network system to a critical core configuration .

in addition , 5 of the programs had experienced cost increases .

these cost increases ranged from $2.9 million ( less than 1 percent ) for the army's logistics modernization program increment 2 to $1.5 billion ( 163 percent ) for the army's tactical mission command program .

program officials reported a variety of reasons for the increases in planned cost estimates .

these reasons included the following: underestimating schedule .

officials for the air force's defense enterprise accounting and management system increment 1 program attributed its 60 percent cost increase to underestimating the level of effort that was needed to develop the system within the estimated schedule .

for example , the program did not account for software upgrades and , when this effort was added to the schedule to account for the work , the cost increased .

contractor issues .

officials from the national security agency's key management infrastructure increment 2 program attributed its cost increase of 14 percent to schedule delays caused by the contractor and , as a result , increased funding at the milestone c decision point .

underestimating development and test efforts .

officials from the army's tactical mission command program attributed the cost increase of 163 percent to higher than expected costs to conduct research and developmental tests .

ten of the 15 selected mais programs had experienced changes in their planned schedule estimates , and 5 programs had no changes to their schedule estimates .

the changes consisted of schedule slippages that ranged from 5 months for both the army's logistics modernization program increment 2 and the defense health agency's department of defense healthcare management system program , to 5 years for the defense enterprise accounting and management system increment 1 program .

program officials reported that delays in the planned schedule estimates were due to unplanned budget reductions or unrealistic expectations regarding project milestones .

specifically , the reasons for these schedule slippages included: aggressive schedule , funding reduction , and contract issues .

officials for the air force's joint space operations center mission system increment 2 program attributed its schedule slippage of 2 years and 11 months to funding reductions of $18.9 million in fiscal years 2013 and 2014 .

in addition , the officials noted that an aggressive schedule for a milestone b decision , contracting issues in the earlier acquisition phase , and longer than expected time to obtain personnel had contributed to the slippage .

longer than expected time to reach deployment .

officials for the air force's defense enterprise accounting and management system increment 1 program reported that its schedule slippage of 5 years occurred because of a change in the approach to deliver the system in multiple increments , thereby increasing the amount of time it would take to reach the deployment decision milestone .

also , officials for the defense information systems agency's teleport generation 3 program reported a 3-year and 2-month slip .

this schedule delay was due to the program's inability to develop the mobile user and system interface capability by the estimated deployment milestone .

further , program officials for the navy's consolidated afloat networks and enterprise services program attributed its schedule slip of 2 years and 6 months to a longer than expected maintenance period for the test platform and to a lengthy budget approval process , resulting in a slippage in the deployment date .

unplanned procurement fund reduction .

officials for the army's global combat support system - army program reported that its schedule delay of 11 months was due , in part , to a $16 million dollar decrease to the fiscal year 2016 budget .

this unplanned reduction in procurement fund affected their ability to field the system as originally planned .

contractor staffing issues .

officials for the national security agency's key management infrastructure increment 2 program reported significant schedule delays due to the contractor's inability to staff the program with software developers that had the required security clearances .

as a result , a critical change was reported in january 2012 that led to a new independent cost estimate , which extended program development by 10 months .

the new estimate included additional time to improve the governance structure , such as increasing discipline across the oversight process , adding more stakeholder interaction , and improving the use of metrics .

among other information , dod uses key performance parameters as a metric to report on programs' progress toward meeting system performance targets .

this information includes a description of the performance characteristics , the objective and threshold value for each target and , importantly , whether the target has been met in demonstrating performance .

of the nine programs we evaluated , six programs reported that they met all of their performance targets .

for example , the navy's common aviation command and control system , increment 1 program reported in may 2017 that both of its technical performance targets had been met .

according to the program , these targets were related to the readiness of the system to fully support all operational activities and satisfy all technical requirements for military operations and the fusion of all kinds of data onto any workstation .

in another example , the army's logistics modernization program increment 2 program reported in june 2017 that all seven of its performance targets had been met .

according to the program , these targets were related to the system's ability to support military operations , exchange information in the network , provide system and information assurance in a disaster recovery scenario , and be operationally available .

further , three programs reported that they met several , but not all , of their performance targets .

for example , the navy's consolidated afloat networks and enterprise services program reported that it met eight of nine performance targets .

according to program officials , the remaining target ( i.e. , network shall fully support joint critical operational activities ) had not been met because the program lacked an operational platform that was required to demonstrate its performance .

the defense information systems agency's teleport generation 3 program reported that it met 8 of 12 performance targets .

according to programs officials , the remaining 4 targets ( i.e. , coverage to allow warfighter communications , capacity to provide 100 percent of the required services , and interoperability with military and commercial frequencies and wave forms ) had not been met because the program needed to field multiple systems and perform solution testing , which they expect to be completed in fiscal year 2018 .

further , the air force's defense enterprise accounting and management system increment 1 program officials reported that it met 3 of 4 targets ( i.e. , compliance with requirements , network ready , and sustainment to ensure materiel availability ) .

the officials reported that the program did not meet the remaining target because it was waiting for an evaluation of cyber test results before proceeding .

according to the software engineering institute's capability maturity model integration® for acquisition ( cmmi® - acq ) , an appropriate requirements management process involves establishing an agreed - upon set of requirements , ensuring traceability between requirements and work products , and managing any changes to the requirements in collaboration with stakeholders .

likewise , an effective risk management process identifies potential problems before they occur , so that risk - handling activities may be planned and invoked , as needed , across the life of the project in order to mitigate the potential for adverse impacts .

leading requirements management practices help organizations to better manage the design , development , and delivery of systems within established cost and schedule time frames .

these practices include developing an understanding with the requirements providers of the meaning of the requirements , obtaining commitment to requirements from project participants , managing changes to requirements as they evolve during the project , maintaining bidirectional traceability among requirements and work , ensuring that project plans and work products remain aligned with requirements .

an effective risk management process includes the following leading practices determining risk sources and categories ; defining parameters used to analyze and categorize risks and to control the risk management effort ; establishing and maintaining the strategy to be used for risk identifying and documenting risks ; evaluating and categorizing each identified risk using defined risk categories and parameters , and determining its relative priority ; developing a risk mitigation plan in accordance with the risk monitoring the status of each risk periodically and implementing the risk mitigation plan as appropriate .

the three selected mais programs that we evaluated had fully implemented most , but not all , of the five leading practices for managing requirements and the seven leading practices for managing risks .

specifically , two of three programs implemented all of the requirements management practices , while one program implemented most , but not all , of the practices .

further , one of three programs implemented all of the risk management practices , while two programs implemented most , but not all of the practices .

table 3 shows the extent to which practices were implemented by the three selected programs .

two of the three programs had fully implemented the requirements management practices .

the other program had partially implemented two practices and fully implemented three practices .

navy — navy consolidated afloat networks and enterprise services the navy had fully implemented the five requirements management practices for the consolidated afloat networks and enterprise services program .

for example , the program developed an understanding with requirements providers of the meaning of the requirements .

specifically , there was a plan for documenting , managing , and controlling changes to requirements throughout the system lifecycle .

this plan served as the primary guidance for integrating the management of all specified and derived requirements for the consolidated afloat networks and enterprise services system program .

in addition , the program had established criteria for determining requirements providers .

specifically , roles and responsibilities for requirements management had been identified .

further , the program managed changes to requirements as they evolved during the project .

for example , the program provided evidence that it maintains a requirements change history , including the rationale for changes .

defense logistics agency — defense agencies initiative , increment 2 the defense logistics agency had fully implemented the five requirements management practices for the defense agencies initiative , increment 2 .

for example , the program had established objective criteria for the evaluation and acceptance of requirements .

specifically , there was a process in place to develop and finalize deliverables in support of the business requirements identified by the stakeholders , ensure that requirements management activities were performed in a timely manner throughout the life of the project , and review and approve requirements deliverables .

further , throughout the process , the requirements manager tracked requirements changes and maintained traceability of end user needs to the system performance specification .

the defense health agency had fully implemented three and partially implemented two of the five requirements management practices for the defense healthcare management system modernization program .

for example , the program had established objective criteria for the evaluation and acceptance of requirements .

specifically , any new or updated requirements were presented to a configuration steering board for review and approval prior to any changes being made .

further , throughout the process , the requirements manager tracked requirements changes and maintained traceability to ensure they were documented .

the program has not developed an understanding with the requirements providers on the specific meaning of the requirements .

for example , although the program had developed a requirements management plan which provided guidance in this area , according to program officials , the plan was not signed and approved based on the recent shift of the program from a non - business mais program to a mais business program operating under dod instruction 5000.75 .

program officials stated that the requirements management plan is not expected to be complete until final guidance is provided by the office of the secretary .

regardless of this recent shift , the program should have already had an approved requirements management plan in place since program initiation .

in the absence of an approved plan , the program lacks assurance that it can effectively communicate and manage requirements practices .

further , the program had not demonstrated that it identified any changes that should be made to plans and work products resulting from changes to the requirements baseline .

programs officials stated that efforts to review modifications to the plan due to requirements changes had not been conducted , but they expected the review and approval to be done at some future date .

however , they could not provide a specific time frame .

according to cmmi® - acq , until project plans and work products are updated to coincide with changes in requirements , the program will not be able to effectively identify inconsistencies between requirement changes and project plans and work products , and initiate corrective actions to resolve them .

one program had fully implemented the risk management practices , while two had fully implemented all but one practice .

navy — navy consolidated afloat networks and enterprise services the navy had fully implemented six and partially implemented one risk management practice for the consolidated afloat networks and enterprise services system program .

for example , the program's risks defined consistent criteria for evaluating and quantifying risk likelihood and severity levels .

specifically , the program provided a risk exposure ( eg , a risk source used to examine and oversee changes that impact the project ) , which is the value that is given to a risk event , a product , or the overall program based on the analysis of the probability and consequences of the event .

further , the program's risk management guide outlined risk performance , cost , and schedule criteria .

in addition , the program demonstrated that it included the cost and benefits of implementing risk mitigation plans .

specifically , a risk's description provided the cost impacts associated with the risk , which in turn provided evidence that cost and benefits were considered during risk evaluation .

however , the navy partially implemented one practice .

specifically , although the program provided its failover / recovery plan that is intended to return the program to a state of readiness after a failure , the plan did not explicitly identify environmental elements .

a program official stated that environmental factors , such as risks that could negatively affect their work , is understood , but these factors had not been documented in the plan .

further , the official stated that the program should update the plan accordingly , but did not provide a time frame to complete this effort .

until all potential issues , hazards , threats , and vulnerabilities that could negatively affect work efforts have been identified in the plan , successful risk management cannot be ensured .

defense logistics agency — defense agencies initiative , increment 2 the defense logistics agency had fully implemented all seven risk management practices for the defense agencies initiative , increment 2 .

for example , the program identified program risks , including risk sources , categories , and stakeholders .

in addition , defense agencies initiative , increment 2 risks followed consistent criteria for evaluating and quantifying risk likelihood and severity levels .

specifically , risk level was based on a combination of factors to include both likelihood and consequence .

in all instances , consensus on the risk levels was required between the risk owner and the customer counterpart .

further , the program's contingency plan provided guidance when outages fell into one of three disaster categories including natural disasters , man - made disasters , and technological disasters .

defense health agency — defense healthcare management system modernization the defense health agency had fully implemented six and partially implemented one of the seven risk management practices for the defense healthcare management system modernization program .

for example , the program's risks followed consistent criteria for evaluating and quantifying risk likelihood and severity levels .

specifically , the program's risk and issue management plan described how to assess the impact level in each risk area ( performance , project and program schedules , and cost ) .

further , the program prioritized risks for mitigation .

for example , risks were categorized and charted as low , medium , or high , and grouped accordingly in the program's risk register .

further , the program's disaster recovery plan provides processes that allowed rapid support recovery for critical operations during a disaster , including environmental disasters such as tornadoes .

regarding the partially implemented practice , the program provided an example of a risk mitigation plan .

however , the program indicated that costs and benefits were not quantified within the program - level risk mitigation plans .

according to cmmi® - acq , risk mitigation activities should be examined for benefits they provide versus resources they will expend .

just like any other design activity , alternative plans may need to be developed and costs and benefits of each alternative assessed .

however , the program does not require that costs and benefits be included as part of its risk mitigation planning efforts .

as a result , the information for making an informed decision on cost and benefits of risk mitigation solutions is limited .

program officials did not indicate whether they have plans to implement this practice , and did not provide an explanation as to why they are unable to provide this information .

until the program quantifies costs and benefits , it will not be able to effectively select the most appropriate risk mitigation plan to address each risk .

while dod's policy for non - business mais programs adheres to all four leading it management practices , the department's policy for mais business programs does not adhere to two leading practices on establishing initial and current baseline estimates on cost and schedule and predetermining threshold estimates , as well as reporting periodically on performance information to stakeholders .

until dod adheres to these practices in its policies that govern mais business programs , it cannot ensure that stakeholders will have the information they need to manage and oversee their investments .

following leading it acquisition practices on requirements and risk management is essential to help programs effectively plan and direct their development and acquisition efforts .

all of the leading it acquisition practices for requirements and risk management had been fully or partially implemented by three programs that we reviewed .

however , the defense health agency's defense healthcare management system modernization has not finalized its requirements management plan nor has it identified changes that should be made to plans and work products resulting from changes to the requirements baseline .

until the program addresses these practices , it will lack a comprehensive plan for managing its requirements and it may not be able to effectively identify inconsistencies and initiate corrective actions .

further , the navy consolidated afloat networks and enterprise services program did not fully identify and document risks that could negatively affect work efforts .

in addition , the defense health agency's defense healthcare management system modernization did not quantify costs and benefits of risk mitigation within its program - level risk mitigation plans .

as a result , successful risk management for avoiding , reducing , and controlling the probability of risk occurrence cannot be ensured .

we are making the following three recommendations to the secretary of defense to direct: the under secretary of defense for acquisition and sustainment to update the policy or guidance for mais business programs .

specifically , the update should include the following elements: establishment of initial and current baseline cost and schedule predetermined threshold cost and schedule estimates to identify the point when programs may be at high risk , and quarterly and annual reports on the performance of programs to stakeholders .

 ( recommendation 1 ) the director of the defense health agency to direct the program manager for the defense healthcare management system modernization program to: finalize and approve its requirements management plan , identify and document changes that should be made to plans and work products resulting from changes to the requirements baseline , and quantify costs and benefits of risk mitigation within its program - level risk mitigation plans .

 ( recommendation 2 ) the secretary of the navy to direct the program manager for the navy consolidated afloat networks and enterprise services program to: identify and document , in the failover / recovery plan , all potential external environmental issues , such as hazards , threats , and vulnerabilities that could negatively affect work efforts .

 ( recommendation 3 ) .

dod provided written comments on a draft of this report , which are reproduced in appendix ii .

in its comments , the department partially concurred with our first recommendation and concurred with the two other recommendations .

dod partially concurred with the first recommendation on updating the policy or guidance for mais business programs .

specifically , the under secretary of defense for acquisition and sustainment stated that regarding establishing baselines , the dod instruction 5000.75 requires establishment of cost , schedule , and performance parameters for each release before development or delivery .

the 5000.75 also requires consideration of program progress against baselined cost , schedule , and performance as a criterion at the limited deployment and full deployment decision points .

a baseline requirement thus exists in dod instruction 5000.75 but it is not described as an acquisition program baseline , which may be familiar to readers of dod instruction 5000.02 .

however , the under secretary added that the army's implementation guidance includes guidance that states each increment must have an acquisition program baseline with its own set of threshold and objective values set by the user .

while we agree that the existing policy requires such parameters to be captured and included in the department's decision making process , we found the policy to be vague in its discussion of these parameters and to not clearly define what a baseline is , or which baselines are to be used or reported for comparison purposes .

for example , the policy does not make a distinction between the initial acquisition program baseline , current baseline , and baseline deviations .

yet , such information is important because it provides a basis for decision makers to identify the extent to which a program may have deviated from its initial cost , schedule , or technical performance baseline .

by making these distinctions in the policy , the department's policy for its mais business programs will be more consistent with its other policy for non - business mais programs with regard to the way an acquisition program baseline is defined and the elements that should be captured and reported to its decision makers .

in turn , the program managers who prepare these reports and the decision makers who rely on them will have information that is consistently and succinctly prepared for making credible decisions .

regarding adding provisions in its policy for the establishment of predetermined thresholds , the under secretary stated that the 5000.75 states that the milestone decision authority is responsible for delivery within cost , schedule , and performance parameters , and the milestone decision authority is to do this by establishing oversight controls for programs , including procedures to report and address variances .

the under secretary added that the 5000.75 does not suggest the practice of establishing a predetermined threshold for the variance , and dod will consider the addition of this feature to the 5000.75 update .

finally , regarding providing periodic annual and quarterly reports to the department's leadership , the under secretary stated that such a periodic report would add value only if there had been no recent communication of program status from the program office to the leadership or stakeholders communities .

while such communication is expected to occur frequently , its regularity is not specified in current policy or guidance .

the under secretary stated that dod will consider adding a provision for a report to leadership and functional stakeholder if such communication has not occurred within the past 3 or 4 months .

dod concurred with the second and third recommendations related to the department's implementation of selected it management practices .

regarding the second recommendation , the under secretary of defense for acquisition and sustainment agreed to direct the defense healthcare management system modernization program manager to update and approve the requirements management plan , identify and document changes to the requirements baseline , and quantify the costs and benefits in the risk mitigation plans .

further , regarding the third recommendation , the secretary of the navy agreed to direct the program manager to identify and document all potential external environmental issues that could negatively affect work efforts for the navy's consolidated afloat networks and enterprise services program .

by taking these steps , these programs should be better positioned to effectively identify inconsistencies in managing changes to their requirements , and be more responsive to the potential for environmental issues .

we are sending copies of this report to the appropriate congressional committees ; the secretary of defense ; the secretaries of the army , navy , and air force ; the under secretary of defense for acquisition and sustainment ; the director of the defense health agency ; and other interested parties .

this report also is available at no charge on the gao website at http: / / www.gao.gov .

should you or your staffs have any questions on information discussed in this report , please contact me at ( 202 ) 512-4456 or harriscc@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iii .

the national defense authorization act for fiscal year 2012 mandated that we select , assess , and report on selected major automated information systems ( mais ) programs annually through march 2018 .

gao satisfied the statutory mandate by submitting a draft of this report to the congressional committees on march 29 , 2018 .

this final version of the report is the sixth and last report in the series of annual mandated assessments .

our objectives were to: ( 1 ) assess the department of defense's ( dod ) policy for the management and oversight of mais programs ; ( 2 ) describe the extent to which selected mais programs have changed their planned cost and schedule estimates and met performance targets ; and ( 3 ) assess the extent to which selected mais programs have used leading information technology ( it ) acquisition practices , including requirements and risk management .

to address the first objective , we identified four leading it management practices in gao's information technology investment management guide and compared dod's policy adherence to those practices .

these leading practices are: instituting the investment board , which is the process for creating and defining the membership , guiding policies , operations , roles , responsibilities , and authorities within the organization ; identifying decision authorities for making important acquisition decisions ; providing oversight whereby the organization monitors each project on its performance progress ( eg , establishing and tracking baseline estimates on cost and schedule goals , and thresholds to identify high risk on cost and schedule ) ; and capturing and providing performance information about a particular investment ( project ) to decision makers at regular intervals ( eg , quarterly and annually ) .

we then compared dod's policies used to manage and oversee the department's non - business mais programs and mais business programs against these leading it management practices .

the department's policy documents for managing and overseeing non - business mais programs and mais business programs include the: memorandum by the under secretary of defense for acquisition , technology , and logistics , dated november 17 , 2017 , regarding the regulatory response to the repeal of title 10 , united states code , chapter 144a , major automated information system programs .

memorandum by the under secretary of defense for acquisition , technology , and logistics , dated april 24 , 2017 , regarding the transition of programs to business system categories .

dod instruction 5000.75 , business systems requirements and acquisition , effective february 2 , 2017 .

dod instruction 5000.02 , operation of the defense acquisition system , effective february 2 , 2017 .

we also interviewed an official from the former office of the under secretary of defense for acquisition , technology , and logistics , who was responsible for the development of plans and policy for the administration regarding the management and monitoring of non - business mais programs and mais business programs to address the second objective , we used dod's official list of 34 business and non - business mais programs , as of april 18 , 2017 , to establish a basis for selecting programs .

of the 34 programs , we selected the 15 business and non - business mais programs that met our criteria: programs must be unclassified and have an initial acquisition program baseline that could be used as a reference point for evaluating cost , schedule , and technical performance characteristics .

we then collected and analyzed key documents , reports , and artifacts for each program and summarized the information on estimated cost , schedule , and technical performance goals , including their latest program status in meeting those estimated goals .

next , we analyzed and compared each selected program's first acquisition program baseline cost estimate to the latest estimate to determine the extent to which planned program costs had changed .

specifically , we used the total life - cycle cost estimate and analyzed and compared them to the latest estimate to determine the extent to which planned program costs had changed .

similarly , to determine the extent to which these programs changed their planned schedule estimates , we compared each program's first acquisition program baseline schedule to the latest schedule .

to determine whether the selected programs met their performance targets , we analyzed each program's self - identified system performance targets and compared them against actual system performance metrics and latest test reports .

we also reviewed additional information on each program's cost , schedule , and performance , including program documentation , such as dod's mais annual and quarterly reports , acquisition program baselines , system test reports , and our prior reports .

we then aggregated and summarized the results of these analyses across the programs .

to address the third objective , we started with the list of the 15 programs from the second objective as a basis for selecting three mais programs as case studies .

we used a combination of the following criteria to select the mais programs to review .

programs used in a most recent mais review were eliminated from consideration .

the program was not designated as classified .

the program had a baseline .

based on these criteria , we chose the following systems: navy consolidated afloat networks and enterprise services ; defense logistics agency's defense agencies initiative , increment 2 ; defense health agency's defense healthcare management system modernization .

we then analyzed each selected program's it acquisition documentation and compared it to key requirements and risk management and leading practices — including software engineering institute's capability maturity model® integration for acquisition ( cmmi - acq ) practices — to determine the extent to which the programs were implementing these practices .

in particular , the requirements management practices we reviewed were: develop an understanding with the requirements providers on the meaning of the requirements , obtain commitment to requirements from project participants , manage changes to requirements as they evolve during the project , maintain bidirectional traceability among requirements and work , and ensure that project plans and work products remain aligned with requirements .

specifically , we analyzed program requirements documentation , including requirements management plans , requirements traceability matrices , requirements change forms , technical performance assessments , and requirements board meeting minutes .

additionally , we interviewed program officials to obtain additional information about their requirements management practices .

the conclusions reached for this objective are not generalizable to the larger population of 34 business and non - business mais programs .

we also reviewed the following risk management practices: determine risk sources and categories ; define parameters used to analyze and categorize risks and to control the risk management effort ; establish and maintain the strategy to be used for risk management ; identify and document risks ; evaluate and categorize each identified risk using defined risk categories and parameters , and determine its relative priority ; develop a risk mitigation plan in accordance with the risk management strategy ; and monitor the status of each risk periodically and implement the risk mitigation plan as appropriate .

specifically , we analyzed program risk documentation , including risk reports , risk - level assignments , risk management plans , risk mitigation plans , and risk board meeting minutes .

additionally , we interviewed program officials to obtain additional information about their risks and risk management practices .

to assess the reliability of the data of these programs we used to support the findings in this report , we corroborated program office responses with relevant program documentation and interviews with agency officials .

we found no data reliability issues and determined that the data used in this report were sufficiently reliable for our reporting purposes .

we have also made appropriate attribution indicating the sources of the data .

we conducted this performance audit from april 2017 to may 2018 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in addition to the contact name above , the following staff also made key contributions to this report: eric winter ( assistant director ) , john ortiz ( analyst in charge ) , alex bennett , neha bhatt , chris businsky , and rebecca eyler .

