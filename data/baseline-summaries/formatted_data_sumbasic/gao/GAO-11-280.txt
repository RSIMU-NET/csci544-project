the 1.4 million elderly and disabled residents living in nursing homes are considered a highly vulnerable population .

they frequently depend on others for assistance with basic activities of daily living such as dressing , eating , or toileting , and some require skilled nursing or rehabilitative care .

the vast majority of nursing homes that care for these residents participate in medicare and medicaid , and in 2009 , nursing homes received about $89 billion in payments from these programs .

ensuring quality of care in these nursing homes is a joint responsibility of the centers for medicare & medicaid services ( cms ) , within the u.s. department of health and human services ( hhs ) , and state survey agencies .

congress and cms set federal requirements , and cms contracts with state survey agencies to perform both routine inspections of nursing homes , known as standard surveys , and complaint investigations , among other activities .

complaint investigations offer a unique opportunity to identify and correct potential care problems .

they can provide more timely alerts of potential problems than standard surveys and target specific areas identified by residents , their families , nursing home staff , and others .

in 2009 , half of all violations of federal requirements that resulted in some level of harm to nursing home residents were cited during complaint investigations .

state survey agencies generally develop their own investigation procedures but must follow certain federal procedures and time frames for complaints that allege a violation of federal requirements .

state survey agencies also must provide certain information about their complaint investigations to cms through its national complaints database .

cms oversees state survey agencies in part by assessing their performance on four standards that pertain to nursing home complaints .

these standards are part of a broader cms state performance standards system .

members of congress and others have raised concerns about the timeliness and adequacy of nursing home complaint investigations , as well as the manner in which the findings are communicated to complainants .

concerns have focused not only on state survey agencies' nursing home complaint investigations , but also on cms's oversight .

you expressed interest in learning more about these issues .

specifically , we examined ( 1 ) the number and types of complaints cms's database showed as received , investigated , and substantiated by state survey agencies ; ( 2 ) whether state survey agencies were meeting cms's performance standards and complainant communication requirements and steps taken by the agencies to meet them ; and ( 3 ) the effectiveness of cms's oversight of state survey agencies' complaint investigation processes .

to describe the number and types of nursing home complaints received , investigated , and substantiated by state survey agencies , we analyzed cms's national complaints data for calendar years 2004 through 2009 for all 50 states and the district of columbia .

because concerns have focused primarily on complaints , we included only complaints in our analysis for this objective and excluded facility - reported incidents , which nursing homes are required to self - report to state survey agencies .

in addition , we included only complaints that alleged a violation of federal requirements .

to assess the reliability of the complaints data we received from cms , we interviewed officials from cms and state survey agencies about the quality of the data , reviewed relevant documentation , and examined the data for reasonableness and internal consistency .

in the course of this assessment , we found some data limitations .

specifically , cms officials told us that they have concerns that some state survey agencies may not have entered all of the complaints they received into cms's national database .

we therefore consider the number of complaints in cms's national data to be a conservative estimate of the total number of complaints received by state survey agencies .

in addition , we analyzed only those variables that we found to be reliable .

we learned that in some cases , data are missing for certain variables that state survey agencies are not required to enter into the database — such as the date on which the state survey agency acknowledged the complaint — and that state survey agencies interpret certain variables differently from one another .

for example , state survey agencies have differing interpretations of what it means to substantiate a complaint .

some state survey agencies limit use of the term to complaints where at least one deficiency is cited while others consider complaints to be substantiated if they are confirmed , even if no deficiencies are cited .

in this report , we chose to report data about complaints that were substantiated with at least one federal deficiency cited , as we believe these data should be more consistent across states than data on all complaints reported to be substantiated .

in addition , the citation of a federal deficiency demonstrates that the nursing home has failed to meet federal requirements .

after reviewing the possible limitations of the complaints data , we determined that the data we report were sufficiently reliable for the purposes of our report .

to determine whether state survey agencies are meeting cms's standards and complainant communication requirements and to describe steps they have taken to meet the requirements , we analyzed scores for two of the four nursing home complaint performance standards in cms's state performance standards system for fiscal years 2006 through 2009 for all 50 states and the district of columbia .

for our analysis , we reviewed performance on the two standards we considered the most reliable: ( 1 ) prioritization of complaints based on the severity of the allegations and ( 2 ) timeliness of investigations .

although these standards assess state survey agencies' performance with respect to incidents as well as complaints , we used scores on these standards as measures of performance with respect to complaints alone .

cms does not calculate separate scores for complaints .

moreover , on a national level , complaints considerably outnumber incidents in cms's database , and state survey agencies' scores on the standards are therefore likely to primarily reflect their performance with respect to complaints .

we analyzed scores from fiscal years 2006 through 2009 because cms reorganized its performance system in 2006 , and the most recent data available at the time of our study were from fiscal year 2009 .

because of changes made in the standards' requirements and scoring during this time period , we have presented trend data only when scores were comparable over time .

we also analyzed cms's national complaints data on the length of time taken by state survey agencies to investigate complaints in calendar year 2009 .

in addition , we reviewed the guidance cms provided to state survey agencies and its own regional offices , which are responsible for evaluating state survey agencies' nursing home complaint processes .

we also conducted structured telephone interviews with cms regional office officials in atlanta , chicago , and dallas and state survey agency officials in arkansas , florida , michigan , tennessee , texas , and wisconsin .

we gathered additional perspectives on cms's requirements at a membership meeting of the association of health facility survey agencies ( ahfsa ) , the organization that represents state survey agencies .

finally , we reviewed both templates and samples of actual letters to complainants provided by the six state survey agencies in our sample .

to assess the effectiveness of cms's oversight of state survey agencies' complaint investigation processes , we drew on information from our data analyses and interviews , including interviews with officials at cms headquarters .

we also evaluated the four nursing home complaint performance standards using key criteria for performance measures identified by gao and other audit agencies .

these criteria include whether the standards are comprehensive , limited in number and overlap , practical , balanced , comparable over time , and reliable .

additionally , to examine the extent to which cms has used performance information to promote improvements in state survey agencies' nursing home complaint investigation processes , we reviewed information from our interviews and data analyses .

we also reviewed corrective action plans that state survey agencies in our sample were required to submit for any performance standards they failed between fiscal years 2006 through 2009 .

we conducted our review from january 2010 through april 2011 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

when investigating complaints about nursing homes , state survey agencies follow state policies and procedures based on cms instructions .

to oversee state survey agencies' complaint investigation processes , cms uses data from its complaints database and state performance standards system .

cms's state operations manual outlines procedures for state survey agencies' investigation of nursing home complaints .

this manual is based on requirements in statutes and regulations and includes a detailed protocol for handling complaints and incidents , such as directions for key parts of the complaints process — intake , prioritization , investigation , and reporting of results .

intake .

state survey agencies receive complaints via phone calls , e - mails , or letters .

at intake , staff review the information provided by the complainant and , because each complaint can have more than one allegation , determine the type ( s ) of allegations involved , such as resident abuse or poor quality of care .

prioritization .

based on the nature of the allegations , staff assign a priority level to the complaint , which determines if an onsite investigation is required .

four of the eight priority levels require an onsite investigation .

 ( see table 1. ) .

for example , investigations for complaints that allege “immediate jeopardy” to a resident's health , safety , or life must be started within 2 working days of receipt , while investigations for complaints that allege a high level of actual harm ( “actual harm - high” ) to a resident must be started within 10 working days of prioritization .

investigation .

during the unannounced investigation , state agency surveyors may conduct a document review and observe nursing home conditions .

additionally , surveyors interview witnesses , including the resident about whose care the complaint was filed and other residents with similar care needs , being careful to protect the anonymity of those involved in the complaint .

surveyors determine whether the allegations are substantiated and whether the nursing home should be cited for any deficiencies ( failure to meet federal or state quality standards ) , which may be related or unrelated to the complaint allegations .

deficiencies are categorized according to scope and severity .

scope refers to the number of residents potentially or actually affected and has three levels — isolated , pattern , or widespread .

severity refers to the degree of relative harm and has four levels — immediate jeopardy ( actual or potential for death or serious injury ) , actual harm , potential for more than minimal harm , or potential for minimal harm .

reporting of results .

after the complaint investigation is completed , the state survey agency notifies the complainant and the nursing home of the outcome of the investigation , following guidelines specified in the state operations manual .

cms oversees state survey agencies' complaint investigation processes using its complaints data and state performance standards system .

cms's complaints data .

as of january 1 , 2004 , state survey agencies were required to enter data about all complaints and incidents into the acts — automated survey processing environment ( aspen ) complaints / incidents tracking system — database according to guidance provided by cms .

officials in cms's headquarters and regional offices can access all information in acts , though the information is stored on individual state servers .

cms provides guidance to state survey agencies regarding acts database procedures , including what complaint information states are required to enter .

the information is then uploaded into cms's national complaints database , which contains a variety of information about complaints , such as the date of the alleged event , the name of the nursing home involved , and the source of the complaint .

 ( see table 2. ) .

state performance standards system .

cms's 10 regional offices are responsible for annually evaluating state survey agencies' nursing home complaint investigations using four performance standards .

 ( see table 3. ) .

cms developed the state performance standards system in fiscal year 2001 to assess whether state survey agencies were meeting the requirements for the survey and certification program and to identify areas for improvement .

in fiscal year 2006 , cms reorganized the performance standards system , and in the following years made several revisions to the four nursing home complaint performance standards .

none of the standards focus exclusively on nursing home complaints .

for some standards , the scope of review includes incidents as well as complaints , facilities other than nursing homes , or standard surveys as well as complaint investigations .

for all except the timeliness standard , the review is based on samples rather than the universe of complaints and incidents .

upon completion of the performance evaluation , cms regional offices share the results with each respective state survey agency and cms headquarters , which in turns shares each state's scores with all of the other states .

state survey agencies that fail performance standards must submit corrective action plans to their cms regional offices , which the regional offices can accept or reject , depending on whether they believe the state has outlined appropriate steps to address poor performance .

the regional offices use these plans to follow up with state survey agencies as part of their monitoring activities .

cms's national complaints data show that state survey agencies received over 50,000 complaints about nursing homes in calendar year 2009 .

the number and types of complaints varied among states .

state survey agencies investigated all but 102 of the complaints that required an investigation .

among complaints that were investigated and uploaded to cms's national database for 2009 , 19 percent were substantiated with at least one federal deficiency cited .

state survey agencies reported receiving 53,313 complaints about nursing homes in 2009 .

in 2009 , 9 states received fewer than 100 complaints while 17 states received more than 1,000 .

six states — illinois , missouri , new york , ohio , texas , and washington — accounted for roughly half of all 2009 complaints in cms's database .

although the number of nursing home residents has remained relatively stable , the number of complaints received generally increased by about 1,000 complaints a year from 2004 to 2008 .

in 2009 , the number of complaints dropped by about 5,000 .

complaint rate .

nationally , in 2009 , cms's database showed a complaint rate of roughly 38 complaints per 1,000 nursing home residents .

the complaint rate ranged from less than 1 ( 0.77 ) in south dakota to about 137 in washington .

additionally , 11 states received 15 or fewer complaints per 1,000 nursing home residents , while 14 states received more than 45 .

 ( see fig .

1. ) .

submission of complaints and sources .

cms data show that state survey agencies received three - quarters of complaints in 2009 by phone .

complaints also were submitted through other means , such as in writing , through e - mail , or in person .

in 2009 , complaints were typically submitted by family members ( 47 percent ) , anonymously ( 19 percent ) , or by residents ( 10 percent ) .

complaints were also submitted by current nursing home staff or other sources .

prioritization of complaints .

in 2009 , among the complaints in cms's national data , state survey agencies prioritized most as either actual harm - high ( 45 percent ) or actual harm - medium ( 33 percent ) .

roughly 10 percent of complaints were prioritized as immediate jeopardy and about 4 percent were prioritized as actual harm - low .

approximately 8 percent of complaints were prioritized at the four lowest levels and did not require an onsite investigation .

state survey agencies varied in the percentage of complaints they prioritized at different levels .

for example , 23 state survey agencies prioritized more than 50 percent of complaints as immediate jeopardy or actual harm - high , while 7 state survey agencies prioritized fewer than 10 percent of complaints they received at these two levels .

allegations .

allegations are specific charges within complaints ; each complaint can have multiple allegations .

in 2009 , according to cms's national data , the average number of allegations per complaint was 2.3 .

allegations that focused on quality of care or treatment accounted for about 40 percent of all allegations in 2009 .

 ( see table 4. ) .

cms data show that in 2009 about 48,900 of the approximately 53,300 complaints received required an investigation and that state survey agencies investigated all but 102 of those complaints .

among those 102 complaints , 25 percent were prioritized as either immediate jeopardy or actual harm - high ( 6 and 19 percent respectively ) .

the remaining 75 percent were complaints prioritized as actual harm - medium or actual harm - low .

the percentage of complaints investigated from 2004 through 2009 remained relatively stable even as the number of complaints increased in all years except 2009 .

in 2009 , an investigation was initiated within cms's required time frames for most complaints prioritized as either immediate jeopardy or actual harm - high .

among immediate jeopardy complaints , an investigation was initiated within 2 working days of receiving the complaint for 88 percent of complaints .

among complaints prioritized as actual harm - high , an investigation was initiated within 10 working days of prioritization for 72 percent of complaints .

roughly 19 percent of the complaints that were investigated and uploaded into cms's complaints database for 2009 were substantiated with at least one deficiency cited .

however , there was considerable variation across states .

in 19 states , more than 30 percent of the complaints investigated were substantiated with at least one deficiency cited , while in 5 states , the proportion was less than 10 percent .

of the approximately 16,000 nursing homes nationwide , about 2,800 had one substantiated complaint where at least one deficiency was cited .

in addition , about 1,100 nursing homes had two such complaints .

the percentage of immediate jeopardy complaints that were substantiated with at least one deficiency cited was higher than for complaints prioritized at lower levels in 2009 .

according to cms's complaints database , roughly 26 percent of the immediate jeopardy complaints that were investigated were substantiated with at least one deficiency cited .

among complaints prioritized at lower levels , the percentage was around 21 percent for actual harm - high complaints , 17 percent for actual harm - medium complaints , and 12 percent for actual harm - low complaints .

in 2009 , among the complaints prioritized as immediate jeopardy or actual harm - high , the percentage substantiated with at least one deficiency was higher if the investigation was initiated within required time frames than if it was not .

for example , among actual harm - high complaints that were investigated within 10 working days of prioritization , 22 percent were substantiated with at least one federal deficiency cited .

 ( see table 5. ) .

in contrast , among actual harm - high complaints that were investigated late , the proportion was 17 percent .

 ( app .

i contains state - level data on complaints received , investigated , and substantiated by state survey agencies , according to cms data. ) .

many state survey agencies did not meet some of cms's performance standards for nursing home complaints in fiscal year 2009 .

in particular , 19 state survey agencies had difficulty investigating complaints and incidents prioritized as actual harm - high within the required time frame .

state survey agencies reported that they have taken or plan to take steps in four key areas — staffing , agency restructuring , training and guidance , and monitoring — to meet cms's nursing home complaint standards .

although the standards do not assess state survey agencies' communication with complainants , cms does expect agencies to convey investigation findings to complainants in accordance with cms's state operations manual .

we found that agencies varied in their interpretations of the manual's instructions , and some provided limited information to complainants .

more than half of state survey agencies had difficulty meeting certain cms performance standards pertaining to nursing home complaints .

according to cms's assessment for fiscal year 2009 , 28 state survey agencies failed the timeliness of investigations standard for either immediate jeopardy or actual harm - high complaints , the prioritization of complaints standard , or both .

timeliness of investigations standard .

cms's assessment of state survey agencies' performance found that some had difficulty meeting the timeliness of investigations standard , which evaluates: ( 1 ) whether an investigation was initiated within 10 working days of prioritization for actual harm - high complaints and incidents for nursing homes , and ( 2 ) whether an investigation was initiated within 2 working days of receipt for immediate jeopardy complaints and incidents for nursing homes and other facilities .

state survey agencies must begin investigating at least 95 percent of complaints and incidents within required time frames .

for actual harm - high complaints and incidents , cms evaluates performance for nursing homes separately from that of other facilities .

for immediate jeopardy complaints and incidents , cms evaluates performance for both nursing homes and other types of facilities .

cms found that in fiscal year 2009 , 19 state survey agencies failed to meet the timeliness of investigations standard for complaints and incidents prioritized as actual harm - high .

this marked an improvement from fiscal year 2008 , when 25 states failed .

states' fiscal year 2009 scores varied widely .

for example , among states failing this standard , louisiana nearly passed with 94.4 percent of actual harm - high complaints and incidents investigated within the required time frame , while michigan's score was 17.3 percent .

 ( for information on all state survey agencies' performance on this standard , see app .

ii. ) .

according to cms's national data for calendar year 2009 , the 19 states that failed this standard in fiscal year 2009 accounted for more than half ( 52 percent ) of all actual harm - high complaints received nationally .

in these 19 states , at least 43 percent of actual harm - high complaint investigations were initiated late , and at least 33 percent were initiated more than 11 working days late .

officials from the three state survey agencies in our sample that failed to meet the timeliness standard for actual harm - high complaints cited long - standing workload and staffing issues as reasons .

more specifically , officials with the michigan and texas survey agencies said they had difficulty because of staffing shortages and because the volume of complaints and incidents increased .

tennessee officials noted that the state has tried to hire the additional staff needed to investigate the state's backlog of complaints , but has been hampered by low salaries for surveyor positions as well as a cumbersome state hiring process .

nationwide , state survey agencies generally performed better on cms's timeliness standard for immediate jeopardy complaints and incidents than they did for actual harm - high complaints and incidents .

in cms's assessment for fiscal year 2009 , all but nine state survey agencies passed this standard by initiating investigations within 2 working days of receipt for at least 95 percent of the immediate jeopardy complaints and incidents they received about nursing homes and other facilities .

among the nine state survey agencies that failed this standard , four had scores at or below 50 percent .

as with actual harm - high complaints and incidents , the two state survey agencies in our sample that failed the timeliness standard for immediate jeopardy complaints and incidents — michigan and tennessee — cited staffing shortages or increases in the number of complaints and incidents as key reasons .

fourteen state survey agencies that met cms's timeliness standard for immediate jeopardy complaints and incidents did not meet the timeliness standard for actual harm - high complaints and incidents .

an official in one cms regional office noted that immediate jeopardy complaints are the highest priority and therefore rightly received the most attention .

prioritization of complaints standard .

cms's assessment of state survey agencies' performance found that most agencies ( 32 ) consistently passed this standard for the past four years .

state survey agencies must appropriately prioritize at least 90 percent of complaints and incidents .

cms evaluates performance for nursing homes separately from that of other facilities .

in cms's assessment for fiscal year 2009 , all but nine state survey agencies passed this performance standard .

among the nine state survey agencies that failed this standard in fiscal year 2009 , most had scores between 70 percent and 88 percent .

 ( see app .

ii for information on all state survey agencies' performance on this standard. ) .

all but one of the six state survey agencies in our sample passed the prioritization standard in fiscal year 2009 .

officials from tennessee said that the agency had difficulty meeting this standard because of personnel changes and because it took time for new management to fully understand how the agency operates .

officials from the five state survey agencies in our sample that passed this standard generally attributed their agencies' performance on the prioritization standard to staff skills and experience , training , and processes for quality control .

for example , officials from two state survey agencies — arkansas and texas — attributed their states' success , in part , to a supervisor's or quality assurance specialist's review of the priority levels assigned by the staff members who received the complaint .

state survey agencies reported that they have taken or plan to take steps in four key areas — staffing , agency restructuring , training and guidance , and monitoring — to either improve or maintain performance on cms's nursing home complaint standards .

staffing .

officials from three of the state survey agencies in our sample indicated that because staff shortages affected their ability to meet cms standards , they had taken steps to increase staffing .

for example , officials of the michigan survey agency , which repeatedly failed the timeliness of investigations standard between 2006 and 2009 , reported that beginning in fiscal year 2009 , the agency was able to hire additional surveyors and as of june 1 , 2010 , had eliminated its backlog of complaints .

tennessee officials indicated that the agency received state legislature approval in february 2009 to hire additional surveyors to fill vacant positions .

texas officials also hired additional surveyors to conduct complaint investigations .

officials of state survey agencies in our sample that met all or most of cms's nursing home complaint standards credited , among other factors , experienced agency staff .

for example , wisconsin officials indicated that the agency's ability to meet cms's standards was partly due to the quality of the staff hired by the agency — specifically , some staff members' experience in the regulatory process , as both health care providers and regulators .

agency restructuring .

some state survey agencies restructured complaint investigation operations to address performance issues , either consolidating regional offices or creating separate units to investigate complaints .

for example , to provide better statewide coverage with available staff , the tennessee survey agency downsized from three regional offices to two .

arkansas and texas both established separate complaint investigation units — in arkansas's case , more than 10 years ago — in an effort to better manage large volumes of complaints .

officials of state survey agencies that have separate complaint investigation units cited several advantages to dividing complaint investigation functions from standard survey functions , including greater efficiency and flexibility .

for example , some officials said that staff assigned to the complaints unit are able to build experience and familiarity with the process and thus conduct more efficient investigations and prepare more accurate reports ; likewise , staff that focus on standard surveys are able to conduct these inspections more efficiently because they do not have to investigate complaints at the same time .

one official also said that a separate complaint investigation unit affords managers more flexibility — for example , by allowing them to more easily change staff members' assignments from day to day to respond to high priority complaints .

training and guidance .

officials of some state survey agencies attributed their agencies' successful performance on the prioritization of complaints standard partly to staff training .

state survey agencies also issued guidance , including policy manuals and standardized forms or templates , to guide staff through the complaint investigation process .

for example , florida provides staff with a 44-page manual , with chapters on intake , prioritization , and investigation of complaints , and created an automated complaint investigation form that captures information about each allegation in a complaint , as well as the evidence collected and findings reached with respect to each .

monitoring .

among the state survey agencies in our sample that failed to meet some of cms's standards , officials indicated that their agencies had implemented or planned to implement additional monitoring efforts .

for example , texas officials indicated that the agency conducts reviews throughout the complaint process .

for example , after a complaint has been prioritized , a quality assurance specialist reviews the information to ensure that the prioritization was appropriate .

similarly , officials from tennessee's survey agency indicated that the agency planned to increase monitoring .

in particular , the officials indicated that each of the state's regional offices would track and report quarterly on the timeliness of investigations for all immediate jeopardy and actual harm - high complaints .

tennessee officials indicated that surveyors in the state's regional offices would be immediately alerted when they are assigned an immediate jeopardy complaint to investigate , something not always done in the past .

state survey agencies in our sample that generally passed cms's performance standards indicated that monitoring programs contributed to the agencies' success .

for example , a florida official indicated that a supervisor reviews a sample of complaints received on the previous day to determine whether they were prioritized appropriately .

although the cms performance standards do not assess whether state survey agencies are providing sufficient information to complainants about investigation results , cms's state operations manual indicates that state survey agencies should provide a written report to complainants in accordance with certain guidelines specified in the manual .

the manual specifies that the state agency should acknowledge the complainant's concerns , identify the agency's regulatory authority to investigate , provide a summary of investigation methods and the date of the investigation , summarize the investigation findings , and identify any follow - up action to be taken .

the six state survey agencies in our sample varied in their interpretations of the manual , particularly the instruction to provide a summary of the investigation findings .

two of the six agencies consistently provided detailed information that specifically addressed complainants' allegations .

for example , one sample letter we received from the wisconsin survey agency lists four specific allegations made by the complainant and then describes the agency's finding with respect to each , including whether a deficiency was cited .

 ( see fig .

2 for an excerpt from this letter. ) .

the other state survey agency that provided detailed information ( michigan ) did so by enclosing the investigation report with the letter , along with the statement of deficiencies , if any were cited .

a michigan survey agency official said that staff also make at least one attempt to contact a complainant by telephone to explain the findings .

in contrast , four of the state survey agencies sent complainants only boilerplate descriptions of the complaint investigation , typically sending one type of form letter if surveyors cited deficiencies and another if they did not .

for example , in the sample letter we received from florida , the survey agency varied the middle paragraph of its three - paragraph letter depending on whether deficiencies were cited ( see fig .

3 ) .

an official of this agency said the letter was intended to let complainants know that the point of an investigation is to determine a nursing home's compliance with regulations .

of the four state survey agencies that provided boilerplate descriptions of their investigation findings , two told complainants how to obtain a more detailed report .

for example , a sample letter from the arkansas state survey agency noted that the agency's report on the deficiencies cited and the nursing home's plan of correction should be posted in the nursing home .

an arkansas survey agency official said that complainants could also request a copy of the investigation report , but that it might be heavily redacted to protect medical and identifying information .

cms's oversight of state survey agencies' complaint investigation processes , through its performance standards system and complaints database , is hampered by data reliability issues .

while the four performance standards cms uses to assess state survey agencies' processes for investigating nursing home complaints are consistent with certain key criteria for performance measures identified by gao and other audit agencies , the standards have weaknesses in areas related to other key criteria , particularly data reliability , due in part to inadequate sample sizes and inconsistent interpretation of some standards by cms reviewers .

in addition , cms has not made full use of the information it collects about state survey agencies' complaint investigation processes .

for example , in part because of data reliability concerns , cms does not routinely use data from the complaints database to calculate certain measures that could enhance its understanding of state survey agencies' performance .

although cms requires state survey agencies that fail performance standards to develop corrective action plans , these plans do not necessarily address the underlying causes of performance issues , such as staffing shortages .

cms's four nursing home complaint performance standards — ( 1 ) prioritization of complaints , ( 2 ) timeliness of investigations , ( 3 ) quality of investigations , and ( 4 ) documentation of deficiencies — are consistent with some , but not all , of the key criteria for performance measures identified by gao and other audit agencies .

specific weaknesses we identified include a lack of comparability over time in the performance scores and thus an inability to assess trends ; a lack of balance among some standards ; and , most critically , a lack of data reliability , due in part to inadequate sample sizes and varying interpretations of the standards .

consistent with key criteria for performance measures , cms's performance standards are comprehensive and limited in number and overlap .

officials of all of the state survey agencies and cms regional offices in our sample indicated that they considered the four nursing home complaint standards comprehensive .

although the performance standards system does not include standards for certain steps in the complaint investigation process , such as intake , officials indicated that the standards cover key steps , which include prioritizing complaints , scheduling and conducting investigations , and documenting any deficiencies identified .

the standards are also limited in number and overlap , with each focused on different aspects of the nursing home complaint process than the others .

performance trends cannot be easily assessed because scores are not comparable over time .

because cms changed the scoring methodologies for three of the four nursing home complaint standards during the past 4 years , it is not readily apparent from scores on these standards whether state survey agencies' performance improved or worsened over that time period .

cms officials generally felt that the changes had enhanced the standards — in the case of the documentation of deficiencies and quality of investigations standards , by holding state survey agencies accountable for meeting all of the underlying requirements or by highlighting specific areas in need of improvement .

further , they did not identify the lack of trend data as a major concern .

officials noted that cms judges state survey agencies' performance for a given year , not in relation to prior years , and does not count scores on a standard in the first year after a significant change in methodology .

however , a lack of consistent trend data makes it more difficult for cms to assess whether the steps that it and the states are taking to improve performance on the nursing home complaint standards are having the desired effect .

the balance among standards may be undermined by how the prioritization standard is scored .

in general , the standards are balanced , so that the incentives created by one standard are counterbalanced by the incentives created by other standards .

however , because the prioritization standard requires only that complaints be assigned a priority level at or above the level assigned by cms reviewers , this standard may create an incentive for state survey agencies to assign higher priority levels than are warranted — which may jeopardize the timeliness of investigations .

as one state survey agency official pointed out , the staff members who prioritize complaints may not be responsible for conducting investigations ; consequently , these staff may be more focused on the agency's meeting the prioritization standard than the timeliness standard and thus err on the side of caution in prioritizing complaints .

according to cms headquarters officials , the prioritization standard is scored this way because the agency was most concerned about complaints being prioritized at too low a level and did not want to fault state survey agencies for investigating complaints sooner than necessary .

however , officials of two cms regional offices noted that assigning complaints too high a priority level can cause misallocation of resources , as state survey agencies that prioritize complaints at higher levels than are warranted must investigate these complaints within shorter time frames than they otherwise would .

some performance scores are unreliable because of inadequate sample sizes and varying interpretations of standards among cms reviewers .

for three of the four cms performance standards , the samples specified by cms are in some cases too small to yield reliable data .

scores on the prioritization of complaints , quality of investigations , and documentation of deficiencies standards were generally based on a sample of 10 to 40 cases ( 10 percent , up to a maximum of 40 ) .

with samples this small , the margin of error around states' scores on the prioritization of complaints standard , for example , was as much as 19 percentage points in fiscal year 2009 .

accordingly , at least some of the states that received passing marks on this standard may actually have failed , and at least five of the nine states that received failing marks may actually have passed .

although the small sample sizes cms requires make the reviews involved in certain standards more practical , by reducing the documentation cms reviewers must examine , the trade - off is a lack of precision in the scores for these standards .

moreover , interpretation of some standards has varied among cms reviewers — in terms of both the materials reviewed to assess performance and how certain requirements were construed by reviewers .

materials reviewed .

to assess the quality of investigations , some cms regional offices reviewed only information surveyors entered into the complaints database , while other cms regional offices reviewed more extensive hard - copy notes from complaint investigations .

cms headquarters officials indicated that relying solely on the information in the complaints database to assess the quality of investigations was not consistent with federal guidance , stating that regional office officials should follow the guidance for the standard , which calls for reviewers to examine a variety of documents , including surveyor worksheets and investigation notes .

they also noted that the investigation notes are not required data elements in the complaints database .

some state survey agency officials said that their scores on this standard have suffered because the investigation notes in the database do not always provide a complete picture of the agency's complaint investigations .

how requirements were construed .

state survey agency officials we interviewed also noted differences in how cms reviewers understood certain requirements in the standards , particularly in the documentation of deficiencies standard .

for example , officials described differences in reviewers' interpretations of what it means to quantify the extent of a deficient practice , one of the requirements in that standard .

one state survey agency official said that his agency's scores on the standards improved from one half of the year to the next simply because the cms staff conducting the review changed .

officials in one of the cms regions where all state survey agencies failed the documentation of deficiencies standard acknowledged the 100 percent failure rate was at least partially due to a change in the regional office's review — specifically , regional managers having issued more explicit instructions to staff about how to assess states' performance on particular requirements .

the clustering of failing scores on this standard within certain cms regions also suggests regional variation in interpretation ; in three regions , all of the state survey agencies failed the documentation of deficiencies standard in fiscal year 2009 , while in the other seven regions , half or fewer of the state survey agencies failed .

although some cms regional offices have tried to ensure consistent interpretation of the standards within their own regions — for example , by requiring that multiple reviewers concur on any failing marks given to state survey agencies and encouraging ongoing dialogue about the standards — some officials we interviewed believe cms should do more to ensure consistency across regions .

cms headquarters officials told us that the agency has issued additional guidance when officials became aware of a need for clarification , but some cms regional office officials said that parts of the guidance need enhancement and that cms headquarters should have more staff dedicated to developing guidance and answering questions from regional office staff .

in addition , some state survey agency officials suggested that cms regional offices should have less autonomy in the performance review process .

one official suggested that cms headquarters should exert more control over the regional offices with respect to the review process , and others indicated a need for more “review of the reviewers” — for example , by having the performance reviews conducted by each regional office validated by another .

officials of one state survey agency , noting that state survey agencies can appeal their performance scores only to the same regional office that conducted their performance review , suggested that a second regional office should at least be involved in the appeals process .

cms has not made full use of the information it collects about state survey agencies' complaint investigation processes through its complaints database and performance standards system .

for example , cms does not routinely use data from its complaints database to calculate certain measures that could enhance its understanding of state survey agencies' performance investigating complaints and has not publicly reported state survey agencies' scores on the performance standards .

cms has not made full use of data in the complaints database to monitor performance .

in part because of data reliability concerns , cms does not routinely calculate certain measures that could shed additional light on state survey agencies' performance — such as substantiation rates or additional measures of the timeliness of investigations .

substantiation rates , if interpreted by state survey agencies in a consistent manner , could provide insight into the quality of complaint investigations .

given the many factors that influence these rates , including whether the complaints have a basis in fact , it would not be appropriate to require state survey agencies to achieve a particular rate .

however , substantial variation in rates , either among states or over time , could signal issues with complaint investigations and prompt further inquiry by cms .

a cms headquarters official told us that because some state survey agencies may consider a complaint to be substantiated even if no federal deficiencies are cited , cms headquarters does not systematically monitor substantiation rates and most cms regional offices probably do not do so either .

the patient protection and affordable care act ( ppaca ) , enacted march 23 , 2010 , requires hhs to post on the nursing home compare web site summary information on substantiated complaints , including their number , type , severity and outcome , by march 23 , 2011 .

accordingly , a cms official told us that cms headquarters will issue guidance to ensure that state survey agencies interpret substantiation in a consistent manner .

additional measures of timeliness — such as the number of days by which state survey agencies miss the deadlines for some complaint investigations — could provide cms with a more comprehensive picture of performance in this area .

we found that some state survey agencies with similar scores on cms's timeliness standard for actual harm - high complaints in fiscal year 2009 had very different backlogs of complaint investigations .

for example , looking at two state survey agencies with performance scores of 82 and 85 percent — which indicates , respectively , that 18 and 15 percent of their investigations were late — we found that 51 percent of one agency's late investigations were initiated more than 30 days late in calendar year 2009 , compared with 4 percent for the other agency .

currently , the reliability of timeliness measures such as this is uncertain because state survey agencies do not necessarily enter all complaints into cms's database or prioritize complaints in the same way .

responsibility for training to address performance issues has generally been left to cms regional offices .

the cms regional offices in our sample have used information from the performance standards system to identify performance issues , but training designed to address these issues has generally been undertaken by individual cms regional offices and , as a result , has varied in content and scope .

complaint investigation training at the national level has been limited and was not designed to address specific performance issues identified during reviews .

officials of most of the state survey agencies in our sample indicated that cms's training and guidance was sufficient , but officials of two state survey agencies noted that their agencies provide any training above the basic level .

one state survey agency official said that cms should offer more comprehensive training , including more material on complaint investigations , so that states are not “sinking or swimming” on their own and are able to conduct investigations in a more consistent manner .

ppaca directed hhs to enter into a contract to establish a national training institute to help surveyors develop complaint investigation skills .

however , as of march 2011 , funds had not yet been appropriated to implement this provision of the act , and cms estimates that it would cost about $12 million to establish the institute .

as a start , cms has redirected about $1 million from other projects to initiate a project which will provide instruction on all aspects of complaint surveys for all facility types , including nursing homes .

corrective action plans are not timely and may not address the underlying causes of performance issues .

cms requires state survey agencies that fail performance standards to submit plans to improve their performance , but cms does not require these plans to be submitted until halfway through the next performance cycle , which allows little time for corrective actions to take effect before the next performance review .

 ( see fig .

4. ) .

moreover , despite cms regional office input , the plans do not necessarily address the underlying causes of state survey agencies' failure to meet performance standards .

for example , all three of the state survey agencies in our sample that failed the timeliness of investigations standard for immediate jeopardy complaints , actual harm - high complaints , or both in all 4 fiscal years from 2006 through 2009 cited staff shortages as a reason , but two of the three submitted at least one corrective action plan during that period that did not propose hiring the additional staff needed .

cms regional office officials indicated that they had accepted such corrective action plans because the steps the state survey agencies did propose — such as developing a graphic analysis tool to track performance or implementing additional central oversight of regional offices — were likely to improve performance to some extent , and because cms does not have the authority to require state survey agencies to hire or reallocate staff .

only one of the cms regional offices in our sample reported ever having rejected a corrective action plan , and officials of one cms regional office told us they preferred that a corrective action plan provide a realistic account of what a state survey agency was going to try to achieve rather than propose actions that the agency could not carry out .

some cms officials view the penalties the agency might impose for failure to meet nursing home complaint standards as counterproductive or unrealistic .

cms's regulations provide for penalties to be imposed on a state survey agency for failure to follow procedures specified by cms for complaint investigations , such as reducing funding or terminating the contract under which the state survey agency conducts standard surveys and complaint investigations .

cms headquarters officials noted that while cms has reduced funding to state survey agencies for failure to meet requirements for standard surveys , such as statutory time frames , the agency has not done the same for complaint investigations .

one official said that cms has not done so partly because of concerns about the fairness of penalizing states for failure to meet standards that may vary from year to year , as well as concerns that reducing states' funding might make it even more difficult for them to meet the standards .

some cms regional office officials said that reducing state survey agencies' funding for failure to complete complaint investigations on time made sense , but others said that taking resources away from the agencies could be counterproductive , further hampering their ability to carry out investigations .

although cms could terminate its contract with a state survey agency , cms officials we interviewed indicated that this was not a realistic option .

cms has not publicly reported state survey agencies' performance scores .

public reporting of performance information has been advocated by gao and other auditors as a critical step in performance management because it provides policymakers and the public with information needed to assess progress and may also serve to motivate agency managers and staff .

while cms has shared state survey agencies' scores on the performance standards with all of the other state survey agencies , it has not made the scores available to other stakeholders , such as residents , family members , or advocates .

according to a cms headquarters official , some state survey agencies have made their own scores publicly available , but cms has not yet issued any guidance to the states on public disclosure of scores .

this official told us that cms plans to issue a policy memo affirming state survey agencies' right to disclose their own scores and is also considering making all of the scores publicly available , possibly on cms's web site .

although some cms regional office officials questioned whether performance reports might too easily be misconstrued by the public and necessarily gloss over details that would provide a more nuanced picture of performance , gao's prior work on performance management suggests reports can be structured to avoid these potential pitfalls — for example , by explaining the limitations of the data and using clearly defined terms and readily understood tables and graphs to convey information .

in the past decade , cms has made several efforts to improve the intake and investigation of nursing home complaints by state survey agencies , including ( 1 ) implementation of a database that not only helps state survey agencies track complaints but also helps cms monitor the state survey agencies' performance and ( 2 ) establishment of and refinements to its performance standards related to nursing home complaints .

however , our review indicates that challenges remain .

cms's complaint data have limitations .

we found that the lack of consistency in state surveys agencies' use of the database — particularly in terms of which complaints are entered and how certain fields are interpreted — undermines the reliability of some of the data and limits the usefulness of the database as a monitoring tool .

cms does not routinely use the data to calculate measures such as substantiation rates that could enhance its understanding of complaint investigations partly because of concerns about the reliability of the data .

cms's performance reviews highlight state workload issues .

although state survey agencies generally prioritized nursing home complaints in accordance with cms's performance standard , we found that many agencies had difficulty managing a heavy workload of actual harm - high complaints .

in 2009 , state survey agencies prioritized 45 percent of the more than 53,000 nursing home complaints they received as actual - harm high , which requires initiation of an investigation within 10 working days of prioritization .

in fiscal year 2009 , 19 state survey agencies failed to meet the cms timeliness standard for these complaints .

staffing shortages and heavy workloads were cited as key reasons by survey agency officials we interviewed whose states had failed this standard .

cms's policy for scoring the prioritization standard may contribute to these workload issues by creating an incentive for the agency staff who prioritize complaints to assign higher priority levels than are warranted .

while cms is correct in asserting that prioritizing complaints at too high a level is preferable to the reverse , this practice can have a significant impact on state survey agencies' workload and thus on their ability to meet requirements for timely investigations .

additionally , cms data for 2009 showed that , among investigated complaints prioritized as either immediate jeopardy or actual harm - high , the percentage substantiated with at least one federal deficiency cited was higher if the investigation was initiated within required time frames than if it was not .

though many factors can affect whether complaints are substantiated , including whether there is evidence to support them , considerable variation in substantiation rates , among the states or over time , could indicate potential concerns with state survey agencies' complaint investigations .

some performance standards scores are unreliable due to small samples and varying interpretations of requirements .

cms has also made efforts to refine its performance standards for nursing home complaints .

however , as with the complaints data , scores on some standards are unreliable , because of inadequate sample sizes and varying interpretations of the standards by the cms regional office officials who conduct the performance reviews .

while we recognize that cms may have opted for small samples for some standards in order to limit the amount of documentation reviewers must examine each year , sample sizes could be increased without increasing reviewers' workloads if performance on certain standards — those that require document review — were assessed less frequently than once a year .

less frequent reviews could also help address the issue of state survey agencies receiving their final scores and submitting their corrective action plans so far into the next performance cycle that little time remains for them to improve their performance .

the credibility of the scores could be further enhanced by ensuring that the standards are consistently interpreted by the cms regional offices .

clarifying cms guidance could help in this regard as well as in ensuring that state survey agencies understand their responsibilities with respect to each aspect of the complaint investigation process , including the manner in which investigation results are communicated to complainants .

cms is considering making state survey agencies' scores on the performance standards publicly available .

while we support such a step , we believe that it is important to consider the reliability of data , as well as its comparability over time , when deciding which scores to publish .

for such performance reports to be useful to the public , they should also include meaningful trend data that reflect agencies' actual progress over time , as well as a clear explanation of the limitations of the data .

to ensure that information entered into cms's complaints database is reliable and consistent , we recommend that the administrator of cms: identify issues with data quality and clarify guidance to states about how particular fields in the database should be interpreted , such as what it means to substantiate a complaint .

to strengthen cms's assessment of state survey agencies' performance in the management of nursing home complaints , we recommend that the administrator of cms take the following three actions: conduct additional monitoring of state performance using information from cms's complaints database , such as additional timeliness measures .

assess state survey agencies' performance in certain areas — specifically , documentation of deficiencies , prioritization of complaints , and quality of investigations — less frequently than once a year .

assure greater consistency in assessments by identifying differences in interpretation of the performance standards and clarifying guidance to state survey agencies and cms regional offices .

to strengthen and increase accountability of state survey agencies' management of the nursing home complaints process , we recommend that the administrator of cms take the following three actions: clarify guidance to the state survey agencies about the minimum information that should be conveyed to complainants at the close of an investigation .

provide guidance encouraging state survey agencies to prioritize complaints at the level that is warranted , not above that level .

implement cms's proposed plans to publish state survey agencies' scores but limit publication to those performance standards that cms considers the most reliable and clear .

we received written comments on a draft of this report from hhs and from the association of health facility survey agencies ( ahfsa ) , the organization that represents state survey agencies .

hhs provided written comments , which are reproduced in app .

iii .

hhs generally concurred with all of our recommendations .

with respect to our first recommendation , hhs agreed that cms should take steps to ensure that information entered into the agency's complaints database is reliable and consistent .

hhs said that cms will convene a workgroup — including staff from cms headquarters , cms regional offices , and state survey agencies — to address data quality issues .

hhs also agreed that cms needs to strengthen its assessment of state survey agencies' performance in the management of nursing home complaints .

hhs said that cms's planned workgroup will review the three specific actions we recommended and identify ways to strengthen the agency's oversight process .

finally , hhs agreed that cms needs to strengthen and increase accountability of state survey agencies' management of the nursing home complaints process .

regarding the specific actions we recommended , hhs said that cms will provide increased guidance to states regarding the minimum information that must be conveyed to complainants at the close of an investigation and provide clarification and guidance to ensure that complaints are prioritized at the appropriate level .

with respect to our recommendation that cms publish state survey agencies' scores on certain nursing home complaint performance standards , hhs said that cms will work with state officials and others to identify key information about state survey agencies' performance that would be of public value .

hhs also provided technical comments , which we incorporated as appropriate .

ahfsa emphasized the critical importance of enforcing federal and state survey and certification standards and noted that in many states , complaint systems have significant connections to state and local licensing and enforcement activities , which are outside cms's jurisdiction .

ahfsa noted that several of the policy and operational issues raised in our report create challenges for states .

these include lack of clarity about what it means to substantiate a complaint and lack of timely notification to the states of any changes in cms's performance standards for nursing home complaints .

ahfsa also commented that cms's guidance on prioritizing complaints could be improved but questioned whether many states were prioritizing complaints at a higher level than is warranted in order to meet cms's prioritization standard .

in addition , ahfsa said that the complaint system is the primary safety net for vulnerable nursing home residents and therefore suggested that states should err on the side of caution when prioritizing complaints in order to better protect residents .

ahfsa also provided some state - specific comments , which we incorporated as appropriate .

as agreed with your office , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the secretary of health and human services , the administrator of the centers for medicare & medicaid services , and other interested parties .

in addition , the report will be available at no charge on the gao web site at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-7114 or at dickenj@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix iv .

this appendix provides additional information on the number of complaints received , investigated , and substantiated by all 50 state survey agencies and the survey agency for the district of columbia for 2009 based on complaints in centers for medicare & medicaid services' ( cms ) national complaints database .

we included only complaints and excluded facility - reported incidents , which nursing homes are required to self - report to state survey agencies .

additionally , we included only complaints that alleged a violation of federal requirements .

in the course of our work , we found some limitations to the data we obtained , including that state survey agencies interpret certain variables , such as substantiation , differently from one another and that data are missing for certain variables , such as the date on which the state survey agency acknowledged the complaint .

additionally , we learned that cms's national database may not include all complaints because the state survey agencies may not have entered all of the complaints they received .

because of the data limitations we found , we included in our analysis only those variables that we found to be reliable , and we consider the number of complaints from cms's national complaints database to be a conservative estimate of the total number of complaints received by state survey agencies .

score ( percent ) pass ( √ ) or fail ( x ) score ( percent ) pass ( √ ) or fail ( x ) score ( percent ) score ( percent ) pass ( √ ) or fail ( x ) score ( percent ) pass ( √ ) or fail ( x ) score ( percent ) √= passed performance standard x= failed performance standard .

a blank in the score column indicates that the state received a passing score ( at least 90 percent for the prioritization of complaints standard and at least 95 percent for the timeliness of investigation standards for immediate jeopardy and actual harm - high complaints ) .

pennsylvania officials reported that the state did not pass the prioritization of complaints standard because it required all complaint investigations to be initiated within 48 hours and survey agency staff therefore assigned a priority level of immediate jeopardy to nearly all complaints .

because cms guidance on this standard was not clear in fiscal year 2009 , the cms regional office that assessed pennsylvania's performance considered complaints assigned a priority level higher than warranted to be inappropriately prioritized and therefore gave the state a failing score on this standard .

in addition to the contact name above , walter ochinko , assistant director ; jennie apter ; shaunessye curry ; christie enders ; nancy fasciano ; dan lee ; lisa motley ; matthew rae ; and jessica smith made key contributions to this report .

nursing homes: complexity of private investment purchases demonstrates need for cms to improve the usability and completeness of ownership data .

gao - 10-710 .

washington , d.c.: september 30 , 2010 .

poorly performing nursing homes: special focus facilities are often improving , but cms's program could be strengthened .

gao - 10-197 .

washington , d.c.: march 19 , 2010 .

nursing homes: addressing the factors underlying understatement of serious care problems requires sustained cms and state commitment .

gao - 10-70 .

washington , d.c.: november 24 , 2009 .

nursing homes: opportunities exist to facilitate the use of the temporary management sanction .

gao - 10-37r .

washington , d.c.: november 20 , 2009 .

nursing homes: cms's special focus facility methodology should better target the most poorly performing homes , which tended to be chain affiliated and for - profit .

gao - 09-689 .

washington , d.c.: august 28 , 2009 .

medicare and medicaid participating facilities: cms needs to reexamine its approach for funding state oversight of health care facilities .

gao - 09-64 .

washington , d.c.: february 13 , 2009 .

nursing homes: federal monitoring surveys demonstrate continued understatement of serious care problems and cms oversight weaknesses .

gao - 08-517 .

washington , d.c.: may 9 , 2008 .

nursing home reform: continued attention is needed to improve quality of care in small but significant share of homes .

gao - 07-794t .

washington , d.c.: may 2 , 2007 .

nursing homes: efforts to strengthen federal enforcement have not deterred some homes from repeatedly harming residents .

gao - 07-241 .

washington , d.c.: march 26 , 2007 .

nursing homes: despite increased oversight , challenges remain in ensuring high - quality care and resident safety .

gao - 06-117 .

washington , d.c.: december 28 , 2005 .

nursing home quality: prevalence of serious problems , while declining , reinforces importance of enhanced oversight .

gao - 03-561 .

washington , d.c.: july 15 , 2003 .

nursing homes: public reporting of quality indicators has merit , but national implementation is premature .

gao - 03-187 .

washington , d.c.: october 31 , 2002 .

nursing homes: federal efforts to monitor resident assessment data should complement state activities .

gao - 02-279 .

washington , d.c.: february 15 , 2002 .

nursing homes: sustained efforts are essential to realize potential of the quality initiatives .

gao / hehs - 00-197 .

washington , d.c.: september 28 , 2000 .

nursing home care: enhanced hcfa oversight of state programs would better ensure quality .

gao / hehs - 00-6 .

washington , d.c.: november 4 , 1999 .

nursing home oversight: industry examples do not demonstrate that regulatory actions were unreasonable .

gao / hehs - 99-154r .

washington , d.c.: august 13 , 1999 .

nursing homes: proposal to enhance oversight of poorly performing homes has merit .

gao / hehs - 99-157 .

washington , d.c.: june 30 , 1999 .

nursing homes: complaint investigation processes often inadequate to protect residents .

gao / hehs - 99-80 .

washington , d.c.: march 22 , 1999 .

nursing homes: additional steps needed to strengthen enforcement of federal quality standards .

gao / hehs - 99-46 .

washington , d.c.: march 18 , 1999 .

california nursing homes: care problems persist despite federal and state oversight .

gao / hehs - 98-202 .

washington , d.c.: july 27 , 1998 .

