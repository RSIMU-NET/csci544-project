the national aeronautics and space administration ( nasa ) plans to spend over $100 billion to develop new capabilities and technologies critical to supporting the initial goals outlined in the president's 2004 vision for space exploration ( see fig .

1 for a conceptual drawing of nasa's proposed crew vehicle ) .

the vision , which nasa has characterized as bold , includes plans to explore the moon , mars , and beyond .

despite many successes , such as landing the pathfinder and exploration rovers on mars , nasa has had difficulty carrying out a number of other missions , such as the x - 33 , a technology demonstrator for future reusable launch vehicles , because the agency was overly optimistic in what could be achieved within available resources .

nasa's failure to define requirements adequately and quantify the resources needed to meet those requirements resulted in some projects costing more , taking longer , and achieving less than originally planned .

in addition to these project management challenges , a constrained federal budget and a shrinking experienced project manager and technical workforce , well - versed in systems engineering and architecture design , will present further challenges to nasa in the years ahead .

to meet these challenges , nasa recently updated its program and project management policy and is developing an agencywide systems engineering policy .

nasa expects that these new polices will help the agency manage its projects with greater efficiency , responsibility , and accountability .

we have issued a series of reports on the importance of obtaining critical information and knowledge at key junctures in major system acquisitions before additional investments are made .

this work has shown that following a knowledge - based approach helps developers meet cost and schedule objectives in developing new and more sophisticated products — the kinds of results that nasa seeks .

given the major endeavor that nasa is about to undertake , the agency's history of cost and schedule overruns and technical problems , and the significant challenges the agency currently faces and will likely face , you asked us to ( 1 ) evaluate whether nasa's policies support an acquisition approach consistent with best practices identified in gao's work on system acquisitions and ( 2 ) describe how nasa - wide acquisition policies are implemented at the various nasa centers .

to conduct our work , we reviewed and analyzed nasa - wide program and project management policies as they relate to flight systems and ground support projects and systems engineering guidance and compared the policies and guidance with criteria contained in gao's best practices work on systems acquisition , including space systems .

we also interviewed nasa headquarters officials from the office of the chief engineer responsible for the policy and guidance .

in addition , we reviewed nasa center - specific program and project management policies and systems engineering policies , as they relate to flight systems and ground support projects , and interviewed officials responsible for implementing those policies .

we focused primarily on goddard space flight center ( gsfc ) , the jet propulsion laboratory ( jpl ) , johnson space center ( jsc ) , and marshall space flight center ( msfc ) , which manage the majority of nasa's flight systems and ground support projects .

complete details of our scope and methodology can be found in appendix i .

we performed our work from may 2005 to november 2005 in accordance with generally accepted government auditing standards .

over the past decade , nasa has experienced significant problems with several of its projects , which gao and others have reported on ( see table 1 for some examples of such problems ) .

in addition , in 2002 we reported on several sources of failures in nasa programs , including underestimating complexity and technology maturity , and inadequate review and systems engineering processes .

further , we reported that the sources of these problems were not new and that nasa failed to consistently apply lessons previously learned .

the failures identified in our 2002 report were in part the result of the “faster , better , cheaper” approach to managing its major acquisitions , which nasa adopted in the 1990s .

these problems , along with others , highlighted the need for the agency to reevaluate its approach to cost and schedule estimating , risk assessments , technology development , project reviews , and systems engineering .

in 1998 , nasa adopted a new program and project management policy , which was revised in 2002 .

the policy provided significant flexibility , including allowing tailoring and projects to opt out of requirements at the discretion of the project manager .

in march 2005 — following a series of internal and external assessments of nasa that showed that the agency faced significant problems with project management — nasa again revised its program and project management policy , which includes policy requirements for the development of flight systems and ground support projects .

according to nasa officials , further changes to the policy are anticipated in light of new agency leadership .

the march 2005 policy document , nasa procedural requirement ( npr ) 7120.5c , differs from previous versions of the policy in that it delineates requirements based on four nasa investment areas: basic and applied research , advanced technology development , flight systems and ground support , and institutional infrastructure .

the policy also reinstitutes a life cycle phased approach to product development and institutes a project categorization scheme , based on project cost and priority , which denotes the oversight authorities and the level of detail that is needed to support project planning documents .

see figure 2 below .

nasa has also attempted to address some of its cost - estimating weaknesses by instituting a cost analysis data requirement ( cadre ) and establishing thresholds for the use of earned value management ( evm ) .

another major change to the policy is the establishment of the independent technical authority ( ita ) .

according to the policy , the purpose of ita is to establish sound technical requirements and decisions for safe and reliable system operations separate from the project management and reporting chain .

finally , agency officials told us that while the requirements in previous versions of the policy were easy to tailor , projects now must document compliance with the requirements in a “compliance matrix” and must request and have approved any deviations and / or waivers to requirements .

although npr 7120.5c contains some mandatory requirements with regard to systems engineering , according to agency officials , nasa has never had an agencywide systems engineering policy to inform the development of flight systems and ground support projects .

since 1995 , in the absence of a policy on systems engineering , project managers and systems engineers have relied on information contained in nasa's systems engineering handbook to guide their systems engineering approach on projects .

project managers and systems engineers , however , are not required to follow the handbook .

recognizing the need for a more structured and rigorous approach to systems engineering agencywide , nasa's office of the chief engineer is currently leading the effort to develop a systems engineering policy .

the policy is in draft form .

over the last several years , we have undertaken a body of work on how leading developers in industry and government use a knowledge - based approach to deliver high quality products on time and within budget .

a knowledge - based approach to product development efforts enables developers to be reasonably certain , at critical junctures or “knowledge points” in the acquisition life cycle , that their products are more likely to meet established cost , schedule , and performance baselines and , therefore provides them with information needed to make sound investment decisions .

see figure 3 for a depiction of a knowledge - based acquisition life cycle .

knowledge point 1 ( kp1 ) : resources and needs match .

knowledge point 1 occurs when a sound business case is made for the product — that is , a match is made between the customer's requirements and the product developer's available resources in terms of knowledge , time , workforce , and money .

to determine available resources , successful developers rely on current and valid information from predecessor projects , new technologies that have demonstrated a high level of maturity , system engineering data , and experienced people .

successful developers also communicate extensively with customers to match their wants and needs with available resources and with the developers ability to manufacture an appropriate product .

knowledge point 2 ( kp2 ) : product design is stable .

knowledge point 2 occurs when a developer determines that a product's design is stable — that is , it will meet customer requirements and cost and schedule targets .

a best practice is to achieve design stability at the product's critical design review ( cdr ) , usually held midway through development .

completion of at least 90 percent of engineering drawings at the cdr provides tangible evidence to decision makers that the design is stable .

knowledge point 3 ( kp3 ) : production processes are mature .

this level of knowledge is achieved when it has been demonstrated that the product can be manufactured within cost , schedule , and quality targets .

a best practice is to ensure that all key manufacturing processes are in statistical control — that is , they are repeatable , sustainable , and capable of consistently producing parts within the product's quality tolerances and standards — at the start of production .

it is important that the product's reliability be demonstrated before production begins , as investments can increase significantly if defective parts need to be repaired or reworked .

if the knowledge attained at each juncture does not confirm the business case on which the initial investment was originally justified , the project should not go forward and additional resources should not be committed .

product development efforts that do not follow a knowledge - based approach can be frequently characterized by poor cost , schedule , and performance outcomes .

nasa's revised acquisition policy for developing flight and ground support systems incorporates some of the elements of a knowledge - based acquisition approach .

however , it lacks specific key criteria and decision reviews necessary to fully support such an approach .

nasa's policy defines a phased life cycle approach and requires a major decision review to move from project formulation to implementation .

the policy requirements for this review address many of the key elements necessary to match needs to resources , such as requirements to establish project baselines .

however , the policy does not require that projects demonstrate technologies at high levels of maturity before launching a project and investing a large amount of resources .

in addition , nasa's policy does not require any further major decision reviews following the formulation phase of the project .

major decision reviews in the implementation phase based on specific evaluation criteria at the final design and fabrication , assembly , and testing milestones — critical decision points in any product development — could help nasa ensure that sufficient knowledge has been gained to warrant moving forward in the development process .

the life cycle for all nasa projects is divided into two major phases — formulation and implementation .

because flight systems and ground support projects are particularly complex and have long life cycles , nasa has further divided the formulation and implementation phases for these projects to allow managers to assess management and engineering progress ( see fig .

4 ) .

flight systems and ground support projects must successfully complete two major decision reviews: a preliminary - non advocate review ( pre - nar ) between phases a and b and a non - advocate review ( nar ) between phases b and c. at these reviews , the governing program management committee ( gpmc ) evaluates the cost , schedule , safety , and technical content of the project to ensure that the project is meeting commitments specified in key management documents .

following each of these reviews , the gpmc recommends to the appropriate decision authority whether the project should be authorized to proceed .

as with kp1 in a knowledge - based acquisition life cycle , the nar marks the official project approval point in the life cycle .

after approval at the nar , projects are included as part of implementation reviews of their parent program .

these implementation reviews are conducted biennially and are not tied to any design or production milestones .

after entering the implementation phase , the gpmc is notified if cost or schedule performance exceeds the baselines established at the nar by 10 percent or when key performance criteria are not met .

exceeding the nar baselines can result in the gpmc conducting a termination review to determine whether or not to continue the project .

to help ensure project requirements do not outstrip resources , leading developers obtain the right knowledge about a new product's technology , design , and production at the right time .

nasa's policy emphasizes many elements needed at the nar ( or kp1 ) to match needs to resources , such as validating requirements , developing realistic cost and schedule estimates and human capital plans , and establishing a preliminary design .

the policy does not , however , require projects to demonstrate technologies at high levels of maturity before launching a project .

table 2 compares kp1 criteria and nasa's policy criteria .

while nasa requires projects to develop plans that describe how technologies will be matured and to provide alternative development strategies for technologies that do not mature as expected , it does not establish a minimum threshold for technology maturity .

consequently , projects can enter the implementation phase with immature technologies and embark on a risky path of having to build technology , design , and production knowledge concurrently .

our best practices work has shown that maturing technologies during the preliminary design phase and before entering product development is a key element of matching needs to resources and that there is a direct relationship between the maturity of technologies and the risk of cost and schedule growth .

allowing technology development to carry over into the product development phase increases the risk that significant problems will be discovered late in development .

addressing such problems at this stage may require extensive retrofitting and redesign as well as retesting , which can jeopardize performance and result in more time and money to fix .

this approach also makes it more difficult for projects to demonstrate the same level of design stability in later phases of implementation since technology and design activities will be done concurrently .

technology readiness levels ( trl ) — a concept developed by nasa — can be used to gauge the maturity of individual technologies .

the higher the trl , the more the technology has been proven and the lower the risk of performance problems and cost and schedule overruns ( see fig .

5 ) .

trl 7 — demonstrating a technology as a fully integrated prototype in an operational environment — is the level of maturity preferred by product developers to minimize risks when entering product development .

successful developers will not commit to undertaking product development , and more importantly investing resources , unless they have high confidence that they have achieved a match between what the customer wants and what the project can deliver .

technologies that are not mature continue to be developed in an environment that is focused solely on technology development .

once matured , these technologies can be transitioned to projects .

this puts developers in a better position to succeed because they can focus on integrating the technologies and testing and proving the product design .

our prior work has shown that successful developers establish specific criteria to ensure that requisite knowledge has been attained before moving forward from final design into the latter stages of development .

before making significant increases in investments to fabricate , assemble , and test the product , these developers conduct a decision review to determine if the design is stable and performs as expected and the project is ready to enter the next phase .

to make this determination and reach kp2 , successful developers use specific , knowledge - based standards and criteria .

 ( see app .

ii for more information on the specific knowledge - based standards and criteria successful developers use to judge readiness to proceed beyond detailed design activities. ) .

successful developers also demand proof that manufacturing processes are in control and product reliability goals are attained before committing to production .

to determine whether they have achieved this knowledge point , kp3 , successful developers conduct another mandatory decision review in which they use specific , knowledge - based standards and criteria to determine if the product can be produced within cost , schedule , and quality targets .

 ( see app .

ii for more information on specific knowledge - based standards and criteria used by successful developers to judge readiness to enter into production. ) .

contrary to these best practices , the nar at the end of the preliminary design phase — kp1 — is the last major decision review in the nasa project life cycle .

 ( see fig .

6. ) .

although npr 7120.5c requires that projects document in the project plan a continuum of technical and management reviews , such as a pdr and cdr , it does not require any specific reviews .

in addition , nasa's march 2005 policy does not require a nar - type decision review to ensure a project has obtained the knowledge needed to proceed beyond the final design phase into the fabrication , assembly , and test phase , which serves as both the demonstration and production phase of the nasa life cycle .

according to nasa officials , projects conduct a cdr at the end of the final design phase to ensure adequate information is available about product design and producibility before entering the fabrication , assembly , and test phase .

the cdr , however , is a technical review — not a major decision review like the nar .

furthermore , the policy does not establish criteria as to what constitutes successful completion of a cdr .

nasa's policy also does not require a major decision review before beginning manufacturing .

 ( see fig .

6 above. ) .

therefore , the transition from final design to fabrication , assembly , and test often marks a de facto production decision .

according to nasa officials , the agency rarely enters a formal production phase due to the small quantities of space systems that they build .

however , due to the high cost of failure associated with nasa projects and the costs and risks involved in repairing a system in - orbit , a major decision review at production that assesses product reliability is essential even for these limited production systems .

in addition , although nasa's production quantities are typically low , in some instances nasa does produce larger quantities of a system or subsystem , such as the external tanks for the space shuttle .

furthermore , nasa's plans indicate that the agency may be increasing production for elements of their future systems .

for example , nasa's exploration systems architecture study indicates that nasa plans to build several new crew exploration vehicles , with disposable elements , such as the lunar lander , solid rocket boosters , and space shuttle main engines that will require higher numbers of production runs .

rather than establish specific criteria by which all projects are judged , nasa's policy requires that projects manage to baselines and plans established in key management documents and approved at the project nar .

the baselines and plans serve as their primary tools for measuring project progress and as the primary basis for judgment at project reviews .

while the plans may include some information that addresses knowledge - based criteria for design and production , the instructions for preparing them leaves the establishment of thresholds and success criteria to the discretion of the project manager .

for example , nasa policy requires that projects include , as part of the project plan , a verification and validation sub plan that describes the project's approach to verifying and validating hardware and software as part of the project plan .

the policy , however , includes no instruction as to what constitutes a sufficient approach to testing .

in other words , there are no requirements concerning the fidelity of test articles or the realism of the test environment .

similarly , nasa's policy requires that projects include , as part of the project plan , a systems engineering sub plan that describes the project's approach to systems engineering and the technical standards that are applicable , including metrics that verify the processes .

the policy , however , does not identify the types of metrics appropriate to verify the process or establish any threshold criteria .

the absence of major decision reviews , along with specific criteria in the fabrication , assembly , and test phase , could result in concurrent design and manufacturing activities , a practice our past work has found increases risk in acquisition programs .

furthermore , lacking a major decision review to ensure that projects have gained the appropriate levels of knowledge at kp2 and kp3 , nasa decision makers cannot be provided a high level of certainty that the project will meet cost , schedule , and performance requirements and have no assurance that the provisions of the key management documents required by npr 7120.5c are being executed after the nar .

nasa centers have varying approaches to implementing project management policies and systems engineering guidance for flight systems and ground support projects .

some centers use criteria at key decision points that are similar to the criteria required to ensure a knowledge - based approach is followed , while others lack such criteria .

as a result , each center reports a different level and type of knowledge about a project at key decision points .

centers also rely on project managers and systems engineers to employ good project management and systems engineering practices .

however , given the loss of experienced project managers and the decline of in - house systems engineering and technical capabilities agencywide , that reliance could be problematic .

these situations make it difficult for nasa decision makers to evaluate center projects on a common foundation of knowledge and make sound investment decisions and tradeoffs based on those evaluations .

a standardized , knowledge - based approach would prepare nasa to face competing budgetary priorities and make difficult decisions regarding the investment in and termination of projects .

while nasa centers are given discretion about how they implement agencywide policies , they are expected to have procedures and guidelines in place for implementing those policies .

some centers have developed center - specific policies and criteria for implementing nasa's project management policies and system engineering guidance , while others have not .

centers also rely on project managers and systems engineers to implement the requirements of npr 7120.5c and to use nasa's systems engineering handbook as guidance for good systems engineering practices .

some nasa centers have also developed criteria in their policies that are similar to the criteria used to ensure a knowledge - based approach is followed ; other centers lack such criteria .

because of their varying policies and criteria , each center requires a different level of knowledge at the same point in a project's development cycle .

for example , gsfc requires its projects to mature technologies to trl 6 by the preliminary design review — before entering the implementation phase .

on the other hand , jpl , msfc , and jsc policies do not require projects to mature technology to a particular level before entering implementation , leaving the determination of needed technology maturity up to the project manager .

requirements for assessing design maturity also vary across the centers .

while most of the center policies require a cdr to enter “phase d — fabrication , assembly , and test” — the criteria used to assess projects at this point vary .

for example , both gsfc and msfc require projects to have completed a percentage of design drawings at this review .

msfc requires that 90 percent of design drawings to be complete by cdr , which is consistent with best practices .

while gsfc establishes a minimum threshold of drawings to be complete by cdr — greater than 80 percent — neither jsc nor jpl establish a minimum percentage drawing requirement .

instead , jsc requires the design be complete and drawings ready to begin production , and jpl requires that the design be mature and provide confidence in the integrity of the flight system design .

almost none of the center policies include a requirement to assess the maturity of production processes .

according to nasa officials , due to the low quantities of systems generally produced by the agency , most of the center policies do not require a review before beginning manufacturing .

only jsc requires a production readiness review to ensure that production plans , facilities , and personnel are in place and ready to begin production .

however , the criteria do not specify quantifiable thresholds to measure production readiness at the review .

jpl , msfc , and gsfc do not have policies that outline requirements for such a review .

in addition to individual policy requirements , centers may rely on project managers and systems engineers to employ good project management and systems engineering practices .

for example , an experienced project manager at jpl told us that although jpl policy does not require a particular trl at pdr to enter implementation , he required that all technologies for his project be around a trl 6 in order to separate technology development from systems development .

reliance on project managers to implement good practices , however , could be problematic given the diminishing number of experienced project managers available to lead projects and the decline of in - house systems engineering and technical capabilities agencywide caused by increasing retirements and outsourcing .

in a knowledge - based process , the achievement of each successive knowledge point builds on the preceding one , giving decision makers the information they need , when they need it , to make decisions about whether to invest significant additional funds to move forward with product development .

our work has shown that successful product development efforts are marked by adherence to a disciplined process that establishes and uses common and consistent criteria for decision making at these key points .

with varying project management and systems engineering criteria , nasa centers' technical reviews , such as pdr , provide different levels of knowledge to support nasa's major decision reviews , such as the nar , which nasa uses to support its major investment decisions for flight systems and ground support projects .

in the near future , nasa will need to determine the resources necessary to develop the systems and supporting technologies to achieve the president's vision for space exploration and structure its investment strategy accordingly .

initial implementation of the vision as explained in nasa's exploration systems architecture study calls for completing the international space station , developing a new crew exploration vehicle , and returning to the moon no later than 2020 .

nasa estimates that it will cost approximately $104 billion over the next 13 years to accomplish these initial goals .

these priorities , along with nasa's other missions , will be competing within nasa for funding .

it will likely be difficult for nasa managers to agree on which projects to invest in and which projects to terminate .

the nasa administrator has acknowledged that nasa faces difficult choices about its missions in the future — for example , between human space flight , science , and aeronautics missions .

using consistent criteria to evaluate all nasa projects would help ensure that the same level and type of knowledge is available about individual projects at key decision points .

analogous information about all flight systems and ground support projects would allow decision makers to make apples - to - apples comparisons across projects and make investment decisions , and trade - offs , based upon these comparisons .

further , policies with consistent criteria can provide inexperienced project managers and systems engineers with the necessary guidance to implement good project management and systems engineering practices and ensure that the right knowledge is available for decision makers .

nasa officials within the chief engineer's office acknowledged the need for more consistency in criteria across the various nasa centers in order to successfully achieve nasa's vision for space exploration .

some nasa centers , however , are resistant to standardized criteria because they feel it could be overly prescriptive .

these centers indicated that because of the unique nature of the work done at each of the 10 nasa centers , it would be unrealistic to hold every project to the same criteria .

nonetheless , our work has shown that the process used by successful product developers to develop leading - edge technology and products does not differ based upon the type of product being developed .

further , these developers adhere to a disciplined process that establishes and uses common and consistent criteria for decision making — regardless of the type of product or technology being developed .

using consistent criteria can allow nasa decision makers to assess the likely return on competing investment priorities and to reevaluate alternatives and make investment decisions across projects to increase the likelihood of attaining the strategic goals of the agency .

several of nasa's major acquisitions have been marked by cost , schedule , and performance problems .

yet the challenges nasa faces in the future are likely to far exceed those it has faced in the past .

the complex technical requirements associated with fulfilling the president's vision , the fiscal constraints under which nasa will be required to operate , the diminished number of experienced project managers and systems engineers , and the potential for increased production make following a knowledge - based approach for flight systems and ground support projects all the more critical .

while nasa has made improvements to its policies governing project management , the lack of major decision reviews beyond the initial project approval gate leaves decision makers with little knowledge about the progress of the agency's projects .

further , without a standard set of criteria to measure projects at crucial phases in the development life cycle , nasa cannot be assured that its decisions will result in the best possible return on its investments .

since nasa is currently in the process of revising its program and project management policies and developing an agencywide systems engineering policy , we believe this presents a unique opportunity for the agency to correct some of the problems identified during our review .

in order to close the gaps between nasa's current acquisition environment and best practices on knowledge - based acquisition , we recommend that nasa take steps to ensure nasa projects follow a knowledge - based approach for product development .

specifically , we recommend that the nasa administrator direct the office of the chief engineer to take the following two actions: in drafting its systems engineering policy , incorporate requirements in the policy for flight systems and ground support projects to capture specific product knowledge by key junctures in project development .

the demonstration of this knowledge should be used as exit criteria for decision making at the following key junctures: before projects are approved to transition from formulation to implementation , the policy should require that projects demonstrate that key technologies have reached a high maturity level .

before projects are approved to transition from final design to fabrication , assembly , and test , the policy should require that projects demonstrate that the design is stable .

before projects are approved to transition into production , the policy should require projects to demonstrate that the design can be manufactured within cost , schedule , and quality targets .

revise npr 7120.5c to institute additional major decision reviews following the nar for flight systems and ground support projects , which result in recommendations to the appropriate decision authority .

these reviews should be tied to the key junctures during project development mentioned above in order to increase the likelihood that cost , schedule , and performance requirements of the project will be met .

we provided a draft of this report to nasa for review and comment .

in written comments , nasa indicated that it agreed with our recommendations and outlined specific actions that the agency plans to take to address them .

the actions that nasa plans to take to address our recommendations are a positive step toward achieving successful project outcomes and ensuring that decision makers are appropriately investing the agency's resources .

we are pleased to hear that many knowledge - based practices identified in our report are currently being practiced agencywide in the management and development nasa systems .

the addition of such practices to nasa's policies will only strengthen their use agencywide and ensure that these practices continue to be utilized by less experienced project managers and systems engineers as the more experienced workforce retires .

the effectiveness of such practices , however , will be limited if project officials are not held accountable for demonstrating a high level of knowledge , consistent with the success criteria that nasa plans to require in its policies , at key junctures in development .

it is critical that project officials not only have a high level of knowledge about a project at key junctures , but also that this information is used by decision makers to make decisions on whether to invest additional resources and allow a project to proceed through the development life cycle .

nasa's comments are reprinted in appendix iii .

nasa also provided technical comments , which we addressed throughout the report as appropriate .

as agreed with your offices , unless you announce its contents earlier , we will not distribute this report further until 30 days from its date .

at that time , we will send copies to nasa's administrator and interested congressional committees .

we will make copies available to others upon request .

in addition , the report will be available at no charge on the gao web site at http: / / www.gao.gov .

if your or your staff have any questions concerning this report , please contact me at ( 202 ) 512-4841 or lia@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are acknowledged in appendix iv .

to determine the extent to which nasa's current policies support an acquisition approach consistent with best practices identified in gao's work on system acquisitions , we reviewed and analyzed nasa - wide program and project management policies and systems engineering guidance .

our review and analysis of the policy focused on requirements for flight systems and ground support projects .

we interviewed nasa headquarters officials from the office of the chief engineer who are responsible for the policy and guidance .

we compared nasa's policy on program and project management with criteria contained in gao best practices work on systems acquisition and space system acquisitions .

we concentrated on whether the policy provides a framework for a knowledge - based process and the criteria necessary to carry out this intent .

to determine how nasa - wide acquisition policies are implemented across the various nasa centers , we reviewed nasa center - specific program and project management policies and systems engineering policies and interviewed officials responsible for implementing those policies .

while we interviewed officials from all centers , we focused on the centers that manage the majority of nasa's flight systems and ground support projects — gsfc , jpl , jsc , and msfc .

this approach included site visits with gsfc , jpl , jsc , and msfc and teleconferences with the remaining centers .

we compared examples of the centers' implementation of the policies and specific criteria included in these policies with our best practices work on systems acquisition .

we performed our work from may 2005 to november 2005 in accordance with generally accepted government auditing standards .

in addition to the individual named above , james l. morrison , assistant director ; valerie colaiaco , tom gordon , alison heafitz , shelby s. oakley , ron schwenn , karen sloan , and john s. warren , jr. , made key contributions to this report .

space acquisitions: stronger development practices and investment planning need to address continuing problems .

gao - 05-891t .

washington , d.c.: july 12 , 2005 .

defense acquisitions: incentives and pressures that drive problems affecting satellite and related acquisitions .

gao - 05-570r .

washington , d.c.: june 23 , 2005 .

defense acquisitions: space - based radar effort needs additional knowledge before starting development .

gao - 04-759 .

washington , d.c.: july 23 , 2004 .

defense acquisitions: risks posed by dod's new space systems acquisition policy .

gao - 04-379r .

washington , d.c.: january 29 , 2004 .

space acquisitions: committing prematurely to the transformational satellite program elevates risks for poor cost , schedule , and performance outcomes .

gao - 04-71r .

washington , d.c.: december 4 , 2003 .

defense acquisitions: improvements needed in space systems acquisition policy to optimize growing investment in space .

gao - 04-253t .

washington , d.c.: november 18 , 2003 .

defense acquisitions: despite restructuring , sbirs high program remains at risk of cost and schedule overruns .

gao - 04-48 .

washington , d.c.: october 31 , 2003 .

defense acquisitions: improvements needed in space systems acquisition management policy .

gao - 03-1073 .

washington , d.c.: september 15 , 2003 .

military space operations: common problems and their effects on satellite and related acquisitions .

gao - 03-825r .

washington , d.c.: june 2 , 2003 .

military space operations: planning , funding , and acquisition challenges facing efforts to strengthen space control .

gao - 02-738 .

washington , d.c.: september 23 , 2002 .

polar - orbiting environmental satellites: status , plans , and future data management challenges .

gao - 02-684t .

washington , d.c.: july 24 , 2002 .

defense acquisitions: space - based infrared system - low at risk of missing initial deployment date .

gao - 01-6 .

washington , d.c.: february 28 , 2001 .

defense acquisitions: assessments of selected major weapon programs .

gao - 05-301 .

washington , d.c.: march 31 , 2005 .

defense acquisitions: stronger management practices are needed to improve dod's software - intensive weapon acquisitions .

gao - 04-393 .

washington , d.c.: march 1 , 2004 .

defense acquisitions: assessments of selected major weapon programs .

gao - 04-248 .

washington , d.c.: march 31 , 2004 .

defense acquisitions: dod's revised policy emphasizes best practices , but more controls are needed .

gao - 04-53 .

washington , d.c.: november 10 , 2003 .

defense acquisitions: assessments of selected major weapon programs .

gao - 03-476 .

washington , d.c.: may 15 , 2003 .

best practices: setting requirements differently could reduce weapon systems' total ownership costs .

gao - 03-57 .

washington , d.c.: february 11 , 2003 .

best practices: capturing design and manufacturing knowledge early improves acquisition outcomes .

gao - 02-701 .

washington , d.c.: july 15 , 2002 .

defense acquisitions: dod faces challenges in implementing best practices .

gao - 02-469t .

washington , d.c.: february 27 , 2002 .

best practices: better matching of needs and resources will lead to better weapon system outcomes .

gao - 01-288 .

washington , d.c.: march 8 , 2001 .

best practices: a more constructive test approach is key to better weapon system outcomes .

gao / nsiad - 00-199 .

washington , d.c.: july 31 , 2000 .

defense acquisition: employing best practices can shape better weapon system decisions .

gao / t - nsiad - 00-137 .

washington , d.c.: april 26 , 2000 .

best practices: dod training can do more to help weapon system program implement best practices .

gao / nsiad - 99-206 .

washington , d.c.: august 16 , 1999 .

best practices: better management of technology development can improve weapon system outcomes .

gao / nsiad - 99-162 .

washington , d.c.: july 30 , 1999 .

defense acquisitions: best commercial practices can improve program outcomes .

gao / t - nsiad - 99-116 .

washington , d.c.: march 17 , 1999 .

defense acquisition: improved program outcomes are possible .

gao / t - nsiad - 98-123 .

washington , d.c.: march 18 , 1998 .

best practices: successful application to weapon acquisition requires changes in dod's environment .

gao / nsiad - 98-56 .

washington , d.c.: february 24 , 1998 .

major acquisitions: significant changes underway in dod's earned value management process .

gao / nsiad - 97-108 .

washington , d.c.: may 5 , 1997 .

best practices: commercial quality assurance practices offer improvements for dod .

gao / nsiad - 96-162 .

washington , d.c.: august 26 , 1996 .

