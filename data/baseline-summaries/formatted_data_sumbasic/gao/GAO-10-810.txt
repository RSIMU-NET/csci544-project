the importance of managed care in the medicaid program is significant , with nearly half of all medicaid enrollees — approximately 20.7 million individuals — enrolled in capitated managed care in 2008 and a total of over $62 billion in federal and state spending for managed care in 2007 .

moreover , medicaid — a joint federal - state program that finances health care for certain categories of low - income individuals — is expanding .

with the passage of the patient protection and affordable care act ( ppaca ) in march 2010 , states will expand coverage under the medicaid program to an estimated 18 million additional people .

expansions of medicaid are likely to increase the number of people enrolled in and amount of spending for managed care , making effective federal oversight of this large and complex component of the medicaid program particularly critical .

the potential benefits and risks of medicaid managed care are substantial .

managed care is designed to ensure the provision of appropriate health care services in a cost - efficient manner .

however , capitation payments , which are made prospectively to health plans to provide or arrange for services for medicaid enrollees , can create an incentive to underserve or deny access to needed care .

thus , appropriate safeguards are needed to ensure access to care and appropriate payment in medicaid managed care .

one such safeguard included in federal law is the requirement that states' capitation rates be actuarially sound .

in 2002 , the centers for medicare & medicaid services ( cms ) , the agency within the department of health and human services ( hhs ) that oversees states' medicaid programs , issued regulations defining actuarially sound rates as those that are ( 1 ) developed in accordance with generally accepted actuarial principles and practices ; ( 2 ) appropriate for the populations to be covered and the services to be furnished ; and ( 3 ) certified as meeting applicable regulatory requirements by qualified actuaries .

the regulations also specify the documentation states are required to submit to cms regional offices to demonstrate compliance with the requirements , including a description of their rate - setting methodology and the data used to set rates .

in 2003 , cms finalized a detailed checklist that its regional office staff could use in their reviews of states' rate setting and for states and states' actuaries to consider in setting rates .

the children's health insurance program reauthorization act of 2009 directed us to examine the extent to which state medicaid managed care payment rates are actuarially sound .

specifically , we assessed ( 1 ) cms's oversight of states' compliance with the medicaid managed care actuarial soundness requirements , and ( 2 ) cms's efforts to ensure the quality of the data used to set rates .

to assess cms's oversight of states' compliance with the actuarial soundness requirements , we reviewed documentation of cms's oversight efforts from 6 of the 10 cms regional offices .

these offices were responsible for reviewing rate setting and approving rates for 26 of the 34 states with comprehensive managed care programs , were geographically diverse , and oversaw states with programs that ranged in size and accounted for about 85 percent of national managed care enrollment .

our review of cms's oversight efforts included completing a structured review of 28 cms files documenting rate - setting reviews completed as of october 31 , 2009 .

 ( see app .

i for a summary of the criteria we used to select the 6 cms regional offices and the methodology for our review of cms files. ) .

to supplement our review , we interviewed officials in cms's central office and the 6 selected cms regional offices to obtain information regarding steps taken by cms to ensure the actuarial soundness of rates ; and we reviewed regional office standard operating procedures .

we also interviewed medicaid officials from 11 of the states overseen by the 6 selected cms regional offices to obtain their views of , and experiences with , cms's oversight of state compliance with the actuarial soundness requirements .

these states were geographically diverse and had managed care programs that varied in size .

 ( see app .

ii for our criteria for selecting states for interviews. ) .

to assess cms's efforts to ensure the quality of data used to set rates , we reviewed cms policies and guidance related to rate setting .

in addition , in interviews with officials from cms's central office and the selected regional offices , we asked about steps cms takes to ensure data quality , including what information cms requires states to include in their rate - setting submissions to demonstrate the appropriateness and reliability of the data used to set rates and whether any audits or studies of rate setting had been performed .

we also assessed , as part of our review of cms files , the information provided in states' rate - setting submissions about steps taken to ensure data quality , including statements made by states' actuaries .

in interviews with state medicaid officials , we asked about their processes to ensure data quality and their experiences with cms oversight of data quality .

we also reviewed relevant audit findings from the washington state auditor's office .

finally , we contacted officials from five health plans to discuss their efforts to ensure the quality of the data submitted to states for rate setting .

we conducted our performance audit from october 2009 through july 2010 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

under medicaid managed care , states contract with health plans and prospectively pay the plans a fixed monthly rate per enrollee to provide or arrange for most health services .

these contracts are known as “risk” contracts because plans assume the risk for the cost of providing covered services .

states' processes for developing rates may vary in a number of ways , including the type and time frames of data they use as the basis for setting rates , referred to as the base - year data , and what approach they use to negotiate rates with health plans .

after rates are developed , an actuary certifies the rates as actuarially sound for a defined period of time , typically 1 year .

in order to receive federal funds for its managed care program , a state is required to submit its rate - setting methodology and rates to cms for review and approval .

this review , completed by cms regional office staff , is designed to ensure a state complies with federal regulatory requirements for setting actuarially sound rates .

cms published a final rule on june 14 , 2002 , outlining the agency's regulatory requirements for actuarially sound rates .

these requirements largely focus on the process states must use in setting rates .

for example , the regulations require states to document their rate - setting methodology and include an actuarial certification of rates .

in addition , the regulations include a requirement that when states use data from health plans as the basis for rates they must have plan executives certify the accuracy and completeness of their data .

the regulations do not include standards for the type , amount , or age of the data that states mayuse in setting rates .

the regulations also do not include standards for the reasonableness or adequacy of rates .

in the preamble to the final rule , cms noted that health plans were better able to determine the reasonableness and adequacy of rates when deciding whether to contr act with a state .

in july 2003 , cms finalized a detailed checklist that regional office staff could use when reviewing states' rate - setting submissions for compliance with the actuarial soundness requirements and that states and states' actuaries could use when developing rates .

the checklist includes citations to , and a description of , each regulatory requirement ; guidance on what constitutes state compliance with the requirement ; and spaces for the cms official to check whether each requirement was met and cite evidence from the state's submission for compliance with the requirement .

the checklist also provides guidance on the level of review that should occur for different types of rate changes .

when the state is developing a new rate , or using new actuarial techniques or data to change previously approved rates , the checklist indicates a full review should be done , which entails reviewing the state's submission for compliance with all of the requirements covered in the checklist .

for adjustments to rates that were previously approved as meeting the regulations , the checklist indicates a partial review should be done ; a partial review focuses on a few key requirements in the checklist , such as ensuring that the state has included a certification of rates from a qualified actuary .

as of june 2010 , cms was in the process of revising the checklist .

one of the planned changes was to emphasize the need for more complete encounter data because cms officials indicated that the agency has determined that encounter data that do not include pricing information are not sufficient for setting rates .

cms expects to complete the checklist revisions by november 2010 .

 ( see table 1 for a summary of the sections in cms's checklist. ) .

according to cms officials , the regional officials responsible for conducting rate - setting reviews may have a financial background , but are not actuaries .

officials also noted that cms's oact , which provides actuarial advice to other offices within cms , is generally not involved with medicaid rate - setting reviews .

however , they indicated that when the cms officials responsible for rate - setting reviews have concerns with a state's rate - setting methodology and cannot resolve those concerns with the state , they can contact oact to request an independent review .

cms's regulations require that actuarially sound rates be developed in accordance with generally accepted actuarial principles and practices .

there is no actuarial standard of practice ( asop ) that applies to actuarial work performed to comply with cms's regulations .

however , in 2005 , the american academy of actuaries published a practice note that provides nonbinding guidance on certifying medicaid managed care rates .

the practice note includes a proposed definition for “actuarial soundness,” as there was no other working definition of the term that would be relevant to the actuary's role in certifying medicaid managed care rates .

under the definition , rates are actuarially sound if , for the period of time covered by the certification , projected premiums provide for all “reasonable , appropriate , and attainable costs ; ” also under the definition , rates do not have to encompass all possible costs that any health plan might incur .

the note emphasizes that the definition only applies to the certification of medicaid managed care rates , and that it differs from the definition used when certifying a health plan's rates .

the practice note also provides information on the actuary's role in assessing the quality of data used to set rates and refers the actuary to the asop on data quality for further guidance .

the practice note explains that if the actuary is involved in developing the rate , then the actuary would consider all available data , including ffs data , medicaid managed care encounter data , and medicaid managed care financial reports and financial statements .

the actuary would typically compare data sources for reasonableness and check for material differences when determining the preferred source or sources for the base - year data .

the asop on data quality clarifies that while actuaries should generally review the data for reasonableness and consistency they are not required to audit the data .

the asop also explains that the accuracy and completeness of the data are the responsibility of those that provided them , namely the state or health plans .

cms has been inconsistent in its review of states' rate setting .

in the six cms regional offices we reviewed , cms had not reviewed one state's rate setting for compliance with the actuarial soundness requirements and had not conducted a full review for another .

we also identified a number of other inconsistencies in cms's review of states' compliance with the actuarial soundness requirements .

variation in cms regional offices' practices contributed to these inconsistencies in oversight .

in the six cms regional offices we reviewed , we found inconsistencies in cms's review of state's rate setting , including significant gaps in the agency's oversight of two states' compliance with the actuarial soundness requirements .

first , cms had not reviewed one state's ( tennessee ) rate setting for compliance with the actuarial soundness requirements or approved the state's rates .

in 2007 , tennessee began transitioning its managed care program , which included all of the state's approximately 1 million medicaid enrollees , to risk contracts that were subject to the actuarial soundness requirements .

since moving to risk contracts , the state submitted at least two actuarial reports to cms's atlanta regional office indicating the program change , but these documents did not trigger a cms review .

these reports did not include actuarial certifications , and tennessee officials confirmed that the state's rates had not been certified by an actuary , which is a regulatory requirement .

as a result , according to cms officials , tennessee received , and is continuing to receive , approximately $5 billion a year in federal funds for rates that we determined had not been certified by an actuary or assessed by cms for compliance with the requirements .

based on issues we raised during our review , cms determined that tennessee was not in compliance with the actuarial soundness requirements and , as of june 2010 , was working to bring the state into compliance .

second , while cms officials said that all states should have had a full review of rate setting after the actuarial soundness requirements became effective in august 2002 , it appeared that cms officials had not completed a full rate - setting review for nebraska .

cms had no documentation of its last full review of nebraska's rate setting , but officials believed that the last full review was completed in 2002 .

according to nebraska officials , the state last made significant changes to its rate setting for the state fiscal year beginning in 2001 , which according to criteria in cms's checklist would have triggered a full cms review .

based on what cms and nebraska officials told us , cms's last full review was likely done before the actuarial requirements became effective .

as a result , nebraska received federal funds for more than 7 years for rates that may not have been in compliance with all of the actuarial soundness requirements .

in addition to these gaps in oversight , we found inconsistencies in the reviews cms completed .

in instances when cms did a full rate - setting review , it was unclear whether cms consistently ensured that states met all of the actuarial soundness requirements .

we found evidence that the rates in all 28 of the cms files we reviewed were certified by a member of the american academy of actuaries , as is required by the regulations .

however , the extent to which cms ensured state compliance with other aspects of the actuarial soundness requirements — such as the requirement that rates be based only on services covered under the state's medicaid plan or costs related to providing these services — was unclear .

for example , in nearly a third of the files we reviewed , or 8 of 28 files , cms officials did not use the rate - setting checklist to document their review ; therefore we could not determine whether cms ensured that states were in compliance with all of the requirements .

in 17 of the 20 remaining files where the cms official used the checklist , the official cited evidence of the state's compliance for some requirements , but not others .

when officials did cite evidence , the evidence did not always appear to meet the requirements .

for example , one of the requirements in the regulations is that states provide an assurance that rates are based only on services covered under the state's medicaid plan or costs related to providing these services .

of the 19 files where cms officials cited evidence of such an assurance , we were unable to locate the assurance in 2 of the files .

another requirement is that states include a comparison of expenditures under the previous year's rates to those projected under the proposed rates .

in the 15 files where cms cited evidence of the comparison of expenditures , we did not find a comparison that appeared to meet the requirement in 2 of the files .

see table 2 for more information on the extent to which evidence was cited in the cms files we reviewed .

finally , cms did not consistently review states' rate setting for compliance with the actuarial soundness requirements prior to the new rates being implemented .

in 20 of 28 files we reviewed , we found that cms completed its review of rate setting after the state had begun implementing the proposed rates ; that is , after the effective date of the proposed rates .

cms officials told us that a variety of factors could delay the approval of rates , including states submitting a request for approval after implementing the rates .

cms officials further explained that they did not consider a state to be out of compliance with the actuarial soundness requirements until the end of the federal fiscal year quarter in which the state implemented the unapproved rates .

of the 20 files where cms approved rates after the state implemented them , 13 had rates that were approved more than 3 months after the state implemented the rates , which means that the rates were approved after the end of the quarter in which they were implemented .

cms officials confirmed that the agency generally continued to provide federal funds for the states' managed care contracts even in cases where the rates were not approved by the end of the quarter .

according to cms officials , if the state failed to gain cms approval or had to lower the rates to achieve approval , then cms would reduce future federal reimbursement to account for federal funds paid to states for rates that had not been approved .

however , cms reviewing states' rate setting after states have begun implementing rates may result in changes to states' rate - setting methodology ; this could lead to retroactive changes , including reductions , in health plans' rates .

the possibility of rates being decreased retroactively may make it difficult for health plans to assess the reasonableness and adequacy of rates when contracting with states , an assessment that cms relies on as a check of states' rate setting .

variation in a number of regional office practices contributed to the inconsistency in cms's oversight of states' rate setting .

regional offices varied in the extent to which they tracked state compliance with the requirements , the extent to which they withheld federal funds , their criteria for doing full and partial reviews of rate setting , and what they considered to be sufficient evidence for meeting the requirements .

tracking compliance .

officials from all of the regional offices we spoke with told us that they tracked basic information regarding the status of the cms review process , such as when a state's submission was received and when cms's approval letter was issued .

however , based on our interviews with cms regional officials , we found that four of the six regional offices did not track information that would allow them to identify states that were not in compliance with actuarial soundness requirements , such as the beginning and end dates of the rates specified by the actuary in the certification .

officials from the remaining two regional offices , kansas city and san francisco , told us they tracked the effective dates of approved rates .

withholding funds .

there was also variation among regional offices in the conditions that had to be met in order for states to receive federal funds .

for example , officials from the san francisco regional office told us that they did not release federal funds to states until the states' managed care contract and rates had been approved .

officials said that the office had withheld funds in several cases until the state demonstrated compliance with the requirements .

for example , from october 2008 through april 2010 , the san francisco regional office reported withholding a total of $302.7 million in federal funding for hawaii because the state's contracts and rates did not meet the actuarial soundness requirements .

in contrast , officials we interviewed from the atlanta regional office said that the office would release federal funds to a state even if the state's rates had not yet been approved by cms .

criteria for full and partial reviews .

cms regional officials had different interpretations of when full versus partial reviews of rate setting were necessary .

for example , officials from the new york regional office told us that they completed a full review for each rate - setting submission received , regardless of the changes made to rates or rate setting .

in contrast , a kansas city regional office official told us that she completed a partial review in cases where the state adjusted the rates but had not changed the data used as the basis for rates .

sufficient evidence for compliance .

regional office officials varied in how they determined sufficient evidence for state compliance with certain requirements .

for example , for the requirement that rates are for medicaid - eligible individuals covered under the contract , officials from the san francisco regional office told us that , while they had verified information provided by states on the populations covered under the rates , they mainly looked for an assurance from the state that rates were for eligible populations .

in contrast , a kansas city regional office official explained that an assurance from the state alone would not be sufficient .

rather , the official would require evidence of the eligible populations included in , and excluded from , the rate - setting methodology .

other variations .

variations in other regional office practices may also have contributed to the inconsistency in cms oversight .

for example , management oversight of rate - setting reviews in regional offices varied .

a kansas city regional official who reviews states' rate setting told us that , prior to approving states' rates , she submitted memoranda outlining the impact of states' proposed rate changes and the rationale for recommending approval of the package to her regional office managers .

in contrast , officials from the new york regional office told us that most officials responsible for reviewing and approving states' rate setting worked independently and managers did not review a completed checklist .

other variations in practices that may have had an effect on cms oversight included differences in training and standard procedures for conducting and documenting reviews .

as a result of our review , cms took a number of steps that may address some of the variation in regional office practices .

for example: officials from two regional offices told us that their offices were implementing new standard procedures to address inconsistencies in reviews identified through the course of gao's work ; and in december 2009 , cms began requiring that regional offices use the checklist in reviewing all states' rate - setting submissions and assure central office of its use before approving a state's rates .

however , as we reported above , variations existed even when the checklist was used , such as in the extent to which cms officials using the checklist cited evidence of compliance for each of the actuarial soundness requirements .

cms's efforts to ensure the quality of the data used to set rates were generally limited to requiring assurances from states and health plans , which did not provide the agency with sufficient information to ensure data quality .

cms regulations require states to describe the data used as the basis for rates and provide assurances from their actuaries that the data were appropriate for rate setting .

the regulations also specify that states using data submitted by the health plans as the basis for rates must require executives from the health plans to attest that the data are accurate , complete , and truthful .

the regulations do not include requirements for the type , amount , or age of data or standards for the reasonableness or adequacy of rates .

additionally , cms does not require states to submit documentation about the quality of the data used to set rates .

in our interviews with regional office officials , we found that , when reviewing states' descriptions of the data used for rate setting , cms officials focused primarily on ensuring the appropriateness of the data used by states to set rates rather than their reliability .

this included reviewing the specific services and populations included in the base - year data or checking for assurances of appropriateness from the states' actuaries .

cms officials noted that if they had concerns with the quality of a state's data they would ask the state questions .

none of the officials , however , reported taking any action beyond asking questions .

with limited information on the quality of data used to set rates , cms cannot ensure that states' managed care rates are appropriate and risks misspending billions of federal and state dollars .

actuarial certification does not ensure that the data used to set rates are reliable .

in particular , 9 of the 28 files we reviewed included a disclaimer in the actuary's certification that if the data used were incomplete or inaccurate then the rates would need to be revised .

additionally , in more than half of the 28 files we reviewed , the actuaries noted that they did not audit or independently verify the data and relied on the state or health plans to ensure that the data were accurate and complete .

officials from three of the five health plans we spoke with raised concerns about the completeness of the encounter data used by states to set rates .

additionally , state auditors in washington have raised concerns about the lack of monitoring of the accuracy of data used for rate setting .

the auditors found that the state did not verify the accuracy of the data used as the basis for medicaid managed care rates in fiscal years 2003 through 2007 .

the state auditor's report from fiscal year 2007 concluded that the risk of paying health plans inflated rates increased when the accuracy of data used to establish rates could not be reasonably assumed to be correct .

states have information on the quality of data used for rate setting — information that cms could obtain .

state officials we spoke with reported having information on , and efforts intended to ensure , the quality of the data used to set rates .

for example , new jersey officials told us that the state tested the reliability and accuracy of the health plan financial data used to set rates against encounter data and required health plans to have an independent auditor review selected portions of the financial data .

additionally , arizona officials indicated that the state periodically completes validation studies of the state's encounter data in which they traced a sample of the encounters back to individuals' medical records .

state officials indicated that cms used to require the state to submit results of these studies as a condition of operating its managed care program .

however , given the state's extensive experience with managed care , cms no longer requires the state to submit these studies for all participating health plans .

 ( see app .

iii for a summary of selected states' efforts intended to ensure data quality. ) .

without requiring and reviewing information on states' data quality efforts , cms cannot ensure that these data are of sufficient quality to be used for setting rates .

in addition to information from states , cms conducts audits that could have provided cms officials relevant information about the quality of the data used to set rates .

for example , when describing the state's efforts to ensure the quality of data used to set rates , officials from south carolina noted that cms periodically reviews the state's ffs data through the payment error rate measurement ( perm ) program .

error rates calculated using ffs and encounter data through the perm program could provide cms with insights regarding the quality of the data that some states use to set rates .

in cms's rate - setting review file for south carolina , however , there was no discussion of perm results by either the state or cms .

cms central office officials confirmed that regional office staff do not consider the results of data studies , such as state validation or perm program reports , when reviewing states' rate - setting submissions .

cms also could have conducted or required periodic audits of the data used to set rates .

in medicare advantage , which is medicare's managed care program , cms is required to conduct annual audits of the financial records of at least one - third of the organizations participating in the program .

for medicaid , however , cms had not conducted any recent audits or studies of states' rate setting , including the quality of data used .

specifically , officials in all six of the regional offices we spoke with told us that they had not performed any audits or special studies of states' rate setting .

officials from cms's central office were also not aware of any recent audits or studies done by the four other regional offices .

in addition , officials from cms's central office told us that they could only recall one instance , in the nearly 8 years since the regulations were issued , where oact arranged for an independent assessment of a state's rate setting ; that assessment was done more than 2 years ago .

the statutory and regulatory requirements for actuarially sound rates are key safeguards in efforts to ensure that federal spending for medicaid managed care programs is appropriate , which could help avoid significant overpayments and reduce incentives to underserve or deny enrollees' access to needed care .

cms , however , has been inconsistent in ensuring that states are complying with the actuarial soundness requirements and does not have sufficient efforts in place to ensure that states are using reliable data to set rates .

during the course of our work , cms took steps to address some of the variation in regional office practices that contributed to inconsistencies in overseeing state compliance , such as requiring regional office officials to use the checklist in reviewing all states' rate - setting submissions .

while these are positive steps , they do not address all of the variations in regional office practices that contributed to inconsistencies in cms's oversight of rate setting .

for example , these steps do not address variations in tracking state compliance , which may have led to cms's failure to review tennessee's rates for compliance with the actuarial soundness requirements .

additionally , the steps taken do not address the variation in what evidence cms officials considered sufficient for compliance , how officials used the checklist to document their reviews , and what conditions were necessary for federal funds to be released .

cms also does not have sufficient efforts in place to ensure the quality of the data states used to set rates , relying on assurances from states without considering any other available information on the quality of the data used .

by relying on assurances alone , the agency risks reimbursing states for rates that may be inflated or inadequate .

as a result of the weaknesses in cms's oversight , billions of dollars in federal funds were paid to one state for rates that were not certified by an actuary , and billions more may be at risk of being paid to other states for rates that are not in compliance with the actuarial soundness requirements or are based on inappropriate and unreliable data .

given the complexity of overseeing states' unique and varied medicaid programs , it is appropriate that cms would allow for flexibility in states' rate setting and would expect states to have the primary responsibility for ensuring the quality of the data used to set rates .

however , cms needs to ensure that all states' rate setting complies with all of the actuarial soundness requirements and needs to have safeguards in place to ensure that states' data quality efforts are sufficient .

improvements to cms's oversight of states' rate setting will become increasingly important as coverage under medicaid expands to new populations for which states may not have experience serving , and may have no data on which to base rates .

to improve oversight of states' medicaid managed care rate setting , we recommend that the administrator of cms take three actions .

to improve consistency in the oversight of states' compliance with the medicaid managed care actuarial soundness requirements , we recommend that the administrator of cms: implement a mechanism for tracking state compliance , including tracking the effective dates of approved rates ; and clarify guidance for cms officials on conducting rate - setting reviews .

areas for clarification could include identifying what evidence is sufficient to demonstrate state compliance with the requirements , the conditions necessary for federal funds to be released , and how officials should document their reviews .

to better ensure the quality of the data states use in setting medicaid managed care rates , we recommend that the administrator of cms make use of information on data quality in overseeing states' rate setting .

cms could , among other things , require states to provide cms with a description of the actions taken to ensure the quality of the data used in setting rates and the results of those actions ; consider relevant audits and studies of data quality done by others when reviewing rate setting ; and conduct or require periodic audits or studies of the data states use to set rates .

we provided a draft of this report to hhs for its review and comment .

hhs concurred with all three of our recommendations , and commented that it appreciated our efforts to highlight improvements that cms can make in its oversight of states' compliance with medicaid managed care actuarial soundness requirements , as well as its focus on the quality of data used to set managed care rates .

moreover , hhs noted that cms has identified many of the same issues .

 ( see app .

iv for a copy of hhs's comments. ) .

hhs agreed with our two recommendations related to improving the consistency of cms's oversight , namely that cms implement a mechanism for tracking state compliance with the actuarial soundness requirements and clarify guidance for cms officials on conducting rate - setting reviews .

hhs noted that cms has established a managed care oversight team to develop and implement a number of improvements in its managed care oversight , some of which will address our recommendations .

these improvements included cms's plans to develop standard operating protocols for the review and approval of medicaid managed care rates and provide comprehensive training to cms staff on all aspects of the new process and requirements .

as cms implements efforts aimed at improving its oversight , we reiterate the need to implement a mechanism for tracking state compliance with actuarial soundness requirements , including the effective dates of rates .

hhs also agreed with our recommendation that cms make use of information on data quality in overseeing states' rate setting .

in commenting on our finding related to cms's limited efforts to ensure data quality , hhs noted that a number of requirements within ppaca will give cms additional authority and responsibility for acquiring and utilizing medicaid program data .

in response to our recommendation , hhs noted that , as part of a broader effort to redesign how it collects medicaid data , cms will be setting standards for the type and frequency of managed care data submissions by states .

hhs commented that with more complete data at its disposal , cms will be able to better assess the underlying quality of data submissions and , thus , better execute its oversight and monitoring responsibilities .

cms should use these assessments and other available information when overseeing states' rate setting .

finally , hhs provided technical comments , which we incorporated as appropriate .

we are sending copies of this report to the administrator of cms and other interested parties .

in addition , the report is available at no charge on the gao web site at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-7114 or yocomc@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix v .

to assess the centers for medicare & medicaid services's ( cms ) oversight of states' compliance with the medicaid managed care actuarial soundness requirements , we conducted a structured review of cms files from 6 of the 10 cms regional offices .

we selected cms regional offices that: represented at least 5 of the 10 cms regional offices , collectively had oversight responsibility for at least 65 percent of the 34 states with comprehensive medicaid managed care programs , and were geographically diverse and oversaw states with medicaid managed care programs ranging in size .

the six regional offices that we selected for our review had oversight responsibility for 26 of the 34 states ( or 76 percent ) with comprehensive medicaid managed care programs .

according to information from cms , these 26 states accounted for about 85 percent of medicaid managed care enrollment nationally in 2008 and state program size ranged from 8 percent of medicaid enrollees in illinois to 100 percent in tennessee .

 ( see table 3. ) .

we conducted a structured review of a selection of files from the six cms regional offices .

specifically , we reviewed the files for cms's rate - setting reviews of the most recently approved contract for each state's comprehensive managed care program , or , for states with multiyear contracts , the file for the most recent full review of rate setting completed as of october 31 , 2009 .

several states in the selected regions had multiple comprehensive managed care programs that had separate contracts and rate - setting processes each subject to cms review and approval .

for states that had two programs , we selected the file for the program cms officials indicated was the largest , as defined by the number of enrollees and estimated expenditures .

for the states that had more than two programs , we selected the files for the two largest programs .

for 2 of the 26 states overseen by the six regional offices ( nebraska and tennessee ) , cms had not done a review that met our criteria , so we did not review a file for those states .

in total , we reviewed 28 files , which covered 24 states , 4 of which had two or more programs for which cms did separate reviews .

 ( see table 4. ) .

as part of our file review , we assessed the degree to which cms documented its review .

specifically , we determined whether the cms official completed cms's checklist — a tool cms developed for regional office staff to use when reviewing states' rate - setting submissions for compliance with the actuarial soundness requirements .

for those files where the cms official did not complete the checklist and provided no other documentation of the review , we did no further assessment of cms's review .

for the files where the cms official completed the checklist , we assessed the extent to which cms ensured that the state complied with the actuarial soundness requirements .

to do this , we identified several requirements of the regulations , including that rates were certified by a qualified actuary , that rates were based on covered services for eligible individuals , and that the state documented any adjustments to the base year data .

for these requirements , we assessed whether ( 1 ) cms documented that the state met the requirement , ( 2 ) cms cited evidence for the assessment that the state was in compliance , and ( 3 ) the cited evidence was consistent with the guidance in cms's checklist .

additionally , as part of our review , we summarized descriptive elements of states' rate setting and rates .

for example , we documented the types of data used as the basis for rates and how the state's rates changed from the prior year .

to ensure the accuracy of the information collected as part of our structured review of the files , we conducted independent verifications of each review .

to describe state views of the centers for medicare & medicaid services's ( cms ) oversight of state compliance with the medicaid managed care actuarial soundness requirements and state efforts to ensure the quality of the data used to set rates , we selected 11 of the 34 states with comprehensive medicaid managed care programs and interviewed officials from those states' programs .

we selected states that: varied in the size of their medicaid managed care programs , as defined by the numbers of managed care enrollees , the proportion of states' medicaid population that were in managed care , and the number of mcos participating in the program ; and overlapped with the oversight responsibilities of the six selected cms regional offices .

table 5 provides information about the selected states .

the 11 states we interviewed used a combination of approaches intended to ensure the quality of the data used in medicaid managed care rate setting .

these included front - end efforts intended to prevent errors in data reported by providers and health plans , reconciliation methods to help ensure the reliability and appropriateness of reported data , and in - depth reviews that identified and addressed issues of ongoing concern .

see table 6 for a summary of the selected states' efforts intended to ensure data quality .

in addition to the contact named above , michelle rosenberg , assistant director ; joseph applebaum , chief actuary ; susan barnidge ; william a. crafton ; drew long ; kevin milne ; and dawn d. nelson made key contributions to this report .

