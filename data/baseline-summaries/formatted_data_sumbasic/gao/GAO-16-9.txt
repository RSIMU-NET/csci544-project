the hospital value - based purchasing ( hvbp ) program , which was created in 2010 by the patient protection and affordable care act ( ppaca ) , adjusts medicare payments to hospitals based on a formula that takes into account each hospital's performance on a designated set of quality measures .

prior to the hvbp program , hospitals had received slightly higher medicare payments for submitting data for quality measurement and public reporting under the centers for medicare & medicaid services' ( cms ) inpatient quality reporting ( iqr ) program .

beginning in fiscal year 2013 , the hvbp program provided new bonuses and penalties that were based on each hospital's performance on a subset of those iqr measures .

the hvbp program represents just one example from a range of efforts initiated under ppaca to induce providers to improve their quality of care and become more cost efficient .

some initiatives , like the hvbp program and medicare's hospital readmission reduction program , which establishes financial penalties for hospitals with higher readmission rates , aim to improve hospital quality and efficiency by increasing or decreasing medicare's traditional fee - for - service payments to hospitals .

these initiatives are distinct from “alternative payment models” that aim to improve quality and efficiency by creating a shared stake among different types of providers by giving them a combined payment for all their services .

at the same time that cms is implementing modifications to fee - for - service payments , like the hvbp program , it is also expected to dramatically expand the scope of these alternative payment models across the full range of medicare services .

as policy makers consider how best to pursue these various options , a key question is the extent to which the hvbp program has demonstrated a capacity to improve health care quality and cost efficiency .

the same section of ppaca that created the hvbp program included a provision for us to assess the impact of the hvbp program on medicare quality and expenditures , including the quality of care among small rural , small urban , and safety net hospitals , which are hospitals that provide a significant amount of care to the poor .

the provision called for an interim report to be issued by october 1 , 2015 , and a final report by july 1 , 2017 .

this interim report examines how the additional financial incentive created under hvbp may have affected hospitals' quality of care as well as their efforts to improve quality in the first years of the program's implementation from fiscal year 2013 through fiscal year 2015 , including the effects of the program on small rural , small urban , and safety net hospitals .

this report addresses three questions: 1 .

what initial effects have been observed from the hvbp program on medicare payments to hospitals ? .

2 .

what initial effects have been observed from the hvbp program on the quality of care provided by hospitals ? .

3 .

what initial effect did the hvbp program have on selected hospitals' quality improvement efforts ? .

to determine the initial effects observed from the hvbp program on medicare payments to hospitals , we analyzed data provided by cms on the bonuses and penalties awarded to each of the approximately 3,000 hvbp - eligible hospitals from fiscal year 2013 through fiscal year 2015 .

we analyzed these data for hospitals overall as well as for small urban , small rural , and safety net hospitals .

to do so , we identified small urban and small rural hospitals as those having 100 acute care beds or fewer , using data from the american hospital association survey and cms's determination about hospitals' rural or urban classification .

we identified safety net hospitals using cms data on hospitals' medicare disproportionate patient percentage — a measure of medicaid and low - income medicare patients — and hospitals' proportion of uncompensated care , which we obtained from annual medicare cost reports .

we ranked hvbp - eligible hospitals on both measures and identified as safety net hospitals those hospitals that were in the top 10 percent when summing the rankings of both the disproportionate patient percentage and uncompensated care measures .

in addition , we examined how these scores related to various hospital characteristics , such as a hospital's net income as reported on medicare cost reports .

we reviewed related documentation and interviewed knowledgeable cms and american hospital association officials , and we determined that these data on bonuses and penalties and hospital characteristics were sufficiently reliable for our purposes .

to determine the initial effects observed from the hvbp program on the quality of care provided by hospitals , we analyzed data on quality measures collected by cms between 2005 and 2014 ( the most recent available ) as part of the iqr program for the approximately 3,000 hvbp - eligible hospitals .

this analysis included both iqr quality measures that were used in the hvbp payment formula and other iqr measures not included in the hvbp program , such as measures of hospital readmissions .

we conducted this analysis for all iqr measures related to inpatient care for which we obtained a sufficient number of data points both before and after the implementation of the hvbp program .

 ( see appendix i for a listing of these measures. ) .

the quality measures we analyzed cover hospital performance on clinical processes to provide care , patients' experiences in receiving care , and outcomes associated with patient care .

cms provided the clinical process and patient outcomes data .

we obtained the patient experience data from the hospital compare website , where cms publicly reports individual hospital performance on the iqr measures .

cms officials provided us supplementary information that allowed us to determine the time period of patient care for which each set of patient experience applied , as well as comparable dates for the patient outcome data on mortality and readmissions that we obtained from cms .

however , cms was not able to provide us with one quarter of patient experience data that was not available from the hospital compare website .

to identify any patterns that may be related to the hvbp program , we looked at the median hospital score of each measure during every period for which data were reported to cms , both before and after the hvbp program began .

we analyzed the results of quality measures for hospitals overall as well as for small urban , small rural , and safety net hospitals .

we compared the median scores of small urban , small rural , and safety net hospitals to those of hospitals overall to assess the relative performance of those hospital subgroups .

we reviewed related documentation , interviewed knowledgeable cms officials , and determined that these data were sufficiently reliable for our purposes .

to determine the initial effects of the hvbp program on the quality improvement efforts of selected hospitals , we interviewed 20 officials from eight different hospitals .

our interviews included officials from two small urban hospitals , two small rural hospitals , two safety net hospitals , and two hospitals that were not part of any of these categories .

within each category , we selected one hospital that experienced a relatively large penalty in the first year of the hvbp program and then improved its performance to receive a bonus in at least one subsequent year , and a second hospital that experienced a relatively large penalty in the first year of the hvbp program and then did not improve its performance to receive a bonus in either subsequent year .

because these hospitals were not selected randomly , they do not constitute a representative sample of hospitals participating in the hvbp program .

therefore , the information obtained from these interviews applies solely to this set of hospitals , and cannot be generalized to other hospitals .

we conducted this performance audit from december 2014 to october 2015 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

the hvbp program affects medicare payments to approximately 3,000 acute care hospitals for the inpatient services provided to medicare beneficiaries .

hospitals are included in the hvbp program if they are paid through medicare's inpatient prospective payment system .

thus , hospitals not paid through this system , such as critical access hospitals , are not subject to payment adjustments by the hvbp program .

by law , the hvbp program is budget neutral , which means that the total amount of payment increases , or bonuses , that it awards to hospitals deemed to provide higher quality of care must equal the total amount of payment reductions , or penalties , applied to hospitals deemed to provide lower quality of care .

to accomplish this , cms calculates each hospital's payment adjustment percentage by applying a fixed percentage decrease , and then adding back percentage increases based on the hospital's assessed quality performance in prior years .

as specified in ppaca , the initial percentage reduction grew from 1.0 to 1.5 percent from fiscal year 2013 to fiscal year 2015 , and will reach a maximum of 2 percent in fiscal year 2017 .

the percentage increases added back are based on a hospital's performance on each quality measure included in the hvbp payment formula .

for each of these hvbp quality measures , cms considers both the results of a hospital's absolute performance and the changes in its performance over time , and then counts the better result toward the hospital's quality score .

the total quality score is derived from a hospital's performance on all the hvbp quality measures .

if a hospital obtains a percentage increase or supplement from its hvbp total quality score that exceeds the initial percentage reduction , it receives a net increase , or bonus , from hvbp for that year .

if the increase from its total quality score is smaller than the initial reduction , the hospital receives a net decrease , or penalty , in payments compared to what it otherwise would have received without the hvbp program .

the hvbp quality measures are distributed across several different performance categories — known as domains — that comprise a set of related quality measures .

the number of domains included in the formula has grown from two ( clinical process and patient experience measures ) in fiscal year 2013 to four ( adding patient outcomes and efficiency to the original two ) .

each domain consists of multiple quality measures , except for efficiency which consists solely of the medicare spending per beneficiary measure .

across all of the domains , the number of measures included in the hvbp payment formula has grown from 20 in fiscal year 2013 to 26 in fiscal year 2015 .

before quality measures can be added to the hvbp formula , they must first have been publicly reported under the iqr program for at least one year .

cms makes adjustments each year — usually providing several years notice — to the measures to be included in the hvbp payment formula in future years and to the relative weights applied to the quality domains in calculating each hospital's total quality score .

for example , in fiscal year 2013 , 70 percent of the total quality score was based on clinical process measures .

in fiscal year 2015 , clinical process measures represented 20 percent of the total score .

 ( see appendix ii for a list of all the iqr measures included in the hvbp program. ) .

once cms calculates a hospital's performance across all of the domains and subsequently determines its corresponding bonus or penalty , the inpatient medicare payment for each discharged patient is adjusted up or down throughout the fiscal year based on the size of the hospital's bonus or penalty .

 ( for two hypothetical examples , see fig .

1. ) .

only a portion of the total medicare payment is affected , however .

for example , the hvbp bonus or penalty does not alter certain add - on payments , such as those that compensate hospitals for serving a disproportionate share of low - income patients or for providing medical education .

as a result , hospitals caring for large proportions of low - income medicare or medicaid patients and major teaching hospitals have a lower proportion of their total medicare payments affected by their hvbp bonus or penalty , compared to other hospitals that do not receive these add - on payments .

most hospitals received a bonus or penalty from the hvbp program of less than 0.5 percent of applicable medicare payments in each of the first three years of the program .

small hospitals and hospitals with better financial performance generally had higher payment adjustments , that is , larger bonuses or smaller penalties .

among the subgroups we analyzed , we found that safety net hospitals received lower payment adjustments compared to hospitals overall , but the gap narrowed over time .

small rural and small urban hospitals had similar or better results than hospitals overall .

in each of the hvbp program's first three years , a large majority of hospitals — between 74 percent and 93 percent — received a bonus or penalty of less than 0.5 percent .

 ( see fig .

2. ) .

roughly the same number of hospitals received bonuses and penalties , with more bonuses awarded in fiscal year 2013 and fiscal year 2015 , and more penalties awarded in fiscal year 2014 .

the amount of the annual median bonuses and median penalties increased slightly each year .

the median bonus in 2015 was 0.32 percent of applicable medicare payments and the median penalty was 0.26 percent .

 ( see table 1. ) .

in dollar terms , most of these annual bonuses or penalties were less than $50,000 .

for example , in fiscal year 2015 , 52 percent of hospitals received bonuses or penalties that led to payment adjustments of less than $50,000 , and 72 percent of hospitals had payment adjustments of less than $100,000 .

the size of bonuses or penalties , when measured in dollars , is a function of both the percentage bonus or penalty and the total amount of applicable medicare payments a hospital is owed .

in the aggregate , the hvbp program redistributed about $140 million dollars from hospitals that received penalties to hospitals that received bonuses in 2015 .

we found that smaller hospitals generally had higher payment adjustments — that is , larger bonuses or smaller penalties — than larger hospitals in the hvpb program's first three years .

specifically , hospitals with 60 beds or fewer had the highest median payment adjustments in fiscal years 2013 and 2015 , from among the five different hospital size categories ( by number of beds ) that we analyzed .

in fiscal year 2015 , the overall median payment adjustment for hospitals with 60 beds or fewer was a bonus of 0.38 percent .

in contrast , hospitals in the categories with the largest number of beds — those encompassing 201 to 350 beds and more than 350 beds — had the lowest median payment adjustments in fiscal year 2015 .

 ( hospitals with more than 350 beds also had the lowest median payment adjustments in fiscal year 2013 , but the differences among several of the categories were small. ) .

see appendix iii for the results of our analysis of hospital bed size categories .

in addition , we found that hospitals with better financial performance , as measured by net income , generally had higher payment adjustments under the hvbp program .

in each of the hvbp program's first three years , hospitals with the highest net income had higher payment adjustments than hospitals with negative net income .

hospitals with net income of more than 5.0 percent received the highest median bonuses from among the seven net income categories that we analyzed .

 ( see appendix iv. ) .

hospitals with lowest net income from among the categories we analyzed — negative margins of greater than - 5.0 — had among the lowest median payment adjustments in the hvbp program in fiscal years 2013 and 2014 .

however , the pattern for this group of hospitals with the lowest net income did not continue for fiscal year 2015 , as these hospitals had median payment adjustments that were higher than those of hospitals in some other net income categories .

safety net hospitals consistently had lower median payment adjustments — that is , smaller bonuses or larger penalties — than hospitals overall .

these adjustments ranged between .07 and .12 percentage points lower in the program's first three years , with the smallest gap coming in fiscal year 2015 .

 ( see table 2. ) .

safety net hospitals exceeded hospitals overall in scores for efficiency but had lower scores each year for the other three hvbp domains .

 ( see appendix v. ) therefore , one reason why the gap narrowed in fiscal year 2015 was the addition of the efficiency domain to the hvbp formula in that year .

in contrast , small urban hospitals had higher median payment adjustments — that is , larger bonuses or smaller penalties — than hospitals overall during the program's first three years .

the greatest difference was in fiscal year 2015 , when small urban hospitals had a median payment adjustment 0.22 percentage points higher than hospitals overall .

small urban hospitals had generally higher scores across each of the hvbp program's performance domains compared to hospitals overall in all three years , with the exception of the patient outcomes domain in fiscal year 2014 .

compared to safety net and small urban hospitals , small rural hospitals' median payment adjustments more closely mirrored those of hospitals overall .

in two of the program's first three years , the median payment adjustment for small rural hospitals was within 0.02 percentage points of the median for all hospitals , before increasing relative to hospitals overall in fiscal year 2015 .

small rural hospitals generally had higher median scores on the patient experience and cost efficiency domains than hospitals overall and had lower median scores on the clinical processes and patient outcomes domains .

as with hospitals overall , most safety net , small urban , and small rural hospitals received bonuses or penalties of less than 0.5 percent in each of the program's first three years .

 ( see appendix vi. ) .

however , the proportion of these hospitals with bonuses or penalties of less than 0.5 percent was generally lower than for hospitals overall , with the largest differences in fiscal year 2015 .

for example , 59 percent of small urban hospitals received payment adjustments of less than 0.5 percent in fiscal year 2015 — compared to 74 percent for hospitals overall .

in the same year , about 36 percent of small urban hospitals received bonuses of 0.5 percent or greater , compared to 18 percent of hospitals overall .

our analysis found no apparent shift in hvbp quality measure trends during the initial years of the program , but such shifts could emerge over time as the program implements planned changes .

the same pattern held for most quality measures not included in the hvbp program .

the exception was readmissions , where the performance of the same group of hospitals showed a clear shift in trend towards improvement during the initial years of the hvbp program .

while the hvbp program aims to provide an incentive to improve hospitals' quality of care , preliminary analysis of information from 2013 and 2014 — the two years of quality measure results after the program's implementation that were available at the time of our analysis — shows that it did not noticeably alter the existing trends in hospitals' performance on any of the quality measures used to determine hvbp payment adjustments that we examined .

this lack of apparent change applied to all of the clinical process , patient experience , and outcomes measures included in the program's payment formula that had sufficient available data points for us to assess .

in general , trends observed for each measure before the hvbp program took effect in october 2012 remained largely unchanged after the program's implementation , as shown by changes over time in the median hospital quality score for each measure .

on clinical process measures , hospitals showed improvement that began before implementation of the hvbp program .

these measures assess the extent to which hospitals correctly follow certain well - accepted processes to treat patients , for example by selecting an appropriate initial antibiotic for a pneumonia patient .

the median scores for all of these clinical process measures increased prior to the implementation of the hvbp program .

 ( see fig .

3. ) .

as a result , by the start of the hvbp program in october 2012 , the median scores for all clinical process measures included in the program were already at or close to 100 percent , indicating that hospitals consistently followed these treatment procedures before the beginning of the hvbp program , and so there was limited opportunity for hospitals to improve on these measures after the program was implemented .

as previously noted , cms officials have adjusted the hvbp formula so that the weight given to clinical process measures has decreased over time , from 70 percent in 2013 to 20 percent in 2015 , with an additional decrease to 5 percent by 2017 .

for patient experience measures — on which , unlike clinical process measures , hospital scores were not at nor close to 100 percent — hospitals showed steady , incremental improvement on the measures both before and after implementation of the hvbp program .

these measures reflect the responses of hospital patients to survey questions about the quality of their hospital experience , such as how well their pain was controlled .

for each of the hvbp patient experience measures , the median hospital score trended steadily upward or , in a few cases , remained the same from one reporting period to the next , with no substantial shift that coincided with the start of the hvbp program in october 2012 .

 ( see fig .

4. ) .

on the three hvbp patient outcomes measures we analyzed — each of which measures patient mortality that may be related to hospital quality — the overall trends were mixed , but remained largely consistent both before and after implementation of the hvbp program .

hospitals showed steady improvement ( i.e. , a decrease ) in the rate of mortality due to heart attack , both before and after hvbp program implementation .

on the other hand , rates of mortality due to heart failure and pneumonia stayed roughly constant over the same time period , increasing slightly prior to the implementation of hvbp and then possibly leveling off .

 ( see fig .

5. ) .

all three mortality measures — heart attack , heart failure , and pneumonia — use information from medicare claims data to track patient mortality within 30 days of a hospital admission and risk adjust the results based on patient characteristics .

small rural , small urban , and safety net hospitals sometimes performed better or worse than hospitals overall on one hvbp quality measure or another across the three domains , but these differences in relative performance did not change noticeably with the implementation of the hvbp program .

we found a generally consistent pattern in which , for each of these individual measures , any difference in performance between hospitals in the subgroup and hospitals overall during the period before the program either disappeared by the time the program took effect or remained relatively constant in the following time period .

on clinical process measures included in the hvbp program , small rural , small urban , and safety net hospitals generally matched hospitals overall with very high performance before hvbp was implemented .

on patient experience measures included in the hvbp program , small rural and small urban hospitals performed slightly better than hospitals overall — both before and after its implementation — while safety net hospitals performed slightly worse .

on patient outcomes measures included in the hvbp program , small urban hospitals generally matched the performance of hospitals overall , both before and after its implementation , while safety net hospitals ( on the measures for heart attack and pneumonia mortality ) and small rural hospitals ( on all three mortality measures ) performed slightly worse .

these trends in the hvbp quality measures reflect the relatively short period of time after the program was implemented in october 2012 , which leaves open the possibility that more noticeable changes could emerge over a longer period of time .

such shifts in quality trends may develop slowly for two reasons .

first , hospitals may take time to implement their responses to the program , and these responses , once implemented , may take additional time to achieve results .

second , the hvbp program has evolved substantially over time and will continue to do so , and therefore its effects on quality may also be different .

for example , the amount of medicare payments at risk will increase from 1.0 percent in fiscal year 2013 to 2.0 percent in fiscal year 2017 and after .

in addition , new quality measures are being added to the program , and the quality measure domains have increased from two to four , with a fifth — safety — due to be added to the hvbp formula in fiscal year 2017 .

moreover , the weights attached to those domains , and therefore the relative effect each domain has on a hospital's total quality score , have also shifted substantially .

that is particularly true of the clinical process domain , on which hospitals did not have much room for improvement , as most hospitals already received scores at or close to 100 percent before the hvbp program was implemented .

as we previously noted , this domain will drop from 70 percent of the total quality score in fiscal year 2013 to 5 percent in fiscal year 2017 .

with more quality data collected over a longer period of time following the implementation of the hvbp program , it may be possible to detect more subtle and delayed effects of the program .

most of the iqr quality measures we examined that were not included in the hvbp program had trends that were similar to those in the program .

specifically , trends for non - hvbp clinical process measures were very similar to trends for hvbp clinical process measures , in that hospitals had improved on these measures and reached a high level prior to the start of the hvbp program .

 ( see fig .

6. ) .

in addition , the one iqr patient experience measure not incorporated into the hvbp program , a measure indicating whether patients would recommend the hospital , exhibited a trend very similar to that of the hvbp patient experience measures shown earlier in fig .

4 .

the other non - hvbp measures that we examined were the 30-day hospital readmissions rates for heart attack , heart failure , and pneumonia ; on all three measures , hospitals showed a different pattern — a clear initial shift in trend toward improved quality in the period leading up to the implementation of the hvbp program .

these three measures track the percentage of patients with each condition that are readmitted to a hospital within 30 days after being discharged .

such readmissions may be an indication that patients' recoveries from their initial hospitalizations were incomplete or that patients received inadequate care after their discharges .

readmissions for all three conditions remained largely unchanged from year to year through the end of 2009 ; afterwards , each declined noticeably around 2010 and continued to decline over the next two years .

 ( see fig .

7. ) .

the three non - hvbp readmission measures are targeted by the separate hospital readmissions reduction program .

some analysts who have reviewed this program noted that this initial shift in trend toward higher quality on these measures took place after the law that established the readmissions reduction program , ppaca , was passed in 2010 .

they noted that hospitals had an opportunity to implement strategies to reduce their readmissions before the program began to impose its penalties in october 2012 .

while the hospital readmissions reduction program took effect at the same time as the hvbp program , the difference in the observed trend for the measures targeted by the readmissions program , compared to the hvbp program , may in part reflect differences in the design of the two programs .

these differences include ( 1 ) focusing on just readmission rates ( in contrast to a complex mix of process , patient experience , outcome , and efficiency measures for the hvbp program ) , ( 2 ) not assessing hospitals on their levels of improvement , but instead focusing only their level of readmissions ( with adjustments for patient demographics ) , and ( 3 ) providing only penalties , rather than bonuses , which have generally been larger in magnitude than penalties provided under hvbp .

as with the hvbp quality measures , these trends reflect the initial years of the hospital readmissions reduction program , and they could change with time .

moreover , there could be other factors beyond the implementation of this program that influenced the decline in heart attack , heart failure and pneumonia readmissions over that time period .

nonetheless , the conjunction of the drop in hospital readmission rates and the introduction of a financial incentive program targeting those rates provides some additional indication that financial incentives of the sort broadly offered by programs like the hvbp program and the hospital readmissions reduction program may , under certain circumstances , promote enhanced quality of care .

however , a clear understanding of the extent of that impact , and the circumstances under which it may be maximized , will depend on the results of future research .

officials from selected hospitals reported that the hvbp program reinforced their ongoing quality improvement programs without leading to major changes .

in addition , they cited a variety of factors that affected their capacity to make quality improvements , though they said that these factors were not directly influenced by the hvbp program .

officials from eight selected hospitals we contacted reported that the actions that their hospitals took in response to the hvbp program focused on reinforcing ongoing efforts to improve quality .

prior to the hvbp program , each of these hospitals had established a quality improvement program that sought to improve the hospital's performance on quality measures targeted by medicare's iqr program , as well as , in some cases , additional quality measures specified by private insurers , organizations of peer hospitals , or the hospital itself .

officials from the selected hospitals reported a variety of specific responses to the hvbp program .

these responses reflected the hospitals' differing individual circumstances and generally involved incremental adjustments to existing quality improvement programs , rather than major changes .

the hospital officials described two ways in particular that the hvbp program reinforced these existing hospital efforts: ( 1 ) elevating the profile of the hvbp quality measures and thereby providing hospitals with a way to focus their quality improvement efforts , and ( 2 ) motivating hospital officials to increase the resources directed towards quality improvement .

some officials at the selected hospitals noted that one key effect of the hvbp program was to elevate the profile of those iqr measures included in the hvbp formula .

these officials characterized the hvbp measures as a set of “national quality goals” which allowed them to benchmark their own performance against that of other hospitals .

hospital officials pointed in particular to the outcome measures in the hvbp program as influencing efforts to expand their hospitals' ongoing quality improvement efforts beyond the traditional focus on clinical process measures .

however , these officials noted that this increased emphasis on outcomes measures was part of a larger transformation occurring throughout the health care system .

according to the officials , a range of private sector value - based purchasing and other related initiatives were leading them in the same direction , and therefore it was difficult for hospital officials to differentiate actions taken in response to the hvbp program from responses to these other initiatives .

officials at the selected hospitals also credited the hvbp program with helping to motivate them to increase the resources directed at quality improvement .

several of these hospital officials described how quality improvement was a resource - intensive effort , in which one key resource was skilled staff who could collect , analyze , and act on timely , accurate and relevant data .

hospital officials reported that they had increased the number of such staff in recent years .

some officials suggested that the linkage of hospital quality to payments , such as through the hvbp program and comparable private sector initiatives , had helped to justify that shift in staff resources .

however , according to hospital officials , this increase in staff contributed broadly to each hospital's quality improvement efforts , rather than being limited to the particular hvbp quality measures .

officials at the selected hospitals emphasized that their ability to identify and address quality issues depended on their obtaining data about how their hospital was performing on relevant measures at the current time .

because the quality information provided by cms to both hospitals and the public reflects patient care provided months or years in the past , these hospital officials found that they needed to generate more timely quality information on their own , either internally or through private vendors .

this information allowed them to assess their current quality problems and also determine if the steps that they took to address problems were working .

however , several officials at the selected hospitals noted that their ability to generate more current information was limited to certain types of quality measures , primarily those focused on clinical processes and patient experience .

by contrast , many of these hospital officials said that they could not replicate the outcome measures that cms calculated from medicare claims — as those measures often reflected what happened to patients after they left the hospital and are therefore based in part on data not readily available to hospitals .

these hospital officials reported that improving their performance on patient outcomes was more challenging without accurate and current data .

just as hospitals had quality improvement programs in place prior to the hvbp program , their efforts to improve efficiency were also already growing when the hvbp program took effect .

according to some officials at the selected hospitals , the addition of the medicare spending per beneficiary measure to the hvbp program formula , with the introduction of the efficiency domain in fiscal year 2015 , did little to affect those efforts .

in part that was because , like the hvbp outcome measures , hospital officials reported that they could not independently calculate their medicare spending per beneficiary scores , nor did they clearly understand what they would need to do to improve these scores .

instead , these hospital officials reported that they have proceeded with a range of more general efforts to improve efficiency by reducing their costs without impairing quality .

these include initiatives to lower supply costs by standardizing the selection of medical devices , such as artificial joints , as well as systemic assessments of work processes designed to streamline their delivery of care .

officials at the selected hospitals reported varying levels of intensity in the pursuit of these efficiency goals , depending on the particular circumstances of their hospital .

however , according to these officials , the impetus behind these efficiency efforts came from an increased focus for both public and private payers on controlling the growth of hospital costs .

numerous officials at the selected hospitals stated that their efforts to improve efficiency were aimed at securing the economic survival of their hospital in an increasingly challenging health care marketplace , rather than responding to a specific incentive from the hvbp program .

the issue that officials from most of the selected hospitals we contacted frequently identified as a barrier to quality improvement efforts was the hospital's information technology ( it ) system , especially its electronic health record .

some of these officials described how implementing a new it system slowed down their work as staff grappled with learning the system , how limitations to the system prevented the production of desired performance - related data , and how the it system diverted significant hospital resources into implementing and maintaining the system — resources that could otherwise have been applied elsewhere , such as to quality improvement efforts .

while some hospital officials we spoke to described the difficulties associated with implementing and effectively utilizing their it systems , some highlighted the benefits of those systems as a tool for enhancing quality .

these officials stated that physicians and other staff had come to rely upon their it systems over time and that these systems helped their clinicians to better manage and coordinate care .

others said that their it systems helped them to better manage their quality performance efforts , such as through built - in clinical process reminders in their electronic health record systems or by facilitating the collection of the patient clinical data needed for quality measures .

some other factors that officials at the selected hospitals identified as having a negative effect on their ability to make quality improvements included a lack of financial resources , the absence of timely and easily interpretable quality performance data , and personnel issues .

these hospital officials told us that reduced reimbursement rates and the financial demands of a variety of other priorities limited the resources available for desired quality improvement efforts .

some of these officials also discussed challenges associated with interpreting performance data received from cms , in part due to the delay between when the actions or outcomes measured actually occur and when the resulting scores are reported back to the hospital .

personnel issues — including limited physician engagement or a shortage of staff with needed quality improvement - related skills — were also described by some officials as having a negative effect on quality improvement efforts .

some officials at both small rural and safety net hospitals we contacted cited particular patient population and community factors as barriers to their quality improvement efforts .

for example , some safety net hospital officials spoke about difficulties that arise from serving a disproportionate share of patients with characteristics — such as low incomes , mental health issues , language barriers , or little access to transportation — which officials said make it harder to coordinate care and achieve better outcomes .

in addition , some officials at safety net hospitals stated that a lack of available external resources in their community — such as mental health services , social services , and other health care services external to the hospital — or a lack of coordination between those resources make it harder to coordinate care and achieve better outcomes .

some small rural hospital officials also described similar barriers to improving quality of care , highlighting in particular the limited availability of mental health and social services in their community .

collaboration was a factor that numerous officials at the selected hospitals mentioned as having a beneficial effect on quality improvement efforts , and these officials discussed a range of different forums they had found for collaborative learning .

some cited the usefulness of their area's hospital engagement network in providing a forum for sharing best practices .

others discussed the benefits of learning from regional or state - based networks that they accessed through their state hospital association or another convening body .

officials from hospitals that are part of a hospital system spoke about collaboration within their system .

while officials at the selected hospitals outlined for us the many factors they believed affected their quality improvement efforts , they did not indicate that these factors were specific to the hvbp program .

instead , these hospital officials said they were working to improve quality for a number of reasons , including responding to the hvbp program , and that these factors applied to their ongoing quality improvement efforts as a whole .

consequently , these officials characterized these factors as inhibiting or facilitating each hospital's quality improvement efforts broadly rather than being factors that specifically affected or were affected by the implementation of the hvbp program .

we provided a draft of this report to the department of health and human services for review , which includes cms .

the department provided technical comments , which we incorporated as appropriate .

we are sending copies of this report to the secretary of health and human services , the administrator of the centers for medicare & medicaid services , and other interested parties .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staffs have any questions about this report , please contact me at ( 202 ) 512-7114 or at kohnl@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix vii .

the following table lists the inpatient quality reporting ( iqr ) program measures included in our analysis of quality trends before and after the introduction of the hospital value - based purchasing ( hvbp ) program .

the table identifies which quality domain each measure belongs to ; specifies whether the measure was used to calculate hvbp scores anytime during fiscal years 2013 , 2014 , or 2015 ; provides the iqr code and description that designate the measure under the iqr program ; and indicates the number of data points available for our analysis , in which we assessed possible shifts in trends from the period before the hvbp program came into effect through the period after its implementation .

most of these measures have data points reported quarterly to the iqr program , with the exception of the patient outcome measures ( mortality and readmissions ) , which are reported annually .

description heart attack patients received fibrinolytic agent within 30 minutes of hospital arrival heart attack patients received percutaneous coronary intervention within 90 minutes of hospital arrival heart failure patients received discharge instructions blood culture performed in the emergency department prior to first antibiotic received in hospital for pneumonia patients appropriate initial antibiotic selection for community acquired pneumonia patient prophylactic antibiotic received within 1 hour prior to surgical incision received prophylactic antibiotic consistent with recommendations for surgical patients prophylactic antibiotics discontinued within 24 hours after surgery end time ( 48 hours for cardiac surgery ) .

in addition to the contact named above , will simerl , assistant director ; zhi boon ; krister friday ; colbie holderness ; eric peterson ; david plocher ; vikki porter , and steve robblee made key contributions to this report .

health care transparency: actions needed to improve cost and quality information for consumers .

gao - 15-11 .

washington , d.c.: october 20 , 2014 .

electronic health record programs: participation has increased , but action needed to achieve goals , including improved quality of care .

gao - 14-207 .

washington , d.c.: march 6 , 2014 .

health care quality measurement: hhs should address contractor performance and plan for needed measures .

gao - 12-136 .

washington , d.c.: january 13 , 2012 .

hospital quality data: hhs should specify steps and time frame for using information technology to collect and submit data .

gao - 07-320 .

washington , d.c.: april 25 , 2007 .

hospital quality data: cms needs more rigorous methods to ensure reliability of publicly released data .

gao - 06-54 .

washington , d.c.: january 31 , 2006 .

