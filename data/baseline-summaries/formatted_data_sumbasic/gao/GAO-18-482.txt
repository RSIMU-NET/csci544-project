job corps is the nation's largest residential , educational , and career and technical training program for low - income youth generally between the ages of 16 and 24 .

the job corps program is administered by the office of job corps in the department of labor's ( dol ) employment and training administration ( eta ) .the program enrolls approximately 50,000 new students each year at 123 job corps centers nationwide and for fiscal year 2017 was appropriated about $1.7 billion .

for almost a decade , concerns have been raised regarding the safety and security of job corps students .

for example , dol office of inspector general ( oig ) audits in 2009 , 2010 , 2015 , and 2017 found that the office of job corps did not properly address serious incidents related to student safety and security because of deficiencies in its oversight of program disciplinary policies .

as a result , the dol oig included providing a safe learning environment at job corps centers among the department's top management challenges in november 2017 .

additional concerns were raised regarding the safety and security of students following the deaths of two students at two separate job corps centers in 2015 .

for a june 2017 hearing , you asked us to provide preliminary observations on the safety and security of students in the job corps program .

our preliminary results found that job corps centers reported 49,836 safety and security incidents of various types that occurred both onsite and offsite between january 1 , 2007 , and june 30 , 2016 .

during this time period , approximately 539,000 students were enrolled in the program , according to eta officials .

beginning july 1 , 2016 , eta implemented policy changes that impacted the categorization and number of reportable incidents .

as such , incident data after july 1 , 2016 — the focus of this report — are not comparable with the earlier incident data presented in our june 2017 testimony .

in addition , we reported in our testimony that from march 2007 through march 2017 , students generally reported feeling safe at their job corps center , but reported feeling less safe in certain situations such as when they witnessed physical fights and heard threats between students .

this report examines ( 1 ) what is known about the number and types of reported incidents involving the safety and security of job corps students in program year 2016 ; ( 2 ) what is known about student perceptions of safety and security at job corps centers , and what steps , if any , is eta taking to improve the survey used to collect this information ; and ( 3 ) the extent to which eta has taken steps to address safety and security at job corps centers .

to address our first objective , we analyzed eta's incident data for program year 2016 , the most recent year for which job corps data were available .

eta captures these data in its significant incident reporting system ( sirs ) .

we assessed the reliability of sirs data by reviewing relevant agency documentation about the data and the system that produced them and interviewing knowledgeable eta and dol oig officials .

we determined that the data were sufficiently reliable to report the minimum number of incidents that occurred in program year 2016 .

it is likely that the actual number of incidents was greater than the number reported in sirs because the information is reported by job corps centers , and the dol oig previously found instances of underreporting by a non - generalizable sample of center operators .

while eta has recently taken steps to improve center reporting of significant incidents , according to dol oig officials , it is too early to determine if these steps have resolved the oig's concerns regarding center underreporting .

the incident categories and definitions in this report are taken directly from eta documents and represent how eta categorizes these incidents .

we did not assess these categories and definitions .

to address our second objective , we analyzed eta's national student satisfaction survey data for program year 2016 , the most recent year for which data were available .

the surveys were administered to students in september 2016 and march 2017 , and each had a response rate of about 90 percent .

the semi - annual survey on various aspects of the job corps program included 12 questions about students' perceptions of safety at their center .

we assessed the reliability of the data by reviewing relevant agency documentation about the data and the system that produced them and interviewing knowledgeable eta officials , among other steps .

we determined that the student survey data were sufficiently reliable for our purposes .

to address our third objective , we reviewed documentation on eta's recent actions to improve center safety and job corps policies for monitoring center operators .

we also used criteria to assess whether eta's documentation of its recent and planned actions constituted a comprehensive plan .

these criteria included leading practices for comprehensive planning and standards for internal control in the federal government .

we selected these criteria because they included a process for developing a comprehensive plan and specify the content of such plans , which we determined to be most relevant , given our initial understanding that eta was early in its planning process .

to address all three objectives , we reviewed agency policies and procedures and interviewed eta national and regional officials .

we also conducted site visits to two job corps centers to interview center staff and students about various safety and security issues .

the two selected centers were within geographical proximity to washington , d.c. , operated by different contractors , and had over 100 reported incidents of various types in program year 2016 .

while these two site visits are not generalizable to all job corps centers , they provide examples of student and staff experiences with safety and security .

additional details on our methodology can be found in appendix i .

we conducted this performance audit from april 2017 to june 2018 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

to be eligible for the job corps program , an individual must generally be 16 to 24 years old at the time of enrollment ; be low income ; and have an additional barrier to education and employment , such as being homeless , a high school dropout , or in foster care .

see table 1 for characteristics of students served by job corps during program year 2016 .

once enrolled in the program , youth are assigned to a specific job corps center , usually one located nearest their home and which offers a job training program of interest .

the vast majority of students live at job corps centers in a residential setting , while the remaining students commute daily from their homes to their respective centers .

this residential structure is unique among federal youth programs and enables job corps to provide a comprehensive array of services , including housing , meals , clothing , academic instruction , and job training .

in program year 2016 , about 16,000 students received a high school equivalency and about 28,000 students completed a career technical training program , according to eta officials .

eta administers job corps' 123 centers through its national office of job corps under the leadership of a national director and a field network of six regional offices located in atlanta , boston , chicago , dallas , philadelphia , and san francisco ( see fig .

1 ) .

job corps is operated primarily through contracts , which according to eta officials , is unique among eta's employment and training programs ( other such programs are generally operated through grants to states ) .

among the 123 centers , 98 are operated under contracts with large and small businesses , nonprofit organizations , and native american tribes .

the remaining 25 centers ( called civilian conservation centers ) are operated by the u.s. department of agriculture's ( usda ) forest service through an interagency agreement with dol .

job corps center contractors and the usda forest service employ center staff who provide program services to students .

the president's fiscal year 2019 budget seeks to end usda's role in the program , thereby unifying responsibility under dol .

the administration reported that it was proposing this action because workforce development is not a core mission of usda , and the 25 centers it operates are overrepresented in the lowest performing cohort of centers .

according to eta officials , the office of job corps has oversight and monitoring responsibility to ensure that center operators follow job corps' policy and requirements handbook , including the safety and security provisions .

job corps regional office staff are largely responsible for these duties .

job corps' policy and requirements handbook requires centers to report certain significant incidents to the national office of job corps and to regional offices using sirs .

centers are required to report numerous categories of incidents , including assaults , alcohol and drug - related incidents , and serious illnesses and injuries ( see appendix ii for definitions of these categories of incidents ) .

within the policy and requirements handbook , eta establishes student standards of conduct that specify actions centers must take in response to certain incidents .

in some cases , the incident categories in sirs are related to the specific infractions defined in the policy and requirements handbook , which are classified according to their level of severity .

level i infractions are the most serious , and includes infractions such as arrest for a felony or violent misdemeanor or possession of a weapon , and are required to be reported in sirs .

level ii includes infractions such as possession of a potentially dangerous item like a box cutter , or arrest for a non - violent misdemeanor .

the majority of these infractions are required to be reported in sirs .

minor infractions — the lowest level — include failure to follow center rules , and are not required to be reported in sirs .

centers must report incidents involving both job corps students and staff , and incidents that occur onsite at centers as well as those that occur at offsite locations .

according to eta officials , the agency and its center operators must take steps to protect the safety and security of job corps students when students are under job corps supervision .

students are under job corps supervision when they are onsite at job corps centers and when they are offsite and engaged in center - sponsored activities , such as work - based learning or community service .

according to eta officials , the agency and its contractors are not responsible for protecting the safety and security of job corps students when students are offsite and not under job corps supervision , such as when students are at home on leave .

however , when offsite safety and security incidents of any type occur , job corps center operators are responsible for enforcing the student conduct policy .

for example , if a student is arrested for a felony offsite while not under job corps supervision , the arrest may result in a level i infraction and dismissal from the program .

since 2002 , eta used its student satisfaction survey to periodically obtain views from enrolled job corps students on various aspects of the program , including career development services , interactions between students and staff , access to alcohol and drugs , and overall satisfaction with the program .

the survey of 49 questions has remained the same over time and included 12 questions on students' perceptions of safety and security at centers .

eta used the responses to the 12 safety - related survey questions to calculate a center safety rating , which represented the percentage of job corps students who reported feeling safe at each center , as well as a national safety rating , which represented the percentage of job corps students who reported feeling safe nationwide .

eta officials said they used these ratings to assess students' perceptions of safety at individual centers and nationwide , to monitor and evaluate center operators , and to determine whether eta needed to take action to better address students' safety and security concerns .

in 2018 , eta will pilot a stand - alone survey for safety related topics and remove the safety questions from the student satisfaction survey .

our analysis of eta's data from the significant incident reporting system ( sirs ) showed that job corps centers reported 13,673 safety and security incidents involving students , including those that occurred both onsite and offsite , in program year 2016 .

during this time period ( july 1 , 2016 , through june 30 , 2017 ) , approximately 79,000 students were served by the program , according to eta officials .

drug - related incidents ( 29 percent ) and assaults ( 19 percent ) accounted for 48 percent of all reported incidents involving students .

the remaining 52 percent of reported incidents involving students included breaches of security and safety ( 12 percent ) , alcohol - related incidents ( 6 percent ) , serious illness and injury ( 6 percent ) , theft or damage to property ( 5 percent ) , danger to self or others ( 5 percent ) , and all other types of incidents ( 18 percent ) ( see fig .

2 ) .

according to eta officials , about half of the 3,926 drug - related incidents are due to positive drug test results among students that are administered drug tests about 40 days after entering the program .

we found that about 20 percent of reported onsite and offsite incidents in program year 2016 were of a violent nature , which we define as homicides , sexual assaults , and assaults .

there were two reported homicide incidents in program year 2016 and both occurred while students were offsite and not under job corps supervision .

also , centers reported 177 sexual assaults and 2,593 assaults involving students during program year 2016 .

for each reported sexual assault and assault , sirs provides an additional description of the incident ( see table 2 ) .

in our june 2017 testimony , we stated that 49,836 onsite and offsite safety and security incidents of various types were reported by job corps centers between january 1 , 2007 , and june 30 , 2016 , based on our preliminary analysis of eta's sirs data .

we cannot compare our analysis of safety and security incidents in our june 2017 testimony to the analysis contained in this report for program year 2016 due to a policy change by eta beginning july 1 , 2016 , which affected the categorization and number of reportable incidents .

specifically , eta changed the way some incidents are defined , and required that some incidents be reported in sirs that previously had no such requirement .

anecdotally , officials from one eta regional office and two job corps centers that we visited said that the number of reported incidents has increased since july 1 , 2016 , due to these changes .

in its december 2017 report , the dol oig compared the number of safety and security incidents reported to the oig for the same 8-month periods in 2016 and 2017 and found an increase of 134 percent .

according to the dol oig , this increase is likely due to more accurate incident reporting as a result of the recent policy change .

in addition , the dol oig said an actual increase in incidents is also possible .

our analysis of sirs data found that in program year 2016 , 90 percent of the 13,673 reported safety and security incidents involving students occurred onsite at job corps centers , and 10 percent occurred at offsite locations ( see fig .

3 ) .

for example , 99 percent of drug - related incidents , 96 percent of assault incidents , and 84 percent of alcohol - related incidents occurred onsite .

while most reported incidents occurred onsite , our analysis showed that the majority of reported arrests , deaths , and motor vehicle accidents occurred offsite .

for example , of the 21 student deaths,18 occurred at offsite locations and 3 occurred onsite .

in our june 2017 testimony , we reported that from january 1 , 2007 , through june 30 , 2016 , 76 percent of the reported safety and security incidents occurred onsite at job corps centers , and 24 percent occurred at offsite locations based on our preliminary analysis of eta's sirs data .

however , as previously noted , that analysis is not comparable to the analysis in this report for program year 2016 due to eta's july 1 , 2016 , policy change that impacted the categorization and number of reportable incidents .

we analyzed the 1,406 incidents of 13,673 total reported incidents that were reported to have taken place offsite in program year 2016 to determine if the students involved were on duty ( i.e. , under job corps supervision ) or off duty ( i.e. , not under job corps supervision ) .

we found that for offsite incidents , similar percentages of student victims and perpetrators were on duty and off duty .

specifically , we found that 50 percent of student victims were on duty , 44 percent were off duty , and we were unable to determine the duty status of 6 percent .

for student perpetrators , we found that 45 percent of students were on duty , 45 percent were off duty , and we were unable to determine the duty status of 10 percent .

some types of reported incidents occurred more frequently when students were offsite and off duty .

for example , of the reported arrest incidents that occurred offsite , 76 percent of student perpetrators were off duty .

of the reported death - related incidents that occurred offsite , student duty status was reported as off duty for 16 of 18 incidents .

we were unable to determine the duty status for all students involved in offsite incidents due to inconsistencies in eta's data .

of the 1,406 offsite incidents reported in sirs , there were 178 instances in which a student's duty status location conflicted with the incident location .

for example , the student's duty status was listed as onsite and on duty , but the incident location was listed as offsite .

we asked eta officials why these inconsistencies existed and they were unable to explain all instances in which these inconsistencies occurred .

eta officials did state , however , that these inconsistences can sometimes occur when centers enter information in sirs based on the student's duty status at the time the incident report is completed instead of the student's duty status at the time the incident occurred .

due to this data limitation , we were unable to determine if the 178 students involved in those incidents were on duty or off duty .

we analyzed sirs data to determine the characteristics of students involved in reported safety and security incidents and found that about 17,000 students were reported as victims or perpetrators of all onsite and offsite incidents in program year 2016 .

the total number of students reported as victims or perpetrators is 22 percent of the students served in program year 2016 .

the number of student victims and perpetrators varied across incident types ( see fig .

4 ) .

in program year 2016 , we found that about 5,000 students ( 6 percent of students served ) were reported as victims of various types of onsite and offsite incidents .

we separately examined the gender , age , and enrollment time of reported student victims and found that for all reported incidents the majority of student victims were male , under age 20 , and enrolled in job corps for less than 4 months ( see fig .

5 ) .

these characteristics are somewhat similar to the overall job corps student population , which is primarily male and under age 20 , as previously noted .

for example , 65 percent of reported assault victims and 73 percent of reported theft victims were male .

however , the number of female victims exceeded the number of male victims within some reported incident categories , such as sexual assault , inappropriate sexual behavior , and missing persons .

students under age 20 were victims of 67 percent of reported assault incidents and 63 percent of danger to self or others incidents .

according to eta officials , 18 percent of students served in program year 2016 were enrolled for less than 4 months ; however , across all reported incidents 56 percent of student victims were enrolled for less than 4 months .

for example , about 60 percent of student victims of reported assault and danger to self or other incidents were enrolled in job corps for less than 4 months .

our analysis of sirs data shows that about 13,000 students ( 17 percent of students served ) were reported as perpetrators of various types of onsite and offsite incidents in program year 2016 .

the most commonly reported incidents — drug - related and assaults — also had the highest numbers of student perpetrators .

we found that 6 percent and 5 percent of students served in program year 2016 were perpetrators of reported drug - related and assault incidents , respectively .

similar to our analysis of student victims , we separately examined student characteristics and found that the majority of reported student perpetrators of all reported incidents were male , under age 20 , and enrolled in job corps for less than 4 months ( see fig .

6 ) .

our analysis of eta's student satisfaction survey data from program year 2016 showed that while students generally reported feeling safe at job corps centers , a smaller proportion reported feeling safe in certain situations .

eta considers students to feel safe if they provide certain responses to each of the 12 safety - related survey questions , some of which are phrased as statements .

for example , if a student provided a response of “mostly false” or “very false” to the statement “i thought about leaving job corps because of a personal safety concern,” that student would be counted as feeling safe on that survey question .

on 6 of the 12 safety - related survey questions in program year 2016 , at least 70 percent of responding students indicated that they felt safe ( see table 3 ) .

for example , 74 percent of students responded that they did not ever or in the last month carry a weapon , and 83 percent of students responded that it was very or mostly true that a student would be terminated from job corps for having a weapon at the center .

these are responses that eta considered to indicate feeling safe .

at the two centers we visited , students that we interviewed said that they felt safe onsite at their center .

for example , students at one center said that they felt safe because absolutely no weapons , fighting , or drugs were allowed at the center .

a smaller number of students reported feeling safe on questions that dealt with hearing threats or hearing things from other students that made them feel unimportant .

for example , 36 percent of students reported they had not ever or in the last month heard a student threaten another student at the center , which is considered safe according to eta policy .

meanwhile , 49 percent reported that they had heard a student threaten another student at least once in the last month , and eta considered these responses to indicate that students felt unsafe .

another 15 percent chose “don't know / does not apply.” on another question , 53 percent of students reported that other students had not ever or in the last month said things that made them feel like they were not important , which eta considered as feeling safe .

yet 30 percent reported that others made them feel unimportant at least once in the last month — which eta considered as feeling unsafe — and 17 percent chose “don't know / does not apply.” in response to a question about the student conduct policy , 35 percent of students indicated that the policy was not applied equally to all students .

at the two centers we visited , students that we interviewed had varying views on applying the student conduct policy .

students from one center said that staff have applied the policy in a fair way .

yet at another center , students told us that they have occasionally perceived that staff have not applied the student conduct policy fairly .

they mentioned that they were aware of favoritism in a few recent incidents when staff applied the policy's disciplinary consequences for certain students but not others .

for example , they said that a student they perceived as the perpetrator remained in job corps while a student they perceived as innocent was dismissed .

our june 2017 testimony contained similar observations about students' perceptions of their safety , with students generally reporting that they felt safe at their job corps centers .

for example , most students reported feeling safe because a student found with a weapon at the center would be terminated .

in that testimony , we also noted that students reported feeling less safe on such questions as hearing threats or applying the student conduct policy .

in addition to the 12 safety - related questions , we examined data on the 2 questions about access to alcohol or drugs , and found that almost two - thirds of survey respondents said that it was mostly or very false that they could access alcohol or drugs at their job corps center .

although a large number of reported incidents in program year 2016 involved drugs or alcohol , less than 15 percent of survey respondents said that it was mostly or very true that they could access alcohol or drugs at their job corps center .

based on students' responses to the 12 safety - related questions , eta determined that 88 percent of students indicated that they felt safe in program year 2016 .

eta calculated its national measure of safety — referred to as a safety rating — to summarize and track students' perceptions of their safety and to determine the need for additional action , as noted previously .

similarly , it calculated a safety measure for each center .

however , we calculated a national measure differently and found that an average of 73 percent of students reported feeling safe in program year 2016 .

our national measure reflected the average of how safe each student felt on the 12 safety - related survey questions .

we estimated that one key difference accounted for about 11 of the 15 percentage points between our and eta's measure .

 ( see table 7 in appendix i. ) .

specifically , we calculated our measure based on a numeric average for each student without rounding .

for example , if a student answered all 12 safety questions with 6 responses that he felt safe and another 6 that he felt unsafe , we counted this student as half safe ( 0.5 ) .

meanwhile , eta rounded the average to either safe or unsafe , so that eta counted a student with 6 safe responses and 6 unsafe responses as feeling safe .

in addition to differences in calculations , we developed our own national measure of safety because it is important to assess and track students' perceptions for the program as a whole , as eta has noted .

also , a national measure facilitates analysis of groups of students , such as male or female students or younger or older students , as described below .

we examined whether our national measure differed by age , gender , time in program , center size , or operator type and found statistically significant and meaningful differences in our national measure by students' length of time in the program .

in particular , an average of 78 percent of students in the program for less than 4 months responded that they felt safe , compared to an average of 71 percent for students in the program for at least 4 months .

according to eta officials , differences in responses based on length of time in the program may relate to new students being less aware about life at the center because they begin the program with other newly arrived students for up to 2 months .

for example , eta officials said that new students may live in a dormitory specifically for new students .

thus , they are not yet fully integrated into the larger student body .

although differences were also statistically significant between age groups , center size , and operator type , such differences were not meaningful in a practical manner ( i.e. , around 3 percentage points or less ) .

differences in our national measure by gender were not statistically significant .

when we analyzed the survey's separate question about overall satisfaction with job corps , we found that students who reported they were satisfied with the job corps program responded that they felt safer than students who were not satisfied .

in program year 2016 , about two - thirds of students said it was very or mostly true that they would recommend job corps to a friend , which eta uses to gauge overall satisfaction with the program .

of the 65 percent of students who would recommend job corps to a friend , 79 percent said they felt safe .

of the 11 percent of students who would not recommend job corps to a friend , 52 percent felt safe .

eta officials said that the agency is creating a new expanded safety survey to improve upon the prior survey .

with job corps' heightened attention to safety and security , the new survey — the student safety assessment — is focused solely on safety and security issues and is designed to provide more timely and more detailed information .

more timely information .

eta plans to administer the new safety survey monthly to a random sample of students rather than twice per year to all enrolled students .

also , it will be web - based , rather than the current paper - based survey .

as a result , eta officials said that they will receive more timely information from students because it will take less time to administer the survey and analyze the responses .

more detailed information .

the number of questions about center safety will increase from 12 to about 50 — pending finalization of the survey — which is about the same number of questions on the current student satisfaction survey .

for example , the new questions will ask about sexual assaults and harassment or the types of drugs bought or used at the center , which were not topics covered by the prior survey .

eta continues to work with its contractor with survey expertise to develop , test , and administer the new survey in 2018 , according to eta officials .

to develop the new survey , eta and its contractor have considered , incorporated , and revised questions from other existing surveys .

for example , they have drawn from safety surveys of teenage students and postsecondary students .

eta plans to continue developing and refining the survey and its administration in 2018 , including conducting monthly pilots from january to june 2018 , assessing response rates , and developing a new way to calculate national and center - level safety measures .

additionally , eta officials said that , in 2018 , they will seek to obtain comments and approval on the survey from the office of management and budget .

eta officials told us that they plan to administer the new survey nationally by january 2019 .

as eta refines and administers this new survey , officials told us they plan to develop a new way to measure student safety based on the more detailed survey .

in 2014 , eta launched multiple actions to improve safety and security at job corps centers in response to dol oig recommendations ( see table 4 ) .

for example , in 2015 the dol oig found eta's oversight of job corps centers ineffective , in part , because eta's student conduct policy excluded some violent offenses .

as a result , eta revised its student conduct policy by elevating several infractions previously classified as level ii to level i ( the most severe ) and by adding several new categories of reportable incidents .

under the revised student conduct policy , assault , a level i infraction , now includes fighting , which was previously a level ii infraction .

in addition , the dol oig found that eta did not monitor centers regularly enough to ensure center consistency in administering job corps disciplinary policies .

in response , eta implemented a risk - based monitoring strategy that identifies potential safety and security issues before they occur .

staff from five eta regional offices and at one job corps center we visited said that eta's actions overall helped to improve center safety and security .

for example , staff from five regional offices said that the changes to the student conduct policy that were implemented in july 2016 clearly describe the penalties for infractions and eliminate grey areas that previously allowed center staff to use their professional judgement .

staff from four regional offices also said these changes resulted in tradeoffs that reduced center staff discretion in imposing penalties .

in addition , at one center we visited , the director of safety and security told us he updated the center's security - related standard operating procedures in response to eta's guidance .

eta's guidance was part of the 2017 updates to the policy and requirements handbook in response to dol oig concerns about reporting potentially serious criminal misconduct to law enforcement .

eta national officials said that the new risk - based monitoring strategy has improved center monitoring because it has allowed them to more effectively direct resources to areas of greatest need .

officials in five eta regional offices agreed that the new strategy improved their ability to monitor centers .

the new monitoring strategy shifted the focus from addressing problems after they have occurred to a data - driven strategy that tracks center performance and identifies emerging problems .

this strategy provides eta and center operators an opportunity to address problems before they occur , according to eta national officials .

for example , the new monitoring strategy features new tools , including the risk management dashboard .

the dashboard is a summary analysis tool that conducts trend analysis using center data and allows regional staff to engage in targeted interventions at centers with potential safety and security concerns .

in addition , under the new monitoring strategy , instead of only conducting scheduled monitoring visits to a center at set times , regional staff conduct unannounced visits based on data indicating a decline in center performance or other triggers .

see appendix vi for additional information on the new monitoring strategy .

although the new risk - based monitoring strategy has improved center monitoring , it is not consistently implemented across regional offices , according to eta national officials .

they told us that similar problems identified at centers may be treated with different levels of focus or intensity from one region to another .

in addition , national and regional officials told us that regional office staff have relied on professional judgment to determine the appropriate response to centers that may be at risk of noncompliance with safety and security policies , which could lead to inconsistencies .

for example , when problems are identified at centers , the type of assessment to conduct is left to regional office staff discretion .

as a result , staff in one region may decide that the most comprehensive assessment , the regional office center assessment , is needed , while another region's staff would select a targeted assessment , which is more limited in scope .

eta national officials said that although each determination could be justified based on resource constraints and competing priorities , they would like to increase implementation consistency in this area .

to address regional inconsistencies , eta national and regional office staff said that guidance in the form of standard operating procedures ( sop ) would be helpful .

these procedures would promote consistency in how policies are interpreted and applied and would help ensure that centers are held to the same standards , according to eta national officials .

for example , sops could specify which type of assessment to conduct in response to specific problems identified at centers .

internal control standards state that managers should document in policies each unit's responsibility for an operational process .

regional office staff said that they previously had a helpful tool , the program assessment guide , that linked policies in the policy and requirements handbook to the monitoring assessment process .

regional office staff said they used the program assessment guide to prepare for center monitoring visits and it was a helpful training tool for new staff .

our review of eta documentation found that the program assessment guide included specific questions to ask center staff about how they meet safety and security requirements and suggested where to look for information to determine center compliance with policies .

however , the program assessment guide , which has not been updated since 2013 , does not include recent changes to the policy and requirements handbook , such as the updated student conduct policy .

eta national officials told us that limited staffing has made it difficult to update the program assessment guide as frequently as changes are made to the policy and requirements handbook .

in february 2018 , eta national officials told us they plan to issue a variety of sops related to monitoring center safety and security issues ( see table 5 ) .

eta officials initially said these sops would be completed in august or november 2018 and later revised its plans with a goal of completing all sops by august 2018 .

however , in august 2017 , eta officials had told the dol oig that these sops would be completed in the march to july 2018 timeframe .

eta officials said that a staffing shortage in the office of job corps' division of regional operations and program integrity delayed development of the sops .

this division — established in 2015 to coordinate regional operations and strengthen communications and quality assurance — includes eight staff positions ; however , as of january 2018 , the division has two staff members on board .

eta officials said that they have not yet received departmental approval to fill the six vacant positions in the division .

given this uncertainty , it is questionable whether eta's revised timeframes will be met .

without sops or other relevant guidance , eta cannot ensure that monitoring for center safety and security will be carried out uniformly across the program .

as a result , centers may be held to different standards , and the program may not achieve its center safety and security goals .

in addition to inconsistencies in monitoring and a lack of sufficient guidance , staff in all six regional offices told us that components of eta's risk - based monitoring strategy created reporting overlaps .

as part of the new monitoring strategy , regional staff have additional reports that they complete — such as the risk management dashboard action report and corrective action tracker — about potential safety and security problems or actual violations found at centers .

some regional staff said the desk monitoring report includes similar information to the risk management dashboard and corrective action tracker reports , which regional offices submit to the eta national office .

staff in one regional office said that they enter the same information about the status of center safety and security violations multiple times on the corrective action tracker because the time between reporting periods is too short to allow for meaningful action to be taken .

staff from four regional offices said completing duplicative reports reduces time that could be used to conduct additional center monitoring , such as onsite visits , or to perform other key duties .

eta national officials disagreed that overlap exists among monitoring reports .

they said that although reports may appear to overlap , the reports are complementary and not duplicative , and are used at different points in the monitoring process ( see fig .

7 for an overview of eta's monitoring process ) .

for example , eta national staff told us that desk monitoring reports are primarily used by regional staff at the beginning of the monitoring process to identify potential problems and are not substantially reviewed by the national office .

eta national officials also said that the risk management dashboard report is used at the beginning of the monitoring process to identify problems , whereas the corrective action tracker is used later in the process after violations have been identified and corrective actions have been planned to bring the center back into compliance .

in addition , eta national officials also noted that regional staff are not asked to complete all reports every month .

for example , regional staff complete a risk management dashboard action report only for those centers with potential safety and security concerns .

we compared the information included in five monitoring reports — the center culture and safety assessment , corrective action tracker , desk audit , regional office center assessment , and risk management dashboard action report — and found opportunities for streamlining .

for example , we found that the center culture and safety assessment , corrective action tracker , and regional office center assessment , all include a narrative description of the violations identified by regional staff categorized according to the corresponding requirement in the policy and requirements handbook .

in addition , eta regional office staff said the corrective action tracker , a microsoft excel spreadsheet , is cumbersome to use and within the spreadsheet they attach and submit additional documentation .

eta national officials agreed that streamlining or automating monitoring tools would be helpful for its regional staff , along with additional training to help staff understand the different reports and how to write the required narratives .

eta national officials also told us that they did not systematically review existing reports before creating additional ones for the new risk - based monitoring process .

officials said they have lacked the resources to make some improvements that could reduce the time regional office staff spend on reporting .

standards for internal control state that managers should identify the organizational level at which the information is needed , the degree of specificity needed , and state that managers should review information needs as an on - going process .

streamlining or automating reporting requirements can help centralize documentation relevant to monitoring center safety and security , possibly eliminate seemingly duplicative reporting requirements , and help regional staff manage their workloads .

while eta initiated multiple actions to address various safety and security issues , the agency does not have a comprehensive plan to improve center safety and security .

a comprehensive plan describes the organization's long - term goals , its strategy and timelines for achieving those goals , and the measures that will be used to assess its performance in relationship to its goals .

it can also guide decision - making to achieve desired outcomes , including the priority with which to implement these efforts .

eta officials told us that although they do not have a single document that reflects a formal comprehensive plan , they have employed a comprehensive approach to improve center safety and security .

however , in prior work , gao established the importance of comprehensive planning to ensure agencies effectively execute their missions and are accountable for results .

gao has also identified leading practices that help ensure organizations achieve their objectives .

these leading practices include developing goals , strategies to achieve goals , plans to assess progress toward goals , and leadership and stakeholder involvement in plan development ( see table 6 ) .

eta officials agreed that a comprehensive plan is needed , but told us that limited staff capacity and lack of expertise have hindered their ability to produce a comprehensive plan .

in particular , the division of regional operations and program integrity would have a role in developing the agency's comprehensive plan .

as previously mentioned , eta officials told us that they did not have approval to fill the six vacant positions in the division .

with only two of the eight positions filled , eta officials said that they prioritized correcting the deficiencies identified by the dol oig and responding to immediate safety and security concerns .

eta officials told us they plan to produce a comprehensive plan when they have secured the staff to do so .

however , at this time , eta does not have a specific timeframe for producing such a plan .

when the agency begins developing a comprehensive plan , it could consider using the leading practices outlined above and drawing on the expertise of the government - wide performance improvement council .

in the absence of a comprehensive plan for safety and security , eta risks the success of its new initiatives because they are not linked in an overall framework that demonstrates how they are aligned or contribute to goals for improving center safety and security .

it is important that job corps students be provided with a safe and secure learning environment .

for the last several years , however , numerous incidents have threatened the safety and security of students .

eta has taken steps to improve center safety and security , but its efforts could be strengthened by ensuring regional office staff responsible for monitoring job corps centers are better supported with additional guidance and streamlined reporting requirements .

without providing regional staff with this additional support , the full potential of the new monitoring strategy may not be realized .

while eta has implemented several actions to address safety and security concerns , it does not have a comprehensive plan to guide all of its efforts .

without a comprehensive plan , eta will not be able to assess its overall effectiveness in addressing center safety and security .

we are making the following three recommendations to eta: the assistant secretary of eta should ensure the office of job corps expeditiously develops additional guidance , such as sops or updates to the program assessment guide , to ensure regional offices consistently implement the risk - based monitoring strategy .

 ( recommendation 1 ) the assistant secretary of eta should ensure the office of job corps streamlines the monitoring reports completed by regional office staff .

this streamlining could include automating monitoring tools , consolidating monitoring reports , or taking other appropriate action .

 ( recommendation 2 ) the assistant secretary of eta should ensure the office of job corps commits to a deadline for developing a comprehensive plan for job corps center safety and security that aligns with leading planning practices , such as including a mission statement with goals , timelines , and performance measures .

this could also include developing the planning expertise within the office of job corps , leveraging planning experts within other agencies in dol , or seeking out external experts , such as the government - wide performance improvement council .

 ( recommendation 3 ) .

we provided a draft of this report to dol for review and comment .

we received written comments from dol , which are reprinted in appendix vii .

dol concurred with our three recommendations .

the department stated that it will move forward to develop standard operating procedures for its risk - based monitoring strategy , review and streamline existing monitoring reports , and provide additional training for its regional office staff .

the department also plans to develop a formal written comprehensive plan for job corps safety and security .

dol also provided technical comments that we have incorporated in the report as appropriate .

as agreed with your office , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies to the appropriate congressional committees and the secretary of labor .

in addition , the report is available at no charge on the gao website at http: / / www.gao.gov .

if you or your staff have any questions about this report , please contact me at ( 202 ) 512-7215 or brownbarnesc@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made key contributions to this report are listed in appendix viii .

the objectives of this review were to examine ( 1 ) what is known about the number and types of reported incidents involving the safety and security of job corps students in program year 2016 ; ( 2 ) what is known about student perceptions of safety and security at job corps centers , and what steps , if any , is the employment and training administration ( eta ) taking to improve the survey used to collect this information ; and ( 3 ) the extent to which eta has taken steps to address safety and security at job corps centers .

to address all three objectives , we reviewed agency policies and procedures , such as the job corps policy and requirements handbook and guidance issued to center operators and eta staff .

in addition , we interviewed eta officials , including office of job corps national staff , office of job corps regional directors , and staff in all six regional offices .

we also conducted site visits at the woodstock job corps center in woodstock , maryland , and the potomac job corps center in washington , d.c. we selected these two centers because they were within geographical proximity to washington , d.c. , operated by different contractors , and had over 100 reported safety and security incidents each in program year 2016 .

at each center , we interviewed the center director , head of safety and security , a group of staff members , and a group of students .

the staff and students we spoke with were selected by the centers .

while these two site visits are not generalizable to all job corps centers , they provide examples of student and staff experiences with safety and security .

to determine the number and types of safety and security incidents reported by job corps centers , we analyzed eta's incident data for program year 2016 ( july 1 , 2016 to june 30 , 2017 ) .

this was the most recent year of job corps data available at the time of our review .

eta captures these data in its significant incident reporting system ( sirs ) .

centers must report incidents involving both job corps students and staff , and incidents that occur at onsite and offsite locations .

eta has 20 categories of incidents in sirs .

see appendix ii for incident category definitions .

the incident categories and definitions in this report are taken directly from eta documents and represent how eta categorizes these incidents .

we did not assess these categories and definitions .

in this report , we present information on reported safety and security incidents in program year 2016 involving at least one student victim or perpetrator .

there were 13,673 reported incidents involving students ; additional incidents are reported in sirs that did not involve students .

when these additional incidents are included , a total of 14,704 safety and security incidents were reported in program year 2016 .

see appendix iii for further information on the total number of incidents reported .

to calculate the number and types of reported incidents , we analyzed the primary incident type that was assigned to each incident reported in sirs .

to provide additional information on reported assaults and sexual assaults , we also analyzed the secondary incident type that was assigned to each reported assault and sexual assault in sirs .

to calculate the total number and types of reported deaths , we analyzed both primary incident types and secondary incident types .

in sirs , deaths can be reported under three different primary incident types ( “death” , “assault” , and “danger to self or others” ) .

when an incident is assigned to any of these primary incident types , it may also be assigned a secondary incident type of “homicide,” among other secondary incident types .

in addition , we analyzed the duty status for student victims and perpetrators of offsite incidents .

in sirs , students are described as being either ( 1 ) on duty , which means that they are onsite at a center or in a job corps supervised offsite activity ; or ( 2 ) off duty , which means they are offsite and not under job corps supervision .

for the 1,406 offsite incidents , we were unable to determine student duty status in 178 instances due to inconsistencies in eta's data .

this report focuses on reported safety and security incidents in program year 2016 , which was from july 1 , 2016 , to june 30 , 2017 .

on july 1 , 2016 , eta implemented policy changes that impacted the categorization and number of reportable safety and security incidents .

accordingly , incident data after july 1 , 2016 , are not comparable with earlier incident data , including incident data we reported in a june 2017 testimony .

we assessed the reliability of sirs data by reviewing relevant agency documentation about the data and the system that produced them and interviewing eta and department of labor office of inspector general ( dol oig ) officials knowledgeable about the data .

we determined the data were sufficiently reliable to report the minimum number of incidents that occurred in program year 2016 .

it is likely that the actual number of incidents was greater than the number reported in sirs because the information is reported by job corps centers and the dol oig previously found instances of underreporting by a non - generalizable sample of center operators .

in its march 2017 report , dol oig found that 12 of 125 job corps centers did not report 34 percent of significant incidents in sirs from january 1 , 2014 , through june 30 , 2015 .

eta has recently taken steps to improve center reporting of significant incidents , such as revising the student conduct policy to more clearly define behavior infractions and conducting system - wide training to ensure uniform understanding and enforcement of student conduct policies .

however , dol oig officials told us in january 2018 that it is too early to determine if these steps have resolved the dol oig's concerns regarding center underreporting .

to examine what is known about student perceptions of their safety and security at job corps centers , we analyzed students' responses to the student satisfaction survey administered during program year 2016: september 2016 and march 2017 .

we analyzed responses from both of these surveys in program year 2016 , which was the most recent year for which data were available .

eta provided centers with the standardized paper - based survey to administer to students in - person on designated weeks .

the survey of 49 close - ended questions contained 12 questions that eta used to assess students' safety .

in addition to questions on student safety , the survey includes questions on other topics , including student demographics , overall satisfaction with job corps , and access to drugs and alcohol on center .

according to data from eta , the response rate for each survey was approximately 90 percent of all enrolled students .

eta calculated the response rate by dividing the number of students who responded to the survey by the number of enrolled students during the week of survey administration .

students responded anonymously to the survey .

because about 90 percent of students provided responses and about 10 percent did not , we analyzed the potential for non - response biases based on several student characteristics .

if the responses of those who did not respond would have differed from the responses of those who did on relevant safety questions , the results calculated solely from those who responded may be biased from excluding parts of the population with different characteristics or views .

we compared age , time in program , race , and gender — key characteristics available for the population of enrollees and respondents — to determine areas for potential bias .

we determined that the potential for non - response biases existed for particular groups of students: younger students and those enrolled in the program for at least 6 months .

for race , the potential for non - response bias was unclear .

we found no potential bias for gender .

specifically , we found the following: age .

younger students were under - represented , and older students were over - represented among survey respondents .

thus , to the extent that non - responding younger students would have answered safety questions differently than responding younger students , the potential for bias existed in the survey results we analyzed .

when we asked eta officials about such a potential bias , they responded that they did not have evidence or documentation suggesting that age is a predictor of students' level of perceived safety in the program .

length of time in the program .

students in the program less than 6 months were over - represented among survey respondents , and students enrolled in the program over 6 months were under - represented in the survey .

to the extent that non - responding students would have answered safety questions differently based on length of time enrolled , the potential for bias existed in the survey results we analyzed .

when we asked eta officials about such a potential bias , they noted that new students may be less aware about life at the center because they begin the program with other newly arrived students for up to 2 months .

thus , they are not yet fully integrated into the larger student body .

otherwise , they did not have evidence or documentation suggesting that length of time in the program correlates with students' level of perceived safety .

race .

it is unclear whether the distribution of race for respondents differs from that in the population .

specifically , ignoring item non - response , about 7 percent of respondents selected “other,” and if those respondents were black / african american , the distributions between the respondents and sample would be similar since this would result in the respondent race percentage being close to 50 percent , like the population of enrollees .

if respondents who selected “other” were actually distributed across the race categories , this would result in a difference between the respondent and population race / ethnicity characteristics , and to the extent that students' responses to safety questions differ by race , this could result in a potential bias of respondent survey results we analyzed .

we analyzed race for purposes of potential non - response bias , and not as part of statistical tests of survey results described below .

gender .

we found no potential non - response bias for gender because the distribution of gender for respondents was similar to that in the population of students enrolled in the program .

in addition to our non - response bias analysis , we assessed the reliability of the survey data by reviewing relevant agency documentation about the data and the system that produced them , testing data electronically , and interviewing eta officials knowledgeable about the data .

we determined that the student survey data were sufficiently reliable for our purposes .

for the 12 safety - related survey questions , job corps policy specified responses that the agency counted as safe or unsafe , which we followed .

as noted previously , eta considers students to feel safe if they provided certain responses to each of the 12 safety - related survey questions , some of which are phrased as statements .

for example , if a student provided a response of “mostly false” or “very false” to the statement “i thought about leaving job corps because of a personal safety concern,” that student would be counted as feeling safe on that survey question ( see table 3 ) .

the percentages that we calculated are not comparable to prior publications , including eta reports , because , for example , eta revised ( i.e. , recoded ) students' responses in certain circumstances , as explained below in table 7 .

meanwhile , we used the original responses that students provided and did not revise them .

also , eta excluded responses of “don't know / does not apply” from its percentages .

as a result , our percentages are not comparable with those reported by eta .

we also calculated national measures of safety for the program and for particular demographic groups of students ( eg , male , female ) .

our calculation was similar to eta's national safety rating in certain respects .

for example , as eta did , we determined how safe each individual student felt as the unit of analysis .

therefore , the national measures of gao and eta may not equal the average of the 12 questions because , for example , not all students answered every safety question .

however , in other respects , we produced our national measure differently than eta .

table 7 explains the three ways that our calculation differed from eta's .

although the student safety surveys were an attempt to survey a census of the population of participants , we treated the survey as a sample in certain respects due to the non - response of about 10 percent of students as well as the ongoing nature of the regularly repeated survey .

therefore , we considered these data as a random sample from a theoretical population of students in this program and used statistical tests to assess any differences .

treating the data as a statistical sample , we carried out statistical tests of differences in safety measures for student characteristics ( eg , age , gender , length of time in the program ) .

because of the large sample size , smaller differences may be detected as statistically significant .

this is because statistical significance is a function of the magnitude of the true difference ( statistical tests are more likely to detect differences when the true values are very different ) as well as the sample size ( larger samples can detect statistical significance of smaller magnitudes , when compared to smaller sample sizes , when all else is equal ) .

however , we used statistical significance in conjunction with whether the detected differences are meaningful or important , in a practical sense .

in particular , we used a series of f - tests to statistically test , at the alpha = 0.05 level , for difference in average safety measure , across categories of age , gender , time in program , center size , and operator type .

appendix ii: categories of incidents in the significant incident reporting system ( sirs ) .

our analysis of the employment and training administration's ( eta ) significant incident reporting system ( sirs ) data showed that there were 14,704 reported safety and security incidents at job corps centers in program year 2016 , which include incidents involving students , staff , and non - job corps individuals .

see table 9 .

job corps centers reported 13,673 safety and security incidents involving students , including those that occurred both onsite and offsite , in program year 2016 .

see table 10 for information on each job corps center , including the number of incidents involving students reported in program year 2016 .

we calculated safety measures for each job corps center , based on student responses to the safety - related questions on the student satisfaction survey ( see table 11 ) .

we used the methodology described in appendix i to calculate safety measures for the centers .

results in table 11 are from the march 2017 survey , the most recent for program year 2016 .

the percentages in this table are not comparable and should not be analyzed with the numbers of reported incidents at each center because they are distinct measures that cover different periods of time .

the employment and training administration's ( eta ) risk - based monitoring strategy is designed to identify emerging problems that place a job corps center at - risk for safety and security problems .

the strategy is largely implemented by regional office staff , which work with the office of job corps' newly formed division of regional operations and program integrity and use a variety of tools to assess , track , and report on center performance ( see table 12 ) .

in addition to the contact named above , mary crenshaw ( assistant director ) , andrea dawson ( analyst - in - charge ) , sandra baxter , and matthew saradjian made key contributions to this report .

additional assistance was provided by alex galuten , gretta goodwin , benjamin licht , grant mallie , mimi nguyen , nhi nguyen , monica savoy , almeta spencer , manuel valverde , kathleen van gelder , and sonya vartivarian .

