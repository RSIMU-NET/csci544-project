i appreciate the opportunity to be here to discuss the report we are issuing today on the first set of recipient reports made available in october 2009 in response to the american recovery and reinvestment act's section 1512 requirement .

on october 30 , recovery.gov ( the federal web site on recovery act spending ) reported that more than 100,000 recipients had reported hundreds of thousands of jobs created or retained .

gao is required to comment quarterly on the estimates of jobs created or retained as reported by direct recipients of recovery act funding from federal agencies .

in the first quarterly gao report , being released today , we address the following issues: ( 1 ) the extent to which recipients were able to fulfill their reporting requirements and the processes in place to help ensure recipient reporting data quality and ( 2 ) how macroeconomic data and methods , and the recipient reports , can be used to help gauge the employment effects of the recovery act .

because the recipient reporting effort will be an ongoing process of cumulative reporting , our review represents a snapshot in time .

at this juncture , given the national scale of the recipient reporting exercise and the limited time frames in which it was implemented , the ability of the reporting mechanism to handle the volume of data from a wide variety of recipients represents a solid first step in moving toward more transparency and accountability for federal funds ; however , there is a range of significant reporting and quality issues that need to be addressed .

consequently , our report contains several recommendations to improve data quality that office of management and budget ( omb ) staff generally agreed to implement .

we will continue to review the processes that federal agencies and recipients have in place to ensure the future completeness and accuracy of data reported .

finally , our report notes that because the recipient reports cover about one - third of recovery act funds , both the data in those reports and other macroeconomic data and methods together can offer a more complete view of the overall employment impact of the recovery act .

in december 2007 , the united states entered what has turned out to be the deepest recession since the end of world war ii .

in responding to this downturn , the recovery act employs a combination of tax relief and government spending .

about one - third of the funds provided by the act are for tax relief to individuals and businesses ; one - third is in the form of temporary increases in entitlement programs to aid people directly affected by the recession and provide some fiscal relief to states ; and one - third falls into the category of grants , loans , and contracts .

as of september 30 , 2009 , approximately $173 billion , or about 22 percent , of the $787 billion provided by the recovery act had been paid out by the federal government .

nonfederal recipients of recovery act - funded grants , contracts , and loans are required to submit reports with information on each project or activity , including the amount and use of funds and an estimate of jobs created or retained .

of the $173 billion paid out , about $47 billion — a little more than 25 percent — is covered by this recipient report requirement .

neither individuals nor recipients receiving funds through entitlement programs , such as medicaid , or through tax programs are required to report .

in addition , the required reports cover direct jobs created or retained as a result of recovery act funding ; they do not include the employment impact on materials suppliers ( indirect jobs ) or on the local community ( induced jobs ) , as shown in figure 1 .

to implement the recipient reporting data requirements , omb has worked with the recovery accountability and transparency board ( recovery board ) to deploy a nationwide data collection system at www.federalreporting.gov , while the data reported by recipients are available to the public for viewing and downloading on www.recovery.gov ( recovery.gov ) .

omb's june 22 , 2009 , guidance on recipient reporting also includes a requirement for data quality review .

prime recipients have been assigned the ultimate responsibility for data quality checks and the final submission of the data .

because this is a cumulative reporting process , additional corrections can take place on a quarterly basis .

the first of the required recipient reports cover cumulative activity since the recovery act's passage in february 2009 through the quarter ending september 30 , 2009 .

as shown in figure 2 , omb specified time frames for different stages in the reporting process: for this current report , prime recipients and delegated subrecipients were to prepare and enter their information from october 1 to october 10 ; prime recipients were able to review the data for completeness and accuracy from october 11 to october 21 , and a federal agency review period began october 22 .

the final recipient reporting data for the first round of reports were first made available on october 30 .

to assess the reporting process and data quality efforts , gao performed an initial set of edit checks and basic analyses on the final recipient report data that first became available at recovery.gov on october 30 , 2009 .

we built on information collected at the state , local , and program level as part of our bimonthly reviews of selected states' and localities' uses of recovery act funds .

these bimonthly reviews focus on recovery act implementation in 16 states and the district of columbia , which contain about 65 percent of the u.s. population and are estimated to receive collectively about two - thirds of the intergovernmental federal assistance funds available through the recovery act .

to understand state quality review and reporting procedures , we visited the 16 selected states and the district of columbia during late september and october 2009 and discussed with prime recipients projects associated with 50 percent of the total funds reimbursed as of september 4 , 2009 , for that state in the federal - aid highway program administered by the department of transportation ( dot ) .

prior to the start of the reporting period on october 1 , we obtained information on prime recipients' plans for the jobs data collection process .

after the october 10 data reporting period , we went back to see if prime recipients had followed their own plans and subsequently talked with at least two subrecipients to gauge their reactions to the reporting process and assess the documentation they were required to submit .

we gathered and examined issues raised by recipients in these jurisdictions regarding reporting and data quality and interviewed recipients on their experiences using the web site reporting mechanism .

during the interviews , we looked at state plans for managing , tracking , and reporting on recovery act funds and activities .

in a similar way , we examined a nonjudgmental sample of department of education ( education ) recovery act projects at the prime and subrecipient level .

we also collected information from selected transit agencies and housing authorities as part of our bimonthly recovery act reviews .

to gain insight into and understanding of quality review at the federal level , we interviewed federal agency officials who have responsibility for ensuring a reasonable degree of quality across their program's recipient reports .

we assessed the reports from the inspectors general ( ig ) on recovery act data quality reviews from 15 agencies .

we are also continuing to monitor and follow up on some of the major reporting issues identified in the media and by other observers .

for example , a number of press articles have discussed concerns with the jobs reporting done by head start grantees .

according to a health and human services ( hhs ) recovery act official , hhs is working with omb to clarify the reporting policy as it applies to head start grantees .

we will be reviewing these efforts as they move forward .

for our discussion of how macroeconomic data and methods and recipient reporting together can be used to assess the employment effects of the recovery act , we analyzed economic and fiscal data using standard economic principles and reviewed the economic literature on the effect of monetary and fiscal policies for stimulating the economy .

we also reviewed the guidance that omb developed for recovery act recipients to follow in estimating the effect of funding activities on employment , reviewed reports that the council of economic advisers ( cea ) issued on the macroeconomic effects of the recovery act , and interviewed officials from cea , omb , and the congressional budget office ( cbo ) .

our work was conducted in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audits to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence we obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

as detailed in our report , our analysis and fieldwork indicate there are significant issues to be addressed in reporting , data quality , and consistent application of omb guidance in several areas .

erroneous or questionable data entries .

many entries merit further attention due to an unexpected or atypical data value or relationship between data .

quality review by federal agencies and prime recipients .

o coverage: while omb estimates that more than 90 percent of recipients reported , questions remain about the other 10 percent .

o review: over three quarters of the prime reports were marked as having undergone review by a federal agency , while less than 1 percent were marked as having undergone review by the prime recipient issues in the calculation of full - time equivalents ( fte ) .

different interpretations of omb guidance compromise the ability to aggregate the data .

we performed an initial set of edit checks and basic analyses on the recipient report data available for download from recovery.gov on october 30 .

as part of our review , we examined the relationship between recipient reports showing the presence or absence of any full - time equivalent ( fte ) counts with the presence or absence of funding amounts shown in either or both data fields for “amount of recovery act funds received” and “amount of recovery act funds expended.” forty - four percent of the prime recipient reports showed an fte value .

however , as shown in table 1 , we identified 3,978 prime recipient reports where ftes were reported but no dollar amount was reported in the data fields for amount of recovery act funds received and amount of recovery act funds expended .

these records account for 58,386 of the total 640,329 ftes reported .

there were also 9,247 reports that showed no ftes but did show some funding amount in either or both of the funds received or expended data fields .

the total value of funds reported in the expenditure field on these reports was $965 million .

those recipient reports showing ftes but no funds and funds but no ftes constitute a set of records that merits closer examination to understand the basis for these patterns of reporting .

our review also identified a number of cases in which other anomalies suggest a need for review: discrepancies between award amounts and the amounts reported as received , implausible amounts , or misidentification of awarding agencies .

while these occurred in a relatively small number of cases , they indicate the need for further data quality efforts .

omb guidance assigns responsibility for data quality to the prime recipient and provides for federal agency review .

a correction could be initiated by either the prime recipient or the reviewing agency .

omb requires that federal agencies perform limited data quality reviews of recipient data to identify material omissions and significant reporting errors and notify the recipients of the need to make appropriate and timely changes to erroneous reports .

the prime recipient report records we analyzed included data on whether the prime recipient and the agency reviewed the record in the data quality review time frames .

over three quarters of the prime recipient reports were marked as having undergone federal agency review .

less than 1 percent of the records were marked as having undergone review by the prime recipient .

the small percentage reviewed by the prime recipients themselves during the omb review time frame warrants further examination .

while it may be the case that the recipients' data quality review efforts prior to initial submission of their reports were seen as not needing further revision during the review timeframe , it may also be indicative of problems with the process of noting and recording when and how the prime recipient reviews occur and the setting of the review flag .

in addition , the report record data included a flag as to whether a correction was initiated .

overall , slightly more than a quarter of the reports were marked as having undergone a correction during the period of review .

in its guidance to recipients for estimating employment effects , omb instructed recipients to report solely the direct employment effects as “jobs created or retained” as a single number .

recipients are not expected to report on the employment impact on materials suppliers ( “indirect” jobs ) or on the local community ( “induced” jobs ) .

omb guidance stated that “the number of jobs should be expressed as ‘full - time equivalents ( ftes ) ,' which is calculated as total hours worked in jobs created or retained divided by the number of hours in a full - time schedule , as defined by the recipient.” consequently , the recipients are expected to report the amount of labor hired or not fired as result of having received recovery act funds .

it should be noted that one fte does not necessarily equate to the job of one person .

organizations may choose to increase the hours of existing employees , for example , which can certainly be said to increase employment but not necessarily be an additional job in the sense of adding a person to the payroll .

problems with the interpretation of this guidance or the calculation of ftes were one of the most significant problems we found .

jobs created or retained expressed in ftes raised questions and concerns for some recipients .

while reporting employment effects as ftes should allow for the aggregation of different types of jobs — part - time , full - time , or temporary — and different employment periods , if the calculations are not consistent , the ability to aggregate the data is compromised .

one source of inconsistency was variation in the period of performance used to calculate ftes , which occurred in both the highway and education programs we examined .

for example , in the case of federal highways projects , some have been ongoing for six months , while others started in september 2009 .

in attempting to address the unique nature of each project , dot's federal highway administration ( fhwa ) faced the issue of whether to report fte data based on the length of time to complete the entire project ( project period of performance ) versus a standard period of performance , such as a calendar quarter , across all projects .

according to fhwa guidance , which was permitted by omb , ftes reported for each highway project are expressed as an average monthly fte .

because ftes are calculated by dividing hours worked by hours that represent a full - time schedule , a standard period of performance is important if numbers are to be added across programs .

as an illustration , take a situation in which one project employed 10 people full time for 1 month , another project employed 10 people full time for 2 months , and a third project employed 10 people full time for 3 months .

fhwa's use of average monthly fte would result in ftes being overstated compared either with using omb's june 22 guidance or to standardizing the reports for one quarter .

under fhwa's approach , 30 ftes would be reported ( 10 for each of the three projects ) ; on the other hand , using a standardized measure , 20 ftes would be reported ( 3-1 / 3 for the first project , 6-2 / 3 for the second project , and 10 for the third ) .

conversely , if a project starts later than the beginning of the reporting period , applying omb's june 22 guidance , which requires reporting of ftes on a cumulative basis , could result in reporting fewer ftes than would be the case under a standardized reporting period approach .

in either case , failure to standardize on a consistent basis prevents meaningful comparison or aggregation of fte data .

this was also an issue for education programs .

for example , in california , two higher education systems calculated fte differently .

in the case of one , they chose to use a 2-month period as the basis for the fte performance period .

the other chose to use a year as the basis for the fte .

the result is almost a three - to - one difference in the number of ftes reported for each university system in the first reporting period .

although education provides alternative methods for calculating an fte , in neither case does the guidance explicitly state the period of performance of the fte .

omb's decision to convert jobs into ftes provides a consistent lens to view the amount of labor being funded by the recovery act , provided each recipient uses a standard time frame in calculating the fte .

the current omb guidance , however , creates a situation where , because there is no standard starting or ending point , an fte provides an estimate for the life of the project .

without normalizing the fte , aggregate numbers should not be considered , and the issue of a standard period of performance is magnified when looking across programs and across states .

recipients were also confused about counting a job created or retained even though they knew the number of hours worked that were paid for with recovery act funds .

while omb's guidance explains that in applying the fte calculation for measuring the number of jobs created or retained recipients will need the total number of hours worked that are funded by the recovery act , it could emphasize this relationship more thoroughly throughout its guidance .

while there were problems of inconsistent interpretation of the guidance , the reporting process went relatively well for highway projects .

dot had an established procedure for reporting prior to enactment of the recovery act .

as our report shows , in the cases of education and the department of housing and urban development , which do not have this prior reporting experience , we found more problems .

state and federal officials are examining identified issues and have stated their intention to deal with them .

in our report , we make a number of recommendations to omb to improve the consistency of fte data collected and reported .

omb should continue to work with federal agencies to increase recipient understanding of the reporting requirements and application of the guidance .

specifically , omb should clarify the definition and standardize the period of measurement for ftes and work with federal agencies to align this guidance with omb's guidance and across agencies ; given its reporting approach , consider being more explicit that “jobs created or retained” are to be reported as hours worked and paid for with recovery act funds ; and continue working with federal agencies and encourage them to provide or improve program - specific guidance to assist recipients , especially as it applies to the full - time equivalent calculation for individual programs .

given some of the issues that arose in our review of the reporting process and data , we also recommend that omb should work with the recovery board and federal agencies to re - examine review and quality assurance processes , procedures , and requirements in light of experiences and identified issues with this round of recipient reporting and consider whether additional modifications need to be made and if additional guidance is warranted .

in commenting on a draft of our report , omb staff told us that omb generally accepts the report's recommendations .

it has undertaken a lessons - learned process for the first round of recipient reporting and will generally address the report's recommendations through that process .

as recipient reporting moves forward , we will continue to review the processes that federal agencies and recipients have in place to ensure the completeness and accuracy of data , including reviewing a sample of recipient reports across various recovery act programs to assure the quality of the reported information .

as existing recipients become more familiar with the reporting system and requirements , these issues may become less significant ; however , communication and training efforts will need to be maintained and in some cases expanded as new recipients of recovery act funding enter the system .

in addition to our oversight responsibilities specified in the recovery act , we are also reviewing how several federal agencies collect information and provide it to the public for selected recovery act programs , including any issues with the information's usefulness .

our subsequent reports will also discuss actions taken on the recommendations in this report and will provide additional recommendations , as appropriate .

while the recipient reports provide a real - time window on the use and results of recovery act spending , the data will represent only a portion of the employment effect , even after data quality issues are addressed .

a fuller picture of the employment effect would include not only the direct jobs reported but also the indirect and induced employment gains resulting from government spending .

in addition , the entitlement spending and tax benefits included in the recovery act also create employment .

therefore , both the data reported by recipients and other macroeconomic data and methods are helpful in gauging the overall employment effects of the stimulus .

economists will use statistical models to estimate a range of potential effects of the stimulus program on the economy .

in general , the estimates are based on assumptions about the behavior of consumers , business owners , workers , and state and local governments .

neither the recipients nor analysts can identify with certainty the impact of the recovery act because of the inability to compare the observed outcome with the unobserved , counterfactual scenario ( in which the stimulus does not take place ) .

at the level of the national economy , models can be used to simulate the counterfactual , as cea and others have done .

at smaller scales , comparable models of economic behavior either do not exist or cover only a very small portion of all the activity in the macroeconomy .

our report discusses a number of the issues that are likely to affect the impact of the recovery act , including the potential effect of different types of stimulus .

we also discuss state and sectoral employment trends and that the impact of the recovery act will vary across states .

the employment effects of recovery act funds are likely to vary with the condition of a state's labor market , as measured by its unemployment rate .

labor markets in every state weakened over the course of the recession , but the degree to which this has occurred varies widely across states .

figure 3 illustrates this — it shows the geographic distribution of the magnitude of the recession's impact on unemployment as measured by the percentage change in unemployment between december 2007 and september 2009 .

the impact of funds allocated to state and local governments will also likely vary with states' fiscal conditions .

finally , let me provide the committee with an update on allegations of fraud , waste , and abuse made to our fraudnet site .

as of november 13 , 2009 , fraudnet has received 106 recovery act – related allegations that were considered credible enough to warrant further review .

we referred 33 allegations to the appropriate agency inspectors general for further review and investigation .

our forensic audits and special investigations unit is actively pursuing 8 allegations , which include wasteful and improper spending ; conflicts of interest ; and grant , contract , and identity fraud .

another 9 are pending further review by our criminal investigators , and 15 were referred to other gao teams for consideration in their ongoing work .

we will continue to monitor these referrals and will inform the committee when outstanding allegations are resolved .

the remaining 41 allegations were found not to address waste , fraud , or abuse ; lacked specificity ; were not recovery act - related ; or reflected only a disagreement with how recovery act funds are being disbursed .

we consider these allegations to be resolved and no further investigation is necessary .

mr. chairman and members of the committee , this concludes my statement .

i would be pleased to respond to any questions you may have .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

the published product may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

