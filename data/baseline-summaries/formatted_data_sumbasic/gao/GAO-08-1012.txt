the u.s. census bureau ( bureau ) estimates that even after adjusting for inflation , the 2010 decennial census will be the most expensive census in our nation's history , costing from $13.7 billion to $14.5 billion .

the bureau estimates that more than $2 billion will be used to employ temporary field staff for nonresponse follow - up — its largest field operation where enumerators interview households that did not return census forms .

increasing the response rate would reduce the number of households that bureau field staff must visit during this nationwide operation .

according to bureau officials , a 1 percent increase in the response rate can save $75 million .

the bureau expects to hire over 700,000 temporary workers to conduct nonresponse follow - up with about 47 million households over the course of 10 weeks in 2010 .

the bureau initially based the schedule , staffing , and funding it needed for nonresponse follow - up on an estimated national response rate of 69 percent .

however , in february 2008 , the director of the bureau initiated a replanning of the field data collection automation program — a major acquisition that includes systems ; equipment , including handheld computers ; and infrastructure for field staff to use in collecting data for the 2010 census .

after analyzing several options to revise the design of the 2010 decennial census , on april 3 , 2008 , the secretary of commerce announced that the bureau would no longer use handheld computers in nonresponse follow - up and revised the estimated national response rate from 69 percent to 64 percent .

the bureau estimated that this option would result in a cost increase of $2.2 billion to $3 billion over the previously reported cost estimate of $11.5 billion .

to address your concerns about reducing the cost of nonresponse follow - up operations , we reviewed the bureau's estimated response rate and plans for increasing response .

specifically , we ( 1 ) analyzed how the bureau develops , supports , and updates the response rate estimate , and the extent to which the bureau uses the estimate to inform its 2010 planning efforts ; ( 2 ) described the methods the bureau considered for increasing response rates in 2010 and what it did to test these methods ; and ( 3 ) assessed how the bureau identifies and selects for testing methods to increase response rate , including considering other surveys' methods for increasing response .

to meet these objectives , we reviewed documentation to support the components of the response rate estimate and research literature on methodologies to increase response to mail surveys and efforts to estimate survey response rate .

we analyzed bureau documents related to 2000 census evaluations , the 2010 research and testing program , the 2010 census life cycle cost estimate , and the communications campaign .

we also interviewed bureau officials in the decennial management division and other divisions about methods to increase self - response .

further , we interviewed experts on survey methodology from statistics canada , the u.s. department of labor's bureau of labor statistics , and various academic institutions , as well as former census bureau officials and researchers .

we asked the experts a common set of questions in order to compare responses and identify recurring themes .

appendix i includes a list of experts we interviewed and additional information on our scope and methodology .

we conducted our review from july 2007 through september 2008 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in 1970 , the bureau moved away from conducting the census door - to - door and began mailing census questionnaires to households to be filled out and returned by mail .

since the 1970 census , the bureau has used mail as the primary method for collecting census data .

for census 2000 , the mailout / mailback method was used for more than 80 percent of the population .

households that fail to mail back the census questionnaires are included in nonresponse follow - up workload , where enumerators follow up with door - to - door visits and telephone calls or solicit census data from knowledgeable people , such as neighbors .

the census response rate declined dramatically from 1970 through 1990 .

the 1970 response rate was 78 percent .

the rate decreased to 75 percent for the 1980 census and then decreased again to 65 percent for the 1990 census .

although the bureau estimated that the 2000 census response rate would continue to decline to 61 percent , actual response exceeded the estimate , reaching 65 percent for the mailout / mailback universe prior to nonresponse follow - up .

the response rate is defined as the percentage of census forms completed and returned for all housing units that were on the bureau's address file eligible to receive a census questionnaire delivered by mail or by a census enumerator .

the denominator used in calculating the response rate includes vacant housing units and other addresses that were determined to be undeliverable or deleted through other census operations .

since 1970 , per household census costs have increased ( in constant 2010 dollars ) from about $14 in 1970 to an estimated $88 in 2010 — a figure that does not include the recent , major redesign of the field data collection automation program .

according to the bureau , factors contributing to the increased costs include an effort to accommodate more complex households , busier lifestyles , more languages and greater cultural diversity , and increased privacy concerns .

in addition , the number of housing units — and hence , the bureau's workload — has continued to increase .

the bureau estimated that the number of housing units for the 2010 census will increase by almost 14 percent over 2000 census levels ( from 117.5 million to 133.8 million housing units ) .

as a result of multiple factors , the total inflation - adjusted life cycle cost for the decennial census has increased more than tenfold since 1970 , as shown in figure 1 .

the bureau conducts its testing , evaluation , and experimentation program for the decennial census primarily through the decennial statistical studies division .

the division develops and coordinates the application of statistical techniques in the design and conduct of decennial census programs .

the bureau conducts various tests throughout the decade to determine the effect and feasibility of form or operational changes .

for example , in the 1990s , the bureau tested whether adding a mandatory response message and implementing a multiple mailing strategy , such as sending an advance letter and reminder postcard , as shown in figures 2 and 3 , would increase the response rate .

based on positive test results , these methods were added to the census 2000 design .

the decennial statistical studies division also conducts evaluations of census operations typically using data collected as part of the decennial process to determine whether individual steps in the census operated as expected .

it is also responsible for conducting experiments during the census that may be instructive for future censuses .

these experiments usually involve using alternative processes for a subset of the population .

the bureau is working with internal and external stakeholders on defining and developing its program for experiments and evaluations for the 2010 census , known as census program for evaluations and experiments , with design work and implementation starting in 2008 and continuing through 2011 .

the final set of activities would include analysis , documentation , and presentation of the research , and these activities would start in 2009 and be completed by the end of fiscal year 2013 .

the bureau developed the response rate estimate for the 2010 census in 2001 but could not demonstrate support for one of the three components underpinning the estimate .

to establish the 2010 estimate , bureau officials told us that they used census 2000 mail response data as the baseline and then incorporated three other components to arrive at a response rate estimate of 69 percent: an increase in response related to eliminating the long form and moving to a short - form - only census , an increase in response related to sending a replacement questionnaire to nonresponding households , and a general decline in mail response due to decreasing public participation in surveys .

the components of the estimate are outlined in figure 4 , and a detailed explanation of the baseline and each component follows .

the baseline repone rte i the rte chieved in milot / milback reas in census 2000 when the nonrepone follow - p worklod was identified .

tritioning to hort - form - only census expected to increase reponecause the long form , ent to one - ixth of the poption in the past , has lower repone rte hitoriclly .

miling replcement qtionnire to ll household tht hve not reponded certin dte has een hown to increase mil repone in te .

prticiption i expected to decline asrt of trend of decreasing public prticiption in survey .

included in the baseline national response rate of 65 percent are the effects of methods , such as the multiple mailing strategy and the communications campaign ( called the partnership and marketing program ) that were implemented in census 2000 and are planned to be implemented in the 2010 census as well .

bureau officials stated that the communications campaign , which included paid advertising , had an impact on the response rate achieved in 2000 , but were unable to quantify that effect and did not project the campaign's effect for 2010 .

the bureau estimated an increase of 1 percentage point from eliminating the long form and moving to a short - form - only census .

the bureau conducted an analysis comparing census 2000 response rates for the short form and the long form .

even though the difference in response rates for the two form types was rather large — the short form had a response rate that was more than 10 percentage points higher than the long form — the overall effect on the response rate estimate was small because the long form was sent to only approximately 17 percent of housing units in 2000 .

in 2001 , the bureau expected that sending a replacement questionnaire to households that had not responded by a certain date would increase the response rate by 7 percentage points .

the magnitude of this component was based on test results from the 1990s , which showed an increase in the response rate related to the replacement mailing of at least 7 percentage points , and possibly 10 percentage points or more .

bureau officials stated that they estimated this effect conservatively because they assumed that a higher response rate from a replacement questionnaire is more likely to occur in tests than in the decennial census .

also , testing showed that not all the respondents who return replacement questionnaires would be removed from the nonresponse follow - up workload prior to being enumerated because of the timing of the enumerator's visit .

the bureau estimated a decrease of 4 percentage points from the baseline level due to what it believes is a decline over time in public survey participation .

however , this assumption is not supported by quantitative analysis or research studies but rather based on the opinion of subject matter experts and senior officials .

further , the bureau could not demonstrate who was consulted , when they were consulted , or how they decided on the amount of the general decline .

best practices for cost estimation from our cost assessment guide call for documenting assumptions and data sources used to develop cost estimates , such as the general decline component of the response rate estimate .

in addition , several experts we interviewed agreed that the bureau should have used quantitative analysis of mail response data from other surveys to support the general decline component when it developed the estimate in 2001 .

to help support the general decline component , we suggested that the bureau use changes in participation in the american community survey , which uses a similar mailing strategy to the decennial census and for which response is also required by law , for comparison purposes .

in may 2008 , the bureau completed an analysis of american community survey response rate data from 2000 to 2007 , which demonstrated a decline of 6.6 percentage points in cooperation rates to the initial questionnaire .

although the decline in response to the american community survey may not be directly comparable to response behavior for the decennial census , it provides some support for the bureau's assumption that mail survey participation may be declining .

the bureau does not have procedures for developing the response rate estimate .

specifically , the bureau has no established policies for documenting deliberations related to or data sources used in developing the estimate , including no 2010 census decision memorandum to document the original estimate prepared in 2001 .

several experts also suggested that the bureau should develop a model for developing the estimate and incorporate response rate data and demographic data from other surveys .

bureau officials , however , noted that they have not determined how to apply data from other surveys to estimate the census response rate because the census differs from other surveys , nor do they plan to develop a model of the response rate estimate .

instead , bureau officials stated that they tried to conservatively estimate the response rate to ensure that they are adequately prepared during nonresponse follow - up and to avoid repeating what happened in 1990 , when the bureau overestimated the response rate , requiring a supplemental appropriation of $110 million and forcing it to extend nonresponse follow - up by up to 8 weeks for some areas .

in contrast , in 2000 the response rate exceeded the bureau's estimate .

conservatively estimating the response rate may be a reasonable approach .

however , having clear , detailed documentation about decisions related to or data sources used in developing the estimate would enable the bureau and others to better assess whether the estimate is reliable , such as whether its assumptions are supported and realistic .

an unreliable response rate estimate can produce an inaccurate cost estimate and can increase risk and uncertainty to operational plans that are based on the response rate estimate .

although the bureau updated the response rate estimate as a result of a major redesign of census operations undertaken in april 2008 , the bureau still lacks procedures for establishing when and how to reevaluate the response rate estimate .

from 2001 through april 2008 , the bureau did not reevaluate the estimate to determine whether it should be updated , even though , after establishing the initial estimate in 2001 , the bureau completed several evaluations from census 2000 and conducted several census tests that could have informed the estimate .

during the first few years of the decade , the bureau completed 12 evaluations that discussed aspects of the census 2000 response rate .

in addition , the bureau conducted five tests from 2003 through 2007 that were designed , in part , to test methods to increase response .

for example , in 2005 and 2007 , the bureau tested a two - column bilingual form , which includes identical questions and response options in english and spanish .

the 2005 test demonstrated a significant positive effect on mail response rates of 2.2 percentage points overall , and a 3.2 percentage point increase in areas with high concentrations of hispanic and non - white populations , and the 2007 test revealed a similar impact .

however , bureau officials stated that they were concerned that the two - column bilingual form has not been tested in a census environment .

in addition , they noted that the bilingual form will be sent to only a portion of the country — approximately 10 percent of census tracts — with high concentrations of spanish - speaking populations , based on american community survey data .

best practices state that assumptions , such as the response rate estimate , should be revised as new information becomes available .

our cost assessment guide recommends that preliminary information and assumptions be monitored to determine relevance and accuracy and be updated as changes occur to reflect the best information available .

further , according to several experts , the bureau could have updated the estimate based on response rate data and demographic data from other surveys , and another expert suggested that the bureau use triggering events , such as after tests , for reviewing the response rate estimate .

based on this expert's experience , the bureau could establish a change control board chaired by senior bureau officials to determine whether the response rate estimate should be revised .

however , bureau officials explained that they do not update the estimate based on results from tests because the tests cannot replicate the decennial census environment .

overall , the bureau has not specified when or how it is to reevaluate its response rate estimate .

establishing these procedures would help the bureau ensure that the estimate is current and reliable in order to better inform planning efforts .

the bureau revised the estimate down to 64 percent after announcing that nonresponse follow - up would be changed from an automated to a paper - based operation .

prior to the redesign , the bureau had planned to reduce the nonresponse follow - up workload by using handheld computers to remove households that returned their forms late — including many replacement mailing returns — from the enumerator assignments on a daily basis .

according to bureau officials , they revised the response rate estimate based on the timing of mail returns in 2000 and replacement questionnaire returns in the 2003 test .

however , the revised estimate does not fully reflect recently designed procedures to remove late mail returns in 2010 .

specifically , for 2010 the bureau now plans to mail the replacement questionnaire earlier , send a blanket replacement questionnaire to some areas and a targeted replacement questionnaire to others , and conduct three clerical removals of late mail returns immediately prior to and during the nonresponse follow - up operation .

these operational plans are still being finalized pending further analysis .

bureau officials said that although they hope that these revised operations will increase response , they did not update the response rate estimate to reflect these current operational plans because they have not tested this approach under decennial census conditions and therefore have no basis for estimating the potential effect of these operational changes on response .

to estimate costs and to plan for activities such as nonresponse follow - up , questionnaire printing , and postage needs , the bureau uses a life cycle cost model that relies on response rate estimates for four primary lco types and not the national estimate .

using lco - type estimates helps to account for expected differences in response patterns across geographic settings .

for example , response rates for inner - city areas are estimated to be lower than in suburban areas .

these estimates range from 55 percent to 72 percent , but lack support for how they were developed .

in determining the 2010 response rate estimates for the four lco types , the bureau said that it equally applied two components from the national estimate — the replacement mailing component and the short - form - only component — to the lco types in the cost model .

however , the bureau did not conduct quantitative analysis to determine whether the replacement mailing component in the national estimate should be applied equally for each lco type .

by applying an equal percentage point increase across all lco types for the replacement mailing , the bureau has , in effect , assumed that the lco type with the lowest baseline — 48 percent — would experience a higher relative increase in response — 15 percent — due to the replacement mailing than the lco type with the highest baseline — 65 percent — which would be expected to experience an 11 percent increase in response .

the bureau has not demonstrated support for assuming that the lco types will experience these different relative increases in response .

further , the bureau could not demonstrate whether or how the short - form - only component and the general decline component of the national estimate were reflected in the life cycle cost model .

best practices for cost estimation from our cost assessment guide call for assumptions to be thoroughly documented , data to be normalized , and each cost element to be supported by auditable and traceable data sources .

following these best practices could allow the bureau to enhance its use of the response rate estimate in planning for the decennial census and better inform stakeholders about the reliability of the estimate .

it is unclear why officials could only explain how one component of the national response rate estimate was applied to lco - type estimates in the life cycle cost model .

however , according to the bureau , it is currently documenting how these estimates are used to calculate the costs for operations and how the estimates have changed over time .

having support for the lco - type estimates would better inform the bureau's planning efforts for operations that directly rely on response , such as determining workload and hiring enumerators for nonresponse follow - up .

we determined from reviewing bureau testing documents that through various national and field tests and experiments , the bureau tested nine methods to increase self - response to the 2010 census , as shown in table 1 .

the bureau currently plans to implement two of these methods — the replacement questionnaire and two - column bilingual form ( see fig .

5 ) .

three other methods for increasing mail response and four methods for increasing response through an electronic data collection system were tested but are not planned for implementation in 2010 .

an additional method the bureau plans to include in the 2010 census to increase response , the integrated communications campaign , has not been tested , although the bureau conducted a similar campaign in 2000 and plans to test campaign messages with audiences in early 2009 .

additional details regarding the testing of these methods can be found in appendix ii .

for the 2010 census , the bureau does not plan to include three methods it tested to increase mail response , as shown in figures 6 , 7 , and 8 .

two of these methods — a telephone reminder call and messaging to distinguish the initial and replacement questionnaires — were not found to significantly improve response and therefore will not be implemented as part of the 2010 census .

the third method — including a due date on the initial mailing package — was found to generate faster responses when tested in 2003 , and increase overall response by 2 percentage points when tested in conjunction with a compressed mailing schedule in 2006 .

however , the bureau also believes that the use of a due date alone could cause a lower response rate because some people may not send back the census form after the due date .

according to bureau officials , they are not including this method in the decennial census design because they would like to further test it — both with and without a compressed mailing schedule — in a census environment .

it will be important for the bureau to optimize this testing opportunity by designing the test to determine the extent to which the faster and higher response is due to a compressed schedule versus a due date , as well as exploring other test treatments the bureau has recommended in the past , such as including the due date on multiple mailing pieces .

bureau officials said that additional testing on the use of a due date will be conducted as part of the 2010 census program for evaluations and experiments , which the national academy of sciences recommended in its december 2007 interim report .

the bureau did not provide further details on plans for the census program for evaluations and experiments , but officials have said that they will consider costs and staffing needs in deciding what to evaluate .

the academy's final report is due in september 2009 .

in addition to testing methods to increase mail response , the bureau also tested four methods to increase self - response through electronic data collection systems: ( 1 ) providing for response via an interactive voice response system ; ( 2 ) sending a letter to encourage either responding via internet or returning the initial questionnaire , instead of sending a replacement questionnaire ; ( 3 ) using computer - assisted telephone interviewing ; and ( 4 ) providing capability for responding via the internet .

the bureau found that the first two methods did not increase response in tests and does not plan to include them in the 2010 census .

computer - assisted telephone interviewing allows respondents to use the telephone to connect with operators who record interview responses electronically .

the bureau found that this method increased the overall response rate in a census 2000 experiment .

however , in a march 2004 report , the bureau also stated that the method would likely be too costly in terms of hardware , software , and staffing resources , compared to the increase in response it might generate .

computer - assisted telephone interviewing was not tested after the 2000 census .

although the internet option was found to increase overall response during the census 2000 experiment , it did not increase overall response when tested again in 2003 , when a replacement mailing was also tested .

according to a july 2006 bureau decision memo titled , “rationale for the decision to eliminate the internet option from the dris contract,” the bureau decided not to include the internet option in the design of the 2010 census largely because it had underestimated the costs of the contract that included developing the internet response option .

in responding to a draft of this report , the bureau stated that they made the decision because test results showed that offering the internet option did not increase overall response and would not offer any cost savings .

according to the 2006 memo , the bureau also determined that the operational risks and costs to develop this option outweighed the potential benefits .

in terms of benefits , the bureau found improvements in data completeness and data timeliness from internet responses in tests conducted in 2000 / 2001 for the american community survey and in 2003 and 2005 for the national census tests .

the bureau noted that these benefits could translate into reduced costs since less follow - up is required to improve data accuracy , and earlier receipt of responses could result in fewer replacement questionnaires that need to be mailed and fewer households that need to be enumerated during nonresponse follow - up .

however , with only 6 to 7 percent of the test population using the internet option , the bureau concluded that no cost savings could be realized from reducing the number or size of data capture centers ( facilities that process returned questionnaires ) planned for 2010 .

finally , the bureau stated that the inability to fully test the internet option and growing concerns about internet security made it unfeasible for the bureau to implement the internet as a response option for 2010 .

despite its july 2006 decision , the bureau recently announced that it is considering including the internet option as part of the 2010 census design ; however , the bureau has not developed plans for further testing this option .

through its contractor and subcontractors , the bureau has taken a number of steps to inform the planning of the communications campaign but has not yet fully developed the campaign's testing and evaluation plans .

from late 2006 through early 2008 , focus groups were conducted with various ethnic groups and hard - to - count populations , such as unattached singles , to identify potential barriers and motivators to participation , to better understand methods of communication that work for different groups , and to develop the campaign's overall creative expression .

the bureau also developed an audience segmentation model using census 2000 response data , updated through 2006 using american community survey data , to provide a more detailed understanding of the characteristics , such as home ownership and unemployment level , of those more or less likely to respond , as well as where they live , in order to better target communications to encourage census participation .

in addition , in 2008 , a national phone and in - person survey is being conducted to further explore barriers and motivators to response , particularly in hard - to - count populations , which would inform campaign message development .

according to agency officials , beginning in early 2009 , campaign messages are to be tested by showing storyboards to audiences that will use electronic devices to vote on the messages .

these messages will be tested in 14 languages and for other populations , such as spanish speakers in puerto rico .

according to the draft plan , testing of events , partnership toolkits , promotional items , and public relations ideas will also be conducted .

however , the bureau has not yet developed detailed plans for this testing because , according to one official , the bureau intends to further develop testing plans as future fiscal year funding amounts become available .

an example of a census 2000 communications campaign poster is shown in figure 9 .

in addition , although the bureau expects to award a contract by the end of fiscal year 2008 for an independent evaluation measuring the campaign's performance against its goals of increasing mail response , improving accuracy , and reducing the differential undercount , and improving cooperation with enumerators , it has not yet done so .

in the past , the bureau has said that although evaluations have shown that the census 2000 communications campaign increased awareness for that census , it was difficult to link increased awareness to changes in respondent behavior .

bureau officials said that they have attempted to analyze census 2000 data to identify factors that influence behavior , but their research results were inconclusive .

going forward , it will be important for the bureau to determine its plans for evaluating the 2010 communications campaign so that it does not miss opportunities to collect data in the census environment to inform future campaigns .

for 2010 , the bureau developed a strategy to identify various methods to test for increasing response .

specifically , the bureau established test objectives and research questions , such as identifying the optimal mix of response options for the public to respond to the 2010 census and determining security and confidentiality issues surrounding technology .

the bureau also developed the 2010 census integrated program plan and 2010 census operations and systems plan to better document its planning .

however , bureau officials did not document the methods that they considered but decided not to test in the 2010 testing cycle or the rationale behind those decisions .

further , for methods that the bureau decided to test , officials could not provide support for how they selected or prioritized these methods .

although officials said that they considered cost , complexity of the test , and compatibility of experiments in their decisions , they did not specify how they defined or weighed these factors to select and prioritize the nine methods they chose to test .

to ensure thorough and comprehensive planning of the decennial census , our past work on lessons learned from census 2000 highlighted the importance of documentation to support research , testing , and evaluation , and a comprehensive and prioritized plan of goals , objectives , and projects .

while the bureau has developed the 2010 census integrated program plan and 2010 census operations and systems plan to better document its planning , these and other planning documents we reviewed did not provide support for how the bureau selected and prioritized methods to test .

it is unclear why the bureau lacks procedures for documenting decisions concerning how it selected for testing methods to increase response .

documenting decisions about methods that were not selected for testing would help the bureau more effectively build capacity and institutional knowledge about changes in methods to consider in the future .

according to bureau officials , they consider the experience of other survey organizations when identifying methods for increasing response rate .

for example , they said that they attend research conferences to learn about experiences of other organizations that conduct national surveys to identify potential methods to increase response rate .

both bureau officials and some survey experts noted that methods used to increase response in other surveys may only be indirectly applicable to the decennial census .

for example , for the economic census , officials said that the bureau sends nonresponding businesses multiple reminder letters ; the final letter to large businesses informs them that the department of justice will be pursuing nonrespondents .

bureau officials said that these methods are less feasible for the decennial census to implement because of the shorter time frame for obtaining responses and concerns about being respondent - friendly to households .

in addition , one survey expert noted that methods applicable to small - scale surveys , such as personalizing a cover letter , may be less feasible to implement for the decennial census .

further , survey experts we interviewed generally said that they were unaware of additional methods from censuses undertaken by other countries or private sector surveys that the bureau could consider to increase mail response .

some experts noted differences between how the united states and other countries conduct their censuses , which may make it difficult to directly transfer other countries' practices to the u.s. census .

for example , some european censuses use a population register to collect names , unlike the united states , which builds its survey frame from phone and address lists .

in addition , past research has provided evidence that government - sponsored self - administered surveys , such as the decennial census , tend to achieve higher response rates than nongovernmental surveys .

nonetheless , testing modifications to methods that the bureau has previously considered or tested in earlier studies may yield additional opportunities for increasing response .

for example , the bureau could test various telephone reminder messages stating that response is mandatory by law or providing instructions for obtaining a new census form .

although bureau officials said that they have previously used the american community survey to inform the census design , analyzing respondent behavior to the american community survey , because of its similar mailing strategy to the decennial census , could help the bureau regularly refine its survey methodology for increasing census response .

although the survey forms are different , many concepts , such as targeting the second mailing , modifying the appearance of the mailing , and varying telephone and internet messages to prompt nonrespondents , could be tested with reasonable inference to the census .

nonresponse follow - up is the largest field operation , and the bureau estimates that it will cost more the $2 billion .

to control the cost of nonresponse follow - up , it will be important for the bureau to devise a strategy for getting people to return their census forms .

a reliable response rate estimate is a critical element necessary for determining the resources needed to carry out nonresponse follow - up .

the bureau did not have support for one of the components of the 2010 response rate estimate — a general decline in responsiveness — and the bureau does not have procedures for reviewing the estimate after testing to determine whether it should be revised .

establishing procedures for developing the response rate estimate , including documenting data sources and decisions , would enable the bureau and others to better assess the estimate's reliability .

also , establishing procedures for when , such as after tests or other triggering events , and how to reevaluate the estimate would help the bureau ensure that it is providing the most current response rate estimate for planning nonresponse follow - up and other activities , such as questionnaire printing .

the bureau's strategy of estimating the response rate conservatively may be prudent given past difficulties with conducting nonresponse follow - up after overestimating the response rate in 1990 .

nonetheless , establishing and following procedures for developing , documenting , and reevaluating the estimate are important steps for understanding differences between the estimate and the actual response rate for 2010 and for evaluating the components and underlying assumptions when developing the estimate for the next census .

successful enumeration depends on early research , testing , and evaluation of census methods to increase response .

establishing procedures for selecting and prioritizing the testing of methods — such as the internet or reminder telephone call — including documenting methods considered but not tested , would help the bureau demonstrate that it has chosen an optimal research strategy for the decennial census , more effectively build capacity and institutional knowledge about changes in methods to consider in the future , and enable it to more efficiently begin testing for the next census .

to enhance credibility of the response rate for determining cost and planning for future census activities , to inform assumptions underlying the 2020 response rate estimate , and to improve the planning and transparency of the bureau's research and testing , we are recommending that the secretary of commerce direct the bureau to take the following three actions: establish procedures for developing the 2020 response rate estimate , including documenting the data sources supporting the estimate's components and decisions that are made in establishing the components and analyzing 2010 data to assess the reasonableness of assumptions used in applying the national estimate's components to the lco - type estimates .

establish procedures for reevaluating and updating the 2020 estimate , including identifying events or changes in related operations that should trigger a review and documenting the results of such reviews .

establish procedures for selecting methods for increasing response rate that will be the subject of research and testing , including requirements for documenting how the bureau defines and weighs factors used to select methods and documentation on methods considered but not tested .

the secretary of commerce provided written comments on a draft of this report on september 22 , 2008 .

the comments are reprinted in appendix iii .

commerce generally agreed with our conclusions and recommendations and stated that the bureau is committed to developing and implementing a documented , systematic methodology for establishing response rate estimates for future censuses and reevaluating the estimates throughout the decade .

because the recommendations in our draft report focused on costs and planning for the 2010 census , we revised our recommendations to reflect actions to be taken to support future census planning , including analyzing 2010 data to assess the reasonableness of assumptions used in applying the national estimate's components to the lco - type estimates .

commerce also provided technical corrections , which we incorporated as appropriate .

in its comments , commerce disagreed with our statement that the internet response option increased response in the census 2000 experiment .

commerce cited a summary statement from a bureau report that concluded that the use of multiple response modes tested in 2000 does not increase response .

however , bureau analyses from october 25 , 2002 , and march 2004 on the census 2000 experiment stated that the overall response rate increased when the internet was offered as an alternative response mode .

we therefore made no changes in the report .

commerce strongly disagreed with our statement about the reason why the bureau decided not to include the internet option in the design of the 2010 census .

in the report , we state that underestimating contract costs was the primary reason the bureau eliminated the internet option , which we attribute to a july 19 , 2006 , memo documenting the bureau's rationale for eliminating the internet response option from the decennial response integration system ( dris ) contract .

this memo states that the decision “was due largely to the fact that the census bureau underestimated the fy 2006-2008 contractor costs proposed to develop dris.” we therefore left this statement unchanged .

however , we added the bureau's explanation provided in its agency comment letter that the decision was based on test results , which showed that offering this option did not increase overall response and would not offer any cost savings .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days after its issue date .

at that time , we will send copies of this report to the secretary of commerce , the department of commerce's inspector general , the director of the u.s. census bureau , and interested congressional committees .

we will make copies available to others upon request .

this report will also be available at no charge on gao's web site at http: / / www.gao.gov .

if you or your staff have any questions concerning this report , please contact mathew j. scirè at ( 202 ) 512-6806 or sciremj@gao.gov or ronald s. fecso at ( 202 ) 512-2700 or fecsor@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iv .

the objectives of this report were to ( 1 ) assess how the u.s. census bureau ( bureau ) develops , supports , and updates the response rate estimate , and the extent to which the bureau uses the response rate estimate to inform its 2010 planning efforts ; ( 2 ) describe the methods the bureau considered for increasing response rates in 2010 and what it did to test these methods ; and ( 3 ) assess how the bureau identifies and selects for testing methods to increase response rates , including considering other surveys' methods for increasing response .

the scope of our review was limited to the census mailout / mailback universe , which covered more than 80 percent of households in census 2000 .

the majority of households in this category have standard city - style addresses , allowing them to receive their census questionnaires in the mail in addition to being expected to return their questionnaires by mail .

we excluded from our review operations and methods aimed at enumerating those not included in the mailout / mailback universe , such as the be counted initiative and enumeration at transitory locations ; those initiatives related to , but not primarily focused on , increasing self - response , such as improving the quality of the master address file and providing assistance through questionnaire assistance centers ; methods tested prior to 2000 and already implemented in previous censuses ; and those primarily intended to improve operational efficiency , such as postal tracking .

to determine how the bureau develops and uses the response rate estimate , we reviewed documentation to support the components of the response rate estimate and research literature on efforts to estimate survey response rate .

we interviewed bureau officials in the decennial management division about the process used to develop and update the estimate , the assumptions on which the estimate is based , and how the estimate is used .

we also interviewed experts on survey methodology from statistics canada , the u.s. department of labor's bureau of labor statistics , and various academic institutions , as well as former census bureau officials and survey methodologists to obtain their views on the strengths and weaknesses of the bureau's process for developing and updating the estimate .

we compared responses to a common set of questions we asked the experts in order to identify themes .

we also reviewed bureau strategic planning documents — in particular , the 2010 census life cycle cost model with supporting documentation , as well as the 2010 census integrated program plan and the 2010 census operations and systems plan — to understand the bureau's use of the estimate , and evaluated the bureau's practices for using the response rate estimate for generating the life cycle cost estimate against best practices criteria in our cost assessment guide and other relevant gao products .

to describe the methods the bureau considered for increasing response rates in 2010 and how the bureau tested these methods , we reviewed bureau analyses and evaluations of tests on methods to increase mail response and various bureau planning documents , such as the 2010 census operations and systems plan .

in addition , we reviewed documentation on the bureau's communications campaign , such as evaluations of the 2000 partnership and marketing program and the 2010 census integrated communications campaign plan .

we interviewed bureau officials in the decennial management division to obtain additional context about the methods they considered and tests they conducted .

to assess how the bureau identifies and selects methods to test for increasing response rates , we reviewed various bureau planning documents , such as research and development planning group action plans , for factors that the bureau considers in selecting methods to test .

we interviewed bureau officials in the decennial management division and other divisions about the process for identifying and selecting methods for increasing response .

we also reviewed our past work on lessons learned from census 2000 on the importance of documentation and planning in order to evaluate the bureau's process for selecting and prioritizing methods to test .

we interviewed experts on survey methodology from statistics canada , the u.s. department of labor's bureau of labor statistics , and various academic institutions , as well as former census bureau officials and researchers , about additional methods for increasing response that the bureau could consider and to obtain their perspectives on the bureau's process for identifying , testing , and implementing methods .

we compared responses to a common set of questions we asked the experts in order to identify recurring themes .

we also reviewed research literature on methodologies to increase response to mail surveys to identify additional methods that the bureau could consider .

we interviewed the following experts in survey methodology: anil arora , director general , census program branch , statistics paul biemer , distinguished fellow in statistics , research triangle don a. dillman , regents professor , thomas s. foley distinguished professor of government and public policy , and deputy director for research and development in the social and economic sciences research center , washington state university , and former senior survey methodologist , u.s. census bureau elizabeth martin , former senior survey methodologist , u.s. census colm o'muircheartaigh , vice president for statistics and methodology , national opinion research center and professor , irving b. harris graduate school of public policy studies , university of chicago kenneth prewitt , carnegie professor of public affairs , school of international and public affairs , columbia university and former director , u.s. census bureau clyde tucker , senior survey methodologist , bureau of labor statistics we conducted our review from july 2007 through september 2008 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

replacement mailing .

the bureau plans to include the replacement mailing in the 2010 census design .

the replacement mailing involves sending a new questionnaire to households after households have received the initial census questionnaire in order to increase the likelihood that households will respond .

the bureau tested a targeted replacement mailing — where households that have not returned their initial questionnaires by a cutoff date receive the replacement form — in the early 1990s and found that this method resulted in a 10 to 12 percent increase in the mail response rate .

a blanket replacement mailing — where all households received a replacement questionnaire , including those that had already responded — was planned for census 2000 , but the bureau dropped it from the design because of operational concerns that became apparent in the 1998 dress rehearsal .

a targeted replacement mailing was incorporated into the 2010 design , based on the test results from the 1990s and the bureau's plans to move to a short - form - only census .

in 2003 , the bureau tested the targeted replacement mailing and was able to confirm the results of the tests from the early 1990s .

subsequent testing of the replacement mailing focused on ensuring that the bureau could implement it successfully , including processing and removing the returns from the nonresponse follow - up workload using the handheld computers .

the decision to eliminate the handheld computers from nonresponse follow - up and make nonresponse follow - up a paper - based operation diminished the bureau's ability to remove late mail returns ( including replacement questionnaires that are returned ) from the nonresponse follow - up workload .

the bureau then examined options to get a better effect from the replacement mailing and decided to try to get the replacement mailings out more quickly .

in order to do this , the bureau decided that it would send a blanket replacement mailing to census tracts identified as low response areas , based on census 2000 response data and updated demographic data from the american community survey .

the replacement mailing packets for these tracts can be printed and labeled in advance — approximately 25 million total .

households not in these areas will receive a replacement questionnaire on a targeted basis — that is , only if they are in census tracts identified as medium response areas and if their initial questionnaires have not been received by the cutoff date .

the bureau estimates that it can print and label 15 million of these targeted replacement mailing packages in 4 days .

under this schedule , the bureau will finish mailing out the replacement questionnaires on april 8 , whereas under the original plan the replacement questionnaire mail out would not be completed until april 19 .

as a result , more households should be able to return the replacement questionnaires in time to be removed from the nonresponse follow - up workload .

two - column bilingual form .

the bureau plans to use a two - column bilingual form in certain locations in 2010 .

the two - column bilingual form provides two response columns , one in english and one in spanish .

each column contains the same questions and response options , and respondents are instructed to choose the language that is most comfortable for them .

the bureau tested the bilingual form in 2005 to determine whether it would ( 1 ) increase overall response to the census and ( 2 ) lower item nonresponse ( when a household returns the form but does not respond to a particular question ) when compared to the standard english form .

in the 2005 test , the two - column bilingual form panel demonstrated a significant positive effect on mail response rates of 2.2 percentage points overall , and a 3.2 percentage point increase in areas with high concentrations of hispanic and non - white populations , but did not achieve lower rates of item nonresponse .

the bureau conducted another test of the two - column bilingual form in 2007 , which produced response rate results similar to the 2005 results .

in 2010 , the bureau plans to mail the two - column bilingual form to households in communities with heavy concentrations of spanish speakers and areas with low english proficiency .

telephone reminder call .

the bureau does not plan to use a telephone reminder call in 2010 .

the multiple contact strategy that the bureau used in 2000 included a reminder postcard mailed 1 week after the initial questionnaire packets were mailed .

as part of the 2003 national census test , the bureau tested the effect of an automated telephone reminder call in place of a reminder postcard on increasing the mail response rate .

out of a sample of 20,000 households , the bureau was able to obtain phone numbers for 6,208 ( 31 percent ) , and these households received telephone calls to remind them to return their questionnaires if they had not already done so .

the initial results indicated a significantly higher cooperation rate for the telephone reminder call panel when compared to the control panel , which received reminder postcards .

the bureau later conducted a supplementary analysis to determine if the higher cooperation rate was related to an underlying higher propensity to cooperate among households with listed telephone numbers .

this analysis compared cooperation rates of two groups of households: those for which telephone numbers were available and those for which telephone numbers were not available .

among households for which a telephone number was available , the bureau observed no significant difference in cooperation rates for housing units that received a reminder postcard compared to those that received a reminder telephone call .

the bureau does not plan to use a telephone reminder call in place of a reminder postcard in the 2010 census .

due date on initial questionnaire mailing package .

the bureau will not place a due date on the initial questionnaire mailing package as part of the 2010 census design .

the value of placing a due date on the mailing package with the initial questionnaire is that it might evoke a sense of urgency or importance in respondents , leading to increased response to the census .

in 2003 , when the bureau tested this method , it found that the inclusion of a due date did not significantly affect the overall response rate .

however , it did result in a significantly higher response rate at an earlier point in the test , which can decrease the size of the replacement questionnaire mailing .

the bureau tested a due date again in 2006 , this time combined with a “compressed schedule,” in which questionnaires were mailed 14 days ( as opposed to 21 days , as in the control group ) before census day .

a due date for mailing the questionnaire back was given in the advance letter , on the outgoing envelope and cover letter for the questionnaire mailing , and on the reminder postcard .

the final report of the test concluded that the inclusion of the due date and compressed schedule resulted in a significantly higher mail response rate , by 2.0 percentage points .

in addition , several measures of data completeness and coverage showed significant improvement .

bureau officials decided not to include the use of a due date in the 2010 census , noting that they would like to conduct further testing to better understand the effects of a due date versus a compressed schedule .

the bureau is considering whether to test both the use of a due date and a compressed schedule in its 2010 census program for evaluations and experiments .

messaging to distinguish the replacement from the initial questionnaire .

the bureau does not plan to use a message to distinguish the replacement questionnaire from the initial questionnaire in 2010 .

the inclusion of a message on the replacement questionnaire informing respondents that they did not need to return the replacement questionnaire if they had already provided a response from the previous mailing was thought to be a way to reduce the number of multiple returns , and possibly improve overall response .

the bureau tested this method in 2005 , and while the results showed a significant decline in the submission of multiple returns , they also showed a significant decrease in the response rate of 1.2 percentage points .

including a message to distinguish the replacement from the initial questionnaire was not recommended for , and will not be included in , the 2010 census .

interactive voice response .

the bureau does not plan to use interactive voice response in 2010 .

interactive voice response allows respondents to use the telephone to respond verbally to digitized voice files that contain census questions and instructions .

speech recognition software is used to determine and record responses .

interactive voice response was tested in 2000 , with households given the choice of providing their census data via interactive voice response or a paper questionnaire .

the response rate for the interactive voice response panel was not statistically different from that of the control ( mail only ) group .

however , the results are difficult to interpret because a portion of the sample in the interactive voice response panel either received the census form late or did not receive it at all .

in 2003 , the bureau tested two different strategies for getting respondents to provide their census data using interactive voice response .

one strategy , known as a push strategy , did not include a paper questionnaire in the initial mailing but rather pushed respondents to reply using interactive voice response .

the other strategy , known as a choice strategy , included an initial paper questionnaire with the interactive voice response information on it , allowing respondents to choose their response mode .

all nonrespondents received a paper replacement questionnaire .

households that had a choice of responding via paper or interactive voice response had overall response rates similar to households that only received paper , with about 7 percent of respondents given the choice using interactive voice response .

households in the push strategy had a significantly lower response rate — 4.9 percentage points lower than households that only received a paper questionnaire .

the bureau does not plan to give respondents the option of providing their census data using interactive voice response in 2010 .

letter encouraging internet response or returning initial questionnaire instead of sending replacement questionnaire .

the bureau will not send a letter encouraging internet response or returning the initial questionnaire instead of sending a replacement questionnaire in 2010 .

instead of mailing a replacement paper questionnaire to nonrespondents , a letter could be sent to households encouraging them either to complete the paper questionnaire that they previously received or to use the internet to submit their responses .

the bureau tested this method in 2005 , sending a replacement mailing that contained a letter with an internet address and an identification number needed to access the internet questionnaire in place of a paper replacement questionnaire .

compared to sending out a paper replacement questionnaire , this method resulted in significantly fewer responses overall , decreasing the response rate by 3.7 percentage points .

the bureau will not include a letter encouraging the use of the internet instead of a replacement questionnaire in 2010 , in part because the internet option was dropped from the 2010 census design .

computer - assisted telephone interviewing .

the bureau will not use computer - assisted telephone interviewing for increasing response in 2010 .

computer - assisted telephone interviewing allows respondents to use the telephone to connect with operators , who conduct interviews and record responses electronically .

in a 2000 experiment , households were given the option of returning a paper form or providing their census data via computer - assisted telephone interviewing .

when compared to households that were only given paper questionnaires , computer - assisted telephone interviewing brought about a 2.06 percentage point improvement in the overall response rate and also had a low item nonresponse rate .

however , it entailed substantial costs for hardware , software , and programmer and interviewer time .

the bureau has not tested computer - assisted telephone interviewing since 2000 and does not plan to use this option in 2010 .

internet .

the internet response option allows respondents to use an internet - based questionnaire — with screens designed to resemble the paper questionnaire — to respond to the census .

respondents answer multiple - choice questions by clicking the appropriate buttons and checkboxes and text - entry questions by typing their answers into response fields .

the bureau gave respondents the option to respond by internet in a 2000 experiment .

some households in the test were given the choice of providing their census data via internet or a paper questionnaire .

the experiment found that the internet response option resulted in a 2.46 percentage point increase in response .

in 2003 , the bureau again tested allowing respondents the option of providing their answers via the internet by sending a paper questionnaire along with instructions for responding via the internet in the initial mailing .

households that had a choice to respond by paper or the internet had a similar overall response rate to households that were provided only paper , with about 10 percent of respondents choosing to respond by internet .

the bureau decided not to include the internet in the 2010 census , despite including it in the scope of the contract awarded in 2005 for the decennial response integration system .

the bureau noted that this decision was based on a number of factors , including the bureau's underestimation of the contractor costs for the first 3 years of the contract , as well as test results that indicated that the internet would not increase the response rate and concerns about the security of respondents' data prior to the bureau receiving it .

communications campaign .

census 2000 included a greatly expanded outreach and promotion campaign — including , for the first time , paid advertising — in an attempt to increase public awareness of and promote positive attitudes about the census .

this program , called the partnership and marketing program , was considered a success after the bureau reversed the trend of declining mail response rates , and the bureau made plans to continue the program for 2010 .

bureau officials stated that the 2010 campaign consolidates all census communications under a single communications contract .

this integrated communications campaign aims to motivate the entire populations of the 50 states , the district of columbia , puerto rico , and other u.s. territories to participate in the census through partnerships ( with community groups , businesses , colleges , faith - based organizations , and other targeted groups ) ; public relations ; events ; census in schools ; and paid advertisements in broadcast , print , and online media .

bureau officials noted that the advertising campaign would not be included in the dress rehearsal because the bureau's experience including the advertising campaign in the 1998 dress rehearsal did not provide the feedback needed to revise the creative aspects of the campaign .

to refine the communications campaign , the bureau conducted an audience segmentation analysis to identify how to best reach people with the paid advertising campaign .

in addition , the bureau conducted focus groups in 2006 and 2007 to provide information on what motivates individuals to respond .

the communications campaign is scheduled to run from mid - 2008 through june 2010 .

in 2008 and 2009 , most of the activities are focused on preparing and mobilizing partnerships .

further development of specific messages for various audiences and communication channels will take place from november 2008 through april 2009 .

starting in mid - 2009 , the partnership program will begin outreach to certain hard - to - count populations .

activities and events targeting all audiences will begin in january 2010 and peak in march 2010 .

in addition to contacts named above , lisa pearson , assistant director ; david bobruff ; don brown ; and elizabeth fan made key contributions to this report .

tom beall , susan etzel , andrea levine , donna miller , ellen rominger , and elizabeth wood provided significant technical support .

