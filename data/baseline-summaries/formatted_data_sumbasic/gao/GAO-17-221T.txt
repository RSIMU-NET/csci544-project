i am pleased to be here today to discuss the u.s. census bureau's ( bureau ) approach to delivering an enterprise information technology ( it ) initiative , referred to as the census enterprise data collection and processing ( cedcap ) program , and its efforts to ensure the integrity and security of systems and data to be used in the 2020 decennial census .

cedcap is a large and complex modernization program intended to deliver a system - of - systems for all the bureau's survey data collection and processing functions , rather than continuing to rely on unique , survey - specific systems .

cedcap is particularly important because it is intended to support significant changes in how the bureau ( which is a part of the department of commerce ) is planning to conduct the 2020 census .

specifically , the bureau is aiming to modernize and automate its outdated and inefficient methods of conducting decennial censuses .

this includes plans to significantly change the methods and technology it uses to count the population , such as offering an option for households to respond to the survey via the internet ; enabling a mobile data collection application for field - based enumerators to use on mobile devices to collect survey data from households ; and automating the management of field operations .

these new capabilities and supporting systems are expected to be delivered by cedcap .

with less than a year remaining before the census 2018 end - to - end test is to begin in august 2017 ( which is intended to test all key systems and operations to ensure readiness for the 2020 census ) , this hearing is especially timely .

my statement today will discuss ( 1 ) issues the bureau has had in managing interdependencies between the 2020 census and cedcap programs , ( 2 ) potential information security challenges the bureau faces in its redesigned 2020 census program , and ( 3 ) uncertainty about the bureau's readiness for the 2018 end - to - end test .

further , in a separate statement today , my colleague will address the bureau's progress in preparing for the 2020 census , based on 2016 census testing .

the information in this testimony is based primarily on the report we issued in august of this year , which discusses , among other things , the bureau's progress in developing , implementing , and monitoring the cedcap program .

more details on our scope and methodology are provided in that report .

in addition , we obtained information on the current status of and key questions facing the 2020 census through ongoing work we are conducting for this committee .

to do this , we reviewed bureau documentation , including the updated 2020 operational plan , an inventory of it - related decisions , and a list of systems and delivery dates provided by the bureau ; we also interviewed agency officials .

we did not evaluate the reliability of the provided delivery dates , but found them adequate for our purposes of presenting the bureau's current plans .

all of our work was previously performed or is currently being conducted in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

for the 2020 census , the bureau is significantly changing how it intends to conduct the census , in part by re - engineering key census - taking methods and infrastructure , and making use of new it applications and systems .

the cedcap program , which began in october 2014 , is intended to provide data collection and processing solutions ( including systems , interfaces , platforms , and environments ) to support the bureau's multiple surveys throughout the survey life cycle ( including survey design ; instrument development ; sample design and implementation ; data collection ; and data editing , imputation , and estimation ) .

in october 2015 , the bureau estimated that , with its new approach , it expects to be able to conduct the 2020 census for a life - cycle cost of $12.5 billion , which would be a reduction of about $5.2 billion from its estimate of what it would cost to repeat the design and methods of the 2010 census .

however , in june 2016 , we reported that this $12.5 billion cost estimate was not reliable and did not adequately account for risks that could affect the 2020 census costs .

in november 2015 , the bureau issued a 2020 census operational plan , which is intended to outline the design decisions that are to drive how the 2020 decennial census will be conducted — and which are expected to dramatically change the bureau's approach to conducting the 2020 decennial census .

the plan identified 350 redesign decisions that the bureau had either made or was planning to make through 2018 .

in august 2016 , we reported that the bureau had determined that about 51 percent of the design decisions were either it - related or partially it - related ( 84 it - related and 94 partially it - related ) .

as of october 2016 , the bureau reported that it had made 68 it - related and 62 partially it - related design decisions .

for example , the bureau had decided that individuals / households are to be able to respond to the census on the internet from a computer , mobile device , or other devices that access the internet ; that it intends to award a contract to provide mobile phones and the accompanying service to enumerators ; and that it plans to use a hybrid cloud solution where it is feasible .

however , the bureau acknowledged that it still needed to make 16 it - related and 32 partially it - related design decisions , including on ( 1 ) the uses of cloud - based solutions , such as whether it plans to use a cloud service provider to support a tool for assigning , controlling , tracking , and managing enumerators' caseloads in the field ; ( 2 ) the tools and test materials to be used during integration testing ; and ( 3 ) the expected scale of the system workload for those respondents that do not use the bureau - provided census identification .

to inform these design decisions , the bureau held several major operational tests , including the 2014 census test , which was conducted in the maryland and washington , d.c. , areas to evaluate new methods for conducting self - response and non - response follow - up ; the 2015 census test in arizona , which evaluated , among other things , ( 1 ) the use of a field operations management system to automate data collection operations and provide real - time data , ( 2 ) the ability to reduce the non - response follow - up workload using information previously provided to the government , and ( 3 ) the use of personally owned mobile devices by the field - based enumerators who go door to door to collect census data ; the 2015 optimizing self - response test in savannah , georgia , and the surrounding area , which was intended to explore methods of encouraging households to respond using the internet , such as by using advertising and outreach to motivate respondents , and enabling households to respond without a bureau - issued identification number ; and the 2016 census tests in harris county , texas and los angeles , california , which evaluated , among other things , the efficiency of non - response follow - up using contractor - provided mobile devices .

looking forward , the bureau has plans for two additional operational tests: ( 1 ) the 2017 census test — a nationwide sample of how individuals respond to census questions using paper , the internet , or the phone — in order to evaluate key new it components , such as the internet self - response system and the use of a cloud - based infrastructure ; and ( 2 ) the 2018 end - to - end test , scheduled from august 2017 through december 2018 , which , as previously mentioned , is to test all key systems and operations to ensure readiness for the 2020 census .

the 2020 decennial census operations are dependent on about 50 it systems that are currently being developed or are already in production .

eleven of these systems are expected to be provided as cedcap enterprise systems , which have the potential to offer numerous benefits to the bureau's multiple survey programs , such as enabling an internet response option ; automating the assignment , control , and tracking of the caseloads of the field - based enumerators ; and enabling a mobile data collection tool for field work .

more details on each of the cedcap projects can be found in our june 2016 testimony and our august 2016 report .

our august 2016 report noted that the projects were at varying stages of planning and design , and none were in the implementation / deployment stage .

the bureau had previously developed several pilot systems to provide and test different capabilities , but in may 2016 , decided that it would acquire six of the capabilities from a vendor , using a commercial - off - the - shelf it platform , rather than continue to develop the capabilities in - house .

this project is called the enterprise censuses and surveys enabling ( ecase ) initiative .

the capabilities that ecase is to provide include key functionality intended to significantly redesign the 2020 census and achieve efficiency gains , such as enabling an internet response - option and an operational control system that automates the assignment , tracking , and management of enumerators' case work .

the bureau does not have a firm estimate for the cost of the cedcap projects .

in 2013 , the cedcap program office estimated that the program would cost about $548 million from 2015 to 2020 .

more recently , in july 2015 , an independent cost estimate for cedcap projected the projects to cost about $1.14 billion from 2015 to 2020 .

however , this july 2015 estimate was developed before the bureau decided to purchase rather than continue to build six of the cedcap capabilities .

as noted in our prior reports , the bureau's past efforts to acquire and implement new approaches and systems have not always gone as planned .

as one example , during the 2010 census , the bureau planned to use handheld mobile devices to support field data collection for the census , including following up with non - respondents .

however , due to significant problems identified during testing of the devices , as well as cost overruns and schedule slippages , the bureau decided not to use the handheld devices for nonresponse follow - up .

instead , it reverted to paper - based processing , which increased the cost of the 2010 census by up to $3 billion and significantly increased the risk of not completing the census on time .

due in part to these technology issues the bureau was facing , we designated the 2010 census a high - risk area in march 2008 .

further , we testified in november 2015 that key it decisions needed to be made soon because the bureau was less than 2 years away from end - to - end testing of all systems and operations to ensure readiness for the 2020 census , leaving limited time to implement the systems .

we emphasized that the bureau had deferred key it - related decisions , and that it was running out of time to develop , acquire , and implement the systems it will need to deliver the redesigned operations .

the bureau is not alone in facing challenges in acquiring it systems — it is a systemic issue that plagues the federal government .

although the executive branch has undertaken numerous initiatives to better manage the more than $80 billion that is annually invested in it , we have a significant body of work that has found that federal it investments too frequently fail or incur cost overruns and schedule slippages while contributing little to mission - related outcomes .

we have previously testified that the federal government has spent billions of dollars on failed it investments , such as the department of defense's expeditionary combat support system , which was canceled in december 2012 , after spending more than a billion dollars and failing to deploy within 5 years of initially obligating funds ; the department of veterans affairs' financial and logistics integrated technology enterprise program , which was intended to be delivered by 2014 at a total estimated cost of $609 million , but was terminated in october 2011 due to challenges in managing the program ; and the national oceanic and atmospheric administration , department of defense , and the national aeronautics and space administration's national polar - orbiting operational environmental satellite system , which was a tri - agency weather satellite program that was terminated in february 2010 after having spent 16 years and almost $5 billion on the program , when a presidential task force decided to disband the system .

our work has shown that these and other failed it projects often suffered from a lack of disciplined and effective management , such as project planning , requirements definition , and program oversight and governance .

in many instances , agencies have not consistently applied best practices that are critical to successfully acquiring it investments , such as ( 1 ) program staff having the necessary knowledge and skills ; ( 2 ) program staff prioritizing requirements ; ( 3 ) end users participating in the testing of system functionality prior to end user acceptance testing ; ( 4 ) government and contractor staff being stable and consistent ; and ( 5 ) program officials maintaining regular communication with the prime contractor .

due to the challenges of acquiring it across the federal government , we added improving the management of it acquisitions and operations as a key area in our 2015 high - risk report .

as part of this new area , we also identified cedcap as one of nine programs across the federal government in need of the most attention .

in august 2016 , we reported that the cedcap and 2020 census programs were intended to be on parallel implementation tracks and had major interdependencies ; however , the interdependencies between these two programs had not always been effectively managed .

importantly , cedcap relies on 2020 census to be one of the biggest consumers of its enterprise systems , and 2020 census relies heavily on cedcap to deliver key systems to support its redesign .

nevertheless , while both programs had taken a number of steps to coordinate , such as holding weekly schedule coordination meetings and participating in each other's risk review board meetings , they lacked processes for effectively integrating their schedule dependencies , integrating the management of interrelated risks , and managing requirements .

specifically: the cedcap and 2020 census programs did not have an effective process for integrating schedule dependencies .

best practices identified in our schedule assessment guide call for dependencies between two programs to be automatically linked and dynamically responsive to change , or handled through a defined repeatable process if manual reconciliation cannot be avoided .

we reported that the cedcap and 2020 census programs had both established master schedules that contain thousands of milestones and tens of thousands of activities and had identified major milestones within each program that were intended to align with each other .

however , the cedcap and 2020 census programs maintained their master schedules using different software where dependencies between the two programs were not automatically linked , were not dynamically responsive to change , and not handled through a defined repeatable process .

instead , the bureau's practice of maintaining separate dependency schedules , which must be manually reconciled , had proven to be ineffective and had contributed to the misalignment between the programs' schedules .

we concluded in our report that , without an effective process for ensuring alignment between the two programs , the bureau faces increased risk that capabilities for carrying out the 2020 census will not be delivered as intended .

thus , we recommended that the bureau define , document , and implement a repeatable process to establish complete alignment between the cedcap and 2020 census programs by , for example , maintaining a single dependency schedule .

the bureau agreed with this recommendation and indicated it would be taking actions to address it .

cedcap and 2020 census did not have an integrated list of risks facing both programs .

we reported that the two programs had taken steps to collaborate on identifying and mitigating risks , such as having processes in place for identifying and mitigating risks that affect their respective programs .

however , we found that these programs did not have an integrated list of risks ( referred to as a risk register ) with agreed - upon roles and responsibilities for tracking them , as called for by best practices identified by gao for collaboration and leading practices in risk management .

this decentralized approach introduced two key challenges: ( 1 ) there were inconsistencies in tracking and managing interdependent risks , and ( 2 ) tracking risks in two different registers could result in redundant efforts and potentially conflicting mitigation efforts .

to address this , we recommended that the bureau establish a comprehensive and integrated list of all interdependent risks facing the cedcap and 2020 census programs , and clearly identify roles and responsibilities for managing this list .

the bureau agreed with this recommendation and indicated it would take actions to address it .

among other requirements management challenges , we reported that although the bureau had drafted a process for managing requirements between cedcap and 2020 census programs , the process had not yet been finalized .

as a result , the bureau had developed three system releases without having a fully documented and institutionalized process for collecting those requirements .

in july 2016 , bureau officials stated that , due to the recent selection of a commercial vendor to deliver many of the cedcap capabilities , they did not plan to finalize this process until january 2017 .

we made three recommendations to the bureau to strengthen its requirements management processes .

the bureau agreed with these recommendations and reported that it planned to take actions to address them .

while the bureau plans to extensively use it systems to support the 2020 census redesign in an effort to realize potentially significant efficiency gains and cost savings , we reported that this redesign introduces critical information security challenges related to the following: minimizing the threat of phishing aimed at stealing personal information , which could target 2020 census respondents , as well as census employees and contractors ; ensuring that individuals gain only limited and appropriate access to adequately protecting approximately 300,000 mobile devices ; ensuring adequate control of security performance requirements in a cloud environment , such as those related to data reliability , preservation , privacy , and access rights ; adequately considering information security when making decisions about the it solutions and infrastructure supporting the 2020 census ; making certain that key it positions are filled and have appropriate information security knowledge and expertise ; ensuring that contingency and incident response plans are in place that encompass all of the it systems to be used to support the 2020 census ; adequately training bureau employees , including its massive temporary workforce , in information security awareness ; making certain that security assessments are completed in a timely manner and that risks are at an acceptable level ; and properly configuring and patching systems supporting the 2020 census .

for example , the introduction of an option for households to respond using the internet puts respondents more at risk for phishing attacks .

in addition , because the bureau plans to provide its enumerators with mobile devices to collect information from households that did not self - respond to the survey , it is important that the bureau ensures that these devices are adequately protected .

more details on each of these challenges can be found in our recently issued report .

in early 2016 , the bureau's acting chief information officer and its chief information security officer acknowledged these challenges and described the bureau's plans to address them .

for example , the bureau has developed a risk management framework , intended to ensure that proper security controls are in place and provide authorizing officials with details on residual risks and progress to address those risks .

to minimize the risk of phishing , bureau officials noted that they plan to contract with a company to monitor the internet for fraudulent sites pretending to be those of the census bureau .

continued focus on these considerable challenges will be important as the bureau begins to develop and / or acquire systems and implement the 2020 design .

looking forward , there is uncertainty as to whether the census bureau will be ready for the 2018 end - to - end test .

we have ongoing work for this committee that is evaluating the significant challenges the bureau faces in developing , testing , and integrating systems prior to the 2018 test .

among other things , we plan to address the following key questions: is the bureau sufficiently prepared to complete the development , testing , and integration of all of the systems and infrastructure in time for the end - to - end test ? .

there are less than 9 months before the 2018 test is scheduled to begin , but a great deal of development work remains to be completed and the bureau is still developing the plans and schedules leading up to the 2018 test .

for example , as of october 2016 , only 3 of the 50 systems ( 6 percent ) had been delivered .

the other 47 systems that the bureau plans to use during the 2018 end - to - end test were in various forms of development , including: 22 systems ( or 44 percent ) that were expected to be delivered by the time the 2018 end - to - end test begins ; 15 systems ( or 30 percent ) that were expected to be delivered after the 2018 end - to - end test begins ; and 10 systems ( or 20 percent ) that did not have firm delivery dates .

figure 1 depicts the percentage of systems that have been delivered , are scheduled before and after august 1 , 2017 , and that have not yet been firmly scheduled for delivery .

in addition , the bureau has not identified the entire infrastructure ( i.e. , cloud solutions and / or data centers ) that it plans to use for the 2018 test or 2020 operations and , as of october 2016 , it did not yet have a time frame for the implementation of the infrastructure .

is the bureau effectively managing its significant contractor support ? .

the bureau is relying on contractor support in many key areas , including the technical integration of all of the key systems and infrastructure , and the development of many of the data collection systems .

for example , in august 2016 , the bureau awarded a contract for the technical integration of the 2020 census systems and infrastructure , to include an evaluation of the systems and infrastructure , development of the infrastructure ( eg , cloud or data center ) to meet the bureau's scalability and performance needs , integration of all of the systems , and support for testing activities .

however , key dates for this work have yet not been finalized .

in addition , the bureau is relying on other contractors to develop a number of key systems , such as ( 1 ) development of the it platform that will be used to collect data from a majority of respondents — through the use of the internet , telephone , and non - response follow - up activities ; ( 2 ) procurement of the mobile devices and cellular service to be used for non - response follow - up ; and ( 3 ) development of the it infrastructure in the field offices .

the 2020 census will be the first time that the bureau uses a technical integrator in this manner ; collects data nationwide via the internet ; and relies on mobile devices for non - response follow - up .

a greater reliance on contractors for these key components of the 2020 census requires the bureau to focus on sound management and oversight of the key contracts , projects , and systems .

does the bureau have back - up plans in case key systems are not ready in time for the 2018 test ? .

the 2017 census test ( with a census day of april 1 , 2017 ) will be the first time that the bureau has an opportunity to test various it systems and infrastructure in operation , including the internet response system and the system to be used for phone responses .

however , because the bureau is revising its plans for the 2017 test , it has not yet determined whether or how it will test other systems and features prior to the end - to - end test , such as the mobile devices that the enumerator's will use to record and upload household information and whether these systems can handle a nationwide scope .

uncertainty about what will be included in the 2017 test has the potential to add risk to the 2018 end - to - end test , and it will be important for the bureau to make plans in case key systems are not ready in time for the 2018 test .

can the bureau adequately secure the systems and data , and respond to breaches should they occur ? .

as described previously , the bureau faces significant challenges in securing systems and data , and tight time frames can exacerbate those challenges .

because many of the systems to be used in the 2018 end - to - end test are not yet fully developed , the bureau has not finalized all of the controls to be implemented , completed an assessment of those controls , developed plans to remediate any control weaknesses , and determined whether there is time to fully remediate any weaknesses before the system test begins .

we are continuing to evaluate these and other important areas related to the bureau's efforts to ensure its systems are ready for the 2020 decennial census .

in summary , the cedcap program has the potential to offer numerous benefits to the bureau's multiple survey programs , including the 2020 census program .

while the bureau had taken steps to implement cedcap projects , considerable work remains for its production systems to be in place to support the 2020 census end - to - end system integration test — which is to occur in less than a year .

given the numerous and critical dependencies between the cedcap and 2020 census programs , their parallel implementation tracks , and the 2020 census' immovable deadline , it is imperative that the interdependencies between these programs be effectively managed .

implementation of our recommendations to , among other things , use a repeatable process to establish complete alignment between the programs ; establish an integrated list of all interdependent risks facing the programs ; and strengthen the programs' processes for requirements management would help align the programs and better ensure that the efficiency and effectiveness goals of the 2020 census redesign are achieved .

additionally , while the large - scale technological changes for the 2020 decennial census introduce great potential for efficiency and effectiveness gains , it also introduces many information security challenges , including educating the public to offset inevitable phishing scams .

continued focus on these considerable security challenges will be important as the bureau begins to develop and / or acquire systems and implement the 2020 census design .

in our ongoing work for this committee , we plan to address key questions about the bureau's ability to develop , integrate , test , and secure the it systems and infrastructure in time for the end – to - end test .

given the short window of time before the test begins , it is important that the bureau continue to focus its attention on implementing and securing the systems that will collect and store the personal information of millions of american people .

chairman meadows , ranking member connolly , and members of the subcommittee , this completes my prepared statement .

i would be pleased to respond to any questions that you may have .

if you have any questions concerning this statement , please contact david a. powner at ( 202 ) 512-9286 or pownerd@gao.gov .

gao staff who made key contributions to this testimony are carol harris ( director ) , colleen phillips ( assistant director ) , shannin g. o'neill ( assistant director ) , kate sharkey ( analyst in charge ) , andrew beggs , chris businsky , juana collymore , becca eyler , lee mccracken , andrea starosciak , jeanne sung , and umesh thakkar .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

the published product may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

