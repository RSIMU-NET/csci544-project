for decades , the department of defense ( dod ) has been challenged in modernizing its timeworn business systems .

in 1995 , we designated dod's business systems modernization program as high risk , and we continue to designate it as such today .

as our research on public and private sector organizations shows , two essential ingredients to a successful systems modernization program are having a well - defined enterprise architecture and an effective institutional approach to managing information technolo gy ( it ) investments .

accordingly , we made recommendations to the secretary of defense in may 2001 that included the means for effectively developing an enterprise architecture and establishing a corporate , architecture - centric approach to investment control and decision making .

between 2001 and 2005 , we reported that the department's business systems modernization program continued to lack both of these , concluding in 2005 that hundreds of millions of dollars had been spent on a business enterprise architecture ( bea ) and investment management structures that had limited value .

accordingly , we made more explicit architecture and investment management - related recommendations .

to further assist dod in addressing these modernization management challenges , congress included provisions in the ronald w. reagan national defense authorization act for fiscal year 2005 ( the act ) that were consistent with our recommendations .

more specifically , the act requires the department to , among other things , ( 1 ) develop a bea , ( 2 ) develop a transition plan to implement the architecture , ( 3 ) identify systems information in its annual budget submission , ( 4 ) establish a system investment approval and accountability structure , ( 5 ) establish an investment review process , and ( 6 ) certify and approve any system modernizations costing in excess of $1 million .

the act further requires that the secretary of defense submit an annual report to congressional defense committees on dod's compliance with certain requirements of the act not later than march 15 of each year from 2005 through 2009 .

additionally , the act directs us to submit to these congressional committees — within 60 days of dod's report submission — an assessment of dod's actions to comply with these requirements .

as agreed with your offices , the objective of our review was to assess the actions taken by dod to comply with requirements of section 2222 of title 10 , u.s. code .

to accomplish this , we used our prior annual report under the act as a baseline , analyzing whether the department had taken actions to comply with those requirements , related guidance , and our prior recommendations that we previously identified as not yet addressed .

in doing this , we also relied on the results of relevant reports that we have issued since our prior annual report .

we also reviewed the department's report to congress , which was submitted on march 18 , 2009 , and evaluated the information used to satisfy the budget submission and investment review , certification , and approval aspects of the act .

we conducted this performance audit at dod offices in arlington , virginia , from january to may 2009 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

details on our objective , scope , and methodology are contained in appendix i .

dod is a massive and complex organization and is entrusted with more taxpayer dollars than any other federal department or agency .

to illustrate , congress provided dod with about $512 billion in appropriations for fiscal year 2009 .

additionally , congress has provided about $808 billion in supplemental emergency funding for operations in support of the global war on terrorism since 2001 .

moreover , the recent american recovery and reinvestment act of 2009 contains nearly $12.6 billion in appropriations for dod for military construction , environmental restoration , and other purposes .

organizationally , the department includes the office of the secretary of defense , the joint chiefs of staff , the military departments , numerous defense agencies and field activities , and various unified combatant commands that are responsible for either specific geographic regions or specific functions .

 ( see fig .

1 for a simplified depiction of dod's organizational structure. ) .

in support of its military operations , the department performs an assortment of interrelated and interdependent business functions , including logistics management , procurement , health care management , and financial management .

as we have previously reported , the dod systems environment that supports these business functions is overly complex and error prone , and is characterized by ( 1 ) little standardization across the department , ( 2 ) multiple systems performing the same tasks , ( 3 ) the same data stored in multiple systems , and ( 4 ) the need for data to be entered manually into multiple systems .

moreover , the department recently reported that this systems environment is composed of approximately 2,480 separate business systems .

for fiscal year 2009 , dod requested about $15.3 billion in funds to operate , maintain , and modernize these business systems and associated it infrastructure .

as we have previously reported , the department's nonintegrated and duplicative systems impair its ability to combat fraud , waste , and abuse .

in fact , dod currently bears responsibility , in whole or in part , for 15 of our 30 high - risk areas .

eight of these areas are specific to the department , while it shares responsibility for 7 other governmentwide high - risk areas .

collectively , these high - risk areas relate to dod's major business operations that are inextricably linked to the department's ability to perform its overall mission , directly affect the readiness and capabilities of u.s. military forces , and can affect the success of a mission .

dod's business systems modernization is one of the high - risk areas , and it is an essential enabler to addressing many of the department's other high - risk areas .

for example , modernized business systems are integral to the department's efforts to address its financial , supply chain , and information security management high - risk areas .

effective use of an enterprise architecture — a modernization blueprint — is a hallmark of successful public and private organizations .

since the early 1990s , we have promoted the use of architectures to guide and constrain systems modernization , recognizing them as a crucial means to meeting this challenging goal: optimally defined operational and technological environments .

congress , the office of management and budget ( omb ) , and the federal chief information officers ( cio ) council have also recognized the importance of an architecture - centric approach to modernization .

the clinger - cohen act of 1996 mandates that an agency's cio develop , maintain , and facilitate the implementation of an information technology architecture .

further , the e - government act of 2002 requires omb to oversee the development of enterprise architectures within and across agencies .

in addition , we , omb , and the cio council have issued guidance that emphasizes the need for system investments to be consistent with these architectures .

for example , in april 2003 , we issued a framework that emphasizes the importance of having an enterprise architecture as a critical frame of reference for organizations when they are making it investment decisions .

also , in december 2008 , omb issued guidance that addresses system investment compliance w ith agency architectures .

a corporate approach to it investment management is another important characteristic of successful public and private organizations .

recognizing this , congress enacted the clinger - cohen act of 1996 , which requires omb to establish processes to analyze , track , and evaluate the risks and results of major capital investments in it systems made by executive agencies .

in response to the clinger - cohen act and other statutes , omb has developed policy and issued guidance for planning , budgeting , acquisition , and management of federal capital assets .

we have also issued guidance in this area that defines institutional structures ( such as investment boards ) , processes for developing information on investments ( such as cost / benefit ) , and practices to inform management decisions ( such as whether a given investment is aligned with an enterprise architecture ) .

an enterprise architecture provides a clear and comprehensive picture of an entity , whether it is an organization ( eg , a federal department ) or a functional or mission area that cuts across more than one organization ( eg , financial management ) .

an architecture describes the enterprise in logical terms ( such as interrelated business processes and business rules , information needs and flows , and work locations and users ) as well as in technical terms ( such as hardware , software , data , communications , security attributes , and performance standards ) .

it provides these perspectives both for the enterprise's current , or “as is,” environment , and for its target , or “to be,” environment , and it provides a transition plan for moving from the “as is” to the “to be” environment .

this transition plan provides a temporal road map for moving between the two environments and incorporates such considerations as technology opportunities , marketplace trends , fiscal and budgetary constraints , institutional system development and acquisition capabilities , legacy and new system dependencies and life expectancies , and the projected value of competing investments .

the suite of products produced for a given entity's enterprise architecture , including its structure and content , is largely governed by the framework used to develop the architecture .

since the 1980s , various architecture frameworks have been developed , such as john a. zachman's “a framework for information systems architecture” and the dod architecture framework .

the importance of developing , implementing , and maintaining an enterprise architecture is a basic tenet of both organizational transformation and systems modernization .

managed properly , an enterprise architecture can clarify and help optimize the interdependencies and relationships among an organization's business operations and the underlying it infrastructure and applications that support these operations .

moreover , when an enterprise architecture is employed in concert with other important management controls , such as portfolio - based capital planning and investment control practices , architectures can greatly increase the chances that an organization's operational and it environments will be configured to optimize mission performance .

the alternative , as our work has shown , is the perpetuation of the kinds of operational environments that burden many agencies today , where a lack of integration among business operations and the it resources supporting them leads to systems that are duplicative , poorly integrated , and unnecessarily costly to maintain and interface .

our framework provides federal agencies with a common benchmarking tool for planning and measuring their efforts to improve enterprise architecture management .

one approach to structuring an enterprise architecture is referred to as a federated enterprise architecture .

such a structure treats the architecture as a family of coherent but distinct member architectures that conform to an overarching architectural view and rule set .

this approach recognizes that each member of the federation has unique goals and needs as well as common roles and responsibilities with the levels above and below it .

under a federated approach , member architectures are substantially autonomous , although they also inherit certain rules , policies , procedures , and services from higher - level architectures .

as such , a federated architecture gives autonomy to an organization's components while ensuring enterprisewide linkages and alignment where appropriate .

where commonality among components exists , there are also opportunities for identifying and leveraging shared services .

a service - oriented architecture is an approach for sharing business capabilities across the enterprise by designing functions and applications as discrete , reusable , and business - oriented services .

as such , service orientation permits sharing capabilities that may be under the control of different component organizations .

as we have previously reported , such capabilities or services need to be , among other things , ( 1 ) self - contained , meaning that they do not depend on any other functions or applications to execute a discrete unit of work ; ( 2 ) published and exposed as self - describing business capabilities that can be accessed and used ; and ( 3 ) subscribed to via well - defined and standardized interfaces .

a service - oriented architecture approach is thus intended not only to reduce redundancy and increase integration , but also to provide the kind of flexibility needed to support a quicker response to changing and evolving business requirements and emerging conditions .

it investment management is a process for linking it investment decisions to an organization's strategic objectives and business plans that focuses on selecting , controlling , and evaluating investments in a manner that minimizes risks while maximizing the return of investment .

during the selection phase , the organization ( 1 ) identifies and analyzes each project's risks and returns before committing significant funds to any project and ( 2 ) selects those it projects that will best support its mission needs .

during the control phase , the organization ensures that as projects develop and investment expenditures continue , they continue to meet mission needs at the expected levels of cost and risk .

if the project is not meeting expectations , or if problems arise , steps are quickly taken to address the deficiencies .

during the evaluation phase , actual versus expected results are compared once a project has been fully implemented .

this is done to ( 1 ) assess the project's impact on mission performance , ( 2 ) identify any changes or modifications to the project that may be needed , and ( 3 ) revise the investment management process based on lessons learned .

consistent with this guidance , our it investment management ( itim ) framework consists of five progressive stages of maturity for any given agency relative to selecting , controlling , and evaluating its investment management capabilities .

 ( see fig .

2 for the five itim stages of maturity. ) .

the overriding purpose of the framework is to encourage investment selection and control and to evaluate processes that promote business value and mission performance , reduce risk , and increase accountability and transparency .

we have used the framework in several of our evaluations , and a number of agencies have adopted it .

in our itim framework , with the exception of the first stage , each maturity stage is composed of “critical processes” that must be implemented and institutionalized in order for the organization to achieve that stage .

each itim critical process consists of “key practices” — to include organizational structures , policies , and procedures — that must be executed to implement the critical process .

our research shows that agency efforts to improve investment management capabilities should focus on implementing all lower - stage practices before addressing higher - stage practices .

stage 2 critical processes lay the foundation by establishing successful , predictable , and repeatable investment control processes at the project level .

stage 3 is where the agency moves from project - centric processes to portfolio - based processes and evaluates potential investments according to how well they support the agency's missions , strategies , and goals .

organizations implementing these stage 2 and 3 practices have in place selection , control , and evaluation processes that are consistent with the clinger - cohen act .

stages 4 and 5 require the use of evaluation techniques to continuously improve both investment processes and portfolios in order to better achieve strategic outcomes .

the national defense authorization act ( ndaa ) for fiscal year 2008 designated the deputy secretary of defense as the chief management officer ( cmo ) for dod and created a deputy cmo position .

the cmo's responsibilities include developing and maintaining a departmentwide strategic plan for business reform and establishing performance goals and measures for improving and evaluating overall economy , efficiency , and effectiveness and monitoring and measuring the progress of the department .

the deputy cmo's responsibilities include recommending to the cmo methodologies and measurement criteria to better synchronize , integrate , and coordinate the business operations to ensure alignment in support of the warfighting mission .

the business transformation agency ( bta ) supports the deputy cmo in leading and coordinating business transformation efforts across the department .

the cmo and deputy cmo are to interact with several entities to provide executive leadership for the direction , oversight , and execution of dod's business transformation efforts , which include business systems modernization .

these entities include the defense business systems management committee ( dbsmc ) , which serves as the highest - ranking investment review and decision - making body for business systems modernization activities and is chaired by the deputy secretary of defense ; the principal staff assistants , who serve as the certification authorities for business system modernizations in their respective core business missions ; the investment review boards ( irb ) , which are chaired by the certifying authorities and form the review and decision - making bodies for business system investments in their respective areas of responsibility ; and the bta , which is responsible for supporting the irbs , and for leading and coordinating business transformation efforts across the department .

table 1 lists these entities and provides greater detail on their roles , responsibilities , and composition .

in 2005 , dod reported that it had adopted a “tiered accountability” approach to business systems modernization .

under this approach , responsibility and accountability for business architectures and systems investment management are assigned to different levels in the organization .

for example , the bta is responsible for developing the corporate bea ( i.e. , the thin layer of dod - wide policies , capabilities , standards , and rules ) and the associated enterprise transition plan ( etp ) .

the components are responsible for defining a component - level architecture and transition plans associated with their own tiers of responsibility and for doing so in a manner that is aligned with ( i.e. , does not violate ) the corporate bea .

similarly , program managers are responsible for developing program - level architectures and plans and ensuring alignment with the architectures and transition plans above them .

this concept is to allow for autonomy while also ensuring linkages and alignment from the program level through the component level to the corporate level .

table 2 describes the four investment tiers and identifies the associated reviewing and approving entities .

consistent with the tiered accountability approach , the ndaa for fiscal year 2008 required the secretaries of the military departments to designate the department under secretaries as cmos with primary responsibility for business operations .

moreover , the duncan hunter ndaa for fiscal year 2009 requires the military departments to establish business transformation offices to assist their cmos .

congress included six provisions in the fiscal year 2005 ndaa that are aimed at ensuring dod's development of a well - defined bea and associated etp , as well as the establishment and implementation of effective investment management structures and processes .

the requirements are as follows: 1 .

develop a bea that includes an information infrastructure that , at a minimum , would enable dod to comply with all federal accounting , financial management , and routinely produce timely , accurate , and reliable financial information for management purposes ; integrate budget , accounting , and program information and systems ; and provide for the systematic measurement of performance , including the ability to produce timely , relevant , and reliable cost information .

in addition , the bea must include policies , procedures , data standards , and system interface requirements that are to be applied uniformly throughout the department and be consistent with omb policies and procedures .

2 .

develop an etp for implementing the architecture that includes an acquisition strategy for new systems needed to complete the a list and schedule of legacy business systems to be terminated ; a list and strategy of modifications to legacy business systems ; and time - phased milestones , performance metrics , and a statement of financial and nonfinancial resource needs .

3 .

identify each business system proposed for funding in dod's fiscal year budget submissions and include a description of the certification made on each business system proposed for funding in that budget ; funds , identified by appropriations , for current services and for business systems modernization ; and the designated approval authority for each business system .

4 .

delegate the responsibility for business systems to designated approval authorities within the office of the secretary of defense .

5 .

require each approval authority to establish investment review structures and processes , including a hierarchy of irbs — each with appropriate representation from across the department .

the review process must include a review and approval of each business system by an irb before funds at least an annual review of every business system investment ; the use of threshold criteria to ensure an appropriate level of review and accountability ; the use of procedures for making architecture compliance certifications ; the use of procedures consistent with dod guidance ; and the incorporation of common decision criteria .

6 .

effective october 1 , 2005 , dod may not obligate appropriated funds for a defense business system modernization with a total cost of more than $1 million unless the approval authority certifies that the business system modernization complies with the bea ; or is necessary to achieve a critical national security capability or address a critical requirement in an area such as safety or security , or is necessary to prevent a significant adverse effect on an essential project in consideration of alternative solutions ; and the certification is approved by the dbsmc .

the fiscal year 2005 ndaa also requires that the secretary of defense submit to the congressional defense committees a report on the department's compliance with the above provisions .

since 2005 , we have reported that dod has each year taken increasing steps to comply with the requirements of the fiscal year 2005 ndaa and to satisfy relevant systems modernization management guidance .

moreover , we concluded that dod had made important progress each year relative to architecture development , transition plan development , budgetary disclosure , and investment review ; however , aspects of these requirements and relevant guidance had yet to be fully satisfied .

we also reported that dod had fully satisfied the requirement concerning designated approval authorities and continued to certify and approve modernizations costing more than $1 million .

however , each report also concluded that much remained to be accomplished relative to the act's requirements and relevant guidance , as these examples illustrate: the bea lacked important content , such as business rules for , and information flows among , certain business activities , and it had yet to be extended ( i.e. , federated ) throughout the dod component organizations .

the etp did not include investments for all components and did not reflect key factors associated with properly sequencing planned investments , such as dependencies among investments and the capability to execute the plan .

dod and the military departments had yet to fully establish key investment review structures and define related policies and procedures for effectively performing both project - level and portfolio - based investment management .

accordingly , we either provided new or reiterated existing recommendations to address each of these areas .

dod largely agreed with our recommendations .

in august 2008 , we also reported on issues with the process used to certify investments as compliant with dod's bea .

specifically , we reported that key dod business systems modernization programs did not adequately demonstrate compliance with the department's federated bea , even though each program had largely followed dod's existing compliance guidance , used its compliance assessment tool , and was certified and approved as being compliant by department investment oversight and decision - making entities .

in addition , we reported that even though the department's investment oversight and decision - making authorities had certified and approved these business system programs as compliant with the bea , these certification and approval entities did not validate each program's compliance assessment and assertions .

accordingly , we made recommendations to address each of those shortcomings , which dod agreed with .

with respect to departmentwide business transformation , we recently reported that implementation of dod's overall management framework for business transformation is not yet complete because key aspects had not been defined .

for example , we reported that the authority , roles , and relationships for some positions and entities had not been clearly defined , including a clearly defined decision - making authority for the deputy cmo , a clearly defined relationship between dod's deputy cmo and the cmos of the military departments , and clearly defined unique and shared responsibilities of various governance entities , such as the deputy's advisory working group and the dbsmc .

we concluded that the current administration needed to move quickly to nominate and fill key leadership positions , including the deputy secretary of defense ( now statutorily designated as the cmo ) , the deputy cmo , the under secretaries of defense , and the military department cmos .

we also concluded that , in light of the transition , it will be important for senior leaders in the current administration to further define and clarify the roles , responsibilities , and relationships among the various positions and governance entities within dod's management framework for business transformation in order to sustain and further dod's progress .

in addition , we reported that dod's first strategic management plan , issued in 2008 , lacked key information and elements necessary for assisting in successfully achieving business management transformation .

for example , it did not identify any strategic goals , objectives , and performance measures , and while it stated a purpose , the plan did not provide detailed information about business operations .

without strategic goals and objectives , we concluded that the strategic management plan could not be linked to other existing plans and tools for individual business areas , such as the etp .

dod continues to take steps to comply with the requirements of the act and to satisfy relevant systems modernization management guidance .

in particular , dod released an update to its corporate bea ( version 6.0 ) and etp , and issued its annual report to congress describing steps that have been taken and are planned relative to the act's requirements , among other things .

collectively , these steps address several statutory provisions and best practices concerning the bea , transition plan , budgetary disclosure , and investment review of systems costing in excess of $1 million .

however , the pace of dod's progress in defining and implementing these key modernization management controls has slowed compared with the progress the department had made , and we have reported , each of the last 4 years .

as a result , challenges that we identified last year largely remain to be addressed to fully implement the act and relevant guidance .

most notably , the department has yet to extend and evolve its bea and to provide the total federated family of dod parent and subsidiary architectures for the business mission area , which are needed to comply with the act .

it also has yet to fully define it investment management policies and procedures at the corporate and component levels , and the business system information used to support the development of the transition plan and dod's budget requests , as well as certification and annual reviews , is of questionable reliability .

dod officials agree that additional steps are needed to fully implement the act's requirements and related system modernization management best practices .

further , they stated that progress over the last year has been slowed by yet - to - be - resolved issues surrounding the deputy cmo and military department cmo positions .

among other things , the fiscal year 2005 ndaa requires dod to develop a bea that would cover all defense business systems and their related functions and activities and that would enable the entire department to ( 1 ) comply with all federal accounting , financial management , and reporting requirements and ( 2 ) routinely produce timely , accurate , and reliable financial information for management purposes .

the bea should also include policies , procedures , data standards , and system interface requirements that are to be applied throughout the department .

as such , the act requires an architecture that extends to all defense organizational components .

in 2006 , the department adopted an incremental and federated approach to developing such an architecture .

under this approach , the department releases new architecture versions every year that include a corporate bea that is to be augmented by a coherent family of component architectures .

as we have previously reported , such an approach is consistent with best practices and appropriate given dod's scope and size .

in 2008 , we reported that the then - current version of the bea ( version 5.0 ) addressed , to varying degrees , missing elements , inconsistencies , and usability issues that we previously identified , but that gaps still remained .

on march 13 , 2009 , dod released bea 6.0 , which addresses some of these gaps .

for example , it begins to address information assurance by identifying related laws , regulations , and policies .

this is important because the nature and substance of institutionalized security requirements , controls , and standards should be captured in the architecture products , since information assurance permeates every aspect of an organization's operations .

in addition , the latest version of the bea begins to address the technical standards ( eg , w3c xml - encryption ) needed to allow business systems to work in an expeditionary environment , which would , among other things , allow warfighters operating in these environments to access business systems .

version 6.0 of the bea also addresses , to varying degrees , missing elements , inconsistencies , and usability issues that we previously identified , but continues to be missing important content .

examples of these improvements and remaining issues are summarized below .

the latest version includes 35 new business rules .

as we previously reported , business rules are important because they translate business policies and procedures into specific , unambiguous rules that govern what can and cannot be done .

as such , they facilitate consistent implementation of laws , policies , and procedures .

examples of new business rules in the common supplier engagement business priority area are ( 1 ) an accepting or inspecting organization must be provided on all contracts for goods or services and ( 2 ) both a minimum and a maximum ordering limit must be provided when the contract is an indefinite delivery / indefinite quantity contract .

in addition to adding business rules , version 6.0 reflects the deletion of 22 business rules that , according to dod , were no longer applicable and were thus obsolete .

notwithstanding these additions and deletions , bea 6.0 still does not provide business rules for all business processes .

for example , there are no business rules for the file discrepancy report for other goods and services business process in the common supplier engagement and materiel visibility business priority areas .

such limitations in dod's business rules limit the department's ability to ensure that business operations and supporting systems are properly implemented .

the latest version includes additional information on important security architecture content .

for example , it now identifies information assurance laws , regulations , and policies and describes information assurance characteristics of key information exchanges ( eg , awarded contract is designated as a sensitive information exchange ) .

however , not all financial information exchanges ( eg , receipt account trial balance and ledgers ) include such key information assurance characteristics as confidentiality , integrity , and nonrepudiation .

without specifying such information assurance characteristics for all relevant exchanges , dod will be limited in its ability to implement adequate security controls into the systems that support these exchanges .

the latest version continues to add new operational activities , which describe actions performed in conducting dod business operations ( eg , deliver property and forces ) .

these operational activities are important because they are dod's primary basis for determining if a system is being defined in a way that is compliant with the bea .

however , key operational activities are not yet included in the bea .

for example , version 6.0 still does not include the foreign military sales operational activity , which affects multiple dod business missions and organizations .

without including such important operational activities , programs do not have all the information necessary for determining if they are compliant with applicable constraints ( eg , data definitions and business rules ) .

the latest version includes updates on the information that flows among operational nodes ( i.e. , organizations , business operations , and system elements ) .

information flows are important because they define what information is needed and where and how the information moves to and from operational entities .

while version 6.0 adds approximately 50 new information exchanges ( eg , approved payment request ) among business functions and approximately 15 data exchanges ( eg , payment request for goods ) among system functions , it still contains information exchanges ( eg , accounts payable account ) that are not attached or linked to any operational nodes ( or organizations ) .

further , this version's information - related architecture products contain inconsistencies .

for example , information exchanges such as final contract or order costs and estimate at completion are listed in the information exchange integrated dictionary , but are not listed in the operational information exchange product .

as a result , dod's ability to understand how information is shared among operational entities , and subsequently develop or modernize systems that can effectively share such information , will be constrained .

the latest version also depicts end - to - end business flows ( eg , budget to report ) with linkages to bea business processes ( eg , execute apportionment and allocate funds ) .

however , bea 6.0 does not include , for each end - to - end business flow , a create , read , update , and delete matrix that shows how the business processes and their associated applications manage specific data objects ( eg , approved apportionment ) .

these matrices are important because they reveal natural groupings of business activities and data objects , and thus are used to identify business activities to be automated .

without this information , dod will be limited in its ability to develop a target architecture that effectively integrates information and systems that support its business activities .

bta officials recognize many of these issues and state that they will be addressed as the bea continues to evolve .

in this regard , the chief architect stated that the process for evolving the bea is described in the architecture's concept of operations .

specifically , it describes a process that calls for business cases to justify proposed improvements that are then prioritized and used to create a bea plan for dbsmc approval .

however , the concept of operations has yet to be approved , and available documentation does not demonstrate that this process is being followed .

further , we have yet to receive an architecture plan or evidence of dbsmc approval of such a plan .

as we have previously reported and recommended , bta needs an enterprise architecture program management plan that defines what the department's incremental improvements to the architecture ( and transition plan ) will be , and how and when they will be accomplished , including what ( and when ) architecture and transition plan scope and content and architecture compliance criteria will be added into which versions .

bta has not yet developed such a plan .

according to bta officials , the department's next steps are contingent upon ongoing discussions about how architecture planning will be affected by the deputy cmo's efforts to align the department's various planning activities in its strategic management plan , which is to be issued no later than july 1 , 2009 .

these discussions will be further complicated by the lack of clarity surrounding the deputy cmo's roles , responsibilities , and authorities and how the deputy will work with other senior leaders across the department who have responsibility for business operations .

beyond the above - discussed limitations , version 6.0 also continues to represent only the thin layer of corporate architectural policies , capabilities , rules , and standards that apply dod - wide ( i.e. , to all dod federation members ) .

this means that version 6.0 appropriately focuses on addressing a limited set of enterprise - level ( dod - wide ) priorities and providing the overarching and common architectural context that the distinct and substantially autonomous member ( i.e. , component ) architectures inherit .

however , this also means that version 6.0 does not provide the total federated family of dod parent and subsidiary architectures for the business mission area .

recognizing the need to address its component architecture challenges , bta released an update to its initial business mission area federation strategy and road map in january 2008 .

among other things , this strategy was to address how the corporate bea would be extended to the military departments and defense agencies and how business services will be identified and delivered across the business mission area .

 ( see fig .

3 for a conceptual representation of dod's federated bea. ) .

in september 2006 , dod issued its initial business mission area federated strategy and road map , which we reported lacked adequately defined tasks needed to achieve the strategy's goals , such as addressing how strategy execution will be governed , component architectures will be aligned with the latest version of the bea , and common applications and systems across the department will be identified and reused .

accordingly , we reiterated our prior recommendation for a bea management plan , and recommended that dod ensure that this plan describes , at a minimum , how the business mission area architecture federation would be governed ; how the business mission area federation strategy alignment with the dod architecture federation strategy would be achieved ; how component business architectures' alignment with incremental versions of the bea would be achieved ; how shared services would be identified , exposed , and subscribed to ; and what milestones would be used to measure progress and results .

in january 2008 , dod issued an updated strategy , and in may 2008 , we reported that the update , along with the associated global information grid strategy , partially addressed our recommendations .

specifically , we reported that the strategies provided high - level roles and responsibilities for federating the architecture and additional definition around the tasks needed to achieve alignment among dod and component architectures .

we also noted that the strategy for the business mission area provided for conducting pilot programs across the components to demonstrate the technical feasibility of architecture federation , and for using the lessons learned from the pilots to improve and update the strategies .

to their credit , bta and other dod entities , such as asd ( nii ) / dod cio and the department of the army , are collaboratively taking steps to establish the foundation for implementing the strategy .

for example , they have selected the department of the army's defense knowledge online to be bta's federated enterprise portal , which is to be the point of access to information about all dod and component architectures , and is to allow users to search and navigate through this information ; established and are using the dod architecture registry system , which is maintained by asd ( nii ) / dod cio , as the repository to contain architecture content ; conducted five pilots at three military departments and two defense agencies to evaluate various aspects of architecture federation and develop lessons learned about , for example , approaches for capturing and managing architecture metadata ( air force pilot ) , and enterprise search and discovery methods ( navy pilot ) ; and developed guidance on identifying and registering business services and , as of november 2008 , identified and registered 25 business services , such as a service that provides detailed information on each aircraft at the base ( eg , an aircraft's mission capability and maintenance status ) , and a service that allows aircraft maintenance data to be retrieved , created , updated , and removed .

according to officials from asd ( nii ) / dod cio , which is responsible for overall dod architecture federation , the results of the pilots are being used to determine future federation steps for all dod mission areas .

in addition , bta officials said that both bta and asd ( nii ) / dod cio are defining a basic set of standard architecture models , including a common vocabulary for using architecture information across dod , to allow for uniform representation of architecture content .

establishing such a common framework is important because dod's current lack of uniform representation for enterprise architecture content , according to bta and asd ( nii ) / dod cio officials , will limit the understanding and utility of the federated architecture .

notwithstanding the above steps , bta's strategy for federating the bea still does not contain sufficient detail to permit effective and efficient execution and adequately address our recommendations .

for example , the business mission area's federation implementation road map only outlines high - level , near - term milestones , such as milestones for developing a governance charter for the dod cio enterprise guidance board , which is dod's senior forum for guiding the development and approval of enterprise - level guidance ( including it policy , architecture , and standards ) on enterprise architecture , and conducting a pilot with defense knowledge online to test an access control mechanism .

it does not , for example , specify tasks to be performed to achieve those milestones , identify milestones or tasks beyond fiscal year 2010 , or identify resources needed to perform tasks ( eg , funding , staffing , tools , and training ) .

further , the strategy does not describe how the various architecture federation activities taking place across dod come together over time to achieve a federated bea , including measurement of progress , results , and the component architectures' alignment with the latest version of the bea .

bta and asd ( nii ) / dod cio officials stated that these details have yet to be described because of unresolved issues surrounding the deputy cmo and military department cmo positions .

moreover , dod's federation efforts have yet to benefit from any independent verification and validation ( iv&v ) assessments .

as we previously reported , such assessments are important to ensure the completeness , consistency , understandability , and usability of the federated family of architectures .

accordingly , we recommended that dod have its bea iv&v contractor perform such assessments and disclose the results in its annual report to congress .

however , dod's march 2009 annual report does not include this information .

according to bta officials , from october 2007 through march 2009 , bta expended approximately $3 million on bea - related iv&v activities .

however , these activities have focused on the corporate bea and not the entire federated family of architectures .

bta officials also stated that future iv&v activities are not currently focused on the federated family of architectures .

they added that they are engaged in discussions with asd ( nii ) / dod cio on how and who to best perform such assessments , given that the federated bea is a part of dod's overall federated enterprise architecture , which is led by asd ( nii ) / dod cio .

the challenges that the department faces in federating its bea , and the importance of disclosing to congressional defense committees the state of its federation efforts , are amplified by the current state of the military departments' enterprise architecture programs .

specifically , we recently reported that none of the three military departments could demonstrate through verifiable documentation that it had established all of the core foundational commitments and capabilities needed to effectively manage the development , maintenance , and implementation of an architecture , which are outlined in our enterprise architecture management maturity framework .

while the air force's architecture efforts are well ahead of those of the navy and army , all three had yet to fully satisfy important aspects of our framework .

examples of their architecture limitations are discussed below: none of the military departments had fully defined its “as is” and “to be” architecture environments and associated transition plans .

this is important because without a full understanding of architecture - based capability gaps , the departments would not have an adequate basis for defining and sequencing their ongoing and planned business system investments .

none of the military departments had fully addressed security as part of its respective “as is” and “to be” environments .

this is important because security is relevant and essential to every aspect of an organization's operations , and therefore the nature and substance of institutionalized security requirements , controls , and standards should be embedded throughout the architecture , and reflected in each system investment .

none of the military departments was using an iv&v agent to help ensure the quality of its architecture products .

iv&v is a proven means for obtaining unbiased insight into such essential architecture qualities as completeness , understandability , usability , and consistency .

none of the military departments could demonstrate that its it investments were actually in compliance with its architecture .

this is relevant because the benefits from using an architecture , such as improved information sharing , increased consolidation , enhanced productivity , and lower costs , cannot be fully realized unless individual investments are actually in compliance with , among other things , architectural rules and standards .

to address these limitations , we made recommendations aimed at improving the management and content of these architectures .

dod agreed with our recommendations .

however , our recommendations have yet to be fully implemented .

specifically , none of the military departments provided documentation demonstrating that the above - cited limitations have been addressed .

until dod has a well - defined family of architectures for its business mission area , it will not fully implement the requirements of the act and will remain challenged in its ability to effectively manage its business system modernization efforts .

among other things , the act requires dod to develop an etp for implementing its bea that includes listings of the legacy systems that will and will not be part of the target business systems environment and specific time - phased milestones and performance metrics for each business system investment .

on september 30 , 2008 , dod released the latest version of its etp , which in general provides information on about 645 business systems , including , to varying degrees , the required information on 54 systems that are linked to key transformational objectives and priorities .

for example , it includes specific time - phased milestones with status indicators ( eg , met , on track , or deleted ) for about 47 out of the 54 systems , and it includes performance metrics ( eg , voucher payment time and integration test progress ) for about 26 of these .

further , the latest version of the e discusses progress made since march 2008 on business system investments , as well as descriptions of planned near - term activities ( e. g. , next 12 months ) .

however , previously identified limitations in the scope and completeness of the latest version of the etp remain .

examples of improvements and remaining issues are su mmarized below .

the etp provides a range of information for some , but not all , business system investments , such as 3 years of budget information for about 342 out of 645 systems ( about 50 percent ) , 46 of which are linked to key transformation objectives and priorities .

however , the etp does not yet include system and budget information for all the business systems identified in the department's it systems repository .

according to the etp , it does not include budget information for about half of the business systems identified because the budget data for some of these systems were not included in the fiscal year 2009 budget submission .

further , according to bta officials , the etp continues to focus on tier 1 and 2 business systems .

however , not all dod components have developed subordinate transition plans that would address all the business system investments .

for example , as we reported last year , the navy and army have not yet developed subordinate transition plans .

more specifically , navy officials stated that they are revising their enterprise architecture development and governance approach and , according to draft navy enterprise architecture documentation associated with this approach , an enterprise architecture transition plan will be developed .

further , as we reported , the air force's transition plan is limited .

for example , it is not based on an analysis of the gap in capabilities between the department's “as is” and “to be” environments .

collectively , this means that a complete family of dod and component transition plans does not exist .

according to the bta official responsible for the etp , bta and the military departments are currently discussing whether component - level plans should be published separately from or incorporated into the corporate etp .

this is further complicated by the uncertainty surrounding how the deputy cmo will work with other senior leaders who have responsibility for business operations , including the military department cmos .

the etp continues to provide performance measures for some , but not all , enterprise and component investments ( i.e. , programs ) , including key milestones ( eg , initial operating capability ) and status indicators .

however , the plan has yet to include other important information needed to understand the sequencing of new systems becoming operational and legacy systems being phased out .

in particular , the planned investments have not been sequenced based on a range of important factors cited in federal guidance , such as technology opportunities , marketplace trends , fiscal and budgetary constraints , institutional system development and acquisition capabilities , new and legacy system dependencies and life expectancies , and the projected value of competing investments .

rather , the etp continues to be largely based on a bottom - up process in which ongoing programs have been compiled and categorized in the plan around business enterprise priorities .

for example , many of these investments are dependent on net - centric enterprise services , and as such the plans and milestones for each should reflect the incremental capability deployment of these enterprise services .

the etp and the business mission area federation strategy describe the department's approach to enterprise application integration , including plans for using specific services and standards for integrating financial application systems .

including such information in the etp and associated documentation will help to clarify relationships and dependencies among legacy applications and systems and new or modernized applications and systems .

however , all systems needed to achieve integration are not specified .

for example , the etp does not identify all of the systems that must be integrated for each end - to - end business flow ( eg , budget - to - report ) to support activities that are cross - functional and cross - cutting across organizational boundaries .

the etp does not include all legacy systems that will not be part of the target bea and does not provide the schedule for terminating these legacy systems , as required by the act .

for example , while the navy enterprise resource planning program's august 2008 investment review board documentation identifies 41 legacy systems , the etp identifies only 25 of these systems .

in addition , the plan is missing information about some legacy systems and modernization programs .

specifically , the plan does not include termination dates for 40 out of 514 legacy systems .

including a comprehensive and reliable list of legacy systems is important for the department to have a meaningful and reliable basis for managing the disposition of legacy systems and for sequencing the introduction of modernized business operations and supporting systems .

bta officials said that a number of actions are envisioned to address the above - cited areas and further improve the etp , such as working with the military departments and defense agencies to determine which systems should be included in the corporate - level etp and ensuring that the next version of the etp includes more information about dependencies among systems .

until the etp , or a federated family of such plans , either directly or by reference includes relevant information on the full inventory of investments across the department ( and does so in a manner that reflects consideration of the range of variables associated with a well - defined transition plan , such as timing dependencies among investments and the department's capability to manage them ) , it will not provide a sufficient basis for sequencing the introduction of modernized systems .

to help dod improve its etp , we have previously made recommendations that the department is in the process of addressing aimed at formalizing its plans for incrementally improving its transition plan .

another requirement of the act is that dod's annual it budget submission must include key information on each business system for which funding is being requested , such as the system's designated approval authority and the appropriation type and amount of funds associated with development / modernization and current services ( i.e. , operation and maintenance ) .

as we reported last year , the department's fiscal year 2009 budget submission included a range of information required by the act on business system investments .

specifically , for 273 investments that involve development / modernization activities , the submission included such information as the system's ( 1 ) name , ( 2 ) approval authority , and ( 3 ) appropriation type .

the submission also identified the amount of the fiscal year 2009 request that was for development / modernization versus operations / maintenance .

further , for those system investments in excess of $1 million in modernization funding , the submission cited the certification status ( eg , approved , approved with conditions , not applicable , and withdrawing ) and the dbsmc approval date , where applicable .

however , the fiscal year 2009 budget submission does not reflect all business system investments .

to prepare the submission , dod relied on business system investment information ( eg , funds requested , mission area , and system description ) that is entered by the components into dod's select and native programming data input system – information technology ( snap - it ) .

in accordance with dod guidance and according to asd ( nii ) / dod cio officials , the business systems listed in snap - it should match the systems listed in the defense information technology portfolio repository ( ditpr ) — the department's authoritative business systems inventory .

however , the number of business systems in ditpr is unclear .

specifically , in march 2009 , ditpr data provided by dod included about 6,800 systems , and in april 2009 , bta officials stated that the number of operational business systems in the repository was 2,480 , adding that the 6,800 number included systems that were not business systems and systems that may no longer be operational .

however , they have yet to provide support for this revised number of business systems .

regardless , snap - it is potentially missing thousands of business systems that are identified in ditpr .

specifically , snap - it contains about 2,100 systems , of which only about 1,500 are categorized as business systems .

restated , the fiscal year 2009 budget submission is missing somewhere between 980 and 5,300 business systems .

for example , the department of the navy's personnel information system for training , operations , and logistics and the air force's contractor responsibility information system are listed in ditpr but not listed in snap - it .

moreover , as stated earlier in the report , dod has also recognized limitations in its budget submission in its etp .

the asd ( nii ) / dod cio official responsible for administering the snap - it data said that while the components are responsible for ensuring that information about their respective systems is accurate and complete , the department recognizes the need to reconcile the information between snap - it and ditpr to improve the systems' comprehensiveness and accuracy .

however , the department has yet to develop a plan or time frame for doing so .

without a reliable comprehensive inventory of all defense business systems , dod will not be able to ensure the completeness and reliability of its it budget submissions .

the act also requires dod to establish business system investment review structures , such as the previously discussed dbsmc and five irbs , as well as processes that are consistent with the investment management provisions of the clinger - cohen act .

as we have previously reported , organizations that satisfy stages 2 and 3 of our itim framework have the investment selection , control , and evaluation structures , and the related policies , procedures , and practices that are consistent with the investment management provisions of the clinger - cohen act .

dod and the air force have largely established the kind of investment management structures provided for in the act and our itim framework .

however , the navy has not .

moreover , neither dod nor these components have defined the full range of related investment management policies and procedures that our framework identifies as necessary to effectively manage investments as individual business system programs ( stage 2 ) and as portfolios of programs ( stage 3 ) .

until all of dod has put these requisite investment management structures and supporting policies and procedures into place , the billions of dollars that the department and its components invest annually in business systems will remain at risk .

dod has largely established corporate - level organizational structures that are associated with stages 2 and 3 of our framework .

as we reported in may 2008 , the department has an enterprisewide investment board and four subordinate boards , and has assigned them responsibility for business systems investment governance , including conducting investment certification and approval reviews and annual reviews as provided for in the act .

the enterprisewide board — the dbsmc — is composed of the department's top executives , such as the deputy secretary of defense and the asd ( nii ) / dod cio , as provided for in the act .

among other things , the dbsmc is responsible for establishing and implementing policies governing the organization's investment process and approving lower - level investment board processes and procedures .

the subordinate boards include four irbs that are composed of senior officials representing their respective business areas , including representatives from the combatant commands , defense agencies , military departments , and joint chiefs of staff .

among other things , the irbs are responsible and accountable for overseeing and controlling certain business system investments , including ensuring compliance and consistency with the bea .

the department has also assigned responsibility to the under secretary of defense for acquisition , technology , and logistics for managing business system portfolio selection criteria .

since 2008 , the department has taken additional steps to establish a fifth irb , the dod chief information officer's review board , which is to oversee investments in business systems whose primary purpose is to support infrastructure and information assurance activities .

according to dod officials , this board is to replace the enterprise information environment mission area review board , which was the fifth board required by the act , and its charter has been drafted , but not approved .

with respect to the military departments' investment management structures , we reported in may 2008 that the air force had established the organizational structures associated with stages 2 and 3 of our framework , such as a business systems irb consisting of senior executives from the functional business units , including the office of the air force cio .

among other things , this board is responsible for business system investment governance , including conducting investment precertification , approval , and annual reviews , as required by the act .

we recently reported that , in contrast to the air force , the navy had not yet established an enterprisewide irb composed of senior executives from its it and business units , to define and implement a navy - wide business system governance process .

we concluded that without such structures , the navy's ability to ensure that business system investment decisions are made consistently and reflect the needs of the organization was limited .

accordingly , we recommended that the navy establish these management structures .

navy officials told us that a secretary of the navy instruction that is intended to address these limitations has been drafted but not yet approved .

dod has partially defined the full range of corporate and component - level policies and procedures that we previously recommended it establish to effectively support project - level ( stage 2 ) and portfolio - based ( stage 3 ) investment management practices .

specifically , dod recently issued new corporate - level policies and procedures that further address key practices in our itim framework associated with project - level investment management ( stage 2 ) , such as instituting the investment board and providing investment oversight .

in particular , dod's revised 2008 acquisition policy and draft business capability life cycle acquisition policy and guidance outline aspects of how the business investment review processes are to be coordinated with other decision - support processes used at dod , such as the joint capabilities integration and development system and the defense acquisition system .

for example , the revised policies and guidance now require a team to assess the risks associated with each major automated information system and to share the results with the program manager and component functional sponsor , who in turn are to collaboratively report the risks to both the irb and the program's milestone decision authority prior to each milestone decision .

they further require the dbsmc to approve the obligation of funds prior to the first milestone review of each major business system .

in addition , dod also recently revised its policy for overseeing the acquisition of systems that provide joint capabilities , to require all business system investments to comply with the business system investment review process and the business capability life cycle process .

the department has also recently established guidance associated with portfolio - level investment management ( stage 3 ) practices .

however , dod's updated corporate - level policies and procedures are still missing critical project - and portfolio - based investment man we previously recommended , as discussed below .

policies and procedures for instituting the investment board do not address how all investments that are past the development / modernization stage ( i.e. , in operations and maintenance ) are to be governed .

given that dod invests billions of dollars annually in operating and maintaining business systems , this is significant .

for example , while the 2009 up date to the irb guidance now requires an annual review of all investme previously certified by irbs , including those in operations and maintenance , this review is not required for systems in operations and maintenance that were not previously certified by the irbs .

our itimframework emphasizes that the corporate investment boards should review important information about an investment , such as cost and performance baselines , throughout the investment's life cycle .

in addition , while the department's investment process addresses how investme nt - related processes are to be coordinated with the joint capabilities integration and development system and the defense acquisition system , these processes do not apply to all business systems .

for example , do d's updated acquisition policy states that irb involvement in acquisition decisions is required only for major automated information systems .

moreover , the 2008 acquisition policy and draft business capability life cycle acquisition policy and guidance do not address how these process are to be coordinated with the planning , programming , budgeting , an execution process .

furthermore , the business capability life cycle acquisition policy and guidance has yet to be approved .

without approved policies and procedures that provide clear visibility into all inves including linkages to related mana gement systems , inconsistent investment decisions may result .

procedures for selecting an investment do not specify how the irbs use the full range of cost , schedule , and benefit data in making selection ( i.e. , certification ) decisions .

specifically , while the revised 2009 irb guida nce states that the irbs will consider cost , schedule , and benefit data in making certification decisions , the guidance does not define how the boards are to consider these factors .

according to our itim guidance , a structured selection method should provide investment boards , business units , and it developers with a common understanding of the selection process to be followed , including how cost , schedule , and benefit data are to be used to compare and select projects .

furthermore , while dod issued an irb roles and responsibilities policy in january 2009 that states that the c ertification authorities will define the selection criteria for determining whether an investment is to be an enterprisewide system or remain component specific , those certification authorities have yet to do so .

without documenting how the irbs employ such factors when making selection decisions , the department cannot ensure that the boards consistently and objectively select proposals that best meet the department's needs and priorities .

policies and procedures for overseeing an investment do not provide for sufficient visibility into component - level investment management activities , including component reviews of systems in operations and maintenance and smaller investments , commonly referred to as tier 4 investments .

such visibility is important because dod reports that only 346 system modernization efforts have been irb certified and dbsmc approved .

this means that the vast majority of business systems are reviewed and approved only within the component organizations .

while the january 2009 irb roles and responsibilities policy requires that each component submit an end - of - the - fiscal - year report listing those systems that have been reviewed by the cognizant irb , this report lacks important project information .

for example , it does not address components' adherence to cost , schedule , and risk investment selection and control criteria .

according to our itim framework , an investment board should have visibility into each project's performance and progress toward predefined cost , schedule , and benefit expectations as well as each project's exposure to risk .

without such visibility , dod components risk making investment decisions that are inconsistent and not fully grounded in objective data .

policies and procedures have not been fully established for defining the portfolio selection criteria or for creating and evaluating the portfolio of business systems .

specifically , the department has assigned responsibility to its certification authorities for defining the criteria to be used for making portfolio selection decisions , creating portfolios , and evaluating the performance of portfolio investments .

however , these authorities have yet to fulfill these responsibilities .

according to our itim framework , the development and use of portfolio selection criteria focuses on the synergistic benefits to be found among an agency's entire collection of investments , rather than just from the sum of the individual investments .

policies and procedures for conducting postimplementation reviews do not address all business systems .

specifically , in its january 2009 update to its irb guidance , the department added a new type of review , called a closeout annual review , to be performed when a business system modernization has been completed .

according to the guidance , this review is to function as a postimplementation review for irb - certified systems and is to provide the irbs with lessons learned and metrics about completed investment efforts .

however , the guidance does not address how expected benefits were achieved .

according to our itim framework , examining the differences between estimated and actual investment costs and benefits is a key aspect of conducting postimplementation reviews .

according to bta officials , these limitations are due to the newness of its investment review policies and procedures , which they said will be revised over time to address the limitations .

adequately documenting both the policies and the associated procedures that provide predictable , repeatable , and reliable investment selection and that control and govern how an organization manages its it investment portfolios reduces investment risk of failure and provides the basis for rigor , discipline , and repeatability in how investments are selected and controlled across the entire organization .

with respect to the military departments' investment management policies and procedures , we recently reported that the air force and the navy did not have fully documented policies and procedures for overseeing the management of business system investments and for developing and managing complete business systems investment portfolios .

to address these areas , we made recommendations aimed at implementing our framework's stage 2 and 3 practices , and dod partially agreed with these recommendations .

under dod's tiered accountability approach to reviewing and approving business systems investments , in which investment review begins at the component level and proceeds through a hierarchy of review and approval authorities , depending on the size and significance of the investment , it is vital that dod components implement these practices .

bta officials told us that the success of the department's overall process for managing business system investments depends on each component performing a thorough analysis and making informed decisions relative to each business system before it is submitted for higher - level review and approval .

to the air force's credit , it has recently updated its policies and procedures to address our project - level investment management recommendations ( stage 2 of our framework ) .

for example , the air force's recently developed it investment review guidance provides for the review of all business systems , to include those in operations and maintenance , and it defines the process by which its irb will review these systems .

further , the guidance specifies how business investments , including those in operations and maintenance , are to be prioritized using factors such as mission and strategic value and risk .

the air force has also addressed key practices associated with portfolio - level investment management ( stage 3 ) , such as creating and modifying it portfolio selection criteria and assigning responsibility for the development and modification of it portfolio selection criteria .

specifically , the guidance describes the criteria to be used to make portfolio selection , assigns responsibility for developing the criteria to an integrated working team , and assigns responsibility for approval of the criteria to a senior working group .

however , the air force's recent investment review guidance is still missing critical elements needed to effectively carry out essential investment management activities .

for example , the guidance does not yet specify how the business investment management activities are coordinated with other dod management systems , such as the joint capabilities integration and development system , the defense acquisition system , and the planning , programming , budgeting , and execution process .

further , the guidance does not provide for sufficient oversight and visibility into investment management activities .

specifically , while the air force has predefined criteria for adherence to cost , schedule , and performance milestones , and requires the development of corrective actions when a system deviates from milestones , it does not have policies and procedures that guide the implementation of these corrective actions when program expectations are not met .

moreover , the air force has yet to develop policies and procedures for maintaining investment portfolios .

according to the air force , such key practices will be addressed in future revisions to its guidance .

in contrast , the navy has not made as much progress as the air force in addressing either our project - level or portfolio - level recommendations .

for example , the navy has yet to fully document policies and procedures for overseeing the management of business system investments and for developing and managing complete business systems investment portfolios .

among other things , it does not have policies and procedures that specify decision - making processes for program oversight and describe how corrective actions should be taken when projects deviate from their project management plans .

according to the navy , a policy for addressing our recommendations has been drafted , but has yet to be approved .

as discussed in our itim framework , adequately documenting both the policies and associated procedures that govern how an organization manages its it projects and investment portfolios is important because doing so provides the basis for rigor , discipline , and repeatability in how investments are selected and controlled across the entire organization .

until these missing policies and procedures are fully defined at both the corporate and the component levels , it is unlikely that the thousands of dod business system investments will be managed in a consistent , repeatable , and effective manner .

the act specifies two basic requirements that took effect october 1 , 2005 , relative to dod's use of funds for business system modernization investments that involve more than $1 million in obligations .

first , it requires that these investments be certified by a designated approval authority as meeting specific criteria , such as demonstrating compliance with the bea .

second , it requires that the dbsmc approve each of these certifications , adding that failure to do so before the obligation of funds for any such investment constitutes a violation of the anti - deficiency act .

in addition , dod's business system approval and certification guidance directs programs to submit additional information , such as a program's economic analysis , to designated approval authorities .

as it has since 2005 , dod continues to certify and approve business system modernization investments in excess of $1 million .

however , since 2006 , we have identified limitations in the information used to certify and to approve several major programs .

moreover , although irb certification and annual review guidance calls for dod's authoritative business systems repository ( i.e. , ditpr ) to be used to inform business system investment certification and annual review decisions , information in this repository is not always current and accurate .

as a result , dod risks making certification and approval decisions that are not prudent and justified .

the department has established an approach to meeting the act's requirements that reflects its philosophy of tiered accountability .

under this approach , investment review begins within the military departments and defense agencies and advances through a hierarchy of review and decision - making authorities , depending on the size , nature , and significance of the investment .

for those investments that meet the act's dollar thresholds , this sequence of review and decision making includes component precertification , irb certification , and dbmsc approval .

for those investments that do not , investment decision - making authority remains with the component .

this review and decision - making approach has two types of reviews for business systems: certification / approval reviews and annual reviews .

certification / approval reviews .

certification / approval reviews apply to new modernization investments with planned obligations in excess of $1 million .

these reviews focus on program alignment with the bea and must be completed before components obligate modernization funds .

tier 1 , 2 , and 3 investments that involve development and modernization funds are certified and approved at three levels — component precertification , irb certification , and dbsmc approval .

at the component level , program managers are responsible for the information about their respective programs that is in ditpr .

examples of information contained in ditpr are regulatory compliance reports , architectural profiles , financial benefit information ( i.e. , benefit - to - cost ratio ) , and system life cycle costs .

according to the process , the component precertification authority is responsible for precertifying bea compliance and reviewing system modernization funding requests , in addition to ensuring that irbs receive complete , current , and accurate information within the prescribed deadlines .

the precertification authority asserts the status and validity of the investment information by submitting a component precertification letter to the appropriate irb .

at the corporate level , the irb reviews the precertification letter and related material , and if it decides to certify the investment , prepares a certification memorandum for the designated certification authority's signature that documents the irb's decisions and any related conditions .

the memorandum is forwarded to the dbsmc , which either approves or disapproves the irb's decisions and issues a memorandum containing its decisions .

if the dbsmc disapproves a system investment's certification , it is up to the component precertification authority to decide whether to resubmit the investment after it has resolved the relevant issues .

annual reviews .

the annual reviews apply to all business system investments and are intended to determine whether the investment is continuing to comply with the bea , meeting its milestones , and addressing its irb certification conditions .

tier 1 , 2 , and 3 business system investments are annually reviewed by the relevant component and irb .

at the component level , program managers update information on all tiers of system investments that are identified in their component's data repository .

for tier 1 , 2 , or 3 systems that are in development or being modernized , information is updated on cost , milestones , and risk variances and actions or issues related to certification conditions .

the component precertification authority then verifies and submits the information for these investments to the appropriate irb in an annual memo .

at the irb level , tier 1 , 2 , and 3 business system development or modernization investment reviews focus on program compliance with the bea , program cost and performance milestones , and progress in meeting certification conditions .

irbs can advise the dbsmc to revoke a certification when the investment has significantly failed to achieve performance commitments ( i.e. , capabilities , schedule , and costs ) .

when this occurs , the component must address the irb's concerns and resubmit the investment for certification .

since october 1 , 2005 ( the effective date of the relevant provision of the act ) , dod has continued to certify and approve investments with obligations in excess of $1 million .

since fiscal year 2005 , dod has reported that the dbsmc had approved system modernization efforts for a total of 346 systems .

according to dod: all but one of the 346 system modernization efforts were certified and approved as meeting the first condition in the act — being in compliance with the bea .

these systems involved about $8.5 billion in development / modernization funding .

about 60 percent of the 346 system modernization efforts ( 208 ) are owned by the military departments and were accordingly precertified within the military departments .

more specifically , 63 were precertified within the air force , 79 within the army , and 66 within the navy .

although dod has been meeting the act's requirement to certify and approve business system modernization programs , it has at times relied on limited information in doing so .

for example , we recently reported that two large navy business system programs did not adequately demonstrate compliance with the department's federated bea , even though each program largely followed dod's existing compliance guidance , used its compliance assessment tool , and was certified and approved as being compliant by department investment oversight and decision - making entities .

in particular , these programs' bea compliance assessments did not ( 1 ) include all relevant architecture products , such as products that specify the technical standards needed to promote interoperability among related systems ; ( 2 ) examine overlaps with other business systems , even though a stated goal of the bea is to identify duplication and thereby promote the use of shared services ; and ( 3 ) address compliance with the department of the navy's enterprise architecture , which is a major bea federation member .

we attributed these limitations to various reasons , including the fact that the department's guidance did not provide for performing these steps .

in addition , we reported that although the department's investment oversight and decision - making authorities certified and approved these business system programs as compliant with the bea , they did not validate each program's compliance assessment and assertions .

according to dod officials , this was because responsibility for doing so is assigned to dod's component organizations , such as the department of the navy , under the department's tiered accountability approach .

however , the department of the navy oversight and decision - making authorities also did not validate the programs' assessments and assertions .

we concluded that such architecture compliance limitations increase the risk of dod programs being defined and implemented in a way that does not sufficiently ensure interoperability and avoid duplication and overlap .

accordingly , we made a number of recommendations to address these limitations , which the department agreed to implement .

another example of limited information used to certify and approve business system investments is the unreliable economic justifications for the programs .

according to relevant dod guidance , the economic viability of system investments is to be analyzed on the basis of reliable estimates of costs and benefits .

however , we have continued to report on limitations in the cost / benefit analyses used to economically justify major dod business system investments .

more recently , we reported that the global combat support system – marine corps cost estimate was not reliable , as it was not based on historical data from similar programs and it did not account for schedule risks , both of which are needed for the estimate to be considered accurate and credible .

in addition , we reported that the navy enterprise resource planning program did not employ similar cost - estimating practices .

as a result , we concluded that neither program had a sufficient basis for deciding if it was the most cost - effective solution for meeting mission needs , and we made recommendations to address these weaknesses .

dod agreed with our recommendations .

since 2005 , ditpr has been designated as the authoritative repository of information about all dod business systems .

according to dod's business system certification and annual review guidance , information in ditpr is to be updated by component staff , validated by program managers , and reviewed by component precertification authorities to ensure its accuracy , and it is to be used by the irbs and the dbsmc in making certification and approval decisions , respectively .

the information in ditpr is not always accurate , and thus does not always provide an adequate basis for informed decision making .

according to asd ( nii ) / dod cio officials , information entered in ditpr at the component level is not always reliable and validated .

our analysis of selected business system information contained in ditpr confirmed such inaccuracies: at least 900 systems , such as the contractor performance assessment reporting system and the air force's virtual personnel service center , showed life cycle phase start dates as the year 1900 or 1901 .

at least 960 systems , such as the armed forces health longitudinal technology application and bta's wide area workflow system , show a life cycle phase end date of 2099 or later .

moreover , as stated earlier in this report , dod provided inconsistent information about the number of business systems contained in ditpr .

specifically , in march 2009 , ditpr data provided by dod included about 6,800 systems , and in april 2009 bta officials stated that the number of operational business systems in the repository was 2,480 .

thus , the number of business systems in ditpr is also unclear .

according to asd ( nii ) / dod cio officials , a policy is being developed to have the dod inspector general periodically validate the accuracy of the information in ditpr .

given that the information from ditpr is used to make certification and approval decisions , serious limitations in the accuracy of information could affect the quality of the decisions .

the pace of dod's progress in defining and implementing key institutional modernization management controls has slowed relative to each of the prior 4 years , leaving much to be accomplished .

specifically , the corporate bea continues to be missing important content , and it has yet to be federated through development of aligned subordinate architectures for each of the department's component organizations .

further , while the department has updated its strategy for federating the bea , this strategy is still missing important content and it has yet to be implemented .

compounding this situation are recurring limitations in the scope and completeness of the department's enterprise transition plan , as well as the immaturity of the military department architecture programs , including the completeness of their own transition plans .

in addition , the corporate and the military departments' approaches to business systems investment management continue to lack the requisite structures and defined policies and procedures to be considered effective investment selection , control , and evaluation mechanisms .

finally , information used to support the development of the transition plan and dod's budget requests , as well as to inform certification and annual reviews , is of questionable reliability .

collectively , these long - standing limitations in the department's institutional modernization management controls continue to put billions of dollars spent each year on thousands of business system investments at risk .

a well - defined federated architecture and accompanying transition plans for the business mission area , along with well - defined investment management policies and procedures across all levels of the department , are critical to effectively addressing dod's business systems modernization high - risk area .

relatedly , it is important for the department to obtain independent assessments of the completeness , consistency , understandability , and usability of the federated family of business mission area architectures , including associated transition plans , and to share the results of these assessments with its authorizing and appropriations committees .

equally important is for the department to actually implement its architecture and investment management controls in the years ahead on each and every business system investment , and in doing so to ensure that it has reliable information on each investment upon which to base executive decision making .

our previous recommendations to the department have been aimed at accomplishing these and other important activities related to its business systems modernization .

while not a guarantee , having an architecture - centric investment management approach , combined with the actual implementation of other key system acquisition disciplines that are reflected in our existing recommendations , can provide a recipe for the business systems modernization program's removal from our high - risk list .

to the department's credit , it has agreed with these recommendations and committed to implementing them .

moreover , over the previous several years , it has made important progress in doing so , as prior reports have recognized .

however , the pace of the progress has slowed over the last year as the roles , responsibilities , authorities , and relationships among recently established executive positions that are integral to defining and implementing these controls are worked out .

in light of this , it is essential that the dbsmc , which is chaired by the dod cmo , resolve these positional matters , as doing so is on the department's critical path for fully establishing the full range of institutional management controls needed to address its business systems modernization high - risk area .

because we have existing recommendations that address most of the institutional management control weaknesses discussed in this report , we reiterate these recommendations .

in addition , to ensure that dod continues to implement the full range of institutional management controls needed to address its business systems modernization high - risk area , we recommend that the secretary of defense direct the deputy secretary of defense , as chair of the dbsmc and as dod's cmo , to resolve the issues surrounding the roles , responsibilities , authorities , and relationships of the deputy cmo and the military department cmos relative to the bea and etp federation and business system investment management .

further , to ensure that business system investment reviews and related certification and approval decisions , as well as annual budget submissions , are based on complete and accurate information , we recommend that the secretary of defense direct the appropriate dod organizations to develop and implement plans for reconciling and validating the completeness and reliability of information in its ditpr and snap - it system data repositories , and to include information on the status of these efforts in the department's fiscal year 2010 report in response to the act .

in written comments on a draft of this report , signed by the assistant deputy chief management officer and reprinted in appendix ii , the department stated that it has made important progress over the past year on its business system modernization , adding that this progress partly addresses our prior recommendations .

we agree that the department has continued to make progress , and our report recognizes this .

however , our report also recognizes that the pace of this progress has slowed in relation to prior years , and it links this slowdown to implementation of recent management structural changes within the department , which dod's comments acknowledge have had to occur simultaneously .

to facilitate implementation of these structural changes , we recommended that dod resolve the issues surrounding the roles , responsibilities , authorities , and relationships of the deputy cmo and the military department cmos relative to the bea and etp federation and business system investment management .

dod partially agreed with this recommendation .

in particular , the department agreed that additional clarity would be useful in defining the roles and responsibilities of these positions and stated that it is committed to resolving this ambiguity through formal policy in the near future .

however , the department stated that it believes that the deputy cmo has the necessary authority , working on behalf of the deputy secretary of defense , and that the deputy cmo has a sufficiently close working relationship with the deputy cmos of the military departments to make significant strides in the department's business operations improvement efforts , even in the absence of near - term formal guidance .

we do not agree .

as we have previously reported , the department has designated the role of the deputy cmo as an advisor to the cmo , and it has not assigned the deputy cmo clear decision - making authority .

further , the absence of clarity around the deputy cmo's role and responsibilities , which dod acknowledged in its comments , combined with this absence of clear decision - making authority , directly affects the nature of the deputy cmo's relationship with other senior leaders in the department , as relationships are a function of roles , responsibilities , and authorities .

therefore , we stand by our recommendation .

with regard to our second recommendation , to develop and implement plans for reconciling and validating the completeness and reliability of information in its ditpr and snap - it data repositories , and to include information on the status of these efforts in the department's fiscal year 2010 report in response to the act , dod stated that it partially agreed with the recommendation .

in particular , it agreed with the need to reconcile information between the two repositories and stated that it has begun to take actions to address this .

for example , it stated that policy and guidance now require the components to enter information in both ditpr and snap - it using what it described as a “one - to - one” relationship for all defense business systems , and that the dod cio is working with the components to facilitate implementation of this requirement .

in addition , it stated that the dod cio and office of program analysis and evaluation are currently developing a plan to modify both ditpr and snap - it to eliminate duplicate data and integrate them .

notwithstanding its actions aimed at reconciling ditpr and snap - it data , dod commented that it disagreed that the data in the two repositories are unreliable , stating that differences in the data between the two are due to differences in the purpose of each repository , and that the data in each are complete and accurate enough to support their purposes .

in response , we recognize that the repositories are used for different purposes .

however , dod guidance calls for business system information in the two repositories to be consistent and maintained at the same level of detail , which , as we state in our report , is not occurring .

in particular , the number of business systems in ditpr and snap - it is not consistent , which means that one or both lack important information about dod business systems .

as also stated in our report , system - specific information contained in ditpr is not accurate .

for example , at least 900 systems showed life cycle phase start dates as the year 1900 or 1901 , and at least 960 systems show a life cycle phase end date of 2099 or later .

in addition , during the course of our review , dod officials that we interviewed and who operate these repositories recognized these data limitations and agreed that more needed to be done to ensure data reliability .

dod also provided technical comments on a draft of this report that we have incorporated throughout the report , as appropriate .

we are sending copies of this report to interested congressional committees ; the director , office of management and budget ; and the secretary of defense .

this report will also be available at no charge on our web site at http: / / www.gao.gov .

if you or your staffs have any questions on matters discussed in this report , please contact me at ( 202 ) 512-3439 or hiter@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

gao staff who made major contributions to this report are listed in appendix iii .

as agreed with defense congressional committees , our objective was to assess the department of defense's ( dod ) actions to comply with the requirements of section 2222 of title 10 , u.s. code .

to address this , we used our last annual report under the act as a baseline , analyzing whether the department had taken actions to comply with five of the six requirements in section 2222 , related best practices contained in federal guidance , and our prior recommendations that we previously identified as not yet addressed .

generally , these five requirements are ( 1 ) development of a business enterprise architecture ( bea ) , ( 2 ) development of an enterprise transition plan ( etp ) for implementing the bea , ( 3 ) inclusion of business systems information in dod's budget submission , ( 4 ) establishment of business systems investment review processes and structures , and ( 5 ) approval of defense business systems investments with obligations in excess of $1 million .

 ( see the background section of this report for additional information on the act's requirements. ) .

we did not include the sixth requirement , on delegating the responsibility for business systems to designated approval authorities , because our november 2005 report under the act shows that it had been satisfied .

our methodology relative to each of the five requirements is as follows: to determine whether the bea addressed the requirements specified in the act and related guidance , we analyzed version 6.0 of the bea , which was released on march 13 , 2009 , relative to the act's specific architectural requirements and related guidance that our last annual report under the act identified as not being fully implemented .

specifically , we interviewed business transformation agency ( bta ) officials and reviewed written responses and related documentation on steps completed , under way , or planned to address these weaknesses .

we then reviewed architectural artifacts in version 6.0 to validate the responses and identify any discrepancies .

further , we analyzed bea supporting documentation ( eg , bea compare reports ) to determine the number of additions , updates , and deletions made to bea artifacts ( eg , bea business rules , data elements , data objects , data entities , information exchanges , system data exchanges , system entities , system functions , system interfaces , and technical standards ) as compared with the architectural content of version 5.0 .

we also analyzed bea supporting documentation to identify the number of additions , updates , and deletions made to bea artifacts ( eg , bea business rules , data objects , system data exchanges , system entities , and system functions ) that were specifically associated with the financial visibility business enterprise priority area .

to evaluate progress made in federating dod's bea , we reviewed dod's business mission area architecture federation strategy and roadmap version 2.4 , released in january 2008 , comparing the strategy and any associated implementation plans with prior findings and recommendations relative to the content of the strategy .

we also obtained documentation and interviewed cognizant dod officials about efforts to establish a federated dod business mission area enterprise architecture .

further , we reviewed the military departments' responses on actions taken or planned to address our previous recommendations on the maturity of their respective enterprise architecture programs .

in addition , we reviewed the independent verification and validation ( iv&v ) contractor's statement of work and iv&v reports to determine whether they addressed the quality of the department's federated family of corporate and component architectures , including the federated etps , and we interviewed the iv&v contractor and bta officials to determine plans for future iv&v work to address the architectures' quality .

to determine whether the dod etp addressed the requirements specified in the act , we reviewed the updated version of the etp , which was released on september 15 , 2008 , relative to the act's requirements and related transition plan guidance that our last annual report under the act identified as not being fully implemented .

specifically , we interviewed bta officials and reviewed written responses and related documentation on steps completed , under way , or planned to address these weaknesses .

we then reviewed the plan to validate the responses and identify any discrepancies .

in addition , to determine the extent to which the etp included system and budget information for all the business systems identified in the department's information technology ( it ) systems repository , we reviewed and compared the number of defense business systems listed in the department's authoritative business systems inventory — the defense information technology portfolio repository ( ditpr ) — with the number in its it budget system , the select and native programming data input system — information technology ( snap - it ) , with the number in the etp .

further , we reviewed and compared business system information , such as legacy system migration information in the etp , with the information obtained from our recently completed and ongoing business system reviews to determine whether the information was consistent .

we interviewed bta officials to discuss any discrepancies .

furthermore , we obtained and reviewed information from the departments of the air force , army , and navy on the extent to which they have made progress in satisfying existing recommendations associated with developing their respective etps .

we were unable to determine whether dod's fiscal year 2010 information technology budget submission was prepared in accordance with the criteria set forth in the act because the budget submission was not released in time for us to review for this report .

instead , we analyzed and compared information contained in the department's system that is used to prepare its budget submission ( snap - it ) with information in the etp and dod's ditpr system to determine if dod's fiscal year 2009 budget request included all business systems .

we interviewed bta and assistant secretary of defense ( networks and information integration ) / department of defense chief information officer ( asd ( nii ) / dod cio ) officials to discuss the accuracy and comprehensiveness of information contained in the snap - it system , the discrepancies in the information contained in the etp , ditpr , and snap - it systems , and efforts under way or planned to address these discrepancies .

dod officials were not able to provide the supporting data to address any discrepancies in the number of business systems contained in ditpr in time for inclusion in our report .

to determine whether dod has established investment review structures and processes , we focused on the one investment review board specified in the act that we previously reported had yet to be established .

accordingly , we obtained documentation from and interviewed cognizant dod officials about actions completed , under way , and planned relative to the establishment of the dod chief information officer investment review board .

we also obtained and reviewed documentation — such as dod it defense business systems investment review process guidance and operation of the defense acquisition system , department of defense instruction number 5000.02 , as well as the air force information technology investment review guide and air force information technology portfolio management and it investment review — and interviewed knowledgeable dod officials about efforts to address dod corporate and component investment management - related weaknesses that we identified in previous reports .

we also reviewed and leveraged our previous reports that addressed dod corporate and component approaches to managing business system investments .

to determine whether the department was reviewing and approving business system investments exceeding $1 million , we obtained information from bta on the number of defense business systems certified and approved since our last annual review , including information about air force , army , and navy actions that were taken in order to perform the annual systems reviews as required pursuant to the act .

in addition , we summarized the results of recent reports associated with information used during the certification and annual review process .

we also interviewed bta and asd ( nii ) / dod cio officials to determine the steps taken , planned , or under way to validate the accuracy of the information in ditpr to be used by the review boards in making certification and approval decisions .

in addition , we analyzed selected business system information contained in ditpr , such as system life cycle start and end dates , to validate the reliability of the information .

we did not independently validate the reliability of the cost and budget figures provided by dod because the specific amounts were not relevant to our findings .

we conducted this performance audit at dod offices in arlington , virginia , from january 2009 to may 2009 , in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objective .

in addition to the contact person named above , key contributors to this report were neelaxi lakhmani ( assistant director ) , justin booth , michael holland , anh le , emily longcore , lee mccracken , christine san , sylvia shanks , jennifer stavros - turner , and adam vodraska .

