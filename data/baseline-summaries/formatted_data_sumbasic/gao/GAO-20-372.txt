today's globalized economy and transportation systems allow infectious diseases to spread more rapidly than ever .

notable outbreaks include novel coronavirus beginning in 2019 , zika virus disease ( zika ) in 2015 , ebola virus disease ( ebola ) in 2014 , and h1n1 pandemic influenza in 2009 .

disease outbreaks can cause catastrophic harm to the united states , disrupt economic and social systems , and kill , sicken , and traumatize people on a massive scale .

for example , approximately 1 billion people worldwide get sick annually from zoonotic pathogens — pathogens that can spread from animals to humans — of which , approximately 15 million people die .

such outbreaks are on the rise .

the latest example is the novel coronavirus disease which had , as of may 6 , 2020 , caused approximately 250,000 deaths worldwide and sickened approximately 3,600,000 people .

in the united states , the virus had caused approximately 63,000 deaths , and sickened approximately 1,200,000 people .

the situation has heightened u.s. attention to potential future infectious disease threats and raised questions about the nation's preparedness and response capabilities .

it has also raised concerns among some members of congress about how federal agencies predict the spread of emerging infectious diseases , in particular through the use of modeling .

a model is a simplified representation of reality expressed through mathematical or logical relationships .

modeling is widely used in fields as diverse as engineering , finance , meteorology , and wildlife management .

in public health , infectious disease modeling can help decision makers by predicting the social and economic effects of an intervention and informing spending for preparedness and response , among other things .

it can answer public health questions that other methods cannot , whether for practical , ethical , or financial reasons .

however , because models simplify reality , they may give misleading answers if the underlying data or assumptions are flawed or not fully understood by decision makers .

further , some real - world systems can be difficult to model because of their inherent complexity , scale , or randomness .

for these and other reasons , researchers must carefully design , interpret , and communicate the results of models that may be used to support public health decisions .

understanding where and when infectious disease outbreaks may occur can provide information — in near real time — to decision makers who help set disease control policies and allocate resources .

you asked us to examine how federal agencies have used models to inform decision - making in recent infectious disease outbreaks , and the limitations and challenges in developing and using models .

this report examines ( 1 ) the extent to which the department of health and human services ( hhs ) has developed or used models to inform public health planning , policy , and resource allocation for ebola , zika , and pandemic influenza ; ( 2 ) the extent to which hhs coordinated its modeling efforts for selected infectious diseases ; and ( 3 ) steps hhs took to develop and assess the performance of its models for the selected infectious diseases and steps it applied to a selection of infectious disease models .

it also ( 4 ) describes the extent to which hhs has addressed challenges related to modeling for selected infectious diseases .

in our review , we focused on hhs because of its leadership in scientific and technical issues related to infectious disease modeling , role in infectious disease outbreak preparedness and response activities , and use of infectious disease modeling for policy and regulatory activities .

within hhs , we identified four agencies — the centers for disease control and prevention ( cdc ) , office of the assistant secretary for preparedness and response ( aspr ) , national institutes of health ( nih ) , and food and drug administration ( fda ) — that may develop or use infectious disease models .

it is important that these agencies coordinate with one another and with other relevant external entities to avoid the overlap and duplication of modeling efforts across agencies and to share new ideas and advances in modeling that might lead to new insights .

we focused on three infectious diseases in our review: ebola , zika , and pandemic influenza .

we selected these diseases based on their inclusion on the national institute of allergy and infectious diseases' emerging infectious diseases / pathogens list and consulted with agency officials and five infectious disease modeling experts for input on the selection of diseases in our review .

we selected the experts based on our background research and input from agency officials ( additional details on expert selection methodology can be found in appendix i ) .

to examine the extent to which hhs has conducted modeling to inform public health planning , policy , and resource allocations for selected infectious diseases: we interviewed agency personnel , including agency officials and staff who develop and use models , referred to here as “modelers,” and reviewed agency documents and reports to determine how or why the agencies develop or fund models ; determine the types of models used and the questions they are addressing ; or obtain a general description and specific examples of how these agencies use models to inform planning , policy , and resource allocation .

we interviewed nih officials about funding for research related to modeling for the selected diseases .

we interviewed officials from five state health departments — selected based on a review of a cdc draft report on model usage , on the level of influenza activity that states experienced , and geographic variation by u.s. region — about their experiences using cdc - developed modeling tools for influenza response .

for context on and examples of the types of modeling that cdc and aspr conducted , we reviewed documents cdc and aspr officials provided to us or cited in our interviews .

 ( for a bibliography of models reviewed , see appendix ii. ) .

we did not include fda and nih in this portion of the review , because fda has a limited role in modeling , and nih funds , rather than conducts , modeling .

to examine the extent to which hhs agencies coordinated their modeling efforts for the selected infectious diseases: we interviewed agency officials and reviewed documents related to coordination and collaboration , including memoranda of understanding between agencies , to identify the nature and extent of coordination and collaboration across hhs agencies that conduct or fund modeling .

we compared these actions to six of the eight leading collaboration practices we identified in our prior work based on their relevance to the coordination efforts we reviewed ( see appendix i ) .

in this report , and in our past work , we define coordination broadly as any joint activity that is intended to produce more public value than could be produced when organizations act alone .

to examine steps hhs took to develop and assess the performance of models for selected diseases and the steps it applied to a selection of infectious disease models: we identified steps that infectious disease modelers generally consider when developing and assessing the performance of models from a synthesis of information gathered from interviews with agency officials , interviews with additional relevant experts , and reviews of documents .

from these sources , we also gathered information on how these assessments may impact the use of models for public health decision - making .

we reviewed information regarding steps taken to develop and assess the performance of models , for a non - probability sample of models in published papers or memos , including seven models prepared by cdc ( two each for ebola and zika , and three for pandemic influenza ) ; and three prepared by aspr ( one for each disease ) .

we compared the steps taken in the development and assessment of the performance of these models to the commonly - considered steps we identified as described above and followed up with agencies to confirm our determinations and gather information on why some steps were not taken .

to describe the extent to which hhs has addressed challenges related to modeling for selected infectious diseases , we took the following steps: we interviewed selected experts regarding modeling - related challenges .

we also interviewed agency officials , including modelers , and selected experts , regarding challenges and limitations related to modeling ; steps they've taken to address the challenges ; and whether these challenges can be addressed or are ongoing .

we reviewed documents and reports from agencies and other sources such as the national science and technology council report , “towards epidemic prediction: federal efforts and opportunities in outbreak modeling” to identify challenges related to modeling and steps taken or recommended , if any , to alleviate these challenges .

we conducted this performance audit from may 2018 to may 2020 in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

in the united states , hhs is the lead federal agency responsible for public health .

its responsibilities include preparing for , mitigating , responding to , and recovering from public health emergencies .

within hhs , aspr and cdc prepare for and respond to infectious disease outbreaks .

aspr leads and coordinates national preparedness and response to outbreaks in the united states .

it also coordinates and supports advanced research and development , manufacturing , and procurement and deployment of medical countermeasures , such as vaccines , drugs , therapies , and diagnostic tools that can be used in the event of a potential public health emergency to protect the public from harm .

cdc monitors and responds to outbreaks by , among other things , studying the link between infection and health ; monitoring and reporting cases of infection ; and providing guidance to the public , travelers , and health care providers .

during public health emergencies , cdc may operate an emergency operations center ( eoc ) for monitoring and coordinating its response to emergencies — including infectious disease outbreaks of ebola , zika , and pandemic influenza — in the united states and abroad .

the eoc staff helps with directing specific incident operations ; acquiring , coordinating , and delivering resources to incident sites ; and sharing incident information with the public .

other agencies perform additional work related to infectious diseases .

for example , fda monitors and protects the blood supply , and nih makes grant awards that support research related to diseases and modeling .

aspr , cdc , and fda have different approaches to modeling .

in the cases of zika , ebola , and pandemic influenza , cdc and aspr are two key agencies that conduct federal infectious disease modeling efforts .

as of february 2020 , aspr had a centralized modeling unit staffed by about nine people , who are a mix of federal and contract employees , according to aspr officials .

at cdc , however , modeling is decentralized and integrated into the individual centers that make up the agency .

some staff work full time on modeling , while others spend part of their time on other tasks .

in addition , some of cdc's modeling efforts are conducted externally .

according to cdc , approximately 70 staff members participated in modeling studies , as of october 2018 .

of those staff , cdc's health economics and modeling unit employed about 10 modelers who have worked on ebola and other diseases .

for zika , cdc officials responding to zika said most modeling work was done by one modeler in cdc's division of vector - borne diseases , a part of the national center for emerging and zoonotic infectious diseases .

cdc influenza officials said influenza modeling is conducted by six or seven members of cdc's influenza division .

agency infectious disease modeling activities are not limited to ebola , zika , or pandemic influenza .

agency efforts to protect the nation from disasters and emergencies can be organized into two elements: preparedness and response .

infectious disease modeling is one tool used to inform a wide range of decisions related to outbreak preparedness and in response to an outbreak .

in the context of infectious disease outbreaks , aspr and cdc perform work on preparedness and response .

for example , aspr leads the public health emergency medical countermeasures enterprise ( phemce ) , an interagency group that helps develop medical countermeasures — fda - regulated products including drugs , or devices that may be used in the event of a potential public health emergency to protect the public from harm .

cdc may activate its eoc to assist with the response during an outbreak .

for example , during the 2014-2016 west africa ebola outbreak , cdc activated its eoc in july 2014 to help coordinate activities .

cdc personnel were deployed to west africa to assist with response efforts , including surveillance , data management , and laboratory testing .

since the 1980's , emerging infectious diseases have resulted in more recurrent disease outbreaks , causing an increasing number of human infections .

emerging infectious diseases have at least one of the following characteristics: they are newly recognized , have emerged in new areas , are newly affecting many more individuals , or have developed new attributes .

some of these diseases — including ebola and zika — are zoonotic pathogens , meaning they spread from animals to humans .

zoonotic pathogens can be carried from an animal to a human by another animal , such as a mosquito , chicken , or bat , which is known as a vector .

such pathogens sicken approximately 1 billion people annually .

according to the world health organization , ebola causes an acute , serious illness , which is often fatal if untreated .

ebola is introduced into human populations through close contact with the blood and other bodily fluids of infected animals .

humans spread ebola through direct contact with the bodily fluids of infected individuals or objects contaminated with these fluids .

ebola symptoms include fever , muscle pain , vomiting , diarrhea , impaired kidney and liver functioning , and , in some cases , internal and external bleeding .

there have been five ebola outbreaks since 2014 , including the 2014-2016 west africa outbreak which caused more than 28,600 cases and 11,325 deaths .

since 2018 , there has been an ongoing outbreak in the democratic republic of the congo .

figure 1 provides a timeline of ebola outbreaks since 2014 .

zika is a virus that is primarily transmitted through mosquito bites .

it can cause symptoms such as fever , rash , conjunctivitis ( red eyes ) , and joint and muscle pain .

it can also be transmitted from mother to child during pregnancy , or around the time of birth , or from person to person through sexual contact or blood transfusion .

many infected people do not have symptoms or will only experience mild symptoms .

the zika outbreak that began in 2015 affected individuals infected with the virus in ways that had not been seen with previous outbreaks of the disease .

specifically , during the 2015-2016 outbreak , zika infection in pregnant women was linked to microcephaly and other severe brain defects , according to cdc .

cdc officials said this was the first time in more than 50 years that an infectious pathogen has been identified as the cause of birth defects .

zika was also linked to other problems , such as miscarriage , stillbirth , and guillain - barré syndrome , an uncommon disorder affecting the nervous system .

in the western hemisphere , the first cases of locally - transmitted zika were confirmed in brazil in may 2015 .

in december 2015 , locally - transmitted zika was reported in puerto rico .

on january 22 , 2016 , cdc activated its emergency operations center to respond to outbreaks of zika occurring in the americas and to increased reports of birth defects and guillain - barré syndrome in areas affected by zika .

within the continental united states , the first locally - transmitted cases were confirmed in florida in june 2016 .

the world health organization declared zika a public health emergency of international concern from february to november 2016 .

in the spring of 2009 , a novel influenza virus emerged , known as influenza a ( h1n1 ) pdm09 .

according to cdc , it was detected first in the united states and quickly spread across the world , causing a pandemic or global outbreak of a new influenza a virus .

this new virus contained a combination of influenza genes not previously identified in animals or people .

the virus was very different from other h1n1 viruses circulating at the time , so seasonal influenza vaccines offered little cross - protection against infection with the new h1n1 virus , according to cdc .

a vaccine against the new virus was produced , but it was not available in large quantities until late november — after the peak of illnesses during the second wave in the united states .

cdc activated its eoc on april 22 , 2009 , to manage the h1n1 response .

from april 12 , 2009 , to april 10 , 2010 , cdc estimated there were about 60.8 million cases , 274,304 hospitalizations , and 12,469 deaths in the united states due to the new h1n1 virus .

according to cdc , few young people had any existing immunity — as detected by antibody response — to the virus , but nearly one - third of people over 60 years old had antibodies against it , likely from exposure to an older h1n1 virus .

multiple strains of influenza can infect humans , including strains that originate in animals .

according to cdc , human infections with an asian lineage avian influenza a ( h7n9 ) virus were first reported in china in march 2013 .

during an epidemic that lasted from october 1 , 2016 , through september 30 , 2017 , the world health organization reported 766 human infections with h7n9 virus , making it the largest h7n9 epidemic .

from 2013 to december 7 , 2017 , there were 1,565 humans infected with asian lineage h7n9 reported by the world health organization .

according to cdc , while the risk posed by h7n9 virus to the public's health was low , the agency was concerned about its pandemic potential .

agencies use infectious disease models to answer a variety of public health questions , including those related to outbreak preparedness and response .

a model is a physical , mathematical , or logical representation of a system , phenomenon , or process that allows a researcher to investigate that system , phenomenon , or process in a controlled way .

for example , the classic susceptible - infected - recovered or “sir” model divides a population into three categories: 1 ) susceptible to the disease , s ; 2 ) infected and infectious , i ; and 3 ) recovered or removed from the infected or susceptible population , r. this model uses equations to determine how many people move between these three categories .

the equations contain parameters — numerical descriptors of the disease based , for example , on experiment , expert opinion , or statistics of an ongoing or past outbreak .

the equations allow the researcher to estimate how many people are or could be affected by the disease .

for example , for past ebola outbreaks , models estimated that after 40 days , about 44 percent of the population in close contact with infected individuals was susceptible to infection , 31 percent was infected , and 22 percent was recovered .

based on these parameters , equations for transfer between categories , and underlying demographics of the community , an epidemiologist could use the model to estimate how many people within a given town could be susceptible , infected , or removed from the categories of susceptible or infected ( due to death or recovery and immunity ) .

based on model estimates and if a vaccine was available , cdc officials said the decision maker could plan for a specific number of vaccine kits and additional medical staff and supplies to treat infected patients .

models can also help agency officials anticipate future outbreaks , forecast the spread or severity of a disease , and predict the effects and costs of different intervention options .

after an outbreak , models can help sort out what happened , what drove the outbreak , and how it compared to past outbreaks .

other tools are available to accomplish some of these tasks , but models are particularly useful when existing data are not sufficient to answer a given question , or when agencies need to integrate data from disparate sources .

infectious disease models can be put into two broad categories: statistical models .

this type of model identifies relationships or patterns that can be used to describe what is occurring or predicts what may occur in the future based on what has occurred in the past .

statistical models tend to use a large amount of data , such as past observed events , to forecast future events , such as disease occurrence , but do not require a fundamental understanding of biological processes or human behavior .

they can predict outcomes when causes are not known or understood and when scientific understanding of a disease is limited .

they tend to use large amounts of data on past events to forecast future events .

statistical models do not provide full explanations about an infectious disease but may be used when epidemiologists have all or most of the data needed to test a hypothesis .

several benefits can be derived from statistical modeling , including the ability to control for multiple factors that might impact the outcome reviewed , and the ability to isolate the potential effect of infectious disease factors on a particular outcome .

mechanistic models .

mechanistic models rely heavily on scientific evidence and theory related to infectious diseases , and the understanding of disease dynamics or human behavior from prior knowledge — such as biological processes or interactions between people — to represent known processes .

they use basic infectious disease science to inform public health guidance and provide insights into outbreak emergence , spread , and control .

for example , population - based models can simulate the course of an epidemic by dividing the population into different categories , such as susceptible , infected , and recovered .

mechanistic models can project the likely course of disease transmission , calculate and predict the effect of proposed interventions , and take into account variable conditions , such as human behavior .

both statistical and mechanistic models can range from simpler to more complex .

a simpler model may , for example , have fewer parameters ( inputs ) or equations than a more complex model .

according to cdc modelers and an expert , a simpler model may be run with a variety of software , ranging from spreadsheet software to more sophisticated software , whereas more complex models are usually run using sophisticated statistical or mathematical programming languages .

as a model becomes more complex , it can become harder to describe , recreate , and understand its internal functioning .

modeling is identified as a beneficial tool in various national plans for disease response and biodefense .

these plans do not define the extent to which modeling should occur or how models should be developed for policy , resource allocation , or planning purposes .

see table 1 for examples of relevant national plans .

cdc and aspr use models primarily to answer questions from decision makers .

cdc and aspr officials told us , and documents show , that modeling is one source of information that may inform such decisions , along with sources such as expert opinion , surveillance , other prior work on the disease , and an official's own knowledge .

cdc modelers and officials said there is no “rule” as to when to use models , and in some situations , it may not be considered useful .

for example , cdc did not use modeling when issuing a travel notice for an ebola outbreak in specific provinces in the democratic republic of the congo , officials said .

instead , cdc based the travel order on an analysis that considered disease incidence and prevalence , public health infrastructure , and the availability of therapeutics , among other things .

similarly , cdc officials responding to ebola said modeling may be undesirable when it would take too long to engage the necessary external subject matter experts or when modeling would detract from responding to a disease .

cdc and aspr modelers use models for a variety of purposes .

cdc officials said modeling is done differently for each disease , and the amount and type of modeling varies across cdc centers , in part because some centers have less capacity to conduct modeling than others .

according to a cdc internal report , the most frequent uses of infectious disease modeling at cdc are: guiding preparedness and response efforts ; conducting economic analyses to evaluate the benefits of public health actions , thereby reducing illness and deaths from infectious diseases ; understanding pathogen biology , disease transmission , and estimating disease burden ; and assessing the effect of interventions and prevention strategies .

aspr modelers and officials said models have provided information about topics such as: resources , including protective equipment , needed to help respond to an ebola outbreak ; the number of therapeutics and vaccine doses needed to respond to ebola , both in africa and domestically ; expected u.s. demand for zika diagnostics ; and the number of vaccine doses needed to mitigate the spread of pandemic influenza .

aspr modelers and officials said modelers tend to serve in a broad role that can include modeling , data analysis , or other tasks .

for example , officials said a modeler could provide a team with day - to - day analytic support and not necessarily spend time developing models or use them .

additionally , aspr maintains a visualization hub that can be used for outbreak planning and response , including outbreaks of pandemic influenza and other emerging infectious diseases ( see fig .

2 ) .

cdc and aspr modelers and officials said they generally initiate modeling in response to questions from decision makers .

the modelers then work closely with epidemiologists and other subject matter experts to answer the questions .

modeling , according to cdc officials , may be used by individuals or groups within centers , such as division directors , branches , or teams to influence decisions .

who answers a particular question depends , according to aspr modelers and officials , on the decision maker .

sometimes questions asked will not be within their mission — modelers may suggest such questions be sent to a more relevant agency or part of hhs .

cdc and aspr have modeled to answer a variety of public health questions relevant to ebola , zika , and pandemic influenza , and , at times , the results helped inform policy and planning decisions .

modelers and officials provided the following examples: planning: aspr modelers and officials said the bulk of the agency's modeling is related to the planning , development , and deployment of medical countermeasures .

for example , these modelers and officials said many clinical trials for vaccines and therapeutics were planned during the 2014-2016 ebola outbreak response .

as a part of these planning activities , aspr modelers said modelers developed forecasts of future trajectories of disease incidence under a variety of conditions .

these forecasts indicated a significant likelihood the disease incidence in sierra leone could decrease to a level that would significantly reduce the success of the trials , according to modelers .

additionally , at the beginning of the 2014-2016 ebola outbreak response , cdc modelers received modeling questions related to the resources needed to effectively limit the spread of the disease , according to cdc documentation .

cdc used models to predict the number of ebola cases that could be expected over time with and without disease interventions such as ebola treatment units , community care centers , and safe burials .

on the basis of this information and other factors , including a united nations document on ebola needs , cdc leadership and other u.s. government officials recommended a rapid increase in ebola response aid , according to cdc documentation .

according to cdc documentation , later analyses demonstrated that this increase helped to greatly reduce the actual number of cases , compared to the likely number if prompt action had not been taken .

additionally , in response to the h7n9 influenza outbreak in 2017 , aspr modeled to determine when doses of influenza vaccine should be delivered and how many doses should be administered in order to mitigate a domestic outbreak .

this model found that having a vaccine stockpile could be helpful in preventing disease and that a slow effort to administer an h7n9 vaccine could reduce the vaccine's usefulness .

policy: during the zika outbreak , cdc modelers and officials said they modeled to determine the potential effectiveness of using pesticides to remove insects from aircraft , trains , or ships .

according to modelers and agency officials , the issue arose as concern about zika virus grew , including from other countries and u.s. agencies , like the department of transportation and department of defense .

the model indicated that humans are more likely than insects to transport zika on airplanes , and officials therefore concluded that the use of pesticides on airplanes would not be an effective intervention .

according to cdc modelers and officials , this modeling resulted in an additional sentence being added to world health organization policy , which stated that pesticide use was not expected to be effective .

the extent of modeling conducted for ebola , zika , and pandemic influenza varied according to the question being asked , along with other factors as follows: type of question: cdc and aspr have used models to answer such questions as who should be prioritized for vaccination or treatment , how transmissible a disease is , and how effective certain interventions are likely to be , according to modelers and agency officials .

for example , aspr modelers and officials said they modeled to help estimate the resources needed to respond to an ebola outbreak ; the number of therapeutics and vaccine doses needed to respond to ebola , both in africa and the u.s ; and the expected u.s. demand for zika diagnostics .

one aspr official said that , during the 2009 pandemic influenza outbreak , modeling questions were used to provide decision makers with information on what might happen in a given situation .

for example , models were used to provide information related to decisions on early vaccine distribution and how this intervention could affect the potential mortality rate .

time to model: how soon decision makers needed information also influenced the extent to which cdc and aspr modeled .

for example , if decision makers needed an answer in a week , modelers would inform the decision makers about how much of the answer they could provide within that time frame , aspr modelers said .

similarly , cdc modelers and officials said that , in one instance , modelers had only 12 hours to provide decision makers with information .

even estimating the time needed to develop and conduct modeling could represent an additional challenge , according to cdc modelers responding to zika .

according to a cdc article on modeling to inform responses to novel influenza viruses , the amount of time required to develop and execute a model can vary from less than a week to more than a month .

agency officials concurred with these time frames .

personnel and data availability: the availability of qualified personnel was also a factor that affected how much modeling agencies conducted for the selected diseases .

for example , cdc modelers and officials said the agency's division of vector - borne diseases has focused its resources in other areas , such as building the capacity of states to address vector - borne diseases , and therefore had not invested in individuals with the right skill sets to conduct modeling for the zika outbreak response .

as a result , the division had to call on the three or four cdc modelers from outside of the division who were available to assist with the zika outbreak response , which limited the amount of modeling that could be performed .

data challenges can also limit the types of modeling conducted .

for example , when modeling for zika , aspr modelers said they used available information , but data quality and availability limited their ability to model .

more data typically become available as an outbreak progresses , but models may be most helpful at the beginning of an outbreak when critical decisions need to be made ( see fig .

3 ) .

cdc and aspr do not keep a list of all modeling conducted , and we therefore cannot quantify the extent of their efforts in terms of a number of models .

aspr modelers and officials said modeling is typically one small aspect of the way the agency carries out its mission .

one aspr official said models are never the sole source of information for decision - making .

according to nih officials , nih does not conduct or fund internal modeling for decision - making purposes .

nih's fogarty international center has conducted self - initiated , internal modeling to answer questions generated from research , and from ideas from center - held workshops .

two nih institutes — the national institute of general medical sciences and the national institute of allergy and infectious diseases — along with nih's fogarty international center have awarded grants for external modeling research for our selected diseases .

however , nih officials said these efforts were intended to advance science , not for policy or outbreak response .

cdc and aspr modelers and officials said they considered modeling results to a limited extent when making decisions about resource allocation .

while modeling can help determine the amount of particular resources needed during an infectious disease outbreak , cdc modelers and officials said it is not central to their resource allocation planning .

for example , cdc modelers and officials noted that while a model could inform a decision maker about how many diagnostic testing supplies would be needed based on the range of predicted cases , this would be one input among many into the decision .

decision makers would also consider whether there are other diagnostic test supplies for similar diseases that could be used , the extent of laboratory testing capacity , or the longevity of those supplies .

models can be used to help plan for the cost of interventions by determining the numbers or types of interventions that can be used during a response to an infectious disease outbreak , according to cdc modelers and officials .

it can also help decision makers recognize gaps in their ability to implement resource allocation decisions , according to cdc officials .

for example , cdc leadership described how modeling input requirements spurred analysis of the factors limiting hospitals' use of ventilators during a pandemic influenza outbreak .

this work , according to cdc officials , helped determine the number of ventilators that should be included in the national stockpile .

while modeling results are important to consider during a public health event , aspr officials and modelers said it is also important to consider concrete financial estimates based on prior experience and whether recommended medical interventions or countermeasures are available or effective .

for example , aspr modelers and officials have occasionally been asked to analyze costs for medical countermeasures , but modelers and officials said that few medical countermeasures typically meet the requirements of decision makers , and existing medical countermeasures are typically unavailable for use in a response .

aspr modelers and officials noted that the usefulness of modeling to the decision maker in these instances is limited .

in the event that they were asked to model for such questions , aspr modelers and officials said time would also be a limiting factor in their analysis .

cdc has also developed models to inform decision - making at the state level , specifically to assist state and local public health agencies in developing outbreak response plans .

a professional organization of epidemiologists we contacted expressed some concerns with limitations of cdc models , specifically noting that state and local officials viewed cdc models as lacking the level of refinement needed for their state - and local - level planning needs .

to follow up , we interviewed officials from a non - generalizable selection of five states based on their reported use of cdc models , the level of selected disease activity in the state , and geographic variation .

two of the five state health departments we contacted reported using one of cdc's models for ebola , zika , or pandemic influenza .

these two states confirmed that the usefulness of the cdc flusurge pandemic influenza model was limited by unrealistic assumptions or a lack of predictive capability , but added that the models were useful to them when considering how to allocate resources or otherwise prepare for a severe pandemic .

officials from one state health department told us they had similar concerns with the cdc ebola model regarding an unrealistic overestimate of the potential cases , but added that it was useful for informing staff allocation planning as part of their overall response .

officials from another state health department told us they used cdc's zika modeling results that indicated how many emergency room visits they could expect and what symptoms it would take to confirm a zika infection .

at the time , state officials said , commercial testing for zika was not available , so this modeling was very helpful to health officials looking to recommend who hospitals should test based on the presence of zika symptoms .

state health department officials added that many other factors are considered when deciding on resource allocation , such as local leadership and willingness to embrace the public health response .

the four hhs agencies that work on infectious disease modeling reported using multiple mechanisms to coordinate their efforts .

however , they do not routinely monitor these efforts , evaluate their effectiveness , or report on them to identify areas for improvement .

the four hhs agencies that work on infectious disease modeling — aspr , cdc , fda , and nih — reported using multiple mechanisms to varying extents to coordinate such efforts .

for example: emergency operations center ( eoc ) .

during the response to an outbreak , cdc activates its eoc — a temporary , formal organizational structure for coordinating expertise within cdc and among agencies .

the four hhs agencies — aspr , cdc , fda , and nih — used eocs to coordinate modeling efforts during responses to ebola , zika , and pandemic influenza outbreaks .

for example , during the 2015-2016 zika outbreak , cdc's eoc served as the command center for monitoring and coordinating the response by bringing together cdc scientists with expertise in areas such as arboviruses ( the category that includes zika ) , reproductive health , birth defects , and developmental disabilities .

cdc modelers and officials told us that they had weekly strategy meetings and briefings with response leadership within the eoc where they discussed which modeling questions to prioritize .

in general , cdc modelers in the eoc were expected to coordinate with modelers from other agencies within and outside of hhs — such as aspr , fda , nih , and the department of homeland security — to produce timely estimates of cases , hospitalizations , and deaths .

these estimates can inform response leadership and enable them to assess the speed and impact of the geographic spread of the pandemic .

modelers in the eoc also provide support to decision makers as they examine the potential effects of various response options .

these options include when and how to deploy strategic national stockpile assets , such as influenza antiviral drugs and mechanical ventilators .

we found the use of eocs to be consistent with leading collaboration practices we have previously identified , such as defining and articulating a common outcome .

public health emergency medical countermeasures enterprise ( phemce ) .

the four hhs agencies also participated in phemce , a federal interagency body formed by hhs in 2006 that coordinates the development , acquisition , stockpiling , and recommendations for use of medical products that are needed to effectively respond to a variety of high - consequence public health emergencies .

phemce is led by aspr and also includes partners at the departments of defense , veterans affairs , homeland security , and agriculture .

phemce's 2017-2018 strategy and implementation plan , its most recent , identified ebola , pandemic influenza , and emerging infectious diseases more broadly as high - priority threats .

phemce leadership could ask modelers to address questions related to these infectious diseases , according to aspr modelers and officials .

according to aspr officials , such questions tend to support larger response - related efforts , and modeling results are often incorporated into final reports and products .

according to aspr officials , as of february 2020 , the phemce structure has been updated and it is unclear how modeling fits into the new structure .

we found that coordination through phemce is consistent with leading collaboration practices such as establishing mutually - reinforcing or joint strategies .

working groups .

modelers with the four hhs agencies have participated in working groups related to infectious disease modeling ( see table 2 ) .

the use of working groups and similar bodies is consistent with leading collaboration practices that we have previously reported as useful for enhancing and sustaining interagency collaboration , such as identifying and addressing needs by leveraging resources .

for example , cdc and aspr modelers participated in the national science and technology council's pandemic prediction forecasting science and technology working group , which facilitates coordination among numerous federal agencies .

in 2016 , this group produced a report that identified challenges in outbreak prediction and modeling for federal agencies and offered recommendations for federal actions to advance the development and effective application of outbreak prediction capabilities .

description this interagency working group , directed by the national science and technology council , is responsible for analyzing the state of infectious disease modeling and prediction , and facilitating coordination among numerous federal agencies .

according to cdc modelers and officials , as of october 2018 , the charter for this group is no longer active , and it meets on a voluntary , ad hoc basis .

according to cdc officials , this group connects modelers by holding seminars , managing an email list , and arranging for members to peer review one another's models .

this group had over 160 participants from various centers across cdc , as of june 2019 .

during the 2014-2016 ebola and 2015-2016 zika outbreaks , the department of health and human services' ( hhs ) office of the assistant secretary for preparedness and response ( aspr ) established temporary modeling coordination groups that brought together government agencies and academics to share early modeling results and discuss pressing questions that could be answered through modeling , according to aspr modelers and officials .

a wide range of entities participated in these groups , including the four hhs agencies , other federal agencies such as the departments of defense and homeland security , universities , and foreign entities , such as the world health organization and the united kingdom .

according to aspr modelers and officials , there are no plans to convene modeling coordination groups unless there is an ongoing infectious disease outbreak .

joint model development .

aspr and cdc modelers jointly developed some modeling products during outbreak responses .

for example , during the 2014-2016 ebola response , aspr and cdc developed a model to estimate future numbers of ebola patients needing treatment at any one time in the united states .

according to a publication describing the model , policymakers have used it to evaluate responses to the risk for arrival of ebola - infected travelers , and it can be used in future infectious disease outbreaks of international origin to plan for persons requiring treatment within the united states .

building these positive working relationships can help bridge organizational cultures by building trust and fostering communication , which facilitates collaboration and is vital in responding to emergencies .

for example , in our 2011 report , we found that , through interagency planning efforts , federal officials built relationships that helped facilitate the federal response to the h1n1 influenza pandemic .

similarly , hhs officials said that federal coordination during the h1n1 pandemic was much easier because of these formal networks and informal relationships built during pandemic planning activities and exercises .

memoranda of understanding .

the four hhs agencies have entered into various agreements through memoranda of understanding in order to define their relationships for coordinating infectious disease modeling ( see table 3 ) .

generally these memoranda were between individual agencies rather than department - wide .

we found that the use of memoranda of understanding was consistent with leading collaboration practices , such as agreeing on roles and responsibilities .

our prior work found that agencies that articulate their agreements in formal documents can strengthen their commitment to working collaboratively .

similarly , cdc modelers and officials said that written agreements can reduce the possibility of misunderstandings or disagreements and help ensure that participants have a mutual understanding of collaboration goals .

for example , in the absence of such written agreements , the potential for duplication is increased because agencies could be working on similar types of models without one another's knowledge .

table 3 .

selected examples of memoranda of understanding for coordinating on infectious disease modeling collaborating agencies the office of the assistant secretary for preparedness and response ( aspr ) and centers for disease control and prevention ( cdc ) aspr and the food and drug administration ( fda ) description from 2013 to 2018 , cdc and aspr had a memorandum of understanding to promote collaboration , provide expertise , and facilitate data and information exchange related to infectious disease modeling .

this agreement expired in 2018 .

aspr modelers and officials told us that , as of august 2019 , it had not been updated , and there were no plans to do so .

despite this , according to cdc modelers and officials , the substance of the agreement is still being followed .

cdc modelers and officials told us they continue to collaborate with aspr modelers on the development of models that address questions of mutual interest .

for example , for the ongoing ebola response , cdc modelers and officials said they have kept aspr informed on modeling efforts , and aspr shares data on vaccine production that is included in one of the models .

aspr and fda have a memorandum of understanding to promote collaboration and enhance knowledge and efficiency by providing for the sharing of information and expertise .

this memorandum was in place from 2012 to 2017 , and was then renewed in 2019 .

it remains valid unless modified by consent of both parties or terminated by either party immediately upon written notice in the event that a federal statute is enacted or a regulation is issued by a federal partner that materially affects the memorandum .

according to fda modelers and officials , the agreement facilitates collaboration related to fda's medical countermeasure initiative and fda's role in supporting the hhs - led public health emergency medical countermeasures enterprise ( phemce ) .

fda modelers and officials told us that the agreement supports the frequent , ongoing collaborations between fda and aspr , including collaboration related to preparedness for emerging infectious diseases .

however , fda modelers and officials said , while no specific steps have been taken with regards to collaborating on infectious disease modeling under the agreement , modeling assistance could be provided in the future , if needed .

description from 2013-2018 , aspr had a memorandum of understanding with nih's models of infectious disease agent study program to ( 1 ) enable models of infectious disease agent study program researchers to work with aspr as part of public health preparedness and response activities , ( 2 ) share data and information , and ( 3 ) support model development and use in the hhs modeling hub .

this agreement has expired .

aspr modelers and officials told us that , as of august 2019 , it has not been updated , and there were no plans to do so .

since 2015 , cdc has had a memorandum of understanding with nih's models of infectious disease agent study program , to promote collaboration and facilitate the exchange of data , tools ( models ) , methods , and information .

it was set to expire in february 2020 .

from 2013 to 2018 , aspr had separate memoranda of understanding with the departments of defense and homeland security to promote collaboration , provide expertise , and facilitate data and information exchange .

the goals of the collaboration in both agreements were to explore ways to , among other things: share analytical approaches and efforts , such as modeling and simulation tools , in support of public health preparedness and response activities ; provide personnel as needed to facilitate analytical efforts ; and share data and information .

these goals were similar to those laid out in the agreement between cdc and aspr .

these agreements expired in 2018 .

aspr modelers and officials told us that , as of october 2019 , they have not been updated , and there were no plans to do so .

forecasting competitions .

cdc and nih have sponsored formal forecasting competitions to improve modeling for ebola , zika , and seasonal influenza .

according to a report from the national science and technology council , controlled , multi‐center modeling contests and projects generate valuable insights .

for example , they often show that simpler models perform as well as more complex models and that ensemble models , which combine the results of multiple models to predict an outcome , perform better than an individual model .

such competitions are consistent with a leading collaboration practice we previously reported: identifying and addressing needs by leveraging resources .

in this case , such leveraging allowed cdc and nih to obtain additional benefits and insights on models that may not otherwise be available .

these modeling competitions can therefore help the hhs agencies better prepare for future outbreaks through coordination with participants .

the following are examples of forecasting competitions sponsored by cdc or nih: ebola competition .

nih's fogarty international center held an ebola forecasting competition from august to december 2015 , related to the 2014-2016 west african ebola outbreak , to compare the accuracy of predictions from different ebola models , among other things .

according to nih modelers and officials , lessons learned from the challenge were that ( 1 ) with regard to short - term incidence predictions , ensemble estimates were more consistently accurate than predictions by any individual participating model ; ( 2 ) as expected , more accurate and granular epidemiological data improved forecasting accuracy ; ( 3 ) the availability of contextual information , including patient - level data and situational reports , is important for accurate predictions ; ( 4 ) the accuracy of forecasting was not positively associated with more complex models ; and ( 5 ) coordination of modeling teams and comparison of different models is important to ensure robustness of predictions .

according to nih officials , based on these lessons and in response to the most recent ebola outbreak , nih has established a coordination group to share information about modeling and data sharing for this particular outbreak and a formal model comparison is underway under world health organization leadership .

aedes ( zika ) competition .

in 2019 , cdc hosted a forecasting competition related to using models to predict the presence of aedes mosquitoes , which is a vector for the zika virus .

evaluating these models can , according to cdc , help clarify model accuracy and utility , the seasonal and geographical dynamics of these mosquitoes , and key directions for future research .

according to cdc documentation , these advances can contribute to improved preparedness for arboviral invasion in the united states and in other regions where aedes suitability may be limited and changing .

cdc plans to evaluate forecasts for this competition in early 2020 , as soon as final surveillance data for 2019 are available .

flusight ( seasonal influenza ) competition .

cdc holds an annual seasonal influenza forecasting competition — known as flusight — to facilitate efforts to engage external researchers to improve the science and usability of seasonal influenza forecasts .

the results of the competition are evaluated by the cdc influenza division , which works with state and local partners to determine whether the results are useful to them and if there are other metrics , milestones , or targets that would be more helpful in making public health decisions .

according to cdc officials in february 2020 , the results from the flusight competition are not directly incorporated into pandemic influenza forecasting because the most accurate seasonal influenza forecasts would not necessarily be the most accurate pandemic influenza forecasts .

according to these officials , the overall lessons learned from the flusight competition relate to how to quantify , visualize , and communicate model results and model accuracy , as well as the value of forecast ensembles to summarize multiple models .

cdc officials said these lessons are incorporated into pandemic influenza forecasting plans .

coordination with academic and other modelers .

cdc coordinated infectious disease modeling efforts with academic and other modelers through various means , including the following: intergovernmental personnel act agreements .

cdc has used agreements under the intergovernmental personnel act of 1970 to collaborate with external experts on modeling efforts .

for example cdc's division of vector - borne diseases had an agreement from 2014 to 2017 to assign a cdc official to the harvard t.h .

chan school of public health .

the agreement was to help cdc integrate with a larger modeling community and provide the harvard school of public health with expertise in arboviral diseases and applied public health .

vector - borne disease centers of excellence .

cdc has funded the vector - borne disease centers of excellence , which are engaged in modeling - specific projects .

in 2017 , cdc established five universities as regional centers of excellence to help prevent and rapidly respond to emerging vector - borne diseases across the united states .

according to cdc , the goals of the centers are to build effective collaboration between academic communities and public health organizations at federal , state , and local levels for surveillance , prevention , and response , among other things .

support for other governmental entities .

cdc has coordinated with other entities — such as state and local officials — to provide modeling tools , estimates of case counts , or effects of interventions during the ebola , zika , and pandemic influenza outbreaks .

for example , cdc developed pandemic influenza models for state and local health departments to use in influenza pandemic planning activities .

the tools are available on the cdc pandemic influenza website and from aspr's emergency preparedness information portal .

as previously discussed , officials from two of the states we spoke with said they generally were unaware of the availability of the models .

according to cdc modelers and officials , these models were developed in the mid - 2000s for pandemic influenza planning and remain useful but had not been a priority to update because they have not received a request to do so .

informal collaboration .

cdc has engaged in a range of informal collaborations related to infectious disease modeling .

according to cdc modelers and officials , modelers often develop relationships through conferences or other contacts .

for example , cdc modelers and officials said they informally collaborated on ebola modeling needs with academic institutions , as well as modelers and analysts in the world health organization and other u.s. government agencies , such as the federal emergency management agency .

for example , cdc modelers and officials told us that model estimates produced under collaboration with academics helped inform decisions about how many beds to be ordered and delivered on the ground in west africa during the 2014-2016 ebola outbreak .

similar to the forecasting competitions described above , such informal coordination mechanisms are consistent with the best practice of identifying and addressing needs by leveraging resources , thus obtaining additional benefits that may not be available if they were working separately .

for example , we have previously reported that informal collaboration mechanisms — such as building relationships between key personnel and soliciting input for research projects — can provide the opportunity to leverage expertise .

cdc and aspr modelers and officials did not routinely monitor , evaluate , and report on coordination efforts for infectious disease modeling .

while cdc did conduct after - action reviews for ebola and zika , which included a review of modeling efforts , such reviews are not routine outside of a response and do not examine modeling coordination between agencies .

aspr modelers and officials told us they saw no reason to monitor coordination efforts under the memorandum of understanding with cdc because such memoranda outline expectations rather than requirements .

however , we have found that agencies that create a means to monitor , evaluate , and report the results of collaborative efforts can better identify areas for improvement .

we have previously reported that progress reviews or after action reviews can be useful mechanisms for monitoring , evaluating , and reporting on collaborative efforts .

for example , we previously reported that , to monitor , evaluate , and report on the status of achieving the healthy people 2010 objectives , hhs held progress reviews in which the federal agencies with lead responsibilities for a focus area reported on the progress towards achieving the objectives .

during these reviews , the participating agencies discussed the data trends , barriers to achieving the objectives , strategies undertaken to overcome barriers , and alternative approaches to attain further progress .

by holding similar progress reviews in which cdc and aspr evaluate and report on coordination efforts for infectious disease modeling , these agencies could be better positioned to identify and address challenges prior to infectious disease outbreaks occurring , which could lead to improved responses .

further , there is the potential for overlap and duplication of modeling efforts across agencies , which may not be identified if coordination efforts are not effectively being monitored , and which could lead to inefficiencies .

the memorandum of understanding between cdc and aspr had expired in 2018 .

agency officials told us they had no plans to review or update the agreement .

according to aspr modelers and officials , the agreement has not been updated because it was not a priority and the substance of the expired agreement is being followed .

however , without an active agreement in place that clearly defines the goals of the collaborative effort and the roles and responsibilities of participants , a lack of understanding and agreement becomes more likely , particularly as agencies' priorities evolve over time .

our prior work on leading collaboration practices found that agencies that articulate their agreements in formal documents can strengthen their commitments to working collaboratively , and that such agreements are most effective when they are regularly reviewed and updated .

further , we found that the memorandum of understanding between aspr and cdc was not fully implemented when it was active .

for example , according to this agreement , cdc was to appoint a designee to participate in a steering committee related to modeling within hhs .

however , aspr modelers and officials told us that this steering committee was never formed because of changing leadership and priorities .

they told us that hhs does not have any intention to form such a steering committee in the future .

however , our past work shows creating a steering committee or other similar coordination mechanism could help facilitate monitoring of coordination efforts .

we similarly found that other memoranda of understanding related to infectious disease modeling were not fully implemented .

for example , although aspr had a 2013-2018 memorandum of understanding with nih's models of infectious disease agency study program , aspr modelers and officials said they rarely use models funded by nih , including those funded through the program .

in particular , aspr modelers and officials recalled only using one such model in recent years .

that model , known as “flute,” is an influenza model that was used as part of a larger study on vaccine availability .

however , aspr modelers faced challenges in using this model .

specifically , these aspr modelers and officials said the flute model initially was not compatible with aspr's computer system , so software engineers had to modify the source code to resolve the compatibility issue .

the model did not have documentation describing its parameters , according to aspr modelers and officials , so they had to read through the model's source code to understand them .

similarly , regarding a separate agreement between aspr and fda , fda modelers and officials said that , while there is ongoing information sharing , no specific steps have been taken with regard to collaborating on infectious disease modeling under the agreement .

however , these modelers and agency officials said that modeling assistance could be provided in the future , if needed .

we identified four elements of practices for developing and assessing models: ( 1 ) communication between decision maker and modeler , ( 2 ) description of the model , ( 3 ) verification , and ( 4 ) validation .

we determined that cdc and aspr generally followed these gao - identified practices for 10 models we reviewed .

however , for four of the 10 models , cdc modelers did not provide all of the details needed in the verification steps to reproduce their model results , which is inconsistent with hhs guidelines on transparency and reproducibility .

according to our interviews with agency modelers and experts , along with our review of selected literature , there are no documented standards that prescribe the steps agencies must or should follow when developing and assessing models .

however , based on our interviews and review , we identified four broad elements of the modeling process that modelers generally consider .

they are: 1 communication between modelers and officials to refine questions to be addressed by the model , such as geographic spread of the disease and total cases of the disease ; 2 description of the model , including detailed descriptions of assumptions and data sources used ; 4 validation .

figure 4 outlines the model development and assessment process .

based on our assessment of 10 selected models , we found that cdc and aspr generally took steps that corresponded to our four elements , and agency modelers generally agreed with our assessment of each model .

see table 4 for more information on the elements .

see appendix iii for a list of models we reviewed and a complete list of the steps we identified that make up each element .

communication between modeler and decision maker .

in all 10 agency models we reviewed , we found that agencies took all the steps we identified for communication between decision maker and modeler .

in some cases , these steps were formalized , while in others they were informal .

for example , cdc modelers responding to ebola ensured communication with decision makers by following a memo template they developed , which has a section requiring modelers to communicate key aspects of their model .

these modelers noted , however , that they would not follow all the steps in their memo template for models developed during an outbreak because of time constraints .

cdc modelers responding to pandemic influenza noted they do not have formal best practices for communication about key model aspects to decision makers , and a cdc modeler responding to zika highlighted the role of cdc's emergency operations center ( eoc ) in communication between decision makers and modelers , which is activated only during a response .

aspr modelers noted that — as a best practice — they hold a discussion for all new models , in which decision makers describe what they are looking for and modelers describe what they can provide .

description of the model .

in nine of the 10 models we reviewed , modelers took all steps we identified for describing their model type , inputs , outputs , assumptions , and limitations .

in one case , aspr's “flumodels” package , the agency did not carry out the step of describing the model's limitations .

aspr modelers told us they did not do so because they expected the model's intended users — primarily federal public health modeling experts — would understand the limitations of their model , an assumption we find reasonable .

verification .

in six of 10 models reviewed , we found agency modelers followed most of the steps we identified for model verification .

however , in four of the seven cdc models reviewed , cdc did not publish the model's code , a part of model reproducibility and a model verification step .

we examine cdc's policy and efforts on reproducibility in more detail below .

validation .

for four of the 10 models we reviewed , agencies performed few validation steps .

in all three cdc pandemic influenza models we reviewed , and the aspr zika model , sensitivity analysis was the only validation step performed .

cdc influenza modelers said they did not perform other validation steps because of a lack of comparable external models or applicable data which could be used for other types of model validation .

for example , they said they could not validate their models using real - world data because they made projections for scenarios that did not come to pass ( eg , an unmitigated pandemic influenza outbreak ) .

they said they have continued to look for comparable models that could be used to cross - validate their model estimates .

aspr modelers responding to the zika outbreak also did not have access to comparable external models or applicable data to confirm their model projections , but have since attempted to validate their model .

for the other six models we reviewed , agencies carried out most but not all validation steps .

for example , cdc modelers responding to zika also said they did not perform cross - validation ( comparison of different model results to each other ) for their zika model because of a lack of comparable models .

however , these aspr and cdc zika modelers said they have attempted to validate their model since its publication as new data emerges , and we found this occurred .

assessing model validity assessing model validity means determining whether a model is sufficiently accurate for its purpose .

several methods are available , including the following: modelers can compare the results of the model against real - world data the model was designed to predict .

if there are no such data , another method is to determine how much the model projections change in response to changes in input data .

this is known as model sensitivity analysis .

modelers can also withhold a part of the available data in building the model and then confirm the model can reproduce the withheld data .

real - world data is to run the model along with a separate , independent model using the same input data , and comparing the outputs .

cdc modelers and aspr modelers responding to zika followed identified practices and validated their model projections for the zika outbreak , although their efforts yielded mixed results for model performance .

cdc modelers responding to zika attempted to estimate whether there was an enhanced risk of microcephaly in infants born to expectant mothers infected with zika .

using data available during the initial stage of the outbreak , they calculated the enhanced risk to be between 0.88 and 13.2 percent if the mother was infected in the first trimester .

in two subsequent studies using later data on the actual incidence of microcephaly as a result of the outbreak , other researchers found the enhanced risk was within the bounds of cdc modelers' earlier projections: a 10 percent enhanced risk in one study and an 8.3 percent enhanced risk in the other .

in the second case , aspr modelers attempted to estimate potential new cases of guillain - barré syndrome , a rare disorder in which the body's immune system attacks part of its own nervous system , in places burdened by zika infection .

their initial projections were that there would be between 191 and 305 new cases in puerto rico , a three - to five - fold increase above the number normally expected .

aspr modelers attempted to verify these results themselves and found that the incidence did increase , but only two - fold , to 123 new cases .

through independent performance evaluations .

for example , agencies sometimes host modeling competitions , in which independent modelers compare the predictive performance of multiple models under controlled conditions using standardized data .

the national institutes of health hosted an ebola forecasting competition in 2015 , and the centers for disease control and prevention ( cdc ) launched its flusight competition in 2013 .

the challenge of modeling during an outbreak .

early in the 2014-2016 ebola outbreak , centers for disease control and prevention ( cdc ) officials faced the challenge of answering questions with limited data and time .

in order to estimate the potential number of future cases and to aid in planning for additional disease - control efforts , cdc developed ebolaresponse , an excel spreadsheet - based model that could forecast how interventions would impact the outbreak .

using ebolaresponse , cdc predicted in early september 2014 that 1.4 million cases of ebola could occur in liberia and sierra leone by january 2015 , if the world health community did not increase interventions .

these estimates included a correction factor intended to account for the underreporting of cases and that , according to officials , was to represent model uncertainty .

partly because of these estimates of rapidly increasing cases , cdc and others increased intervention by sending more treatment units , personnel , and medical supplies in late 2014 .

ebolaresponse was created to model the effects of intervention , and it later turned out to be unreliable for the 4-month forecast that cdc used to support its request for increased intervention .

independent analysis found that the model could forecast cases up to a month ahead well but could not provide any measure of uncertainty .

furthermore , the model was unable to make accurate forecasts much beyond 3 months , a limitation that was common among the models used during the outbreak .

cdc later reported that roughly 8,500 cases , or 34 percent of the corrected ebolaresponse prediction of 25,000 cases , occurred in liberia by the end of january 2015 .

we also found that cdc and aspr modeling approaches varied somewhat , while generally remaining within the bounds of our identified practices .

for example , all the agency modeling groups reviewed their model assumptions , but they also varied in whether this review was formal or informal and internal or external .

cdc modelers responding to ebola use a formal internal peer review process during non - outbreak periods , as well as a detailed checklist to ensure communication with decision makers , full consideration of model inputs and outputs , quantification of model uncertainty , and validation of the model .

by contrast , cdc modelers responding to zika told us they do not have a formal system for evaluating their models , and instead rely on their own review of model assumptions .

aspr and cdc pandemic influenza modelers told us their modeling approach also relied on peer review , but the review was done by external experts ; informally for aspr and formally for cdc pandemic influenza modelers .

there are several reasons agency modeling approaches can vary .

according to agency modelers , agency modeling practices can be influenced by the availability of time , data , and comparable models .

for example , cdc pandemic influenza modelers and officials said they follow a shortened process when facing time constraints by documenting model development in a journal publication after the model has already been put to use .

similarly , cdc modelers responding to ebola noted that , during a response , a lack of time may mean models are not reviewed through cdc's formal clearance process ; instead , a more informal review of model results may occur .

cdc and aspr modelers also described variation in the complexity of the models they use .

they said they sometimes use both simple and complex models for the same disease and during the same outbreak .

cdc modelers and officials responding to ebola said that they preferred models run in spreadsheet programs for their transparency and communicability , whereas cdc influenza modelers mostly use dedicated statistical software programs to run models and spreadsheets for communicating with state and local health departments .

aspr modelers develop more complex prediction models so that they can be reused to answer more than one question , as opposed to models run in spreadsheet programs that are designed to answer one question .

experts and agency modelers generally agreed that infectious disease models should not be more complex than is necessary to answer the questions they were developed to address .

a simpler model may be run on a variety of software programs , ranging from spreadsheet programs to specialized programming languages that can do statistical analysis .

one downside of models run in spreadsheet programs , according to cdc influenza modelers , is that it is harder to conduct quality control measures .

two experts we spoke to , along with cdc zika modelers , also expressed concerns with reliability and reproducibility of models run in spreadsheet programs .

since 2002 , hhs agencies responsible for disseminating influential scientific , financial , or statistical information have been required to ensure methods used to develop this information are “reproducible.” a 2019 report from the national academies of sciences , engineering , and medicine noted that the scientific enterprise depends on the ability of the scientific community to scrutinize scientific claims and to gain confidence over time in results and inferences that have stood up to repeated testing .

as part of this process of scrutiny , a study's data and code should be made available so that the study is reproducible by others .

the national academies report defines reproducibility as obtaining consistent computational results using the same input data , computational steps , methods , code , and conditions of analysis .

reproducibility is specifically addressed earlier in this section in our discussion of model verification , a step that requires making code available for independent review .

hhs requires its component agencies to either follow hhs department guidelines on reproducibility or to ensure their own guidelines include a high degree of transparency about the data and methods used to generate scientific information .

hhs guidelines require that , in a scientific context , agencies identify the supporting data and models for their published scientific information and provide sufficient transparency about data and methods that an independent reanalysis could be undertaken by a qualified member of the public .

when asked whether cdc has specific policies related to reproducibility that would have applied to provision of model code in their published scientific research , cdc referred to its guidelines developed in response to the 2002 hhs guidelines .

however , cdc guidelines do not contain any reference to reproducibility , models , or provision of model code .

cdc guidelines for review of scientific information provided to the public focus on completeness , accuracy and timeliness , data management and analysis , clarity and accuracy of presentation , and validity of interpretation of findings .

cdc's policy on public health research and non - research data management and access does not make any reference to reproducibility or model code .

this lack of reference to reproducibility in cdc's guidelines and policies is not in accordance with hhs guidelines .

our review found four instances in which cdc modelers did not provide model code when they published their models .

cdc modelers said in some instances , issues with publication formats made the code difficult to share , they did not have time to produce a user - friendly version of the code , or they would share the code upon request .

by contrast , aspr modelers provided code for every model within our review when they published their models .

while neither agency cited a specific hhs policy that required them to share model code , aspr modelers noted that their internal peer review process typically includes sharing model source code with other modelers within phemce .

in our review of hhs guidelines and agency - specific guidance for these hhs guidelines , we found that , of three published agency guidance , two require reproducibility , or transparency for the methods used in the reports they issue to the public .

of these agencies , cdc was the only one that did not explicitly require transparency or reproducibility .

the national academies report noted that researchers have to be able to understand others' research in order to build on it .

this report also notes that the ability of qualified third parties to reproduce a model using published code is important because it can reveal mistakes in model code , which can lead to serious errors in interpretation and reported results .

if researchers do not share an important aspect of their study , such as their model code , it is difficult to confirm the results of their research and ultimately produce new knowledge .

one agency official acknowledged the importance of releasing model code , noting that hhs could benefit by ensuring policies across the agency are consistent regarding reproducibility and transparency in modeling .

by not specifically addressing reproducibility in their policy on dissemination of scientific information , cdc risks undermining the reliability of the scientific information they disseminate to the public .

based on our review of documents and reports from agencies , as well as expert and agency interviews , we identified three categories of challenges that cdc modelers and officials and aspr modelers faced when modeling for ebola , zika , and pandemic influenza , along with steps they took to address the challenges .

the categories are data , resources , and communicating results .

according to a 2016 report from the national science and technology council ( nstc ) , obtaining timely and accurate data and information has long been a major challenge to an effective response during an infectious disease outbreak .

one expert described reliable data as a modeler's most limited resource .

until data of sufficient quality and quantity are available and usable , the predictive value of models will be limited .

agency modelers and officials provided examples of data - related challenges , which we categorize as follows: data access .

public health data , according to one expert , often has access restrictions .

for example , aspr modelers said their ability to access data during the 2014-2016 ebola outbreak was reduced by a need to enter into agreements with data - owning countries in order to obtain patient data .

modelers said there were agreements between cdc and data owners , but further agreements would have been required for aspr to obtain data because the agreements did not authorize cdc to share data with its partners .

in addition to the example above , the lack of data sharing agreements during the 2014- 2016 ebola outbreak response led to modeling projects being delayed , according to a cdc publication .

aspr modelers said their inability to obtain data without a data - sharing agreement made it challenging for them to developing a current , reliable estimate of ebola incidence before modelers could start creating future estimates of disease incidence .

they said that , as a result , they instead developed a statistical model , which provided less reliable estimates of future numbers of disease cases than they would have preferred .

modelers said they worked to address this challenge by obtaining data and indirect information through personal relationships with other modelers .

in addition to the example provided above , cdc modelers and officials responding to ebola described experiencing data access challenges .

data availability .

without sufficient data , models may be unable to identify an epidemic's key drivers , which could result in misdirected intervention efforts .

for example , aspr modelers noted that during the 2015-2016 zika outbreak response , there were substantial limits on available data , and data that were available could be unreliable and delayed .

they said it was very difficult , and in many cases effectively impossible , to determine the accuracy of forecasting models for the evolving zika outbreak .

in addition , cdc officials and modelers responding to ebola , zika , and influenza described encountering limits on available data as an ongoing challenge .

steps that modelers said they have taken to address data availability challenges include designing models to use a minimum amount of data , building trust and communication with stakeholders who might be able to provide additional data , and updating data systems to provide all available information .

according to cdc modelers , data availability will likely continue to pose a challenge to public health responses .

data collection .

there is limited manpower during an infectious disease outbreak response , which can limit the health care system's ability to collect data , according to cdc modelers and officials responding to ebola and aspr modelers .

aspr modelers said if a provider has to fill out a time - consuming form , then they will be delayed in treating the next patient .

in order to address this challenge , cdc modelers and officials and aspr modelers said data requesters should ask for the minimum amount of data needed .

for example , cdc modelers and officials said they focus on understanding what data are essential , how they are collected , and the policy implications of reporting those data .

a 2016 nstc report recommended the federal government address this challenge by identifying questions likely to arise during an outbreak response , in order to help define and prioritize data collection and modeling goals .

data quality .

experts said creating models with low - quality data can result in inaccurate models that may not provide clear answers to decision maker questions .

for example , cdc modelers and officials responding to the 2015-2016 zika outbreak said the data quality varied , based on many factors such as surveillance systems that were doing different things and defining reporting zika cases differently , and the availability of diagnostic testing .

because of data quality concerns , there were questions about whether modeling could be conducted , but through discussions modelers and agency officials said they were able to address challenges .

to address such challenges , cdc modelers and officials responding to zika said they worked to improve public data sharing , sent an official to the pan - american health organization to help interpret data and understand the outbreak from an international perspective , and used modeling methods appropriate for data with high levels of uncertainty .

in addition to the example provided above , cdc modelers and officials responding to ebola , aspr modelers , and experts described experiencing data quality challenges .

data integration .

cdc modelers and officials responding to ebola and zika also faced the challenge of integrating multiple data sets , which may not be standardized or in a readily usable form .

for example , cdc modelers and officials responding to zika found it challenging to integrate data as the definition of the disease was refined over time .

as the definition got more specific and monitoring systems became available , it was hard to establish data trends , these officials said .

further , there were variations in who would be tested , with all people who exhibited symptoms being tested in some areas , and only pregnant women in others , and also when data would be placed into a combined form and reported to state , national , or international officials , according to these officials .

this integration issue may have complicated efforts to conduct modeling such as determining the risk of microcephaly in infants over time .

in order to address this challenge , zika modelers said they set up an online data repository to , among other things , standardize shared data .

cdc modelers and officials responding to ebola and zika , along with experts , said finding staff with sufficient training to support modeling during an infectious disease outbreak represented an ongoing challenge .

for example , cdc modelers responding to zika said it can be difficult to find modelers with both an epidemiological background and skills in coding and mathematics .

modelers and agency officials said those who had the correct skills were in high demand , and it was difficult to fully engage them in the zika outbreak response .

they said they could have conducted more modeling or completed modeling efforts more rapidly if they had had access to more modelers with the right skills .

to address this challenge , modelers participate in trainings on how to communicate what models can and cannot do , participate in working groups that support modeling efforts , employ the intergovernmental personnel mobility act program , maintain collaborations with external partners , and host students and researchers .

aspr modelers said they faced personnel challenges in their modeling efforts but that they were wide - ranging and not specific to ebola , zika , or pandemic influenza .

according to a 2016 nstc report , time constraints make it challenging for researchers to keep up with scientific literature during an outbreak .

cdc influenza modelers said they faced this challenge and that they conduct weekly searches for new influenza publications , which normally identify about 150 publications each week .

to address this challenge , modelers said they conduct literature searches , share the responsibility of reviewing publications and informing others of their content , talk to experts , and attend conferences .

modelers said this challenge was more easily addressed than others .

communicating model results can be difficult and , as modelers and agency officials pointed out , decision makers will not give credence to results from a model they do not understand .

model results , according to cdc influenza modelers , are often nuanced and complicated , and officials have to think about what pieces of information are the most important to convey to a decision maker , the public , or health officials .

furthermore , as one expert noted , the complexities of modeling can get lost in translation , especially with the media , which may focus on only a worst - case scenario .

when modeling for infectious diseases , appropriately communicating complex information has been described as a constant challenge , and cdc influenza modelers described it as their biggest challenge .

cdc influenza modelers particularly noted the challenge of communicating uncertainty .

cdc influenza and aspr modelers said if decision makers did not understand the models , they could misunderstand the results , which , according to aspr modelers , could lead to errors in decision making .

cdc modelers and officials responding to ebola and zika , cdc influenza modelers , aspr modelers , and experts described experiencing challenges communicating model results to decision makers .

clear communication may help prevent misunderstandings .

for example , one review article said officials may not understand what models can and cannot do before an epidemic , and modelers may not be fully aware of a decision maker's needs .

an expert said there is a need to constrain the use of models intended to inform decisions so that the model does not over - or under - influence a decision maker .

and , according to aspr modelers , decision makers sometimes want a model to make a decision for them , although models can only inform the decision making process .

they said this is less of a problem during an outbreak response , when decision makers know they have to act based on incomplete information .

some steps officials described taking to address communication challenges were similar across cdc and aspr officials .

for example , cdc modelers and officials and aspr modelers said they took steps to improve communication , such as working to develop relationships outside of an outbreak and to improve how data are visualized .

for example , aspr modelers and officials said they provided decision makers with a website that displays an interactive influenza model known as shinyflu .

the website lets users adjust a model to see how its results could change based on its inputs used .

however , modelers said this only works if the decision maker is willing to engage with data .

other steps to address communication challenges were not discussed by all modelers we spoke to .

for example , aspr modelers said that , when they use models with high uncertainty , they do additional research to assess and communicate how a model could be misrepresenting a real - world problem .

additionally , cdc modelers responding to zika and cdc influenza modelers said they sometimes use the language of weather forecasting — which provides information on the risk of an event occurring over a specified period of time — to help communicate model outcomes .

for all 10 of the models we reviewed , modelers communicated all the information they had agreed to provide to decision makers , including information about model uncertainty .

agency modelers and officials said they provided this information through discussions with decision makers and by showing decision makers the results of multiple modeling situations to convey uncertainty .

infectious disease modeling is one tool that can provide decision makers with valuable information to support outbreak preparedness and response .

in particular , modeling can help answer questions that are difficult to address in other ways because of practical , ethical , or financial reasons .

federal agencies have recognized the importance of modeling .

cdc and aspr reported using it to inform policy and planning questions and , to a more limited extent , to inform planning and the use of resources .

hhs agencies that work on infectious disease modeling — aspr , cdc , fda , and nih — reported using multiple mechanisms to coordinate their modeling efforts , including working groups , memoranda of understanding , and coordination with academic and other external modelers .

the use of these mechanisms was consistent with many leading collaboration practices , such as defining and articulating a common outcome and addressing needs by leveraging resources .

however , hhs does not routinely monitor and evaluate its coordination efforts , as called for by another leading collaboration practice , which limits the department's ability to identify areas for improvement .

further , there is the potential for overlap and duplication of modeling efforts across agencies , which may not be identified if coordination efforts are not effectively being monitored , and could lead to inefficiencies .

by holding progress reviews in which cdc and aspr evaluate and report on coordination efforts for infectious disease modeling , these agencies could be better positioned to identify and address challenges prior to infectious disease outbreaks , which could lead to improved response efforts .

cdc and aspr modelers generally followed gao - identified modeling practices , with the notable exception of model verification .

specifically , cdc did not make model code available to others for four of the seven cdc models we reviewed .

hhs does not have a policy that requires its agencies to share model code , but it does require its component agencies to either follow its guidelines or ensure that their own guidelines include a high degree of transparency to facilitate reproducibility by qualified third parties .

without sharing code and other important information , cdc cannot ensure that its models are reproducible , a key characteristic of reliable , high - quality scientific research .

in order to facilitate hhs infectious disease modeling efforts , we are making two recommendations .

the secretary of health and human services should develop a mechanism to routinely monitor , evaluate , and report on coordination efforts for infectious disease modeling across multiple agencies .

 ( recommendation 1 ) the secretary of health and human services should direct cdc to establish guidelines that ensure full reproducibility of cdc's research by sharing with the public all permissible and appropriate information needed to reproduce research results , including , but not limited to , model code .

 ( recommendation 2 ) .

we provided a draft of this report to the department of health and human services ( hhs ) for review and comment .

in its comments , reproduced in appendix iv , hhs agreed with our recommendations and noted that it was developing a process to coordinate its infectious disease modeling efforts across its components .

with regard to our second recommendation — that hhs should direct cdc to establish guidelines that ensure the full reproducibility of cdc's research by sharing all permissible and appropriate information needed to reproduce research results , including , but not limited to , model code — hhs's comments indicated that cdc believes it has already completed actions to implement this recommendation .

for example , the hhs comments state that cdc has established policies such as “public access to cdc funded publications” and “policy on public health research and nonresearch data management and access” that ensure that results are made available to the public , as appropriate .

however , as we state in our report , these policies do not contain any reference to reproducibility , models , or provision of model code and therefore do not fully address our recommendation .

cdc also said in the hhs comments that its methods — including its practice of providing a copy of model code upon request — are in line with standard practice in the scientific community and peer - reviewed journals .

however , in the four instances we identified where cdc modelers did not share code , code being available upon request was only one of the reasons cited .

further , this practice is inconsistent with those of the other hhs agencies we reviewed , and may limit the ability of external researchers to confirm the results of cdc's research and ultimately produce new knowledge .

as noted in our report , by not specifically addressing reproducibility in its policies on access to data and publications , cdc risks undermining the reliability of scientific information disseminated to the public .

therefore , we did not change our recommendation in response to hhs's comments .

we did , however , revise our report to include information on other hhs agency policies related to reproducibility .

hhs also provided technical comments , which we incorporated as appropriate .

as agreed with your offices , unless you publicly announce the contents of this report earlier , we plan no further distribution until 30 days from the report date .

at that time , we will send copies of this report to the appropriate congressional committees , the secretary of health and human services , and to other interested parties .

in addition , this report will be available at no charge on the gao website at http: / / www.gao.gov .

if you are your staff have questions about this report , please contact timothy m. persons , chief scientist , at ( 202 ) 512-6888 or personst@gao.gov .

contact points for our offices of congressional relations and public affairs may be found on the last page of this report .

key contributors to this report are listed in appendix v .

in conducting our review of infectious disease modeling by the department of health and human services ( hhs ) agencies , our objectives were to ( 1 ) examine the extent to which hhs has used various types of models to inform policy , planning , and resource allocation for public health decisions for selected infectious diseases , ( 2 ) examine the extent to which hhs coordinated their modeling efforts for selected infectious diseases , ( 3 ) examine the steps hhs generally took to develop and assess the performance of its models for the selected diseases and steps it applied to a selection of infectious disease models , and ( 4 ) describe the extent to which hhs has addressed challenges related to modeling for selected infectious diseases .

for purposes of this review , we focused on hhs because of its focus on scientific and technical issues related to disease modeling , role in infectious disease outbreak preparedness and response activities , and use of modeling for policy and regulatory issues related to disease .

within hhs , we identified four agencies — hhs's office of the assistant secretary for preparedness and response ( aspr ) , the centers for disease control and prevention ( cdc ) , national institutes of health ( nih ) , and food and drug administration ( fda ) — which may develop or use infectious disease models .

to inform all four objectives , we selected three naturally - occurring infectious diseases that have pandemic or epidemic potential — ebola virus disease ( ebola ) , zika virus disease ( zika ) , and pandemic influenza — to use as examples of broader infectious disease modeling efforts .

we selected these diseases based on document review , their inclusion on nih's pathogen priority list , modeling being conducted by hhs agencies , and interviews with experts that we selected based on their experience with infectious disease .

based on these steps , the team selected diseases that fit into one of the three categories on nih's pathogen priority list: the disease ( 1 ) can be transmitted easily from person to person , resulted in a high mortality rate and had the potential for major public health impact , might cause social disruption , and may require special action for public health preparedness ( ebola ) , ( 2 ) was moderately easy to disseminate , and required specific enhancements for diagnostic capacity and enhanced disease surveillance ( zika ) , or ( 3 ) was an emerging pathogen that could be engineered for mass dissemination in the future because of availability , ease of production and dissemination , and have the potential for high morbidity and mortality rates and major health impacts ( pandemic influenza ) .

to examine the types of models developed by hhs agencies to inform policy , planning , and resource allocation decisions , we reviewed documents from 2009 — the year of the last pandemic influenza outbreak in the united states — to april 2019 to identify examples of models developed by the agencies for the three selected diseases .

for context on and examples of the types of modeling that cdc and aspr have conducted , we reviewed published articles that cdc and aspr officials and experts provided to us or cited during the course of our review , such as articles identified during interviews which we later obtained .

we also obtained selected internal memoranda , when available , that described models used in the ebola virus outbreak .

we did not include fda and nih in this review because fda has a limited role in modeling , and nih generally funds , rather than conducts , modeling .

this review yielded articles and memoranda describing about 60 cdc and aspr models .

see appendix ii for a bibliography of model publications reviewed .

we then categorized the models using categories derived from a federal working group report to characterize the types of modeling conducted and the purpose of the modeling , when that purpose was identified .

to analyze each study , one analyst initially coded each study , and each classification was then independently reviewed to verify that it had been correctly classified and to resolve any categorization discrepancies .

we used these categories to describe types of modeling efforts undertaken by hhs agencies .

because we focused on studies published between 2009 and 2019 , our findings are not generalizable to models that were developed outside of that time period .

additionally , because we relied on agency officials or reviews of relevant agency documents and publications to identify studies , we may not have captured all studies relevant to our scope .

further , because cdc and aspr modelers and officials said that they do not publish every model they conduct , our review was not intended to develop an inventory of the modeling conducted during the time period .

therefore , we were unable to determine the extent to which the models we identified represented agency modeling efforts as a whole .

to describe the extent of model use for public health decision making , we interviewed officials from hhs agencies identified as decision makers for conducting the response to these selected diseases — cdc , aspr , and fda — and officials who conducted the modeling .

we also interviewed two nih institutes and one center about funding for research related to modeling for the selected diseases .

additionally , we conducted semi - structured interviews of officials from five states concerning their use of models prepared by hhs agencies for decision making , among other topics .

we selected these states based on a review of a cdc draft report on states' use of cdc models , on the level of influenza activity experienced by states , and consideration of geographic variation by u.s. region .

during our review , we sought to identify the common types of decisions that could be informed by models , as well as the considerations that could impact the extent to which a decision maker requests and uses models for specific types of decisions .

based on interviews with agency officials and our review of hhs models we identified examples of models that were used to make specific decisions during response and non - response times .

because we relied on officials to describe the extent to which models inform decision making , we may not have captured all relevant instances when models for the selected infectious diseases informed decision makers .

to examine coordination and collaboration across hhs agencies , we reviewed documents describing hhs agencies' collaboration and coordination mechanisms such as memoranda of understanding , descriptions of emergency operations center procedures , and after - action reports following infectious disease outbreaks .

we also conducted interviews with and requested information from hhs officials , asking them to provide information on their efforts to coordinate their infectious disease modeling activities .

in this report , and in our past work , we define coordination broadly as any joint activity that is intended to produce more public value than could be produced when organizations act alone .

we compared these actions to relevant selected collaboration leading practices: define and articulate a common outcome ; establish mutually reinforcing or joint strategies ; identify and address needs by leveraging resources ; agree on roles and responsibilities ; establish compatible policies , procedures , and other means to operate across agency boundaries ; and develop mechanisms to monitor , evaluate , and report on results .

because we judgmentally selected a group of experts and diseases , the results of our review cannot be generalized to hhs coordination efforts for other infectious diseases .

however , our assessment of collaboration and coordination activities did cover modeling efforts for the three selected diseases .

to identify steps that are generally considered when modelers develop infectious disease models and assess their performance , we conducted semi - structured interviews with relevant experts from academia and other organizations and cdc and aspr officials , and reviewed literature identified by experts .

we used a snowball sampling approach to identify relevant experts and groups .

we initially identified five infectious disease modeling experts through informal conversation with individuals working in the field , infectious disease modeling experts known through gao work , as well as a review of websites , publications , and grants funded by nih .

using a snowball sampling approach , we reviewed key literature related to the steps generally taken to develop models and assess their performance , consulted with infectious disease modeling experts , and interviewed agency officials to identify relevant groups , as well as individual experts , who could convey to us the steps generally taken during infectious disease modeling .

through literature searches , the team identified literature from public health journals or other major sources .

the team applied personal background and knowledge in public health , infectious disease modeling , and statistics to help identify key sources .

for the selected literature , we reviewed references and used a snowball approach to identify further relevant studies .

finally , we reviewed cdc guidance on decision making for data access and long - term preservation as it related to documentation standards .

based on our review of identified literature , we developed a data collection instrument to assess the extent to which cdc and aspr used the steps for infectious disease model development identified by experts and in the literature .

through this data collection instrument , we gathered information about the elements of developing and assessing model performance and the steps that could be taken within each element .

in order to develop the data collection instrument , based on our review of literature , we mapped out steps to develop and assess model performance , and developed broad categories of assessment elements .

within each assessment element , we included steps modelers could take as a part of each assessment element .

for example , the data collection instrument included items that recorded model verification steps that might have been taken by modeler ( s ) within the broader model verification element .

the instrument was reviewed by internal stakeholders , who provided feedback on its content .

prior to sending the data collection instrument to the agency , we filled in information on verification steps taken for each of the 10 selected models , based on provided model documentation to reflect steps we determined modelers took as a part of the model development and assessment process .

in order to provide officials with this information , two analysts reviewed each model's documentation , with one analyst providing an initial coding of the model and the other reviewing and verifying the first analyst's findings .

this method was first tested on one of the 10 selected models by two analysts independently coding information from the model's documentation into the data collection instrument and then reviewing coding choices to reconcile any differences found .

we then sent the instruments with filled - in information to cdc and aspr modelers to receive their feedback concerning the steps taken to develop models and assess their performance , provide any missing information , and resolve any ambiguities .

see appendix iii for a list of the 10 selected models reviewed and steps to develop and assess model performance included in the data collection instrument .

the data collection instrument was intended to record whether a specific step had been taken , but did not assess the quality of the modeling steps .

in order to determine steps cdc and aspr took to develop and assess its models , we selected a non - generalizable sample of 10 models for review in our data collection instrument that demonstrated steps that hhs agencies took to develop models and assess their performance .

the model selection process described above informed our selection of infectious disease models .

to be selected for inclusion in our non - generalizable sample , the model had to be ( 1 ) developed by cdc , or aspr officials or contractors ; ( 2 ) developed to answer a question about ebola , zika , or pandemic influenza ; and ( 3 ) used to inform public health decision makers during an outbreak or for preparedness activities .

we selected 10 models that differed in form and answered different types of questions , which included studies prepared during both outbreak preparedness and response times , and covered topics such as the impact of vaccination programs on deaths and hospitalization .

for ebola and zika , we focused on review of selected papers or memos produced since 2014 in order to capture the time period following the 2014-2016 ebola and 2015-2016 zika outbreaks .

for pandemic influenza , we focused on papers and memos produced since 2009 , when the h1n1 pandemic occurred in the united states .

because we selected from a group of models identified by hhs modelers and officials for ebola , zika , and pandemic influenza , the results of our review cannot be generalized to other diseases outside of the scope of this report .

furthermore , we requested models that informed public health decision making , and did not consider models that were not used for this purpose .

because we reviewed a non - generalizable sample of 10 models , the results of our review cannot be generalized to a larger population of models prepared by hhs agencies .

to identify challenges associated with modeling for the selected infectious diseases , we reviewed documents and reports to identify modeling challenges and steps to address those challenges , and interviewed agency officials and modelers , and experts identified through the previously - described snowball sampling methodology .

we used semi - structured interview protocols that included open - ended questions about challenges associated with infectious disease modeling and limitations associated with model development .

not all officials and experts we interviewed provided comments on every challenge or limitation .

in addition , because we judgmentally selected a group of experts and diseases , the results of our review cannot be generalized to all infectious disease modeling efforts .

we conducted this performance audit from may 2018 to may 2020 , in accordance with generally accepted government auditing standards .

these standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

carias , cristina , et al .

“preventive malaria treatment for contacts of patients with ebola virus disease in the context of the west africa 2014- 15 ebola virus disease response: an economic analysis.” the lancet infectious diseases , vol .

16 , no .

4 ( april 2016 ) : pp .

449-458 .

christie , athalia , et al .

“possible sexual transmission of ebola virus — liberia , 2015.” morbidity and mortality weekly report , vol .

64 , no .

17 ( may 8 , 2015 ) : pp .

479-481 .

martin i. meltzer , et al .

“estimating the future number of cases in the ebola epidemic - liberia and sierra leone , 2014-2015.” morbidity and mortality weekly report , vol .

63 , no .

3 suppl .

 ( september 26 , 2014 ) : pp .

1-14 .

meltzer , martin i. , et al .

“modeling in real time during the ebola response.” morbidity and mortality weekly report , vol .

65 , no .

3 suppl .

 ( july 8 , 2016 ) : pp .

85-89 .

rainisch , gabriel , et al .

“estimating ebola treatment needs , united states.” emerging infectious diseases , vol .

21 , no .

7 ( july 2015 ) : pp .

1273-1275 .

rainisch , gabriel , et al .

“regional spread of ebola virus , west africa , 2014.” emerging infectious diseases , vol .

21 , no .

3 ( march 2015 ) : pp .

444-447 .

undurraga , eduardo a. , cristina carias , martin i. meltzer , emily b. kahn .

“potential for broad - scale transmission of ebola virus disease during the west africa crisis: lessons for the global health security agenda.” infectious diseases of poverty , vol .

6 , no .

159 ( 2017 ) .

washington , michael l. , martin i. meltzer .

“effectiveness of ebola treatment units and community care centers liberia , september 23- october 31 , 2014.” morbidity and mortality weekly report , vol .

64 , no .

3 ( january 30 , 2015 ) : pp .

67-69 .

adamski , alys , et al .

“estimating the numbers of pregnant women infected with zika virus and infants with congenital microcephaly in colombia , 2015 – 2017.” journal of infection , vol .

76 ( 2018 ) : pp .

529-535 .

dirlikov , emilio , et al .

“guillain - barré syndrome and healthcare needs during zika virus transmission , puerto rico , 2016.” emerging infectious diseases , vol .

23 , no .

1 ( january 2017 ) : pp.134-136 .

ellington , sascha r. , et al .

“estimating the number of pregnant women infected with zika virus and expected infants with microcephaly following the zika virus outbreak in puerto rico , 2016.” jama pediatrics , vol .

170 , no .

10 ( 2016 ) : pp .

940-945 .

grills , ardath , et al .

“projected zika virus importation and subsequent ongoing transmission after travel to the 2016 olympic and paralympic games — country - specific assessment , july 2016.” morbidity and mortality weekly report , vol .

65 , no .

28 ( july 22 , 2016 ) : pp.711-715 .

johansson , michael a. , et al .

“zika and the risk of microcephaly.” the new england journal of medicine , vol .

375 ( july 7 , 2016 ) : pp.1-4 .

johnson , tammi l. , et al .

“modeling the environmental suitability for aedes ( stegomyia ) aegypti and aedes ( stegomyia ) albopictus ( diptera: culicidae ) in the contiguous united states.” journal of medical entomology , vol .

54 , no .

6 ( november 7 , 2017 ) : pp .

1605-1614 .

mitchell , patrick k. et al. , “reassessing serosurvey - based estimates of the symptomatic proportion of zika virus infections.” american journal of epidemiology , vol .

188 , no .

1 ( january 2019 ) : pp .

206-213 .

mier - y - teran - romero , luis , mark j. delorey , james j. sejvar , michael a. johansson .

“guillain - barré syndrome risk among individuals infected with zika virus: a multi - country assessment.” bmc medicine , vol .

16 , no .

67 ( 2018 ) .

mier - y - teran - romero , luis , andrew j. tatem , michael a. johansson .

“mosquitoes on a plane: disinsection will not stop the spread of vector - borne pathogens , a simulation study.” plos neglected tropical diseases , vol .

11 , no .

7 ( july 3 , 2017 ) .

reefhuis , jennita , et al .

“projecting month of birth for at - risk infants after zika virus disease outbreaks.” emerging infectious diseases , vol .

22 , no .

5 ( may 2016 ) : pp .

828-832 .

russell , steven , et al .

“detecting local zika virus transmission in the continental united states: a comparison of surveillance strategies.” plos currents outbreaks ( november 22 , 2017 ) .

watts .

alexander g. , et al .

“elevation as a proxy for mosquito - borne zika virus transmission in the americas.” plos one , vol .

12 , no .

5 ( may 24 , 2017 ) .

atkins , charisma y. , et al .

“estimating effect of antiviral drug use during pandemic ( h1n1 ) 2009 outbreak , united states.” emerging infectious diseases , vol .

17. no .

9 ( september 2011 ) : pp .

1591-1598 .

biggerstaff , matthew , et al .

“estimates of the number of human infections with influenza a ( h3n2 ) variant virus , united states , august 2011 – april 2012.” clinical infectious diseases , vol .

57 , suppl .

1 ( 2013 ) : pp .

s12-s15 .

biggerstaff , matthew , et al .

“estimating the potential effects of a vaccine program against an emerging influenza pandemic — united states.” clinical infectious diseases , vol .

60 , suppl .

1 ( 2015 ) : pp .

s20-s29 .

carias , cristina , et al .

“potential demand for respirators and surgical masks during a hypothetical influenza pandemic in the united states.” clinical infectious diseases , vol .

60 , suppl .

1 ( 2015 ) : pp .

s42-s51 .

cauchemez , simon , et al .

“role of social networks in shaping disease transmission during a community outbreak of 2009 h1n1 pandemic influenza.” proceedings of the national academy of sciences of the united states , vol .

108 , no .

7 ( february 15 , 2011 ) : pp .

2825-2830 .

dawood , fatimah s. , et al .

“estimated global mortality associated with the first 12 months of 2009 pandemic influenza a h1n1 virus circulation: a modelling study.” the lancet infectious diseases , vol .

12 ( september 2012 ) : pp .

687-695 .

fung , isaac chun - hai , et al .

“modeling the effect of school closures in a pandemic scenario: exploring two different contact matrices.” clinical infectious diseases , vol .

60 , suppl .

1 ( 2015 ) : pp .

s58-s63 .

iuliano , a. danielle , et al .

“estimates of global seasonal influenza - associated respiratory mortality: a modelling study.” the lancet , vol .

391 , no .

10127 ( march 31 , 2018 ) : pp .

1285-1300 .

jain , seema , et al .

“hospitalized patients with 2009 h1n1 influenza in the united states , april – june 2009.” the new england journal of medicine , vol .

361 , no .

20 ( november 12 , 2009 ) : pp .

1935-1944 .

kostova , deliana , et al .

“influenza illness and hospitalizations averted by influenza vaccination in the united states , 2005 – 2011.” plos one , vol .

8 , no .

6 ( june 19 , 2013 ) .

lafond , kathryn e. , et al .

“global role and burden of influenza in pediatric respiratory hospitalizations , 1982 – 2012: a systematic analysis.” plos medicine , vol .

13 , no .

3 ( march 24 , 2016 ) .

meltzer , martin i. , nancy j. cox , keiji fukuda .

“the economic impact of pandemic influenza in the united states: priorities for intervention.” emerging infectious diseases , vol .

5 , no .

5 ( september - october 1999 ) : pp .

659-671 .

meltzer , martin i. , et al .

“estimates of the demand for mechanical ventilation in the united states during an influenza pandemic.” clinical infectious diseases , vol .

60 , suppl .

1 ( 2015 ) : pp .

s52-s57 .

o'hagan , justin j. , et al .

“estimating the united states demand for influenza antivirals and the effect on severe influenza disease during a potential pandemic.” clinical infectious diseases , vol .

60 , suppl .

1 ( 2015 ) : pp .

s30-s41 .

presanis , anne m. , et al .

“the severity of pandemic h1n1 influenza in the united states , from april to july 2009: a bayesian analysis.” plos medicine , vol .

6 , no .

12 ( december 8 , 2009 ) .

reed , carrie , et al .

“estimates of the prevalence of pandemic ( h1n1 ) 2009 , united states , april - july 2009.” emerging infectious diseases , vol .

15 , no .

12 ( december 2009 ) : pp .

2004-2007 .

reed , carrie , martin i. meltzer , lyn finelli , anthony fiore .

“public health impact of including two lineages of influenza b in a quadrivalent seasonal influenza vaccine.” vaccine , vol .

30 ( 2012 ) : pp .

1993-1998 .

reed , carrie , et al .

“estimating influenza disease burden from population - based surveillance data in the united states.” plos one , vol .

10 , no .

3 ( march 4 , 2015 ) .

rolfes , melissa a. , et al .

“annual estimates of the burden of seasonal influenza in the united states: a tool for strengthening influenza surveillance and preparedness.” influenza and other respiratory viruses , vol .

12 ( 2018 ) : pp .

132-137 .

russell , k. , et al .

“utility of state - level influenza disease burden and severity estimates to investigate an apparent increase in reported severe cases of influenza a ( h1n1 ) pdm09 – arizona , 2015 – 2016.” epidemiology and infection , vol .

146 ( june 14 , 2018 ) : pp .

1359-1365 .

shrestha , sundar s. , et al .

“estimating the burden of 2009 pandemic influenza a ( h1n1 ) in the united states ( april 2009 – april 2010 ) .” clinical infectious diseases , vol .

52 , suppl .

1 ( 2011 ) : pp .

s75-s82 .

tokars , jerome i. , melissa a. rolfes , ivo m. foppa , carrie reed .

“an evaluation and update of methods for estimating the number of influenza cases averted by vaccination in the united states.” vaccine , vol .

36 ( 2018 ) : pp .

7331-7337 .

appendix iii: ten selected infectious disease models and questions from data collection instrument document describing model meltzer , martin i. , charisma y. atkins , scott santibanez , barbara knust , brett w. petersen , elizabeth d. ervin , stuart t. nichol , inger k. damon , michael l. washington .

estimating the future number of cases in the ebola epidemic – liberia and sierra leone , 2014-2015 , mmwr .

volume 63 , number 3 , september 26 , 2014 .

rainisch , gabriel , manjunath shankar , michael wellman , toby merlin , and martin i. meltzer .

regional spread of ebola virus , west africa , 2014 .

emerging infectious diseases .

volume 21 , number 3 , march 2015 .

asher , jason .

forecasting ebola with a regression transmission model .

epidemics .

volume 22 , 2018 .

ellington , sascha r. , owen devine , jeanne bertolli , alma martinez quiñones , carrie k. shapiro - mendoza , janice perez - padilla , brenda rivera - garcia , regina m. simeone , denise j. jamieson , miguel valencia - prado , suzanne m. gilboa , margaret a. honein , michael a. johansson .

estimating the number of pregnant women infected with zika virus and expected infants with microcephaly following the zika virus outbreak in puerto rico , 2016 .

jama pediatrics .

volume 170 , number 10 , october 2016 .

johansson , michael a. , luis mier - y‐teran - romero , jennita reefhuis , suzanne m. gilboa , and susan l. hills .

zika and the risk of microcephaly .

new england journal of medicine .

volume 375 , number 1 , july 7 , 2016 .

dirlikov , emilio , krista kniss , chelsea major , dana thomas , cesar a. virgen , marrielle mayshack , jason asher , luis mier - y - teran - romero , jorge l. salinas , daniel m. pastula , tyler m. sharp , james sejvar , michael a. johansson , brenda rivera - garcia .

guillain - barré syndrome and healthcare needs during zika virus transmission , puerto rico , 2016 .

emerging infectious diseases .

volume 23 , number 1 , january 2017 .

biggerstaff , matthew , carrie reed , david l. swerdlow , manoj gambhir , samuel graitcer , lyn finelli , rebekah h. borse , sonja a. rasmussen , martin i. meltzer , carolyn b. bridges .

estimating the potential effects of a vaccine program against an emerging influenza pandemic — united states , clinical infectious diseases .

volume 60 , issue supplement 1 , 2015 .

carias , cristina , gabriel rainisch , manjunath shankar , bishwa b. adhikari , david l. swerdlow , william a. bower , satish k. pillai , martin i. meltzer , lisa m. koonin .

potential demand for respirators and surgical masks during a hypothetical influenza pandemic in the united states .

clinical infectious disease .

volume 60 , issue supplement 1 , 2015 .

reed , carrie , frederick j. angulo , david l. swerdlow , marc lipsitch , martin i. meltzer , daniel jernigan , and lyn finelli .

estimates of the prevalence of pandemic ( h1n1 ) 2009 , united states , april – july 2009 , emerging infectious diseases .

volume 15 , number 12 , december 2009 .

asher , jason , matthew clay .

deterministic compartmental models for influenza with mitigations .

r: “flumodels” package .

version: 1.0.7 , april 24 , 2017 .

purpose: the government accountability office has been asked by the congress to review the department of health and human services' agency efforts to model infectious disease .

as part of our methodology , we selected and reviewed published papers and internal memoranda from the sources provided to us .

we reviewed these sources to describe the steps taken to describe , verify , validate , and communicate results of these modeling efforts .

the purpose of this inquiry is to provide the authors of the selected papers the opportunity to confirm , clarify , or provide additional information in the table below .

instructions: in the table below , we have two sets of columns: one set indicating gao's assessment of whether the document contained information about a step being taken .

the second set of columns is for the authors of the selected paper to fill out .

if you agree with information in the gao columns , please indicate your concurrence in the reviewer comments column .

otherwise , please provide information accordingly .

if a step is marked “step taken” please review the entries we have made in the gao reviewer comments column for accuracy and completeness and indicate your concurrence in the reviewer comments column .

please also provide additional supporting documentation if available .

for any steps that were taken , but where we indicated either “not taken” or “not enough information to determine” in our review , please provide a description of the actual steps and any documentation you may have .

if a step was not taken , please provide an indication as to why that step was not taken and , if possible , please provide supporting documentation .

for example , if limited data availability impacted the ability to conduct a model validation step ( s ) , then please include this information in the appropriate table cells .

10 independent expert ( internal or external ) review of key programming 11 debugging tests and checks for coding accuracy 12 model's code or excel spreadsheet is available 13 test model assumptions ( i.e .

confirming model assumptions are reasonable and appropriate for question ) , for example: distributional assumptions about model residuals form of the model 14 model handling of input data / parameters is verified as correct ( i.e .

as intended by developers ) .

16 sensitivity analysis ( assessing impact of assumption / parameter uncertainty on output or model form ) 17 cross validation or between model comparisons: compare results to other models that address the same problem 18 external validation: compare model results to actual event data 19 predictive validation: compare model predictions for future events to actual outcomes .

21 modelers supply customer with agreed upon information , which may vary depending on the model 22 modeler provides customer with clear information on uncertainty in model results , such as inclusion of standard errors or confidence intervals , or qualitative explanations of uncertainty in the model results assessment steps question: do you think that the assessment elements identified in the table above sufficiently reflect the steps that should generally be taken to develop and assess the performance of models ? .

would you remove any steps , add any steps , or make any other adjustments to these steps in order to consider them best practices in assessing performance of models , generally ? .

please explain .

in addition to the contact named above , the following individuals made contributions to this report: sushil sharma ( assistant director ) , charlotte e. hinkle ( analyst - in - charge ) , sam amrhein , breanne cave , jehan chase , carol a. gotway crawford , justin cubilo , karen doran , nancy fasciano , douglas g. hunker , dennis mayo , anika mcmillon , sarah resavy , edward rice , ben shouse , amber sinclair , walter vance , sarah veale , and richard zarrella .

