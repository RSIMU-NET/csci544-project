appendix a . acronyms this table lists acronyms that are used in this crs report . how credible are these representations ? for a program or agency , is "success" being defined appropriately ? are credible and appropriate methods of policy analysis , measurement , and evaluation being used ? what resources and tools might congress draw upon , including from its support agencies and the public , to scrutinize any "evidence" that is presented ? what are the policy implications of available evidence and analyses ? oversight , transparency , and public participation . congress oftentimes relies on transparency and public participation to help it conduct oversight of policy development and implementation within agencies and omb . oversight findings may generate interest in subsequent lawmaking or other legislative activity . what have been the recent activities of performance improvement officers and the performance improvement council ? are they functioning effectively ? what is happening during quarterly reviews ? are agencies and omb focusing on learning and improvement in addition to goal achievement ? is the omb performance website providing the required information ? if a goal is removed from the website , or if a goal's target is revised , will the website retain any record of the previous goal or target ? might it be worthwhile to communicate informally with a goal leader or other official who is responsible for a topic under gprama , or more formally invite the official to testify at a hearing ? are non - federal stakeholders being consulted by agencies in the development of agency strategic plans ? what are stakeholders' views about agencies' goals ? are omb and agencies consulting effectively with congress about the potential elimination of requirements to submit plans and reports to congress ? is gprama being implemented in a way that helps agency program managers and front - line staff without creating perverse incentives for organizations and individuals ? crosscutting policy areas . congress and observers have expressed interest in policy areas that cut across agency and programmatic boundaries . in these areas , more than one agency or program may collaborate and contribute toward desired policy outcomes or , conversely , duplicate effort . for example , gprama requires omb to include information on its performance website about each agency program and how the program contributes to one or more of the agency's goals . gao is separately required to report annually on programs , agencies , and initiatives with "duplicative goals and activities. most of gao's march 2011 findings cited "potential" fragmentation , overlap , or duplication , and gao oftentimes recommended further analysis or enhanced coordination . are agencies and omb using their scarce analytical resources effectively to coordinate efforts and identify and exploit potential efficiencies ? are agencies and omb using appropriate tools to conduct these analyses , potentially including evaluations and logic modeling ? are there implications for coordination across congressional committees ? gprama 's design and implementation . compared to the four - year phase - in period for gpra 1993 , the phase - in period for gprama before full implementation is fairly short .