these are very different concepts . if congress is presented in a decision - making situation with a single program evaluation , is the evaluation enough to have high confidence in the findings ? program evaluations can provide helpful insight into policy problems and the manner and extent to which federal policies address those problems . unfortunately , however , one or more program evaluations do not always produce information that is comprehensive , accurate , credible , or unbiased . for example , a program evaluation can be designed to answer a certain question , but the way someone frames the original evaluation question can influence how a program is ultimately portrayed . most prominently , this can be the case when setting criteria for "success," such as a program's goals or the preferred outcomes of interest . however , actors in the policy process often have varying views on how to judge a program's or policy's success . it is not always clear , therefore , that a study's research question will be viewed by most observers as covering what should have been covered to validly or comprehensively evaluate a program . in addition , a program evaluation will not always necessarily be well designed or implemented . in such cases , a study might produce results that are flawed or inaccurate . even in the best case — if an evaluation is appropriate for the research question being studied , is well designed and implemented , and there is widespread consensus on how to judge "success" — it is still possible that random chance or unforeseen events might result in an evaluation that produces information that is inaccurate or flawed . for example , it is possible that an evaluation might provide a "false positive" or "false negative" result ( eg , the study finds the program successful when actually it was not , or finds a program unsuccessful when it actually was successful ) . if this situation were the case , the study findings might not reveal it . the subject of data or information quality is also oftentimes a subject of concern when conducting or interpreting program evaluations . how might congress cope with these possibilities ? how confident must a member or committee be in evaluation information , including from rcts , in order to use the information to inform thinking and conclusions about a policy ? in response , social science researchers have recommended that consumers of evaluation information be aware of the practical capabilities and limitations of various program evaluation methods and also scrutinize a study's claims of internal , external , and construct validity . they have also suggested looking for multiple studies and , if available , systematic reviews . other observers have suggested using the resources of gao or other congressional support agencies to help interpret or validate conclusions and scrutinizing these matters through hearings and oversight . finally , congress might consider whether federal agencies have sufficient capacity and independence to conduct , interpret , and objectively present program evaluations to congress . at times , congress and other actors have expressed concern over the capacity of agencies to adequately perform certain tasks , including management functions that range from procurement to financial management .