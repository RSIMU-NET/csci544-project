this was also an issue for education programs . for example , in california , two higher education systems calculated fte differently . in the case of one , they chose to use a 2-month period as the basis for the fte performance period . the other chose to use a year as the basis for the fte . the result is almost a three - to - one difference in the number of ftes reported for each university system in the first reporting period . although education provides alternative methods for calculating an fte , in neither case does the guidance explicitly state the period of performance of the fte . omb's decision to convert jobs into ftes provides a consistent lens to view the amount of labor being funded by the recovery act , provided each recipient uses a standard time frame in calculating the fte . the current omb guidance , however , creates a situation where , because there is no standard starting or ending point , an fte provides an estimate for the life of the project . without normalizing the fte , aggregate numbers should not be considered , and the issue of a standard period of performance is magnified when looking across programs and across states . recipients were also confused about counting a job created or retained even though they knew the number of hours worked that were paid for with recovery act funds . while omb's guidance explains that in applying the fte calculation for measuring the number of jobs created or retained recipients will need the total number of hours worked that are funded by the recovery act , it could emphasize this relationship more thoroughly throughout its guidance . while there were problems of inconsistent interpretation of the guidance , the reporting process went relatively well for highway projects . dot had an established procedure for reporting prior to enactment of the recovery act . as our report shows , in the cases of education and the department of housing and urban development , which do not have this prior reporting experience , we found more problems . erroneous or questionable data entries . many entries merit further attention due to an unexpected or atypical data value or relationship between data . quality review by federal agencies and prime recipients . o coverage: while omb estimates that more than 90 percent of recipients reported , questions remain about the other 10 percent . o review: over three quarters of the prime reports were marked as having undergone review by a federal agency , while less than 1 percent were marked as having undergone review by the prime recipient issues in the calculation of full - time equivalents ( fte ) . different interpretations of omb guidance compromise the ability to aggregate the data . we performed an initial set of edit checks and basic analyses on the recipient report data available for download from recovery.gov on october 30 .