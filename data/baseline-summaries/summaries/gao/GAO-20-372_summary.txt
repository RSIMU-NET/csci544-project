validation . for four of the 10 models we reviewed , agencies performed few validation steps . in all three cdc pandemic influenza models we reviewed , and the aspr zika model , sensitivity analysis was the only validation step performed . cdc influenza modelers said they did not perform other validation steps because of a lack of comparable external models or applicable data which could be used for other types of model validation . for example , they said they could not validate their models using real - world data because they made projections for scenarios that did not come to pass ( eg , an unmitigated pandemic influenza outbreak ) . verification . in six of 10 models reviewed , we found agency modelers followed most of the steps we identified for model verification . however , in four of the seven cdc models reviewed , cdc did not publish the model's code , a part of model reproducibility and a model verification step . we examine cdc's policy and efforts on reproducibility in more detail below . they said they have continued to look for comparable models that could be used to cross - validate their model estimates . aspr modelers responding to the zika outbreak also did not have access to comparable external models or applicable data to confirm their model projections , but have since attempted to validate their model . for the other six models we reviewed , agencies carried out most but not all validation steps . for example , cdc modelers responding to zika also said they did not perform cross - validation ( comparison of different model results to each other ) for their zika model because of a lack of comparable models . however , these aspr and cdc zika modelers said they have attempted to validate their model since its publication as new data emerges , and we found this occurred . assessing model validity assessing model validity means determining whether a model is sufficiently accurate for its purpose . several methods are available , including the following: modelers can compare the results of the model against real - world data the model was designed to predict . if there are no such data , another method is to determine how much the model projections change in response to changes in input data . this is known as model sensitivity analysis . modelers can also withhold a part of the available data in building the model and then confirm the model can reproduce the withheld data . real - world data is to run the model along with a separate , independent model using the same input data , and comparing the outputs . cdc modelers and aspr modelers responding to zika followed identified practices and validated their model projections for the zika outbreak , although their efforts yielded mixed results for model performance . cdc modelers responding to zika attempted to estimate whether there was an enhanced risk of microcephaly in infants born to expectant mothers infected with zika . using data available during the initial stage of the outbreak , they calculated the enhanced risk to be between 0.88 and 13.2 percent if the mother was infected in the first trimester .