reliability . measures reflect this attribute when they produce the same result under similar conditions . reliability is increased when verification and validation procedures exist , such as checking performance data for significant errors by formal evaluation or audit . va's performance measures fully reflected the reliability attribute ; dol's measures partially reflected it . va officials told us they ensure data quality through the use of validation processes , error messages , and notifications that appear in real - time as data are entered . additionally , there are dedicated program offices that work with the vamc's and service providers to monitor and reconcile data . finally , va's policies describe steps that should be taken to review and verify the quality of the data . dol officials told us they review hvrp performance data quality at different levels in the agency ( regional and national ) and use a data validation tool to identify potential errors . however , dol officials acknowledge limitations with data quality , namely the lack of an electronic system to compile the data and the potential for human error when entering data into spreadsheets . further , hvrp service providers may be unclear about the data quality steps to take because dol's performance measurement policies provide limited information on data reliability procedures . dol officials stated that they have conducted webinar training on the data validation tool , but acknowledge that no written policy exits for the data validation process . without guidance from dol on the quality control processes that should be applied to performance data , service providers may not understand how to improve data quality and dol may not have reasonable assurance that these performance data are the most accurate and reliable available . while va's measures reflected all the selected attributes of successful performance measures , including communicating linkage , we identified other areas where communication about these measures is not clear . for example , staff from three of the vamcs we interviewed and two service providers described communication issues related to performance measures for four programs ( hud - vash , gpd , hvces , and dchv ) . these issues included concerns that va does not understand the realities on the ground that prevent vamc staff and service providers from meeting the measures ( such as limited housing availability ) and vamc staff being unaware they could use performance scorecards to drill down and learn more about why their performance targets were not met . additionally , some vamc staff and service providers we interviewed do not fully understand the measures . for example , dchv and hchv staff we interviewed from four vamcs and three gpd service providers told us they have felt penalized for transitioning veterans from a va homeless assistance program to another program or to substance abuse or mental health treatment because va's performance measures count these transitions as “negative exits.” according to va officials , however , there are only three instances where participant program exits are counted as negative: 1 ) when participants are asked to leave for failure to follow rules ; 2 ) when participants leave for failure to comply with program requirements ; and 3 ) when participants leave without telling program staff .