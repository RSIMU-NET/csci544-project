ii ) . today's head start is a much different program than it was 30 years ago . one of the more serious of the methodological problems was noncomparability of comparison groups . the most reliable way to determine program impact is to compare a group of head start participants with an equivalent group of nonparticipants . the preferred method for establishing that the groups are equivalent at outset is to randomly assign participants to either the head start group or the comparison group . only one of the studies we reviewed used random assignment to form the head start and non - head start comparison groups . most of these studies formed a comparison group by selecting children who were similar to the head start participants on some characteristic thought to be important to the outcome under study . although impact studies are sometimes difficult and expensive , they are the only way to answer the question , “is this program making a difference ? ” thus , we included only studies in this review that gave some information on program impact . see appendix i for details on criteria we used to select studies . to determine what research suggests about the impact of head start , we searched many electronic databases to locate published and unpublished manuscripts . we also spoke with early childhood researchers and practitioners to identify research studies . our search yielded nearly 600 citations and documents , which were screened for possible inclusion in the study . of these , we found 22 studies that fit our agreed - upon criteria and are reviewed in this study . ( see app . small samples present problems in research because they adversely affect statistical procedures used in analyses . some procedures cannot appropriately be used with small samples ; others are rendered less able to detect differences , resulting in an underestimation of program effects . no completed , large - scale evaluation of any outcome of head start that used a nationally representative sample was found in our review . one characteristic of head start is program variability , not only in the kind of services delivered , but also in the quality of services . making summary statements about program impact requires that the sample of programs studied represent all programs nationwide . although one evaluation had a study design that would have allowed findings to be generalized to the national program , this study was never completed . in the late 1970s , hhs contracted for a national evaluation of the educational services component of basic head start . the design called for a longitudinal study that would follow children and their parents from preschool through the fourth grade . the evaluation was to compare the basic educational skills program , regular head start , and a non - head start control group . thirty head start programs were to be randomly selected , and head start - eligible children from these communities were to be randomly assigned to head start or the control group . many methodological problems as well as funding problems occurred , however , during the implementation of this study , and it was abandoned .