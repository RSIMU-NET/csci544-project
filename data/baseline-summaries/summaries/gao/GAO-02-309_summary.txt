we disagree . we believe that separating the cost of the impact and process evaluations is more than a matter of bookkeeping . even though the work done during the process phase of an evaluation may have implications for the impact evaluation phase of an evaluation , it would seem that , given the complexity of impact evaluations , ojp and nij would want to have in place appropriate controls to provide reasonable assurance that the evaluations are being effectively and efficiently carried out at each phase of the evaluation . tracking the cost of these evaluation components would also help reduce the risk that ojp's , nij's , and , ultimately , the taxpayer's investment in these impact evaluations is not wasted . as discussed earlier , we recognize that there are substantive differences in the intent , structure , and design of the various discretionary grant programs managed by ojp and its bureaus and offices , including those managed by vawo . our report focuses on the rigor of impact evaluations of grant programs administered by vawo and not on the program's implementing legislations . although flexibility may make sense from a program perspective , it makes it difficult to develop a well designed and methodologically rigorous evaluation that produces generalizeable results about the impact of the entire program . our report does not suggest that other types of evaluations , such as comprehensive process evaluations , are any less useful in providing information about how well a program is operating . the scope of our review covered impact evaluations of byrne and vawo discretionary grant programs â€” those designed to assess the net effect of a program by comparing program outcomes with an estimate of what would have happened in the absence of the program . in addition to the above , wendy c. simkalo , jared a. hermalin , chan my j. battcher , judy k. pagano , grace a. coleman , and ann h. finley made key contributions to this report . too early to assess . technically developed evaluation sites and is not representative of either all rural domestic violence program grantees , particular types of projects , or delivery styles . ( 2 ) the lack of comparison groups will make it difficult to exclude the effect of external factors , such as victim safety and improved access to services , on perceived change . ( 3 ) several so - called short - term outcome variables are in fact process variables ( eg , number of police officers who complete a training program on domestic violence , identification of barriers to meeting the needs of women and children ) . ( 4 ) it is not clear how interview and focus group participants are to be selected , ( 5 ) statistical procedures to be used in the analyses have not been sufficiently identified . the nij peer review committee had concerns about whether the evaluation could demonstrate that the program was working . nij funded the application as a cooperative agreement because a substantial amount of agency involvement was deemed necessary to meet the objectives of the evaluation .