such indicators are important . for example , according to dss officials , the indicator pertaining to the completion of security reviews provides government customers assurances that industrial security representatives are monitoring their contractors . the timeliness of clearances also matters because the facility and its personnel cannot access classified information in support of a government contract until dss has cleared them . for each of the indicators , dss established specific performance goals . while dss did not meet all of its goals related to the timeliness of contractor facility and personnel clearances , it met or exceeded the goals related to security reviews . for example , dss's goal is to conduct annual security reviews of 98 percent of the facilities that store classified information on site . in fiscal year 2002 , the most recent year for which data are available , dss reported meeting this goal . dss also reported that it exceeded the goal of having 75 percent of its security reviews cover all pertinent areas within contractor facilities' security programs . based on a review of selected security review reports , dss determined that 86 percent of its security reviews conducted in fiscal year 2002 covered all pertinent areas and accurately reflected the contractor facilities' overall security posture . however , dss measured its achievement of this goal based on field office chiefs' selection and review of about 550 of the approximately 9,000 reports completed by industrial security representatives . this review does not focus on the quality of the facilities' security programs or the representatives' review of those programs . instead , it is used to determine the completeness of the reports . these current goals and measures alone do not enable dss to determine whether its oversight is effectively ensuring that contractors protect classified information . there are no goals related to how well facilities are protecting classified information , which would provide an indication as to whether dss is achieving its mission . for example , while dss evaluates the completeness of security review reports submitted by industrial security representatives , it does not evaluate its performance in terms of the ratings and number of findings that result from security reviews . nor does dss evaluate its performance in terms of the frequency of security violations and information compromises occurring at contractor facilities . by not assessing its performance based on factors such as facility compliance with nispom requirements , dss cannot determine whether its oversight efforts are contributing to an increase or decrease in facilities' compliance and the protection of classified information . dss maintains records on how well contractor facilities protect classified information but does not analyze these records . there are no programwide analyses of violations reported by facilities or results of dss's reviews of facilities . further , the manner in which dss maintains records on facilities' security programs — geographically dispersed paper - based files — does not lend itself to analysis . industrial security representatives maintain a file folder on each facility they oversee . according to dss officials , the information contained in these file folders represents the official record on each contractor facility . the folders are the primary means for documenting information on facilities' security programs and representatives' interactions with those facilities .