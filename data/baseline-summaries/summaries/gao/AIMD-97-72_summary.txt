we disagree . federal regulations provide for the suspension of federal funding when states' systems under development cease to substantially comply with requirements and other provisions of the apd.further , irrespective of the deadline , allowing systems to be developed ineffectively and inefficiently at the expense of the taxpayers is not supporting the goals and underlying intent of the legislation . allowing a state to go forward before correcting inadequacies in approach contributes to rising systems' costs . in this report and in our 1992 report , we pointed out that ocse continues to fund systems with serious problems — problems that threaten their very success . as discussed in this report , such an approach invites the need to correct serious problems later in the development process , when it is more costly and time - consuming to do so . ocse has periodically suspended state funding for automation projects . as we reported , however , almost 60 percent of these disruptions were due to insufficient information on the required apd , or for states' exceeding their authorized funding levels — not for more substantive issues on the soundness of the development approach itself . even when funding was held up for major systems - related problems , efforts to correct these problems did not appear to be made in a timely fashion . further , in cases in which an hhs regional official suggested that ocse hold up funding for a project , the agency did not stop funding until the project “crashed. hhs agreed that the states are encountering automation problems and that states need a greater degree of oversight . the department stated that ocse follows a structured approach in reviewing states apd submissions . we believe this approach is not sufficient oversight . while we described the agency's review process — apd and certification reviews , we believe that the apd process should ensure that systems development activities at critical decision points are evaluated . ocse does not consistently monitor state systems development at critical milestone points , such as the completion of design or requirements development . we noted that ocse's certification reviews are usually conducted toward the end of the development process , and as such are often too late to help identify problems and redirect the approach . another issue raised by hhs was that with a variety of concurrent systems development activities , including the staggering welfare reform deadlines , it may be difficult to use our suggested “one structured methodology fits all.” we are certainly not advocating that ocse require or impose a “one structured methodology fits all” approach . a structured approach to reviewing systems development — irrespective of the particular methodology used — would also allow for systems variability , including the differences in project size , scope , and complexity . the key to a structured approach is the identification of critical milestones that are the basis for systems reviews . states value this process ; one state official noted that its project would be unmanageable without it . other state officials told us that ocse should play a more active role , and that they considered it important that the agency assess the management and direction of the project early to avoid or minimize later problems .