equipment availability . equipment that is not mission capable . age of equipment . condition of nonpacing items . are further improvements to dod's reporting process needed ? before i answer these questions , some background on dod's readiness assessment system may be helpful . dod assesses military readiness at three levels — ( 1 ) the individual unit level ; ( 2 ) the joint force level ; and ( 3 ) the aggregate , or strategic , level . “unit readiness” refers to the ability of units , such as army divisions , navy ships , and air force wings , to provide capabilities required of the combatant commands and is derived from the ability of each unit to deliver the outputs for which it was designed . “joint readiness” is the combatant commands' ability to integrate and synchronize units from one or more services to execute missions . “strategic readiness” is a synthesis of unit and joint readiness and concerns the ability of the armed forces as a whole , including the services , the combatant commands , and the combat support agencies , to fight and meet the demands of the national security strategy . any discussion of readiness measurement must start with sorts . this automated system , which functions as the central listing for more than 9,000 military units , is the foundation of dod's unit readiness assessment process and is a primary source of information used for reviews at the joint and strategic levels . the system's database indicates , at a selected point in time , the extent to which these units possess the required resources and training to undertake their wartime missions . units regularly report this information using a rating system that comprises various indicators on the status of personnel , equipment , supplies , and training . sorts is intended to enable the joint staff , the combatant commands , and the military services to , among other things , prepare lists of readily available units , assist in identifying or confirming major constraints on the employment of units , and confirm shortfalls and distribution problems with unit resources . until the early 1990s , dod defined “readiness” narrowly in terms of the ability of units to accomplish the missions for which they were designed , and sorts was the only nonservice - specific system dod had to measure readiness . even today , sorts remains an important component of readiness assessment in that data from the system is used extensively by the services to formulate a big - picture view of readiness . however , limitations to sorts have been well documented for many years by various audit and oversight organizations . for example , prior reviews by our office and others have found: sorts represents a snapshot in time and does not signal impending changes in readiness . sorts relies on military judgment for certain ratings , including the commanders' overall rating of unit readiness . in some cases , sorts ratings reflect a higher or lower rating than the reported analytical measures support . however , dod officials view subjectivity in sorts reports as a strength because the commanders' judgments provide professional military assessments of unit readiness .