these requirements were new in most states . more explicit expectations for rigor . in four of the seven states we reviewed , the stcs for the most recently approved cycle of states' demonstrations included new , explicit language requiring state evaluations to meet the prevailing standards of scientific and academic rigor . these included standards for the evaluation design and conduct as well as the interpretation and reporting of findings . according to cms , in the past , states have not always discussed methodological limitations in their evaluation reports . in addition to strengthening evaluation requirements , cms has also taken steps since 2014 to enhance its oversight during the design and early stages of state - led evaluations , and , according to officials , some of these steps are likely to improve the usefulness of evaluations . specifically , cms has provided technical assistance to help states design their evaluations , sometimes leveraging expertise from other parts of hhs , including the hhs office of the assistant secretary for planning and evaluation and the center for medicare & medicaid innovation as well as outside contractors . for example , officials stated that the agency assists states in developing relevant and standardized measures and provides assistance to help address states' data limitations . officials said this has resulted in more robust evaluation designs with increased potential to isolate outcomes and impacts . cms has also used contractors to help in its review of state evaluation designs , including sampling designs , and evaluation reports . since 2014 , one contractor has provided over 30 assessments of evaluation designs and findings in at least 11 states . according to officials , this has increased cms's capacity to identify methodological weaknesses and negotiate changes with states to improve the usefulness of evaluations . for example , cms's contractor reviewed four draft survey instruments that indiana planned to use in its evaluation , providing comments on the sampling frames and the structure and organization of survey questions . in response to the contractor's feedback , indiana made changes to the surveys to gather more reliable information and improve their readability . finally , cms has begun making changes to how it sets due dates for final evaluation reports . cms officials told us that in spring 2017 , cms began requiring states to submit a comprehensive evaluation report for demonstrations in its high priority policy areas for evaluation at the end of each demonstration cycle , rather than after the expiration of the demonstration . cms's recent demonstration renewals in florida and missouri — approved in august and september of 2017 , respectively — required a final , summative evaluation report at the end of the demonstration cycle , consistent with the policy . in october 2017 , cms officials stated that the agency was expanding this policy and was now planning to require final reports at the end of each cycle for all demonstrations , as they are approved or renewed . however , cms had not established written procedures for implementing this new policy . it is too soon to assess the effectiveness of cms's recent efforts to strengthen state - led evaluations .