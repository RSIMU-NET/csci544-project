missing cbocs . we found that 53 cbocs ( 7 percent of all cbocs ) were missing from the cboc report from the first quarter of fiscal year 2017 , rendering the data incomplete . vha officials provided examples of why a cboc might not be included in the report . for example , a newer cboc might not be included because it did not have quality of care data available at the time the report was developed . however , we identified several other sites that were listed in the report , despite unavailable data . inaccurate summary calculations . due to the incorrect site classifications and missing cbocs , the national - and visn - level summary calculations of performance in the cboc report were also inaccurate . specifically , the report includes national - and visn - level averages for each hedis measure , which vha officials can use as benchmarks for clinic performance . these averages were over - inclusive — incorporating performance results from additional sites that were not cbocs , and under - inclusive — omitting performance results from cbocs that were missing from the report . these inaccuracies may lead vha officials to draw incorrect conclusions about the quality of care provided in cbocs . for example , officials from one vamc told us that they use the national averages as benchmarks against which they compare the performance of their cbocs . because this vamc requires cbocs with lower - than - average hedis performance results to develop a formal action plan to improve performance , officials may not be identifying clinics that are in need of an action plan due to the inaccuracy of the averages . in addition , vha central office officials who develop the cboc report said that the results from recent reports have shown that vha - operated and contracted clinics in general provided the same standard of care , but this conclusion may not be correct as it is based on unreliable data . no guidance or training for use of the cboc report . vha central office officials do not provide guidance or training specific to the cboc report to assist visns and vamcs in using it to oversee cbocs . this is inconsistent with federal standards for internal control related to the control environment , which state that management should , among other things , develop personnel to achieve the entity's objectives . no requirement for visns or vamcs to use the cboc report . vha does not require that the cboc report be used as a tool to oversee cbocs . as a result , we found that the report was not widely used . specifically , an official from the office of the deputy under secretary for health for organizational excellence — which produces the cboc report — told us that the office's role is to compile the reports and distribute them , but not to monitor performance . officials from the office of the deputy under secretary for health for operations and management said that visns and vamcs are expected to use the report as part of their cboc oversight ; however , we found there is no requirement that they do so .