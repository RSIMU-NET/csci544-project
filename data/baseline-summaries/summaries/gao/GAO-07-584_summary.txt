this is not the case . safestat does a good job of identifying carriers that pose high crash risks . as we reported in june 2007 , we found that safestat is nearly twice as effective ( 83 percent better than ) as random selection in identifying carriers that pose high crash risks and , therefore , has value for improving safety . nonetheless , we found that fmcsa's policy for prioritizing compliance reviews could be improved by applying either our regression model approach or one of the prioritization approaches we developed in this report . while we believe that the regression model approach provides somewhat better safety results , we understand , as discussed in our june 2007 report , that it could require fmcsa to re - educate the motor carrier industry and others , such as safety advocates , insurers , and the public , about the new approach . we would prefer that fmcsa implement our recommendation that it use our regression model approach but adopting either our regression model approach or one of the prioritization approaches we developed in this report would , in our opinion , improve fmcsa's targeting of high - risk carriers . the recommendation that we make in this report reflects this conclusion . finally , fmcsa has been very helpful and responsive during both our — largely concurrent — reviews . for our june 2007 report , we assessed the quality of the data used by safestat and the degree to which the quality of the data affects safestat's identification of high - risk carriers , and we identified actions fmcsa has taken to improve the quality of the data used by safestat . we found that crash data reported by the states from december 2001 through june 2004 have problems in terms of timeliness , accuracy , and completeness that potentially hinder fmcsa's ability to identify high - risk carriers . regarding timeliness , we found that including late - reported data had a small impact on safestat — had all crash data been reported within 90 days of when the crashes occurred , 182 of the carriers identified by safestat as highest risk would have been excluded ( because other carriers had higher crash risks ) , and 481 carriers that were not originally designated as posing high crash risks would have scored high enough to be considered high risk , resulting in a net addition of 299 carriers ( or 6 percent ) to the original 4,989 carriers that the safestat model ranked as highest risk in june 2004 . we were not able to quantify the effect of incomplete or inaccurate data on safestat's ability to identify carriers that pose high crash risks , because doing so would have required us to gather crash records at the state level — an effort that was impractical . fmcsa has acted to improve the quality of safestat's data by completing a comprehensive plan for data quality improvement , implementing an approach to correct inaccurate data , and providing grants to states for improving data quality , among other things . we could not quantify the effects of fmcsa's efforts to improve the completeness or accuracy of the data for the same reason as just mentioned . ( see app .