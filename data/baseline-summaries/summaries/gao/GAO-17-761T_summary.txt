( see fig . as of january 2017 , cms had begun compiling basic statistics on the volume and consistency of data submissions and preparing automated summary reports for maos indicating the diagnosis information used for risk adjustment ; however cms had not yet taken other important steps identified in its medicaid protocol , which we used for comparison . the steps cms had not yet taken as of our january 2017 report are: establish benchmarks for completeness and accuracy . this step would establish requirements for collecting and submitting ma encounter data . we also interviewed cms officials . my remarks on the progress cms has made in validating encounter data and its plans to use the data are based on our 2017 report examining these issues . for that report , we compared cms's activities with the agency's protocol for validating medicaid encounter data , which are comparable data collected and submitted by entities similar to maos , and federal internal control standards . we also reviewed relevant agency documents and interviewed cms officials about ma encounter data collection and reporting . more detailed information on our objectives , scope , and methodology for this work can be found in the issued reports . for this statement , we also asked cms officials for updates on the status of our prior recommendations . we conducted the work on which this statement is based in accordance with generally accepted government auditing standards . those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives . we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives . cms did not always target the contracts with the highest coding intensity scores , use results from prior contract - level radv audits , account for contract consolidation , or account for contracts with high enrollment . for example , only four of the contracts selected for the 2011 radv audit had coding intensity scores at the 90th percentile or above . even though we found that coding intensity scores are not strongly correlated with diagnostic discrepancies , they are still somewhat correlated . also , cms's 2011 contract selection methodology did not consider results from the agency's prior radv audits , potentially overlooking information indicating contracts with known improper payment risk . finally , even though the potential dollar amount of improper payments to maos with high rates of unsupported diagnoses is likely greater when contract enrollment is large , cms officials stated that the 2011 contract - level radv audit contract selection did not account for contracts with high enrollment . we made two recommendations to address these issues: we recommended that ( 1 ) cms improve the accuracy of coding intensity calculations , and ( 2 ) modify its processes for selecting contracts for radv audit to focus on those most likely to have improper payments . in july 2017 , cms officials told us that the agency is working to implement these recommendations regarding the selection of contracts for audit .