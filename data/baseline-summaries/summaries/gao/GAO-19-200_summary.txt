( recommendation 1 ) . we provided a draft of this report for review and comment to the departments of agriculture , defense , education , health and human services , interior , justice , labor , and veterans affairs , and to the environmental protection agency . however , the practical difficulties of conducting any survey may introduce errors , commonly referred to as nonsampling errors . for example , difficulties in interpreting a particular question , sources of information available to respondents , or entering data into a database or analyzing them can introduce unwanted variability into the survey results . we took steps in developing the surveys , collecting the data , and analyzing them to minimize such nonsampling error . for example , to minimize difficulties interpreting a particular survey question , we incorporated the suggestions from an independent reviewer to add explicit instructions for how to use the pull - down menus and consistently phrased requests for information . we reviewed the completed surveys and clarified information with agency officials , as needed . we further reviewed the survey to ensure the ordering of survey sections was appropriate and that the questions within each section were clearly stated and easy to comprehend . to reduce nonresponse , another source of nonsampling error , we sent out email reminder messages to encourage officials to complete the survey . in reviewing the survey data , we performed automated checks to identify inappropriate answers . we further reviewed the data for missing or ambiguous responses and followed up with agency officials when necessary to clarify their responses . on the basis of our application of recognized survey design practices and follow - up procedures , we determined that the data were of sufficient quality for our purposes . in terms of agency actions to manage overlap and fragmentation and to detect / prevent duplication , we followed up with select agencies to better understand what prompted the actions they took and the lessons they learned from evaluating those efforts . we did not conduct a legal analysis to confirm the various characterizations of the programs in this report , such as information on their budgetary obligations , services provided , target population , eligibility criteria , or program goals . instead , all such program information in this report is based on our survey results , as confirmed by agency officials . further , we did not review agencies' financial reporting systems or audit the figures provided to us . we reviewed fiscal year 2019 budget documents to determine if they could be used to verify data provided by the agencies , but they did not consistently contain the program - level details needed . these may include but are not limited to formal evaluations . however , without a long - term evaluation plan developed in consultation with key stakeholders , dol may not learn whether its actions to improve e&t program coordination and integration are working , and thus may continue undertaking activities that are not leading to desired results . with the enactment of wioa in 2014 , steps were taken toward aligning employment and training programs and ensuring greater cross - agency coordination .