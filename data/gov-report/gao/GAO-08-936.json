{"id": "GAO-08-936", "url": "https://www.gao.gov/products/GAO-08-936", "title": "2010 Census: Census Bureau's Decision to Continue with Handheld Computers for Address Canvassing Makes Planning and Testing Critical", "published_date": "2008-07-31T00:00:00", "released_date": "2008-09-02T00:00:00", "highlight": [{"section_title": "Why GAO Did This Study", "paragraphs": ["The U.S. Census Bureau (Bureau) had planned to rely heavily on automation in conducting the 2010 Census, including using handheld computers (HHC) to verify addresses. Citing concerns about escalating costs, in March 2008 the Secretary of Commerce announced a redesign of the key automation effort. GAO was asked to (1) analyze Bureau and contractor data showing how HHCs operated and their impact on operations, and (2) examine implications the redesign may have on plans for address canvassing in the 2010 Census. GAO reviewed Bureau and contractor data, evaluations, and other documents on HHC performance and staff productivity; interviewed Bureau and contractor officials; and visited the two dress rehearsal sites to observe and document the use of the HHCs in the field."]}, {"section_title": "What GAO Found", "paragraphs": ["Census and contractor data highlight problems field staff (listers) experienced using HHCs during the address canvassing dress rehearsal operation in 2007. Help desk logs, for example, revealed that listers most frequently reported issues with transmission, the device freezing, mapspotting (collecting mapping coordinates), and difficulties working with large blocks. When problems were identified, the contractor downloaded corrected software to the HHCs. Nonetheless, help desk resources were inadequate. The Bureau acknowledged that issues with the use of technology affected field staff productivity. After address canvassing, the Bureau established a review board and worked with its contractor to create task teams to analyze and address Field Data Collection Automation (FDCA) performance issues. Although the Bureau recognized that technology issues affected operations, and the contractor produced data on average transmission times, the Bureau and its contractor did not fully assess the magnitude of key measures of HHC performance. GAO previously recommended the Bureau establish specific quantifiable measures in such areas as productivity and performance. Also, the FDCA contract calls for the contractor to provide near real-time monitoring of performance metrics through a \"dashboard\" application. This application was not used during the census dress rehearsal. The Bureau has developed a preliminary list of metrics to be included in the dashboard such as daily measures on average transmission duration and number of failed transmissions, but has few benchmarks for expected performance. For example, the Bureau has not developed an acceptable level of performance on total number of failed transmissions or average connection speed. Technology issues and the Bureau's efforts to redesign FDCA have significant implications for address canvassing. Among these are ensuring that FDCA solutions for technical issues identified in the dress rehearsal are tested, the help desk adequately supports field staff, and a solution for conducting address canvassing in large blocks is tested. In June 2008, the Bureau developed a testing plan that includes a limited operational field test, but the plan does not specify the basis for determining the readiness of the FDCA solution for address canvassing and when and how this determination will occur."]}], "report": [{"section_title": "Letter", "paragraphs": ["In March 2008, we designated the 2010 Decennial Census as a high-risk  area, citing a number of long-standing and emerging challenges. These  include weaknesses in managing information technology, operational  planning, and cost estimating, as well as uncertainty over dress rehearsal  plans and the ultimate cost of the census. Because the census is  fundamental for many government decisions, threats to a timely and  reliable census can affect the public\u2019s confidence in government.", "From May to June 2007, the U.S. Census Bureau (Bureau) conducted the  address canvassing operation of the 2008 Dress Rehearsal. This operation  was the Bureau\u2019s final opportunity to test, under census-like conditions,  handheld computers (HHC) developed by the contractor that will be  deployed during the 2010 Census Address Canvassing operation\u2014 scheduled to take place in the spring of 2009. In previous decennial  censuses, the Bureau relied on a paper-based operation. According to the  Bureau, the HHCs were to be a keystone to the reengineered census  because they were to be used in developing an accurate address list for the  Bureau and in obtaining information from households that fail to return  Census forms. The Bureau believed that the HHCs would reduce the  amount of paper used, process data in real time, and improve the quality of  the data. However, at a March 2008 hearing, the Department of Commerce  (Commerce) and the Bureau stated that the Field Data Collection  Automation (FDCA) program, under which the HHCs are being developed,  was likely to incur significant cost overruns and announced a redesigning  effort to get the 2010 Decennial Census back on track.", "The Secretary of Commerce outlined several alternatives for redesigning  this central technology investment, and on April 3, 2008, he decided to  continue with the HHCs for address canvassing. During redesign  deliberations, Bureau officials pointed out that it was too late in the  decennial cycle to consider dropping the use of the HHCs for address  canvassing in 2009. They considered that with hard deadlines fast  approaching, there was not enough time to revert to a paper-based address  canvassing operation. The decision to use the HHCs in the 2010 Address  Canvassing operation makes it critical that any problems identified with  the HHCs in the dress rehearsal are resolved quickly and that the Bureau  understand the implications of proceeding with this technology.", "Continued oversight of 2010 Census preparation is critical as the Bureau is  redesigning operations late in the decennial cycle and relying on new  technology to modernize its address listing and mapping activities. To  respond to your interest in performance of the HHCs during 2008 Dress  Rehearsal Address Canvassing, we examined whether the HHCs worked in  collecting and transmitting address and mapping data. As part of this  subcommittee\u2019s ongoing oversight of the 2010 Census, we testified in April  2008 on our preliminary observation of weaknesses with HHC  performance and the potential implications for the 2010 Census. We also  raised the importance of performance measures and planning,  recommending that the Bureau establish specific quantifiable measures in  such areas as productivity and performance. At the subcommittee\u2019s  request, we (1) analyzed Bureau and contractor data showing how HHCs  operated and its implications on operations, and (2) examined  implications the redesign may have on plans for address canvassing in the  2010 Census.", "In responding to these objectives, we reviewed Bureau planning  documents, data on HHC performance and staff productivity, evaluation  reports, and staff observations of address canvassing operations. We  reviewed contract documents, help desk logs, contractor data on  transmissions, and contractor evaluations of HHC performance. We also  interviewed Bureau and contractor officials to determine the functionality  of the HHCs during dress rehearsal address canvassing. Finally, we visited  the two dress rehearsal sites in California and North Carolina to attend  address canvassing lister training and to observe and document the use of  the HHCs in the field during the dress rehearsal in the summer of 2007.  Appendix I provides more detail on our scope and methodology. We  conducted this performance audit from April 2007 to July 2008 in  accordance with generally accepted government auditing standards. Those  standards require that we plan and perform the audit to obtain sufficient,  appropriate evidence to provide a reasonable basis for our findings and  conclusions based on our audit objectives. We believe that the evidence  obtained provides a reasonable basis for our findings and conclusions  based on our audit objectives."], "subsections": [{"section_title": "Background", "paragraphs": ["In preparation for the 2010 Census, the address canvassing operation was  tested as part of the 2008 Dress Rehearsal. From May 7 to June 25, 2007,  the Bureau conducted its address canvassing operation for its 2008 Dress  Rehearsal in selected localities in California (see fig. 1) and North Carolina  (see fig. 2). The 2008 Census Dress Rehearsal took place in San Joaquin  County, California, and nine counties in the Fayetteville, North Carolina,  area. According to the Bureau, the dress rehearsal sites provided a  comprehensive environment for demonstrating and refining planned 2010  Census operations and activities, such as the use of HHCs equipped with  Global Positioning System (GPS).", "Prior to Census Day, Bureau listers perform the address canvassing  operation, during which they verify the addresses of all housing units.  Address canvassing is a field operation to help build a complete and  accurate address list. The Bureau\u2019s Master Address File (MAF) is intended  to be a complete and current list of all addresses and locations where  people live or potentially live. The Topographically Integrated Geographic  Encoding and Referencing (TIGER\u00ae) database is a mapping system that  identifies all visible geographic features, such as type and location of  streets, housing units, rivers, and railroads. Consequently, MAF/TIGER\u00ae  provides a complete and accurate address list (the cornerstone of a  successful census) because it identifies all living quarters that are to  receive a census questionnaire and serves as the control mechanism for  following up with households that do not respond. If the address list is  inaccurate, people can be missed, counted more than once, or included in  the wrong location(s).", "Generally, during address canvassing, census listers go door to door  verifying and correcting addresses for all households and street features  contained on decennial maps. The address listers add to the 2010 Census  address list any additional addresses they find and make other needed  corrections to the 2010 Census address list and maps using GPS-equipped  HHCs. Listers are instructed to compare what they discover on the ground  to what is displayed on their HHC.", "As part of the 2004 and 2006 Census Tests, the Bureau produced a  prototype of the HHC that would allow the Bureau to automate  operations, and eliminate the need to print millions of paper  questionnaires, address registers, and maps used by temporary listers to  conduct address canvassing and non-response follow-up as well as to  allow listers to electronically submit their time and expense information.  The HHCs for these tests were off-the-shelf computers purchased and  programmed by the Bureau. While the Bureau was largely testing the  feasibility of using HHCs for collecting data, it encountered a   number of technical problems. The following are some of the problems we  observed during the 2004and 2006 tests:    slowness and frequent lock-up,    problems with slow or unsuccessful transmissions, and    difficulty in linking a mapspot to addresses for multi-unit structures.", "For the 2008 Dress Rehearsal and the 2010 Census, the Bureau awarded  the development of the hardware and software for a HHC to a contractor.  In March 2006, the Bureau awarded a 5-year contract of $595,667,000 to  support the FDCA project. The FDCA project includes the development of  HHCs, and Bureau officials stated that the HHCs would ultimately increase  the efficiency and reduce costs for the 2010 Census. According to the  Director of the Census Bureau, the FDCA program was designed to supply  the information technology infrastructure, support services, hardware, and  software to support a network for almost 500 local offices and for HHCs  that will be used across the country. He also indicated that FDCA can be  thought of as being made up of three fundamental components: (1)  automated data collection using handheld devices to conduct address  canvassing, and to collect data during the non-response follow-up of those  households that do not return the census form; (2) the Operations Control  System (OCS) that tracks and manages decennial census workflow in the  field; and (3) census operations infrastructure, which provides office  automation and support for regional and local census offices.", "The 2008 Dress Rehearsal Address Canvassing operation marked the first  time the contractor-built HHCs and the operations control system were  used in the field. In 2006, we reported that not using the contractor-built  HHCs until 2008 Dress Rehearsal Address Canvassing would leave little  time to develop, test, and incorporate refinements to the HHCs in  preparation for the 2010 Census. We also reported that because the  Bureau-developed HHC had performance problems, the introduction of a  new HHC added another level of risk to the success of the 2010 Census.", "For the 2008 Dress Rehearsal, the FDCA contractor developed the  hardware and software used in census offices and on the HHCs. See figure  3 for more details. The HHC included several applications that varied  depending on the role of the user: software enabling listers to complete  their time and expense electronically; text messaging software enabling  listers to communicate via text message; software enabling staff to review  all work assigned to them and enabling crew leaders to make assignments;  software enabling staff to perform address canvassing; and an instrument  enabling quality control listers to perform quality assurance tasks."], "subsections": []}, {"section_title": "Field Operations Were Affected by Problems Encountered Using New Technology, and the Bureau Did Not Sufficiently Specify What It Expected of Technology", "paragraphs": ["The dress rehearsal address canvassing started May 7, 2007, and ended  June 25, 2007, as planned. The Bureau reported in its 2008 Census Dress  Rehearsal Address Canvassing Assessment Report being able to use the  HHC to collect address information for 98.7 percent of housing units  visited and map information for 97.4 percent of the housing units visited.  There were 630,334 records extracted from the Bureau\u2019s address and  mapping database and sent to the Bureau\u2019s address canvassing operation  and 574,606 valid records following the operation. Mapspots (mapping  coordinates) were collected for each structure that the Bureau defined as  a Housing Unit, Other Living Quarters, or Uninhabitable. Each single- family structure received its own mapspot, while multi-unit structures  shared a single mapspot for all the living quarters within that structure.  According to the Bureau\u2019s 2008 Dress Rehearsal Address Canvassing  Assessment Report, the address canvassing operation successfully  collected GPS mapspot coordinates in the appropriate block for  approximately 92 percent of valid structures; most of the remaining 8  percent of cases had a manual coordinate that was used as the mapspot. It  is not clear whether this represents acceptable performance because the  Bureau did not set thresholds as to what it expected during the address  canvassing dress rehearsal."], "subsections": [{"section_title": "Listers Encountered Problems Using HHCs to Update Addresses and Collect Mapspots during the Dress Rehearsal Address Canvassing Operation", "paragraphs": ["Listers experienced multiple problems using the HHCs. For example, we  observed and the listers told us that they experienced slow and  inconsistent data transmissions from the HHCs to the central data  processing center. The listers reported the device was slow to process  addresses that were a part of a large assignment area. Bureau staff  reported similar problems with the HHCs in observation reports, help desk  calls, and debriefing reports. In addition, our analysis of Bureau  documentation revealed problems with the HHCs consistent with those we  observed in the field:    Bureau observation reports revealed that listers most frequently had  problems with slow processing of addresses, large assignment areas, and  transmission.", "The help desk call log revealed that listers most frequently reported issues  with transmission, the device freezing, mapspotting, and large assignment  areas.", "The Bureau\u2019s debriefing reports illustrated the impact of the HHCs  problems on address canvassing. For example, one participant  commented that the listers struggled to find solutions to problems and  wasted time in replacing the devices.", "Collectively, the observation reports, help desk calls, debriefing reports,  and Motion and Time Study raised serious questions about the  performance of the HHCs during the address canvassing operation. The  Bureau\u2019s 2008 Dress Rehearsal Address Canvassing Assessment Report  cited several problems with HHCs. For example, the Bureau observed the  following problems:    substantial software delays for assignment areas with over 700 housing    substantial software delays when linking mapspots at multi-unit    unacceptable help desk response times and insufficient answers, which  \u201cseverely\u201d affected productivity in the field, and  inconsistencies with the operations control system that made management  of the operation less efficient and effective.", "The assessment reported 5,429 address records with completed field work  were overwritten during the course of the dress rehearsal address  canvassing operation, eliminating the information that had been entered in  the field. The Bureau reported that this occurred due to an administrative  error that assigned several HHCs the same identification number. Upon  discovering the HHC mistake, the FDCA contractor took steps during the  dress rehearsal address canvassing operation to ensure that all of the HHC  devices deployed for the operation had unique identification numbers. Left  uncorrected, this error could have more greatly affected the accuracy of  the Bureau\u2019s master address list during dress rehearsal.", "The HHCs are used in a mobile computing environment where they upload  and download data from the data processing centers using a commercial  mobile broadband network. The data processing centers housed  telecommunications equipment and the central databases, which were  used to communicate with the HHCs and manage the address canvassing  operation. The HHCs download data, such as address files, from the data  processing centers, and upload data, such as completed work and time  and expense forms, to the data processing centers. The communications  protocols used by the HHCs were similar to those used on cellular phones  to browse Web pages on the Internet or to access electronic mail. For  HHCs that were out of the coverage area of the commercial mobile  broadband network or otherwise unable to connect to the network, a dial- up capability was available to transfer data to the data processing centers.  FDCA contract officials attributed HHC transmission performance  problems to this mobile computing environment, specifically:  telecommunication and database problems that prevented the HHC from  communicating with the data center,    extraneous data being transmitted (such as column and row headings),    an unnecessary step in the data transmission process.", "When problems with the HHC were identified during address canvassing,  the contractor downloaded corrected software in five different instances  over the 7-week period of the dress rehearsal address canvassing  operation. After address canvassing, the Bureau established a review  board and worked with its contractor to create task teams to address  FDCA performance issues such as (1) transmission problems relating to  the mobile computing environment, (2) the amount of data transmitted for  large assignment areas, and (3) options for improving HHC performance.  One factor that may have contributed to these performance problems was  a compressed schedule that did not allow for thorough testing before the  dress rehearsal. Given the tighter time frames going forward, testing and  quickly remedying issues identified in these tests becomes even more  important."], "subsections": []}, {"section_title": "The Bureau Achieved Productivity Expectations for Rural Areas but Not Urban/suburban Areas", "paragraphs": ["Productivity results were mixed when Census listers used the HHC for  address canvassing activities. A comparison of planned versus reported  productivity reveals lister productivity exceeded the Bureau\u2019s target by  almost two housing units per hour in rural areas, but missed the target by  almost two housing units per hour in urban/suburban areas. Further, the  reported productivity for urban/suburban areas was more than 10 percent  lower than the target, and this difference will have cost implications for  the address canvassing operation. Table 1 shows planned and reported  productivity data for urban/suburban and rural areas.", "While productivity results were mixed, the lower than expected  productivity in urban/suburban areas represents a larger problem as  urban/suburban areas contain more housing units\u2014and therefore a larger  workload. According to the Bureau\u2019s dress rehearsal address canvassing  assessment report, HHC problems appear to have negatively affected  listers\u2019 productivity. The Bureau\u2019s assessment report concluded that  \u201cproductivity of listers decreased because of the software problems.\u201d  However, the extent of the impact is difficult to measure, as are other  factors that may have affected productivity.", "The effect of decreases in productivity can mean greater costs. The  Bureau, in earlier cost estimates, assumed a productivity rate of 25.6  housing units per hour, exceeding both the expected and reported rates  for the dress rehearsal. We previously reported that substituting the actual  address canvassing productivity for the previously assumed 25.6 units per  hour resulted in a $270 million increase in the existing life-cycle cost  estimate. The Bureau has made some adjustments to its cost estimates to  reflect its experience with the address canvassing dress rehearsal, but  could do more to update its cost assumptions. We recommended the  Bureau do so in our prior report."], "subsections": []}, {"section_title": "The Bureau Collected Some Data on HHC Performance Issues, but Did Not Develop Benchmarks", "paragraphs": ["The Bureau took some steps to collect data, but did not fully evaluate the  performance of the HHCs. For instance, the contractor provided the  Bureau with data such as average transmission times collected from  transmission logs on the HHC, as required in the contract. But the Bureau  has not used these data to analyze the full range of transmission times, nor  how this may have changed throughout the entire operation. Without this  information, the magnitude of the handheld computers\u2019 performance  issues throughout dress rehearsal was not clear. Also, the Bureau had few  benchmarks (the level of performance it is expected to attain) to help  evaluate the performance of HHCs throughout the operation. For example,  the Bureau has not developed an acceptable level of performance for total  number of failed transmissions or average connection speed. Additionally,  the contractor and the Bureau did not use the dashboard specified in the  contract for dress rehearsal activities. Since the dress rehearsal, the  Bureau has specified certain performance requirements that should be  reported on a daily, weekly, monthly, and on an exception basis.", "In assessing an \u201cin-house built\u201d model of the HHC, we recommended in  2005 that the Bureau establish specific quantifiable measures in such areas  as productivity that would allow it to determine whether the HHCs were  operating at a level sufficient to help the Bureau achieve cost savings and  productivity increases. Further, our work in the area of managing for  results has found that federal agencies can use performance information,  such as that described above, to make various types of management  decisions to improve programs and results. For example, performance  information can be used to identify problems in existing programs, identify  the causes of problems, develop corrective actions, plan, identify  priorities, and make resource allocation decisions. Managers can also use  performance information to identify more effective approaches to program  implementation.", "The Bureau had planned to collect certain information on operational  aspects of HHC use, but did not specify how it would measure HHC  performance. Specifically, sections of the FDCA contract require the HHCs  to have a transmission log with what was transmitted, the date, time, user,  destination, content/data type, and outcome status. In the weeks leading  up to the January 16, 2008, requirements delivery, Bureau officials drafted  a document titled \u201cFDCA Performance Reporting Requirements,\u201d which  included an array of indicators such as average HHC transmission  duration, total number of successful HHC transmissions, total number of  failed HHC transmissions, and average HHC connection speed. Such  measures may be helpful to the Bureau in evaluating its address  canvassing operations. While these measures provide certain useful  information, they only cover a few dimensions of performance. For  example, to better understand transmission time performance, it is  important to include analyses that provide information on the range of  transmission times.", "The original FDCA contract also requires that the contractor provide near  real-time reporting and monitoring of performance metrics on a \u201ccontrol  panel/dashboard\u201d application to visually report those metrics from any  Internet-enabled PC. Such real-time reporting would help the Bureau and  contractor identify problems during the operation, giving them the  opportunity to quickly make corrections. However, the \u201ccontrol  panel/dashboard\u201d application was not used during the dress rehearsal. The  Bureau explained that it needed to use the dress rehearsal to identify what  data or analysis would be most useful to include on the dashboard it  expects to use for address canvassing in 2009. In January and February  2008, the Bureau began to make progress in identifying the metrics that  will be used in the dashboard. According to Bureau officials, the  dashboard will include a subset of measures from the \u201cFDCA Performance  Reporting Requirements\u201d such as average HHC transmission time and total  number of successful and failed HHC transmissions, which would be  reported on a daily basis. Between April 28, 2008, and May 1, 2008, the  Bureau and its contractor outlined the proposed reporting requirements  for the dashboard. The Bureau indicated that the dashboard will be tested  during the systems testing phase, which is currently scheduled for  November and December 2008. They did not specify if the dashboard will  be used in the operational field test of address canvassing, which is the  last chance for the Bureau to exercise the software applications under  Census-like conditions.", "The dress rehearsal address canvassing study assessment plan outlines the  data the Bureau planned to use in evaluating the use of the HHC, but these  data do not allow the Bureau to completely evaluate the magnitude of  performance problems. The plan calls for using data such as the number of  HHCs shipped to local census offices, the number of defective HHCs, the  number of HHCs broken during the dress rehearsal address canvassing  operation, the number checked in at the end of the operation, whether  deployment affected the ability of staff to complete assignments,  software/hardware problems reported through the help desk, the amount  of time listers lost due to hardware or software malfunctions, and  problems with transmissions. The plan also called for the collection of  functional performance data on the HHCs, such as the ability to collect  mapspots.", "Despite reporting on the data outlined in the study plan, the Bureau\u2019s  evaluation does not appear to cover all relevant circumstances associated  with the use of the HHC. For example, the Bureau does not measure when  listers attempt transmissions but the mobile computing environment does  not recognize the attempt. Additionally, the Bureau\u2019s evaluation does not  provide conclusive information about the total amount of downtime listers  experienced when using the HHC. For example, in the Bureau\u2019s final 2008  Census Dress Rehearsal Address Canvassing Assessment Report, the  Bureau cites its Motion and Time Study as reporting observed lister time  lost due to hardware or software malfunctions as 2.5 percent in the  Fayetteville and 1.8 percent in the San Joaquin County dress rehearsal  locations. The report also notes that the basis for these figures does not  include either the downtime between the onset of an HHC error and the  last/successful resolution attempt, nor does it include the amount of time a  lister spent unable to work due to an HHC error. These times were  excluded because they were not within the scope of the Motion and Time  Study of address canvassing tasks. However, evaluating the full effect of  HHC problems should entail accounting for the amount of time listers  spend resolving HHC errors or are not engaged in address canvassing  tasks due to HHC errors."], "subsections": []}]}, {"section_title": "The Redesign of the Decennial Census Carries with It Significant Implications for 2010 Address Canvassing", "paragraphs": ["Because of the performance problems observed with HHCs during the  2008 Dress Rehearsal, and the Bureau\u2019s subsequent redesign decision to  use the HHCs for the actual address canvassing operation, HHC use will  have significant implications for the 2010 Address Canvassing operation.  In his April 9, 2008, congressional testimony, the Bureau\u2019s Director  outlined next steps that included developing an integrated schedule for  address canvassing and testing. On May 22, 2008, the Bureau issued this  integrated schedule, which identifies activities that need to be  accomplished for the decennial and milestones for completing tasks.  However, the milestones for preparing for address canvassing are very  tight and in one case overlap the onset of address canvassing. Specifically,  the schedule indicates that the testing and integrating of HHCs will begin  in December 2008 and be completed in late March 2009; however, the  deployment of the HHCs for address canvassing will actually start in  February 2009, before the completion of testing and integration. It is  uncertain whether the testing and integration milestones will permit  modification to technology or operations prior to the onset of operations.  Separately, the Bureau on June 6, 2008, produced a testing plan for the  address canvassing operation. This testing plan includes a limited  operational field test of address canvassing; however, the plan does not  specify that the dashboard described earlier will be used in this test. The  address canvassing testing plan is a high-level plan that describes a partial  redo of the dress rehearsal to validate certain functionality and represents  a reasonable approach. However, it does not specify the basis for  readiness of the FDCA solution for address canvassing and when and how  this determination will occur\u2014when the Bureau would say that the  contractor\u2019s solution meets its operational needs.", "Field staff reported problems with HHCs when working in large  assignment areas during address canvassing. According to Bureau  officials, the devices could not accommodate more than 720 addresses\u20143  percent of dress rehearsal assignment areas were larger than that. The  amount of data transmitted and used slowed down the HHCs significantly.  In a June 2008, congressional briefing, Bureau officials indicated once  other HHC technology issues are resolved the number of addresses the  HHCs can accommodate may increase or decrease from the current 720.  Identification of these problems caused the contractor to create a task  team to examine the issues, and this team recommended improving the  end-to-end performance of the mobile solution by controlling the size of  assignment area data delivered to the HHC for address canvassing. One  specific recommendation was limiting the size of assignment areas to 200  total addresses. However, the redesign effort took another approach and  decided that the Bureau will use laptops and software used in other  demographic surveys to collect information in large blocks (assignment  areas comprise one or more blocks). Specifically, the collection of  information in large blocks (those with over 700 housing units) will be  accomplished using existing systems and software known as the  Demographic Area Address Listing (DAAL) and the Automated Listing  and Mapping Instrument (ALMI). Prior to the start of the address  canvassing operation, blocks known to have more than 700 housing units  would be removed from the scope of the FDCA solution. These blocks will  be flagged in the data delivered to the contractor and will not be included  for the address canvassing operation. Because this plan creates dual-track  operations, Bureau officials stated that differences exist in the content of  the extracts and that they are currently working to identify the differences  and determine how to handle those differences. Additionally, they said  that plans for the testing of the large block solution are expected to occur  throughout various phases of the testing for address canvassing and will  include performance testing, interface testing, and field testing.", "The costs for a help desk that can support listers during address  canvassing were underestimated during planning and have increased  greatly. Originally, the costs for the help desk were estimated to be  approximately $36 million, but current estimates have the cost of the help  desk rising as high as $217 million. The increased costs are meant to  increase the efficiency and responsiveness of the help desk so that listers  do not experience the kind of delays in getting help that they did during  the address canvassing dress rehearsal. For example, the Bureau\u2019s final  assessment of dress rehearsal address canvassing indicated that  unacceptable help desk response times and insufficient answers severely  affected productivity in the field. Field staff told us that help desk  resources were unavailable on the weekends and that they had difficulty  getting help. The increased costs cited above are due in part to  improvements to the help desk, such as expanded availability and  increased staffing.", "Lower than expected productivity has cost implications. In fact, the  Bureau is beginning to recognize part of this expected cost increase.  Specifically, the Bureau expects to update assumptions for the number of  hours listers may work in a given week. The model assumes 27.5 hours per  week, but the Bureau now expects this to be 18. This will make it  necessary to hire more listers and, therefore, procure more HHCs. The  Bureau adjusted its assumptions based on its experience in the dress  rehearsal. Our related report recommends updating assumptions and cost  estimates."], "subsections": []}, {"section_title": "Conclusions", "paragraphs": ["The dress rehearsal represents a critical stage in preparing for the 2010  Census. This is the time when Congress and others should have the  information they need to know how well the design for 2010 is likely to  work, what risks remain, and how those risks will be mitigated. We have  highlighted some of the risks facing the Bureau in preparing for its first  major field operation of the 2010 Census\u2014address canvassing. Going  forward, it will be important for the Bureau to specify how it will ensure  that this operation will be successfully carried out. If the solutions do not  work in resolving HHC technology issues the Bureau will not achieve  productivity targets, and decennial costs will continue to rise. Without  specifying the basis and time frame for determination of readiness of the  FDCA address canvassing solution, the Bureau will not have the needed  assurance that the HHCs will meet its operational needs. Such testing is  especially critical for changes to operations that were not part of the  address canvassing dress rehearsal. For example, because data collection  in large blocks will be conducted in parallel with the address canvassing  operation, and the Bureau is currently working to identify the differences  in the content of the resulting extracts, it is important that this dual-track  be tested to ensure it will function as planned. Furthermore, without  benchmarks defining successful performance of the technology, the  Bureau and stakeholders will be less able to reliably assess how well the  technology worked during address canvassing. Although the Bureau field  tested the HHCs in its dress rehearsal last year, it did not then have in  place a dashboard for monitoring field operations. The Bureau\u2019s proposal  for a limited field operations test this fall provides the last opportunity to  use such a dashboard in census-like conditions. To be most effective, test  results, assessments, and new plans need to be completed in a timely  fashion, and they must be shared with those with oversight authority as  soon as they are completed."], "subsections": []}, {"section_title": "Recommendations for Executive Action", "paragraphs": ["To ensure that the Bureau addresses key challenges facing its  implementation of the address canvassing operation for the 2010 Census,  we recommend that the Secretary of Commerce direct the Bureau to take  the following four actions:    Specify the basis for determining the readiness of the FDCA solution for  address canvassing and when and how this determination will occur\u2014 when the Bureau would say that the contractor\u2019s solution meets its  operational needs.", "Specify how data collection in large blocks will be conducted in parallel  with the address canvassing operation, and how this dual-track will be  tested in order to ensure it will function as planned.", "Specify the benchmarks for measures used to evaluate the HHC  performance during address canvassing.", "Use the dashboard to monitor performance of the HHCs in the operational  field test of address canvassing."], "subsections": []}, {"section_title": "Agency Comments and Our Evaluation", "paragraphs": ["The Secretary of Commerce provided written comments on a draft of this  report on July 25, 2008. The comments are reprinted in appendix II.  Commerce had no substantive disagreements with our conclusions and  recommendations and cited actions it is taking to address challenges GAO  identified. Commerce offered revised language for one recommendation,  which we have accepted. Commerce also provided technical corrections,  which we incorporated.", "Specifically, we revised our recommendation that the Bureau \u201cSpecify the  basis for acceptance of the FDCA solution for address canvassing and  when that acceptance will occur\u2014when the Bureau would say it meets its  operational needs and accepts it from the contractor\u201d to \u201cSpecify the basis  for determining the readiness of the FDCA solution for address canvassing  and when and how this determination will occur\u2014when the Bureau would  say that the contractor\u2019s solution meets its operational needs.\u201d Also, after  further discussion with Bureau officials, we provided more specific  measures of address and map information successfully collected. We  revised our discussion of the 2004 and 2006 census tests to make clear that  the HHC prototype was only used for non-response follow-up in the 2004  test. Finally, we revised our language on their decision to contract the  development of HHC hardware and software to address the Bureau\u2019s  concerns about how we characterized the timing of its decision.", "As agreed with your offices, unless you publicly announce the contents of  this report earlier, we plan no further distribution until 30 days from the  report date. At that time, we will send copies of this report to other  interested congressional committees, the Secretary of Commerce, and the  Director of the U.S. Census Bureau. Copies will be made available to  others upon request. This report will also be available at no charge on  GAO\u2019s Web site at http://www.gao.gov.", "If you have any questions on matters discussed in this report, please  contact Mathew J. Scir\u00e8 at (202) 512-6806 or sciremj@gao.gov, or David A.  Powner at (202) 512-9286 or pownerd@gao.gov. Contact points for our  Offices of Congressional Relations and Public Affairs may be found on the  last page of this report. GAO staff who made major contributions to this  report are listed in appendix III."], "subsections": []}]}, {"section_title": "Appendix I: Scope and Methodology", "paragraphs": ["Our objectives for this report were to analyze U.S. Census Bureau  (Bureau) and contractor data showing how handheld computers (HHC)  operated and its implications on operations, and examine implications the  redesign may have on plans for address canvassing in the 2010 Census. To  determine how well the HHC worked in collecting and transmitting  address and mapping data, and what data the Bureau and contractor used  in assessing HHC performance during address canvassing, we examined  Bureau documents, observed HHCs in use, and interviewed Bureau and  contractor officials. For example, we reviewed Census Bureau memos that  outline the data on HHC performance the Bureau planned to collect. We  reviewed the Field Data Collection Automation (FDCA) contract, focusing  specifically on what performance specifications and requirements were  included in the contract. We observed HHC use during dress rehearsal  address canvassing, and interviewed Bureau officials and contractor  officials about HHC use and performance during the dress rehearsal of  address canvassing. Specifically, we observed five different listers over the  course of 2 days in the Fayetteville, North Carolina, dress rehearsal site  and six different listers over 3 days in the San Joaquin County, California,  dress rehearsal site. We also analyzed data on HHC use including data on  HHC functionality/usability, HHC log data, the Bureau\u2019s Motion and Time  Study, the Bureau\u2019s 2008 Dress Rehearsal assessments, observational and  debriefing reports, a log of help desk tickets, and lessons-learned  documents. Additionally, we interviewed knowledgeable Bureau and  contractor officials. We did not independently verify the accuracy and  completeness of the data either input into or produced by the operation of  the HHCs.", "To better understand how HHC performance affected worker productivity,  we attended the dress rehearsal address canvassing training for listers,  interviewed Bureau officials about HHC performance, and examined data  provided in the Bureau\u2019s Motion and Time Study and other sources related  to predicted and reported productivity. In addition, we identified and  analyzed the factors that contribute to HHC performance on aspects of  address canvassing productivity. We examined the Bureau\u2019s Motion and  Time Study results, conducted checks for internal consistency within the  reported results, and met with Bureau officials to obtain additional  information about the methodology used. The results reported in the study  are estimates based on a non-random sample of field staff observed over  the course of the address canvassing operation. Within the context of  developing estimates for the time it takes address listers to perform  address canvassing tasks and successfully resolve certain HHC problems,  we determined that these data were sufficiently reliable for the purposes  of our analysis. However, the study\u2019s methodology did not encompass a  full accounting of the time field staff spent on the job, nor did the report  explain how some results attributed to the Motion and Time Study were  derived.", "We also compared the Bureau\u2019s expected productivity rates to  productivity rates reported to us by the Bureau in response to our request  for actual productivity data from the 2008 Dress Rehearsal Addressing  Canvassing operation. After analyzing the Bureau\u2019s productivity data, we  requested information about how the productivity data figures were  calculated in order to assess their reliability. In reviewing documentation  on the methodology and data, we identified issues that raise concerns. The  Bureau acknowledged that data for all address field staff were not  included in its analysis. Even though the productivity figures reported to  us and presented in this report are generally in line with the range of  productivity figures shown in the Bureau\u2019s Motion and Time Study, the  missing data, along with the Bureau\u2019s lack of response to some of our  questions about calculations of productivity figures, limit the reliability of  these data. We determined that they are adequate for purposes of this  report in that they provide a rough estimate of field worker productivity,  but are not sufficiently reliable to be characterized as definitive  representation of the actual productivity experienced in the 2008 Dress  Rehearsal Address Canvassing operation.", "To ascertain the implications the redesign may have on plans for address  canvassing in the 2010 Census, we observed meetings with officials of the  Bureau, Commerce, Office of Management and Budget, and the contractor  who were working on the FDCA redesign at Bureau headquarters. We also  met with the Director of the Census Bureau and analyzed key Department  of Commerce, Bureau, and contractor documents including the 2010  Census Risk Reduction Task Force Report and a program update provided  by the contractor (as well as new and clarified requirements). The Bureau  is in the process of revising some of its plans for conducting address  canvassing and had not finalized those plans prior to the completion of  this audit.", "We conducted this performance audit from April 2007 to July 2008 in  accordance with generally accepted government auditing standards. Those  standards require that we plan and perform the audit to obtain sufficient,  appropriate evidence to provide a reasonable basis for our findings and  conclusions based on our audit objectives. We believe that the evidence  obtained provides a reasonable basis for our findings and conclusions  based on our audit objectives."], "subsections": []}, {"section_title": "Appendix II: Comments from the Department of Commerce", "paragraphs": [], "subsections": []}, {"section_title": "Appendix III: GAO Contacts and Staff Acknowledgments", "paragraphs": [], "subsections": [{"section_title": "GAO Contacts", "paragraphs": [], "subsections": []}, {"section_title": "Acknowledgments", "paragraphs": ["In addition to the contact names above, Assistant Director Signora May,  Stephen Ander, Thomas Beall, Jeffrey DeMarco, Richard Hung, Barbara  Lancaster, Andrea Levine, Amanda Miller, Niti Tandon, Lisa Pearson,  Cynthia Scott, Timothy Wexler, and Katherine Wulff made key  contributions to this report."], "subsections": []}]}], "fastfact": []}