{"id": "GAO-12-418", "url": "https://www.gao.gov/products/GAO-12-418", "title": "Medical Devices: FDA Has Met Most Performance Goals but Device Reviews Are Taking Longer", "published_date": "2012-02-29T00:00:00", "released_date": "2012-03-29T00:00:00", "highlight": [{"section_title": "Why GAO Did This Study", "paragraphs": ["The Food and Drug Administration (FDA) within the Department of Health and Human Services (HHS) is responsible for overseeing the safety and effectiveness of medical devices sold in the United States. New devices are generally subject to FDA review via the 510(k) process, which determines if a device is substantially equivalent to another legally marketed device, or the more stringent premarket approval (PMA) process, which requires evidence providing reasonable assurance that the device is safe and effective. The Medical Device User Fee and Modernization Act of 2002 (MDUFMA) authorized FDA to collect user fees from the medical device industry to support the process of reviewing device submissions. FDA also committed to performance goals that include time frames within which FDA is to take action on a proportion of medical device submissions. MDUFMA was reauthorized in 2007.", "Questions have been raised as to whether FDA is sufficiently meeting the performance goals and whether devices are reaching the market in a timely manner. In preparation for reauthorization, GAO was asked to (1) examine trends in FDA\u0092s 510(k) review performance from fiscal years (FY) 2003-2010, (2) examine trends in FDA\u0092s PMA review performance from FYs 2003-2010, and (3) describe stakeholder issues with FDA\u0092s review processes and steps FDA is taking that may address these issues. To do this work, GAO examined FDA medical device review data, reviewed FDA user fee data, interviewed FDA staff regarding the medical device review process and FDA data, and interviewed three industry groups and four consumer advocacy groups."]}, {"section_title": "What GAO Found", "paragraphs": ["Even though FDA met all medical device performance goals for 510(k)s, the elapsed time from submission to final decision has increased substantially in recent years. This time to final decision includes the days FDA spends reviewing a submission as well as the days FDA spends waiting for a device sponsor to submit additional information in response to a request by the agency. FDA review time excludes this waiting time, and FDA review time alone is used to determine whether the agency met its performance goals. Each fiscal year since FY 2005 (the first year that 510(k) performance goals were in place), FDA has reviewed over 90 percent of 510(k) submissions within 90 days, thus meeting the first of two 510(k) performance goals. FDA also met the second goal for all 3 fiscal years it was in place by reviewing at least 98 percent of 510(k) submissions within 150 days. Although FDA has not yet completed reviewing all of the FY 2011 submissions, the agency was exceeding both of these performance goals for those submissions on which it had taken action. Although FDA review time decreased slightly from FY 2003 through FY 2010, the time that elapsed before FDA\u0092s final decision increased substantially. Specifically, from FY 2005 through FY 2010, the average time to final decision for 510(k)s increased 61 percent, from 100 days to 161 days.", "FDA was inconsistent in meeting performance goals for PMA submissions. FDA designates PMAs as either original or expedited; those that FDA considers eligible for expedited review are devices intended to (a) treat or diagnose life-threatening or irreversibly debilitating conditions and (b) address an unmet medical need. While FDA met the performance goals for original PMA submissions for 4 out of 7 years the goals were in place, it met those goals for expedited PMA submissions only twice out of 7 years. FDA review time and time to final decision for both types of PMAs were highly variable but generally increased in recent years. For example, the average time to final decision for original PMAs increased from 462 days for FY 2003 to 627 days for FY 2008 (the most recent year for which complete data are available).", "The three industry groups and four consumer advocacy groups GAO interviewed noted a number of issues related to FDA\u0092s review of medical device submissions. The four issues most commonly raised by stakeholders included (1) insufficient communication between FDA and stakeholders throughout the review process, (2) a lack of predictability and consistency in reviews, (3) an increase in time to final decision, and (4) inadequate assurance of the safety and effectiveness of approved or cleared devices. FDA is taking steps\u0097including issuing new guidance documents, enhancing reviewer training, and developing an electronic system for reporting adverse events\u0097that may address many of these issues. It is important for the agency to monitor the impact of those steps in ensuring that safe and effective medical devices are reaching the market in a timely manner.", "In commenting on a draft of this report, HHS generally agreed with GAO\u0092s findings and noted that FDA has identified some of the same performance trends in its annual reports to Congress. HHS also called attention to the activities FDA has undertaken to improve the medical device review process."]}], "report": [{"section_title": "Letter", "paragraphs": ["The Food and Drug Administration (FDA) within the Department of Health  and Human Services (HHS) is responsible for overseeing the safety and  effectiveness of medical devices sold in the United States. Congress  passed the Medical Device User Fee and Modernization Act of 2002  (MDUFMA) to provide additional resources for FDA to support the  process of reviewing medical device applications. MDUFMA authorized  FDA to collect user fees from the medical device industry to supplement  its annual appropriation for salaries and expenses for fiscal years   (FY) 2003 through 2007. The medical device user fee program was  reauthorized in 2007 as part of the Food and Drug Administration  Amendments Act (FDAAA); the reauthorization was called the Medical  Device User Fee Amendments of 2007 (MDUFA) and authorizes FDA to  collect user fees for FYs 2008 through 2012. FDA\u2019s authority to collect  user fees for medical devices expires on October 1, 2012, and the  medical device user fee program will need to be reauthorized for FDA to  continue to collect user fees. Medical device user fee amounts have  become a larger proportion of FDA\u2019s funding for medical device review  processes, rising from 10.6 percent of costs in FY 2003\u2014the first year  FDA collected medical device user fees\u2014to 19.5 percent of costs in   FY 2010, the most recent year for which data are available. In FY 2010,  MDUFA user fees collected by FDA\u2014including application,  establishment, and product fees\u2014totaled nearly $67 million, including  over $29 million in application fees. Application fees are collected for a  variety of medical device submission types, including premarket  notifications (510(k)s) and premarket approvals (PMAs).", "Under each authorization of the medical device user fee program, FDA  committed to performance goals related to the review of medical device  submissions. The performance goals include specific time frames within  which FDA is to take action on submissions. These performance goals,  as well as user fee amounts, are negotiated between FDA and industry  stakeholders and submitted to congressional committees prior to each  reauthorization. Questions have been raised about whether FDA is  sufficiently meeting the user fee performance goals and whether medical  devices are reaching the market in a timely manner. A number of  congressional committees have recently held hearings during which the  medical device industry questioned FDA\u2019s timeliness, while other  stakeholders questioned FDA\u2019s ability to ensure safety and effectiveness.", "In preparation for the reauthorization of the medical device user fee  program, you requested that we examine FDA\u2019s medical device review  process. In this report, we (1) examine trends in FDA\u2019s 510(k) medical  device review performance for FYs 2003 through 2010, (2) examine  trends in FDA\u2019s PMA medical device review performance for FYs 2003  through 2010, and (3) describe the issues stakeholders have raised about  the medical device review processes and steps FDA is taking that may  address these issues. We provide additional details on FDA\u2019s medical  device review performance in appendix I. You also asked us to provide  information on the number of full-time equivalent (FTE) staff involved in  the medical device review process; this information is provided in  appendix II.", "To determine the trends in FDA\u2019s medical device review performance for  510(k)s and PMAs for FYs 2003 through 2010, we examined data  obtained from FDA on the review process for all 510(k)s and PMAs  submitted to FDA in those years. To provide context for FDA\u2019s  performance prior to enactment of the user fee acts, we also analyzed  review data for all 510(k)s and PMAs submitted for FYs 2000 through  2002. Additionally, we reviewed data on FY 2011 submissions in order to  provide preliminary performance results for that year.focused on the proportion of medical device submissions in each fiscal  year for which FDA met or did not meet the applicable performance  goal(s); the total time from the date of submission to the date a final  decision was made\u2014including both the time FDA spent reviewing a  submission and any time the sponsor took to respond to questions or  requests for additional information from FDA; the FDA review time   (i.e., the time counted toward user fee performance goals, which does not  include any time the sponsor took to respond to any questions from FDA);   Our analyses  and the average number of review cycles prior to approval.reviewed publicly available FDA user fee data for FY 2003 through 2010  and interviewed FDA staff regarding the medical device review process  and the data we received from FDA.", "To describe the issues stakeholders have raised about the device review  processes and what steps FDA is taking that may address these issues,  we reviewed congressional testimony and interviewed three industry  groups and four consumer advocacy groups. participated in at least half of the meetings held by FDA to discuss the  reauthorization of the user fee program. Furthermore, the industry groups  we interviewed represent a mixture of large and small medical device  manufacturers and cover a significant portion of the device market. We  performed content analyses of the interviews to determine the most  pressing issues based on how often each issue was raised.", "All of these groups have  We conducted this performance audit from October 2011 through  February 2012 in accordance with generally accepted government  auditing standards. Those standards require that we plan and perform the  audit to obtain sufficient, appropriate evidence to provide a reasonable  basis for our findings and conclusions based on our audit objectives. We  believe that the evidence obtained provides a reasonable basis for our  findings and conclusions based on our audit objectives."], "subsections": [{"section_title": "Background", "paragraphs": ["When we refer to consumer advocacy groups, we are referring to groups that advocate  on behalf of consumers and patients. its safety and effectiveness. Class I includes devices with the lowest risk  (e.g., tongue depressors, reading glasses, forceps), while class III  includes devices with the highest risk (e.g., breast implants, coronary  stents). Almost all class I devices and some class II devices   (e.g., mercury thermometers, certain adjustable hospital beds) are  exempt from premarket notification requirements. Most class III device  types are required to obtain FDA approval through the PMA process, the  most stringent of FDA\u2019s medical device review processes. The  remaining device types are required to obtain FDA clearance or approval  through either the 510(k) or PMA processes.", "If eligible, a 510(k) is filed when a manufacturer seeks a determination  that a new device is substantially equivalent to a legally marketed device  known as a predicate device. In order to be deemed substantially  equivalent (i.e., cleared by FDA for marketing), a new device must have  the same technological characteristics and intended use as the predicate  device, or have the same intended use and different technological  characteristics but still be demonstrated to be as safe and effective as the  predicate device without raising new questions of safety and  effectiveness. Most device submissions filed each year are 510(k)s. For  example, of the more than 13,600 device submissions received by FDA in  FYs 2008 through 2010, 88 percent were 510(k)s.", "The medical device performance goals were phased in during the period  covered by MDUFMA (the FYs 2003 through 2007 cohorts) and were  updated for MDUFA.  Under MDUFA, FDA\u2019s goal is to complete the  review process for 90 percent of the 510(k)s in a cohort within 90 days of  submission (known as the Tier 1 goal) and to complete the review process for 98 percent of the cohort within 150 days (the Tier 2 goal).(See table 1 for the 510(k) performance goals for the FYs 2003 through  2011 cohorts). FDA may take any of the following actions on a 510(k)  after completing its review:  issue an order declaring the device substantially equivalent; issue an order declaring the device not substantially equivalent; or advise the submitter that the 510(k) is not required (i.e., the product is  not regulated as a device or the device is exempt from premarket  notification requirements).", "Each of these actions ends the review process for a submission. A  sponsor\u2019s withdrawal of a submission also ends the review process.", "Alternatively, FDA may \u201cstop the clock\u201d on a 510(k) review by sending a  letter asking the sponsor to submit additional information (known as an AI  letter). This completes a review cycle but does not end the review  process. The clock will resume (and a new review cycle will begin) when  FDA receives a response from the sponsor. As a result, FDA may meet  its 510(k) performance goals even if the time to final decision (FDA review  time plus time spent waiting for the sponsor to respond to FDA\u2019s requests  for additional information) is longer than the time frame allotted for the  performance goal. For example, a sponsor might have submitted a 510(k)  on March 1, 2009, to start the review process. If FDA sent an AI letter on  April 1, 2009 (after 31 days on the clock), the sponsor provided a  response on June 1, 2009 (after an additional 61 days off the clock), and  FDA issued a final decision on June 11, 2009 (10 more days on the  clock), then the FDA review time counted toward the MDUFA  performance goals would be 41 days (FDA\u2019s on-the-clock time). FDA  would have met both the Tier 1 (90 day) and Tier 2 (150 day) time frames  for that device even though the total number of calendar days (on- and  off-the-clock) from beginning the review to a final decision was 102 days.  (See table 2 for a comparison of FDA review time and time to final  decision.) FDA tracks the time to final decision and reports on it in the  agency\u2019s annual reports to Congress on the medical device user fee  program.", "A PMA is filed when a device is not substantially equivalent to a predicate  device or has been classified as a class III PMA device (when the risks  associated with the device are considerable). The PMA review process is  the most stringent type of medical device review process required by  FDA, and user fees are much higher for PMAs than for 510(k)s. PMAs  are designated as either original or expedited. FDA considers a device  eligible for expedited review if it is intended to (a) treat or diagnose a life- threatening or irreversibly debilitating disease or condition and   (b) address an unmet medical need.submissions to determine which are appropriate for expedited review,  regardless of whether a company has identified its device as a potential  candidate for this program.", "FDA assesses all medical device  To meet the MDUFA goals, FDA must complete its review of 60 percent  of the original PMAs in a cohort within 180 days of submission (Tier 1)  and 90 percent within 295 days (Tier 2). For expedited PMAs, 50 percent  of a cohort must be completed within 180 days (Tier 1) and 90 percent  within 280 days (Tier 2). (See table 3 for the PMA performance goals for  the FYs 2003 through 2011 cohorts.) The various actions FDA may take  during its review of a PMA are the following: major deficiency letter; not approvable letter; and denial order.", "The major deficiency letter is the only one of these actions that does not  end the review process for purposes of determining whether FDA met the  MDUFA performance goal time frame for a given submission. As with the  AI letter in a 510(k) review, FDA can stop the clock during the PMA  review process by sending a major deficiency letter (ending a review  cycle) and resume it later upon receiving a response from the  manufacturer. In contrast, taking one of the other four actions  permanently stops the clock, meaning any further review that occurs is  excluded from the calculation of FDA review time. In addition, the  approval order and denial order are also considered final decisions and  end FDA\u2019s review of a PMA completely. A sponsor\u2019s withdrawal of a  submission also ends the review process.", "FDA\u2019s review of medical device submissions has been discussed in  recent congressional hearings, meetings between FDA and stakeholders  about the medical device user fee program reauthorization, and published  reports. In addition, in August 2010, FDA released reports which  described the results of two internal assessments conducted by FDA of  its medical device review programs. In January 2011, FDA released a  plan of action that included 25 steps FDA intends to take to address the  issues identified in these assessments."], "subsections": []}, {"section_title": "FDA Met All Performance Goals for 510(k)s but the Time to Final Decision Has Increased Substantially in Recent Years", "paragraphs": ["For FYs 2003 through 2010, FDA met all Tier 1 and Tier 2 performance  goals for 510(k)s. In addition, FDA review time for 510(k)s decreased  slightly during this period, but time to final decision increased  substantially. The average number of review cycles and FDA\u2019s requests  for additional information for 510(k) submissions also increased during  this period."], "subsections": [{"section_title": "FDA Met All Tier 1 and Tier 2 Performance Goals for 510(k)s from 2003 through 2010", "paragraphs": ["FDA met all Tier 1 performance goals for the completed 510(k) cohorts  that had Tier 1 goals in place. The percentage of 510(k)s reviewed  within 90 days (the current Tier 1 goal time frame) exceeded 90 percent  for the FYs 2005 through 2010 cohorts (see fig. 1.) Although the 510(k)  cohort for FY 2011 was still incomplete at the time we received FDA\u2019s  data, FDA was exceeding the Tier 1 goal for those submissions on which  it had taken action. FDA\u2019s performance varied for 510(k) cohorts prior to  the years that the Tier 1 goals were in place but was always below the  current 90 percent goal.", "FDA met the Tier 2 goals for all three of the completed cohorts that had  Tier 2 goals in place. Specifically, FDA met the goal of reviewing   98 percent of submissions within 150 days for the FYs 2008, 2009, and  2010 cohorts (see fig. 2.) Additionally, although the 510(k) cohort for   FY 2011 was still incomplete at the time we received FDA\u2019s data, FDA  was exceeding the Tier 2 goal for those submissions on which it had  taken action. FDA\u2019s performance for 510(k) cohorts prior to the years  that the Tier 2 goals were in place was generally below the current   98 percent goal.", "While the average FDA review time for 510(k) submissions decreased  slightly from the FY 2003 cohort to the FY 2010 cohort, the time to final  decision increased substantially. Specifically, the average number of days  FDA spent on the clock reviewing a 510(k) varied somewhat but overall  showed a small decrease from 75 days for the FY 2003 cohort to 71 days  for the FY 2010 cohort (see fig. 3). However, when we added off-the- clock time (where FDA waited for the sponsor to provide additional  information) to FDA\u2019s on-the-clock review time, the resulting time to final  decision decreased slightly from the FY 2003 cohort to the FY 2005  cohort before increasing 61 percent\u2014from 100 days to 161 days\u2014from  the FY 2005 cohort through the FY 2010 cohort. FDA officials told us that  the only alternative to requesting additional information is for FDA to  reject the submission. The officials stated that as a result of affording  sponsors this opportunity to respond, the time to final decision is longer  but the application has the opportunity to be approved.", "Additionally, although the 510(k) cohort for FY 2011 was still incomplete  at the time we received FDA\u2019s data, the average FDA review time and  time to final decision were lower in FY 2011 for those submissions on  which it had taken action."], "subsections": []}, {"section_title": "Number of Review Cycles and Requests for Additional Information Increased for 510(k) Submissions from 2003 to 2010", "paragraphs": ["The average number of review cycles per 510(k) increased substantially  (39 percent) from FYs 2003 through 2010, rising from 1.47 cycles for the   FY 2003 cohort to 2.04 cycles for the FY 2010 cohort (see fig. 4).", "In addition, the percentage of 510(k)s receiving a first-cycle decision of  substantially equivalent (i.e., cleared by FDA for marketing) decreased  from 54 percent for the FY 2003 cohort to 20 percent for the FY 2010  cohort, while the percentage receiving first-cycle AI requests exhibited a  corresponding increase. (See fig. 5.) The average number of 510(k)  submissions per year remained generally steady during this period.  Although the 510(k) cohort for FY 2011 was still incomplete at the time we  received FDA\u2019s data, of the first-cycle reviews that had been completed,  the percentage of submissions receiving a first-cycle decision of  substantially equivalent was slightly higher than for the FY 2010 cohort  (21.2 percent in FY 2011 compared with 20.0 percent in FY 2010). In  addition, the percentage receiving a first-cycle AI request was lower   (68.2 percent for FY 2011 compared with 77.0 for FY 2010).", "The percentage of 510(k)s that received a final decision of substantially  equivalent also decreased in recent years\u2014from a high of 87.9 percent  for the FY 2005 cohort down to 75.1 percent for the FY 2010 cohort. The  percentage of 510(k)s receiving a final decision of not substantially  equivalent increased for each cohort from FYs 2003 through 2010, rising  from just over 2.9 percent to 6.4 percent. (See fig. 6.)"], "subsections": []}]}, {"section_title": "FDA Was Inconsistent in Meeting Performance Goals for PMAs While FDA Review Time and Time to Final Decision Generally Increased", "paragraphs": ["For FYs 2003 through 2010, FDA met most of the goals for original PMAs  but fell short on most of the goals for expedited PMAs. In addition, FDA  review time and time to final decision for both types of PMAs generally  increased during this period. Finally, the average number of review cycles  increased for certain PMAs while the percentage of PMAs approved after  one review cycle generally decreased."], "subsections": [{"section_title": "FDA Met Most Goals for Original PMAs but Fell Short of Most Goals for Expedited PMAs from 2003-2010", "paragraphs": ["Since FY 2003, FDA met the original PMA performance goals for four of  the seven completed cohorts that had goals in place, but met the goals  for only two of the seven expedited PMA cohorts with goals.  Specifically, FDA met its Tier 1 performance goals for original PMAs for  all three of the completed original PMA cohorts that had such goals in  place, with the percentage increasing from 56.8 percent of the FY 2007  cohort to   80.0 percent of the FY 2009 cohort completed on time. (See fig. 7.)  While the FY 2010 and 2011 cohorts are still incomplete, FDA is  exceeding the goals for those submissions on which it has taken action.", "FDA\u2019s performance had declined steadily in the years immediately before  implementation of these goals\u2014from 67.1 percent of the FY 2000 cohort  to 34.5 percent of the FY 2006 cohort completed within 180 days.", "FDA\u2019s performance in meeting the Tier 2 performance goals for original  PMAs fell short of the goal for three of the four completed cohorts during  the years that these goals were in place. FDA met the MDUFMA Tier 2  performance goal (320 days) for the FY 2006 original PMA cohort but not  for the FY 2007 cohort, and did not meet the MDUFA Tier 2 performance  goal (295 days) for either of the completed cohorts (FYs 2008 and 2009)  to which the goal applied (see fig. 8). While the FYs 2010 and 2011  original PMA cohorts are still incomplete, FDA is exceeding the MDUFA   FDA\u2019s  Tier 2 goals for those submissions on which it has taken action.performance varied for original PMA cohorts prior to the years that the  Tier 2 goals were in place but was always below the current goal to have  90 percent reviewed within 295 days.", "For expedited PMAs, FDA met the Tier 1 and Tier 2 performance goals  for only two of the seven completed cohorts for which the goals were in  effect. FDA met the Tier 1 (180-day) goal for only one of the two  completed cohorts during the years the goal has been in place, meeting  the goal for the FY 2009 cohort but missing it for the FY 2008 cohort (see   fig. 9). FDA\u2019s performance varied for cohorts prior to the years that the  Tier 1 expedited PMA goals were in place but was below the current goal  of 50 percent in all but 1 year.", "FDA\u2019s performance in meeting the Tier 2 performance goals for expedited  PMAs fell short of the goal for four of the five completed cohorts during  the years that these goals were in place. FDA met the MDUFMA Tier 2  performance goal (300 days) for the FY 2005 cohort but not for the   FY 2006 or 2007 cohorts, and did not meet the MDUFA Tier 2  performance goal (280 days) for either of the completed cohorts (FY 2008  and 2009) to which the goal applied (see fig. 10). FDA\u2019s performance  varied for expedited PMA cohorts prior to the years that the Tier 2 goals  were in place but always fell below the current goal to have 90 percent  reviewed within 280 days.", "FDA review time for both original and expedited PMAs was highly  variable but generally increased across our analysis period, while time to  final decision also increased for original PMAs. Specifically, average FDA  review time for original PMAs increased from 211 days in the FY 2003  cohort (the first year that user fees were in effect) to 264 days in the   FY 2008 cohort, then fell in the FY 2009 cohort to 217 days (see fig. 11).  When we added off-the-clock time (during which FDA waited for the  sponsor to provide additional information or correct deficiencies in the  submission), average time to final decision for the FYs 2003 through 2008  cohorts fluctuated from year to year but trended upward from 462 days for  the FY 2003 cohort to 627 days for the FY 2008 cohort.", "The results for expedited PMAs fluctuated even more dramatically than  for original PMAs\u2014likely due to the small number of submissions (about   7 per year on average). Average FDA review time for expedited PMAs  generally increased over the period that user fees have been in effect,  from 241 days for the FY 2003 cohort to 356 days for the FY 2008 cohort,  then fell to 245 days for the FY 2009 cohort (see fig. 12). The average  time to final decision for expedited PMAs was highly variable but overall  declined somewhat during this period, from 704 days for the FY 2003  cohort to 545 days for the FY 2009 cohort.", "The average number of review cycles per original PMA increased   27.5 percent from 1.82 in the FY 2003 cohort (the first year that user fees  were in effect) to 2.32 cycles in the FY 2008 cohort. For expedited PMAs,  the average number of review cycles per submission was fairly steady at  approximately 2.5 cycles until the FY 2004 cohort, then peaked at 4.0 in  the FY 2006 cohort before decreasing back to 2.5 cycles in the FY 2009  cohort. We found nearly identical trends when we examined the subsets  of original and expedited PMAs that received a final FDA decision of  approval.", "In addition, the percentage of original PMAs receiving a decision of  approval at the end of the first review cycle fluctuated from FYs 2003  through 2009 but generally decreased\u2014from 16 percent in the FY 2003  cohort to 9.8 percent in the FY 2009 cohort. Similarly, the percentage  receiving a first-cycle approvable decision decreased from 12 percent in  the FY 2003 cohort to 2.4 percent in the FY 2009 cohort. The percentage  of expedited PMAs receiving first-cycle approval fluctuated from year to  year, from 0 percent in 5 of the years we examined to a maximum of   25 percent in FY 2008.", "The percentage of original PMAs that ultimately received approval from  FDA fluctuated from year to year but exhibited an overall decrease for the  completed cohorts from FYs 2003 through 2008. Specifically,   74.0 percent of original PMAs in the FY 2003 cohort were ultimately  approved, compared to 68.8 percent of the FY 2008 cohort. The  percentage of expedited PMAs that were ultimately approved varied  significantly from FYs 2003 through 2009, from a low of 0 percent in the  FY 2007 cohort to a high of 100 percent in the FY 2006 cohort."], "subsections": []}]}, {"section_title": "Stakeholders Noted Issues with the Medical Device Review Process; FDA Is Taking Steps That May Address Many of These Issues", "paragraphs": ["The industry groups and consumer advocacy groups we interviewed  noted a number of issues related to FDA\u2019s review of medical device  submissions. The most commonly mentioned issue raised by industry and  consumer advocacy stakeholder groups was insufficient communication  between FDA and stakeholders throughout the review process. Industry  stakeholders also noted a lack of predictability and consistency in reviews  and an increase in time to final decision. Consumer advocacy group  stakeholders noted issues related to inadequate assurance of the safety  and effectiveness of approved or cleared devices. FDA is taking steps  that may address many of these issues."], "subsections": [{"section_title": "Stakeholders Cite Insufficient Communication between FDA and Stakeholders throughout the Review Process", "paragraphs": ["Most of the three industry and four consumer advocacy group  stakeholders that we interviewed told us that there is insufficient  communication between FDA and stakeholders throughout the review  process. For example, four stakeholders noted that FDA does not clearly  communicate to stakeholders the regulatory standards that it uses to  evaluate submissions. In particular, industry stakeholders noted problems  with the regulatory guidance documents issued by FDA. These  stakeholders noted that these guidance documents are often unclear, out  of date, and not comprehensive. Stakeholders also noted that after  sponsors submit their applications to FDA, insufficient communication  from FDA prevents sponsors from learning about deficiencies in their  submissions early in FDA\u2019s review. According to one of these  stakeholders, if FDA communicated these deficiencies earlier in the  process, sponsors would be able to correct them and would be less likely  to receive a request for additional information. Two consumer advocacy  group stakeholders also noted that FDA does not sufficiently seek patient  input during reviews. One stakeholder noted that it is important for FDA to  incorporate patient perspectives into its reviews of medical devices  because patients might weigh the benefits and risks of a certain device  differently than FDA reviewers.", "FDA has taken or plans to take several steps that may address issues  with the frequency and quality of its communications with stakeholders,  including issuing new guidance documents, improving the guidance  development process, and enhancing interactions between FDA and  stakeholders during reviews. For example, in December 2011, FDA  released draft guidance about the regulatory framework, policies, and  practices underlying FDA\u2019s 510(k) review in order to enhance the  transparency of this program. In addition, FDA implemented a tracking  system and released a standard operating procedure (SOP) for  developing guidance documents for medical device reviews to provide  greater clarity, predictability, and efficiency in this process. FDA also  created a new staff position to oversee the guidance development  process. Additionally, according to an overview of recent FDA actions to  improve its device review programs, FDA is currently enhancing its  interactive review process for medical device reviews by establishing  performance goals for early and substantive interactions between FDA  and sponsors during reviews. This overview also notes that FDA is  currently working with a coalition of patient advocacy groups on  establishing mechanisms for obtaining reliable information on patient  perspectives during medical device reviews."], "subsections": []}, {"section_title": "Industry Stakeholders Report a Lack of Predictability and Consistency in Reviews", "paragraphs": ["The three industry stakeholders that we interviewed also told us that there  is a lack of predictability and consistency in FDA\u2019s reviews of device  submissions. For example, two stakeholders noted that review criteria  sometimes change after a sponsor submits an application. In particular,  one of these stakeholders noted that criteria sometimes change when the  FDA reviewer assigned to the submission changes during the review.  Additionally, stakeholders noted that there is sometimes inconsistent  application of criteria across review divisions or across individual  reviewers. Stakeholders noted that enhanced training for reviewers and  enhanced supervisory oversight could help resolve inconsistencies in  reviews and increase predictability for sponsors.", "In the two internal assessments of its device review programs that FDA  released in August 2010, the agency found that insufficient predictability  in its review programs was a significant problem. FDA has taken steps  that may address issues with the predictability and consistency of its  reviews of device submissions, including issuing new SOPs for reviews  and enhancing training for FDA staff. For example, in June 2011, FDA  issued an SOP to standardize the practice of quickly issuing written  notices to sponsors to inform them about changes in FDA\u2019s regulatory  expectations for medical device submissions. FDA also recently  developed an SOP to assure greater consistency in the review of device  submissions when review staff change during the review.April 2010, FDA began a reviewer certification program for new FDA   Additionally, in  reviewers designed to improve the consistency of reviews. According to  the overview of recent FDA actions to improve its device review  programs, FDA also plans to implement an experiential learning program  for new reviewers to give them a better understanding of how medical  devices are designed, manufactured, and used."], "subsections": []}, {"section_title": "Industry Stakeholders Note an Increase in Time to Final Decision", "paragraphs": ["The three industry stakeholders we interviewed told us that the time to  final decision for device submissions has increased in recent years. This  is consistent with our analysis, which showed that the average time to  final decision has increased for completed 510(k) and original PMA  cohorts since FY 2003. Additionally, stakeholders noted that FDA has  increased the number of requests for additional information, which our  analysis also shows. Stakeholders told us they believe the additional  information being requested is not always critical for the review of the  submission. Additional information requests increase the time to final  decision but not necessarily the FDA review time because FDA stops the  review clock when it requests additional information from sponsors. Two  of the stakeholders stated that reviewers may be requesting additional  information more often due to a culture of increased risk aversion at FDA  or because they want to stop the review clock in order to meet  performance goals.", "According to FDA, the most significant contributor to the increased  number of requests for additional information\u2014and therefore increased  time to final decision\u2014is the poor quality of submissions received from  sponsors. In July 2011, FDA released an analysis it conducted of review   According to FDA, in over 80 percent  times under the 510(k) program.of the reviews studied for this analysis, reviewers asked for additional  information from sponsors due to problems with the quality of the  submission. FDA officials told us that sending a request for additional  information is often the only option for reviewers besides issuing a  negative decision to the sponsor. FDA\u2019s analysis also found that   8 percent of its requests for additional information during the first review  cycle were inappropriate. Requests for additional information were  deemed inappropriate if FDA requested additional information or data for  a 510(k) that (1) were not justified, (2) were not permissible as a matter of  federal law or FDA policy, or (3) were unnecessary to make a substantial  equivalence determination. FDA has taken steps that may address issues  with the number of inappropriate requests for additional information. For  example, the overview of recent FDA actions indicates the agency is  developing an SOP for requests for additional information that clarifies  when these requests can be made for 510(k)s, the types of requests that  can be made, and the management level at which the decision must be  made."], "subsections": []}, {"section_title": "Consumer Advocacy Group Stakeholders Suggest That FDA Provides Inadequate Assurance of the Safety and Effectiveness of Approved or Cleared Devices", "paragraphs": ["Three of the four consumer advocacy group stakeholders with whom we  spoke stated that FDA is not adequately ensuring the safety and  effectiveness of the devices it approves or clears for marketing. One of  these stakeholders told us that FDA prioritizes review speed over safety  and effectiveness. Two stakeholders also noted that the standards FDA  uses to approve or clear devices are lower than the standards that FDA  uses to approve drugs, particularly for the 510(k) program. Two  stakeholders also expressed concern that devices reviewed under the  510(k) program are not always sufficiently similar to their predicates and  that devices whose predicates are recalled due to safety concerns do not  have to be reassessed to ensure that they are safe. Finally, three  stakeholders told us that FDA does not gather enough data on long-term  device safety and effectiveness through methods such as postmarket  analysis and device tracking.", "These issues are similar to those raised elsewhere, such as a public  meeting to discuss the reauthorization of the medical device user fee  program, a congressional hearing, and an Institute of Medicine (IOM)  report. For example, during a September 14, 2010, public meeting to  discuss the reauthorization, consumer advocacy groups\u2014including two of  those we interviewed for our report\u2014urged the inclusion of safety and  effectiveness improvements in the reauthorization, including raising  premarket review standards for devices and increasing postmarket  surveillance. Additionally, during an April 13, 2011, congressional  hearing, another consumer advocacy group expressed concerns about  FDA\u2019s 510(k) review process and recalls of high-risk devices that were  cleared through this process. Finally, in July 2011, IOM released a  report summarizing the results of an independent evaluation of the 510(k)  program. FDA had requested that IOM conduct this evaluation to  determine whether the 510(k) program optimally protects patients and  promotes innovation. IOM concluded that clearance of a 510(k) based on  substantial equivalence to a predicate device is not a determination that  the cleared device is safe or effective.", "FDA has taken or plans to take steps that may address issues with the  safety and effectiveness of approved and cleared devices, including  evaluating the 510(k) program and developing new data systems. For  example, FDA analyzed the safety of 510(k) devices cleared on the basis  of multiple predicates by investigating an apparent association between  these devices and increased reports of adverse events. FDA concluded  that no clear relationship exists. FDA also conducted a public meeting to  discuss the recommendations proposed in the IOM report in September  2011. FDA is also developing a device identification system that will  allow FDA to better track devices that are distributed to patients, as well  as an electronic reporting system that will assist with tracking and  analyzing adverse events in marketed devices."], "subsections": []}]}, {"section_title": "Concluding Observations", "paragraphs": ["While FDA has met most of the goals for the time frames within which the  agency was to review and take action on 510(k) and PMA device  submissions, the time that elapses before a final decision has been  increasing. This is particularly true for 510(k) submissions, which  comprise the bulk of FDA device reviews. Stakeholders we spoke with  point to a number of issues that the agency could consider in addressing  the cause of these time increases. FDA tracks and reports the time to  final decision in its annual reports to Congress on the medical device user  fee program, and its own reports reveal the same pattern we found. In its  July 2011 analysis of 510(k) submissions, FDA concluded that reviewers  asked for additional information from sponsors\u2014thus stopping the clock  on FDA\u2019s review time while the total time to reach a final decision  continued to elapse\u2014mainly due to problems with the quality of the  submission. FDA is taking steps that may address the increasing time to  final decision. It is important for the agency to monitor the impact of those  steps in ensuring that safe and effective medical devices are reaching the  market in a timely manner."], "subsections": []}, {"section_title": "Agency Comments", "paragraphs": ["HHS reviewed a draft of this report and provided written comments, which  are reprinted in appendix III. HHS generally agreed with our findings and  noted that FDA has identified some of the same performance trends in its  annual reports to Congress. HHS noted that because the total time to  final decision includes the time industry incurs in responding to FDA\u2019s  concerns, FDA and industry bear shared responsibility for the increase in  this time and will need to work together to achieve improvement. HHS  also noted that in January 2011, FDA announced 25 specific actions that  the agency would take to improve the predictability, consistency, and  transparency of its premarket medical device review programs. Since  then, HHS stated, FDA has taken or is taking actions designed to create a  culture change toward greater transparency, interaction, collaboration,  and the appropriate balancing of benefits and risk; ensure predictable and  consistent recommendations, decision making, and application of the  least burdensome principle; and implement efficient processes and use of  resources. HHS also provided technical comments, which we  incorporated as appropriate.", "As agreed with your office, unless you publicly announce the contents of  this report earlier, we plan no further distribution until 30 days from the  report date. At that time, we will send copies of this report to the  Secretary of Health and Human Services, the Commissioner of FDA, and  other interested parties. In addition, the report will be available at no  charge on the GAO website at http://www.gao.gov.", "If you or your staff have any questions about this report, please contact  me at (202) 512-7114 or crossem@gao.gov. Contact points for our  Offices of Congressional Relations and Public Affairs may be found on  the last page of this report. GAO staff who made key contributions to this  report are listed in appendix IV."], "subsections": []}]}, {"section_title": "Appendix I: FDA Medical Device Review Performance for Fiscal Years (FY) 2000\u20132011", "paragraphs": [], "subsections": [{"section_title": "of the Medical Device", "paragraphs": ["2002 (MDUFMA) (MDUFA)", "Cycles that were currently in progress at the time we received FDA\u2019s data were included in this  analysis. The average number of review cycles for the FY 2011 cohort may increase as those reviews  are completed but will not decrease.  \u2014 We treated PMA submissions as meeting the time frame for a given performance goal if they were  reviewed within the goal time plus any extension to the goal time that may have been made. The only  reason the goal time can be extended is if the sponsor submits a major amendment to the submission  on its own initiative (i.e., unsolicited by FDA).  The FYs 2010 and 2011 original PMA cohorts were considered still incomplete. Specifically, for   18.5 percent of the FY 2010 original PMA cohort and 48.8 percent of the FY 2011 cohort, FDA had  not yet made a decision that would permanently stop the review clock for purposes of determining  whether FDA met its performance goals (i.e., an approval, approvable, not approvable, withdrawal, or  denial) at the time we received FDA\u2019s data; this includes reviews by CBER through September 30,  2011, and reviews by CDRH through December 1, 2011. As a result, it was too soon to tell what the  final results for these cohorts would be. It is possible that some of the reviews taking the most time  were among those not completed when we received FDA\u2019s data. The percentage of original PMAs  reviewed within 180 days for the FY 2010 and FY 2011 cohorts may increase or decrease as those  reviews are completed; the number reviewed within 180 days and the number and percentage  reviewed within 320 days and within 295 days may decrease as those reviews are completed.  Only original PMAs that had received a decision permanently stopping the review clock were used to  determine the number and percentage of original PMAs reviewed within 180 days, within 320 days,  and within 295 days.  Cycles that were currently in progress at the time we received FDA\u2019s data were included in this  analysis. The average number of review cycles for the incomplete cohorts may increase as those  reviews are completed but will not decrease.  This analysis includes only those original PMAs for which FDA or the sponsor had made a final  decision; this includes reviews by CBER through September 30, 2011, and reviews by CDRH through  December 1, 2011. For this analysis, the FYs 2009 through 2011 original PMA cohorts were  considered still incomplete. Specifically, 22 percent of the FY 2009 original PMA cohort, 46.3 percent  of the FY 2010 cohort, and 65.1 percent of the FY 2011 cohort had not yet received a final decision.  As a result, it was too soon to tell what the final results for these cohorts would be. It is possible that  some of the reviews taking the most time were among those not completed when we received FDA\u2019s  data. The percentages of final decisions that were approval, denial, or withdrawal and the average  time to final decision for original PMAs not meeting the 295-day time frame for the FYs 2009 through  2011 cohorts may increase or decrease as those reviews are completed. The average number of  review cycles for the FYs 2009 through 2011 cohorts may increase as those reviews are completed  but will not decrease.", "For the FYs 2010 through 2011 cohorts, there were no original PMAs that had received a final  decision that did not meet the 295-day time frame. \u2014 We treated PMA submissions as meeting the time frame for a given performance goal if they were  reviewed within the goal time plus any extension to the goal time that may have been made. The only  reason the goal time can be extended is if the sponsor submits a major amendment to the submission  on its own initiative (i.e., unsolicited by FDA).  The FYs 2010 and 2011 expedited PMA cohorts were considered still incomplete. Specifically,   33 percent of the FY 2010 expedited PMA cohort and 71.4 percent of the FY 2011 cohort had not yet  received a final decision; this includes reviews by CBER through September 30, 2011, and reviews  by CDRH through December 1, 2011. Additionally, for 16.7 percent of the FY 2010 expedited PMA  cohort and 71.4 percent of the FY 2011 cohort, FDA had not yet made a decision that would  permanently stop the review clock for purposes of determining whether FDA met its performance  goals (i.e., an approval, approvable, not approvable, withdrawal, or denial) at the time we received  FDA\u2019s data. As a result, it was too soon to tell what the final results for these cohorts would be. It is  possible that some of the reviews taking the most time were among those not completed when we  received FDA\u2019s data. The percentage of expedited PMAs reviewed within 180 days for the FY 2010  and FY 2011 cohorts may increase or decrease as those reviews are completed; the number  reviewed within 180 days and the number and percentage reviewed within 300 days and within   280 days may decrease as those reviews are completed. The percentages of final decisions that  were approval, denial, or withdrawal and the average time to final decision for the FYs 2010 through  2011 cohorts may increase or decrease as those reviews are completed. The average number of  review cycles for the FYs 2010 through 2011 cohorts may increase as those reviews are completed  but will not decrease.  Fiscal years for which there was no corresponding expedited PMA performance goal are denoted  with a dash (\u2014).  \u201cn/a\u201d denotes not applicable. In these years, there was no corresponding expedited PMA  performance goal and therefore no determination of whether the goal was met.", "For the FYs 2010 through 2011 cohorts, there were no expedited PMAs that had received a final  decision that did not meet the 280-day time frame."], "subsections": []}]}, {"section_title": "Appendix II: Number of Full-time Equivalent (FTE) FDA Staff Supporting Medical Device User Fee Activities, FYs 2003 through 2010", "paragraphs": ["FDA centers and offices  Center for Devices and Radiological Health (CDRH)", "Office of Management Operations (OSM/OMO)", "Office of Information Technology (OIT)", "Office of Science and Engineering Laboratories (OST/OSEL)", "Office of Communication Education and Radiation Programs  (OHIP/OCER)", "Office of Surveillance and Biometrics (OSB)", "Office of In Vitro Diagnostics (OIVD)", "Committee Conference Management (CCM)", "Center for Biologics Evaluation and Research (CBER)", "Center Director\u2019s Office, Office of Management (OM), Office  of Information Management (OIM), and Office of  Communication, Outreach, and Development (OCOD)", "Office of Cellular, Tissue & Gene Therapies  Office of Vaccines Research & Review  Office of Therapeutics Research & Review  Office of Biostatistics & Epidemiology  Office of Compliance & Biologics Quality  Office of Regulatory Affairs (ORA)", "Office of the Commissioner (OC)", "Shared Service (SS)", "OCD includes Medical Device Fellowship Program employees even though the Fellows were  assigned to work throughout CDRH.  OIT was included in the OMO FTE total prior to FY 2008.  OIVD did not exist prior to FY 2004. Also, the Radiology Devices Branch was moved from ODE to  OIVD between FY 2009 and FY 2010.  CCM was included in the OMO FTE total prior to FY 2008.", "Shared Service FTE were not separated from the center FTE until FY 2004."], "subsections": []}, {"section_title": "Appendix III: Comments from the Department of Health and Human Services", "paragraphs": [], "subsections": []}, {"section_title": "Appendix IV: GAO Contact and Staff Acknowledgments", "paragraphs": [], "subsections": [{"section_title": "GAO Contact", "paragraphs": [], "subsections": []}, {"section_title": "Staff Acknowledgments", "paragraphs": ["In addition to the contact named above, Robert Copeland, Assistant  Director; Carolyn Fitzgerald; Cathleen Hamann; Karen Howard; Hannah  Marston Minter; Lisa Motley; Aubrey Naffis; Michael Rose; and Rachel  Schulman made key contributions to this report."], "subsections": []}]}], "fastfact": []}