{"id": "GAO-13-796T", "url": "https://www.gao.gov/products/GAO-13-796T", "title": "Information Technology: OMB and Agencies Need to More Effectively Implement Major Initiatives to Save Billions of Dollars", "published_date": "2013-07-25T00:00:00", "released_date": "2013-07-25T00:00:00", "highlight": [{"section_title": "Why GAO Did This Study", "paragraphs": ["The federal government reportedly plans to spend at least $82 billion on IT in fiscal year 2014. Given the scale of such planned outlays and the criticality of many of these systems to the health, economy, and security of the nation, it is important that OMB and federal agencies provide appropriate oversight and adequate transparency into these programs. Nevertheless, IT projects too frequently incur cost overruns and schedule slippages, and result in duplicate systems while contributing little to mission-related outcomes. Additionally, projects sometimes fail or operate inefficiently, at the cost of billions of dollars.", "GAO was asked to testify on the results and recommendations from its selected reports that focused on key aspects of the federal government's management of IT investments. To prepare this statement, GAO drew on previously published work, as well as ongoing follow-up on prior recommendations."]}, {"section_title": "What GAO Found", "paragraphs": ["GAO has issued a number of key reports on the federal government's efforts to efficiently acquire and manage information technology (IT). While the Office of Management and Budget (OMB) and federal agencies have taken steps to address underperforming IT projects and more effectively manage IT through a number of major initiatives, additional actions are needed. For example, OMB has taken significant steps to enhance the oversight accountability of federal investments by creating the IT Dashboard, an OMB public website which provides detailed information on federal agencies' major investments. However, GAO previously found there were issues with the accuracy and reliability of cost and schedule data in the Dashboard and recommended steps that OMB and agencies should take to improve these data--this is important since the Dashboard currently reports 154 investments totaling almost $10.4 billion being at risk. OMB agreed with the recommendations.", "GAO recently reported that OMB and selected agencies have held multiple reviews--known as TechStats--of selected investments that are failing or are not producing results. Positive outcomes have been tracked and reported from these reviews, with most producing improved governance, as well as projects with accelerated delivery, reduced scope, and termination. However, for the selected agencies, GAO found that the number of at-risk TechStats held to date was only about 33 percent of the current number of medium- and high-risk investments. GAO was also unable to validate OMB's reported results of almost $4 billion in life-cycle cost savings. GAO therefore recommended that OMB validate the resulting cost savings and require agencies to conduct TechStats for each investment rated with a moderately high- or high-risk rating on the IT Dashboard. OMB generally agreed with the recommendations.", "GAO has also issued several reports on the federal government's progress towards consolidating its growing number of data centers. Most recently, in April 2013, GAO reported that agencies closed 420 data centers by the end of December 2012; however, OMB had not tracked and reported on other key performance measures, such as progress against the initiative's cost savings goal of $3 billion by the end of 2015. In addition, GAO identified weaknesses that existed in the oversight of the data center consolidation initiative, including not ensuring the completeness of agencies' data center inventories and consolidation plans. GAO recommended that OMB track and report on key performance measures and improve the execution of important oversight responsibilities. OMB agreed with these recommendations.", "In March 2012, OMB launched PortfolioStat, which requires agencies to conduct annual reviews of its IT investments and make decisions on eliminating duplication, among other things. OMB believes this effort has the potential to save $2.5 billion over the next 3 years. OMB has since made significant changes to PortfolioStat in March 2013, including integrating it with its data center consolidation initiative and establishing new reporting requirements. However, GAO recently reported that OMB had not yet established revised data center metrics and goals for the combined initiative. GAO has ongoing work looking at PortfolioStat, including determining whether agencies are completing key actions."]}, {"section_title": "What GAO Recommends", "paragraphs": ["GAO has issued numerous recommendations to OMB and agencies on key aspects of IT management, including OMB's public website, known as the IT Dashboard, which provides detailed information on federal agencies' major investments; reviews of underperforming projects, known as TechStats; and efforts to consolidate federal data centers."]}], "report": [{"section_title": "Letter", "paragraphs": ["I am pleased to be here today to discuss the highlights and  recommendations of our selected reports that focused on key aspects of  the federal government\u2019s acquisition and management of information  technology (IT) investments. As reported to the Office of Management  and Budget (OMB), federal agencies plan to spend at least $82 billion on  IT in fiscal year 2014. Given the scale of such planned outlays and the  criticality of many of these systems to the health, economy, and security  of the nation, it is important that OMB and federal agencies provide  appropriate oversight and transparency into these programs and avoid  duplicative investments, whenever possible, to ensure the most efficient  use of resources.", "As we have previously reported, federal IT projects too frequently incur  cost overruns and schedule slippages while contributing little to mission- related outcomes. During the past several years, we have issued  multiple reports and testimonies on federal initiatives to acquire and  improve the management of IT investments. In those reports, we made  numerous recommendations to federal agencies and OMB to further  enhance the management and oversight of IT programs.", "As part of its response to our prior work, OMB deployed a public website  in 2009, known as the IT Dashboard, which provides detailed information  on federal agencies\u2019 major IT investments, including assessments of  actual performance against cost and schedule targets (referred to as  ratings) for approximately 700 major federal IT investments. In addition,  OMB has initiated other significant efforts following the creation of the  Dashboard. For example, OMB began leading reviews\u2014known as  TechStat Accountability Sessions (TechStats)\u2014of selected IT  investments to increase accountability and improve performance;  launched an initiative to reduce the number of federal data centers (the  Federal Data Center Consolidation Initiative (FDCCI)); and initiated  PortfolioStat, which requires agencies to conduct annual reviews of their  IT investments and make decisions on eliminating duplication.", "You asked us to testify on the results and recommendations from our  selected reports that focused on key aspects of the federal government\u2019s  management of IT investments. Accordingly, my testimony specifically  discusses our past work on OMB\u2019s IT Dashboard, TechStat reviews, IT  acquisition best practices, FDCCI, and PortfolioStat, as well as failed and  challenged IT projects. My testimony also discusses ongoing follow-up  work on our prior recommendations from these reports. All work on which  this testimony is based was performed in accordance with generally  accepted government auditing standards. Those standards require that  we plan and perform the audit to obtain sufficient, appropriate evidence to  provide a reasonable basis for our findings and conclusions based on our  audit objectives. We believe that the evidence obtained provides a  reasonable basis for our findings and conclusions based on our audit  objectives."], "subsections": [{"section_title": "Background", "paragraphs": ["Information technology should enable government to better serve the  American people. However, according to OMB, despite spending more  than $600 billion on IT over the past decade, the federal government has  achieved little of the productivity improvements that private industry has  realized from IT.Too often, federal IT projects run over budget, behind  schedule, or fail to deliver promised functionality. In combating this  problem, proper oversight is critical.", "Both OMB and federal agencies have key roles and responsibilities for  overseeing IT investment management. OMB is responsible for working  with agencies to ensure investments are appropriately planned and  justified. Additionally, each year, OMB and federal agencies work  together to determine how much the government plans to spend on IT  projects and how these funds are to be allocated."], "subsections": [{"section_title": "Agencies Have Spent Billions on Failed and Poorly Performing Investments", "paragraphs": ["To assist agencies in managing their IT investments, Congress enacted  the Clinger-Cohen Act of 1996, which requires OMB to establish  processes to analyze, track, and evaluate the risks and results of major  capital investments in information systems made by federal agencies and  report to Congress on the net program performance benefits achieved as  a result of these investments. Further, the act places responsibility for  managing investments with the heads of agencies and establishes chief  information officers (CIO) to advise and assist agency heads in carrying  out this responsibility.", "Many of these investments are critical to our nation. For example, they  include systems to secure our nation, control aircraft, and process tax  returns. However, the federal government has spent billions of dollars on  failed and poorly performing IT investments, as the following examples  illustrate:  In December 2012, the Department of Defense (DOD) canceled the  Air Force\u2019s Expeditionary Combat Support System after having spent  more than a billion dollars and missing multiple milestones, including  failure to achieve deployment within 5 years of obligating funds. The  system was to provide the Air Force with a single, integrated logistics  system that was to control and account for about $36 billion of  inventory. We issued several reports on this system and found that,  among other things, the program was not fully following best practices  for developing reliable schedules and cost estimates. Among other  things, we had recommended that DOD ensure that any future system  deficiencies identified through independent assessments are resolved  or mitigated prior to further deployment of the system.", "In January 2011, the Department of Homeland Security ended the  Secure Border Initiative Network (SBInet) program after obligating  more than $1 billion to the program because it did not meet cost- effectiveness and viability standards. Since 2007, we had identified a  range of issues and made several recommendations to improve this  program. For example, in May 2010 we reported that the final  acceptance of the first two deployments had slipped from November  2009 to September 2010 and from March 2010 to November 2010,  and that the cost-effectiveness of the system had not been justified.  As a result, we recommended that the department (1) limit near-term  investment in the first incremental block of the program, (2)  economically justify any longer-term investment in it, and (3) improve  key program management disciplines. This work contributed to the  department\u2019s decision to cancel the program.", "In February 2010, a task force led by the President\u2019s Office of Science  and Technology Policy decided to disband the National Polar-orbiting  Operational Environmental Satellite System (NPOESS), a weather  satellite program managed by three different agencies, after having  spent 16 years and almost $5 billion on the program. We issued a  series of reports on the NPOESS program that highlighted the  technical challenges, cost growth, and tri-agency management  challenges facing the program. For example, in June 2009 we  reported that the program\u2019s approved cost and schedule baselines  were not achievable, and that costs could grow by approximately $1  billion over the then-current $13.95 billion estimate. We further noted  that schedules for the launch of a demonstration satellite and the first  two operational satellites were expected to be delayed, increasing the  risk of a gap in satellite continuity. However, after the program\u2019s  cancellation, the agencies were directed to undertake separate  acquisitions.", "Appendix I provides further details on federal IT projects that have failed  or faced significant challenges.", "In addition to these projects, the IT Dashboard identifies other at-risk  investments. Specifically, as of July 2013, according to the IT Dashboard,  154 of the federal government\u2019s approximately 700 major IT  investments\u2014totaling about $10.4 billion\u2014were in need of management  attention (rated to indicate the need for attention or to indicate significant  concerns). (See fig. 1.)", "In addition to poorly performing investments, federal IT spending is  hampered by inefficient operations and duplication, as the following  examples illustrate:", "Federal data centers. In March 2011, we reported that the increasing  demand for IT had led to a dramatic rise in the number of federal data  centers, with many housing similar types of equipment and providing  similar processing and storage capabilities.  As federal agencies  have modernized their operations, put more of their services online,  and increased their information security profiles, they have demanded  more computing power and data storage resources. According to  OMB, the number of federal data centers grew from 432 in 1998 to  more than 2,000 in 2010. The growth in the number of federal data  centers, many offering similar services and resources, has resulted in  overlap and duplication among the centers. In addition, according to  OMB, in August 2009 the average utilization rate for servers ranged  from 5 percent to 15 percent. In contrast, OMB\u2019s 2012 Data Center  Consolidation Plan guidance states that the target for server utilization  is 60 to 70 percent.", "Duplicative IT investments. In September 2011, we reported that  limitations in OMB\u2019s guidance hindered efforts to identify IT  duplication. Specifically, although OMB\u2019s guidance to federal  agencies on how to categorize IT investments allowed for analysis of  investments with similar functions, it did not go far enough to allow  identification of potentially duplicative investments. Specifically, since  the fiscal year 2004 budget cycle, OMB had required agencies to  categorize their IT investments according to primary function and  subfunction. In their fiscal year 2011 submissions, agencies reported  the greatest number of IT investments in Information and Technology  Management (1,536 investments), followed by Supply Chain  Management (777 investments), and Human Resource Management  (622 investments). Similarly, planned expenditures on investments  were greatest in Information and Technology Management, at about  $35.5 billion. Figure 2 depicts, by primary function, the total number of  investments within the 26 federal agencies that report to the IT  Dashboard, as of July 2011.", "However, we noted that categorizing IT investments according to  primary function and subfunction limited OMB\u2019s ability to identify  potentially duplicative investments both within and across agencies  because similar investments may be organized under different  functions. Accordingly, we recommended that OMB revise guidance  to federal agencies on categorizing IT investments to ensure that the  categorizations are clear and that it allows agencies to choose  secondary categories, where applicable. OMB generally agreed with  this recommendation and has since taken action to implement it.  Specifically, OMB updated its policy to enable agencies to select one  primary category and up to four secondary categories for each IT  investment.", "We also reported that results of OMB initiatives to identify potentially  duplicative investments were mixed and that several federal agencies  did not routinely assess their entire IT portfolios to identify and remove  or consolidate duplicative systems. Specifically, we said that most of  OMB\u2019s recent initiatives had not yet demonstrated results, and several  agencies did not routinely assess legacy systems to determine if they  are duplicative. As a result, we recommended that OMB require  federal agencies to report the steps they take to ensure that their IT  investments are not duplicative as part of their annual budget and IT  investment submissions. OMB generally agreed with this  recommendation and has since taken action to implement it.  Specifically, in March 2012, OMB issued a memorandum to federal  agencies regarding implementing PortfolioStat reviews. As previously  mentioned, these reviews are intended to assist in ending the  investment in duplicative IT investments. In addition, as part of this  effort, OMB is requiring agencies to document their cost savings and  cost avoidance due to consolidation beginning in their fiscal year 2014  budget submissions."], "subsections": []}, {"section_title": "OMB Has Launched Major Initiatives for Overseeing IT Investments", "paragraphs": ["OMB has implemented a series of initiatives to improve the oversight of  underperforming investments, more effectively manage IT, and address  duplicative investments. These efforts include the following:  IT Dashboard. Given the importance of transparency, oversight, and  management of the government\u2019s IT investments, in June 2009 OMB  established a public website, referred to as the IT Dashboard, that  provides detailed information on approximately 700 major IT  investments at 27 federal agencies, including ratings of their  performance against cost and schedule targets. The public  dissemination of this information is intended to allow OMB; other  oversight bodies, including Congress; and the general public to hold  agencies accountable for results and performance.", "TechStat reviews. In January 2010, the Federal CIO began leading  TechStats sessions\u2014face-to-face meetings to terminate or  turnaround IT investments that are failing or are not producing results.  These meetings involve OMB and agency leadership and are  intended to increase accountability and transparency and improve  performance. Subsequently, OMB empowered agency CIOs to hold  their own TechStat sessions within their respective agencies.  According to the former Federal CIO, the efforts of OMB and federal  agencies to improve management and oversight of IT investments  have resulted in almost $4 billion in savings.", "FDCCI. Concerned about the growing number of federal data centers,  in February 2010 the Federal CIO established FDCCI. This initiative\u2019s  four high-level goals are to promote the use of \u201cgreen IT\u201d by  reducing the overall energy and real estate footprint of government  data centers; reduce the cost of data center hardware, software, and  operations; increase the overall IT security posture of the government;  and shift IT investments to more efficient computing platforms and  technologies. OMB believes that this initiative has the potential to  provide about $3 billion in savings by the end of 2015.", "PortfolioStat. In order to eliminate duplication, move to shared  services, and improve portfolio management processes, in March  2012 OMB launched the PortfolioStat initiative. Specifically,  PortfolioStat requires agencies to conduct an annual agency-wide IT  portfolio review to, among other things, reduce commodity IT  spending and demonstrate how their IT investments align with the  agency\u2019s mission and business functions. PortfolioStat is designed  to assist agencies in assessing the current maturity of their IT  investment management process, making decisions on eliminating  duplicative investments, and moving to shared solutions in order to  maximize the return on IT investments across the portfolio. OMB  believes that the PortfolioStat effort has the potential to save the  government $2.5 billion over the next 3 years by, for example,  consolidating duplicative systems."], "subsections": []}]}, {"section_title": "OMB and Agencies Have Taken Steps to Improve the Acquisition and Management of IT Investments, but Additional Actions Are Needed", "paragraphs": ["Over the past several years, we have highlighted OMB and agency efforts  to improve the transparency into and oversight of underperforming federal  IT investments, more effectively manage IT, and address duplicative  investments. Notably, we issued a series of reports on: the IT Dashboard;  OMB and agency efforts to address troubled projects through TechStat  reviews; critical factors underlying successful acquisitions; and OMB and  agency efforts to improve the management of IT through federal data  center consolidation efforts, as well as address duplication through  PortfolioStat.", "OMB has taken significant steps to enhance the oversight, transparency,  and accountability of federal IT investments by creating its IT Dashboard,  and by improving the accuracy of investment ratings. However, we found  weaknesses with the accuracy and reliability of cost and schedule data,  and we recommended steps that OMB should take to improve these data.", "Our July 2010 report found that the cost and schedule ratings on  OMB\u2019s Dashboard were not always accurate for the investments we  reviewed, because these ratings did not take into consideration  current performance. As a result, the ratings were based on outdated  information. We recommended that OMB report on its planned  changes to the Dashboard to improve the accuracy of performance  information and provide guidance to agencies to standardize  milestone reporting. OMB agreed with our recommendations and, as  a result, updated the Dashboard\u2019s cost and schedule calculations to  include both ongoing and completed activities. Similarly, in March  2011, OMB had initiated several efforts to increase the Dashboard\u2019s  value as an oversight tool, and had used its data to improve federal IT  management. However, agency practices and the Dashboard\u2019s  calculations contributed to inaccuracies in the reported investment  performance data. These included, for instance, missing data  submissions or erroneous data at each of the five agencies we  reviewed, along with instances of inconsistent program baselines and  unreliable source data. As a result, we recommended that the  agencies take steps to improve the accuracy and reliability of their  Dashboard information, and that OMB improve how it rates  investments relative to current performance and schedule variance.  Most agencies generally concurred with our recommendations; OMB  agreed with our recommendation for improving ratings for schedule  variance. It disagreed with our recommendation to improve how it  reflects current performance in cost and schedule ratings, but more  recently made changes to Dashboard calculations to address this  while also noting challenges in comprehensively evaluating cost and  schedule data for these investments.", "Our subsequent report in 2011 noted that that the accuracy of  investment cost and schedule ratings had improved since our July  2010 report because OMB had refined the Dashboard\u2019s cost and  schedule calculations. Most of the ratings for the eight investments we  reviewed were accurate, although more could be done to inform  oversight and decision making by emphasizing recent performance in  the ratings. We recommended that the General Services  Administration comply with OMB\u2019s guidance for updating its ratings  when new information becomes available (including when  investments are rebaselined) and the agency concurred. Since we  previously recommended that OMB improve how it rates investments,  we did not make any further recommendations.", "More recently, in October 2012 we found that opportunities existed to  improve transparency and oversight of investment risk at our selected  agencies. Specifically, CIOs at six federal agencies consistently  rated the majority of their IT investments as low risk. These agencies  rated no more than 12 percent of their investments as high or  moderately high risk, and two agencies (DOD and the National  Science Foundation) rated no investments at these risk levels. Over  time, about 47 percent of the agencies\u2019 Dashboard investments  received the same rating in every rating period. For ratings that  changed, the Department of Homeland Security and Office of  Personnel Management reported more investments with reduced risk  when initial ratings were compared with those in March 2012; the  other four agencies reported more investments with increased risk. In  the past, OMB reported trends for risky IT investments needing  management attention as part of the President\u2019s annual budget  submission, but discontinued this reporting in fiscal year 2010.  Accordingly, we recommended OMB analyze agencies\u2019 investment  risk over time as reflected in the Dashboard\u2019s CIO ratings and present  its analysis with the President\u2019s annual budget submission, with which  OMB concurred.", "Further, agencies generally followed OMB\u2019s instructions for assigning  CIO ratings, which included considering stakeholder input, updating  ratings when new data become available, and applying OMB\u2019s six  evaluation factors. DOD\u2019s ratings were unique in reflecting additional  considerations, such as the likelihood of OMB review, and  consequently DOD did not rate any of its investments as high risk.  However, in selected cases, these ratings did not appropriately reflect  significant cost, schedule, and performance issues reported by GAO  and others. Although three DOD investments experienced significant  performance problems and were part of a GAO high-risk area  (business systems modernization), they were all rated low risk or  moderately low risk by the DOD CIO. For example, in early 2012, we  reported that Air Force\u2019s Defense Enterprise Accounting and  Management System faced a 2-year deployment delay and an  estimated cost increase of about $500 million from an original life- cycle cost estimate of $1.1 billion (an increase of approximately 45  percent), and that assessments by DOD users had identified  operational problems with the system, such as data accuracy issues,  an inability to generate auditable financial reports, and the need for  manual workarounds. In July 2012, the DOD Inspector General  reported that the system\u2019s schedule delays were likely to diminish the  cost savings it was to provide, and would jeopardize the department\u2019s  goals for attaining an auditable financial statement. DOD\u2019s CIO rated  the Defense Enterprise Accounting and Management System low risk  or moderately low risk from July 2009 through March 2012.", "Moreover, DOD did not apply its own risk management guidance to  the ratings, which reduces their value for investment management  and oversight. Therefore, we recommended that DOD ensure that its  CIO ratings reflect available investment performance assessments  and its risk management guidance. DOD concurred with our  recommendation.", "Regarding TechStat reviews, we reported that OMB and selected  agencies had held multiple TechStats, but additional OMB oversight was  needed to ensure that these meetings were having the appropriate impact  on underperforming projects and that resulting cost savings were valid.   Specifically, we reported that as of April 2013, OMB reported conducting  79 TechStats, which focused on 55 investments at 23 federal agencies.  Further, 4 selected agencies\u2014the Departments of Agriculture,  Commerce, Health and Human Services, and Homeland Security\u2014 conducted 37 TechStats covering 28 investments. About 70 percent of  the OMB-led and 76 percent of agency-led TechStats on major  investments were considered medium to high risk at the time of the  TechStat. However, the number of at-risk TechStats held to date was  relatively small compared to the current number of medium- and high-risk  IT investments. Specifically, the OMB-led TechStats represented roughly  18.5 percent of the investments across the government that had a  medium- or high-risk CIO rating. For the 4 selected agencies, the number  of TechStats represented about 33 percent of the investments that have a  medium- or high-risk CIO rating. We concluded that until OMB and  agencies develop plans to address these weaknesses, the investments  would likely remain at risk.", "In addition, we reported that OMB and selected agencies had tracked and  reported positive results from TechStats, with most resulting in improved  governance. Agencies also reported projects with accelerated delivery,  reduced scope, or termination. We also found that OMB reported in 2011  that federal agencies achieved almost $4 billion in life-cycle cost savings  as a result of TechStat sessions. However, we were unable to validate  OMB\u2019s reported results because OMB did not provide artifacts showing  that it ensured the results were valid. From our selected agencies, three  investments had cost implications. Agencies provided supporting  documentation for about $22.2 million in cost savings and avoidances.  We concluded that until OMB obtains and shares information on the  methods used to validate reported results, it would be difficult for the  results to be independently validated and for OMB to provide assurance  to Congress and the public that TechStats were achieving their intended  impact. We therefore recommended that OMB validate the resulting cost  savings from TechStats that it reports to Congress and require agencies  to conduct TechStats for each IT investment rated with a moderately  high- or high-risk CIO rating on the IT Dashboard. We also made  recommendations to the selected agencies to strengthen their TechStat  processes. OMB and the Department of Commerce officials generally  agreed with our recommendations. The Department of Agriculture  partially agreed with our assessment; neither it nor the Department of  Health and Human Services commented on the recommendations.", "Subsequent to the launch of the Dashboard and the TechStat reviews,  and to help the federal agencies address the well-documented acquisition  challenges they face, we identified seven successful investment  acquisitions and nine common factors critical to their success in 2011.  Specifically, we reported that department officials identified seven  successful investment acquisitions, in that they best achieved their  respective cost, schedule, scope, and performance goals. In addition,  common factors critical to the success of three or more of the seven  investments were: (1) program officials were actively engaged with  stakeholders; (2) program staff had the necessary knowledge and skills;  (3) senior department and agency executives supported the programs; (4)  end users and stakeholders were involved in the development of  requirements; (5) end users participated in testing of system functionality  prior to formal end user acceptance testing; (6) government and  contractor staff were stable and consistent; (7) program staff prioritized  requirements; (8) program officials maintained regular communication  with the prime contractor; and (9) programs received sufficient funding.  Further, officials from all seven investments cited active engagement with  program stakeholders as a critical factor to the success of those  investments. These critical factors support OMB\u2019s objective of improving  the management of large-scale IT acquisitions across the federal  government, and wide dissemination of these factors could complement  OMB\u2019s efforts.", "In an effort to consolidate the growing number of federal data centers, in  2010, OMB launched the FDCCI. As part of this initiative, agencies  developed plans to consolidate data centers; however, these plans were  incomplete and did not include best practices. In addition, although  agencies had made progress on their data center closures, OMB had not  determined initiative-wide cost savings, and oversight of the initiative was  not being performed in all key areas. Finally, as part of ongoing follow-up  work, we determined that agencies closed additional data centers, but  that the number of federal data centers was significantly higher than  previously estimated by OMB.", "In July 2011, we issued a report on the status of FDCCI and found  that only 1 of the 24 agencies had submitted a complete inventory and  no agency had submitted complete plans. Further, OMB had not  required agencies to document the steps they had taken, if any, to  verify the inventory data. We concluded that until these inventories  and plans were complete, agencies would not be able to implement  their consolidation activities and realize expected cost savings.  Moreover, without an understanding of the validity of agencies\u2019  consolidation data, OMB could not be assured that agencies were  providing a sound baseline for estimating consolidation savings and  measuring progress against those goals. Accordingly, we made  several recommendations to OMB, including that the Federal CIO  require that agencies, when updating their data center inventory, state  what actions were taken to verify the information in the inventory and  to identify any associated limitations on the data, and to complete the  missing elements in their inventories and consolidation plans. OMB  generally agreed with our report and has since taken actions to  address our recommendations. For example, in July 2011, OMB  required agency CIOs to submit a letter that identified steps taken to  verify their data center inventory information and attest to the  completeness of their consolidation plan. In addition, in March 2012,  OMB required that all agencies, by the end of the fourth quarter of  every fiscal year, complete all elements missing from their  consolidation plans.", "Additionally, in July 2012, we updated our review of FDCCI\u2019s status  and found that, while agencies\u2019 2011 inventories and plans had  improved as compared to their 2010 submissions, only 3 agencies  had submitted a complete inventory and only 1 agency had submitted  a complete consolidation plan. In addition, we noted that 3 agencies  had submitted their inventory using an outdated format, in part,  because OMB had not publicly posted its revised guidance.  Notwithstanding these weaknesses, we found that 19 agencies  reported anticipating about $2.4 billion in cost savings between 2011  and 2015.", "We also reported that none of five selected agencies had a master  program schedule or cost-benefit analysis that was fully consistent  with best practices. To assist agencies with their data center  consolidation efforts, OMB had sponsored the development of a  FDCCI total cost of ownership model that was intended to help  agencies refine their estimated costs for consolidation; however,  agencies were not required to use the cost model as part of their cost  estimating efforts. Accordingly, we reiterated our prior  recommendation that agencies complete missing plan and inventory  elements and made new recommendations to OMB to publically post  guidance updates on the FDCCI website and to require agencies to  use its cost model. OMB generally agreed with our recommendations  and has since taken steps to address them. More specifically, OMB  posted its 2012 guidance for updating data center inventories and  plans, as well as guidance for reporting consolidation progress, to the  FDCCI public website. Further, the website has been updated to  provide prior guidance documents and OMB memoranda. In addition,  OMB\u2019s 2012 consolidation plan guidance required agencies to use the  cost model as they developed their 2014 budget request.", "More recently, we reported and testified that the 24 FDCCI  agencies made progress towards OMB\u2019s goal to close 40 percent, or  1,253 of the 3,133 total federal data centers, by the end of 2015, but  OMB had not measured agencies\u2019 progress against its other goal of  $3 billion in cost savings by the end of 2015. Agencies closed 420  data centers by the end of December 2012 and had plans to close an  additional 548 to reach 968 by December 2015\u2014285 closures short of  OMB\u2019s goal. OMB had not determined agencies\u2019 progress against its  cost savings goal because, according to OMB staff, the agency has  not determined a consistent and repeatable method for tracking cost  savings. We reported that this lack of information makes it uncertain  whether the $3 billion in savings is achievable by the end of 2015. We  concluded that until OMB tracks and reports on performance  measures such as cost savings, it will be limited in its ability to  oversee agencies\u2019 progress against key goals.", "Further, we reported that, pursuant to OMB direction, three  organizations\u2014the Data Center Consolidation Task Force, the  General Services Administration Program Management Office, and  OMB\u2014are responsible for federal data center consolidation oversight  activities. We found that while most activities were being performed,  there were still several weaknesses in oversight. For example, while  the General Services Administration\u2019s Program Management Office  had collected agencies\u2019 quarterly data center closure updates and  made the information publically available on an electronic dashboard  for tracking consolidation progress, it had not fully performed other  oversight activities, such as conducting analyses of agencies\u2019  inventories and plans. In addition, while OMB had implemented  several initiatives to track agencies\u2019 consolidation progress, such as  establishing requirements for agencies to update their plans and  inventories yearly and to report quarterly on their consolidation  progress, the agency had not approved the plans on the basis of their  completeness or reported on progress against its goal of $3 billion in  cost savings. The weaknesses in oversight of the data center  consolidation initiative were due, in part, to OMB not ensuring that  assigned responsibilities are being executed. We concluded that  improved oversight could better position OMB to assess progress  against its cost savings goal and minimize agencies\u2019 risk of not  realizing expected cost savings.", "We therefore recommended that OMB\u2019s Federal CIO track and report  on key performance measures, extend the time frame for achieving  planned cost savings, and improve the execution of important  oversight responsibilities. OMB agreed with two of our  recommendations and stated that it plans to evaluate the remaining  recommendation related to extending the time frame.", "Finally, as part of ongoing follow-up work, we reported that agencies  had closed an additional 64 data centers compared to the total  number of reported closures through the end of December 2012.  More specifically, as of May 2013, agencies had reported closing 484  data centers by the end of April 2013, and were planning to close an  additional 571 data centers\u2014for a total of 1,055\u2014by September 2014.  However, we also found that the number of federal data centers had  grown significantly since OMB had reported in December 2011 that  there were approximately 3,133 data centers. Specifically, as of July  2013, 22 of the 24 FDCCI agencies had collectively reported 6,836  data centers in their inventories, which is approximately 3,700 data  centers more than OMB\u2019s previous estimate from December 2011.", "To address duplicative IT investments, OMB launched PortfolioStat in  March 2012, which is designed to assist agencies in assessing the  current maturity of their IT portfolio management process, making  decisions on eliminating duplication, and moving to shared services in  order to maximize the return on IT investments across the portfolio.", "We recently reported and testified on OMB\u2019s PortfolioStat initiative,  including that, in March 2013, OMB issued a memorandum documenting  additional guidance to help strengthen the initiative. In its memorandum,  OMB noted that the results from PortfolioStat so far had been  significant\u2014including that agencies had identified and committed to  nearly 100 opportunities to consolidate or eliminate commodity IT  investments and also described plans to strengthen the initiative by  integrating PortfolioStat and FDCCI, streamlining agency reporting  requirements, and establishing guidance for conducting PortfolioStat  sessions in fiscal year 2013. For example, to improve the outcomes of  PortfolioStat and to advance agency IT portfolio management, OMB\u2019s  memorandum consolidated previously collected IT plans, reports, and  data calls into three primary collection channels\u2014an information  resources management strategic plan, an enterprise road map, and an  integrated data collection channel. Agencies\u2019 draft versions of their  strategic plans and enterprise road maps were due to OMB in May 2013,  as well as their first integrated data collections. The integrated data  collections are to be updated quarterly beginning in August 2013 and the  strategic plans and road maps are to be updated after Congress receives  the President\u2019s budget for fiscal year 2015.", "However, our April 2013 report noted that key data-center-related  performance metrics of the combined initiative were not yet fully defined.  For example, OMB\u2019s March 2013 memorandum stated that, to more  effectively measure the efficiency of an agency\u2019s data center assets,  agencies would also be measured by the extent to which their data  centers are optimized for total cost of ownership by incorporating metrics  for data center energy, facility, labor, and storage, among other things.  Although OMB had indicated which performance measures it planned to  use going forward, it had not documented the specific metrics for  agencies to report against. OMB\u2019s March 2013 memorandum indicates  that these would be developed by the Data Center Consolidation Task  Force, but did not provide a time frame for when this will be completed.", "Further, our report noted that OMB\u2019s integration of FDCCI with  PortfolioStat also included a modification to the previous data center  consolidation goal of closing approximately 40 percent of the total number  of agency data centers. Specifically, OMB stated an agency\u2019s data center  population will now be placed into one of two categories\u2014core and non- core data centers\u2014but for which the memorandum did not provide  specific definitions. OMB further stated that its new goal is to close 40  percent of non-core data centers but, as noted, the definitions of core and  non-core data centers were not provided. Therefore, the total number of  data centers to be closed under OMB\u2019s revised goal could not be  determined.", "We also reported that, although OMB had previously stated that  PortfolioStat was expected to result in savings of approximately $2.5  billion through 2015, its March 2013 memorandum did not establish a  new cost savings goal that reflected the integration of FDCCI. Instead,  OMB stated that all cost savings goals previously associated with FDCCI  would be integrated into broader agency efforts to reshape their IT  portfolios, but did not provide a revised savings estimate. We concluded  that the lack of a new cost savings goal would limit OMB\u2019s ability to  determine whether or not the new combined initiative is on course toward  achieving its planned objectives. As a result, we recommended that OMB  track and annually report on key data center consolidation performance  measures, such as the size of data centers being closed and cost savings  to date. OMB agreed with our recommendation.", "We have ongoing work looking at OMB\u2019s PortfolioStat initiative, including  determining whether agencies completed key required PortfolioStat  actions, evaluating selected agencies' plans for making portfolio  improvements and achieving associated cost savings, and describing  OMB's plans to improve the PortfolioStat process.", "In summary, OMB\u2019s and agencies\u2019 recent efforts have resulted in greater  transparency and oversight of federal spending, but continued leadership  and attention are necessary to build on the progress that has been made.  For example, federal agencies need to continue to improve the accuracy  of information on the Dashboard to provide greater transparency and  even more attention to the billions of dollars invested in troubled projects.  Further, additional TechStat reviews are needed to focus management  attention on additional troubled projects and establish clear action items  to turn the projects around or terminate them. In addition, the expanded  use of the common factors critical to the successful management of large- scale IT acquisitions should result in the more effective delivery of  mission-critical systems.", "The federal government can also build on the momentum of progress on  agencies\u2019 data center closures as the federal data center consolidation  effort is integrated with PortfolioStat. OMB recently released additional  guidance that expanded this important initiative\u2019s scope and reported that  significant progress had been made to date, including more than 100  opportunities to consolidate or eliminate commodity IT investments.  Moving forward, it will be important for OMB to be transparent on  agencies\u2019 progress against key performance metrics, such as data center  consolidation cost savings, in order to ensure that the PortfolioStat  initiative is meeting its established objectives. Overall, the implementation  of GAO recommendations can help further reduce wasteful spending on  poorly managed, unnecessary, and duplicative investments.", "Chairman Mica, Ranking Member Connolly, and Members of the  Subcommittee, this completes my prepared statement. I would be  pleased to respond to any questions that you may have at this time."], "subsections": []}, {"section_title": "GAO Contact and Staff Acknowledgments", "paragraphs": ["If you or your staffs have any questions about this testimony, please  contact me at (202) 512-9286 or at pownerd@gao.gov. Individuals who  made key contributions to this testimony are Dave Hinchman (Assistant  Director), Justin Booth, Rebecca Eyler, Lee A. McCracken, Jonathan  Ticehurst, and Kevin Walsh."], "subsections": []}]}, {"section_title": "Appendix I: Examples of IT Project Failures and Challenges", "paragraphs": ["The federal government continues to spend billions of dollars on troubled  IT investments. This appendix identifies examples of major IT  investments that have failed or faced significant challenges. In this  regard, we focused on IT projects that were considered major  development or acquisition efforts, based on their size or mission  criticality. We considered a project to have failed if it was terminated by  the agency after substantial investment and without delivering significant  planned capabilities. A project was considered to be challenged if we had  identified significant issues in its performance or management and made  recommendations for improvement. To identify these projects, we  reviewed our work published since January 1, 2003, that addressed the  performance or management of federal agency IT projects. We did not  include a project on our lists if it was not the subject of a GAO report."], "subsections": [{"section_title": "Failed Investments", "paragraphs": ["Since 2003, a number of major IT projects at federal agencies have  failed. Specifically, agencies canceled the following investments after  spending millions of dollars:", "Department of Defense\u2019s (DOD) Expeditionary Combat Support  System (ECSS)", "DOD\u2019s Defense Integrated Military Human Resources System  (DIMHRS)", "Department of Homeland Security\u2019s (DHS) Computer-Assisted  Passenger Prescreening System (CAPPS II)", "DHS\u2019s Electronically Managing Enterprise Resources for Government  Effectiveness and Efficiency (eMerge2)", "DHS\u2019s Next Generation Homeland Security Information Network  (HSIN Next Gen)", "DHS\u2019s Secure Border Initiative Network (SBInet)", "Federal Bureau of Investigation\u2019s (FBI) Virtual Case File (VCF)", "General Services Administration\u2019s (GSA) e-Authentication Program", "National Archives and Records Administration\u2019s (NARA) Electronic  Records Archive (ERA)", "National Polar-orbiting Operational Environmental Satellite System  (NPOESS)", "Office of Personnel Management\u2019s (OPM) Retirement Systems", "Veterans Affairs\u2019 (VA) Scheduling Replacement Project", "VA\u2019s Core Financial and Logistics System (CoreFLS)", "VA\u2019s Financial and Logistics Integrated Technology Enterprise  (FLITE) Program", "VA\u2019s Health Information Systems and Technology Architecture\u2014 Foundations Modernization (VistA-FM)", "These projects were canceled after going over budget, missing schedule  milestones, or failing to deliver intended capabilities. In many of these  cases, we had identified issues in the management of these programs  and made recommendations for improvement. These issues were often  related to a lack of disciplined and effective management, such as project  planning, requirements definition, and program oversight and  governance. The following provides additional information on these failed  IT investments.", "DOD\u2019s Expeditionary Combat Support System (ECSS)", "In December 2012, DOD canceled ECSS after having spent more than a  billion dollars and missing multiple milestones, including failure to achieve  deployment within 5 years of obligating funds. The system was to provide  the Air Force with a single, integrated logistics system that was to control  and account for about $36 billion of inventory. We issued several reports  on this system and found that, among other things, the program was not  fully following best practices for developing reliable schedules and cost  estimates. Among other things, we had recommended that DOD ensure  that any future system deficiencies identified through independent  assessments be resolved or mitigated prior to further deployment of  ECSS.", "DOD\u2019s Defense Integrated Military Human Resources System  (DIMHRS)", "In February 2010, DIMHRS was canceled after 10 years of development  and approximately $850 million spent, due, in part, to a lack of strategic  alignment, governance, and requirements management, as well as the  overall size and scope of the effort. The system was intended to provide  a joint, integrated, standardized personnel and pay system for all military  personnel. In 2008, we had reported that Army officials had concerns  about the extent to which Army requirements were being incorporated  into DIMHRS and that DOD had not established a clear, well-defined  process for maintaining effective communications to better prepare the  Army to deploy DIMHRS. We had recommended that DOD develop a  clearly defined process for effectively communicating the differences  between DIMHRS\u2019s capabilities and the Army\u2019s requirements. However,  subsequent to the cancellation decision, each military service is now  responsible for developing its own integrated personnel and pay system.", "DHS\u2019s Computer-Assisted Passenger Prescreening System (CAPPS  II)", "In August 2004, DHS canceled its CAPPS II program\u2014a Transportation  Security Administration (TSA) initiative to develop a system to identify  passengers requiring additional security attention\u2014due to a variety of  delays and challenges. In February 2004, we reported that, according to  program officials, approximately $41.5 million had been allocated for the  system\u2019s acquisition to date and that the program faced a number of  implementation challenges. Specifically, key activities in the development  of CAPPS II had been delayed, and TSA had not completed important  system planning activities. In addition, TSA had not completely addressed  seven of the eight issues identified by Congress as key areas of interest  related to the development, operation, and public acceptance of CAPPS  II. We also identified other challenges, including developing the  international cooperation needed to obtain passenger data, managing the  possible expansion of the program\u2019s mission beyond its original purpose,  and ensuring that identity theft could not be used to negate the security  benefits of the system. We recommended, among other things, that DHS  develop project plans, including schedules and estimated costs, to guide  development; establish a plan for completing critical security activities;  and develop a process by which passengers can get erroneous  information corrected. CAPPS II was eventually replaced by the Secure  Flight system, which in turn was completely revamped and replaced by a  new version of Secure Flight that finally became operational.", "DHS\u2019s Electronically Managing Enterprise Resources for  Government Effectiveness and Efficiency (eMerge)", "DHS canceled its eMerge project, including approximately $18 million in contractor  costs. As we reported in June 2007, DHS officials stated that several of  the work products developed for eMerge However, we found that key work products were of limited  value. Specifically, the concept of operations did not contain an adequate  description of the legacy systems and a clear articulation of the vision that  should guide the department\u2019s improvement efforts, and key requirements  developed for the project were unclear and incomplete. We  recommended, among other things, that, going forward, DHS employ best  practices in defining its financial management system strategy, such as  developing a comprehensive concept of operations document,  standardizing business processes, and using disciplined processes to  minimize project risk.", "DHS\u2019s Next Generation Homeland Security Information Network  (HSIN Next Gen)", "In October 2010, DHS terminated the acquisition of its HSIN Next Gen  system, which was to be the follow-on to its original HSIN system, the  department\u2019s primary IT system for sharing terrorism-related information.  The department cited, among other things, continuing cost, schedule, and  performance shortfalls and the lack of key IT management controls and  capabilities that are essential to mitigating such shortfalls and ensuring  successful system delivery. In 2008 we reported that DHS had yet to  implement the full set of controls essential to effectively manage the  acquisition of HSIN Next Gen. We recommended that DHS strengthen its  acquisition management controls before it started to implement the  system. The termination of HSIN Next Gen resulted in a cost reduction of  $128,969,000.", "DHS\u2019s Secure Border Initiative Network (SBInet)", "In January 2011, the Secretary of Homeland Security ended the SBInet  program after obligating more than $1 billion to the program because it  did not meet cost-effectiveness and viability standards. Since 2007, we  had identified a range of issues and made several recommendations to  improve this program. For example, in May 2010 we reported that the  final acceptance of the first two deployments had slipped from November  2009 to September 2010 and from March 2010 to November 2010, and  that the cost-effectiveness of the system had not been justified. We  concluded that DHS had not demonstrated that the considerable time and  money being invested to acquire and deploy the program was a wise and  prudent use of limited resources. As a result, we recommended that the  department (1) limit near-term investment in the first incremental block of  the program, (2) economically justify any longer-term investment in it, and  (3) improve key program management disciplines. This work contributed  to the department\u2019s decision to cancel the program.", "FBI\u2019s Virtual Case File (VCF)", "In March 2005, the FBI discontinued the VCF component of its Trilogy  project after investing 3 years and $170 million. The FBI terminated the  project after Trilogy\u2019s overall projected costs grew from $380 million to  $537 million, the program fell behind schedule, and pilot testing showed  that completion of VCF was infeasible and cost prohibitive. Among  reasons we and others cited for VCF\u2019s failure were poorly defined system  requirements, ineffective requirements change control, limited contractor  oversight, and human capital shortfalls due to, for example, a lack of  continuity in certain management positions and a lack of trained staff for  key program positions.", "GSA\u2019s e-Authentication Program   In October 2003, it was reported that GSA had terminated plans to  develop an \u201ce-Authentication gateway,\u201d which was to provide a  consolidated electronic authentication service to support the e- government initiatives sponsored by OMB. We had reported 1 month  earlier in September 2003 that, according to agency officials, 13 agencies  had provided a total of $13.5 million to GSA for the gateway as of August  18, 2003, with another $3 million expected from another agency by the  end of fiscal year 2003. However, GSA had achieved few of its project  objectives and extended the milestone for completing a fully operational  system. We noted that the modest progress that had been achieved to  date called into question the likelihood that the project could successfully  field an operational gateway, even within the revised schedule. Further,  the project faced a number of challenges, including developing  procedures and guidance defining the specific technologies to support  different authentication requirements, agreeing upon technical standards  to provide a basis for ensuring interoperability, and taking full measures to  ensure that the gateway system was adequately secured and that privacy  information adequately protected.", "NARA\u2019s Electronic Records Archive (ERA)", "In July 2010, OMB directed NARA to halt development of its ERA system  at the end of fiscal year 2011 (a year earlier than planned). OMB cited  concerns about the system\u2019s cost, schedule, and performance and  directed NARA to better define system functionality and improve strategic  planning. Through fiscal year 2010, NARA had spent about $375 million  on the system. We issued several reports and made recommendations to  improve this system, noting, among other things, that NARA\u2019s plans for  ERA lacked sufficient detail to clearly show what functions had been  delivered or were to be included in future increments and at what cost;  the agency had been inconsistent in its use of earned value management  to monitor the project\u2019s progress; and NARA lacked a contingency plan  for ERA to ensure system continuity in the event that normal operations  were disrupted. These findings and recommendations contributed to the  decision to halt the system.", "National Polar-orbiting Operational Environmental Satellite System  (NPOESS)", "In February 2010, a presidential task force decided to disband NPOESS  after having spent 16 years and almost $5 billion on the program.  NPOESS was a tri-agency weather satellite program managed by the  National Oceanic and Atmospheric Administration (NOAA), DOD, and the  National Aeronautics and Space Administration (NASA). We issued a  series of reports on the NPOESS program that highlighted the technical  challenges, cost growth, and tri-agency management challenges facing  the program. For example, in June 2009 we reported that the program\u2019s  approved cost and schedule baselines were not achievable, and that  costs could grow by approximately $1 billion over the then-current $13.95  billion estimate. We further noted that schedules for the launch of a  demonstration satellite and the first two operational satellites were  expected to be delayed, increasing the risk of a gap in satellite continuity.  We had also found that the NPOESS program\u2019s tri-agency executive  council was ineffective, and we made recommendations aimed at  improving this executive-level oversight. However, after the program\u2019s  cancellation, the agencies were directed to undertake separate  acquisitions.", "OPM\u2019s Retirement Systems Modernization  In February 2011, OPM canceled its Retirement Systems Modernization  program after several years of trying to improve the implementation of this  investment. This was the agency\u2019s third major effort over a more than  20-year period to automate the processing of federal employee retirement  claims. According to OPM, it spent approximately $231 million on this  investment. We issued a series of reports on the agency\u2019s efforts to  modernize its retirement system and found that the agency was hindered  by weaknesses in several important management disciplines that are  essential to successful IT modernization efforts. Accordingly, we made  recommendations in areas such as project management, organizational  change management, testing, cost estimating, and earned value  management. In May 2008, an OPM official cited the issues that we  identified as justification for issuing a stop work order to the system  contractor, and the agency subsequently terminated the contract, which  resulted in a cost reduction of $136.5 million between fiscal years 2009  and 2013.", "VA\u2019s Scheduling Replacement Project  In September 2009, VA terminated its Scheduling Replacement Project,  after spending an estimated $127 million over 9 years. The investment  was to modernize its more than 25-year-old outpatient scheduling system,  but the department had not yet implemented any of the planned system\u2019s  capabilities. VA began a new initiative that it refers to as HealtheVet  Scheduling on October 1, 2009. In May 2010, we reported that VA\u2019s  efforts to successfully complete the Scheduling Replacement Project  were hindered by weaknesses in several key project management  disciplines and a lack of effective oversight that, if not addressed, could  undermine the department\u2019s second effort to replace its scheduling  system. As the department proceeded with future development, we  recommended that it take actions to improve key processes, including  acquisition management, system testing, and progress reporting, which  are essential to the department\u2019s second outpatient scheduling system  effort.", "VA\u2019s Core Financial and Logistics System (CoreFLS)", "VA\u2019s first attempt to develop an integrated financial and asset  management system, CoreFLS, began in 1998 but was discontinued by  the department in 2004 because the pilot system failed to support VA\u2019s  operations after the department reportedly spent more than $249 million  on development. The department conducted three independent  assessments of the initiative that collectively identified 141 findings, which  the department categorized into functional areas of responsibility such as  acquisition management, organizational change management, program  management, and systems engineering. VA aggregated these findings  into a repository of lessons learned to inform future efforts. However, we  reported in September 2008 that the department had not taken corrective  actions to address all the findings, and recommended that it do so.  Subsequently, VA officials provided documentation showing that all items  in the repository had been addressed.", "VA\u2019s Financial and Logistics Integrated Technology Enterprise  (FLITE) Program  In October 2011, VA terminated its FLITE program, an effort to deliver an  integrated financial and asset management system for the department.  Begun in 2005, the system was intended to be delivered by 2014 at a  total estimated cost of $608.7 million but was canceled due to challenges  in managing the program, including an unsuccessful pilot of the Strategic  Asset Management system. The FLITE program was VA\u2019s second effort  to develop such a system. We had reported in October 2009 that the  department had not yet fully established capabilities needed to ensure  that the program will be successfully implemented and recommended that  it take steps to improve program management.", "VA\u2019s Health Information Systems and Technology Architecture\u2014 Foundations Modernization (VistA-FM)", "In October 2010, VA terminated its VistA-FM program, which was to  address the need to transition the VA electronic medical record system to  a new architecture. As we reported in October 2009, the program, which  had been estimated to cost $1.9 billion, had significant weaknesses in its  earned value management processes, and we estimated that the  program would likely overrun its budget at completion by about $350.2  million. As a result of our recommendations and an internal department  evaluation of the program, multiple components of the program were  suspended, before the program was finally terminated in 2010."], "subsections": []}, {"section_title": "Challenged IT Investments", "paragraphs": ["In addition to canceling many failed projects, the government has  continued to invest in challenged IT projects. The following are selected  examples of such investments that have faced significant challenges:", "Department of Commerce/Census Bureau\u2019s 2010 Decennial Census", "Department of Commerce/NOAA\u2019s Geostationary Operational  Environmental Satellite-R (GOES-R) Series", "DHS\u2019s Rescue 21 Program", "DHS\u2019s United States Visitor and Immigrant Status Indicator  Technology (US-VISIT) Program", "DOD\u2019s Armed Forces Health Longitudinal Technology Application  (AHLTA)", "DOD\u2019s Defense Enterprise Accounting and Management System  (DEAMS)", "DOD\u2019s Global Combat Support System-Army (GCSS-Army)", "DOD\u2019s Global Combat Support System\u2013Marine Corps (GCSS-MC)", "DOD\u2019s Navy Enterprise Resource Planning System (Navy ERP)", "DOD\u2019s Navy Next Generation Enterprise Network (NGEN)", "DOD/Department of the Treasury\u2019s Navy Cash Program", "DOD/VA\u2019s Integrated Electronic Health Record (iEHR)", "DOD/VA\u2019s Federal Health Care Center (FHCC)", "Food and Drug Administration\u2019s (FDA) Mission Accomplishments and  Regulatory Compliance Services (MARCS)  Internal Revenue Service\u2019s (IRS) Customer Account Data Engine  (CADE)", "NASA\u2019s James Webb Space Telescope (JWST)", "U.S. Department of Agriculture\u2019s (USDA) Modernize and Innovate the  Delivery of Agricultural Systems (MIDAS) Program  We have identified challenges facing these projects, many due to  ineffective or undisciplined management, and have made  recommendations for improvement. The following provides additional  information on these challenged IT investments.", "Department of Commerce/Census Bureau\u2019s Decennial Census  At a cost of about $13 billion, the 2010 Decennial Census was the  costliest in history. This was due, in part, to cost overruns and major  performance problems with key IT systems. For example, the Census  Bureau\u2019s Field Data Collection Automation (FDCA) program, originally  estimated to cost $596 million, was intended to use handheld mobile  devices to support field data collection for the census, including in-person  follow-up with those who did not return their census questionnaires  (nonresponse follow-up). However, we testified in March 2008 that the  program was experiencing significant problems, including schedule  delays and cost increases from changes in requirements. We had  previously reported that the FDCA project office had not implemented the  full set of acquisition management capabilities that were needed to  effectively manage the program and that the changes to requirements  had been a contributing factor to both schedule delays and cost increases  experienced by the FDCA program.", "In April 2008, due to problems identified during testing and cost overruns  and schedule slippages, the Secretary of Commerce announced a  redesign of the 2010 Census, resulting in a $205 million increase in life- cycle costs. Also in April 2008, the Census Bureau decided not to use the  handheld devices for nonresponse follow-up, but did continue to use the  devices for other decennial census operations. Dropping the use of  handhelds for nonresponse follow-up and replacing them with a paper- based system increased the cost of the Census by up to $3 billion.  Although the bureau worked aggressively to improve the paper-based  system that replaced the handheld computers, we reported in December  2010 that the paper-based system also experienced significant issues  when it was put in operation. For example, performance problems with  the IT system used to manage the nonresponse follow-up process led to  processing backlogs, which hindered the bureau\u2019s ability to fully  implement quality assurance procedures as planned. We recommended,  accordingly, that the bureau incorporate best practices in its IT acquisition  management policy. In September 2012, we reported that the Census  Bureau still needed to implement key IT management practices to select,  control, and evaluate its IT investments and effectively manage system  development, as well as key practices for effective workforce planning,  and recommended it take eight actions to do so. Until such steps are  taken, the bureau faces the risk that the same kind of IT management  and implementation challenges that faced the 2010 Decennial Census will  impact the 2020 Census.", "Department of Commerce/NOAA\u2019s Geostationary Operational  Environmental Satellite-R (GOES-R) Series  The Department of Commerce\u2019s NOAA, with the aid of NASA, is to  procure the next generation of geostationary operational environmental  satellites\u2014a series of four satellites intended to replace existing weather  satellites that will likely reach the end of their useful lives in about 2015.  This new series is considered critical to the United States\u2019 ability to  maintain the continuity of data required for weather forecasting. NOAA  estimates that the GOES-R series will cost $10.9 billion through 2036; the  launch of the first satellite is planned for October 2015. In September  2010, we reported that, since 2006, the launch dates of the first two  satellites in the series have been delayed by about 3 years, which could  lead to a gap in coverage if the existing weather satellites fail  prematurely. We also found that NOAA had not established adequate  continuity plans in the event of a satellite failure with no backup available  and that the agency had not adequately involved users at federal  agencies that rely on GOES data in developing and prioritizing  requirements. We recommended that NOAA address weaknesses in its  continuity plans and improve its processes for involving other federal  agencies. Subsequently, NOAA established a continuity plan for GOES-R  and developed a communications plan for involving agencies that depend  on GOES data.", "In June 2012 we reported that technical problems with instruments and  spacecraft, among others, had delayed key reviews and led to increased  complexity for the development of GOES-R. While the program reported  having $1.2 billion in reserve to manage future delays and cost growth,  significant development remained, and we concluded that the program  may not be able to ensure that it has adequate resources to cover  ongoing challenges and unexpected problems. In addition, we found that  the program\u2019s schedule contained deficiencies, and it had not fully  implemented risk management best practices. We recommended that  NOAA assess and report reserves needed over the life of the program  and address the issues with its schedules and risk management. NOAA  reported that it would take steps to implement these recommendations.", "DHS\u2019s Rescue 21 Program  DHS\u2019s Rescue 21 program is intended to modernize the U.S. Coast  Guard\u2019s maritime search and rescue communications capability. Since  2003, we have reported on significant weaknesses in the oversight and  management of the program, including continued cost growth and  schedule delays. For example, in May 2006, we found that the  estimated total acquisition cost for Rescue 21 had increased from $250  million in 1999 to $710.5 million in 2005, and the time line for achieving  full operating capability had been delayed from 2006 until 2011. We  recommended that executive-level management oversee Rescue 21\u2019s  progress toward cost and schedule milestones and manage risks;  establish milestones to complete an integrated baseline review; and  develop revised cost and schedule estimates. More recently, in July 2012,  we reported that the Rescue 21 program\u2019s life-cycle cost estimate had  grown to approximately $2.7 billion\u2014an increase of approximately $2.4  billion since 1999\u2014and that completion was delayed to 2017. Program  officials stated that increases in the cost estimate were due, in part, to  additional schedule delays and more realistic estimates of future costs for  ongoing system technology refreshment. However, we noted that the  program\u2019s cost estimate did not exhibit all qualities of a reliable cost  estimate and recommended that DHS direct responsible officials to  update future life-cycle cost estimates using cost-estimating practices that  address the weaknesses we identified.", "DHS\u2019s United States Visitor and Immigrant Status Indicator  Technology (US-VISIT) Program  DHS\u2019s US-VISIT program is charged with developing a biometric  verification capability for non-U.S. citizens entering and leaving the  country. From fiscal year 2002 to fiscal year 2012, DHS\u2019s US-VISIT  program was appropriated over $3.5 billion, and the program has  successfully developed a massive biometric database and deployed an  entry capability. However, the program had not developed an exit  capability and last conducted an exit pilot in 2009. We have reported on  issues associated with key aspects of US-VISIT program management,  such as risk management and the reliability of cost estimates and  program schedules, as well as the lack of a completed strategic plan and  the results of the 2009 exit pilot. We recommended that DHS review the  program\u2019s approach to risk management and earned value management,  and that DHS develop a plan and integrated schedule for a  comprehensive exit capability. We also recommended that the program  incorporate additional sources of information when making future  decisions about an exit capability. However, there are no known current  plans to develop an exit process, and the President\u2019s fiscal year 2013  budget request called for eliminating a standalone US-VISIT program  office and incorporating the program\u2019s mission into Customs and Border  Protection and Immigration and Customs Enforcement. We have ongoing  recommendation follow-up work regarding this issue.", "DOD\u2019s Armed Forces Health Longitudinal Technology Application  (AHLTA)", "DOD has obligated approximately $2 billion over 13 years to acquire an  electronic health record system\u2014referred to as its AHLTA initiative. In  October 2010, we reported that DOD had delivered various capabilities  for outpatient care and dental care documentation, but it scaled back  other capabilities it had originally planned to deliver, such as replacement  of legacy systems and inpatient care management. In addition, users  continued to experience significant problems with the performance  (speed, usability, and availability) of the portions of the system that have  been deployed. These problems were due in part to weaknesses in key  acquisition management and planning processes. DOD initiated efforts to  improve system performance and enhance functionality and plans to  continue its efforts to stabilize the AHLTA system through 2015, as a  \"bridge\" to the new electronic health record system it intends to acquire.  According to DOD, the planned new electronic health record system\u2014 known as the EHR Way Ahead\u2014is to be a comprehensive, real-time  health record for service members and their families and beneficiaries. To  help better manage these efforts, we recommended that DOD take six  actions to help ensure that it has disciplined and effective processes in  place to manage the acquisition of further electronic health record system  capabilities.", "DOD\u2019s Defense Enterprise Accounting and Management System  (DEAMS)", "The Air Force\u2019s DEAMS is the agency\u2019s target accounting system  designed to provide accurate, reliable, and timely financial information. In  March 2012, we reported that DEAMS faced a 2-year deployment delay  and an estimated cost increase of about $500 million from its original life- cycle cost estimate of $1.1 billion, an increase of approximately 45  percent. Further, in February 2012, we reported that assessments by  DOD users had identified operational problems with the system, such as  data accuracy issues, an inability to generate auditable financial reports,  and the need for manual workarounds. We recommended that DOD  take actions to ensure the correction of system problems prior to further  system deployment, including user training. In July 2012, the DOD  Inspector General reported that the DEAMS schedule delays were likely  to diminish its intended cost savings and would jeopardize the  department\u2019s goals for attaining an auditable financial statement.", "DOD\u2019s Global Combat Support System-Army (GCSS-Army)", "GCSS-Army is intended to improve the Army\u2019s supply chain management  capabilities and provide accurate equipment readiness status reports,  among other things. In March 2012, we reported that GCSS-Army was  experiencing a cost overrun of approximately $300 million on an original  life-cycle cost estimate of $3.9 billion (an increase of approximately 8  percent) and a deployment delay of approximately 2 years. Among other  things, we recommended that DOD ensure any future system deficiencies  identified through independent assessments are resolved or mitigated  prior to further deployment of the system. In addition, because the DOD  CIO rated GCSS-Army as low or moderately low risk from July 2009  through March 2012 on OMB\u2019s federal IT Dashboard, we recommended  that the department\u2019s CIO reassess the department\u2019s considerations for  assigning risk levels to investments on the Dashboard, to include external  assessments of performance and risk.", "DOD\u2019s Global Combat Support System\u2013Marine Corps (GCSS-MC)", "GCSS-MC is intended to provide the deployed warfighter enhanced  capabilities in the areas of warehousing, distribution, logistical planning,  depot maintenance, and improved asset visibility. In July 2008, we  reported that not effectively implementing key IT management controls,  such as economically justifying investment in the system, had in part  contributed to a 3-year schedule slippage and a cost overrun of about  $193 million on the first phase of the program and would likely contribute  to future delays and overruns if not corrected. Accordingly, we made  recommendations to address the identified deficiencies, such as cost and  schedule estimating, risk management, and system quality measurement  weaknesses. In October 2010, we reported that GCSS-MC faced a 3- year deployment delay on phase 1. We also reported in March 2012 that  GCSS-MC faced an estimated cost increase of about $970 million from its  original life-cycle cost estimate of $126 million. As of December 2011,  the life-cycle cost estimate was estimated to be $1.1 billion, and a revised  full deployment date was being considered.", "DOD\u2019s Navy Enterprise Resource Planning System (Navy ERP)", "Navy ERP is intended to standardize the acquisition, financial, program  management, maintenance, procurement, plant and wholesale supply,  and workforce management capabilities of the Navy. In March 2012, we  reported that Navy ERP faced a 2-year deployment delay and an  estimated cost increase of about $1 billion from its original life-cycle cost  estimate of $1.87 billion. This estimate was later revised in August 2004,  December 2006, and again in September 2007 to $2.4 billion. In October  2010, we reported that these slippages occurred, in part, because of  problems experienced in data conversion and adopting new business  procedures associated with implementing the Navy ERP. Moreover, in  September 2008, we reported that not effectively implementing key IT  management controls, such as earned value management, had  contributed to the more than 2-year schedule delay and almost $600  million cost overrun on the program since it began, and would likely  contribute to future delays and overruns if not corrected. Accordingly, we  made recommendations to address the identified deficiencies, such as  improving cost and schedule estimating, earned value management, and  risk management weaknesses.", "DOD\u2019s Navy Next Generation Enterprise Network (NGEN)", "DOD\u2019s NGEN is to replace the Navy Marine Corps Intranet program and  include capabilities such as secure transport of voice and data, data  storage, and e-mail, to be incrementally acquired through multiple  providers. The program, which is expected to cost about $38 billion  through fiscal year 2024, had weaknesses in its acquisition approach.  Specifically, in March 2011, we reported that the program was not well  positioned to meet its cost and schedule estimates. For example, the  department had not sufficiently analyzed alternative acquisition  approaches and did not have a reliable schedule for executing NGEN.  We recommended DOD limit further investment until it conducted an  interim review to reconsider the selected acquisition approach and  addresses its investment management issues. In September 2012, we  reported that while DOD had revised its acquisition approach, it was still  suffering from management issues related to measuring cost  effectiveness, completing milestones on schedule, and mitigating risk.", "DOD/Department of the Treasury\u2019s Navy Cash Program  Initiated in 2001, Navy Cash is a joint Department of the Navy and  Department of the Treasury Financial Management Service program to  create a cashless environment on ships using smart card technology. It  was estimated to cost about $320 million to fully deploy. In 2008, we  reported that the system had not been assessed and defined in a way to  ensure that it was not duplicative of programs in the Air Force and the  Army that use smart card technology, nor economically justified on the  basis of reliable analyses of estimated costs and expected benefits over  the program\u2019s life. In addition, we reported that system requirements  and system security had not been effectively managed. Program  oversight and management officials acknowledged the weaknesses and  cited turnover of staff in key positions and their primary focus on  deploying Navy Cash as reasons for the state of some of the IT  management controls. We concluded that after investing about 6 years  and $132 million on Navy Cash and planning to invest an additional $60  million to further develop the program, the department had yet to  demonstrate through verifiable analysis and evidence that the program,  as currently defined, was justified. Accordingly, we recommended that  investment of modernization funding in the program be limited until a  basis for informed decision making was established, and that other  program management weaknesses were corrected.", "DOD/VA\u2019s Integrated Electronic Health Record (iEHR)", "DOD and VA have been challenged over the last 15 years on a variety of  initiatives to share data among the departments\u2019 health information  systems. In March 2011, the Secretaries of DOD and VA committed their  two departments to developing a new common iEHR, and in May 2012  announced their goal of implementing it across the departments by 2017.  According to the departments, the decision to pursue iEHR would enable  DOD and VA to align resources and investments with common business  needs and programs, resulting in a platform that would replace the two  departments\u2019 electronic health record systems with a common system.  The departments estimated the life-cycle cost of this effort at about $25  billion. However, as we noted in a recent testimony, the Secretaries  announced in February 2013 that instead of developing a new common  integrated electronic health record system, the departments would focus  on integrating health records from separate DOD and VA systems. VA  has stated that it will continue to modernize its existing system, called  VistA, while pursuing the integration of health data, while in May 2013,  DOD announced that it planned to purchase a commercial off-the-shelf  product. The Secretaries offered several reasons for this new direction,  including cutting costs, simplifying the problem of integrating DOD and VA  health data, and meeting the needs of veterans and service members  sooner rather than later. Nevertheless, the departments\u2019 recent change in  the program\u2019s direction and history of challenges to improving their health  information systems heighten concern about whether this latest initiative  will be successful.", "DOD/VA\u2019s Federal Health Care Center (FHCC)", "DOD and VA jointly undertook an IT project to support the FHCC in North  Chicago, Illinois, which is the first medical facility to serve both  departments\u2019 patient populations while operating under a single line of  authority. As we reported in February 2011, despite an investment of  more than $122 million, none of the FHCC\u2019s required IT capabilities had  been implemented as planned when the center opened in October  2010. While system components to support single sign-on and single- patient registration became operational in December 2010, a component  to support medical consults was not expected to be completed until  March 2013, and the departments did not have a schedule for completion  of the component to support pharmacy. We recommended that the  departments strengthen their joint IT system planning efforts for the  FHCC by developing plans that include scope definition, cost and  schedule estimation, and project plan documentation and approval. We  also noted that the two departments face barriers in three key IT  management areas\u2014strategic planning, enterprise architecture, and  investment management\u2014and recommended steps for improvement.", "FDA\u2019s Mission Accomplishments and Regulatory Compliance  Services (MARCS)", "FDA\u2019s MARCS program is intended to automate workflow, help track and  manage information about firm compliance with FDA\u2019s regulations, and  eliminate FDA\u2019s existing stove-piped databases. However, the program  has been rebaselined five times since 2002, the total estimated cost has  grown from $221.4 million to $282.7 million, and the estimated completion  date for initial development has slipped from September 2008 to October  2016. According to OMB exhibit 53s from 2004 to 2013, FDA has spent  approximately $160 million from fiscal year 2002 to fiscal year 2011 on  MARCS. In March 2012, we reported FDA had not developed a  comprehensive integrated master schedule for MARCS that would allow  the agency to effectively gauge progress. We further reported that the  agency was reevaluating the scope of the initiative and concluded that,  until this assessment was complete, it was uncertain how or when much  of the intended functionality and improvements associated with MARCS  would be delivered. We recommended that FDA, in completing the  assessment of MARCS, develop an integrated master schedule that  identifies which legacy systems will be replaced and when; identifies all  current and future tasks to be completed; and defines and incorporates  information reflecting needed resources and critical dependencies. We  further recommended that the agency use this schedule to monitor the  progress of MARCS.", "IRS\u2019s Customer Account Data Engine (CADE)", "In December 2011, IRS ended further development of CADE, its effort to  replace legacy systems for storing, managing, and accessing individual  taxpayer accounts. IRS started developing this system in 2002 to replace  the legacy Individual Master File processing system and house tax  information for more than 40 million taxpayers while providing faster  return processing and refunds. In December 2009, we reported that after  over 5 years and $400 million, CADE was only processing about 15  percent of the functionality originally planned for completion by 2012. In  addition, each successive release of the system was expected to process  more complex returns, but several technical challenges had not been  addressed. Given this, IRS estimated that full implementation of CADE  would not be achieved until at least 2018 or possibly as late as 2028. As  a consequence, in 2011 IRS decided to stop development of new CADE  functionality and rethink its strategy for modernizing individual taxpayer  accounts to determine whether an alternative approach could deliver  improvements sooner. This led to the development of CADE 2, a new  program for replacing the Individual Master File. Beginning in January  2012, IRS started using CADE 2 to process returns daily and issue  refunds faster for about 84 million taxpayers. As of January 2013, IRS  reported that there have been no significant problems with the system.", "NASA\u2019s James Webb Space Telescope (JWST)", "NASA\u2019s JWST project is designed to advance understanding of the origin  of the universe. Since 2006, we have identified a range of issues with the  project. For example, in July 2006, we reported that the JWST project  had experienced cost growth exceeding $1 billion\u2014which increased its  life-cycle cost estimate from $3.5 billion to $4.5 billion\u2014and its launch  date had slipped nearly 2 years to 2013. We also found that the program  was not fully adhering to a knowledge-based acquisition approach, which  ensures that resources match requirements in terms of knowledge, time,  and money before program start. Accordingly, we recommended that the  program apply such an approach. In October 2009, we reported that as of  May 2009, the JWST contractor exceeded its planned cost target by  $224.7 million and had not completed $9.4 million in planned work. A  key driver in this cost overrun was greater-than-expected complexity in  the work, which required additional resources. We concurred with the  contractor\u2019s estimate that it would overrun its budget\u2014worth  approximately $1.3 billion\u2014by $448.5 million. We also found that the  program had not fully implemented practices for earned value  management and recommended steps for improvement. In 2011, the  project finalized a major replanning that resulted in further growth to the  project\u2019s expected costs, as well as additional delays to its expected  launch date. On the basis of the replanning, NASA announced that the  project would be rebaselined at approximately $8.8 billion\u2014a 78 percent  increase to the project\u2019s life-cycle cost compared to the previous  baseline\u2014and would launch in October 2018\u2014a delay of 52 months.", "USDA\u2019s Modernize and Innovate the Delivery of Agricultural  Systems (MIDAS) Program  USDA\u2019s MIDAS program is intended to modernize the IT systems  supporting the Farm Service Agency\u2019s 37 farm programs. As we reported  in July 2011, the implementation cost estimate is approximately $305  million, with a life-cycle cost of approximately $473 million. However, we  found that the implementation cost estimate was uncertain because it had  not been updated since 2007, and the program schedule had not been  updated to account for delays. In addition, we reported that the program\u2019s  management approach, while including many leading practices, could be  strengthened. Finally, we found there was a lack of clarity and definition  regarding the roles of executive-level governance bodies responsible for  overseeing the program. We recommended that USDA update cost and  schedule estimates, address management issues, and clarify the roles  and coordination among governance bodies.", "This is a work of the U.S. government and is not subject to copyright protection in the  United States. The published product may be reproduced and distributed in its entirety  without further permission from GAO. However, because this work may contain  copyrighted images or other material, permission from the copyright holder may be  necessary if you wish to reproduce this material separately."], "subsections": []}]}], "fastfact": []}