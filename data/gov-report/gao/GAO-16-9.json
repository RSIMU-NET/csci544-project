{"id": "GAO-16-9", "url": "https://www.gao.gov/products/GAO-16-9", "title": "Hospital Value-Based Purchasing: Initial Results Show Modest Effects on Medicare Payments and No Apparent Change in Quality-of-Care Trends", "published_date": "2015-10-01T00:00:00", "released_date": "2015-10-01T00:00:00", "highlight": [{"section_title": "Why GAO Did This Study", "paragraphs": ["The HVBP program, which the Centers for Medicare & Medicaid Services (CMS) administers, annually evaluates individual hospital performance on a designated set of quality measures related to inpatient hospital services and, based on those results, adjusts Medicare payments to hospitals in the form of bonuses and penalties. The HVBP program was enacted in 2010 as part of the Patient Protection and Affordable Care Act (PPACA). The first HVBP payment adjustments occurred in fiscal year 2013.", "PPACA included a provision for GAO to assess the HVBP program's impact on Medicare quality and expenditures, including the HVBP program's effects on small rural, small urban, and safety net hospitals. This report evaluates the initial effects of the HVBP program on: (1) Medicare payments to hospitals, (2) quality of care provided by hospitals, and (3) selected hospitals' quality improvement efforts. To determine these initial effects of the HVBP program, GAO analyzed CMS data on bonuses and penalties given to hospitals in fiscal years 2013 through 2015 as well as data on hospital quality measures collected by CMS from 2005 through 2014, the most recent year available. GAO also interviewed officials with eight hospitals that participated in the HVBP program. Hospitals were selected to include safety net, small urban, and small rural hospitals, as well as those that were not part of any of these subgroups.", "The Department of Health and Human Services, which includes CMS, reviewed a draft of this report and provided technical comments, which GAO incorporated as appropriate."]}, {"section_title": "What GAO Found", "paragraphs": ["The bonuses and penalties received by most of the approximately 3,000 hospitals eligible for the Hospital Value-based Purchasing (HVBP) program amounted to less than 0.5 percent of applicable Medicare payments each year. GAO found that safety net hospitals, which provide a significant amount of care to the poor, consistently had lower median payment adjustments\u2014that is, smaller bonuses or larger penalties\u2014than hospitals overall in the program's first three years. However, this gap narrowed over time. In contrast, small urban hospitals had higher median payment adjustments each year than hospitals overall, and small rural hospitals' median payment adjustments were similar to hospitals overall in the first two years and higher in the most recent year.", "GAO's analysis found no apparent shift in existing trends in hospitals' performance on the quality measures included in the HVBP program during the program's initial years. However, shifts in quality trends could emerge in the future as the HVBP program continues to evolve. For example, new quality measures will be added, and the weight placed on clinical process measures\u2014on which hospitals had little room for improvement\u2014will be substantially reduced. For many quality measures not included in the HVBP program, GAO also found that trends in hospitals' performance remained unchanged in the period GAO reviewed, but there were exceptions in the case of three measures that are part of a separate incentive program targeting hospital readmissions. This program focuses exclusively on readmissions and imposes only penalties. The timing of changes in readmission trends provides some indication that the use of financial incentives in quality improvement programs may, under certain circumstances, promote enhanced quality of care. However, understanding the extent of that impact depends on the results of future research.", "Officials from selected hospitals GAO interviewed reported that the HVBP program generally reinforced ongoing quality improvement efforts, but did not lead to major changes in focus. In addition, hospital officials cited a variety of factors that affected their capacity to improve quality. For example, officials from most hospitals GAO contacted reported challenges related to using information technology (IT) systems\u2014including electronic health records\u2014to make quality improvements. In contrast, other hospital officials said their IT systems aided their quality performance efforts, such as by helping to collect clinical data needed to track progress on quality measures. Hospital officials described such factors as affecting their hospital's quality improvement efforts as a whole, rather than being specifically linked to implementation of the HVBP program."]}], "report": [{"section_title": "Letter", "paragraphs": ["The Hospital Value-based Purchasing (HVBP) program, which was  created in 2010 by the Patient Protection and Affordable Care Act  (PPACA), adjusts Medicare payments to hospitals based on a formula  that takes into account each hospital\u2019s performance on a designated set  of quality measures. Prior to the HVBP program, hospitals had received  slightly higher Medicare payments for submitting data for quality  measurement and public reporting under the Centers for Medicare &  Medicaid Services\u2019 (CMS) Inpatient Quality Reporting (IQR) program.  Beginning in fiscal year 2013, the HVBP program provided new bonuses  and penalties that were based on each hospital\u2019s performance on a  subset of those IQR measures.", "The HVBP program represents just one example from a range of efforts  initiated under PPACA to induce providers to improve their quality of care  and become more cost efficient. Some initiatives, like the HVBP program  and Medicare\u2019s Hospital Readmission Reduction Program, which  establishes financial penalties for hospitals with higher readmission  rates, aim to improve hospital quality and efficiency by increasing or  decreasing Medicare\u2019s traditional fee-for-service payments to hospitals.  These initiatives are distinct from \u201calternative payment models\u201d that aim to  improve quality and efficiency by creating a shared stake among different  types of providers by giving them a combined payment for all their  services. At the same time that CMS is implementing modifications to  fee-for-service payments, like the HVBP program, it is also expected to  dramatically expand the scope of these alternative payment models  across the full range of Medicare services. As policy makers consider  how best to pursue these various options, a key question is the extent to  which the HVBP program has demonstrated a capacity to improve health  care quality and cost efficiency.", "The same section of PPACA that created the HVBP program included a  provision for us to assess the impact of the HVBP program on Medicare  quality and expenditures, including the quality of care among small rural,  small urban, and safety net hospitals, which are hospitals that provide a  significant amount of care to the poor. The provision called for an interim  report to be issued by October 1, 2015, and a final report by July 1, 2017.  This interim report examines how the additional financial incentive  created under HVBP may have affected hospitals\u2019 quality of care as well  as their efforts to improve quality in the first years of the program\u2019s  implementation from fiscal year 2013 through fiscal year 2015, including  the effects of the program on small rural, small urban, and safety net  hospitals.", "This report addresses three questions:  1.  What initial effects have been observed from the HVBP program on  Medicare payments to hospitals?  2.  What initial effects have been observed from the HVBP program on  the quality of care provided by hospitals?  3.  What initial effect did the HVBP program have on selected hospitals\u2019  quality improvement efforts?", "To determine the initial effects observed from the HVBP program on  Medicare payments to hospitals, we analyzed data provided by CMS on  the bonuses and penalties awarded to each of the approximately 3,000  HVBP-eligible hospitals from fiscal year 2013 through fiscal year 2015.  We analyzed these data for hospitals overall as well as for small urban,  small rural, and safety net hospitals. To do so, we identified small urban  and small rural hospitals as those having 100 acute care beds or fewer,  using data from the American Hospital Association survey and CMS\u2019s  determination about hospitals\u2019 rural or urban classification.  We identified  safety net hospitals using CMS data on hospitals\u2019 Medicare  disproportionate patient percentage\u2014a measure of Medicaid and low- income Medicare patients\u2014and hospitals\u2019 proportion of uncompensated  care, which we obtained from annual Medicare cost reports. We ranked  HVBP-eligible hospitals on both measures and identified as safety net  hospitals those hospitals that were in the top 10 percent when summing  the rankings of both the disproportionate patient percentage and  uncompensated care measures. In addition, we examined how these  scores related to various hospital characteristics, such as a hospital\u2019s net  income as reported on Medicare cost reports. We reviewed related  documentation and interviewed knowledgeable CMS and American  Hospital Association officials, and we determined that these data on  bonuses and penalties and hospital characteristics were sufficiently  reliable for our purposes.", "To determine the initial effects observed from the HVBP program on the  quality of care provided by hospitals, we analyzed data on quality  measures collected by CMS between 2005 and 2014 (the most recent  available) as part of the IQR Program for the approximately 3,000 HVBP- eligible hospitals. This analysis included both IQR quality measures that  were used in the HVBP payment formula and other IQR measures not  included in the HVBP program, such as measures of hospital  readmissions. We conducted this analysis for all IQR measures related to  inpatient care for which we obtained a sufficient number of data points  both before and after the implementation of the HVBP program. (See  appendix I for a listing of these measures.) The quality measures we  analyzed cover hospital performance on clinical processes to provide  care, patients\u2019 experiences in receiving care, and outcomes associated  with patient care. CMS provided the clinical process and patient  outcomes data. We obtained the patient experience data from the  Hospital Compare website, where CMS publicly reports individual hospital  performance on the IQR measures. CMS officials provided us  supplementary information that allowed us to determine the time period of  patient care for which each set of patient experience applied, as well as  comparable dates for the patient outcome data on mortality and  readmissions that we obtained from CMS. However, CMS was not able to  provide us with one quarter of patient experience data that was not  available from the Hospital Compare website. To identify any patterns  that may be related to the HVBP program, we looked at the median  hospital score of each measure during every period for which data were  reported to CMS, both before and after the HVBP program began. We  analyzed the results of quality measures for hospitals overall as well as  for small urban, small rural, and safety net hospitals. We compared the  median scores of small urban, small rural, and safety net hospitals to  those of hospitals overall to assess the relative performance of those  hospital subgroups. We reviewed related documentation, interviewed  knowledgeable CMS officials, and determined that these data were  sufficiently reliable for our purposes.", "To determine the initial effects of the HVBP program on the quality  improvement efforts of selected hospitals, we interviewed 20 officials from  eight different hospitals. Our interviews included officials from two small  urban hospitals, two small rural hospitals, two safety net hospitals, and  two hospitals that were not part of any of these categories. Within each  category, we selected one hospital that experienced a relatively large  penalty in the first year of the HVBP program and then improved its  performance to receive a bonus in at least one subsequent year, and a  second hospital that experienced a relatively large penalty in the first year  of the HVBP program and then did not improve its performance to receive  a bonus in either subsequent year. Because these hospitals were not  selected randomly, they do not constitute a representative sample of  hospitals participating in the HVBP program. Therefore, the information  obtained from these interviews applies solely to this set of hospitals, and  cannot be generalized to other hospitals.", "We conducted this performance audit from December 2014 to October  2015 in accordance with generally accepted government auditing  standards. Those standards require that we plan and perform the audit to  obtain sufficient, appropriate evidence to provide a reasonable basis for  our findings and conclusions based on our audit objectives. We believe  that the evidence obtained provides a reasonable basis for our findings  and conclusions based on our audit objectives."], "subsections": [{"section_title": "Background", "paragraphs": ["The HVBP program affects Medicare payments to approximately 3,000  acute care hospitals for the inpatient services provided to Medicare  beneficiaries. Hospitals are included in the HVBP program if they are paid  through Medicare\u2019s Inpatient Prospective Payment System. Thus,  hospitals not paid through this system, such as critical access hospitals,  are not subject to payment adjustments by the HVBP program.", "By law, the HVBP program is budget neutral, which means that the total  amount of payment increases, or bonuses, that it awards to hospitals  deemed to provide higher quality of care must equal the total amount of  payment reductions, or penalties, applied to hospitals deemed to provide  lower quality of care. To accomplish this, CMS calculates each hospital\u2019s  payment adjustment percentage by applying a fixed percentage  decrease, and then adding back percentage increases based on the  hospital\u2019s assessed quality performance in prior years. As specified in  PPACA, the initial percentage reduction grew from 1.0 to 1.5 percent from  fiscal year 2013 to fiscal year 2015, and will reach a maximum of 2  percent in fiscal year 2017. The percentage increases added back are  based on a hospital\u2019s performance on each quality measure included in  the HVBP payment formula. For each of these HVBP quality measures,  CMS considers both the results of a hospital\u2019s absolute performance and  the changes in its performance over time, and then counts the better  result toward the hospital\u2019s quality score. The total quality score is derived  from a hospital\u2019s performance on all the HVBP quality measures. If a  hospital obtains a percentage increase or supplement from its HVBP total  quality score that exceeds the initial percentage reduction, it receives a  net increase, or bonus, from HVBP for that year. If the increase from its  total quality score is smaller than the initial reduction, the hospital  receives a net decrease, or penalty, in payments compared to what it  otherwise would have received without the HVBP program.", "The HVBP quality measures are distributed across several different  performance categories\u2014known as domains\u2014that comprise a set of  related quality measures. The number of domains included in the formula  has grown from two (clinical process and patient experience measures) in  fiscal year 2013 to four (adding patient outcomes and efficiency to the  original two). Each domain consists of multiple quality measures, except  for efficiency which consists solely of the Medicare Spending per  Beneficiary measure. Across all of the domains, the number of measures  included in the HVBP payment formula has grown from 20 in fiscal year  2013 to 26 in fiscal year 2015. Before quality measures can be added to  the HVBP formula, they must first have been publicly reported under the  IQR program for at least one year. CMS makes adjustments each year\u2014 usually providing several years notice\u2014to the measures to be included in  the HVBP payment formula in future years and to the relative weights  applied to the quality domains in calculating each hospital\u2019s total quality  score. For example, in fiscal year 2013, 70 percent of the total quality  score was based on clinical process measures. In fiscal year 2015,  clinical process measures represented 20 percent of the total score. (See  appendix II for a list of all the IQR measures included in the HVBP  program.)", "Once CMS calculates a hospital\u2019s performance across all of the domains  and subsequently determines its corresponding bonus or penalty, the  inpatient Medicare payment for each discharged patient is adjusted up or  down throughout the fiscal year based on the size of the hospital\u2019s bonus  or penalty. (For two hypothetical examples, see fig. 1.) Only a portion of  the total Medicare payment is affected, however. For example, the HVBP  bonus or penalty does not alter certain add-on payments, such as those  that compensate hospitals for serving a disproportionate share of low- income patients or for providing medical education. As a result, hospitals  caring for large proportions of low-income Medicare or Medicaid patients  and major teaching hospitals have a lower proportion of their total  Medicare payments affected by their HVBP bonus or penalty, compared  to other hospitals that do not receive these add-on payments."], "subsections": []}, {"section_title": "Most Hospitals Received Bonuses or Penalties of Less than Half of One Percent Each Year, with Generally Similar Results for Small and Safety Net Hospitals", "paragraphs": ["Most hospitals received a bonus or penalty from the HVBP program of  less than 0.5 percent of applicable Medicare payments in each of the first  three years of the program. Small hospitals and hospitals with better  financial performance generally had higher payment adjustments, that is,  larger bonuses or smaller penalties. Among the subgroups we analyzed,  we found that safety net hospitals received lower payment adjustments  compared to hospitals overall, but the gap narrowed over time. Small  rural and small urban hospitals had similar or better results than hospitals  overall."], "subsections": [{"section_title": "A Large Majority of Hospitals Received Bonuses or Penalties of Less than Half a Percent Each Year", "paragraphs": ["In each of the HVBP program\u2019s first three years, a large majority of  hospitals\u2014between 74 percent and 93 percent\u2014received a bonus or  penalty of less than 0.5 percent. (See fig. 2.)", "Roughly the same number of hospitals received bonuses and penalties,  with more bonuses awarded in fiscal year 2013 and fiscal year 2015, and  more penalties awarded in fiscal year 2014. The amount of the annual  median bonuses and median penalties increased slightly each year. The  median bonus in 2015 was 0.32 percent of applicable Medicare payments  and the median penalty was 0.26 percent. (See table 1.)", "In dollar terms, most of these annual bonuses or penalties were less than  $50,000. For example, in fiscal year 2015, 52 percent of hospitals  received bonuses or penalties that led to payment adjustments of less  than $50,000, and 72 percent of hospitals had payment adjustments of  less than $100,000. The size of bonuses or penalties, when measured in  dollars, is a function of both the percentage bonus or penalty and the total  amount of applicable Medicare payments a hospital is owed. In the  aggregate, the HVBP program redistributed about $140 million dollars  from hospitals that received penalties to hospitals that received bonuses  in 2015."], "subsections": []}, {"section_title": "Small Hospital Size and Better Financial Performance Were Associated with Higher Payment Adjustments", "paragraphs": ["We found that smaller hospitals generally had higher payment  adjustments\u2014that is, larger bonuses or smaller penalties\u2014than larger  hospitals in the HVPB program\u2019s first three years. Specifically, hospitals  with 60 beds or fewer had the highest median payment adjustments in  fiscal years 2013 and 2015, from among the five different hospital size  categories (by number of beds) that we analyzed. In fiscal year 2015,  the overall median payment adjustment for hospitals with 60 beds or  fewer was a bonus of 0.38 percent. In contrast, hospitals in the  categories with the largest number of beds\u2014those encompassing 201 to  350 beds and more than 350 beds\u2014had the lowest median payment  adjustments in fiscal year 2015. (Hospitals with more than 350 beds also  had the lowest median payment adjustments in fiscal year 2013, but the  differences among several of the categories were small.) See appendix III  for the results of our analysis of hospital bed size categories.", "In addition, we found that hospitals with better financial performance, as  measured by net income, generally had higher payment adjustments  under the HVBP program. In each of the HVBP program\u2019s first three  years, hospitals with the highest net income had higher payment  adjustments than hospitals with negative net income. Hospitals with net  income of more than 5.0 percent received the highest median bonuses  from among the seven net income categories that we analyzed. (See  appendix IV.) Hospitals with lowest net income from among the  categories we analyzed\u2014negative margins of greater than -5.0\u2014had  among the lowest median payment adjustments in the HVBP program in  fiscal years 2013 and 2014. However, the pattern for this group of  hospitals with the lowest net income did not continue for fiscal year 2015,  as these hospitals had median payment adjustments that were higher  than those of hospitals in some other net income categories."], "subsections": []}, {"section_title": "Compared to Hospitals Overall, Safety Net Hospitals Received Lower Payment Adjustments and Small Urban Hospitals Received Higher Payment Adjustments", "paragraphs": ["Safety net hospitals consistently had lower median payment  adjustments\u2014that is, smaller bonuses or larger penalties\u2014than hospitals  overall. These adjustments ranged between .07 and .12 percentage  points lower in the program\u2019s first three years, with the smallest gap  coming in fiscal year 2015. (See table 2.) Safety net hospitals exceeded  hospitals overall in scores for efficiency but had lower scores each year  for the other three HVBP domains. (See appendix V.) Therefore, one  reason why the gap narrowed in fiscal year 2015 was the addition of the  efficiency domain to the HVBP formula in that year.", "In contrast, small urban hospitals had higher median payment  adjustments\u2014that is, larger bonuses or smaller penalties\u2014than hospitals  overall during the program\u2019s first three years. The greatest difference was  in fiscal year 2015, when small urban hospitals had a median payment  adjustment 0.22 percentage points higher than hospitals overall. Small  urban hospitals had generally higher scores across each of the HVBP  program\u2019s performance domains compared to hospitals overall in all three  years, with the exception of the patient outcomes domain in fiscal year  2014.", "Compared to safety net and small urban hospitals, small rural hospitals\u2019  median payment adjustments more closely mirrored those of hospitals  overall. In two of the program\u2019s first three years, the median payment  adjustment for small rural hospitals was within 0.02 percentage points of  the median for all hospitals, before increasing relative to hospitals overall  in fiscal year 2015. Small rural hospitals generally had higher median  scores on the patient experience and cost efficiency domains than  hospitals overall and had lower median scores on the clinical processes  and patient outcomes domains.", "As with hospitals overall, most safety net, small urban, and small rural  hospitals received bonuses or penalties of less than 0.5 percent in each  of the program\u2019s first three years. (See appendix VI.) However, the  proportion of these hospitals with bonuses or penalties of less than   0.5 percent was generally lower than for hospitals overall, with the largest  differences in fiscal year 2015. For example, 59 percent of small urban  hospitals received payment adjustments of less than 0.5 percent in fiscal  year 2015\u2014compared to 74 percent for hospitals overall. In the same  year, about 36 percent of small urban hospitals received bonuses of   0.5 percent or greater, compared to 18 percent of hospitals overall."], "subsections": []}]}, {"section_title": "Most Quality Trends Have Not Shifted Noticeably Since Implementation of the HVBP Program, Although the Program Continues to Evolve", "paragraphs": ["Our analysis found no apparent shift in HVBP quality measure trends  during the initial years of the program, but such shifts could emerge over  time as the program implements planned changes. The same pattern  held for most quality measures not included in the HVBP program. The  exception was readmissions, where the performance of the same group  of hospitals showed a clear shift in trend towards improvement during the  initial years of the HVBP program."], "subsections": [{"section_title": "No Shift in Trends Was Apparent for the HVBP\u2019s Quality Measures in the Program\u2019s Initial Years, but Such Shifts Could Emerge Over Time As the Program Implements Planned Changes", "paragraphs": ["While the HVBP program aims to provide an incentive to improve  hospitals\u2019 quality of care, preliminary analysis of information from 2013  and 2014\u2014the two years of quality measure results after the program\u2019s  implementation that were available at the time of our analysis\u2014shows  that it did not noticeably alter the existing trends in hospitals\u2019 performance  on any of the quality measures used to determine HVBP payment  adjustments that we examined. This lack of apparent change applied to  all of the clinical process, patient experience, and outcomes measures  included in the program\u2019s payment formula that had sufficient available  data points for us to assess. In general, trends observed for each  measure before the HVBP program took effect in October 2012 remained  largely unchanged after the program\u2019s implementation, as shown by  changes over time in the median hospital quality score for each  measure.", "On clinical process measures, hospitals showed improvement that began  before implementation of the HVBP program. These measures assess  the extent to which hospitals correctly follow certain well-accepted  processes to treat patients, for example by selecting an appropriate initial  antibiotic for a pneumonia patient. The median scores for all of these  clinical process measures increased prior to the implementation of the  HVBP program. (See fig. 3.) As a result, by the start of the HVBP  program in October 2012, the median scores for all clinical process  measures included in the program were already at or close to 100  percent, indicating that hospitals consistently followed these treatment  procedures before the beginning of the HVBP program, and so there was  limited opportunity for hospitals to improve on these measures after the  program was implemented. As previously noted, CMS officials have  adjusted the HVBP formula so that the weight given to clinical process  measures has decreased over time, from 70 percent in 2013 to 20  percent in 2015, with an additional decrease to 5 percent by 2017.", "For patient experience measures\u2014on which, unlike clinical process  measures, hospital scores were not at nor close to 100 percent\u2014 hospitals showed steady, incremental improvement on the measures both  before and after implementation of the HVBP program. These measures  reflect the responses of hospital patients to survey questions about the  quality of their hospital experience, such as how well their pain was  controlled. For each of the HVBP patient experience measures, the  median hospital score trended steadily upward or, in a few cases,  remained the same from one reporting period to the next, with no  substantial shift that coincided with the start of the HVBP program in  October 2012. (See fig. 4.)", "On the three HVBP patient outcomes measures we analyzed\u2014each of  which measures patient mortality that may be related to hospital quality\u2014 the overall trends were mixed, but remained largely consistent both  before and after implementation of the HVBP program. Hospitals showed  steady improvement (i.e., a decrease) in the rate of mortality due to heart  attack, both before and after HVBP program implementation. On the other  hand, rates of mortality due to heart failure and pneumonia stayed  roughly constant over the same time period, increasing slightly prior to the  implementation of HVBP and then possibly leveling off. (See fig. 5.) All  three mortality measures\u2014heart attack, heart failure, and pneumonia\u2014 use information from Medicare claims data to track patient mortality within  30 days of a hospital admission and risk adjust the results based on  patient characteristics.", "Small rural, small urban, and safety net hospitals sometimes performed  better or worse than hospitals overall on one HVBP quality measure or  another across the three domains, but these differences in relative  performance did not change noticeably with the implementation of the  HVBP program. We found a generally consistent pattern in which, for  each of these individual measures, any difference in performance  between hospitals in the subgroup and hospitals overall during the period  before the program either disappeared by the time the program took  effect or remained relatively constant in the following time period. On  clinical process measures included in the HVBP program, small rural,  small urban, and safety net hospitals generally matched hospitals overall  with very high performance before HVBP was implemented. On patient  experience measures included in the HVBP program, small rural and  small urban hospitals performed slightly better than hospitals overall\u2014 both before and after its implementation\u2014while safety net hospitals  performed slightly worse. On patient outcomes measures included in the  HVBP program, small urban hospitals generally matched the performance  of hospitals overall, both before and after its implementation, while safety  net hospitals (on the measures for heart attack and pneumonia mortality)  and small rural hospitals (on all three mortality measures) performed  slightly worse.", "These trends in the HVBP quality measures reflect the relatively short  period of time after the program was implemented in October 2012, which  leaves open the possibility that more noticeable changes could emerge  over a longer period of time. Such shifts in quality trends may develop  slowly for two reasons. First, hospitals may take time to implement their  responses to the program, and these responses, once implemented, may  take additional time to achieve results. Second, the HVBP program has  evolved substantially over time and will continue to do so, and therefore  its effects on quality may also be different. For example, the amount of  Medicare payments at risk will increase from 1.0 percent in fiscal year  2013 to 2.0 percent in fiscal year 2017 and after. In addition, new quality  measures are being added to the program, and the quality measure  domains have increased from two to four, with a fifth\u2014safety\u2014due to be  added to the HVBP formula in fiscal year 2017. Moreover, the weights  attached to those domains, and therefore the relative effect each domain  has on a hospital\u2019s total quality score, have also shifted substantially.  That is particularly true of the clinical process domain, on which hospitals  did not have much room for improvement, as most hospitals already  received scores at or close to 100 percent before the HVBP program was  implemented. As we previously noted, this domain will drop from 70  percent of the total quality score in fiscal year 2013 to 5 percent in fiscal  year 2017. With more quality data collected over a longer period of time  following the implementation of the HVBP program, it may be possible to  detect more subtle and delayed effects of the program."], "subsections": []}, {"section_title": "Quality Measures Not Included in the HVBP Program Also Showed No Apparent Shift in Trends During the Same Initial Years, Except for Readmissions", "paragraphs": ["Most of the IQR quality measures we examined that were not included in  the HVBP program had trends that were similar to those in the program.  Specifically, trends for non-HVBP clinical process measures were very  similar to trends for HVBP clinical process measures, in that hospitals had  improved on these measures and reached a high level prior to the start of  the HVBP program. (See fig. 6.) In addition, the one IQR patient  experience measure not incorporated into the HVBP program, a measure  indicating whether patients would recommend the hospital, exhibited a  trend very similar to that of the HVBP patient experience measures  shown earlier in fig. 4.", "The other non-HVBP measures that we examined were the 30-day  hospital readmissions rates for heart attack, heart failure, and pneumonia;  on all three measures, hospitals showed a different pattern\u2014a clear initial  shift in trend toward improved quality in the period leading up to the  implementation of the HVBP program. These three measures track the  percentage of patients with each condition that are readmitted to a  hospital within 30 days after being discharged. Such readmissions may  be an indication that patients\u2019 recoveries from their initial hospitalizations  were incomplete or that patients received inadequate care after their  discharges. Readmissions for all three conditions remained largely  unchanged from year to year through the end of 2009; afterwards, each  declined noticeably around 2010 and continued to decline over the next  two years. (See fig. 7.)", "The three non-HVBP readmission measures are targeted by the separate  Hospital Readmissions Reduction program. Some analysts who have  reviewed this program noted that this initial shift in trend toward higher  quality on these measures took place after the law that established the  readmissions reduction program, PPACA, was passed in 2010. They  noted that hospitals had an opportunity to implement strategies to reduce  their readmissions before the program began to impose its penalties in  October 2012. While the Hospital Readmissions Reduction program  took effect at the same time as the HVBP program, the difference in the  observed trend for the measures targeted by the readmissions program,  compared to the HVBP program, may in part reflect differences in the  design of the two programs. These differences include (1) focusing on  just readmission rates (in contrast to a complex mix of process, patient  experience, outcome, and efficiency measures for the HVBP program),  (2) not assessing hospitals on their levels of improvement, but instead  focusing only their level of readmissions (with adjustments for patient  demographics), and (3) providing only penalties, rather than bonuses,  which have generally been larger in magnitude than penalties provided  under HVBP.", "As with the HVBP quality measures, these trends reflect the initial years  of the Hospital Readmissions Reduction program, and they could change  with time. Moreover, there could be other factors beyond the  implementation of this program that influenced the decline in heart attack,  heart failure and pneumonia readmissions over that time period.  Nonetheless, the conjunction of the drop in hospital readmission rates  and the introduction of a financial incentive program targeting those rates  provides some additional indication that financial incentives of the sort  broadly offered by programs like the HVBP program and the Hospital  Readmissions Reduction program may, under certain circumstances,  promote enhanced quality of care. However, a clear understanding of the  extent of that impact, and the circumstances under which it may be  maximized, will depend on the results of future research."], "subsections": []}]}, {"section_title": "Hospital Officials Reported That the HVBP Program Helped Reinforce Ongoing Quality Improvement Efforts but Did Not Lead to Major Changes", "paragraphs": ["Officials from selected hospitals reported that the HVBP program  reinforced their ongoing quality improvement programs without leading to  major changes. In addition, they cited a variety of factors that affected  their capacity to make quality improvements, though they said that these  factors were not directly influenced by the HVBP program."], "subsections": [{"section_title": "HVBP Program Reinforced Ongoing Quality Improvement Programs at Selected Hospitals", "paragraphs": ["Officials from eight selected hospitals we contacted reported that the  actions that their hospitals took in response to the HVBP program  focused on reinforcing ongoing efforts to improve quality. Prior to the  HVBP program, each of these hospitals had established a quality  improvement program that sought to improve the hospital\u2019s performance  on quality measures targeted by Medicare\u2019s IQR program, as well as, in  some cases, additional quality measures specified by private insurers,  organizations of peer hospitals, or the hospital itself. Officials from the  selected hospitals reported a variety of specific responses to the HVBP  program. These responses reflected the hospitals\u2019 differing individual  circumstances and generally involved incremental adjustments to existing  quality improvement programs, rather than major changes. The hospital  officials described two ways in particular that the HVBP program  reinforced these existing hospital efforts: (1) elevating the profile of the  HVBP quality measures and thereby providing hospitals with a way to  focus their quality improvement efforts, and (2) motivating hospital  officials to increase the resources directed towards quality improvement.", "Some officials at the selected hospitals noted that one key effect of the  HVBP program was to elevate the profile of those IQR measures included  in the HVBP formula. These officials characterized the HVBP measures  as a set of \u201cnational quality goals\u201d which allowed them to benchmark their  own performance against that of other hospitals. Hospital officials pointed  in particular to the outcome measures in the HVBP program as  influencing efforts to expand their hospitals\u2019 ongoing quality improvement  efforts beyond the traditional focus on clinical process measures.  However, these officials noted that this increased emphasis on outcomes  measures was part of a larger transformation occurring throughout the  health care system. According to the officials, a range of private sector  value-based purchasing and other related initiatives were leading them in  the same direction, and therefore it was difficult for hospital officials to  differentiate actions taken in response to the HVBP program from  responses to these other initiatives.", "Officials at the selected hospitals also credited the HVBP program with  helping to motivate them to increase the resources directed at quality  improvement. Several of these hospital officials described how quality  improvement was a resource-intensive effort, in which one key resource  was skilled staff who could collect, analyze, and act on timely, accurate  and relevant data. Hospital officials reported that they had increased the  number of such staff in recent years. Some officials suggested that the  linkage of hospital quality to payments, such as through the HVBP  program and comparable private sector initiatives, had helped to justify  that shift in staff resources. However, according to hospital officials, this  increase in staff contributed broadly to each hospital\u2019s quality  improvement efforts, rather than being limited to the particular HVBP  quality measures.", "Officials at the selected hospitals emphasized that their ability to identify  and address quality issues depended on their obtaining data about how  their hospital was performing on relevant measures at the current time.  Because the quality information provided by CMS to both hospitals and  the public reflects patient care provided months or years in the past,  these hospital officials found that they needed to generate more timely  quality information on their own, either internally or through private  vendors. This information allowed them to assess their current quality  problems and also determine if the steps that they took to address  problems were working. However, several officials at the selected  hospitals noted that their ability to generate more current information was  limited to certain types of quality measures, primarily those focused on  clinical processes and patient experience. By contrast, many of these  hospital officials said that they could not replicate the outcome measures  that CMS calculated from Medicare claims\u2014as those measures often  reflected what happened to patients after they left the hospital and are  therefore based in part on data not readily available to hospitals. These  hospital officials reported that improving their performance on patient  outcomes was more challenging without accurate and current data.", "Just as hospitals had quality improvement programs in place prior to the  HVBP program, their efforts to improve efficiency were also already  growing when the HVBP program took effect. According to some officials  at the selected hospitals, the addition of the Medicare Spending per  Beneficiary measure to the HVBP program formula, with the introduction  of the efficiency domain in fiscal year 2015, did little to affect those efforts.  In part that was because, like the HVBP outcome measures, hospital  officials reported that they could not independently calculate their  Medicare Spending per Beneficiary scores, nor did they clearly  understand what they would need to do to improve these scores. Instead,  these hospital officials reported that they have proceeded with a range of  more general efforts to improve efficiency by reducing their costs without  impairing quality. These include initiatives to lower supply costs by  standardizing the selection of medical devices, such as artificial joints, as  well as systemic assessments of work processes designed to streamline  their delivery of care. Officials at the selected hospitals reported varying  levels of intensity in the pursuit of these efficiency goals, depending on  the particular circumstances of their hospital. However, according to  these officials, the impetus behind these efficiency efforts came from an  increased focus for both public and private payers on controlling the  growth of hospital costs. Numerous officials at the selected hospitals  stated that their efforts to improve efficiency were aimed at securing the  economic survival of their hospital in an increasingly challenging health  care marketplace, rather than responding to a specific incentive from the  HVBP program."], "subsections": []}, {"section_title": "A Variety of Factors Affected Selected Hospitals\u2019 Capacity to Make Quality Improvements, Which Were Not Directly Affected by the HVBP Program", "paragraphs": ["The issue that officials from most of the selected hospitals we contacted  frequently identified as a barrier to quality improvement efforts was the  hospital\u2019s information technology (IT) system, especially its electronic  health record. Some of these officials described how implementing a new  IT system slowed down their work as staff grappled with learning the  system, how limitations to the system prevented the production of desired  performance-related data, and how the IT system diverted significant  hospital resources into implementing and maintaining the system\u2014 resources that could otherwise have been applied elsewhere, such as to  quality improvement efforts.", "While some hospital officials we spoke to described the difficulties  associated with implementing and effectively utilizing their IT systems,  some highlighted the benefits of those systems as a tool for enhancing  quality. These officials stated that physicians and other staff had come to  rely upon their IT systems over time and that these systems helped their  clinicians to better manage and coordinate care. Others said that their IT  systems helped them to better manage their quality performance efforts,  such as through built-in clinical process reminders in their electronic  health record systems or by facilitating the collection of the patient clinical  data needed for quality measures.", "Some other factors that officials at the selected hospitals identified as  having a negative effect on their ability to make quality improvements  included a lack of financial resources, the absence of timely and easily  interpretable quality performance data, and personnel issues. These  hospital officials told us that reduced reimbursement rates and the  financial demands of a variety of other priorities limited the resources  available for desired quality improvement efforts. Some of these officials  also discussed challenges associated with interpreting performance data  received from CMS, in part due to the delay between when the actions or  outcomes measured actually occur and when the resulting scores are  reported back to the hospital. Personnel issues\u2014including limited  physician engagement or a shortage of staff with needed quality  improvement-related skills\u2014were also described by some officials as  having a negative effect on quality improvement efforts.", "Some officials at both small rural and safety net hospitals we contacted  cited particular patient population and community factors as barriers to  their quality improvement efforts. For example, some safety net hospital  officials spoke about difficulties that arise from serving a disproportionate  share of patients with characteristics\u2014such as low incomes, mental  health issues, language barriers, or little access to transportation\u2014which  officials said make it harder to coordinate care and achieve better  outcomes. In addition, some officials at safety net hospitals stated that a  lack of available external resources in their community\u2014such as mental  health services, social services, and other health care services external to  the hospital\u2014or a lack of coordination between those resources make it  harder to coordinate care and achieve better outcomes. Some small rural  hospital officials also described similar barriers to improving quality of  care, highlighting in particular the limited availability of mental health and  social services in their community.", "Collaboration was a factor that numerous officials at the selected  hospitals mentioned as having a beneficial effect on quality improvement  efforts, and these officials discussed a range of different forums they had  found for collaborative learning. Some cited the usefulness of their area\u2019s  Hospital Engagement Network in providing a forum for sharing best  practices. Others discussed the benefits of learning from regional or  state-based networks that they accessed through their state hospital  association or another convening body. Officials from hospitals that are  part of a hospital system spoke about collaboration within their system.", "While officials at the selected hospitals outlined for us the many factors  they believed affected their quality improvement efforts, they did not  indicate that these factors were specific to the HVBP program. Instead,  these hospital officials said they were working to improve quality for a  number of reasons, including responding to the HVBP program, and that  these factors applied to their ongoing quality improvement efforts as a  whole. Consequently, these officials characterized these factors as  inhibiting or facilitating each hospital\u2019s quality improvement efforts broadly  rather than being factors that specifically affected or were affected by the  implementation of the HVBP program."], "subsections": []}]}, {"section_title": "Agency Comments", "paragraphs": ["We provided a draft of this report to the Department of Health and Human  Services for review, which includes CMS. The department provided  technical comments, which we incorporated as appropriate.", "We are sending copies of this report to the Secretary of Health and  Human Services, the Administrator of the Centers for Medicare &  Medicaid Services, and other interested parties. In addition, the report is  available at no charge on the GAO website at http://www.gao.gov.", "If you or your staffs have any questions about this report, please contact  me at (202) 512-7114 or at kohnl@gao.gov. Contact points for our Offices  of Congressional Relations and Public Affairs may be found on the last  page of this report. GAO staff who made key contributions to this report  are listed in appendix VII."], "subsections": []}]}, {"section_title": "Appendix I: Inpatient Quality Reporting Measures Included in GAO\u2019s Analysis", "paragraphs": ["The following table lists the Inpatient Quality Reporting (IQR) program  measures included in our analysis of quality trends before and after the  introduction of the Hospital Value-based Purchasing (HVBP) program.  The table identifies which quality domain each measure belongs to;  specifies whether the measure was used to calculate HVBP scores  anytime during fiscal years 2013, 2014, or 2015; provides the IQR code  and description that designate the measure under the IQR program; and  indicates the number of data points available for our analysis, in which we  assessed possible shifts in trends from the period before the HVBP  program came into effect through the period after its implementation.  Most of these measures have data points reported quarterly to the IQR  program, with the exception of the patient outcome measures (mortality  and readmissions), which are reported annually."], "subsections": []}, {"section_title": "Appendix II: Quality Measures Included in the Hospital Value-based Purchasing Program, Fiscal Years 2013 through 2017", "paragraphs": [], "subsections": [{"section_title": "Measure Included in Fiscal Year", "paragraphs": ["Description  Heart attack patients received fibrinolytic  agent within 30 minutes of hospital arrival  Heart attack patients received percutaneous  coronary intervention within 90 minutes of  hospital arrival  Heart failure patients received discharge  instructions  Blood culture performed in the emergency  department prior to first antibiotic received in  hospital for pneumonia patients  Appropriate initial antibiotic selection for  community acquired pneumonia patient  Prophylactic antibiotic received within 1 hour  prior to surgical incision  Received prophylactic antibiotic consistent  with recommendations for surgical patients  Prophylactic antibiotics discontinued within  24 hours after surgery end time (48 hours for  cardiac surgery)"], "subsections": []}, {"section_title": "Patient Experience", "paragraphs": [], "subsections": []}, {"section_title": "Measure Included in Fiscal Year", "paragraphs": [], "subsections": []}, {"section_title": "Efficiency", "paragraphs": [], "subsections": []}]}, {"section_title": "Appendix III: Median Hospital Value-based Purchasing Payment Adjustments by Bed Size, Fiscal Years 2013 through 2015", "paragraphs": [], "subsections": []}, {"section_title": "Appendix IV: Median Hospital Value-based Purchasing Payment Adjustments by Net Income, Fiscal Years 2013 through 2015", "paragraphs": [], "subsections": []}, {"section_title": "Appendix V: Median Hospital Value-based Purchasing Domain Scores by Hospital Type, Fiscal Years 2013 through 2015", "paragraphs": [], "subsections": []}, {"section_title": "Appendix VI: Bonuses and Penalties under Hospital Value-based Purchasing by Hospital Type, Fiscal Years 2013 through 2015", "paragraphs": [], "subsections": []}, {"section_title": "Appendix VII: GAO Contact and Staff Acknowledgments", "paragraphs": [], "subsections": [{"section_title": "GAO Contact:", "paragraphs": [], "subsections": []}, {"section_title": "Staff Acknowledgments:", "paragraphs": ["In addition to the contact named above, Will Simerl, Assistant   Director; Zhi Boon; Krister Friday; Colbie Holderness; Eric Peterson;   David Plocher; Vikki Porter, and Steve Robblee made key contributions   to this report."], "subsections": []}]}, {"section_title": "Related GAO Products", "paragraphs": ["Health Care Transparency: Actions Needed to Improve Cost and Quality  Information for Consumers. GAO-15-11. Washington, D.C.: October 20,  2014.", "Electronic Health Record Programs: Participation Has Increased, but  Action Needed to Achieve Goals, Including Improved Quality of Care.  GAO-14-207. Washington, D.C.: March 6, 2014.", "Health Care Quality Measurement: HHS Should Address Contractor  Performance and Plan for Needed Measures. GAO-12-136. Washington,  D.C.: January 13, 2012.", "Hospital Quality Data: HHS Should Specify Steps and Time Frame for  Using Information Technology to Collect and Submit Data. GAO-07-320.  Washington, D.C.: April 25, 2007.", "Hospital Quality Data: CMS Needs More Rigorous Methods to Ensure  Reliability of Publicly Released Data. GAO-06-54. Washington, D.C.:  January 31, 2006."], "subsections": []}], "fastfact": []}